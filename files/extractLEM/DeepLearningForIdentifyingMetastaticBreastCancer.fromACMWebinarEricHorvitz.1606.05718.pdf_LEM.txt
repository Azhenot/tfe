


















































Deep Learning for Identifying Metastatic Breast Cancer 

Dayong Wang Aditya Khosla? Rishab Gargeya Humayun Irshad Andrew H Beck 
Beth Israel Deaconess Medical Center, Harvard Medical School 

?CSAIL, Massachusetts Institute of Technology 
{dwang5,hirshad,abeck2}@bidmc.harvard.edu khosla@csail.mit.edu 

rishab.gargeya@gmail.com 

Abstract 

The International Symposium on Biomedical Imaging 
(ISBI) held a grand challenge to evaluate computational 
system for the automate detection of metastatic breast 
cancer in whole slide image of sentinel lymph node biop- 
sies. Our team won both competition in the grand chal- 
lenge, obtain an area under the receiver operating curve 
(AUC) of 0.925 for the task of whole slide image classifica- 
tion and a score of 0.7051 for the tumor localization task. 
A pathologist independently review the same images, ob- 
taining a whole slide image classification AUC of 0.966 and 
a tumor localization score of 0.733. Combining our deep 
learn system’s prediction with the human pathologist’s 
diagnosis increase the pathologist’s AUC to 0.995, rep- 
resent an approximately 85 percent reduction in human 
error rate. These result demonstrate the power of use 
deep learn to produce significant improvement in the 
accuracy of pathological diagnoses. 

1. Introduction 
The medical specialty of pathology be tasked with pro- 

viding definitive disease diagnosis to guide patient treat- 
ment and management decision [4]. Standardized, accu- 
rate and reproducible pathological diagnosis be essential 
for advance precision medicine. Since the mid-19th cen- 
tury, the primary tool use by pathologist to make diag- 
nose have be the microscope [1]. Limitations of the quali- 
tative visual analysis of microscopic image include lack of 
standardization, diagnostic errors, and the significant cog- 
nitive load require to manually evaluate million of cell 
across hundred of slide in a typical pathologist’s workday 
[15, 17, 7]. Consequently, over the past several decade 
there have be increase interest in develop computa- 
tional method to assist in the analysis of microscopic im- 
age in pathology [9, 8]. 

From October 2015 to April 2016, the International 
Symposium on Biomedical Imaging (ISBI) held the Came- 

lyon Grand Challenge 2016 (Camelyon16) to identify top- 
perform computational image analysis system for the 
task of automatically detect metastatic breast cancer in 
digital whole slide image (WSIs) of sentinel lymph node 
biopsies1. The evaluation of breast sentinel lymph node be 
an important component of the American Joint Committee 
on Cancer’s TNM breast cancer stag system, in which 
patient with a sentinel lymph node positive for metastatic 
cancer will receive a high pathologic TNM stage than pa- 
tients negative for sentinel lymph node metastasis [6], fre- 
quently result in more aggressive clinical management, 
include axillary lymph node dissection [13, 14]. 

The manual pathological review of sentinel lymph node 
be time-consuming and laborious, particularly in case in 
which the lymph node be negative for cancer or contain 
only small focus of metastatic cancer. Many center have 
implement test of sentinel lymph node with immuno- 
histochemistry for pancytokeratins [5], which be protein 
express on breast cancer cell and not normally present 
in lymph nodes, to improve the sensitivity of cancer metas- 
tasis detection. However, limitation of pancytokeratin im- 
munohiostochemistry test of sentinel lymph node in- 
clude: increase cost, increase time for slide preparation, 
and increase number of slide require for pathological 
review. Further, even with immunohistochemistry-stained 
slides, the identification of small cancer metastasis can be 
tedious and inaccurate. 

Computer-assisted image analysis system have be de- 
veloped to aid in the detection of small metastatic focus 
from pancytokeratin-stained immunohistochemistry slide 
of sentinel lymph node [22]; however, these system be 
not use clinically. Thus, the development of effective and 
cost efficient method for sentinel lymph node evaluation 
remains an active area of research [11], a there would be 
value to a high-performing system that could increase accu- 
racy and reduce cognitive load at low cost. 

Here, we present a deep learning-based approach for the 
identification of cancer metastasis from whole slide im- 

1http://camelyon16.grand-challenge.org/ 

1 

ar 
X 

iv 
:1 

60 
6. 

05 
71 

8v 
1 

[ 
q- 

bi 
o. 

Q 
M 

] 
1 

8 
Ju 

n 
20 

16 

http://camelyon16.grand-challenge.org/ 
lphilippe 
Zone de texte 
AI and deep learn a a complementary tool for human expertise = human enhancer and NOT a human replacer!!! 

See Eric Horvitz Webinar 



age of breast sentinel lymph nodes. Our approach us 
million of training patch to train a deep convolutional 
neural network to make patch-level prediction to discrim- 
inate tumor-patches from normal-patches. We then aggre- 
gate the patch-level prediction to create tumor probability 
heatmaps and perform post-processing over these heatmaps 
to make prediction for the slide-based classification task 
and the tumor-localization task. Our system won both com- 
petition at the Camelyon Grand Challenge 2016, with per- 
formance approach human level accuracy. Finally, com- 
bining the prediction of our deep learn system with a 
pathologist’s interpretation produce a significant reduc- 
tion in the pathologist’s error rate. 

2. Dataset and Evaluation Metrics 
In this section, we describe the Camelyon16 dataset pro- 

vided by the organizer of the competition and the evalua- 
tion metric use to rank the participants. 

2.1. Camelyon16 Dataset 

The Camelyon16 dataset consists of a total of 400 whole 
slide image (WSIs) split into 270 for training and 130 for 
testing. Both split contain sample from two institution 
(Radbound UMC and UMC Utrecht) with specific detail 
provide in Table 1. 

Table 1: Number of slide in the Camelyon16 dataset. 

Institution Train Train Testcancer normal 
Radboud UMC 90 70 80 
UMC Utrecht 70 40 50 

Total 160 110 130 

The ground truth data for the training slide consists of 
a pathologist’s delineation of region of metastatic cancer 
on WSIs of sentinel lymph nodes. The data be provide in 
two formats: XML file contain vertex of the annotate 
contour of the location of cancer metastasis and WSI bi- 
nary mask indicate the location of the cancer metastasis. 

2.2. Evaluation Metrics 

Submissions to the competition be evaluate on the 
follow two metrics: 

• Slide-based Evaluation: For this metric, team be 
judged on performance at discriminate between 
slide contain metastasis and normal slides. Com- 
petition participant submit a probability for each 
test slide indicate it predict likelihood of contain- 
ing cancer. The competition organizer measure the 
participant performance use the area under the re- 
ceiver operator (AUC) score. 

• Lesion-based Evaluation: For this metric, partic- 
ipants submit a probability and a correspond 
(x, y) location for each predict cancer lesion within 
the WSI. The competition organizer measure partic- 
ipant performance a the average sensitivity for detect- 
ing all true cancer lesion in a WSI across 6 false pos- 
itive rates: 14 , 

1 
2 , 1, 2, 4, and 8 false positive per WSI. 

3. Method 
In this section, we describe our approach to cancer 

metastasis detection. 

3.1. Image Pre-processing 

(a) (b) 

Figure 1: Visualization of tissue region detection during im- 
age pre-processing (described in Section 3.1). Detected tis- 
sue region be highlight with the green curves. 

To reduce computation time and to focus our analysis 
on region of the slide most likely to contain cancer metas- 
tasis, we first identify tissue within the WSI and exclude 
background white space. To achieve this, we adopt a thresh- 
old base segmentation method to automatically detect the 
background region. In particular, we first transfer the orig- 
inal image from the RGB color space to the HSV color 
space, then the optimal threshold value in each channel be 
compute use the Otsu algorithm [16], and the final mask 
image be generate by combine the mask from H and 
S channels. The detection result be visualize in Fig. 1, 
where the tissue region be highlight use green curves. 
According to the detection results, the average percentage 
of background region per WSI be approximately 82%. 

3.2. Cancer Metastasis Detection Framework 

Our cancer metastasis detection framework consists of a 
patch-based classification stage and a heatmap-based post- 
processing stage, a depict in Fig. 2. 

During model training, the patch-based classification 
stage take a input whole slide image and the ground 
truth image annotation, indicate the location of region 
of each WSI contain metastatic cancer. We randomly 



Train 

Test 

whole slide image 

sample 

sample 

training data 

no 
rm 

al 
tu 

m 
or 

deep model 

P(tumor) 

whole slide image 
overlap image 

patch tumor prob. map 

1.0 

0.0 

0.5 

Figure 2: The framework of cancer metastasis detection. 

extract million of small positive and negative patch from 
the set of training WSIs. If the small patch be locate in 
a tumor region, it be a tumor / positive patch and label 
with 1, otherwise, it be a normal / negative patch and label 
with 0. Following selection of positive and negative training 
examples, we train a supervise classification model to dis- 
criminate between these two class of patches, and we em- 
bed all the prediction result into a heatmap image. In the 
heatmap-based post-processing stage, we use the tumor 
probability heatmap to compute the slide-based evaluation 
and lesion-based evaluation score for each WSI. 

3.3. Patch-based Classification Stage 

During training, this stage us a input 256x256 pixel 
patch from positive and negative region of the WSIs 
and train a classification model to discriminate between 
the positive and negative patches. We evaluate the per- 
formance of four well-known deep learn network ar- 
chitectures for this classification task: GoogLeNet [20], 
AlexNet [12], VGG16 [19] and a face orientate deep net- 
work [21], a show in Table 2. The two deeper network 
(GoogLeNet and VGG16) achieve the best patch-based 
classification performance. In our framework, we adopt 
GoogLeNet a our deep network structure since it be gen- 
erally faster and more stable than VGG16. The network 
structure of GoogLeNet consists of 27 layer in total and 

more than 6 million parameters. 

Table 2: Evaluation of Various Deep Models 

Patch classification accuracy 
GoogLeNet [20] 98.4% 
AlexNet [12] 92.1% 
VGG16 [19] 97.9% 
FaceNet [21] 96.8% 

In our experiments, we evaluate a range of magnifica- 
tion levels, include 40×, 20× and 10×, and we obtain 
the best performance with 40× magnification. We use 
only the 40× magnification in the experimental result re- 
port for the Camelyon competition. 

After generate tumor-probability heatmaps use 
GoogLeNet across the entire training dataset, we note that 
a significant proportion of error be due to false positive 
classification from histologic mimic of cancer. To improve 
model performance on these regions, we extract additional 
training example from these difficult negative region and 
retrain the model with a training set enrich for these hard 
negative patches. 

We present one of our result in Fig. 3. Given a whole 
slide image (Fig. 3 (a)) and a deep learn base patch clas- 
sification model, we generate the correspond tumor re- 
gion heatmap (Fig. 3 (b)), which highlight the tumor area. 



(a) Tumor Slide (b) Heatmap (c) Heatmap overlaid on slide 

Figure 3: Visualization of tumor region detection. 

3.4. Post-processing of tumor heatmaps to compute 
slide-based and lesion-based probability 

After completion of the patch-based classification stage, 
we generate a tumor probability heatmap for each WSI. On 
these heatmaps, each pixel contains a value between 0 and 
1, indicate the probability that the pixel contains tumor. 
We now perform post-processing to compute slide-based 
and lesion-based score for each heatmap. 

3.4.1 Slide-based Classification 

For the slide-based classification task, the post-processing 
take a input a heatmap for each WSI and produce a out- 
put a single probability of tumor for the entire WSI. Given 
a heatmap, we extract 28 geometrical and morphological 
feature from each heatmap, include the percentage of tu- 
mor region over the whole tissue region, the area ratio be- 
tween tumor region and the minimum surround convex 
region, the average prediction values, and the long axis 
of the tumor region. We compute these feature over tu- 
mor probability heatmaps across all training cases, and we 
build a random forest classifier to discriminate the WSIs 
with metastasis from the negative WSIs. On the test cases, 
our slide-based classification method achieve an AUC of 
0.925, make it the top-performing system for the slide- 
base classification task in the Camelyon grand challenge. 

3.4.2 Lesion-based Detection 

For the lesion-based detection post-processing, we aim to 
identify all cancer lesion within each WSI with few false 
positives. To achieve this, we first train a deep model (D-I) 
use our initial training dataset described above. We then 
train a second deep model (D-II) with a training set that be 
enrich for tumor-adjacent negative regions. This model 
(D-II) produce few false positive than D-I but have re- 
duced sensitivity. In our framework, we first threshold the 

heatmap produce from D-I at 0.90, which creates a binary 
heatmap. We then identify connect component within 
the tumor binary mask, and we use the central point a the 
tumor location for each connect component. To estimate 
the probability of tumor at each of these (x, y) locations, we 
take the average of the tumor probability prediction gener- 
ated by D-I and D-II across each connect component. The 
score metric for Camelyon16 be define a the average 
sensitivity at 6 predefined false positive rates: 1/4, 1/2, 1, 2, 
4, and 8 FPs per whole slide image. Our system achieve 
a score of 0.7051, which be the high score in the com- 
petition and be 22 percent high than the second-ranking 
score (0.5761). 

4. Experimental Results 
4.1. Evaluation Results from Camelyon16 

In this section, we briefly present the evaluation result 
generate by the Camelyon16 organizers, which be also 
available on the website 2. 

There be two kind evaluation in Camelyon16: Slide- 
base Evaluation and Lesion-based Evaluation. We won 
both of these two challenge tasks. 
Slide-based Evaluation: The merit of the algorithm 
be assess for discriminate between slide contain 
metastasis and normal slides. Receiver operating character- 
istic (ROC) analysis at the slide level be perform and 
the measure use for compare the algorithm be area un- 
der the ROC curve (AUC). Our submit result be gener- 
ated base on the algorithm in Section 3.4.1. As show in 
Fig. 4, the AUC be 0.9250. Notice that our algorithm per- 
form much good than the second best method when the 
False Positive Rate (FPR) be low. 
Lesion-based Evaluation: For the lesion-based evalua- 
tion, free-response receiver operating characteristic (FROC) 
curve be used. The FROC curve be define a the plot of 

2http://camelyon16.grand-challenge.org/results/ 

http://camelyon16.grand-challenge.org/results/ 


Figure 4: Receiver Operating Characteristic (ROC) curve of 
Slide-based Classification 

sensitivity versus the average number of false-positives per 
image. Our submit result be generate base on the al- 
gorithm in Section 3.4.2. As show in Fig. 5, we can make 
two observations: first, the pathologist do not make any 
false positive predictions; second, when the average number 
of false positive be large than 2, which indicates that there 
will be two false positive alert in each slide on average, our 
performance (in term of sensitivity) even outperform the 
pathologist. 

Figure 5: Free-Response Receiver Operating Characteristic 
(FROC) curve of the Lesion-based Detection. 

4.2. Combining Deep Learning System with a Hu- 
man Pathologist 

To evaluate the top-ranking deep learn system 
against a human pathologist, the Camelyon16 organizer 
have a pathologist examine the test image use in the com- 

petition. For the slide-based classification task,the human 
pathologist achieve an AUC of 0.9664, reflect a 3.4 per- 
cent error rate. When the prediction of our deep learn 
system be combine with the prediction of the human 
pathologist, the AUC be raise to 0.9948 reflect a drop 
in the error rate to 0.52 percent. 

5. Discussion 
Here we present a deep learning-based system for the 

automate detection of metastatic cancer from whole slide 
image of sentinel lymph nodes. Key aspect of our sys- 
tem include: enrichment of the training set with patch 
from region of normal lymph node that the system be 
initially mis-classifying a cancer; use of a state-of-the- 
art deep learn model architecture; and careful design of 
post-processing method for the slide-based classification 
and lesion-based detection tasks. 

Historically, approach to histopathological image anal- 
ysis in digital pathology have focus primarily on low- 
level image analysis task (e.g., color normalization, nu- 
clear segmentation, and feature extraction), follow by 
construction of classification model use classical ma- 
chine learn methods, including: regression, support vec- 
tor machines, and random forests. Typically, these algo- 
rithms take a input relatively small set of image feature 
(on the order of tens) [9, 10]. Building on this framework, 
approach have be developed for the automate extrac- 
tion of moderately high dimensional set of image feature 
(on the order of thousands) from histopathological image 
follow by the construction of relatively simple, linear 
classification model use method design for dimen- 
sionality reduction, such a sparse regression [2]. 

Since 2012, deep learning-based approach have con- 
sistently show best-in-class performance in major com- 
puter vision competitions, such a the ImageNet Large 
Scale Visual Recognition Competition (ILSVRC) [18]. 
Deep learning-based approach have also recently show 
promise for application in pathology. A team from the re- 
search group of Juergen Schmidhuber use a deep learning- 
base approach to win the ICPR 2012 and MICCAI 2013 
challenge focus on algorithm development for mitotic 
figure detection[3]. In contrast to the type of machine 
learn approach historically use in digital pathology, 
in deep learning-based approach there tend to be no dis- 
crete human-directed step for object detection, object seg- 
mentation, and feature extraction. Instead, the deep learn- 
ing algorithm take a input only the image and the image 
label (e.g., 1 or 0) and learn a very high-dimensional and 
complex set of model parameter with supervision come 
only from the image labels. 

Our win approach in the Camelyon Grand Challenge 
2016 utilized a 27-layer deep network architecture and ob- 
tained near human-level classification performance on the 



test data set. Importantly, the error make by our deep 
learn system be not strongly correlate with the error 
make by a human pathologist. Thus, although the patholo- 
gist alone be currently superior to our deep learn system 
alone, combine deep learn with the pathologist pro- 
duced a major reduction in pathologist error rate, reduce 
it from over 3 percent to less than 1 percent. More generally, 
these result suggest that integrate deep learning-based 
approach into the work-flow of the diagnostic pathologist 
could drive improvement in the reproducibility, accuracy 
and clinical value of pathological diagnoses. 

6. Acknowledgments 
We thank all the Camelyon Grand Challenge 2016 or- 

ganizers with special acknowledgment to lead coordinator 
Babak Ehteshami Bejnordi. AK and AHB be co-founders 
of PathAI, Inc. 

References 
[1] E. H. Ackerknecht et al. Rudolf virchow: Doctor, statesman, 

anthropologist. Rudolf Virchow: Doctor, Statesman, Anthro- 
pologist., 1953. 1 

[2] A. H. Beck, A. R. Sangoi, S. Leung, R. J. Marinelli, T. O. 
Nielsen, M. J. van de Vijver, R. B. West, M. van de Rijn, and 
D. Koller. Systematic analysis of breast cancer morphology 
uncovers stromal feature associate with survival. Science 
translational medicine, 3(108):108ra113–108ra113, 2011. 5 

[3] D. C. Cireşan, A. Giusti, L. M. Gambardella, and J. Schmid- 
huber. Mitosis detection in breast cancer histology image 
with deep neural networks. In Medical Image Computing 
and Computer-Assisted Intervention–MICCAI 2013, page 
411–418. Springer, 2013. 5 

[4] R. S. Cotran, V. Kumar, T. Collins, and S. L. Robbins. Rob- 
bin pathologic basis of disease. 1999. 1 

[5] B. J. Czerniecki, A. M. Scheff, L. S. Callans, F. R. 
Spitz, I. Bedrosian, E. F. Conant, S. G. Orel, J. Berlin, 
C. Helsabeck, D. L. Fraker, et al. Immunohistochemistry 
with pancytokeratins improves the sensitivity of sentinel 
lymph node biopsy in patient with breast carcinoma. Can- 
cer, 85(5):1098–1103, 1999. 1 

[6] S. B. Edge and C. C. Compton. The american joint com- 
mittee on cancer: the 7th edition of the ajcc cancer stag 
manual and the future of tnm. Annals of surgical oncology, 
17(6):1471–1474, 2010. 1 

[7] J. G. Elmore, G. M. Longton, P. A. Carney, B. M. Geller, 
T. Onega, A. N. Tosteson, H. D. Nelson, M. S. Pepe, K. H. 
Allison, S. J. Schnitt, et al. Diagnostic concordance among 
pathologist interpret breast biopsy specimens. Jama, 
313(11):1122–1132, 2015. 1 

[8] F. Ghaznavi, A. Evans, A. Madabhushi, and M. Feldman. 
Digital image in pathology: whole-slide image and be- 
yond. Annual Review of Pathology: Mechanisms of Disease, 
8:331–359, 2013. 1 

[9] M. N. Gurcan, L. E. Boucheron, A. Can, A. Madabhushi, 
N. M. Rajpoot, and B. Yener. Histopathological image anal- 

ysis: a review. Biomedical Engineering, IEEE Reviews in, 
2:147–171, 2009. 1, 5 

[10] H. Irshad, A. Veillard, L. Roux, and D. Racoceanu. Methods 
for nucleus detection, segmentation, and classification in digi- 
tal histopathology: A reviewcurrent status and future poten- 
tial. Biomedical Engineering, IEEE Reviews in, 7:97–114, 
2014. 5 

[11] S. Jaffer and I. J. Bleiweiss. Evolution of sentinel lymph 
node biopsy in breast cancer, in and out of vogue? Advances 
in anatomic pathology, 21(6):433–442, 2014. 1 

[12] A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet 
classification with deep convolutional neural networks. In 
F. Pereira, C. J. C. Burges, L. Bottou, and K. Q. Weinberger, 
editors, Advances in Neural Information Processing Systems 
25, page 1097–1105. Curran Associates, Inc., 2012. 3 

[13] G. H. Lyman, A. E. Giuliano, M. R. Somerfield, A. B. Ben- 
son, D. C. Bodurka, H. J. Burstein, A. J. Cochran, H. S. 
Cody, S. B. Edge, S. Galper, et al. American society of clini- 
cal oncology guideline recommendation for sentinel lymph 
node biopsy in early-stage breast cancer. Journal of Clinical 
Oncology, 23(30):7703–7720, 2005. 1 

[14] G. H. Lyman, S. Temin, S. B. Edge, L. A. Newman, R. R. 
Turner, D. L. Weaver, A. B. Benson, L. D. Bosserman, H. J. 
Burstein, H. Cody, et al. Sentinel lymph node biopsy for 
patient with early-stage breast cancer: American society of 
clinical oncology clinical practice guideline update. Journal 
of Clinical Oncology, 32(13):1365–1383, 2014. 1 

[15] R. E. Nakhleh. Error reduction in surgical pathology. 
Archives of pathology & laboratory medicine, 130(5):630– 
632, 2006. 1 

[16] N. Otsu. A Threshold Selection Method from Gray-level 
Histograms. IEEE Transactions on Systems, Man and Cy- 
bernetics, 9(1):62–66, 1979. 2 

[17] S. S. Raab, D. M. Grzybicki, J. E. Janosky, R. J. Zarbo, F. A. 
Meier, C. Jensen, and S. J. Geyer. Clinical impact and fre- 
quency of anatomic pathology error in cancer diagnoses. 
Cancer, 104(10):2205–2213, 2005. 1 

[18] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, 
S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, 
et al. Imagenet large scale visual recognition challenge. 
International Journal of Computer Vision, 115(3):211–252, 
2015. 5 

[19] K. Simonyan and A. Zisserman. Very deep convolu- 
tional network for large-scale image recognition. CoRR, 
abs/1409.1556, 2014. 3 

[20] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, 
D. Anguelov, D. Erhan, V. Vanhoucke, and A. Rabinovich. 
Going deeper with convolutions. In CVPR 2015, 2015. 3 

[21] D. Wang, C. Otto, and A. K. Jain. Face Search at Scale: 80 
Million Gallery. 2015. 3 

[22] D. L. Weaver, D. N. Krag, E. A. Manna, T. Ashikaga, 
S. P. Harlow, and K. D. Bauer. Comparison of pathologist- 
detect and automate computer-assisted image analysis 
detect sentinel lymph node micrometastases in breast can- 
cer. Modern pathology, 16(11):1159–1163, 2003. 1 




