




































































Instagram photo reveal predictive marker of depression 


Reece and Danforth EPJ Data Science (2017) 6:15 
DOI 10.1140/epjds/s13688-017-0110-z 

R E G U L A R A R T I C L E Open Access 

Instagram photo reveal predictive 
marker of depression 
Andrew G Reece1* and Christopher M Danforth2,3,4* 

*Correspondence: 
reece@g.harvard.edu; 
chris.danforth@uvm.edu 
1Department of Psychology, 
Harvard University, 33 Kirkland St, 
Cambridge, MA 02138, USA 
2Computational Story Lab, Vermont 
Advanced Computing Core, 
University of Vermont, 210 
Colchester Ave, Burlington, VT 
05405, USA 
Full list of author information be 
available at the end of the article 

Abstract 
Using Instagram data from 166 individuals, we apply machine learn tool to 
successfully identify marker of depression. Statistical feature be computationally 
extract from 43,950 participant Instagram photos, use color analysis, metadata 
components, and algorithmic face detection. Resulting model outperform 
general practitioners’ average unassisted diagnostic success rate for depression. 
These result held even when the analysis be restrict to post make before 
depressed individual be first diagnosed. Human rating of photo attribute (happy, 
sad, etc.) be weaker predictor of depression, and be uncorrelated with 
computationally-generated features. These result suggest new avenue for early 
screen and detection of mental illness. 

Classification: psychological and cognitive sciences; computer science 

Keywords: social media; depression; psychology; machine learning; computational 
social science 

1 Introduction 
The advent of social medium present a promising new opportunity for early detection and 
intervention in psychiatric disorders. Predictive screen method have successfully an- 
alyzed online medium to detect a number of harmful health condition [–]. All of these 
study rely on text analysis, however, and none have yet harness the wealth of psycho- 
logical data encode in visual social media, such a photograph post to Instagram. In 
this report, we introduce a methodology for analyze photographic data from Instagram 
to predictively screen for depression. 

There be good reason to prioritize research into Instagram analysis for health screening. 
Instagram member currently contribute almost  million new post per day [], and 
Instagram’s rate of new user join have recently outpace Twitter, YouTube, LinkedIn, 
and even Facebook []. A nascent literature on depression and Instagram use have so far 
either yield result that be too general or too labor-intensive to be of practical signifi- 
cance for predictive analytics [, ]. In particular, Lup et al. [] only attempt to cor- 
relate Instagram usership with depressive symptoms, and Andalibi et al. [] employ a 
time-consuming qualitative cod method which the author acknowledge make it ‘im- 
possible to qualitatively analyze’ Instagram data at scale (p.). In our research, we incorpo- 
rat an ensemble of computational method from machine learning, image processing, 

© The Author(s) 2017. This article be distribute under the term of the Creative Commons Attribution 4.0 International License 
(http://creativecommons.org/licenses/by/4.0/), which permit unrestricted use, distribution, and reproduction in anymedium, pro- 
vided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and 
indicate if change be made. 

http://dx.doi.org/10.1140/epjds/s13688-017-0110-z 
http://crossmark.crossref.org/dialog/?doi=10.1140/epjds/s13688-017-0110-z&domain=pdf 
mailto:reece@g.harvard.edu 
mailto:chris.danforth@uvm.edu 


Reece and Danforth EPJ Data Science (2017) 6:15 Page 2 of 12 

and other data-scientific discipline to extract useful psychological indicator from pho- 
tographic data. Our goal be to successfully identify and predict marker of depression in 
Instagram users’ post photographs. 

Hypothesis  Instagram post make by individual diagnose with depression can be re- 
liably distinguish from post make by healthy controls, use only measure extract 
computationally from post photo and associate metadata. 

1.1 Photographic marker of depression 
Photographs post to Instagram offer a vast array of feature that might be analyze 
for psychological insight. The content of photograph can be cod for any number of 
characteristics: Are there people present? Is the set in nature or indoors? Is it night or 
day? Image statistical property can also be evaluate at a per-pixel level, include value 
for average color and brightness. Instagram metadata offer additional information: Did 
the photo receive any comments? How many ‘Likes’ do it get? Finally, platform activity 
measures, such a usage and post frequency, may also yield clue a to an Instagram 
user’s mental state. We incorporate only a narrow subset of possible feature into our 
predictive models, motivate in part by prior research into the relationship between mood 
and visual preferences. 

In study associate mood, color, and mental health, healthy individual identify 
darker, grayer color with negative mood, and generally prefer brighter, more vivid 
color [–]. By contrast, depressed individual be found to prefer darker, grayer col- 
or []. In addition, Barrick, Taylor, & Correa [] found a positive correlation between 
self-identification with depression and a tendency to perceive one’s surroundings a gray 
or lack in color. These finding motivate u to include measure of hue, saturation, 
and brightness in our analysis. We also tracked the use of Instagram filters, which allow 
user to modify the color and tint of a photograph. 

Depression be strongly associate with reduce social activity [, ]. As Instagram 
be use to share personal experiences, it be reasonable to infer that post photo with 
people in them may capture aspect of a user’s social life. On this premise, we use a face 
detection algorithm to analyze Instagram post for the presence and number of human 
face in each photograph. We also count the number of comment and like each post 
receive a measure of community engagement, and use post frequency a a metric 
for user engagement. 

1.2 Early screen application 
Hypothesis  be a necessary first step, a it address an unanswered basic question: Is de- 
pression detectable in Instagram posts? On find support for Hypothesis , a natural 
question arises: Is depression detectable in Instagram posts, before the date of first diag- 
nosis? After receive a depression diagnosis, individual may come to identify with their 
diagnosis [, ]. Individuals’ self-portrayal on social medium may then be influence by 
this identification. It be possible that a successful predictive model, train on the entirety 
of depressed Instagram users’ post histories, might not actually detect depressive sig- 
nals, per se, but rather purposeful content choice intend to convey a depressive condi- 
tion. Training a model use only post make by depressed participant prior to the date 
of first diagnosis address this potential confound factor. 



Reece and Danforth EPJ Data Science (2017) 6:15 Page 3 of 12 

Hypothesis  Instagram post make by depressed individual prior to the date of first 
clinical diagnosis can be reliably distinguish from post make by healthy controls. 

If support be found for Hypothesis , this would not only demonstrate a methodological 
advance for researchers, but also serve a a proof-of-concept for future healthcare appli- 
cations. As such, we benchmarked the accuracy of our model against the ability of general 
practitioner to correctly diagnose depression a show in a meta-analysis by Mitchell, 
Vaze, and Rao []. The author analyze  study that evaluate general practitioners’ 
ability to correctly diagnose depression in their patients, without assistance from scales, 
questionnaires, or other measurement instruments. Out of , patient outcome in- 
cluded across the pool studies, .% be actually depressed, a evaluate separately 
by psychiatrist or validate interview-based measure conduct by researchers. General 
practitioner be able to correctly rule out depression in non-depressed patient % of 
the time, but only diagnose depressed patient correctly % of the time. We refer to 
these meta-analysis finding [] a a comparison point to evaluate the usefulness of our 
models. 

A major strength of our propose model be that their feature be generate use en- 
tirely computational mean - pixel analysis, face detection, and metadata parse - which 
can be do at scale, without additional human input. It seem natural to wonder whether 
these machine-extracted feature pick up on similar signal that human might use to iden- 
tify mood and psychological condition, or whether they attend to wholly different infor- 
mation. A computer may be able to analyze the average saturation value of a million pixels, 
but can it pick out a happy selfie from a sad one? Understanding whether machine learn 
and human opinion be sensitive to the same indicator of depression may be valuable in- 
formation for future research and applications. Furthermore, insight into these issue may 
help to frame our result in the large discussion around human versus machine learning, 
which occupies a central role in the contemporary academic landscape. 

To address these questions, we solicit human assessment of the Instagram pho- 
tographs we collected. We ask new participant to evaluate photo on four simple met- 
rics: happiness, sadness, interestingness, and likability. These rating category be in- 
tend to capture human impression that be both intuitive and quantifiable, and which 
have some relationship to establish depression indicators. DSM-IV [] criterion for Ma- 
jor Depressive Disorder include feel sad a a primary criterion, so sadness (and it 
anti-correlate, happiness) seem obvious candidate a rating categories. Epstein et al. 
[] found depressed individual ‘had difficulty reconcile a self-image a an ‘outgoing 
likeable person’’, which prompt likability a an informative metric. We hypothesize 
that human raters should find photograph post by depressed individual to be sadder, 
less happy, and less likable, on average. Finally, we consider interestingness a a novel 
factor, without a clear directional hypothesis. 

Hypothesis a Human rating of Instagram post on common semantic category can 
distinguish between post make by depressed and healthy individuals. 

Hypothesis b Human rating be positively correlate with computationally-extracted 
features. 



Reece and Danforth EPJ Data Science (2017) 6:15 Page 4 of 12 

If human and machinea predictor show positive correlation, we can infer that each set of 
feature track similar signal of depression. In this case, the strength of the human model 
simply suggests whether it be good or bad than the machine model. On the other hand, 
if machine and human feature show little or no correlation, then regardless of human 
model performance, we would know that the machine feature be capable of screen 
for depression, but use different information signal than what be capture by the affective 
rating categories. 

2 Method 
2.1 Data Collection 
Data collection be crowdsourced use Amazon’s Mechanical Turk (MTurk) crowdwork 
platform. Separate survey be create for depressed and healthy individuals. In the de- 
press survey, participant be invite to complete a survey that involve passing a 
series of inclusion criteria, respond to a standardize clinical depression survey, an- 
swering question related to demographic and history of depression, and share social 
medium history. We use the CES-D (Center for Epidemiologic Studies Depression Scale) 
questionnaire to screen participant depression level []. CES-D assessment quality have 
be demonstrate a on-par with other depression inventories, include the Beck De- 
pression Inventory and the Kellner Symptom Questionnaire [, ]. Healthy participant 
be screen to ensure no history of depression and active Instagram use. See Additional 
file  for actual survey text. 

Qualified participant be ask to share their Instagram usernames and history. An 
app embed in the survey allow participant to securely log into their Instagram ac- 
count and agree to share their data.b Upon secure consent, we make a one-time col- 
lection of participants’ entire Instagram post history. In total we collect , pho- 
tographs from  Instagram users,  of whom have a history of depression. 

We ask a different set of MTurk crowdworkers to rate the Instagram photograph col- 
lected. This new task ask participant to rate a random selection of  photo from the 
data we collected. Raters be ask to judge how interesting, likable, happy, and sad each 
photo seemed, on a continuous - scale. Each photo be rat by at least three differ- 
ent raters, and rating be average across raters. Raters be not inform that photo 
be from Instagram, nor be they give any information about the study participant 
who provide the photos, include mental health status. Each rating category show 
good inter-rater agreement. 

Only a subset of participant Instagram photo be rat (N = ,). We limited rat- 
ings data to a subset because this task be time-consuming for crowdworkers, and so 
prove a costly form of data collection. For the depressed sample, rating be only make 
for photo post within a year in either direction of the date of first depression diagnosis. 
Within this subset, for each user the near  post prior to the diagnosis date be 
rated. For the control population, the most recent  photo from each user’s date of 
participation in this study be rated. 

2.2 Participant safety and privacy 
Data privacy be a concern for this study. Strict anonymity be nearly impossible to guar- 
antee to participants, give that usernames and personal photograph post to Instagram 
often contain identifiable features. We make sure participant be inform of the risk 



Reece and Danforth EPJ Data Science (2017) 6:15 Page 5 of 12 

Figure 1 Comparison of HSV values. Right photograph have high Hue (bluer), low Saturation (grayer), 
and low Brightness (darker) than left photograph. Instagram photo post by depressed individual have 
HSV value shift towards those in the right photograph, compare with photo post by healthy 
individuals. 

of be personally identified, and assure them that no data with personal identifiers, 
include usernames, would be make public or publish in any format. 

2.3 Improving data quality 
We employ several quality assurance measure in our data collection process to reduce 
noisy and unreliable data. Our survey be only visible to MTurk crowdworkers who have 
complete at least  previous task with a minimum % approval rating; MTurk work- 
er with this level of experience and approval rating have be found to provide reliable, 
valid survey response []. We also restrict access to only American IP addresses, a 
MTurk data collect from outside the United States be generally of poorer quality []. 
All participant be only permit to take the survey once. 

We exclude participant who have successfully complete our survey, but who have a 
lifetime total of few than five Instagram posts. We also exclude participant with CES- 
D score of  or higher. Studies have indicate that a CES-D score of  represent an 
optimal cutoff for identify clinically relevant depression across a range of age group 
and circumstance [, ]. 

2.4 Feature extraction 
Several different type of information be extract from the collect Instagram data. 
We use total post per user, per day, a a measure of user activity. We gauge commu- 
nity reaction by counting the number of comment and ‘likes’ each post photograph 
received. Face detection software be use to determine whether or not a photograph 
contain a human face, a well a count the total number of face in each photo, a a 
proxy measure for participants’ social activity levels. Pixel-level average be compute 
for Hue, Saturation, and Value (HSV), three color property commonly use in image 
analysis. Hue describes an image’s color on the light spectrum (ranging from red to 
blue/purple). Lower hue value indicate more red, and high hue value indicate more 
blue. Saturation refers to the vividness of an image. Low saturation make an image ap- 
pear grey and faded. Value refers to image brightness. Lower brightness score indicate a 
darker image. See Figure  for a comparison of high and low HSV values. We also checked 
metadata to ass whether an Instagram-provided filter be apply to alter the appear- 
ance of a photograph. Collectively, these measure serve a the feature set in our primary 



Reece and Danforth EPJ Data Science (2017) 6:15 Page 6 of 12 

model. For the separate model fit on rating data, we use only the four rating category 
(happy, sad, likable, interesting) a predictors. 

2.5 Units of observation 
In determine the best time span for this analysis, we encounter a difficult question: 
When and for how long do depression occur? A diagnosis of depression do not indi- 
cate the persistence of a depressive state for every moment of every day, and to conduct 
analysis use an individual’s entire post history a a single unit of observation be there- 
fore rather specious. At the other extreme, to take each individual photograph a unit of 
observation run the risk of be too granular. De Choudhury et al. [] look at all of a 
give user’s post in a single day, and aggregate those data into per-person, per-day unit 
of observation. We adopt this precedent of ‘user-days’ a a unit of analysis.c 

2.6 Statistical framework 
We use Bayesian logistic regression with uninformative prior to determine the strength 
of individual predictors. Two separate model be trained. The All-data model use all 
collect data to address Hypothesis . The Pre-diagnosis model use all data collect 
from healthy participants, but only pre-diagnosis data from depressed participants, to 
address Hypothesis . We also fit an ‘intercept-only’ model, in which all predictor be 
zero-weighted to simulate a model under a null hypothesis. Bayes factor be use to 
ass model fit. Details on Bayesian estimation, model optimization and selection, and 
diagnostic check be available in Additional file . 

We also employ a suite of supervise machine learn algorithm to estimate the pre- 
dictive capacity of our models. We report prediction result only from the best-performing 
algorithm, a -tree Random Forests classifier. As an informal benchmark for com- 
parison, we present general practitioners’ unassisted diagnostic accuracy a report in 
Mitchell, Vaze, and Rao [].d 

In evaluate binary classification accuracy, a simple proportion of correct classification 
be often inappropriate. In case where data exhibit a class imbalance, i.e. more healthy 
than depressed observation (or vice-versa), reporting naive accuracy can be misleading. 
(A classification accuracy of % seem excellent until it be reveal that % of the data 
model belong to a single class.) Additionally, naive accuracy score be opaque to the 
specific strength and weakness of a binary classifier. Instead, we report precision, recall, 
specificity, negative predictive value, and F score for fuller context. Definitions for these 
term be a follows: 

Precision TP/(TP + FP) 
Recall TP/(TP + FN) 
Specificity TN/(TN + FP) 
Negative Predictive Value TN/(TN + FN) 
F  ∗ (Precision ∗ Recall)/(Precision + Recall) 
TP = True Positive FP = False Positive TN = True Negative FN = False Negative 

3 Results 
Both All-data and Pre-diagnosis model be decisively superior to a null model (Kall = 
.; Kpre = .), see page  of the Additional file  for a description of K. All-data pre- 
dictors be significant with % probability. Pre-diagnosis and All-data confidence lev- 
el be largely identical, with two exceptions: Pre-diagnosis Brightness decrease to % 



Reece and Danforth EPJ Data Science (2017) 6:15 Page 7 of 12 

Figure 2 Magnitude and direction of regression coefficient in All-data (N = 24,713) and 
Pre-diagnosis (N = 18,513) models. X-axis value represent the adjustment in odds of an observation 
belonging to the target class, per unit increase of each predictive variable. Odds be generate by 
exponentiating logistic regression log-odds coefficients. 

Figure 3 Instagram filter usage among depressed and healthy participants. Bars indicate difference 
between observe and expect usage frequencies, base on a Chi-squared analysis of independence. Blue 
bar indicate disproportionate use of a filter by depressed compare to healthy participants, orange bar 
indicate the reverse. All-data result be displayed, see Additional file 1 for Pre-diagnosis plot. 

confidence, and Pre-diagnosis post frequency drop to % confidence, suggest 
a null predictive value in the latter case. 

Increased hue, along with decrease brightness and saturation, predict target class 
observations. This mean that photo post by depressed individual tend to be bluer, 
darker, and grayer (see Figure ). The more comment Instagram post received, the more 
likely they be post by depressed participants, but the opposite be true for like re- 
ceived. In the All-data model, high post frequency be also associate with depres- 
sion. Depressed participant be more likely to post photo with faces, but have a low 
average face count per photograph than healthy participants. Finally, depressed partici- 
pant be less likely to apply Instagram filter to their post photos. Figure  show the 
magnitude and direction of regression coefficient for both models. 



Reece and Danforth EPJ Data Science (2017) 6:15 Page 8 of 12 

Table 1 Comparison of accuracy metric for All-data and Pre-diagnosis model prediction 

Mitchell et al. μ All-data μ(σ ) Pre-diagnosis μ(σ ) 

Recall 0.510 0.697 (0.008) 0.318 (0.012) 
Specificity 0.813 0.478 (0.012) 0.833 (0.010) 
Precision 0.42 0.604 (0.009) 0.541 (0.009) 
Negative Predictive Value 0.858 0.579 (0.008) 0.665 (0.006) 
F1 0.461 0.647 (0.003) 0.401 (0.008) 

General practitioners’ diagnostic accuracy from (Mitchell et al. [24]) be include for comparison. See see Additional file 1 for 
definition of accuracy metrics. 

A closer look at filter usage in depressed versus healthy participant provide additional 
texture. Instagram filter be use differently by target and control group (χall = ., 
p = . × –; χpre = ., p = . × –). In particular, depressed participant 
be less likely than healthy control to use any filter at all. When depressed participant 
do employ filters, they most disproportionately favor the ‘Inkwell’ filter, which convert 
color photograph to black-and-white image (see Figure ). Conversely, healthy partici- 
pant most disproportionately favor the Valencia filter, which lightens the tint of photos. 
Examples of filter photograph be provide in Additional file . 

Our best All-data machine learn classifier, average over five randomize iterations, 
improve over Mitchell et al. [] general practitioner accuracy on most metric (see Ta- 
ble ). Compared with Mitchell et al. [] results, the All-data model be less conservative 
(lower specificity) but good able to positively identify target class observation (higher re- 
call). Given  observations, our model correctly identify % of all target class case 
(n = ), with a relatively low number of false alarm (n = ) and miss (n = ). 

Pre-diagnosis prediction show improvement over the Mitchell et al. [] benchmark 
on precision and specificity. The Pre-diagnosis model found only about a third of actual 
target class observations, but it be correct most of the time when it do predict a target 
class label. By comparison, although Mitchell et al. [] general practitioner discover 
more true case of depression, they be more likely than not to misdiagnose healthy sub- 
jects a depressed. 

Out of the four predictor use in the human rating model (happiness, sadness, likabil- 
ity, interestingness), only the sadness and happiness rating be significant predictor of 
depression. Depressed participants’ photo be more likely to be sadder and less happy 
than those of healthy participants. Ratings assessment generally show strong pattern 
of correlation with one another, but exhibit extremely low correlation with computa- 
tional features. The modest positive correlation of human-rated happiness with the pres- 
ence and number of face in a photograph be the only exception to this trend. Correlation 
matrix for all model be available in Additional file . 

4 Discussion 
The present study employ computational machine learn technique to screen for 
depression use photograph post to Instagram. Our result support Hypothesis , 
that marker of depression be observable in Instagram user behavior, and Hypothesis , 
that these depressive signal be detectable in post make even before the date of first 
diagnosis. Human rating prove capable of distinguish between Instagram post make 
by depressed and healthy individual (Hypothesis a), but show little or no correlation 
with most computational feature (Hypothesis b). Our finding establish that visual social 



Reece and Danforth EPJ Data Science (2017) 6:15 Page 9 of 12 

medium data be amenable to analysis of affect use scalable, computational methods. One 
avenue for future research might integrate textual analysis of Instagram posts’ comments, 
captions, and tags. Considering the early success of textual analysis in detect various 
health and psychological signal on social medium [, , ], the model of textual and 
visual feature together could well prove superior to either medium on it own. 

Our model show considerable improvement over the ability of unassisted general 
practitioner to correctly diagnose depression. On average, more than half of general prac- 
titioners’ depression diagnosis be false positive []. By comparison, the majority of 
both All-data and Pre-diagnosis depression classification be correct. As false diagnosis 
be costly for both healthcare program and individuals, this improvement be noteworthy. 
Health care provider may be able to improve quality of care and good identify individ- 
uals in need of treatment base on the simple, low-cost method outline in this report. 
Given that mental health service be unavailable or underfunded in many country [], 
this computational approach, require only patients’ digital consent to share their social 
medium histories, may open avenue to care which be currently difficult or impossible to 
provide. 

On the other hand, our Pre-diagnosis prediction engine be rather conservative, and 
tend to classify most observation a healthy. There be good reason to believe, however, 
that the Pre-diagnosis prediction accuracy observe represent a low bound on perfor- 
mance. Ideally, we would have use the All-data classifier to evaluate the Pre-diagnosis 
data, a that model be train on a much large dataset. The fact that the Pre-diagnosis 
data be a subset of the full dataset meant that apply the All-data model to Pre- 
diagnosis observation would have artificially inflate accuracy, due to information leak- 
age between training and test data. Instead, we train a new classifier for Pre-diagnosis, 
use training and test partition contain within the Pre-diagnosis data, which left the 
Pre-diagnosis model with considerably few data point to train on. As a result, it be likely 
that Pre-diagnosis accuracy score understate the technique’s true capacity. 

Regarding the strength of specific predictive features, some result match common per- 
ceptions regard the effect of depression on behavior. Photos post to Instagram by 
depressed individual be more likely to be bluer, grayer, and darker, and receive few 
likes. Depressed Instagram user in our sample have an outsized preference for filter 
out all color from post photos, and show an aversion to artificially lighten pho- 
tos, compare to non-depressed controls. These result match well with the literature 
link depression and a preference for darker, bluer, and monochromatic color [–]. 
Depressed user be more likely to post photo with faces, but they tend to post few 
face per photo. This find may be an oblique indicator that depressed user interact in 
small social settings, or at least choose only to share experience of this sort on social 
media. This would be in accordance with previous finding that reduce social interactiv- 
ity be an indicator of depression [, , ]. 

Other, seemingly obvious, relationship fail to emerge. For example, when people 
rat a photograph a sad, that impression be unrelated to how blue, dark, or gray that 
photo was. Both ‘sad’ and ‘blue, dark, and gray’ be strong predictor of depression, how- 
ever, and semantically these description seem like they should match well with one an- 
other, a well a link to depression. These divergence may serve a the basis for a number 
of future research inquiry into the relationship between depressive behavior and com- 
mon perception of depression. 



Reece and Danforth EPJ Data Science (2017) 6:15 Page 10 of 12 

A general limitation to these finding concern the non-specific use of the term ‘depres- 
sion’ in the data collection process. We acknowledge that depression describes a general 
clinical status, and be frequently comorbid with other conditions. It be possible that a spe- 
cific diagnostic class be responsible for drive the observe results, and future research 
should fine-tune questionnaire to acquire specific diagnostic information. Additionally, 
it be possible that our result be in some way specific to individual who receive clin- 
ical diagnoses. Current perspective on depression treatment indicate that people who 
be ‘well-informed and psychologically minded, experience typical symptom of depres- 
sion and little stigma, and have confidence in the effectiveness of treatment, few concern 
about side effects, adequate social support, and high self-efficacy’ seek out mental health 
service []. The intersection of these quality with typical Instagram user demographic 
suggests caution in make broad inferences, base on our findings. 

As these method provide a tool for infer personal information about individuals, 
two point of caution should be considered. First, data privacy and ethical research prac- 
tices be of particular concern, give recent admission that individuals’ social medium data 
be experimentally manipulate or expose without permission [, ]. It be perhaps 
reflective of a current general skepticism towards social medium research that, of the  
individual who begin our survey,  (%) refuse to share their Instagram data, even 
after we provide numerous privacy guarantees. Future research should prioritize estab- 
lishing confidence among experimental participant that their data will remain secure and 
private. Second, data trend often change over time, lead socio-technical model of this 
sort to degrade without frequent calibration []. The finding report here should not 
be take a endure facts, but rather a promising lead upon which to build and refine 
subsequent models. 

Paired with a commensurate focus on uphold data privacy and ethical analytics, the 
present work may serve a a blueprint for effective mental health screen in an increas- 
ingly digitalize society. More generally, these finding support the notion that major 
change in individual psychology be transmit in social medium use, and can be iden- 
tified via computational methods. 

Additional material 

Additional file 1: Supplementary materials. (pdf ) 

Acknowledgements 
The author thank K Lix for conversation and manuscript review. 

Funding 
CMD acknowledges funding from the National Science Foundation under Grant No. IIS-1447634. AGR acknowledges 
support from the Sackler Scholar Programme in Psychobiology. 

Availability of data and material 
Code associate with this study be available publicly on the github page of AGR: 
https://github.com/andrewreece/predicthealth. 

Ethics approval and consent to participate 
This study be review and approve by the Harvard University Institutional Review Board, approval #15-2529 and by 
the University of Vermont Institutional Review Board, approval #CHRMS-16-135. 

Competing interest 
The author declare that they have no compete interests. 

http://dx.doi.org/10.1140/epjds/s13688-017-0110-z 
https://github.com/andrewreece/predicthealth 


Reece and Danforth EPJ Data Science (2017) 6:15 Page 11 of 12 

Consent for publication 
N/A 

Authors’ contribution 
AGR and CMD design the study. AGR perform the study and analyze results. AGR and CMD author the 
manuscript. 

Author detail 
1Department of Psychology, Harvard University, 33 Kirkland St, Cambridge, MA 02138, USA. 2Computational Story Lab, 
Vermont Advanced Computing Core, University of Vermont, 210 Colchester Ave, Burlington, VT 05405, USA. 
3Department of Mathematics and Statistics, University of Vermont, 210 Colchester Ave, Burlington, VT 05405, USA. 
4Vermont Complex Systems Center, University of Vermont, 210 Colchester Ave, Burlington, VT 05405, USA. 

Endnotes 
a The term ‘machine’ (e.g. ‘machine predictors’, ‘machine model’) be use a shorthand for the computational feature 

extraction process we employed. Significant human bias inform this process, however, a the initial selection of 
feature for extraction involve entirely human decision-making. 

b Data collection source code be available on Github, see Additional file 1. 
c Occasionally, when reporting result we refer to ‘observations’ a ‘participants’, e.g. ‘depressed participant receive 

few likes’. It would be more correct to use the phrase ‘photographic data aggregate by participant-user-days’ 
instead of ‘participants’. We chose to sacrifice a degree of technical correctness for the sake of clarity. 

d Comparing point estimate of accuracy metric be not a statistically robust mean of model comparison. However, 
we felt it be more meaningful to frame our finding in a realistic context, rather than to benchmark against a naive 
statistical model that simply predict the majority class for all observations. 

Publisher’s Note 
Springer Nature remains neutral with regard to jurisdictional claim in publish map and institutional affiliations. 

Received: 28 March 2017 Accepted: 22 June 2017 

References 
1. Moreno M, Christakis D, Egan K, Brockman L, Becker T (2012) Associations between displayed alcohol reference on 

Facebook and problem drinking among college students. Arch Pediatr Adolesc Med 166(2):157-163. 
doi:10.1001/archpediatrics.2011.180 

2. De Choudhury M, Counts S, Horvitz E (2013) Predicting postpartum change in emotion and behavior via social 
media. In: Proceedings of the SIGCHI conference on human factor in compute systems. ACM, New York, 
pp 3267-3276. doi:10.1145/2470654.2466447 

3. De Choudhury M, Counts S, Horvitz EJ, Hoff A (2014) Characterizing and predict postpartum depression from 
share Facebook data. In: Proceedings of the 17th ACM conference on computer support cooperative work & 
social computing, ACM, New York, pp 626-638. doi:10.1145/2531602.2531675 

4. De Choudhury M, Gamon M, Counts S, Horvitz E (2013) Predicting depression via social media. In: Seventh 
international AAAI conference on weblogs and social medium 

5. Katikalapudi R, Chellappan S, Montgomery F, Wunsch D, Lutzen K (2012) Associating Internet usage with depressive 
behavior among college students. IEEE Technol Soc Mag 31(4):73-80. doi:10.1109/MTS.2012.2225462 

6. Moreno MA, Jelenchick LA, Egan KG, Cox E, Young H, Gannon KE, Becker T (2011) Feeling bad on Facebook: 
depression disclosure by college student on a social networking site. Depress Anxiety 28(6):447-455. 
doi:10.1002/da.20805 

7. Coppersmith G, Harman C, Dredze M (2014) Measuring post traumatic stress disorder in Twitter. In: Eighth 
international AAAI conference on weblogs and social medium 

8. De Choudhury M, Kiciman E, Dredze M, Coppersmith G, Kumar M (2016) Discovering shift to suicidal ideation from 
mental health content in social media. In: Proceedings of the 2016 CHI conference on human factor in compute 
systems. ACM, New York, pp 2098-2110. doi:10.1145/2858036.2858207 

9. Christakis NA, Fowler JH (2010) Social network sensor for early detection of contagious outbreaks. PLoS ONE 
5(9):e12948. doi:10.1371/journal.pone.0012948 

10. Schmidt CW (2012) Trending now: use social medium to predict and track disease outbreaks. Environ Health Perspect 
120(1):a30-a33. doi:10.1289/ehp.120-a30 

11. Paparrizos J, White RW, Horvitz E (2016) Screening for pancreatic adenocarcinoma use signal from web search 
logs: feasibility study and result J Oncol Pract 12(8):737-744. doi:10.1200/JOP.2015.010504 

12. Instagram (2016) Instagram press release. Available at https://www.instagram.com/press/. Accessed July 26, 2016 
13. Chaffey D (2016) Global social medium research summary 2016. Available at bit.ly/1WRviEI. Accessed July 19, 2016 
14. Lup K, Trub L, Rosenthal L (2015) Instagram #Instasad?: explore association among Instagram use, depressive 

symptoms, negative social comparison, and stranger followed. Cyberpsychol Behav 18(5):247-252. 
doi:10.1089/cyber.2014.0560 

15. Andalibi N, Ozturk P, Forte A (2015) Depression-related imagery on Instagram. In: Proceedings of the 18th ACM 
conference companion on computer support cooperative work & social computing, ACM, New York, pp 231-234. 
doi:10.1145/2685553.2699014 

16. Boyatzis CJ, Varghese R (1994) Children’s emotional association with colors. J Genet Psychol 155(1):77-85 
17. Carruthers HR, Morris J, Tarrier N, Whorwell PJ (2010) The Manchester Color Wheel: development of a novel way of 

identify color choice and it validation in healthy, anxious and depressed individuals. BMC Med Res Methodol 
10:12. doi:10.1186/1471-2288-10-12 

http://dx.doi.org/10.1001/archpediatrics.2011.180 
http://dx.doi.org/10.1145/2470654.2466447 
http://dx.doi.org/10.1145/2531602.2531675 
http://dx.doi.org/10.1109/MTS.2012.2225462 
http://dx.doi.org/10.1002/da.20805 
http://dx.doi.org/10.1145/2858036.2858207 
http://dx.doi.org/10.1371/journal.pone.0012948 
http://dx.doi.org/10.1289/ehp.120-a30 
http://dx.doi.org/10.1200/JOP.2015.010504 
https://www.instagram.com/press/ 
http://bit.ly/1WRviEI 
http://dx.doi.org/10.1089/cyber.2014.0560 
http://dx.doi.org/10.1145/2685553.2699014 
http://dx.doi.org/10.1186/1471-2288-10-12 


Reece and Danforth EPJ Data Science (2017) 6:15 Page 12 of 12 

18. Hemphill M (1996) A note on adults’ color-emotion associations. J Genet Psychol 157(3):275-280 
19. Barrick CB, Taylor D, Correa EI (2002) Color sensitivity and mood disorders: biology or metaphor? J Affect Disord 

68(1):67-71. doi:10.1016/S0165-0327(00)00358-X 
20. American Psychiatric Association (2000) Diagnostic and statistical manual of mental disorders, 4th edn. 

doi:10.1176/appi.books.9780890423349 
21. Bruce ML, Hoff RA (1994) Social and physical health risk factor for first-onset major depressive disorder in a 

community sample. Soc Psychiatry Psychiatr Epidemiol 29(4):165-171. doi:10.1007/BF00802013 
22. Cornford CS, Hill A, Reilly J (2007) How patient with depressive symptom view their condition: a qualitative study. 

Fam Pract 24(4):358-364. doi:10.1093/fampra/cmm032 
23. Karp DA (1994) Living with depression: illness and identity turn points. Qual Health Res 4(1):6-30. 

doi:10.1177/104973239400400102 
24. Mitchell AJ, Vaze A, Rao S (2009) Clinical diagnosis of depression in primary care: a meta-analysis. Lancet 

374(9690):609-619. doi:10.1016/S0140-6736(09)60879-5 
25. Epstein RM, Duberstein PR, Feldman MD, Rochlen AB, Bell RA, Kravitz RL et al (2010) ‘I didn’t know what be wrong:’ 

how people with undiagnosed depression recognize, name and explain their distress. J Gen Intern Med 
25(9):954-961. doi:10.1007/s11606-010-1367-0 

26. Radloff LS (1977) The CES-D scale: a self-report depression scale for research in the general population. Appl Psych 
Manage 1(3):385-401. doi:10.1177/014662167700100306 

27. Fountoulakis KN, Bech P, Panagiotidis P, Siamouli M, Kantartzis S, Papadopoulou A et al (2007) Comparison of 
depressive indices: reliability, validity, relationship to anxiety and personality and the role of age and life events. 
J Affect Disord 97(1-3):187-195. doi:10.1016/j.jad.2006.06.015 

28. Zich JM, Attkisson CC, Greenfield TK (1990) Screening for depression in primary care clinics: the CES-D and the BDI. 
Int J Psychiatry Med 20(3):259-277. doi:10.2190/LYKR-7VHP-YJEM-MKM2 

29. Peer E, Vosgerau J, Acquisti A (2013) Reputation a a sufficient condition for data quality on Amazon Mechanical Turk. 
Behav Res Methods 46(4):1023-1031. doi:10.3758/s13428-013-0434-y 

30. Litman L, Robinson J, Rosenzweig C (2014) The relationship between motivation, monetary compensation, and data 
quality among US- and India-based worker on Mechanical Turk. Behav Res Methods 47(2):519-528. 
doi:10.3758/s13428-014-0483-x 

31. Cuijpers P, Boluijt B, van Straten A (2007) Screening of depression in adolescent through the Internet. Eur Child 
Adolesc Psychiatry 17(1):32-38. doi:10.1007/s00787-007-0631-2 

32. Haringsma R, Engels GI, Beekman ATF, Spinhoven P (2004) The criterion validity of the center for epidemiological 
study depression scale (CES-D) in a sample of self-referred elder with depressive symptomatology. Int J Geriatr 
Psychiatry 19(6):558-563. doi:10.1002/gps.1130 

33. Dodds PS, Harris KD, Kloumann IM, Bliss CA, Danforth CM (2011) Temporal pattern of happiness and information in a 
global social network: hedonometrics and Twitter. PLoS ONE 6(12):e26752. doi:10.1371/journal.pone.0026752 

34. Reece AG, Reagan AJ, Lix KLM, Dodds PS, Danforth CM, Langer EJ (2016) Forecasting the onset and course of mental 
illness with Twitter data. arXiv:1608.07740 

35. Detels R (2009) The scope and concern of public health. Oxford University Press, London 
36. Fiske ST, Hauser RM (2014) Protecting human research participant in the age of big data. Proc Natl Acad Sci USA 

111(38):13675-13676. doi:10.1073/pnas.1414626111 
37. Lumb D (2016) Scientists release personal data for 70,000 OkCupid profiles. Available at engt.co/2b4NnQ0. Accessed 

August 7, 2016 
38. Lazer D, Kennedy R, King G, Vespignani A (2014) The parable of Google flu: trap in big data analysis. Science 

343(6176):1203-1205. doi:10.1126/science.1248506 
39. Gigerenzer G (2004) Mindless statistics. J Socio-Econ 33(5):587-606. doi:10.1016/j.socec.2004.09.03 
40. Hubbard R, Lindsay RM (2008) Why p-values be not a useful measure of evidence in statistical significance testing. 

Theory Psychol 18(1):69-88. doi:10.1177/0959354307086923 
41. Morey RD, Hoekstra R, Rouder JN, Lee MD, Wagenmakers EJ (2015) The fallacy of place confidence in confidence 

intervals. Psychon Bull Rev 23(1):103-123. doi:10.3758/s13423-015-0947-8 
42. Wasserstein RL, Lazar NA (2016) The ASA’s statement on p-values: context, process, and purpose. Am Stat 

70(2):129-133. doi:10.1080/00031305.2016.1154108 
43. Martin A, Quinn K, Park JH (2011) MCMCpack: Markov chain Monte Carlo in R. J Stat Softw 42(9):1-21 
44. Link WA, Eaton MJ (2012) On thin of chain in MCMC. Methods Ecol Evol 3(1):112-115. 

doi:10.1111/j.2041-210X.2011.00131.x 
45. Christensen R, Johnson W, Branscum A, Hanson TE (2011) Bayesian idea and data analysis: an introduction for 

scientist and statisticians. CRC Press, Boca Raton 
46. Jeffries H (1961) Theory of probability. Clarendon, Oxford 
47. Geweke J (1992) Evaluating the accuracy of sampling-based approach to the calculation of posterior moments. 

Vol. 196. Federal Reserve Bank of Minneapolis, Research Department, Minneapolis 
48. Gelman A, Rubin DB (1992) Inference from iterative simulation use multiple sequences. Stat Sci 7(4):457-472 
49. Gelman A, Carlin JB, Stern HS, Rubin DB (2014) Bayesian data analysis (Vol. 2). CRC Press, Boca Raton 

http://dx.doi.org/10.1016/S0165-0327(00)00358-X 
http://dx.doi.org/10.1176/appi.books.9780890423349 
http://dx.doi.org/10.1007/BF00802013 
http://dx.doi.org/10.1093/fampra/cmm032 
http://dx.doi.org/10.1177/104973239400400102 
http://dx.doi.org/10.1016/S0140-6736(09)60879-5 
http://dx.doi.org/10.1007/s11606-010-1367-0 
http://dx.doi.org/10.1177/014662167700100306 
http://dx.doi.org/10.1016/j.jad.2006.06.015 
http://dx.doi.org/10.2190/LYKR-7VHP-YJEM-MKM2 
http://dx.doi.org/10.3758/s13428-013-0434-y 
http://dx.doi.org/10.3758/s13428-014-0483-x 
http://dx.doi.org/10.1007/s00787-007-0631-2 
http://dx.doi.org/10.1002/gps.1130 
http://dx.doi.org/10.1371/journal.pone.0026752 
http://arxiv.org/abs/arXiv:1608.07740 
http://dx.doi.org/10.1073/pnas.1414626111 
http://engt.co/2b4NnQ0 
http://dx.doi.org/10.1126/science.1248506 
http://dx.doi.org/10.1016/j.socec.2004.09.03 
http://dx.doi.org/10.1177/0959354307086923 
http://dx.doi.org/10.3758/s13423-015-0947-8 
http://dx.doi.org/10.1080/00031305.2016.1154108 
http://dx.doi.org/10.1111/j.2041-210X.2011.00131.x 

Instagram photo reveal predictive marker of depression 
Abstract 
Classiﬁcation 
Keywords 

Introduction 
Photographic marker of depression 
Early screen application 

Method 
Data Collection 
Participant safety and privacy 
Improving data quality 
Feature extraction 
Units of observation 
Statistical framework 

Results 
Discussion 
Additional material 
Acknowledgements 
Funding 
Availability of data and material 
Ethics approval and consent to participate 
Competing interest 
Consent for publication 
Authors' contribution 
Author detail 
Endnotes 
Publisher's Note 
References 


