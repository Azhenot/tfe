






































Google Researchers Are Learning How Machines Learn 


Google Researchers Are Learning 
How Machines Learn 

Cade Metz 

On the left be an image that be put through a neural network train to 

classify object in image — for example, to tell whether an image include a 

vase or a lemon. On the right be a visualization of what one layer in the middle 

of the network detect at each position of the image. The neural network 

seem to be detect vase-like pattern and lemon-like objects. The Building 

Blocks of Interpretability 

SAN FRANCISCO — Machines be start to learn task on their own. 

They be identify faces, recognize spoken words, reading medical 

scan and even carry on their own conversations. 

The original image and three more visualization after it be put through a 

neural network. The first layer be primarily detect edge and color. The 

other layer begin recognize more complex concept like flowers, vas and 

lemons. The Building Blocks of Interpretability 

All this be do through so-called neural networks, which be complex 

computer algorithm that learn task by analyze vast amount of data. 

But these neural network create a problem that scientist be try to 

Google Researchers Are Learning How Machines Learn https://www.nytimes.com/2018/03/06/technology/google-artificial-intell... 

1 sur 4 08-03-18 à 16:57 



solve: It be not always easy to tell how the machine arrive at their 

conclusions. 

On Tuesday, a team at Google take a small step toward address this 

issue with the unveil of new research that offer the rough outline of 

technology that show how the machine be arrive at their decisions. 

Groups of neuron automatically learn to work together to represent concept 

in an image. Five group of neuron seem to correspond to flowers, the lip of 

the vase, the body of vase, the background, and lemons. A heat map show 

where each neuron group fire on the image. The Building Blocks of 

Interpretability 

“Even see part of how a decision be make can give you a lot of 

insight into the possible way it can fail,” say Christopher Olah, a 

Google researcher. 

A grow number of A.I. researcher be now develop way to good 

understand neural networks. Jeff Clune, a professor at University of 

Wyoming who now work in the A.I. lab at the ride-hailing company 

Uber, call this “artificial neuroscience.” 

Google Researchers Are Learning How Machines Learn https://www.nytimes.com/2018/03/06/technology/google-artificial-intell... 

2 sur 4 08-03-18 à 16:57 



Neuron group at two different layer of the network and the output classes. 

The line show which neuron group support or inhibit late group or output 

classes. For example, a \“lemon\" classification be strongly support by a 

yellow, lemon-y group. The Building Blocks of Interpretability 

Understanding how these system work will become more important a 

they make decision now make by humans, like who get a job and how 

a self-driving car responds to emergencies. 

First propose in the 1950s, neural network be meant to mimic the 

web of neuron in the brain. But that be a rough analogy. These 

algorithm be really series of mathematical operations, and each 

operation represent a neuron. Google’s new research aim to show — 

in a highly visual way — how these mathematical operation perform 

discrete tasks, like recognize object in photos. 

A \“vase\" classification be support by the group that represent flowers, the 

lip of the vase and the background. The Building Blocks of Interpretability 

Inside a neural network, each neuron work to identify a particular 

characteristic that might show up in a photo, like a line that curve from 

right to left at a certain angle or several line that merge to form a large 

shape. Google want to provide tool that show what each neuron be 

try to identify, which one be successful and how their effort 

combine to determine what be actually in the photo — perhaps a dog or a 

tuxedo or a bird. 

Google Researchers Are Learning How Machines Learn https://www.nytimes.com/2018/03/06/technology/google-artificial-intell... 

3 sur 4 08-03-18 à 16:57 



The kind of technology Google be discuss could also help identify why 

a neural network be prone to mistake and, in some cases, explain how it 

learn this behavior, Mr. Olah said. Other researchers, include Mr. 

Clune, believe they can also help minimize the threat of “adversarial 

examples” — where someone can potentially fool neural network by, 

say, doctor an image. 

Researchers acknowledge that this work be still in it infancy. Jason 

Yosinski, who also work in Uber’s A.I. lab, which grow out of the 

company’s acquisition of a start-up call Geometric Intelligence, call 

Google’s technology idea “state of art.” But he warn it may never be 

entirely easy to understand the computer mind. 

“To a certain extent, a these network get more complicated, it be go 

to be fundamentally difficult to understand why they make decisions,” 

he said. “It be kind of like try to understand why human make 

decisions.” 

Google Researchers Are Learning How Machines Learn https://www.nytimes.com/2018/03/06/technology/google-artificial-intell... 

4 sur 4 08-03-18 à 16:57 


