






































We Could Build an Artificial Brain Right Now - IEEE Spectrum 


Large-scale brainlike system be possible with exist technology—if we’re 
willing to spend the money 

Advertisement 

(/static/special- 

report-can-we- 

copy-the-brain) 

be have a moment. 

Artificial neural network algorithm like deep 

learning, which be very loosely base on the way the 

human brain operates, now allow digital computer to 

perform such extraordinary feat a translate 

language, hunt for subtle pattern in huge amount 

of data, and beating the best human player at Go. 

Brain-inspired compute 

But even a engineer continue to push this mighty 

compute strategy, the energy efficiency of digital 

compute be fast approach it limits. Our data 

center and supercomputer already draw 

megawatts—some 2 percent of the electricity 

consume in the United States go to data center 

alone. The human brain, by contrast, run quite well on about 20 watts, which represent the power 

produce by just a fraction of the food a person eats each day. If we want to keep improve computing, 

we will need our computer to become more like our brains. 

Hence the recent focus on neuromorphic technology, which promise to move compute beyond simple 

neural network and toward circuit that operate more like the brain’s neuron and synapsis do. The 

development of such physical brainlike circuitry be actually pretty far along. Work at my lab and others 

around the world over the past 35 year have lead to artificial neural component like synapsis and 

dendrite that respond to and produce electrical signal much like the real thing. 

So, what would it take to integrate these building block into a brain-scale computer? In 2013, Bo Marr, a 

former graduate student of mine at Georgia Tech, and I 

and 

conclude that it should be possible to build a silicon version of the human cerebral cortex with the 

transistor technology then in production. What’s more, the result machine would take up less than a 

cubic meter of space and consume less than 100 watts, not too far from the human brain. 

look at the best engineering and neuroscience 

knowledge of the time (http://journal.frontiersin.org/article/10.3389/fnins.2013.00118/full) 

That be not to say create such a computer would be easy. The system we envision would still require a 

few billion dollar to design and build, include some significant packaging innovation to make it 

compact. There be also the question of how we would program and train the computer. Neuromorphic 

researcher be still struggle to understand how to make thousand of artificial neuron work together 

and how to translate brainlike activity into useful engineering applications. 

Still, the fact that we can envision such a system mean that we may not be far off from smaller-scale 

chip that could be use in portable and wearable electronics. These gadget demand low power 

We Could Build an Artificial Brain Right Now - IEEE Spectrum http://spectrum.ieee.org/computing/hardware/we-could-build-an-artificial-brain-right-now 

1 sur 7 07/08/2017 19:41 



Photo: Dan Saelinger 

consumption, and so a highly energy-efficient neuromorphic chip—even if it take on only a subset of 

computational tasks, such a signal processing—could be revolutionary. Existing capabilities, like speech 

recognition, could be extend to handle noisy environments. We could even imagine future 

smartphones conduct real-time language translation between you and the person you’re talk to. 

Think of it this way: In the 40 year since the first signal-processing integrate circuits, Moore’s Law have 

improve energy efficiency by roughly a factor of 1,000. The most brainlike neuromorphic chip could 

dwarf such improvements, potentially drive down power consumption by another factor of 100 million. 

That would bring computation that would otherwise need a data center to the palm of your hand. 

will be one in which we build analogue for all the essential 

functional component of the brain: the synapses, which connect neuron and allow them to receive and 

respond to signals; the dendrites, which combine and perform local computation on those incoming 

signals; and the core, or soma, region of each neuron, which integrates input from the dendrite and 

transmits it output on the axon. 

The ultimate brainlike machine 

Simple version of all these basic component have already be implement in silicon. The start 

point for such work be the same metal-oxide-semiconductor field-effect transistor, or MOSFET, that be 

use by the billion to build the logic circuitry in modern digital processors. 

These device have a lot in common with neurons. Neurons operate use voltage-controlled barriers, 

and their electrical and chemical activity depends primarily on channel in which ion move between the 

We Could Build an Artificial Brain Right Now - IEEE Spectrum http://spectrum.ieee.org/computing/hardware/we-could-build-an-artificial-brain-right-now 

2 sur 7 07/08/2017 19:41 



interior and exterior of the cell—a smooth, analog process that involves a steady buildup or decline 

instead of a simple on-off operation. 

MOSFETs be also voltage control and operate by the movement of individual unit of charge. And 

when MOSFETs be operate in the “subthreshold” mode, below the voltage threshold use to digitally 

switch between on and off, the amount of current flow through the device be very small—less than a 

thousandth of what be see in the typical switch of digital logic gates. 

The notion that subthreshold transistor physic could be use to build brainlike circuitry originate with 

Carver Mead of Caltech, who help revolutionize the field of very-large-scale circuit design in the 1970s. 

Mead point out that chip designer fail to take advantage of a lot of interest behavior—and thus 

information—when they use transistor only for digital logic. The process, he 

[PDF], 

essentially involves “taking all the beautiful physic that be built into...transistors, mash it down to a 1 

or 0, and then painfully building it back up with AND and OR gate to reinvent the multiply.” A more 

“physical” or “physics-based” computer could execute more computation per unit energy than it digital 

counterpart. Mead predict such a computer would take up significantly less space a well. 

write in 1990 

(https://web.stanford.edu/group/brainsinsilicon/documents/MeadNeuroMorphElectro.pdf) 

In the intervene years, neuromorphic engineer have make all the basic building block of the brain out 

of silicon with a great deal of biological fidelity. The neuron’s dendrite, axon, and soma component can 

all be fabricate from standard transistor and other circuit elements. In 2005, for example, Ethan 

Farquhar, then a Ph.D. candidate, and I 

use a set of six MOSFETs and a handful of capacitors. Our model generate electrical 

pulse that very closely match those in the soma part of a squid neuron, a long-standing experimental 

subject. What’s more, our circuit accomplish this feat with similar current level and energy 

consumption to those in the squid’s brain. If we have instead use analog circuit to model the equation 

neuroscientist have developed to describe that behavior, we’d need on the order of 10 time a many 

transistors. Performing those calculation with a digital computer would require even more space. 

create a neuron circuit (http://ieeexplore.ieee.org/document 

/1406175/) 

Illustration: James Provost 

We Could Build an Artificial Brain Right Now - IEEE Spectrum http://spectrum.ieee.org/computing/hardware/we-could-build-an-artificial-brain-right-now 

3 sur 7 07/08/2017 19:41 



The floating-gate transistor [top left], which can store differ amount of charge, can be use to build a 

“crossbar” array of artificial synapsis [bottom left]. Electronic version of other neuron components, such a the soma region [right], 

can be make from standard transistor and other circuit components. 

Synapses and Soma: 

be a little trickier. A device that behaves like a synapse must have the ability to 

remember what state it be in, respond in a particular way to an incoming signal, and adapt it response 

over time. 

Emulating synapsis 

There be a number of potential approach to building synapses. The most mature one by far be the 

(STLS), a 

device that my colleague and I at Caltech work on in the 1990s while I be a graduate student 

study under Mead. 

single-transistor learn synapse (http://dl.acm.org/citation.cfm?id=2998687.2998789) 

We first present the STLS in 1994, and it become an important tool for engineer who be building 

modern analog circuitry, such a physical neural networks. In neural networks, each node in the network 

have a weight associate with it, and those weight determine how data from different node be 

combined. The STLS be the first device that could hold a variety of different weight and be 

reprogrammed on the fly. The device be also nonvolatile, which mean that it remembers it state even 

when not in use—a capability that significantly reduces how much energy it needs. 

The STLS be a type of floating-gate transistor, a device that be use to build memory cell in flash memory. 

In an ordinary MOSFET, a gate control the flow of electricity through a current-carrying channel. A 

floating-gate transistor have a second gate that sits between this electrical gate and the channel. This 

float gate be not directly connect to ground or any other component. Thanks to that electrical 

isolation, which be enhance by high-quality silicon-insulator interfaces, charge remain in the float 

gate for a long time. The float gate can take on many different amount of charge and so have many 

different level of electrical response, an essential requisite for create an artificial synapse capable of 

vary it response to stimuli. 

My colleague and I use the STLS to demonstrate the first crossbar network, a computational model 

currently popular with nanodevice researchers. In this two-dimensional array, device sit at the 

intersection of input line run north-south and output line run east-west. This configuration be 

useful because it let you program the connection strength of each “synapse” individually, without 

disturb the other element in the array. 

Thanks in part to a recent Defense Advanced Research Projects Agency program call 

, the 

neuromorphic engineering field have see a surge of research into artificial synapsis built from 

nanodevices such a memristors, resistive RAM, and phase-change memory (as well a floating-gate 

devices). But it will be hard for these new artificial synapsis to improve on our two-decade-old floating- 

gate arrays. Memristors and other novel memory come with program challenges; some have 

device architecture that make it difficult to target a single specific device in a crossbar array. Others need 

a dedicate transistor in order to be programmed, add significantly to their footprint. Because 

floating-gate memory be programmable over a wide range of values, it can be more easily fine-tuned to 

compensate for manufacturing variation from device to device than can many nanodevices. A number of 

neuromorphic research group that try integrate nanodevices into their design have recently come 

around to use floating-gate devices. 

SyNAPSE 

(http://www.darpa.mil/program/systems-of-neuromorphic-adaptive-plastic-scalable-electronics) 

all these brainlike component together? In the human brain, of course, neuronsSo how will we put 

We Could Build an Artificial Brain Right Now - IEEE Spectrum http://spectrum.ieee.org/computing/hardware/we-could-build-an-artificial-brain-right-now 

4 sur 7 07/08/2017 19:41 



and synapsis be intermingled. Neuromorphic chip designer must take a more integrate approach a 

well, with all neural component on the same chip, tightly mixed together. This be not the case in many 

neuromorphic lab today: To make research project more manageable, different building block may be 

place in different areas. Synapses, for example, may be relegate to an off-chip array. Connections may 

be rout through another chip call a field-programmable gate array, or FPGA. 

But a we scale up neuromorphic systems, we’ll need to take care that we don’t replicate the arrangement 

in today’s computers, which lose a significant amount of energy drive bit back and forth between logic, 

memory, and storage. Today, a computer can easily consume 10 time the energy to move the data 

need for a multiple-accumulate operation—a common signal-processing computation—as it do to 

perform the calculation. 

The brain, by contrast, minimizes the energy cost of communication by keep operation highly local. 

The memory element of the brain, such a synaptic strengths, be mixed in with the neural component 

that integrate signals. And the brain’s “wires”—the dendrite and axon that extend from neuron to 

transmit, respectively, incoming signal and outgo pulses—are generally fairly short relative to the size 

of the brain, so they don’t require large amount of energy to sustain a signal. From anatomical data, we 

know that more than 90 percent of neuron connect with only their near 1,000 or so neighbors. 

Another big question for the builder of brainlike chip and computer be the algorithm we will run on 

them. Even a loosely brain-inspired system can have a big advantage over digital systems. In 2004, for 

example, my group use floating-gate device to perform multiplication for signal processing with just 

1/1,000 the energy and 1/100 the area of a comparable digital system. In the year since, other 

researcher and my group have successfully demonstrate neuromorphic approach to many other 

kind of signal-processing calculations. 

But the brain be still 100,000 time a efficient a the system in these demonstrations. That’s because 

while our current neuromorphic technology take advantage of the neuronlike physic of transistors, it 

doesn’t consider the algorithm the brain us to perform it operations. 

Today, we be just begin to discover these physical algorithms—that is, the process that will allow 

brainlike chip to operate with more brainlike efficiency. Four year ago, my research group use silicon 

somas, synapses, and dendrite to perform a word-spotting algorithm that identifies word in a speech 

waveform. This physical algorithm exhibit a thousandfold improvement in energy efficiency over 

predict analog signal processing. Eventually, by lower the amount of voltage supply to the chip 

and use small transistors, researcher should be able to build chip that parallel the brain in 

efficiency for a range of computations. 

When I start in neuromorphic research 30 year ago, everyone believe tremendous opportunity 

would arise from design system that be more like the brain. And indeed, entire industry be now 

be built around brain-inspired AI and deep learning, with application that promise to transform 

—among other things—our mobile devices, our financial institutions, and how we interact in public 

spaces. 

And yet, these application rely only slightly on what we know about how the brain actually works. The 

next 30 year will undoubtedly see the incorporation of more such knowledge. We already have much of 

the basic hardware we need to accomplish this neuroscience-to-computing translation. But we must 

develop a good understand of how that hardware should behave—and what computational scheme 

will yield the great real-world benefits. 

We Could Build an Artificial Brain Right Now - IEEE Spectrum http://spectrum.ieee.org/computing/hardware/we-could-build-an-artificial-brain-right-now 

5 sur 7 07/08/2017 19:41 



Consider this a call to action. We have come pretty far with a very loose model of how the brain works. 

But neuroscience could lead to far more sophisticated brainlike computers. And what great feat could 

there be than use our own brain to learn how to build new ones? 

This article appear in the June 2017 print issue a “A Road Map for the Artificial Brain.” 

be a professor of electrical and computer engineering at 

the Georgia Institute of Technology. 

Jennifer Hasler (http://hasler.ece.gatech.edu/) 

Advertisement 

SPECIAL REPORT: CAN WE COPY THE BRAIN? 
(/static/special-report-can-we-copy-the-brain) 

PREVIOUS 
The Human 
Brain Project 
Reboots: A 
Search Engine 
for the Brain Is 
in Sight 

(/computing/hardware/the-human-brain- 

project-reboots-a-search-engine-for-the- 

brain-is-in-sight) 

NEXT 
Neuromorphic 

Chips Are 
Destined for 

Deep 
Learning—or 

Obscurity 
(/semiconductors/design/neuromorphic- 

chips-are-destined-for-deep-learningor- 

obscurity) 

We Could Build an Artificial Brain Right Now - IEEE Spectrum http://spectrum.ieee.org/computing/hardware/we-could-build-an-artificial-brain-right-now 

6 sur 7 07/08/2017 19:41 



(/aerospace/satellites 

/is-there-a-giant- 

planet-lurking- 

beyond-pluto) 

(/transportation/self- 

driving/the-big- 

problem-with- 

selfdriving-cars-is- 

people) 

(/the-human- 

os/biomedical 

/devices/biological- 

computer- 

commands-living- 

cells-to-light-up) 

(/nanoclast 

/semiconductors 

/devices 

/nanoneurons- 

enable- 

neuromorphic-chips- 

for-voice-recognition) 

(/energy/the- 

smarter-grid/the- 

transformers- 

superheroes-of- 

electrical-inventions) 

(/biomedical/devices 

/smart-contact- 

lenses-and-eye- 

implants-will-give- 

doctors-medical- 

insights) 

We Could Build an Artificial Brain Right Now - IEEE Spectrum http://spectrum.ieee.org/computing/hardware/we-could-build-an-artificial-brain-right-now 

7 sur 7 07/08/2017 19:41 


