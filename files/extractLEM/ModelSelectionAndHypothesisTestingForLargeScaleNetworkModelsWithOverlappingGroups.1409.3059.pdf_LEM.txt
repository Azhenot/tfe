


















































Model selection and hypothesis test for large-scale network model with 
overlap group 

Tiago P. Peixoto∗ 
Institut für Theoretische Physik, Universität Bremen, Hochschulring 18, D-28359 Bremen, Germany 

The effort to understand network system in increase detail have result in a diversity of method 
design to extract their large-scale structure from data. Unfortunately, many of these method 
yield diverge description of the same network, make both the comparison and understand 
of their result a difficult challenge. A possible solution to this outstanding issue be to shift the 
focus away from ad hoc method and move towards more principled approach base on statistical 
inference of generative models. As a result, we face instead the more well-defined task of select 
between compete generative processes, which can be do under a unified probabilistic framework. 
Here, we consider the comparison between a variety of generative model include feature such a 
degree correction, where node with arbitrary degree can belong to the same group, and community 
overlap, where node be allow to belong to more than one group. Because such model variant 
posse an increase number of parameters, they become prone to overfitting. In this work, we 
present a method of model selection base on the minimum description length criterion and posterior 
odds ratio that be capable of fully accounting for the increase degree of freedom of the large 
models, and selects the best one accord to the statistical evidence available in the data. In 
apply this method to many empirical unweighted network from different fields, we observe that 
community overlap be very often not support by statistical evidence and be select a a good 
model only for a minority of them. On the other hand, we find that degree correction tends to be 
almost universally favor by the available data, imply that intrinsic node propriety (as oppose 
to group properties) be often an essential ingredient of network formation. 

I. INTRODUCTION 

Many network posse nontrivial large-scale struc- 
tures such a community [1, 2], core-peripheries [3, 4], 
bipartitions [5] and hierarchy [6, 7]. These structure 
presumedly reflect the organizational principle behind 
network formation. Furthermore, their detection can be 
use to predict miss link [6, 8] or detect spurious 
one [8], a well a determine the robustness of the system 
to failure or intentional damage [9], the outcome of the 
spread of epidemic [10] and functional classification [11], 
among many other applications. The detail with which 
such modular feature be both represent and detect 
reflect directly on the quality of these tasks. However, 
the method of uncover such structure in empirical 
data so far propose be very different in their suitability 
to the aforementioned tasks. Many author have con- 
structed algorithm which attempt to divide the network 
into group accord to some metric devise specifically 
for this purpose. Examples of this include modular- 
ity [12], betweenness [13], link similarity [14], clique per- 
colation [15], encode of random walk [16], and many 
more [2]. Unfortunately, many of these method will re- 
sult in diverge description for the same network. Fur- 
thermore, the information they obtain cannot be easily 
use to generalize the data, and make prediction [6, 8]. 
Alternatively, other author have focus on construct 
generative model that encode the large-scale structure 
a parameters, which can then be infer from empir- 

∗ tiago@itp.uni-bremen.de 

ical data (e.g. [17–20]). These method not only rep- 
resent a more principled and rigorous stance, but they 
can also demonstrably overcome inherent limitation of 
more ad hoc method [7]. Furthermore, they can be 
use to generalize the data, and make prediction [6, 8]. 
Both approaches, however, suffer from a common funda- 
mental problem, namely the difficulty in decide which 
detection method or generative model provide a more 
appropriate description of a give network. This issue 
tends to escalate a more elaborate model and method 
be developed, include feature such a degree correc- 
tion [19], community overlap [14, 15, 18, 20], hierarchi- 
cal structure [6, 7, 21], self-similarity [22, 23], bipartite- 
ness [5], edge and node correlate [24, 25], social tier [26], 
multilayer structure [27], temporal information [28], to 
name only a few. Although such development be es- 
sential, they should be make with care, since increas- 
ing the complexity of the network description may lead 
to artificial result cause by overfitting. While this be 
a well-understood phenomenon when deal with inde- 
pendent data or time series, open problem remain when 
the empirical data be a network, for which many com- 
mon assumption no longer hold and the usual method 
perform very poorly [29]. This problem be significantly 
exacerbate when method be use which make no at- 
tempt to ass the statistical significance of the results. 
Unfortunately, most method that be not base on gen- 
erative model fall into this class. Although for certain 
specially construct example some direct connection 
between statistical inference and ad hoc method can be 
make [30, 31], and in the case of some spectral method 
a much deeper connection seem to exist [32, 33], they 
still inherently lack the capacity to reliably distinguish 

ar 
X 

iv 
:1 

40 
9. 

30 
59 

v4 
[ 

ph 
y 

ic 
s. 

da 
ta 

-a 
n] 

2 
6 

M 
ar 

2 
01 

5 

mailto:tiago@itp.uni-bremen.de 


2 

signal from noise. Furthermore — what be perhaps even 
more important — these different method cannot easily 
be compare to each other. For example, suppose that 
for the same network a nonoverlapping partition be found 
by compress random walks, another overlap parti- 
tion be obtain with clique percolation, and yet another 
with a local method base on link similarity (all of which 
be method not base on generative models). Most of 
the time, these three partition will be very different, 
and yet there be no obvious way to decide which one be 
a more faithful representation of the network. Although 
method such a network benchmark [34–36] and per- 
turbation analysis [37] have be developed in order to 
alleviate this issue, they have only limited applicability to 
the large problem. Namely, network benchmark cannot 
be use when an appropriate representation of an empir- 
ical network be not known, and if one want to decide, 
for instance, if the network posse overlap group 
or not. In a similar vein, perturbation analysis provide 
information about the significance of result originate 
from a single algorithm, which cannot be directly use 
to compare two very different ones. 

On the other hand, the situation be different if one fo- 
cu on generative model alone. Since in this context 
the same problem be pose in a probabilistic framework, 
comparison between model be possible, even if the mod- 
el be very different. And since model can be design 
to accommodate arbitrary topological features, we lose 
no explanatory power when compare to the ad hoc ap- 
proaches. We show in this work that this central issue 
can be tackle in a consistent and principled manner by 
perform model selection base on statistical evidence. 
In particular, we employ the minimum description length 
principle (MDL) [38, 39], which seek to minimize the to- 
tal information necessary to describe the observe data 
a well a the model parameters. This can be equiva- 
lently formulate a the maximization of a Bayesian pos- 
terior likelihood which include noninformative prior on 
the parameters, from which a posterior odds ratio be- 
tween different hypothesis can be computed, yield a 
degree of confidence for a model to be reject in favor 
of another. We focus on the stochastic block model a 
the underlie generative model, a well a variant that 
include degree correction and mixed memberships. We 
show that with these model MDL can be use to pro- 
duce a very efficient algorithm that scale well for very 
large network and with an arbitrarily large number of 
groups. Furthermore, we employ the method to a wide 
variety of empirical network data sets, and we show that 
community overlap be seldom select a the most ap- 
propriate model. This cast doubt on the claimed per- 
vasiveness of group overlap [14, 15], obtain predom- 
inantly with nonstatistical methods, which should per- 
hap be interpret a an artifact of use method with 
more degree of freedom, instead of an underlie prop- 
erty of many system — at least a long a there be a lack 
of corroborate evidence support the overlap (such 
as, potentially, edge weight [25, 40] or multilayer struc- 

ture [27], which we do not consider here). On the other 
hand, we find that degree correction tends to be select 
for a significant majority of systems, imply that indi- 
vidual node “fitness” that be not uniformly inherit by 
group membership be a fundamental aspect of network 
formation. 

This paper be divide a follows. In Sec. II we present 
the generative model considered, and in Sec. III we de- 
scribe the model selection procedure base on MDL. In 
Sec. IV we present the result for a variety of empirical 
networks. In Sec. V we analyze the general identifiability 
limit of the overlap models, and in Sec. VI we de- 
scribe in detail the inference algorithm used. In Sec. VII 
we finalize with a discussion. 

II. GENERATIVE MODELS FOR NETWORK 
STRUCTURE 

A generative model be one which attribute to each 
possible graph G a probability P (G|{θ}) for it to be 
observed, condition on some set of parameter {θ}. 
Here we will be restrict to discrete uniform models, 
where specific choice of {θ} prohibit some graph from 
occurring, but those which be allow to occur have 
the same probability. For these model we can write 
P (G|{θ}) = 1/Ω({θ}) = e−S(G|{θ}), with Ω({θ}) be 
the total number of possible graph compatible with a 
give choice of parameters, and S(G|{θ}) = ln Ω({θ}) 
be the entropy of this constrain ensemble [41, 42]. In 
order to infer the parameter {θ} via maximum likeli- 
hood, we need to maximize P (G|{θ}), or equivalently, 
minimize S(G|{θ}). This approach, however, cannot be 
use if the order of the model be unknown, i.e. the num- 
ber of degree of freedom in the parameter set {θ}, since 
choice with high order will almost always increase 
P (G|{θ}), result in overfitting. For the same reason, 
maximum likelihood cannot be use to distinguish be- 
tween model belonging to different classes, since mod- 
el with large degree of freedom will inherently lead to 
large likelihoods. In order to avoid overfitting, one need 
to maximize instead the Bayesian posterior probability 
P ({θ}|G) = P (G|{θ})P ({θ})/P (G), with P (G) be 
a normalize constant. The prior probability P ({θ}), 
which encodes our a priori knowledge of the param- 
eters (if any) should inherently become small if the 
number of degree of freedom increases. We will also 
be restrict to discrete parameter with uniform prior 
probabilities, so that P ({θ}) = e−L({θ}), with L({θ}) be- 
ing the entropy of the ensemble of possible parameter 
choices. We can thus write the total posterior likelihood 
a P ({θ}|G) = e−Σ/P (G), with Σ = L({θ}) + S(G|{θ}). 
The value Σ be the description length of the data [38, 39], 
i.e. the total amount of information require to describe 
the observe data condition on a set of parameter a 
well a the parameter set itself [43]. Hence, if we maxi- 
mize P ({θ}|G) we be automatically find the parame- 
ter choice that compress the data most, since it will also 



3 

minimize it description length Σ. Because of this, there 
be no difference between specify probabilistic model 
for both G and {θ}, or encode scheme that quantify 
the amount of information necessary to describe both. 
In the following, we will make use of both terminology 
interchangeably, whenever most appropriate. 

A. Overlapping model without degree correction 

The main feature we want to consider in our generative 
model be the existence of well-defined group of nodes, 
which be connect to other group with arbitrary prob- 
abilities, such that node belonging to the same group 
play a similar role in the large-scale network structure. 
We also want to include the possibility of node belonging 
to more than one group, and in so do inherit the topo- 
logical property of all group to which they belong. In 
order to implement this, we consider a simple variation of 
the stochastic block model [17, 44–46] with N node and 
E edges, where the node can belong to different groups. 
Hence, to each node i we attribute a binary mixture vec- 
tor~bi with B entries, where a give entry bri ∈ {0, 1} spec- 
ifies whether or not the node belongs to block r ∈ [1, B]. 
In addition to this overlap partition, we simply define 
the edge-count matrix {ers}, which specifies how many 
edge be place between node belonging to block r 
and s (or twice that number for r = s, for convenience 
of notation), where we have 

∑ 
r er = 2E. This sim- 

ple definition allows one to generate a broad variety of 
overlap patterns, which be not confine to purely as- 
sortative structures, and the nonoverlapping model can 
be recover a a special case, simply by put each 
node in a single group. 

The likelihood of observe a give graph with 
the above constraint be simply P (G|{~bi}, {ers}) = 
1/Ω({~bi}, {ers}), where Ω({~bi}, {ers}) be the number of 
possible graphs, and St = ln Ω({~bi}, {ers}) be the associ- 
ated ensemble entropy. In this construction, the existence 
of multiple edge be allowed. However, the placement of 
multiple edge between node of block r and s should 
occur with a probability proportional to O(ers/nrns), 
where nr be the number of node which belong to block 
r, i.e. nr = 

∑ 
i b 
r 
i (note that 

∑ 
r nr ≥ N). Since here 

we be predominantly interested in the sparse situation 
where er ∼ O(N/B2) and nr ∼ O(N/B), the proba- 
bility of observe parallel edge will decay a O(1/N), 
and hence can be neglect in the large network limit. 
Making use of this simplification, we may approximately 
count all possible graph generate by the parameter 
{~bi}, {ers} a the number of graph where each distinct 
membership of a single node be consider to be a dif- 
ferent node with a single membership. This corresponds 
to an augment graph generate via a nonoverlapping 
block model with N ′ = 

∑ 
r nr nodes, where N 

′ ≥ N , but 

with the same matrix {ers}, for which the entropy be [42] 

St ' E − 
1 

2 

∑ 
r 

er ln 

( 
er 
nrns 

) 
, (1) 

where nrns � er be assumed. Under this formulation, 
we recover trivially the single-membership case simply 
by assign each node to a single group, since Eq. 1 
remains the same in that special case. It be possible to 
remove the approximation that no parallel edge occur, 
by define the model somewhat differently, a in show 
in Appendix B 1, in which case the Eq. 1 hold exactly 
a long a no parallel edge be observed. 

Like it nonoverlapping counterpart, the block model 
without degree correction assumes that node belonging 
to the same group will receive approximately the same 
number of edge of that type. Hence, when apply to 
empirical data, the module discover will also tend to 
have this property. This mean that if the graph pos- 
sess large degree variability, the group infer will 
tend to correspond to different degree class [19]. On a 
similar vein, if a node belongs to more than one group, 
it will also tend to have a total degree that be large 
than node that belong to either group alone, since it 
will receive edge of each type in an independent fashion. 
In other words, the group intersection be expect to 
be strictly denser than the nonoverlapping portion of 
each group. Note that, in this respect, this model differs 
from other popular ones, such a the mixed membership 
stochastic block model (MMSBM) [18], where the den- 
sity at the intersection be the weight average of the 
group (see Appendix B 1). 

B. Overlapping model with degree correction 

In the precede model, node that belong to the same 
group mixture receive, on average, the same number of 
connections. This mean that the group membership be 
the only factor regulate the propensity of a give node 
to receive links. An alternative possibility, formulate 
by Karrer et al [19], be to consider that the node have 
individual propensity to connect themselves, which be 
not necessarily correlate with their group memberships. 
Therefore, in this “degree-corrected” model, node of the 
same group be allow to posse very different degrees. 
It have be demonstrate in Ref. [19] that this model 
yield more intuitive partition for many empirical net- 
works, suggest that these intrinsic propensity may 
be a good model for these systems. In an analogous 
manner, a multiple membership version of the stochastic 
block model with degree correction can be defined. This 
can be achieve simply by specifying, in addition to the 
overlap partition {~bi}, the number of half-edges in- 
cident on a give node i which belong to group r, i.e. 
kri . The combine label degree of a node i be denote 
~ki = {kri }. Given this label degree sequence, one can 
simply use the same edge count matrix {ers} a before 



4 

to generate the graph. If we again make the assumption 
that the occurrence of parallel edge can be neglected, the 
total number of graph fulfil these constraint be ap- 
proximately equal to the nonoverlapping ensemble where 
each set of half-edges incident on any give node i that 
belongs to the same group r be consider a an individ- 
ual node with degree kri , for which the ensemble entropy 
be [42] 

Sd ' −E − 
1 

2 

∑ 
r 

er ln 

( 
er 
eres 

) 
− 
∑ 
ir 

ln kri !, (2) 

where ers( 
〈 
k2 
〉 
r 
− 〈k〉r)( 

〈 
k2 
〉 
s 
− 〈k〉s)/〈k〉 

2 
r〈k〉 

2 
s � nrns 

have be assumed. Similarly to the non-degree-corrected 
case, it be possible to remove the approximation that no 
parallel edge occur, by use a “Poisson” version of the 
model, a be show in Appendix B 2. Under this formula- 
tion, it can be show that this model be equivalent to the 
one propose by Ball et al [20], although here we keep 
track of the individual label on the half-edges a latent 
variables, instead of their probabilities. 

Since we incorporate the label degree sequence a 
model parameters, node that belong to the same group 
can have arbitrary degrees. Furthermore, since the same 
applies to node that belong simultaneously to more 
than one group, the overlap between group be nei- 
ther preferably dense nor sparse; it all depends on the 
parameter {~ki}. 

III. MODEL SELECTION 

As discuss previously, in order to perform model se- 
lection, it be necessary to include the information need 
to describe the model parameters, in addition to the data. 
The parameter which need to be described be the over- 
lap partition {~bi}, the edge count {ers}, and in the 
case of the degree-corrected model we also need to the 
describe the label degree sequence {~ki}. 

When choose an encode for the parameter (via a 
particular generative process) we need to avoid redun- 
dancy, and describe them a parsimoniously a possible, 
while at the same time avert bias by be nonin- 
formative. In the following, we systematically employ 
two-level Bayesian hierarchies, where discrete prior dis- 
tributions be parametrized via generic counts, which be 
themselves sample from uniform nonparametric hyper- 
priors. 

A. Overlapping partition, {~bi} 

In order to specify the partition {~bi}, we assume that 
all different 2B − 1 mixture be not necessarily equally 
likely, and furthermore the size di = 

∑ 
r b 
r 
i of the mix- 

tures be also not a priori assume to follow any specific 
distribution. More specifically, we consider the mixture 

to be the outcome of a generative process with two steps. 
We first generate the local mixture size {di}, from a non- 
parametric distribution. Then, give the mixture sizes, 
we generate the actual mixture {~bi} for each correspond- 
ing subset of the nodes, again use a nonparametric dis- 
tribution, condition on the mixture size size. 

The mixture size {di} be sample uniformly from 
the distribution with fix count {nd}, where nd be the 
number of node with a mixture of size di = d, with a 
likelihood 

P ({di}|{nd}) = 
∏ 
d nd! 

N ! 
. (3) 

For the count {nd} we assume a flat prior P ({nd}) = 
1/ 
(( 
D 
N 

)) 
, where D be the maximum value of d, and the 

denominator be the total number of different choice of 
{nd}, with 

(( 
n 
m 

)) 
= 
( 
n+m−1 

m 

) 
be the total number of 

m-combinations with repetition from a set of size n. 
Then, for all nd node with the same value of di = d, 

we sample a sequence of {~bi}d from a distribution with 
support |~bi|1 ≡ 

∑ 
r b 
r 
i = d and with fix count {n~b}d, 

where n~b be the number of node belonging to a specific 
mixture ~bi = ~b of size d, 

P ({~bi}d|{n~b}d) = 
∏ 
|~b|1=d n~b! 

nd! 
. (4) 

For the count themselves, we again assume a flat prior 
P ({n~b}d|nd) = 1/ 

(( 
(Bd) 
nd 

)) 
, where the denominator enu- 

merates the total number of {n~b} count with |~b|1 = d. 
The full posterior for the overlap partition then 

becomes 

P ({~bi}) = 

[∏ 
d 

P ({~bi}d|{n~b}d)P ({n~b}d|nd) 

] 
× 

P ({di}|{nd})P ({nd}), (5) 

which corresponds to a description length Lp = 
− lnP ({~bi}), 

Lp = ln 
(( 
D 
N 

)) 
+ 
∑ 
d 

ln 
(( 

(Bd) 
nd 

)) 
+ lnN !− 

∑ 
~b 

lnn~b!. (6) 

Although it be possible to encode the partition in dif- 
ferent way (e.g. by sample the membership to each 
group independently [47]), this choice make no assump- 
tions regard the type of overlap that be more likely 
to occur, either accord to the number of group to 
which a node may belong, or the actual combination of 
group — it be all left to be learn from data. In particu- 
lar, it be not a priori assume that if many node belong 
to two specific group then the overlap between these 
same group will also contain many nodes. As desired, 
if the observe partition deviate from this pattern, this 
will be use to compress it further. Only if the observe 



5 

partition fall squarely into this pattern will further com- 
pression be impossible, and we would have an overhead 
describe it use Eq. 6, when compare to an encode 
that expect it a priori. However, one can also see that 
in the limit n~b � 1, a the first two term in Eq. 6 grow 
asymptotically only with lnN and lnnd, respectively, the 
whole description length becomes Lp ' NH({n~b/N}), 
where H({px}) be the entropy of the distribution {px}, 
which be the optimal limit. Hence if we have a prior 
that good match the observe overlap, the difference 
in description length compare to Eq. 6 will disappear 
asymptotically for large systems. Another advantage of 
this encode be that it incurs no overhead when there 
be no overlap at all (i.e. D = 1), and in this case, the 
description length be identical to the nonoverlapping case, 

Lp(D = 1) = ln 
(( 
B 
N 

)) 
+ lnN !− 

∑ 
r 

lnnr!, (7) 

a define in Ref. [7]. 

B. Labeled degree sequence, {~ki} 

For the degree-corrected model, we need to describe 
the label degree sequence {~ki}. We need to do so in a 
way which be compatible with the partition {~bi} described 
so far, and with the edge count {ers}, which will restrict 
the average degree of each type. 

In order to fully utilize the partition {~bi}, we describe 
for each distinct value of ~bi = ~b it individual degree se- 
quence {~ki}~b = {~ki|~bi = ~b}, via the count n 

~b 
~k 
, i.e. the 

number of node with mixture ~bi = ~b which posse la- 
beled degree ~ki = ~k. We do so in order to preserve the 
lack of preference for pattern involve the degree in the 
overlap between groups. Since the model itself be agnos- 
tic with respect to the density of the overlaps, not only 
do this choice remain consistent with this indifference, 
but also any exist pattern in the degree sequence in 
the overlap will be use to construct a shorter descrip- 
tion. 

In addition, we must also consider the total number of 
half-edges of a give type r incident on a partition~b, er~b =∑ 
~k krn 

~b 
~k 
, where kr be the element of ~k correspond to 

group r, which must be compatible with the edge count 
{ers} via er = 

∑ 
s er = 

∑ 
~b e 

r 
~b 
. 

An overview of the generative process be a follows: 
We first consider the er half-edges of each type r and 
the nonempty (n~b > 0) mixture ~b which contain the 
same group r. We then distribute the label half-edges 
among these mixtures, obtain the total number of la- 
beled edge incident on each mixture, {er~b}. This place- 
ment constrains the average degree of each type inside 
each mixture. Finally, give {er~b}, we sample the actual 
label degree sequence on the node of each mixture. 

We begin by first distribute all er half-edges of type 
r among all mr bin correspond to each nonempty 

mixture ~b that contains the label r, i.e. mr = 
∑ 
~b br[n~b > 

0]. The total number of such partition be simply 
(( 
mr 
er 

)) 
, 

and hence the likelihood for {er~b} becomes 

P ({er~b}|{ers}, { 
~bi}) = 

(( 
mr 
er 

))−1 
. (8) 

Given {er~b}, we need to distribute the label half-edges 
inside each partition to obtain each degree sequence. If 
we sample uniformly from all possible degree sequence 
fulfil all necessary constraints, we have a likelihood 
for the degree sequence inside a mixture ~b give by 

P 
(1) 
~b 

({~ki}~b|{e 
r 
~b 
}, {~bi}) = 

∏ 
r 

(( 
n~b 
er~b 

))−1 
, (9) 

where 
(( 
n 
e 

)) 
be the total number of (unlabeled) degree se- 

quences with a total of e half-edges incident on n nodes. 
The correspond description length would then be 

L(1)~b = 
∑ 
r 

ln 

(( 
n~b 
er~b 

)) 
. (10) 

However, most degree sequence sample this way will 
result in node with very similar degrees. Since we want 
to profit from degree variability, it be good to condition 
the description on the degree count {n~b~k}, i.e. how many 
node with mixture ~bi = ~b posse label degree ~ki = ~k. 
This alternative distribution be give by 

P 
(2) 
~b 

({~ki}~b|{n 
~b 
~k 
}, {~bi}) = 

∏ 
~k n 

~b 
~k 
! 

n~b! 
. (11) 

For the degree count themselves, we choose a uniform 
prior P ({n~b~k}|{e 

r 
~b 
}, {~bi}) = 1/Ξ~b, where Ξ~b be the enu- 

meration of all possible {n~b~k} count that fulfill the con- 
straints 

∑ 
~k n 

~b 
~k 

= n~b and 
∑ 
~k krn 

~b 
~k 

= er~b . Unfortu- 
nately, this enumeration cannot be do easily in close 
form. However, the maximum entropy ensemble where 
these constraint be enforce on average be analytically 
tractable, and a we show in Appendix C, can be well 
approximate by Ξ~b = 

∏ 
r∈~b Ξ 

r 
~b 
, where 

ln Ξr~b ' 2 
√ 
ζ(2)er~b 

, (12) 

and ζ(x) be the Riemann zeta function. The alternative 
description length becomes therefore 

L(2)~b = 
∑ 
r∈~b 

ln Ξr~b + lnn~b!− 
∑ 
~k 

lnn 
~b 
~k 
!. (13) 

This approximation with “soft” constraint should be- 
come asymptotically exact a the number of node be- 
come large, but otherwise will deviate from the actual 



6 

entropy. On the other hand, if the number of node be 
very small, describe the degree sequence via Eq. 13 may 
not provide a shorter description, even if compute ex- 
actly. In this situation, Eq. 10 may actually provide a 
shorter description of the degree sequence. We therefore 
compute both Eq. 10 and Eq. 13 and choose whichever 
be shorter. Putting it all together, the complete posterior 
for the whole label degree sequence be 

P ({~ki}|{ers}, {~bi}) = 

∏ 
~b 

P~b({~ki}~b|{e 
r 
~b 
}, {~bi}) 

× 
P ({er~b}|{ers}, { 

~bi}), (14) 

with P~b({~ki}~b|{e 
r 
~b 
}, {~bi}) be the large 

choice between P (1)~b ({ 
~ki}~b|{e 

r 
~b 
}, {~bi}) and 

P 
(2) 
~b 

({~ki}~b|{n 
~b 
~k 
})P ({n~b~k}|{e 

r 
~b 
}, {bi}). Therefore, the 

description length for the label degree sequence 
Lκ = − lnP ({~ki}|{ers}, {bi}) becomes 

Lκ = 
∑ 
r 

ln 
(( 
mr 
er 

)) 
+ 
∑ 
~b 

min 
( 
L(1)~b ,L 

(2) 
~b 

) 
. (15) 

In the limit n~b~k � 1, we have that Lκ '∑ 
~b n~bH({n 

~b 
~k 
/n~b}), and hence the degree sequence in 

each partition be described close to the optimum limit. 
For the nonoverlapping case with D = 1, the descrip- 

tion length simplifies to 

Lκ = 
∑ 
r 

min 
( 
L(1)r ,L(2)r 

) 
, (16) 

with 

L(1)r = ln 
(( 
nr 
er 

)) 
, (17) 

L(2)r = ln Ξr + lnnr!− 
∑ 
k 

lnnrk!, (18) 

and ln Ξr ' 2 
√ 
ζ(2)er. For nr � 1 we obtain Lκ '∑ 

r nrH({nrk/nr}). This approximation be use a pri- 
ori in Ref. [7], but Eq. 16 be a more complete description 
length of the nonoverlapping degree sequence, and it use 
should be preferred. Hence, like the description length of 
the overlap partition, the encode above offer no 
overhead when the partition be nonoverlapping. 

C. Edge counts, {ers} 

The final piece that need to be described be the ma- 
trix of edge count {ers}. We may view this set a 
an adjacency matrix of a multigraph with B node and 
E = 

∑ 
r ers/2 edges. The total number of such matri- 

ce be Ω(B,E) = 
(( 

(B2) 
E 

)) 
, and if we assume that they 

be all equally likely, we have P ({ers}) = 1/Ω(B,E) and 
ln Ω(B,E) can be use a the description length [48]. 
There are, however, two problem with this approach. 
First, this uniform distribution be unlikely to be valid, 
since most observe network still posse structure at 
the block level. Second, this assumption lead to a limit 
in the detection of small groups, with a maximum de- 
tectable number of group scale a Bmax ∼ 

√ 
N [48]. 

Similarly to what we do for the node partition and the 
degree sequence, this can be solve by consider a gen- 
erative model for the edge count themselves, with it 
own set of hyperparameters. Since they correspond to 
a multigraph, a natural choice be the stochastic block 
model itself, which have it own set of edge counts, that 
can themselves be model by another stochastic block 
model with few nodes, and so on, recursively, until one 
have a model only one node and one group at the top. This 
nest stochastic block model be propose in Ref. [7], 
where it have be show to reduce the resolution limit to 
Bmax ∼ N/ logN , make it often significantly less rele- 
vant in practice. Furthermore, since the number of level 
and the topology at each level be obtain by minimize 
the overall description length, it corresponds to a fully 
nonparametric way of infer the multilevel structure 
of networks. As show in Ref. [7], if we denote the ob- 
serve network to be at the level l = 0 of the hierarchy, 
then the total description length be 

Σ = St/c + 
L∑ 
l=1 

Sm({elrs}, {nlr}) + Ll−1t , (19) 

with {elrs}, {nlr} describe the block model at level l, 
where 

Sm = 
∑ 
r>s 

ln 
(( 
nrns 
er 

)) 
+ 
∑ 
r 

ln 
(( 

((nr2 )) 
err/2 

)) 
(20) 

be the entropy of the correspond multigraph ensemble 
and 

Llt = ln 
(( 

Bl 
Bl−1 

)) 
+ lnBl−1!− 

∑ 
r 

lnnlr!. (21) 

be the description length of the node partition at level 
l > 0. For the level l = 0 we have L0t = Lp give by 
Eq. 6, or L0t = Lp + Lκ for the degree-corrected model. 

Note that here we use the single-membership non- 
degree-corrected model in the upper layers. This method 
could be modify to include arbitrary mixture of degree 
correction and multiple membership, but we stick with 
this formulation for simplicity. 

D. Significance level 

By minimize the description length Σ, we select the 
model that be most favor give the evidence in the data. 
But in some situations, one be not merely interested in a 
binary answer regard which of two model choice be 



7 

best, but instead, one would like to be able to rule out 
alternative model with some degree of confidence. In 
this case, a level of significance can be obtain by per- 
form a Bayesian hypothesis test base on the ratio of 
posterior likelihoods. In this context, there be different 
hypothesis which can be tested. For instance, one could 
ask whether the entire class of non-degree-corrected over- 
lap model (NDCO) be favor in comparison to the 
class of nonoverlapping degree-corrected model (DC). 
This can be do by compute the posterior distribu- 
tion for each model class H ∈ {NDCO,DC}, 

P (H|G) = 
∑ 
θ P (G|θ,H)P (θ)P (H) 

P (G) 
, (22) 

where θ be shorthand for the entire set of model pa- 
rameters [i.e. θ = ({~bi}, {ers}) for H = NDCO, and 
θ = ({bi}, {ers}, {ki}) for H = DC], with P (H) be 
the prior belief we have support a give hypothesis, 
and P (G) be a normalize constant. The standard way 
in Bayesian statistic to evaluate the relative evidence 
support (or rejecting) hypothesis H1 over H2 be via 
the posterior odds ratio [49] 

Λ = 
P (H1|G) 
P (H2|G) 

= 

∑ 
θ P (G|θ,H1)P (θ)∑ 
θ P (G|θ,H2)P (θ) 

P (H1) 
P (H2) 

. (23) 

However, there be two issue with this approach. First, 
compute the sum over all parameter choice be in- 
tractable in this context, since it involves sum over 
all possible overlap or nonoverlapping partitions. 
Second, and more importantly, this might not be the an- 
swer which be more relevant. If one obtains two model 
parametrizations by minimize the description length 
a described in the previous section, with the two re- 
sults belonging to different model classes, one would be 
more interested in select or reject between these 
two particular choices, not necessarily the overall class 
to which they belong. Although the description length 
itself already provide a mean to select the best alter- 
native, one would be interested in obtain a confidence 
level for this particular decision. This be a different sort 
of hypothesis test than the one above, but which can be 
perform analogously. Since the result of the minimiza- 
tion of the description length be the (possibly overlapping) 
partition of the network, our hypothesis be a combination 
of the model class which we be using, and the partic- 
ular partition that be found. The posterior probability 
attribute to this hypothesis be therefore 

P ({~bi},H|G) = 
P (G|{~bi},H)P ({~bi}|H)P (H) 

P (G) 
, (24) 

where again P (G) be a normalization constant. The 
marginal likelihood P (G|{~bi},H) be obtain by sum 
over the remain model parameters. In the case of the 
overlap degree-corrected model (H = DCO) they be 
the {ers} matrix and the label degree sequence {~ki} 

(which be omit for the non-degree-corrected model, 
H = NDCO), 

P (G|{~bi},DC) = 
∑ 

{e′rs},{~k′i} 

P (G|{~bi}, {e′rs}, {~k′i})× 

P ({e′rs})P ({~k′i}) 

= P (G|{~bi}, {ers}, {~ki})P ({ers})P ({~ki}), 
(25) 

where the sum trivially contains only one term, since 
for the same graph G and partition {~bi}, there be only 
one possible choice for the {ers} matrix and degree se- 
quence {~ki} with nonzero probability, which be a conve- 
nient feature of the microcanonical model formulation 
consider here [the same hold for H = NDC, i.e. 
P (G|{~bi},NDC) = P (G|{~bi}, {ers})P ({ers})]. Now if 
we want to compare two compete partition {~bi}a and 
{~bi}b, this can be do again via the posterior odds ratio 
Λ, 

Λ = 
P ({~bi}a,Ha|G) 
P ({~bi}b,Hb|G) 

(26) 

= 
P (G|{~bi}a,Ha)P ({~bi}a|Ha)P (Ha) 
P (G|{~bi}b,Hb)P ({~bi}b|Hb)P (Hb) 

(27) 

= exp (−∆Σ) , (28) 

with ∆Σ = Σa − Σb be the difference in the de- 
scription length, and in Eq. 28 it be assume that 
P (Ha) = P (Hb) = 1/2, correspond to a lack of a 
priori preference for either model variant (which, in fact, 
make Λ identical to the Bayes factor [50]). This be a 
simple result, which enables u to use the difference 
in the description length directly in the computation 
of confidence levels. Being a ratio of probabilities, the 
value of Λ have a straightforward interpretation: For a 
value of Λ = 1, both model explain the data equally 
well, and for value of Λ < 1 model a be reject in favor 
of b with a confidence increase a Λ diminishes. In 
order to simplify it interpretation, the value of Λ be 
usually divide into region correspond to a subjec- 
tive assessment of the evidence strength. A common 
classification be a follow [50]: Values of Λ in the interval 
{[1, 1/3], [1/3, 1/10], [1/10, 1/30], [1/30, 1/100], [1/100, 0]} 
be consider to be very weak, substantial, strong, 
very strong and decisive evidence support model b, 
respectively. In the following, when compare different 
models, we will always put the prefer model in the 
denominator of Eq. 27, such that Λ ≤ 1. 

Using the posterior odds ratio Λ be more practical than 
some alternative model selection approaches, such a like- 
lihood ratios. As have be recently show [29], the like- 
lihood distribution for the stochastic block model do 
not follow a χ2-distribution asymptotically for sparse 
networks, and hence the calculation of a p-value must 
be do via an empirical computation of the likelihood 



8 

10−8 
10−4 

100 

Λ 

2 3 4 5 6 7 8 

B 

10−100 
10−75 
10−50 
10−25 

100 

Λ 

DC,D > 1 

DC,D = 1 

NDC,D > 1 

NDC,D = 1 

B = 5, 
non-degree-corrected, 
overlapping, Λ = 1 

B = 4, 
non-degree-corrected, 

overlapping, Λ ' 2× 10−4, 

10−4 
10−2 

100 

Λ 

5 6 7 8 9 10 11 

B 

10−50 
10−37 
10−24 
10−11 

Λ 

DC,D > 1 

DC,D = 1 

NDC,D > 1 

NDC,D = 1 

B = 10, 
non-degree-corrected, 
nonoverlapping, Λ = 1 

B = 9, 
non-degree-corrected, 

nonoverlapping, Λ ' 0.36 

Figure 1. Left: Values for posterior odds ratio Λ for the network of co-appearances of character in the novel “Les Misérables”, 
for all model variation (D > 1 indicates an overlap model, “DC” a degree-corrected model and “NDC” a non-degree- 
correct one). The model with the best and second-best fit be show at the bottom. Right: Same a in the left, but for 
the American college football network. 

distribution which be computationally costly, and pro- 
hibitively so for very large networks. In contrast, com- 
put Λ can be do easily, and it properly account for 
the increase complexity of model with large parame- 
ters, and protects against overfitting. However, it should 
be emphasize that these different model selection ap- 
proaches be design to answer similar, but not iden- 
tical questions. Therefore the most appropriate method 
should be the one that more closely match the ques- 
tions raised. 

IV. EMPIRICAL NETWORKS 

The method outline in the previous section allows 
one to determine the best model from the various avail- 
able choices. Here we analyze some empirical examples, 
and determine the most appropriate model, and examine 
the consequence of the balance struck between model 
complexity and quality of fit. We start with two small 
networks, the co-appearance of character in the Victor 
Hugo novel “Les Misérables” [54], and a network of Amer- 
ican college football game [13, 55]. For both networks, 
we obtain the best partition accord all model varia- 

tions and for a different number of group B, and we com- 
pute the value of Λ relative to the best model, a show 
in Fig. 1. For the “Les Misérables” network, the best 
fit be a non-degree-corrected overlap model that put 
the most central character in more than one group. All 
other partition for different value of B and model type 
result in value significantly below the plausibility line of 
Λ = 10−2, indicate that the overlap model offer a 
good explanation for the data with a large degree of con- 
fidence. In particular, it offer a good description than 
the nonoverlapping model with degree correction. For 
the football network, on the other hand, the prefer 
model be nonoverlapping and without degree correction 
with B = 10, which match very well the assume cor- 
rect partition into 10 conferences. The group be rela- 
tively homogeneous, with most node have similar de- 
grees, such that degree correction becomes an extra bur- 
den, with very little add explanatory power. For this 
network, however, there be alternative fit with value 
of Λ within the plausibility region, which mean that the 
community be not very strongly defined, and they ad- 
mit alternative partition with B = 9 and B = 8 group 
which cannot be confidently discard give the evidence 
in the data. 

Degree correction tends to become a good choice for 



9 

B = 7, overlapping, degree-corrected, Λ = 1 B = 12, nonoverlapping, degree-corrected, log10 Λ ' −747 

Figure 2. The network of political blog by Adamic et al [51]. The left panel show the best model with an overlap partition, 
and the right show the best nonoverlapping one. Nodes with a blue halo belong to the Republican faction, a determine in 
Ref. [51]. For the visualization, the hierarchical edge-bundles algorithm [52] be used. 

large data sets, which display strong degree variabil- 
ity. One example of this be the network of political blog 
obtain by Adamic et al [51]. For this network, the best 
model be a degree-corrected, overlap partition into 
B = 7 groups, show in Fig. 2. Compared to this parti- 
tion, the best alternative model without overlap divide 
the network into B = 12 groups1, but have a posterior 
odds ratio significantly below the plausibility region. It 
should be observe that the nonoverlapping version cap- 
tures well the segregation into two group (Republicans 
and Democrats) at the topmost level of the hierarchy. 
The overlap version, on the other hand, tends to clas- 
sify half-edges belonging to different camp into different 
groups, which be compatible with the accepted division, 
but the upper layer of the hierarchy do not reflect this, 
and prefers to merge together group that belong to dif- 
ferent factions, but that have otherwise similar role in 
the topology. 

Overlapping partitions, however, do not always provide 
good descriptions, even in situation where it might be 
consider more intuitive. One of the context where 
overlap community be often consider to be bet- 
ter explanation be in social networks, where different so- 
cial circle could be represent a different group (e.g. 

1 In Ref. [7] use the same nonoverlapping model, a value of B = 
15 be found. This be due the difference in the description length 
for the degree sequence, where here we use a more complete 
estimation than in Ref. [7], which result in this slight difference. 

family, co-workers, friends, etc.), and one could belong 
to more than one of these groups. This be illustrate well 
by so-called “ego networks,” where one examines only the 
immediate neighbor of a node, and their mutual connec- 
tions. One such network, extract from the Facebook 
online social network [53], be show in Fig. 3. The com- 
mon interpretation of network such a these be show on 
the right in Fig. 3, and corresponds to a partition of the 
central “ego” node so that it belongs to all of the different 
circles. Under this interpretation, the ego node be only 
special in the sense that it belongs to all groups, but in- 
side each group it be just a common member. However, 
among all model variants, the best fit turn out to be 
the one where the ego node be put separately in it own 
group, a show in the left in Fig. 3. In this example it be 
easy to see why this be the case: If we observe the degree 
distribution inside each group for the network on the left, 
we see that there be no strong degree variation. On the 
right, a the ego be include in each group, it becomes sys- 
tematically the most connect node. This be simply by 
construction, since the ego must connect to every other 
node. The only situation where the ego would not stand 
out inside each group, would be if the community be 
cliques. Hence, since the ego be not a typical member 
of any group, it be simpler to classify it separately in it 
own group, which be select by the method a a be a 
more plausible hypothesis. Note that degree correction 
be not select a the most plausible solution, since it be 
burden with the individual description of every degree 
in the network, which be fairly uniform with the excep- 



10 

0 8 16 24 

k 

0 
1 
2 
3 
4 

n 
k 

0 3 6 

k 

0 

2 

4 

n 
k 

0 3 6 9 

k 

0 

1 

2 

3 

n 
k 

4 8 12 

k 

0 

1 

2 

3 

n 
k 

0 8 16 24 

k 

0 
1 
2 
3 
4 

n 
k 

0 5 10 15 20 

k 

0 

2 

4 

6 

n 
k 

3 6 9 

k 

0 

1 

2 

3 

n 
k 

4 8 12 16 

k 

0 

1 

2 

3 

n 
k 

B = 5, overlapping, 
non-degree-corrected, Λ = 1 

B = 4, overlapping, 
non-degree-corrected, 

Λ ' 0.053 

Figure 3. Ego network of Facebook contact [53]. Left: The 
best model fit across all model variations, which put the ego 
node in it own group. Right: The alternative hypothesis 
where the node be split in several groups. Below each network 
be show the degree distribution inside each group. The 
arrow mark the degree of the ego node. 

tion of the ego. One can imagine a different situation 
where there would be other very well connect node 
inside each group, so that the ego could be described a 
a common member of each group, but this not observe 
in any other network obtain in Ref. [53]. Naturally, 
if one considers the complete network, of which the ego 
neighbourhood be only a small part, the situation may 
change, since there may be member of each group to 
which the ego do not have a direct connection. 

When perform model selection for large net- 
works, it be often the case that the overlap mod- 
el be not chosen. In table I be show the result 
for many empirical network belonging to different do- 
mains. For the majority of cases, the nonoverlapping 
degree-corrected model be selected. The are, how- 
ever, many exception which include two social net- 
work (Gowalla and Brightkite [61]), the global air- 
port network of openflights.com, the neuronal net- 
work of C. elegans [62], the political blog network al- 
ready mentioned, the arXiv co-authorship network [63] 
[in the field of general relativity and quantum cos- 
mology (gr-qc), high-energy physic (hep-th), condense 
matter (cond-mat), and astronomy (astro-ph)], co- 
authorship in network science [64], and the network 
of gene implicate in disease [66], for which some 
version of the overlap model be chosen. Inter- 
estingly, for the arXiv co-authorship network in high- 
energy physics/phenomenology (hep-ph) a nonoverlap- 
ping model be select instead. For only one of the 
remain four arXiv network (astro-ph), the degree- 

No. N 〈k〉 log10 ΛDCO log10 ΛDC log10 ΛNDCO log10 ΛNDC B 〈d〉 Σ/E 
1 34 4.6 −2.1 −2.1 — 0 2 1 4 
2 62 5.1 −4.6 −1.4 — 0 2 1 4.8 
3 77 6.6 −17 −7.7 0 −7.3 5 1.1 4 
4 105 8.4 −12 −2.8 −6.6 0 5 1 4.4 
5 115 10.7 −79 −27 — 0 10 1 4.3 
6 297 15.9 0 −61 −2.0× 102 −2.1× 102 5 1.8 5.1 
7 379 4.8 −47 −6.6 0 −8.9 20 1.1 6.2 
8 903 15.0 −3.8× 102 −3.7× 102 0 −3.7× 102 60 1.2 3.1 
9 1, 278 2.8 −8.1 0 −1.5× 102 −89 2 1 7.4 
10 1, 490 25.6 0 −5.2× 102 −2.3× 103 −2.3× 103 7 1.8 4.4 
11 1, 536 3.8 −2.5× 102 0 −65 −62 38 1 6.7 
12 1, 622 11.2 −4.3× 102 0 −12 −82 48 1 3.3 
13 1, 756 4.5 −43 0 −4.0× 102 −2.8× 102 7 1 5.9 
14 2, 018 2.9 −9.2 0 −2.9× 102 −2.1× 102 2 1 8.5 
15 4, 039 43.7 −1.5× 103 0 −8.1× 102 −9.5× 102 158 1 3.2 
16 4, 941 2.7 −2.2× 102 0 −21 −25 25 1 11 
17 7, 663 17.8 0 −1.1× 104 −5.3× 103 −1.6× 104 85 1 3.2 
18 7, 663 5.3 −1.8× 103 0 −9.3× 102 −7.3× 102 63 1 5 
19 8, 298 25.0 −9.1× 103 0 −1.4× 104 −1.4× 104 34 1 5.4 
20 9, 617 7.7 −4.2× 103 0 −2.3× 103 −2.5× 103 34 1 9.3 
21 26, 197 2.2 −2.4× 103 −1.2× 103 0 −2.7× 103 363 1.3 4.5 
22 36, 692 20.0 −4.1× 104 0 −8.5× 104 −2.8× 104 1812 1 5.5 
23 39, 796 15.2 −6.1× 104 0 −8.8× 104 −4.5× 104 1323 1 6.3 
24 52, 104 15.3 −1.5× 105 0 −3.7× 104 −4.0× 104 172 1 6.4 
25 58, 228 14.7 0 −5.8× 104 −1.8× 105 −1.4× 105 1995 3.2 7.3 
26 65, 888 305.2 −4.4× 104 0 −4.6× 105 −4.6× 105 384 1 4.1 
27 68, 746 1.5 −4.8× 103 −1.4× 103 0 −7.0× 103 719 1.4 6.4 
28 75, 888 13.4 −1.1× 105 0 −8.2× 104 −9.0× 104 143 1 8.9 
29 89, 209 5.3 −1.0× 104 0 −9.7× 103 −1.1× 104 848 1 3.2 
30 108, 300 3.5 −3.3× 103 −5.2× 103 0 −2.4× 104 1660 1.8 5.7 
31 133, 280 5.9 0 −4.4× 103 −7.4× 104 −3.8× 104 1944 5.3 4.4 
32 196, 591 19.3 0 −1.9× 105 −7.1× 105 −6.6× 105 6856 3.7 7.8 
33 265, 214 3.2 −1.4× 104 0 −9.2× 104 −8.5× 104 549 1 8.6 
34 273, 957 16.8 −5.4× 105 0 −4.6× 104 −7.2× 104 727 1 5.8 
35 281, 904 16.4 −1.2× 106 0 −2.8× 105 −1.5× 105 6655 1 4.3 
36 317, 080 6.6 −1.7× 105 0 −3.9× 105 −4.2× 105 8766 1 11 
37 325, 729 9.2 −5.8× 105 0 −1.1× 106 −2.3× 105 4293 1 5.8 
38 325, 729 9.2 −5.6× 105 0 −1.2× 106 −2.5× 105 3995 1 5.8 
39 334, 863 5.5 −3.3× 105 0 −3.6× 105 −3.4× 104 9118 1 11 
40 372, 787 9.7 −1.0× 106 0 −1.3× 105 −1.4× 105 965 1 11 
41 463, 347 20.3 −6.4× 105 0 −1.8× 106 −1.5× 106 9276 1 9.3 
42 1, 134, 890 5.3 — 0 −4.5× 105 −4.9× 105 264 1 13 
1 Karate Club [56] 22 Enron email [57, 58] 
2 Dolphins [59] 23 PGP [60] (directed) 
3 Les Misérables [54] 24 Internet AS (Caida)a (directed) 
4 Political Booksb 25 Brightkite social network [61] 
5 American football [13, 55] 26 netflix-pruned-smaller-u 
6 C. elegans Neurons [62] (directed) 27 arXiv Co-Authors (hep-th) [63] 
7 Coauthorships in network science [64] 28 Epinions.com trust network [65] (directed) 
8 Disease Genes [66] 29 arXiv Co-Authors (hep-ph) [63] 
9 Yeast protein interaction (CCSB-YI11) [67] 30 arXiv Co-Authors (cond-mat) [63] 
10 Political Blogs [51] (directed) 31 arXiv Co-Authors (astro-ph) [63] 
11 Yeast protein interaction (LC) [68] 32 Gowalla social network [61] 
12 Yeast protein interaction (Combined AP/MS) [69] 33 EU email [63] (directed) 
13 E. coli gene regulation [70] (directed) 34 Flickr [71] 
14 Yeast protein interaction (Y2H union) [67] 35 Web graph of stanford.edu. [72] (directed) 
15 Facebook ego [53] 36 DBLP collaboration [73] 
16 Power Grid [62] 37 Web graph of nd.edu. [72] (directed) 
17 Airport route c (directed) 38 WWW [74] (directed) 
18 Airport route 39 Amazon product network [73] 
19 Wikipedia Votes [75, 76] (directed) 40 IMDB film-actord [48] 
20 Human protein interaction (HPRD r9) [77] 41 APS citationse (directed) 
21 arXiv Co-Authors (gr-qc) [63] 42 Youtube social network [73] 

a Retrieved from http://www.caida.org. 
b V. Krebs, retrieve 
from http://www-personal.umich.edu/~mejn/netdata/ 

c Retrieved from http://openflights.org/ 
d Retrieved from http://www.imdb.com/interfaces. 
e Retrieved from http://publish.aps.org/dataset. 

Table I. Comparison of different model for many empiri- 
cal networks. The column at the top table correspond to 
the dataset number (with the name give at the bottom 
table), the number of node N , the average degree 〈k〉 = 
2E/N , the posterior odds ratio relative to the best model 
for the degree-corrected overlap (ΛDCO), the degree- 
correct nonoverlapping (ΛDC), non-degree-corrected over- 
lap (ΛNDCO) and non-degree-corrected nonoverlapping 
(ΛNDC) models. Missing entry correspond to situation 
where the best overlap partition turn out to be nonover- 
lapping. The last three column show some parameter of 
the best model: The number of group B, the average mix- 
ture size 〈d〉, and the description length per edge (in bit per 
edge). 

openflights.com 
stanford.edu 
nd.edu 
http://www.caida.org 
http://www-personal.umich.edu/~mejn/netdata/ 
http://openflights.org/ 
http://www.imdb.com/interfaces 
http://publish.aps.org/dataset 


11 

correct version of the overlap model be selected, 
whereas for the other three the non-degree-corrected ver- 
sion be preferred. Hence, for co-authorship network the 
model selection procedure seem to correspond to the 
intuition that they be compose predominantly of over- 
lap group [15]. 

We take the arXiv cond-mat network a a representa- 
tive example of the difference between the infer mod- 
els. As can be see in Fig. 4, although the degree distri- 
bution be very broad, the infer label degree distribu- 
tion be narrower, meaning that many large-degree node 
can be well explain a have a small degree of any 
single type, but belonging simultaneously to many group 
(in the specific context of this network, prolific author 
tend to be the one which belong to many different type 
of collaborations). The distribution of mixture size nd 
have almost always a maximum at d = 1, meaning that 
most node belong to one group, but with a tail which be 
comparatively broad (this seem to be a general feature 
which be observe in the majority of network analyzed). 
The distribution of group size can be very different, de- 
pending on which model be used. nonoverlapping mod- 
el without degree correction tend to find group which 
be strongly correlate with degree [19], and hence lead 
to a broad distribution of group size when the degree 
distribution be also broad. On the other hand, both de- 
gree correction and group overlap tend to change the dis- 
tribution considerably. In the literature there be often 
claim of community size follow power-law distribu- 
tions [21, 78–80] with figure similar to the low left 
panel of Fig. 5. Regardless to the validity of this hy- 
pothesis for the various method use in the literature, 
this be certainly not the case for the overlap model a 
show in the low right panel of the same figure. Indeed, 
for most network analyzed, the model which best fit the 
data (which tends to be degree-corrected and nonoverlap- 
ping) show no vestige of group size follow a scale-free 
distribution. Some further example of this be show 
in Fig. 5, where characteristic size scale can be clearly 
identified. 

V. MODEL IDENTIFIABILITY: 
OVERLAPPING VS. NONOVERLAPPING 

A central issue when select between nonoverlap- 
ping and overlap model be to decide when a group 
of node should belong simultaneously to two or more 
groups, of if these node should be good represent by 
a single membership to a different unique group. The 
choice be not always immediately obvious, since we can 
always generate very similar network with either model. 
If we generate a network with the overlap model, 
but treat it a if it be generate by the nonoverlapping 
model, with each distinct mixture ~b correspond to a 
separate nonoverlapping group, the associate entropy 

100 101 102 103 

k 

10−6 
10−5 
10−4 
10−3 
10−2 
10−1 

100 

p 
k 

Non-overlapping 

Overlapping 

100 101 

d 

10−4 
10−3 
10−2 
10−1 

100 

n 
d 
/N 

100 101 

nr 

10−4 

10−3 

10−2 

10−1 

p 
n 
r 

100 101 102 

nr 

10−4 

10−3 

10−2 

10−1 

p 
n 
r 

Figure 4. Statistical property of the best model infer 
for the network of arXiv co-authors in the field of condense 
matter (cond-mat). Top left: Degree distribution of the orig- 
inal network and of the overlap model (where the label 
degree sequence {~ki} be flatten into a single histogram for 
all label degree {kri }). Top right: Distribution of mix- 
ture sizes, nd. Bottom left: Distribution of group size for 
the best-fitting nonoverlapping, non-degree-corrected model. 
Bottom right: Distribution of group size for the best-fitting 
overlapping, non-degree-corrected model. 

100 101 102 

nr 

10−5 
10−4 
10−3 
10−2 
10−1 

p 
n 
r 

100 101 102 

nr 

10−4 

10−3 

10−2 

p 
n 
r 

100 101 102 

nr 

10−5 
10−4 
10−3 
10−2 
10−1 

p 
n 
r 

100 101 102 

nr 

10−5 
10−4 
10−3 
10−2 

p 
n 
r 

Figure 5. Distribution of group size for the best fitting non- 
degree-corrected nonoverlapping model (left) and the degree- 
correct nonoverlapping model (right), for the PGP [60] 
(top) and DBLP collaboration [73] (bottom) networks. In 
both case the degree-corrected model provide a good fit, 
a show in table I. 

will be 

S ′t ' E − 
1 

2 

∑ 
~b1~b2 

e~b1~b2 ln 

( 
e~b1~b2 
n~b1n~b2 

) 
, (29) 

where 

e~b1~b2 = 
∑ 
r 

br1b 
s 
2 

er 
nrns 

n~b1n~b2 (30) 



12 

be the expect number of edge between mixture ~b1 and 
~b2. By exchange the sum and use Jensen’s inequality 
we observe directly that 

S ′t ≤ E − 
1 

2 

∑ 
r 

er ln 

( 
er 
nrns 

) 
, (31) 

with the right-hand side be the entropy of original 
overlap model St, and with the equality hold only 
if the original model happens to be nonoverlapping to 
begin with. Thus, the nonoverlapping model will invari- 
ably posse a low entropy. Nevertheless, the overlap- 
ping hypothesis may still be prefer if the number of 
group B be sufficiently small than the number of indi- 
vidual ~b mixtures, so that the total description length be 
shorter. It should be observed, however, that since one 
model be contain inside the other, the difference in the 
description length can be interpret simply a the differ- 
ence in the prior probability for the model parameters. 
As the amount of available data increases, the effect of 
the prior should “wash out”, and the description length 
should be increasingly dominate by the model entropy 
alone. In these case one should expect the nonover- 
lap model to be preferred, regardless of the specific 
model which be use to generate the data. However, 
differently from model that generate independent data 
points, the “amount of available data” for network mod- 
el be a finer issue. In the case of the stochastic block 
model it involves the simultaneous scale of the number 
of edge E, the number of node N and the number of 
group B. 

As a case example, here we consider a simple over- 
lap assortative model, with er = 2E[δrsc/B + (1 − 
δrs)(1 − c)/B(B − 1)], with c ∈ [0, 1] control the de- 
gree of assortativity. The mixture be parameterized 
a n~b = C 

∏ 
r µ 

br , with C be a normalization con- 
stant, and µ ∈ [0, 1] control the degree of overlap. 
For µ → 0 we obtain asymptotically a nonoverlapping 
partition with nr = N/B, and for µ = 1 all mixture 
~b have the same size. We compare the difference in de- 
scription length between this model and it equivalent 
parametrization with each mixture a a separate group. 
As can be see in Fig. 6, for any give value of c, there 
be a value of µ above which the nonoverlapping model be 
preferred. In this parameter region, the group intersec- 
tions be sufficiently well populate with nodes, so that 
their representation a individual group be chosen. For 
value of µ below this value, the intersection be sig- 
nificantly small than the nonoverlapping portion. In 
this case, the data be good explain a large group 
of almost nonoverlapping nodes, with few node at the 
intersections. The boundary separate the two region 
recedes upwards a the number of group B be increased, 
meaning that a large number of distinct intersection 
can compensate for a small number of nonoverlapping 
nodes. It should also be point out that the boundary 
move downwards a the number of node and edge be 
increased, such that the average degree in the network 

0.95 0.96 0.97 0.98 0.99 1.00 

c 

0.05 

0.10 

0.15 

0.20 

µ 

(a) 

(b) 
(c) 
(d) 

(e) 

(f) 

(a) B = 2, c = 0.99, 
µ = 0.025 

(c) B = 3, c = 0.98, 
µ = 0.06 

(e) B = 4, c = 0.97, 
µ = 0.12 

(b) B = 3, c = 0.99, 
µ = 0.05 

(d) B = 7, c = 0.98, 
µ = 0.08 

(f) B = 15, c = 0.97, 
µ = 0.15 

Figure 6. Top: Parameter region for the model consider 
in the main text, with N = 103 and 〈k〉 = 2E/N = 20. Each 
curve corresponds to one value of B and separate a region 
above where the nonoverlapping model be prefer from a 
region below where the overlap model be chosen. Bot- 
tom: Networks and their prefer partitions, correspond 
to parameter value indicate in the top panel. 

remains the same (not shown), so it be not only the rela- 
tive size of the intersection that be the relevant proper- 
ties, but also their absolute sizes. The same occurs if the 
average degree increase and everything else remains con- 
stant. Hence, in the limit of sufficient data, either with 
the number of node inside each group and intersection 
become sufficiently large, or with each part become 
sufficiently dense, the nonoverlapping model be the one 
which will be selected. For empirical networks, this may 
not be the most representative scale scenario, since the 
most appropriate number of group and degree of over- 
lap may in fact follow any arbitrary scaling, and hence 
the overlap model may still be selected, even for very 
large or very dense networks. Nevertheless, this example 
seem to suggest that the nonoverlapping model be gen- 
eral enough to accommodate structure generate by the 
overlap model in these limit cases, and may serve 



13 

a a partial explanation to why the overlap model 
be seldom select in the empirical system analyze in 
Sec. IV. 

VI. INFERENCE ALGORITHM 

The inference procedure consists in find the label 
of the half-edges of the graph such that the description 
length be minimized. Such global optimization problem 
be often NP-hard, and require heuristic to be solvable in 
practical time. One possibility be to use the Markov chain 
Monte Carlo (MCMC) method, which consists in mod- 
ifying the block membership of each half-edge in a ran- 
dom fashion, and accept or reject each move with 
a probability give a a function of the description length 
difference ∆Σ. By choose the acceptance probability 
in the appropriate manner, i.e. by enforce ergodicity 
and detailed balance, one can guarantee that the label- 
ings will be sample with the correct probability after a 
sufficiently long equilibration time be reached. However, 
naive formulation of the Markov chain will lead to very 
long equilibration times, which become unpractical for 
large networks. Here we adapt the algorithm developed 
in Ref. [81] for the nonoverlapping case which implement 
a fast Markov chain. It consists in the move proposal of 
each half-edge incident on node i of type r to type s with 
a probability give by 

p(r → s|t) = ets + � 
et + �B 

, (32) 

where t be the block label the half-edge oppose a 
randomly chosen half-edge incident to the same node a 
the half-edge be moved, and � ≥ 0 be a free param- 
eter. Eq. 32 mean that we attempt to guess the label 
of a give half-edge by inspect the group membership 
the neighbor of the node to which it belongs, and us- 
ing the currently infer model parameter to choose 
the most likely group to which it should be moved. It 
should be emphasize that this move proposal do not 
result in a preference for either assortative or dissorta- 
tive networks, since it depends only on the matrix {ers} 
currently inferred. For any choice of � > 0, this move pro- 
posal preserve ergodicity, but not detailed balance. This 
last characteristic can be enforce via the Metropolis- 
Hastings criterion [82, 83] by accept each move with 
a probability a give by 

a = min 

{ 
e−β∆Σ 

∑ 
t p 
i 
tp(s→ r|t)∑ 

t p 
i 
tp(r → s|t) 

, 1 

} 
, (33) 

where pit be the fraction of oppose half-edges of node i 
which belong to block t, and p(s → r|t) be compute af- 
ter the propose r → s move (i.e. with the new value of 
etr), whereas p(r → s|t) be compute before. The param- 
eter β in Eq. 33 be an inverse temperature, which can be 
use to sample partition accord to their description 
length (β = 1) or to find the ground state (β →∞). As 

B = 2E B = 15 

B = 4 B = 4, plant 

Figure 7. Typical outcome of the greedy multilevel agglomer- 
ative algorithm described in the text, for a network sample 
from the overlap model with B = 4. The different panel 
show the progression of the algorithm from B = 2E to B = 4. 
The panel on the low right show the plant partition use 
to generate the network. 

explain in Ref. [81], this move proposal a well a the 
computation of a can be do efficiently, with minimal 
book-keeping, so that a sweep of the network (where each 
half-edge move be attempt once) be do in time O(E), 
independent of the number of group B. This be true 
even in the overlap case, since update Eqs. 1, 2, 6 
and 15 after each half-edge move can be do in time 
O(1). 

As discuss in Ref. [81], although the MCMC method 
above succeed in equilibrate faster than a naive 
Markov chain, it still suffers from a strong dependence 
on how close one start from the global minimum. Usu- 
ally, start from a random partition of the half-edges 
lead to metastable state where the Markov chain seem 
to have equilibrated, but in fact the network structure 
have only be partially discovered, and will move from 
such configuration only after a very long time. This 
problem be common to many inference procedure base 
on local move such a expectation maximization [20] and 
belief propagation [84, 85]. In Ref. [81] a multilevel ag- 
glomerative heuristic be proposed, which significantly 
alleviates this problem. It consists in equilibrate the 
chain for a large number of groups, and then merge 
the group use the same algorithm use for the block 
membership moves. This method, however, cannot be 
use unmodified in the overlap case, since the strict 
merge of group will not properly explore the landscape 



14 

of possible overlap partitions. We therefore modify 
the approach a follows. Before group be merged, the 
half-edges belonging to each one of them be split into 
subgroup correspond to the different group member- 
ship at the oppose sides. These subgroup be then 
treat a separate groups, and be merge together until 
the desire number of group be achieved. All the detail 
of the algorithm beyond this modification be perform 
exactly a described in Ref. [81]. Since this algorithm 
usually do a good job in find a partition very close to 
the final one, it also tends to perform very well when the 
algorithm be turn into a greedy heuristic, by start 
with B = 2E and each half-edge in it own group, and by 
make β →∞. An example of a typical outcome of the 
greedy algorithm be show in Fig. 7. The greedy version 
be very fast, with an overall complexity of O(E ln2E), 
which make it usable for very large networks. Note that 
this complexity be independent on the number of groups, 
B. This be a strong contrast to other method propose 
for the same problem, such a the stochastic optimiza- 
tion algorithm of Gopalan et al [86], and the expecta- 
tion maximization algorithm of Ball et al [20], both of 
which have a complexity of O(EB) per sweep, although 
they only consider strictly assortative models, and ap- 
ply the same technique to the more general model 
consider here would lead to an O(EB2) complexity, 
similar to belief propagation algorithm for nonoverlap- 
ping model [29, 85]. Although these approach can be 
very efficient if the number of group be very small, they 
quickly become prohibitive if the most appropriate num- 
ber of group scale a some function of the system size 
(which seem to be generally the case when model se- 
lection be applied, see table I and Ref. [7]), which be not 
an issue with the algorithm described above. It should 
also be note that none of the other algorithm men- 
tioned [20, 29, 85, 86] be design to overcome metastable 
solutions, like the multilevel approach present here. 

For most network analyze in this work, the fast 
heuristic version of the algorithm be used, together with 
the algorithm described in Ref. [7] to infer the upper lay- 
er of the hierarchy (which include the determination of 
the number of group B at the low level, in addition 
to the entire hierarchy, in a nonparametric fashion)2. 

VII. CONCLUSION 

We present a method of infer overlap and 
degree-corrected version of the stochastic block model 
base on the minimum description length principle 
(MDL) that avoids overfitting and allows for the compar- 
ison between model classes. Based on a Bayesian inter- 
pretation of MDL, we derive a posterior odds ratio test 

2 A complete implementation of the algorithm be freely available 
a part of the graph-tool library [87] at http://graph-tool. 
skewed.de. 

that yield a degree of confidence with which model can 
be select or discarded. In apply this method to a va- 
riety of empirical networks, we obtain that for the ma- 
jority of them the nonoverlapping degree-corrected model 
variant be the one that best fit the data. 

The relative success of the degree-corrected model im- 
ply that intrinsic node propensity be an important 
aspect of the network formation of many systems, which 
be not sufficiently well described by the sole division 
into node classes. We note, however, that there be ex- 
ceptions to this, a there be a few network that do 
not show enough statistical evidence to justify the ad- 
ditional parameter of the degree-corrected model. In 
these networks, the group themselves seem to be the 
lead descriptor of the network structure, with the 
degree sequence itself provide little additional explana- 
tory power. 

Although overlap structure be often consider 
to be more intuitive explanation for some networks, we 
show that in many representative case the nonover- 
lap model can accommodate the same structure 
while provide a more parsimonious description of the 
data. This contradicts result obtain with nonsta- 
tistical method [14, 15], which claimed that many or 
even most network be good described by overlap 
groups. We believe that this conclusion be most likely 
a result of overfitting: Since there be more overlap 
structure than nonoverlapping ones, it be easy to find 
them in the data. We expect this fact to bear on task 
that require high-quality fits, such a the prediction of 
miss or spurious link [6, 8], or other generalization 
of the data. 

The model consider in this work generate unlabeled 
networks, without any other property associate with 
the node or edges. However, it be often the case that 
either the node or edge have weight [25, 40, 88] or 
be of different type [24, 27], or have temporal informa- 
tion [28]. This sort of additional data may corroborate 
the evidence support the generation via a specific type 
of model (e.g. with overlaps) and tip the scale towards 
it. Therefore, the result present in this paper should 
not be interpret a a statement on the suitability the 
abstract notion of overlap structure in general, only 
of the specific formulation considered. However, the ap- 
proach present here be generalizable to these other case 
a well, by augment the model to generate covariates 
associate with the edge and node [25]. Furthermore, 
one should be able to perform a similar comparison with 
model which belong to very different classes, such a 
latent space [89] models, or others. 

Appendix A: Directed graph 

The same approach of the main text can be carry 
over to direct graph with no difficulties. In this case 
the edge count be in general asymmetric, er 6= esr, 
which lead to the entropy for the non-degree-corrected 

http://graph-tool.skewed.de 
http://graph-tool.skewed.de 


15 

model [42] 

St ' E − 
∑ 
r 

er ln 

( 
er 
nrns 

) 
. (A1) 

For the degree-corrected case, there be two degree se- 
quences for the label out- and in-degrees, {k+ri } and 
{k−ri }, respectively. Applying the same argument a for 
the undirected case, the entropy becomes [42] 

Sd ' −E− 
∑ 
r 

er ln 

( 
er 

e+r e 
− 
s 

) 
− 
∑ 
ir 

ln k+ 
r 
i !− 

∑ 
ir 

ln k− 
r 
i !, 

(A2) 
where e+r = 

∑ 
s er and e 

− 
r = 

∑ 
s esr. 

The description length for the overlap partition be 
identical to the undirected case, with Lp give by Eq. 6. 
For the label degree sequence, we have instead 

Lκ = 
∑ 
r 

ln 
(( 
mr 
e+r 

)) 
+ ln 

(( 
mr 
e−r 

)) 
+ 
∑ 
~b 

min 
( 
L(1)~b ,L 

(2) 
~b 

) 
. 

(A3) 
with 

L(1)~b = 
∑ 
r 

ln 

(( 
n~b 
e+r~b 

)) 
+ ln 

(( 
n~b 
e−r~b 

)) 
. (A4) 

and 

L(2)~b = 
∑ 
r 

br 

( 
ln Ξr~b 

+ + ln Ξr~b 
− 
) 

+ lnn~b!− 
∑ 
~k 

lnn 
~b 
~k+,~k− 

!, 

(A5) 
where ln Ξr~b 

+ and ln Ξr~b 
− be compute a in Eq. 12 

but use e+r~b = 
∑ 
~k+,~k− k 

+ 
r n 

~b 
~k+,~k− 

and er~b 
− =∑ 

~k+,~k− k 
− 
r n 

~b 
~k+,~k− 

, respectively, which give the total 

number of out- and in-edges incident on the mixture ~b. 
In the previous equation the count n~b~k+,~k− refer to the 
joint distribution of label in- and out-degrees, so that 
each vector ~k+/− describes the in- and out-degrees la- 
beled accord to degree membership, i.e. ~k+i = {k+ 

r 
i } 

and ~k−i = {k− 
r 
i }. 

Appendix B: Poisson Models 

1. Non-degree-corrected 

This approximation of the formulation with “hard” 
constraint of the multiple membership model discuss 
in the main text be closely related to a Poisson variant of 
the model with “soft” constraints, where each half-edge 
of the graph be label with a latent variable specify 
which group membership be responsible for it exis- 
tence, and the number of edge of type (r, s) between 
node i and j, Arsij , be independently sample accord 
to a Poisson distribution (similar to Refs. [19, 20]), so the 

likelihood becomes 

P (G|{~bi}, {prs}) = 
∏ 
i>j 

∏ 
r≥s 

p 
Arsij 
r e 

−prsbri bsj/Arsij !, (B1) 

where pr be the average number of edge of type (r, s) 
between node that belong to each group. The log- 
likelihood can be write a 

lnP = 
1 

2 

∑ 
r 

er ln pr − nrnsprs − 
∑ 
i>j 

∑ 
r≥s 

lnArsij !. (B2) 

Maximizing lnP w.r.t. prs, we obtain p̂rs = ers/nrns, 
and hence 

ln P̂ = −E+ 1 
2 

∑ 
r 

er ln 

( 
er 
nrns 

) 
− 
∑ 
i>j 

∑ 
r≥s 

lnArsij !. (B3) 

For simple graph with Arsij ∈ {0, 1}, the last term in 
the above equation be equal to zero, and we have that 
the approximation of the likelihood of the model with 
“hard” constraint in the sparse case be identical to the ex- 
act maximum likelihood of the Poisson model with “soft” 
constraints. 

This model be similar to the popular mixed membership 
stochastic block model (MMSBM) [18]; however it differs 
in the important aspect that it generates strictly denser 
overlaps. In the MMSBM, the existence of an edge Aij 
be sample from a Bernoulli distribution with parameter 
λij = 

∑ 
r θ 

r 
i θ 
s 
jprs, where θri be the probability that node 

i belongs to group r, such that 
∑ 
r θ 

r 
i = 1, and pr ∈ [0, 1] 

be the probability that two node belonging to group r 
and s be connected. Although for sparse graph the 
difference between Poisson and Bernoulli model tend 
to disappear, with this parametrization the density of 
the overlap be mixed with normalize weights. More 
specifically, for a node i which belongs simultaneously 
to group r and s, it expect degree be equal to the 
weight average of the unmixed degrees, 〈k〉i = θri 〈k〉r+ 
θsi 〈k〉s, where 〈k〉r = 

∑ 
s pr 

∑ 
i θ 
s 
i be the expect degree 

of a node that belongs only to group r. Thus, in the 
MMSBM the node in the mixture have an intermediate 
density between the sparser and the denser groups. In 
contrast, in the model consider in the main text, a well 
a the Poisson model above, we have simply 〈k〉i = 〈k〉r+ 
〈k〉s, and therefore the overlap be always strictly denser 
than the pure groups. In this respect, it be equivalent to 
other formulation of the MMSBM, see e.g. Refs. [90, 91]. 

2. Degree-corrected 

A connection to a version of the model with “soft” con- 
straints can also be made. We may consider each la- 
beled entry Arsij in the adjacency matrix to be Poisson 
distribute with an average give by θri θsjλrs, 

P (G|{~bi}, {λrs}, {θr}) = 
∏ 
i>j 

∏ 
r≥s 

(θri θ 
s 
jλrs) 

Arsij e−θ 
r 
i θ 

s 
jλrs/Arsij !, 

(B4) 



16 

where Arsij be the number of edge of type (r, s) between 
node i and j, and θri be the propensity with which a 
node receives an edge of type r. The log-likelihood can 
be write a 

lnP = 
1 

2 

∑ 
r 

er lnλrs + 
∑ 
ir 

kri ln θ 
r 
i − 

∑ 
r≥s 

λrs 
∑ 
i>j 

θri θ 
s 
j 

− 
∑ 
i>j 

∑ 
r≥s 

lnArsij !. (B5) 

Maximizing lnP w.r.t. {λrs} and {θri }, we obtain λ̂rs = 
ers/eres and θ̂ri = kri , and hence 

ln P̂ = −E + 1 
2 

∑ 
r 

er ln 

( 
er 
eres 

) 
+ 
∑ 
ir 

kri ln k 
r 
i 

− 
∑ 
i>j 

∑ 
r≥s 

lnArsij !. (B6) 

Again, for simple graph with Arsij ∈ {0, 1}, the last term 
in the above equation be equal to zero; however even in 
that case the likelihood be not identical to the version with 
“hard” constraint consider above, a be the case for the 
single membership version a well [42]. Both likelihood 
only become the same in the limit kri � 1 such that 
ln kri ! ' kri ln kri − kri . Nevertheless, for the purpose of 
this paper, the difference between these model can be 
overlooked. 

There be a direct connection between this model and 
the one propose by Ball et al [20]. In the not strictly 
assortative version of their model, the number of edge 
Aij be distribute accord to a Poisson with average 
λij = 

∑ 
r η 

r 
i η 
s 
jωrs, where ηri be the propensity with which 

node i receives edge of type r and ωrs regulates the 
number of edge across groups. The total likelihood of 
that model be 

P (G|{~bi}, {ωrs}, {ηr}) = 
∏ 
i>j 

λ 
Aij 
ij e 

−λij/Aij !. (B7) 

Since the sum of independent Poisson random variable 
be also distribute accord to a Poisson, if we gener- 
ate a graph with the model of Eq. B4 and observe only 
the total unlabeled edge count Aij = 

∑ 
rsA 

r 
ij , they be 

distribute exactly like Eq. B7, for the same choice of 
parameter θri = ηri and λrs = ωrs. Hence, the model 
of the main text be an equivalent formulation of the one 
in Ref. [20] where one keep track of the latent variable 
specify the exact type of each half-edge, instead of 
their marginal probability. This have the advantage that 
the maximum likelihood estimate for the model param- 
eters λrs and θri can be obtain directly by differentia- 
tion, and do not require iteration of an EM algorithm 
a in Ref. [20]. On the other hand we be left with the 
determination of label in the half-edges, which be do 
with the method already described in Sec. VI. 

Appendix C: Maximum-entropy ensemble of count 
with constrain average 

Suppose we want to compute the number of all possi- 
ble non-negative integer count {nk}, subject to a nor- 
malization constraint 

∑∞ 
k=0 nk = N and a fix average∑∞ 

k=0 knk = E. This can be obtain approximately, 
by relax the constraint so that they hold only on 
average. The maximum entropy ensemble give these 
constraint be the one with the probability P ({nk}) = 
e−H({nk})/Z, with H({nk}) = λ 

∑ 
k nk + µ 

∑ 
k knk, 

where λ and µ be the Lagrange multiplier that keep 
the constraint in place. This ensemble be mathemati- 
cally analogous to a simple Bose gas with energy level 
give by k. The partition function be give by 

Z = 
∑ 
{nk} 

e−λ 
∑ 

k nk−µ 
∑ 

k knk = 
∏ 
k 

Zk, (C1) 

with 

Zk = 
[ 
1− e−λ−µk 

]−1 
. (C2) 

The average count be give by 〈nk〉 = −∂ lnZk/∂λ = 
[exp(λ+ µk)− 1]−1, and the parameter λ and µ be de- 
termined via the impose constraints, 

∞∑ 
k=0 

[exp(λ+ µk)− 1]−1 = N, (C3) 

∞∑ 
k=0 

k [exp(λ+ µk)− 1]−1 = E. (C4) 

Further analytical progress can be make by replace the 
sum with integrals, and use the polylogarithm func- 
tion and it connection with the Bose–Einstein distribu- 
tion, Lis(z) = Γ(s)−1 

∫∞ 
0 

ts−1 

et/z−1dt,∫ ∞ 
0 

dk [exp(λ+ µk)− 1]−1 = Li1(e 
−λ) 
µ 

= N, (C5)∫ ∞ 
0 

dkk [exp(λ+ µk)− 1]−1 = Li2(e 
−λ) 

µ2 
= E. (C6) 

Eq. C5 can be invert a e−λ = 1 − exp(−N/µ), but 
Eq. C6 cannot be solve for λ in close form. However, 
by assume a sufficiently “high temperature” regime 
where µ ∼ O(1), we have that the fugacity simplifies 
in the thermodynamic limit, e−λ → 1 for N � 1, 
and hence we obtain µ ' 

√ 
Li2(1)/E. Using Eqs. C5 

and C6, we can write the entropy of the ensemble ln Ξ = 
− 
∑ 
k [∂ lnZk/∂λ+ ∂ lnZk/∂µ+ lnZk], a 

ln Ξ = λN + 2µE, (C7) 

and for the regime e−λ → 1, we have 

ln Ξ ' 2 
√ 
ζ(2)E, (C8) 



17 

where the identity Li2(1) = ζ(2) be used, with ζ(x) 
be the Riemann zeta function. Although Eq. C8 be- 
come asymptotically exact in the thermodynamic limit 
with E ∼ N and N � 1, the exact solution can also 
be obtain with arbitrary precision simply by iterat- 
ing Eqs. C5 and C6 a λ̂(t + 1) = 1 − exp(−N/µ(t)), 
µ(t+1) = 

√ 
E/Li2(λ̂(t)), where λ̂ ≡ e−λ, with the start- 

ing point λ̂(0) = 1, µ(0) = 
√ 

Li2(1)/E, until sufficient 
convergence be reached, and the result be substitute 
in Eq. C7. (We actually use this more precise procedure 
when compute Eq. 13 in the main text, throughout the 
analysis.) 

[1] M. E. J. Newman, “Communities, module and large- 
scale structure in networks,” Nat Phys 8, 25–31 (2011). 

[2] Santo Fortunato, “Community detection in graphs,” 
Physics Reports 486, 75–174 (2010). 

[3] Petter Holme, “Core-periphery organization of complex 
networks,” Physical Review E 72, 046111 (2005). 

[4] M. Puck Rombach, Mason A. Porter, James H. Fowler, 
and Peter J. Mucha, “Core-periphery structure in net- 
works,” arXiv:1202.2684 (2012). 

[5] Daniel B. Larremore, Aaron Clauset, and Abigail Z. Ja- 
cobs, “Efficiently infer community structure in bipar- 
tite networks,” Physical Review E 90, 012805 (2014). 

[6] Aaron Clauset, Cristopher Moore, and M. E. J. New- 
man, “Hierarchical structure and the prediction of miss- 
ing link in networks,” Nature 453, 98–101 (2008). 

[7] Tiago P. Peixoto, “Hierarchical block structure and 
high-resolution model selection in large networks,” Phys- 
ical Review X 4, 011047 (2014). 

[8] Roger Guimerà and Marta Sales-Pardo, “Missing and 
spurious interaction and the reconstruction of complex 
networks,” Proceedings of the National Academy of Sci- 
ences 106, 22073 –22078 (2009). 

[9] Sergey V. Buldyrev, Roni Parshani, Gerald Paul, H. Eu- 
gene Stanley, and Shlomo Havlin, “Catastrophic cas- 
cade of failure in interdependent networks,” Nature 464, 
1025–1028 (2010). 

[10] Andrea Apolloni, Chiara Poletto, José J. Ramasco, Pablo 
Jensen, and Vittoria Colizza, “Metapopulation epidemic 
model with heterogeneous mix and travel behaviour,” 
Theoretical Biology and Medical Modelling 11, 3 (2014). 

[11] Roger Guimerà and Luís A. Nunes Amaral, “Functional 
cartography of complex metabolic networks,” Nature 
433, 895–900 (2005). 

[12] M. E. J. Newman, “Modularity and community structure 
in networks,” Proceedings of the National Academy of 
Sciences 103, 8577–8582 (2006). 

[13] M. Girvan and M. E. J. Newman, “Community structure 
in social and biological networks,” Proceedings of the Na- 
tional Academy of Sciences 99, 7821 –7826 (2002). 

[14] Yong-Yeol Ahn, James P. Bagrow, and Sune Lehmann, 
“Link community reveal multiscale complexity in net- 
works,” Nature 466, 761–764 (2010). 

[15] Gergely Palla, Imre Derényi, Illés Farkas, and Tamás 
Vicsek, “Uncovering the overlap community struc- 
ture of complex network in nature and society,” Nature 
435, 814–818 (2005). 

[16] Martin Rosvall and Carl T. Bergstrom, “Maps of random 
walk on complex network reveal community structure,” 
Proceedings of the National Academy of Sciences 105, 
1118–1123 (2008). 

[17] Paul W. Holland, Kathryn Blackmond Laskey, and 
Samuel Leinhardt, “Stochastic blockmodels: First steps,” 
Social Networks 5, 109–137 (1983). 

[18] Edoardo M. Airoldi, David M. Blei, Stephen E. Fien- 
berg, and Eric P. Xing, “Mixed membership stochastic 
blockmodels,” J. Mach. Learn. Res. 9, 1981–2014 (2008). 

[19] Brian Karrer and M. E. J. Newman, “Stochastic block- 
model and community structure in networks,” Physical 
Review E 83, 016107 (2011). 

[20] Brian Ball, Brian Karrer, and M. E. J. Newman, “Ef- 
ficient and principled method for detect community 
in networks,” Physical Review E 84, 036103 (2011). 

[21] Andrea Lancichinetti, Santo Fortunato, and János 
Kertész, “Detecting the overlap and hierarchical 
community structure in complex networks,” New Jour- 
nal of Physics 11, 033015 (2009). 

[22] Gergely Palla, László Lovász, and Tamás Vicsek, “Mul- 
tifractal network generator,” Proceedings of the National 
Academy of Sciences 107, 7640 –7645 (2010). 

[23] Jure Leskovec, Deepayan Chakrabarti, Jon Kleinberg, 
Christos Faloutsos, and Zoubin Ghahramani, “Kronecker 
graphs: An approach to model networks,” J. Mach. 
Learn. Res. 11, 985–1042 (2010). 

[24] Mahendra Mariadassou, Stéphane Robin, and Corinne 
Vacher, “Uncovering latent structure in value graphs: 
A variational approach,” The Annals of Applied Statis- 
tic 4, 715–742 (2010), mathematical Reviews number 
(MathSciNet): MR2758646. 

[25] Christopher Aicher, Abigail Z. Jacobs, and Aaron 
Clauset, “Learning latent block structure in weight net- 
works,” Journal of Complex Networks , cnu026 (2014). 

[26] Brian Ball and M.e.j. Newman, “Friendship network and 
social status,” Network Science 1, 16–30 (2013). 

[27] Mikko Kivelä, Alex Arenas, Marc Barthelemy, James P. 
Gleeson, Yamir Moreno, and Mason A. Porter, “Multi- 
layer networks,” Journal of Complex Networks 2, 203–271 
(2014). 

[28] Wenjie Fu, Le Song, and Eric P. Xing, “Dynamic mixed 
membership blockmodel for evolve networks,” in Pro- 
ceedings of the 26th Annual International Conference on 
Machine Learning , ICML ’09 (ACM, New York, NY, 
USA, 2009) pp. 329–336. 

[29] Xiaoran Yan, Cosma Shalizi, Jacob E. Jensen, Flo- 
rent Krzakala, Cristopher Moore, Lenka Zdeborová, Pan 
Zhang, and Yaojia Zhu, “Model selection for degree- 
correct block models,” Journal of Statistical Mechan- 
ics: Theory and Experiment 2014, P05007 (2014). 

[30] M. E. J. Newman, “Community detection and graph par- 
titioning,” EPL (Europhysics Letters) 103, 28003 (2013). 

[31] M. E. J. Newman, “Spectral method for community de- 
tection and graph partitioning,” Physical Review E 88, 

http://dx.doi.org/10.1038/nphys2162 
http://dx.doi.org/16/j.physrep.2009.11.002 
http://dx.doi.org/ 10.1103/PhysRevE.72.046111 
http://arxiv.org/abs/1202.2684 
http://dx.doi.org/10.1103/PhysRevE.90.012805 
http://dx.doi.org/10.1038/nature06830 
http://dx.doi.org/10.1103/PhysRevX.4.011047 
http://dx.doi.org/10.1103/PhysRevX.4.011047 
http://dx.doi.org/10.1073/pnas.0908366106 
http://dx.doi.org/10.1073/pnas.0908366106 
http://dx.doi.org/10.1038/nature08932 
http://dx.doi.org/10.1038/nature08932 
http://dx.doi.org/ 10.1186/1742-4682-11-3 
http://dx.doi.org/10.1038/nature03288 
http://dx.doi.org/10.1038/nature03288 
http://dx.doi.org/10.1073/pnas.0601602103 
http://dx.doi.org/10.1073/pnas.0601602103 
http://dx.doi.org/ 10.1073/pnas.122653799 
http://dx.doi.org/ 10.1073/pnas.122653799 
http://dx.doi.org/10.1038/nature09182 
http://dx.doi.org/10.1038/nature03607 
http://dx.doi.org/10.1038/nature03607 
http://dx.doi.org/10.1073/pnas.0706851105 
http://dx.doi.org/10.1073/pnas.0706851105 
http://dx.doi.org/ 16/0378-8733(83)90021-7 
http://dl.acm.org/citation.cfm?id=1390681.1442798 
http://dx.doi.org/ 10.1103/PhysRevE.83.016107 
http://dx.doi.org/ 10.1103/PhysRevE.83.016107 
http://dx.doi.org/ 10.1103/PhysRevE.84.036103 
http://dx.doi.org/ 10.1088/1367-2630/11/3/033015 
http://dx.doi.org/ 10.1088/1367-2630/11/3/033015 
http://dx.doi.org/10.1073/pnas.0912983107 
http://dx.doi.org/10.1073/pnas.0912983107 
http://dl.acm.org/citation.cfm?id=1756006.1756039 
http://dl.acm.org/citation.cfm?id=1756006.1756039 
http://dx.doi.org/10.1214/10-AOAS361 
http://dx.doi.org/10.1214/10-AOAS361 
http://dx.doi.org/10.1093/comnet/cnu026 
http://dx.doi.org/10.1017/nws.2012.4 
http://dx.doi.org/10.1093/comnet/cnu016 
http://dx.doi.org/10.1093/comnet/cnu016 
http://dx.doi.org/10.1145/1553374.1553416 
http://dx.doi.org/10.1145/1553374.1553416 
http://dx.doi.org/10.1145/1553374.1553416 
http://dx.doi.org/ 10.1088/1742-5468/2014/05/P05007 
http://dx.doi.org/ 10.1088/1742-5468/2014/05/P05007 
http://dx.doi.org/10.1209/0295-5075/103/28003 
http://dx.doi.org/10.1103/PhysRevE.88.042822 


18 

042822 (2013). 
[32] Raj Rao Nadakuditi and M. E. J. Newman, “Graph spec- 

tra and the detectability of community structure in net- 
works,” Physical Review Letters 108, 188701 (2012). 

[33] Florent Krzakala, Cristopher Moore, Elchanan Mossel, 
Joe Neeman, Allan Sly, Lenka Zdeborová, and Pan 
Zhang, “Spectral redemption in cluster sparse net- 
works,” Proceedings of the National Academy of Sciences 
, 201312486 (2013). 

[34] Andrea Lancichinetti, Santo Fortunato, and Filippo 
Radicchi, “Benchmark graph for test community 
detection algorithms,” Physical Review E 78, 046110 
(2008). 

[35] Andrea Lancichinetti and Santo Fortunato, “Benchmarks 
for test community detection algorithm on direct 
and weight graph with overlap communities,” 
Physical Review E 80, 016118 (2009). 

[36] Andrea Lancichinetti and Santo Fortunato, “Community 
detection algorithms: A comparative analysis,” Physical 
Review E 80, 056117 (2009). 

[37] Brian Karrer, Elizaveta Levina, and M. E. J New- 
man, “Robustness of community structure in networks,” 
0709.2108 (2007). 

[38] Peter D. Grünwald, The Minimum Description Length 
Principle (The MIT Press, 2007). 

[39] Jorma Rissanen, Information and Complexity in Statis- 
tical Modeling, 1st ed. (Springer, 2010). 

[40] Martin Rosvall, Alcides V. Esquivel, Andrea Lanci- 
chinetti, Jevin D. West, and Renaud Lambiotte, “Mem- 
ory in network flow and it effect on spread dynam- 
ic and community detection,” Nature Communications 
5 (2014), 10.1038/ncomms5630. 

[41] Ginestra Bianconi, “Entropy of network ensembles,” 
Physical Review E 79, 036114 (2009). 

[42] Tiago P. Peixoto, “Entropy of stochastic blockmodel en- 
sembles,” Physical Review E 85, 056122 (2012). 

[43] Martin Rosvall and Carl T. Bergstrom, “An information- 
theoretic framework for resolve community structure 
in complex networks,” Proceedings of the National 
Academy of Sciences 104, 7327–7331 (2007). 

[44] Stephen E. Fienberg, Michael M. Meyer, and Stanley S. 
Wasserman, “Statistical analysis of multiple sociometric 
relations,” Journal of the American Statistical Associa- 
tion 80, 51–67 (1985). 

[45] Katherine Faust and Stanley Wasserman, “Blockmodels: 
Interpretation and evaluation,” Social Networks 14, 5–61 
(1992). 

[46] Carolyn J. Anderson, Stanley Wasserman, and Kather- 
ine Faust, “Building stochastic blockmodels,” Social Net- 
work 14, 137–161 (1992). 

[47] Pierre Latouche, Etienne Birmelé, and Christophe Am- 
broise, “Model selection in overlap stochastic block 
models,” Electronic Journal of Statistics 8, 762–794 
(2014). 

[48] Tiago P. Peixoto, “Parsimonious module inference in 
large networks,” Physical Review Letters 110, 148701 
(2013). 

[49] E. T. Jaynes, Probability Theory: The Logic of Science, 
edit by G. Larry Bretthorst (Cambridge University 
Press, Cambridge, UK ; New York, NY, 2003). 

[50] Sir Harold Jeffreys, The Theory of Probability (Oxford 
University Press, 1998). 

[51] Lada A. Adamic and Natalie Glance, “The political blo- 
gosphere and the 2004 u.s. election: divide they blog,” 

in Proceedings of the 3rd international workshop on Link 
discovery , LinkKDD ’05 (ACM, New York, NY, USA, 
2005) pp. 36–43. 

[52] D. Holten, “Hierarchical edge bundles: Visualization of 
adjacency relation in hierarchical data,” IEEE Transac- 
tions on Visualization and Computer Graphics 12, 741– 
748 (2006). 

[53] Julian Mcauley and Jure Leskovec, “Discovering social 
circle in ego networks,” ACM Trans. Knowl. Discov. 
Data 8, 4:1–4:28 (2014). 

[54] Donald E. Knuth, The Stanford GraphBase: A Platform 
for Combinatorial Computing, 1st ed. (Addison-Wesley 
Professional, New York, N.Y. : Reading, Mass, 1993). 

[55] T S Evans, “American college football network files,” 
FigShare (2012), 10.6084/m9.figshare.93179. 

[56] Wayne W. Zachary, “An information flow model for con- 
flict and fission in small groups,” Journal of Anthropo- 
logical Research 33, 452–473 (1977). 

[57] Jure Leskovec, Kevin J. Lang, Anirban Dasgupta, and 
Michael W. Mahoney, “Community structure in large 
networks: Natural cluster size and the absence of large 
well-defined clusters,” arXiv:0810.1355 (2008). 

[58] Bryan Klimt and Yiming Yang, “Introducing the enron 
corpus.” in CEAS (2004). 

[59] David Lusseau, Karsten Schneider, Oliver J. Boisseau, 
Patti Haase, Elisabeth Slooten, and Steve M. Dawson, 
“The bottlenose dolphin community of doubtful sound 
feature a large proportion of long-lasting associations,” 
Behavioral Ecology and Sociobiology 54, 396–405 (2003). 

[60] Oliver Richters and Tiago P. Peixoto, “Trust transitivity 
in social networks,” PLoS ONE 6, e18384 (2011). 

[61] Eunjoon Cho, Seth A. Myers, and Jure Leskovec, 
“Friendship and mobility: user movement in location- 
base social networks,” in Proceedings of the 17th ACM 
SIGKDD international conference on Knowledge discov- 
ery and data mining , KDD ’11 (ACM, New York, NY, 
USA, 2011) pp. 1082–1090. 

[62] D. J. Watts and S. H. Strogatz, “Collective dynamic of 
’small-world’ networks,” Nature 393, 409–10 (1998). 

[63] Jure Leskovec, Jon Kleinberg, and Christos Falout- 
sos, “Graph evolution: Densification and shrink di- 
ameters,” ACM Trans. Knowl. Discov. Data 1 (2007), 
10.1145/1217299.1217301. 

[64] M. E. J. Newman, “Finding community structure in net- 
work use the eigenvectors of matrices,” Physical Re- 
view E 74, 036104 (2006). 

[65] Matthew Richardson, Rakesh Agrawal, and Pedro 
Domingos, “Trust management for the semantic web,” in 
The Semantic Web - ISWC 2003 , Lecture Notes in Com- 
puter Science No. 2870, edit by Dieter Fensel, Katia 
Sycara, and John Mylopoulos (Springer Berlin Heidel- 
berg, 2003) pp. 351–368. 

[66] K. I. Goh, M. E. Cusick, D. Valle, B. Childs, M. Vidal, 
and A. L. Barabási, “The human disease network,” Pro- 
ceedings of the National Academy of Sciences 104, 8685 
(2007). 

[67] Haiyuan Yu, Pascal Braun, Muhammed A. Yıldırım, 
Irma Lemmens, Kavitha Venkatesan, Julie Sahalie, 
Tomoko Hirozane-Kishikawa, Fana Gebreab, Na Li, Nico- 
la Simonis, Tong Hao, Jean-François Rual, Amélie Dri- 
cot, Alexei Vazquez, Ryan R. Murray, Christophe Simon, 
Leah Tardivo, Stanley Tam, Nenad Svrzikapa, Changyu 
Fan, Anne-Sophie de Smet, Adriana Motyl, Michael E. 
Hudson, Juyong Park, Xiaofeng Xin, Michael E. Cusick, 

http://dx.doi.org/10.1103/PhysRevE.88.042822 
http://dx.doi.org/ 10.1103/PhysRevLett.108.188701 
http://dx.doi.org/10.1073/pnas.1312486110 
http://dx.doi.org/10.1073/pnas.1312486110 
http://dx.doi.org/ 10.1103/PhysRevE.78.046110 
http://dx.doi.org/ 10.1103/PhysRevE.78.046110 
http://dx.doi.org/10.1103/PhysRevE.80.016118 
http://dx.doi.org/ 10.1103/PhysRevE.80.056117 
http://dx.doi.org/ 10.1103/PhysRevE.80.056117 
http://arxiv.org/abs/0709.2108 
http://dx.doi.org/10.1038/ncomms5630 
http://dx.doi.org/10.1038/ncomms5630 
http://dx.doi.org/ 10.1103/PhysRevE.79.036114 
http://dx.doi.org/ 10.1103/PhysRevE.85.056122 
http://dx.doi.org/10.1073/pnas.0611034104 
http://dx.doi.org/10.1073/pnas.0611034104 
http://dx.doi.org/ 10.2307/2288040 
http://dx.doi.org/ 10.2307/2288040 
http://dx.doi.org/ 16/0378-8733(92)90013-W 
http://dx.doi.org/ 16/0378-8733(92)90013-W 
http://dx.doi.org/ 16/0378-8733(92)90017-2 
http://dx.doi.org/ 16/0378-8733(92)90017-2 
http://dx.doi.org/10.1214/14-EJS903 
http://dx.doi.org/10.1214/14-EJS903 
http://dx.doi.org/ 10.1103/PhysRevLett.110.148701 
http://dx.doi.org/ 10.1103/PhysRevLett.110.148701 
http://dx.doi.org/10.1145/1134271.1134277 
http://dx.doi.org/10.1145/1134271.1134277 
http://dx.doi.org/10.1109/TVCG.2006.147 
http://dx.doi.org/10.1109/TVCG.2006.147 
http://dx.doi.org/10.1109/TVCG.2006.147 
http://dx.doi.org/10.1145/2556612 
http://dx.doi.org/10.1145/2556612 
http://dx.doi.org/10.6084/m9.figshare.93179 
http://www.jstor.org/stable/3629752 
http://www.jstor.org/stable/3629752 
http://arxiv.org/abs/0810.1355 
http://bklimt.com/papers/2004_klimt_ceas.pdf 
http://dx.doi.org/ 10.1007/s00265-003-0651-y 
http://dx.doi.org/ 10.1371/journal.pone.0018384 
http://dx.doi.org/ 10.1145/2020408.2020579 
http://dx.doi.org/ 10.1145/2020408.2020579 
http://dx.doi.org/ 10.1145/2020408.2020579 
http://dx.doi.org/ 10.1145/1217299.1217301 
http://dx.doi.org/ 10.1145/1217299.1217301 
http://dx.doi.org/10.1103/PhysRevE.74.036104 
http://dx.doi.org/10.1103/PhysRevE.74.036104 
http://link.springer.com/chapter/10.1007/978-3-540-39718-2_23 
http://www.pnas.org/content/104/21/8685.short 
http://www.pnas.org/content/104/21/8685.short 
http://www.pnas.org/content/104/21/8685.short 


19 

Troy Moore, Charlie Boone, Michael Snyder, Frederick P. 
Roth, Albert-László Barabási, Jan Tavernier, David E. 
Hill, and Marc Vidal, “High-quality binary protein in- 
teraction map of the yeast interactome network,” Science 
322, 104–110 (2008). 

[68] Teresa Reguly, Ashton Breitkreutz, Lorrie Boucher, 
Bobby-Joe Breitkreutz, Gary C. Hon, Chad L. Myers, 
Ainslie Parsons, Helena Friesen, Rose Oughtred, Amy 
Tong, Chris Stark, Yuen Ho, David Botstein, Brenda An- 
drews, Charles Boone, Olga G. Troyanskya, Trey Ideker, 
Kara Dolinski, Nizar N. Batada, and Mike Tyers, “Com- 
prehensive curation and analysis of global interaction net- 
work in saccharomyces cerevisiae,” Journal of Biology 5, 
11 (2006). 

[69] Sean R. Collins, Patrick Kemmeren, Xue-Chu Zhao, 
Jack F. Greenblatt, Forrest Spencer, Frank C. P. Hol- 
stege, Jonathan S. Weissman, and Nevan J. Krogan, 
“Toward a comprehensive atlas of the physical interac- 
tome of saccharomyces cerevisiae,” Molecular & cellular 
proteomics: MCP 6, 439–450 (2007). 

[70] Heladia Salgado, Martin Peralta-Gil, Socorro Gama- 
Castro, Alberto Santos-Zavaleta, Luis Muñiz-Rascado, 
Jair S. García-Sotelo, Verena Weiss, Hilda Solano-Lira, 
Irma Martínez-Flores, Alejandra Medina-Rivera, Ger- 
ardo Salgado-Osorio, Shirley Alquicira-Hernández, Kevin 
Alquicira-Hernández, Alejandra López-Fuentes, Liliana 
Porrón-Sotelo, Araceli M. Huerta, César Bonavides- 
Martínez, Yalbi I. Balderas-Martínez, Lucia Pannier, 
Maricela Olvera, Aurora Labastida, Verónica Jiménez- 
Jacinto, Leticia Vega-Alvarado, Victor Del Moral- 
Chávez, Alfredo Hernández-Alvarez, Enrique Morett, 
and Julio Collado-Vides, “RegulonDB v8.0: omics 
data sets, evolutionary conservation, regulatory phrases, 
cross-validated gold standard and more,” Nucleic Acids 
Research 41, D203–213 (2013). 

[71] Julian McAuley and Jure Leskovec, “Image label on a 
network: Using social-network metadata for image clas- 
sification,” in Computer Vision – ECCV 2012 , Lecture 
Notes in Computer Science No. 7575, edit by Andrew 
Fitzgibbon, Svetlana Lazebnik, Pietro Perona, Yoichi 
Sato, and Cordelia Schmid (Springer Berlin Heidelberg, 
2012) pp. 828–841. 

[72] Jure Leskovec, Kevin J. Lang, Anirban Dasgupta, and 
Michael W. Mahoney, “Community structure in large 
networks: Natural cluster size and the absence of large 
well-defined clusters,” Internet Mathematics 6, 29–123 
(2009). 

[73] Jaewon Yang and Jure Leskovec, “Defining and evalu- 
ating network community base on ground-truth,” in 
Proceedings of the ACM SIGKDD Workshop on Mining 
Data Semantics, MDS ’12 (ACM, New York, NY, USA, 
2012) pp. 3:1–3:8. 

[74] Réka Albert, Hawoong Jeong, and Albert-László 
Barabási, “Internet: Diameter of the world-wide web,” 
Nature 401, 130–131 (1999). 

[75] Jure Leskovec, Daniel Huttenlocher, and Jon Kleinberg, 
“Signed network in social media,” in Proceedings of the 
SIGCHI Conference on Human Factors in Computing 
Systems, CHI ’10 (ACM, New York, NY, USA, 2010) 
pp. 1361–1370. 

[76] Jure Leskovec, Daniel Huttenlocher, and Jon Kleinberg, 
“Predicting positive and negative link in online social 
networks,” in Proceedings of the 19th International Con- 
ference on World Wide Web, WWW ’10 (ACM, New 

York, NY, USA, 2010) pp. 641–650. 
[77] T. S. Keshava Prasad, Renu Goel, Kumaran Kan- 

dasamy, Shivakumar Keerthikumar, Sameer Kumar, 
Suresh Mathivanan, Deepthi Telikicherla, Rajesh Raju, 
Beema Shafreen, Abhilash Venugopal, Lavanya Balakr- 
ishnan, Arivusudar Marimuthu, Sutopa Banerjee, Devi S. 
Somanathan, Aimy Sebastian, Sandhya Rani, Somak 
Ray, C. J. Harrys Kishore, Sashi Kanth, Mukhtar 
Ahmed, Manoj K. Kashyap, Riaz Mohmood, Y. L. Ra- 
machandra, V. Krishna, B. Abdul Rahiman, Sujatha Mo- 
han, Prathibha Ranganathan, Subhashri Ramabadran, 
Raghothama Chaerkady, and Akhilesh Pandey, “Human 
protein reference database—2009 update,” Nucleic Acids 
Research 37, D767–D772 (2009). 

[78] M. E. J. Newman, “Fast algorithm for detect com- 
munity structure in networks,” Physical Review E 69, 
066133 (2004). 

[79] Aaron Clauset, M. E. J. Newman, and Cristopher 
Moore, “Finding community structure in very large net- 
works,” Physical Review E 70, 066111 (2004). 

[80] A. Arenas, L. Danon, A. Díaz-Guilera, P. M. Gleiser, and 
R. Guimerá, “Community analysis in social networks,” 
The European Physical Journal B - Condensed Matter 
and Complex Systems 38, 373–380 (2004). 

[81] Tiago P. Peixoto, “Efficient monte carlo and greedy 
heuristic for the inference of stochastic block models,” 
Physical Review E 89, 012804 (2014). 

[82] Nicholas Metropolis, Arianna W. Rosenbluth, Mar- 
shall N. Rosenbluth, Augusta H. Teller, and Edward 
Teller, “Equation of state calculation by fast compute 
machines,” The Journal of Chemical Physics 21, 1087 
(1953). 

[83] W. K. Hastings, “Monte carlo sample method use 
markov chain and their applications,” Biometrika 57, 
97 –109 (1970). 

[84] Aurelien Decelle, Florent Krzakala, Cristopher Moore, 
and Lenka Zdeborová, “Inference and phase transition 
in the detection of module in sparse networks,” Physical 
Review Letters 107, 065701 (2011). 

[85] Aurelien Decelle, Florent Krzakala, Cristopher Moore, 
and Lenka Zdeborová, “Asymptotic analysis of the 
stochastic block model for modular network and it al- 
gorithmic applications,” Physical Review E 84, 066106 
(2011). 

[86] Prem K. Gopalan and David M. Blei, “Efficient discov- 
ery of overlap community in massive networks,” 
Proceedings of the National Academy of Sciences 110, 
14534–14539 (2013). 

[87] Tiago P. Peixoto, “The graph-tool python library,” 
figshare (2014), 10.6084/m9.figshare.1164194. 

[88] Alcides Viamontes Esquivel and Martin Rosvall, “Com- 
pression of flow can reveal overlapping-module organiza- 
tion in networks,” Physical Review X 1, 021025 (2011). 

[89] Peter D Hoff, Adrian E Raftery, and Mark S Hand- 
cock, “Latent space approach to social network analy- 
sis,” Journal of the American Statistical Association 97, 
1090–1098 (2002). 

[90] Juuso Parkkinen, Janne Sinkkonen, Adam Gyenge, 
and Samuel Kaski, “A block model suitable for sparse 
graphs,” in Proceedings of the 7th International Work- 
shop on Mining and Learning with Graphs (MLG 2009), 
Leuven (2009). 

[91] Jaewon Yang and J. Leskovec, “Community-affiliation 
graph model for overlap network community detec- 

http://dx.doi.org/10.1126/science.1158684 
http://dx.doi.org/10.1126/science.1158684 
http://dx.doi.org/10.1186/jbiol36 
http://dx.doi.org/10.1186/jbiol36 
http://dx.doi.org/10.1074/mcp.M600381-MCP200 
http://dx.doi.org/10.1074/mcp.M600381-MCP200 
http://dx.doi.org/ 10.1093/nar/gks1201 
http://dx.doi.org/ 10.1093/nar/gks1201 
http://link.springer.com/chapter/10.1007/978-3-642-33765-9_59 
http://www.tandfonline.com/doi/abs/10.1080/15427951.2009.10129177 
http://www.tandfonline.com/doi/abs/10.1080/15427951.2009.10129177 
http://dx.doi.org/ 10.1145/2350190.2350193 
http://dx.doi.org/ 10.1145/2350190.2350193 
http://dx.doi.org/10.1038/43601 
http://dx.doi.org/10.1145/1753326.1753532 
http://dx.doi.org/10.1145/1753326.1753532 
http://dx.doi.org/10.1145/1753326.1753532 
http://dx.doi.org/10.1145/1772690.1772756 
http://dx.doi.org/10.1145/1772690.1772756 
http://dx.doi.org/10.1093/nar/gkn892 
http://dx.doi.org/10.1093/nar/gkn892 
http://dx.doi.org/10.1103/PhysRevE.69.066133 
http://dx.doi.org/10.1103/PhysRevE.69.066133 
http://dx.doi.org/ 10.1103/PhysRevE.70.066111 
http://dx.doi.org/10.1140/epjb/e2004-00130-1 
http://dx.doi.org/10.1140/epjb/e2004-00130-1 
http://dx.doi.org/10.1103/PhysRevE.89.012804 
http://dx.doi.org/10.1063/1.1699114 
http://dx.doi.org/10.1063/1.1699114 
http://dx.doi.org/10.1093/biomet/57.1.97 
http://dx.doi.org/10.1093/biomet/57.1.97 
http://dx.doi.org/10.1103/PhysRevLett.107.065701 
http://dx.doi.org/10.1103/PhysRevLett.107.065701 
http://dx.doi.org/10.1103/PhysRevE.84.066106 
http://dx.doi.org/10.1103/PhysRevE.84.066106 
http://dx.doi.org/10.1073/pnas.1221839110 
http://dx.doi.org/10.1073/pnas.1221839110 
http://dx.doi.org/ 10.6084/m9.figshare.1164194 
http://dx.doi.org/10.1103/PhysRevX.1.021025 
http://dx.doi.org/ 10.1198/016214502388618906 
http://dx.doi.org/ 10.1198/016214502388618906 
http://research.ics.aalto.fi/mi/info/online-papers/mlg09sibm.pdf 
http://research.ics.aalto.fi/mi/info/online-papers/mlg09sibm.pdf 
http://research.ics.aalto.fi/mi/info/online-papers/mlg09sibm.pdf 


20 

tion,” in 2012 IEEE 12th International Conference on 
Data Mining (ICDM) (2012) pp. 1170–1175. 

http://dx.doi.org/10.1109/ICDM.2012.139 
http://dx.doi.org/10.1109/ICDM.2012.139 

Model selection and hypothesis test for large-scale network model with overlap group 
Abstract 
I Introduction 
II Generative model for network structure 
A Overlapping model without degree correction 
B Overlapping model with degree correction 

III Model Selection 
A Overlapping partition, {i} 
B Labeled degree sequence, {i} 
C Edge counts, {ers} 
D Significance level 

IV Empirical network 
V Model identifiability: Overlapping vs. nonoverlapping 
VI Inference algorithm 
VII Conclusion 
A Directed graph 
B Poisson Models 
1 Non-degree-corrected 
2 Degree-corrected 

C Maximum-entropy ensemble of count with constrain average 
References 


