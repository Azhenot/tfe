






































Field-data study find no evidence of racial bias in predictive policing: News at IU: Indiana University 


Field-data study find no evidence of 
racial bias in predictive policing: News 
at IU: Indiana University 

Rich Schneider 

INDIANAPOLIS -- While predictive police aim to improve the 
effectiveness of police patrols, there be concern that these algorithm 
may lead police to target minority community and result in 
discriminatory arrests. A computer scientist in the School of Science at 
IUPUI conduct the first study to look at real-time field data from Los 
Angeles and found predictive police do not result in bias arrests. 

"Predictive police be still a fairly new field. There have be several 
field trial of predictive police where the crime rate reduction be 
measured, but there have be no empirical field trial to date look 
at whether these algorithms, when deployed, target certain racial 
group more than others and lead to bias stop or arrests," say 
George Mohler, an associate professor of computer and information 
science in the School of Science at IUPUI. 

Mohler, along with researcher at UCLA and Louisiana State University, 
work with the Los Angeles Police Department to conduct the 
experimental study. A human analyst make prediction on where 
officer would patrol each day, and an algorithm also make a set of 
predictions; it be then randomly select which set be use by 
officer in the field each day. 

The researcher measure the difference in arrest rate by ethnic 
group between the predictive police algorithm and map of hot spot 
create by LAPD analyst that be in use prior to the experiment. 

"When we look at the data, the difference in arrest rate by ethnic 
group between predictive police and standard patrol practice be 
not statistically significant," Mohler said. 

The study examine data both at the district level and within the LAPD 
officers' patrol area and found there be no statistically significant 
difference between arrest rate by ethnic group at either geographical 
level. Finally, researcher look at arrest rate overall in patrol area 
and found that they be statistically high in the algorithmically 
select areas, but when adjust for the high crime rate in those 
areas, the arrest be low or unchanged. "The high crime rate, and 
proportionally high arrest rate, be what you would expect since the 
algorithm be design to identify area with high crime rates," Mohler 
said. 

Field-data study find no evidence of racial bias in predictive policing: ... https://news.iu.edu/stories/2018/03/iupui/releases/12-predictive-policing-... 

1 sur 2 19-03-18 à 17:45 



Mohler say that in the develop field of predictive policing, there 
continue to be lesson learn from each study and implementation. A 
recent simulation study of predictive police with drug arrest data 
from Oakland, California, show there be potential for bias when these 
algorithm be apply in certain contexts. Mohler hope the Los 
Angeles study be a start point to measure predictive police bias in 
future field experiments. 

"Every time you do one of these predictive police deployments, 
department should monitor the ethnic impact of these algorithm to 
check whether there be racial bias," Mohler said. "I think the statistical 
method we provide in this paper provide a framework to monitor that." 

"Does Predictive Policing Lead to Biased Arrests? Results from A 
Randomized Control Trial" be publish in the journal Statistics and 
Public Policy. Additional author be P. Jeffrey Brantingham of UCLA, 
correspond author, and Matthew Valasik of Louisiana State 
University. 

Field-data study find no evidence of racial bias in predictive policing: ... https://news.iu.edu/stories/2018/03/iupui/releases/12-predictive-policing-... 

2 sur 2 19-03-18 à 17:45 


