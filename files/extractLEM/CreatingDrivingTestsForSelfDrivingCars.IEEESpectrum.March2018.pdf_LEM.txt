






































Creating Driving Tests for Self-â†€Driving Cars - IEEE Spectrum 


Volvo-backed Zenuity want to prove that autonomous vehicle can drive 
more safely than human 

Illustration: Jude Buffum 

east of Gothenburg, 

Sweden, people be ushered into 

autonomous vehicle for a test drive. 

But there’s a twist: The vehicle 

aren’t actually autonomous—there’s a 

hidden driver in the back—and the 

people be participate in an 

experiment to discover how they’ll 

behave when the car be chauffeur 

them around. 

At a test track 

At 

—a joint 

venture between 

and 

, a Swedish auto-safety 

company—this test be just one of many 

way we make sure not just that autonomous vehicle work but that they can drive more safely than human 

ever could. If self-driving car be ever go to hit the road, they’ll need to know the rule and how to follow 

them safely, regardless of how much they might depend on the human behind the wheel. 

Zenuity 

(https://www.zenuity.com/) 

Volvo 

(https://www.volvocars.com/us/footer 

/about) Autoliv 

(https://www.autoliv.com/about- 

us/autoliv-brief) 

Even now your car doesn’t need you a much a it once did. Advanced computer vision, radar technology, 

and computational platform already intervene to avoid accidents, turn car into guardian angel for their 

drivers. Vehicles will continue take over more drive task until 

. This will be the big 

transportation revolution since car replace horse-drawn carriages. 

they’re capable of drive themselves 

(/transportation/self-driving/the-first-fully-commercial-robocar-will-be-in-holland) 

Creating Driving Tests for Self-Driving Cars - IEEE Spectrum https://spectrum.ieee.org/transportation/self-driving/creating-driving-test... 

1 sur 8 10-04-18 à 08:50 



But it’s one thing to build a self-driving vehicle that works, and quite another to prove that it’s safe. Traffic 

can be a unpredictable a the weather, and be able to respond to both mean navigate countless 

scenarios. To fully test all those scenario by simply drive around would take not year but centuries. 

Therefore, we have to find other way to assure safety—things like computer simulation and mathematical 

modeling. We’re combine real traffic test with extensive augmented-reality simulation and test case on 

one of the world’s most advanced test track to truly understand how to make self-driving car safe. 

to cruise down a straightaway in the middle of a sunny day. But what 

about what we call corner cases—scenarios in which several unlikely factor occur together? A road litter 

with fall branch during a thunderstorm pose different challenge to a vehicle than an elk cross the 

road while the sun be setting. 

It’s easy for a self-driving vehicle 

Manufacturers 

for vehicle that react incorrectly, and so they want to know how the 

vehicle will respond. For us, the big question be “How do we know the vehicle be safe?” 

will likely be held liable (https://www.engadget.com/2017/12/02/california-axes-self- 

driving-car-rule-limiting-liability/) 

But before that, we must first ask what it mean for a self-driving vehicle to be safe. Safe doesn’t mean 

perfect; perfect information about the environment will never be available. Instead, it must mean the self- 

drive vehicle can handle the problem it’s design to handle, like obey speed limits, yield to a car 

merge into it lane, or observe right-of-way at a stop sign. And it must also recognize when it be at risk of 

exceed it design specifications. For example, the vehicle shouldn’t attempt to drive after be place in 

the middle of the forest. 

In 9 out of 10 accident result in fatality or major injuries, mistake by the driver 

, accord to 

multiple U.S. and U.K. sources. Because of this, the quick answer to what be “safe enough” be usually “better 

than a human driver.” But the devil be in the details. It’s too easy a challenge to surpass the drunken driver or 

even the statistically average driver. The median driver, you might argue, be not very good. 

be a contribute 

factor (http://cyberlaw.stanford.edu/blog/2013/12/human-error-cause-vehicle-crashes) 

We propose that self-driving car be held neither to a standard so strict that it delay the introduction of a 

life-saving technology nor to one so lenient that it treat the initial customer a guinea pigs. Instead, the first 

self-driving vehicle should be demonstrably safer than a vehicle driven by the median human driver. We 

believe that if every component can be demonstrate to work good than a human and if the complex 

algorithm that govern each component can interact together to drive the vehicle, it’s reasonable to conclude 

that the car be 

than the human. 

a good driver (http://www.slate.com/articles/technology/technology/2017/11 

/a_self_driving_car_that_kills_is_still_better_than_a_human_driver.html) 

This mean design the vehicle’s system to handle any situation within it scope and discount the rest. 

While it be possible a parachutist could land directly in front of the vehicle, it be so extremely unlikely it be not 

require to consider that scenario for safety tests. 

Photos: Zenuity 

In bad weather situation like heavy snowfall, a self-driving car must 

recognize that it radar [top], camera [bottom], and other sensor could be impaired, and 

adjust it drive strategy accordingly. 

Snow-Day Safety: 

Creating Driving Tests for Self-Driving Cars - IEEE Spectrum https://spectrum.ieee.org/transportation/self-driving/creating-driving-test... 

2 sur 8 10-04-18 à 08:50 



Any potential for unsafe behavior 

—software bugs, hardware failures, 

sensor limitations, unexpected weather 

conditions—must be show to be very 

rare. Our rule of thumb be that any one 

of these problem should occur less 

than once in a billion hour of 

operation. At that low failure rate, all of 

these potential cause consider 

together still produce a vehicle that be 

not only safe but can be make available 

without take too long to test. 

However, we shouldn’t expect the car 

to solve a problem that even the very 

best human driver could not solve. One 

such problem, often trot out by 

ethic professor and the media, be 

. In this 

hypothetical scenario, someone must 

choose between do nothing and 

allow a runaway trolley to kill 

several people on one track, or actively 

throw a switch, allow the trolley 

to kill one person on another track. The 

parallel to self-driving vehicle be 

clear. What if a vehicle wind up in a 

situation where it must choose between kill several pedestrian or swerve into a barricade and kill it 

own driver? 

the 

trolley dilemma 

(https://www.theatlantic.com 

/technology/archive/2015/10/trolley- 

problem-history-psychology-morality- 

driverless-cars/409732/) 

But this question be a red herring. Given that the risk of end up in any fatal accident be low, then the risk of 

end up in a situation where a choice must be make between two be even lower. All we can demand of self- 

drive car be that they should avoid such impossible choice to begin with. 

what appear to be a safe automate vehicle, we be oblige to prove it safe. One way be 

through a brute-force method. Here, the vehicle be test in real traffic until we can say, with statistical 

significance, that it’s safe—and that would take hundred of million or even billion of hour on the road. 

The first automobile be test in this fashion, even if the people who drove those car be unwitting 

participant in the experiment. 

Once we have 

Creating Driving Tests for Self-Driving Cars - IEEE Spectrum https://spectrum.ieee.org/transportation/self-driving/creating-driving-test... 

3 sur 8 10-04-18 à 08:50 



A Crash Course 
In Self-Driving 
Vehicle Safety 
Tests 

Test “drivers” be place in a 

vehicle they believe be 

autonomous to see how they 

react to be in a self-driving car. 

In reality, a driver hidden in the 

backseat be steer the vehicle. 

There be some situation you 

just can’t test in real life, like a 

deer jumping in front of the 

vehicle. For these situations, the 

best option be to run computer 

simulation to see how the 

vehicle behaves. 

Zenuity be test vehicle on 

Sweden’s AstaZero test track. 

The massive track provide 

multiple settings, include 

simulated residential areas, 

highways, and forest areas. 

It’s also possible to use a divide-and-conquer approach. Rather than ask 

a complex question, such a whether the vehicle’s sensor can spot 

a deer cross the road during a blizzard, it’s easy to ask simpler 

questions, such a whether the car can tell when it sensor be block 

by snow, or when hardware have fail due to cold temperatures. To that 

you could add the question, “If yes, can the vehicle adjust it decision 

make accordingly?” We can then tackle each of these small 

question with whichever verification method be best suit to answer it, 

whether that’s a computer simulation, a quick spin on a test track, or 

put the car in a real traffic situation. 

In reality, any practical approach will fall somewhere between brute- 

force test and the divide-and-conquer mode. Because technology 

develops in fast iterations, it would be wise to emphasize divide and 

conquer. For example, whenever the hardware or software be changed, 

any data collect by a brute-force approach may no longer be valid. 

Divide and conquer directs u to focus on retesting the safety of only the 

system that be updated, while avoid a time-consuming 

regathering of data we already have. 

To tackle divide-and-conquer situations, we divide a self-driving 

vehicle’s system into four components—the human-machine interface, 

perception, decision making, and vehicle control. The human-machine 

interface have to do with the way the vehicle and it user interact. 

Perception be how the vehicle’s sensor create a view of it 

surroundings, decision make plan how the vehicle should respond to 

that view, and vehicle control be the plan’s physical execution. Each 

component have it own corner case and method to verify that it will be 

acceptably safe. 

Consider the user interface in a car that drive itself most of the time 

but still require occasional human intervention. Even then, a user may 

impair the vehicle’s performance by try to take control of the vehicle 

unexpectedly. To find out how people react, we simulate autonomy by 

hiding a professional driver in the back of the vehicle, thus give 

the impression that the vehicle be drive itself, most of the time. We 

call it the “Wizard of Oz” vehicle, because like the famous wizard in the 

movie, we use misdirection to draw attention away from the “man 

behind the curtain,” a the wizard describes himself. 

Creating Driving Tests for Self-Driving Cars - IEEE Spectrum https://spectrum.ieee.org/transportation/self-driving/creating-driving-test... 

4 sur 8 10-04-18 à 08:50 



Illustration: Jude Buffum 

When a test 

track just 

isn’t real 

enough, 

vehicle can be test in real 

traffic situations, whether 

that mean manually drive the 

car to gather sensor data or 

see how the car handle on it 

own, with supervision. 

To understand what the car 

“sees,” the camera can be 

test by show them 

prerecord footage, or by 

log what they pick up during 

a manual drive. 

Placing the car’s radar or 

camera in snowy or wet test 

condition test whether the car’s 

“brain” can detect when the 

sensor themselves be 

obstructed. 

It’s not an elaborate ruse—we hide the actual driver behind some 

plywood. Perhaps surprisingly, the test subject rarely question the 

backseat enclosure. When one of them do ask, we explain it away a a 

space to hold computer or other equipment necessary for the 

prototype. Satisfied, our test subject can sit back and experience a 

“true” self-driving car. In fact, they become so comfortable they often 

get bore or even fall asleep—revealing that we can’t always rely on 

driver to react quickly if car need them to take over in a 

tricky situation. 

Images: Zenuity 

It’s too dangerous to test some scenarios, like a pedestrian 

step out in front of a self-driving car in motion, so those kind of tricky “corner cases” 

be conduct in simulation to find out how the car responds. 

Self-Driving Simulations: 

In time, a human supervision of the vehicle decreases, the big 

challenge becomes show that the vehicle can safely drive— 

unsupervised—in any situation it may encounter. That mean put 

trust in the vehicle’s sensor after perform standalone sensor tests. 

We can test cameras, for example, in real drive conditions, but it’s just 

a easy to point the camera at a screen display an augment image 

of a real road. It’s tough to test whether a camera could detect a moose 

on the road in the real world—getting the moose to cooperate would be 

tricky—but we can test how well the camera see the moose by 

augment actual road footage with an image of a moose at whatever 

distance and angle we need. In contrast, when we test the radar, we 

place the radar in a room where we can partially or entirely cover the 

radar with water or snow and test whether it recognizes the blockage. 

Of course, we also test how these sensor work together in the actual 

vehicle. We can operate the vehicle in a self-driving mode to observe 

how well it gather and us the sensor data. We’re primarily concerned 

with understand how well the vehicle’s sensor function, so we also 

collect sensor data during manual drive session to see how well the 

vehicle detect it surroundings. These drive test also give u an 

opportunity to determine how well the vehicle detects it own 

limitations—for example, radar work well in fog but 

and 

camera do not. The vehicle must 

recognize those limitation and adjust 

accordingly. 

lidar (/cars-that- 

think/transportation/self-driving/tetravue-says-its-lidar-will- 

dominate-the-robocar-business) 

Then come perception. In general, the 

best way to test how well sensor 

perform this job be by place real vehicle in real traffic conditions, in both good and bad weather. For less 

common corner cases, such a detect debris on the road, the real traffic experience be supplement 

with test-track scenarios. 

Creating Driving Tests for Self-Driving Cars - IEEE Spectrum https://spectrum.ieee.org/transportation/self-driving/creating-driving-test... 

5 sur 8 10-04-18 à 08:50 



We conduct our scenario test at the 

, a large 

test track partially own by the 

Research Institutes of Sweden. The test 

track extends through wooded area 

and a section simulate a town. 

AstaZero can be configure to tackle 

virtually any traffic condition we 

would be interested in testing. 

AstaZero Proving Ground 

(http://www.astazero.com/) 

We supplement such traffic test 

with increasingly sophisticated virtual 

simulations. At the same time, 

augment imagery could assist in 

test some corner cases. Using 

augment reality, for example, we can 

test how well a vehicle obeys U.S. 

traffic sign use a road in Sweden; all 

we have to do be superimpose those 

sign over the Swedish ones. This 

approach can be even more helpful in 

test dangerous corner case like 

drive near pedestrian at high speed. 

Decision make must be evaluate 

separately from perception. That is, 

rather than test whether the vehicle 

see the world properly, we judge 

how well it work with the uncertain 

and incomplete picture that the 

perception system provide it. For 

example, a blind corner could be hiding a pedestrian, who’s liable to step into the road just a the vehicle 

approaches. 

must perceive that obstruct sight line and take that limitation into consideration 

by planning to slow down when it approach the corner. Like any human driver, the vehicle must know it 

own limitations. 

The decision-making system (/cars-that-think/transportation/self-driving/nvidia-or-nxpwhose- 

robocar-brain-will-win) 

Creating Driving Tests for Self-Driving Cars - IEEE Spectrum https://spectrum.ieee.org/transportation/self-driving/creating-driving-test... 

6 sur 8 10-04-18 à 08:50 



We’re also building and continuously expand an immense database of scenario to test the decision- 

make system against any scenario we choose. Consider a self-driving vehicle in a lane adjacent to a large 

18-wheeler travel slightly behind it. Ideally, the vehicle will recognize that it be drive in the truck’s blind 

spot and adjust it position to decrease the chance of an accident. Our database of scenario can expose the 

vehicle’s decision-making process to any variety of scenario involve lane changes, merges, or other traffic 

condition with different speeds, positions, and distance between vehicle to observe what decision the 

vehicle makes. Currently, our vehicle can handle lane change quite well, though we still require them to 

keep a great distance from the vehicle around them than a human driver would need. 

Images: Zenuity 

Ensuring that a self-driving car can recognize object like a stall car 

or a moose cross the road be tough if you don’t have one lie around, but real footage 

can be augment with image of these object to train the car to spot them. 

Now You See It: 

Last but not least, the car must be able 

to execute it drive plan. We need to 

know how the vehicle’s normal capacity 

to steer and to brake might be limited 

by condition on the road, such a ice. 

We can rely, in part, on computer 

simulations, thanks to accurate model 

of vehicle components. But we can’t 

model everything; to test how the car 

handle a tire blowout or an 

unexpected pothole, we have to put it 

on the test track. 

We’ve spent quite some time on the 

test track tackle the diverse 

challenge of on-road objects. Even 

small things, such a a rock or an 

exhaust pipe that’s suddenly fall off 

another car, can damage a vehicle if it’s 

go fast enough. For all of these 

objects, we need to be sure the vehicle 

can detect them from far enough away 

to brake or change lane in time. Our 

test be ongoing; while we’ve gotten 

good result for some obstructions, 

others pose specific challenges. Tires in 

the road, for example, aren’t picked up 

by lidar or radar very well. For the 

vehicle to react to them in time, we still 

need to improve it ability to detect 

them with cameras. 

Creating Driving Tests for Self-Driving Cars - IEEE Spectrum https://spectrum.ieee.org/transportation/self-driving/creating-driving-test... 

7 sur 8 10-04-18 à 08:50 



Using a divide-and-conquer approach give u the ability to test how the system component work together. 

To verify the complete system mean run countless simulation of various combination of traffic 

situation and introduce failures. 

Of course, other company be tackle this problem in different ways. In our experience, older, big 

company be rely on brute-force methods. However, we see value in be modular and swap out 

hardware a needed. We also want to keep the driver involve and learn how to build an autonomous vehicle 

that be safe for users. 

We can use these method to test the redundancy of a fully self-driving vehicle. Suppose the vehicle’s brake 

fail. The vehicle must carry out a complex sequence of actions: It have to detect the problem, plan maneuver 

to react with a minimum amount of risk, and carry out that plan use a secondary system. Similar 

redundancy must be include for component like sensors, control units, software, communication 

systems, and the mechanical systems, and they must all be test thoroughly. 

Even after all that, we need to verify that the complete system in the real vehicle in real traffic operates safely. 

Car manufacturer and self-driving vehicle startup will deploy test fleet and driver for this final step. 

Self-driving vehicle be on the way, and they will make road safer and more efficient. But don’t expect to 

see them on street soon. It will still take a while to verify every corner case. Once a vehicle have be verify 

for a specific scenario, like downtown New York City in July, it will take additional verification to ensure it 

can handle the same area under winter conditions, a well a in downtown Shanghai, on country roads, and 

so forth. 

By focus on the acceptable rather than obsess over perfection, and by break down the colossal 

number of safety verification into manageable tasks, we can make self-driving vehicle a reality for many 

customer around the world. 

This article appear in the March 2018 print issue a “Driving Tests for Self-Driving Cars.” 

be the 

technical lead for functional safety in autonomous drive at , in Göteborg, 

Sweden. be technology advisor at Zenuity. 

Jonas Nilsson (https://www.media.volvocars.com/global/en-gb/media/photos/158384/jonas-nilsson) 

Zenuity (https://www.zenuity.com/) 

Erik Coelingh (https://se.linkedin.com/in/coelingh) 

Creating Driving Tests for Self-Driving Cars - IEEE Spectrum https://spectrum.ieee.org/transportation/self-driving/creating-driving-test... 

8 sur 8 10-04-18 à 08:50 


