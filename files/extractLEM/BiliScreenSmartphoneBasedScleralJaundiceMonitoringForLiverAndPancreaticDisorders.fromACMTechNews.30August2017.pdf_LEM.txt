




















































BiliScreen: Smartphone-Based Scleral Jaundice Monitoring for Liver and Pancreatic Disorders 


20 

BiliScreen: Smartphone-Based Scleral Jaundice Monitoring for Liver 
and Pancreatic Disorders 

ALEXMARIAKAKIS,MEGANA. BANKS, LAURENPHILLIPI, LEI YU, JAMES TAYLOR, and SHWE- 
TAK N. PATEL, University of Washington 

Pancreatic cancer have one of the bad survival rate amongst all form of cancer because it symptom manifest late into 
the progression of the disease. One of those symptom be jaundice, the yellow discoloration of the skin and sclera due to the 
buildup of bilirubin in the blood. Jaundice be only recognizable to the naked eye in severe stages, but a ubiquitous test use 
computer vision and machine learn can detect milder form of jaundice. We propose BiliScreen, a smartphone app that 
capture picture of the eye and produce an estimate of a person’s bilirubin level, even at level normally undetectable by the 
human eye. We test two low-cost accessory that reduce the effect of external lighting: (1) a 3D-printed box that control the 
eyes’ exposure to light and (2) paper glass with color square for calibration. In a 70-person clinical study, we found that 
BiliScreen with the box achieves a Pearson correlation coefficient of 0.89 and a mean error of -0.09 ± 2.76 mg/dl in predict 
a person’s bilirubin level. As a screen tool, BiliScreen identifies case of concern with a sensitivity of 89.7% and a specificity 
of 96.8% with the box accessory. 

CCS Concepts: • Human-centered computing→ Smartphones; • Applied computing→ Consumer health; 

Additional Key Words and Phrases: Health sensing; smartphones; jaundice; bilirubin; image processing 

ACM Reference format: 
Alex Mariakakis, Megan A. Banks, Lauren Phillipi, Lei Yu, James Taylor, and Shwetak N. Patel. 2017. BiliScreen: Smartphone- 
Based Scleral Jaundice Monitoring for Liver and Pancreatic Disorders. Proc. ACM Interact. Mob. Wearable Ubiquitous Technol. 
1, 2, Article 20 (May 2017), 26 pages. 
https://doi.org/10.1145/3090085 

1 INTRODUCTION 
Among all form of cancer, Pancreatic cancer have one of the bad survival rate [2]. Many attribute this statistic 
to the fact that the symptom associate with pancreatic cancer often go unnoticed until the cancer be in a late 
stage; 80-85% of patient present themselves with tumor so advanced that they cannot be remove completely 
through surgery [5, 34]. One of the early symptom to appear be jaundice, a yellow discoloration of the skin 
and eyes. In the case of pancreatic cancer, jaundice occurs because a cancerous growth obstructs the common bile 
duct, cause a buildup of bilirubin in the blood [11]. Being able to detect the very first sign of jaundice when 
level of bilirubin be minimally elevate could enable an entirely new screen program for at-risk individuals. 
Jaundice also manifest a a symptom for a variety of other conditions, such a hepatitis and Gilbert’s syndrome, 
but we be primarily motivate by the link between jaundice and pancreatic cancer for the purpose of this paper. 

This work be support by the National Science Foundation Graduate Research Fellowship Program and the Coulter Foundation. Author’s 
addresses: A. Mariakakis and M. A. Banks and S. N. Patel, Computer Science and Engineering Department, University of Washington; L. 
Phillipi and L. Yu, University of Washington Medical Center; J. Taylor, Department of Pediatrics, University of Washington. 
Permission to make digital or hard copy of all or part of this work for personal or classroom use be grant without fee provide that 
copy be not make or distribute for profit or commercial advantage and that copy bear this notice and the full citation on the first 
page. Copyrights for component of this work own by others than ACM must be honored. Abstracting with credit be permitted. To copy 
otherwise, or republish, to post on server or to redistribute to lists, require prior specific permission and/or a fee. Request permission from 
permissions@acm.org. 
© 2017 Association for Computing Machinery. 
2474-9567/2017/5-ART20 $15.00 
https://doi.org/10.1145/3090085 

Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 2, Article 20. Publication date: May 2017. 

https://doi.org/10.1145/3090085 
https://doi.org/10.1145/3090085 


20:2 • Mariakakis et al. 

The clinical gold standard for measure bilirubin be through a blood draw call a total serum bilirubin (TSB). 
TSBs be invasive, require access to a healthcare professional, and be inconvenient if do routinely for screening. 
Medical device manufacturer have investigate non-contact alternative to a TSB for bilirubin. One such device 
be the transcutaneous bilirubinometer (TcB). A TcB shine a wavelength of light that be specifically reflect 
by bilirubin onto the skin and measure the intensity that be reflect back to the device. The computation 
underlie TcBs be design for newborns; their result simply do not translate correctly for adults. Part of 
the reason for this be that normal concentration of bilirubin be much low in adult compare to newborn 
(<1.3 mg/dl vs. <15.0 mg/dl [4]). As it so happens, the sclerae be more sensitive than the skin to change 
in bilirubin because their elastin have a high affinity for bilirubin [22]. This present an opportunity for early, 
non-invasive screen that have be previously unexplored. Our contribution to this space be BiliScreen, a system 
that estimate the extent of jaundice in a person’s eye through picture take from the smartphone and produce 
an estimate of their bilirubin level. 
To be effective, BiliScreen should be sensitive enough to measure the range of bilirubin level exhibit by 

adults. Ruiz et al. [31] found that jaundice be not apparent to the train naked eye until roughly 3.0 mg/dl; 
however, bilirubin level great than 1.3 mg/dl warrant clinical concern. There exists a detection gap between 1.3 
and 3.0 mg/dl that be miss by clinician unless a TSB be requested, which be rarely do without due cause. We 
hypothesize that diagnosis can be make much early and lead to good outcome with a system that be precise 
enough to distinguish between bilirubin level within and outside of those bounds. 
Oftentimes, the trend of a person’s bilirubin level over time be far more informative than just a single point 

measurement. If a person’s bilirubin exceeds normal level for one measurement but then return to normal 
levels, it could be attribute to normal variation. If, however, a person’s bilirubin show an upward trend after it 
exceeds normal levels, it be more likely that a pathologic issue be worsen their condition, such a a cancerous 
obstruction around the common bile duct. Trends be not only important for diagnosis, but also for determine 
the effectiveness of treatment. One course of action for those affected by pancreatic cancer be the insertion of a 
stent in the common bile duct. The stent open the duct so that compound like bilirubin can be broken down 
again; a person’s bilirubin level should decrease thereafter. If their bilirubin continue to rise, then there be either 
issue with the stent or the treatment be ineffective. Trends in bilirubin level be difficult to capture because 
repeat blood draw can be uncomfortable and inconvenient for many people, especially those in an outpatient 
setting. BiliScreen take advantage of the ubiquity of smartphones, dramatically reduce the effort require to 
perform these measurements. 
BiliScreen us the smartphone’s built-in camera to collect picture of a person’s eyes. The sclera, or white 

part of the eyes, be extract from the image use computer vision. Features describe the color of the sclera 
be then produce and analyze by a regression model to return a bilirubin estimate. Since different light 
condition can change the color of the same scene, we evaluate two accessory that account for the ambient 
light conditions. The first accessory be a head-worn box (Fig. 1, top-left), similar to a head-mounted VR display, 
that simultaneously block out ambient light and provide control internal light through the camera’s 
flash. The second accessory be a pair of paper glass print with color square that facilitate calibration 
(Fig. 1, bottom-left). The latter accessory be reminiscent of a previous project call BiliCam [10] by some of the 
co-authors of this work, which us a color-calibration card to account for ambient light condition in picture 
of newborn that be process to detect neonatal jaundice. Beyond their intent of assess bilirubin level by 
detect jaundice through the smartphone camera, the two project be quite different. BiliCam be intend for 
newborns, who exhibit a far wider range of normal bilirubin level than adults. Because the sclera do not have 
a predefined shape, BiliScreen also require an additional step of segmentation. Although BiliScreen have tighter 
precision requirements, it benefit from the fact that the typical sclera be race-agnostic; the same cannot be say 
for skin, which varies across different ethnicities. 

Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 2, Article 20. Publication date: May 2017. 



BiliScreen: Smartphone-Based Scleral Jaundice Monitoring for Liver and Pancreatic Disorders • 20:3 

Fig. 1. BiliScreen be a system that measure a person’s bilirubin level use the smartphone’s camera. We examine two 
method for color normalization: (top-left) a box similar to a head-mounted VR display that control the amount of light 
that reach the eyes, and (bottom-left) paper glass that provide color square for calibration. 

We evaluate BiliScreen in a 70-person preliminary study include individual with normal, borderline, and 
elevate bilirubin levels. We found that BiliScreen with the box accessory, which lead to good result than the 
glasses, estimate an individual’s bilirubin level with a Pearson correlation coefficient of 0.89 and a mean error of 
-0.09 ± 2.76 mg/dl when compare to a TSB. BiliScreen with the glass accessory lead to a Pearson correlation 
coefficient of 0.78 and a mean error of 0.15 ± 3.55 mg/dl. 

Our contribution come in four parts: 
(1) An implementation of the BiliScreen system for convenient bilirubin test with two different method 

for color calibration, 
(2) A novel sclera segmentation algorithm that be robust for individual with jaundice, 
(3) Models that relate the color of the sclera to a measure of bilirubin in the blood, and 
(4) An evaluation of BiliScreen on 70 participants. 

2 RELATED WORK 
The BiliScreen algorithm have two fundamental components: automatic segmentation of the sclera and model 
that map sclera color to bilirubin level. We summarize the literature related to both component below. We then 
provide a brief overview of other smartphone apps dedicate to diagnose condition through the eye. 

2.1 Sclera Imaging 
To our knowledge, BiliScreen be the first application that automatically segment the sclera for medical purposes. 
There is, however, a body of literature that have propose various method of segment the sclera for biometric 
verification and gaze estimation. For biometrics, individual be recognize through the uniqueness of the blood 
vessel pattern in their sclera. For gaze estimation, researcher have rely on the fact that the expose area of 
sclera change a a person make significant change in gaze. 

The most common method for sclera segmentation relies strictly on color information, note that the sclera 
be normally white. Zhou et al. [38] use dynamic threshold in the RGB and HSV color space to create binary 

Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 2, Article 20. Publication date: May 2017. 



20:4 • Mariakakis et al. 

mask that correspond to non-skin- and sclera-colored pixels, respectively. After take the intersection of those 
masks, the iris and pupil be remove by use a visible glint within the iris a a seed for an iterative method 
that move radially until it reach the iris-sclera border. Marcon et al. [23] train a linear discriminant analysis 
classifier on pixel color value to distinguish between sclera and non-sclera pixels. Morphological operation and 
watershed flood be apply to form fuller candidate region for the sclera, after which a classifier train on 
shape information be use to select the region that most resemble the sclera. Das et al. [8] propose a method 
that involves fuzzy k-means cluster on the pixel color and location to form three clusters: the skin, iris, and 
sclera. These strictly color-based method rely on the assumption that the sclera be bright and white, which be 
not the case for people with jaundice. As the sclera becomes more yellow, it color can be confuse with the 
color of lighter skin tones, make it difficult to train a global classifier. Even if the person’s skin tone be know 
beforehand, there be the chance that it color be too similar to the person’s sclera for it to be remove without 
spatial information. 

In a different paper, Das et al. [9] demonstrate a method of sclera segmentation that us active contour-based 
segmentation. In active contour-based segmentation, a snake (i.e., deformable spline) be initialize roughly around 
an object of interest. An energy function be define base on the presence of lines, edges, and corner in the 
image, and the position of the snake be iteratively adjust until that energy function be minimized. For sclera 
segmentation, Das et al. initialize snake to the left and right of the automatically detect pupil. This technique 
be suitable for BiliScreen in that do not depend on the color of the sclera, but the initialization of the snake can 
be difficult when the geometry of the eye be not completely constrained. The location of the sclera relative to the 
pupil depends on both the geometry of the eye and the user’s gaze direction. For instance, depend on the 
narrowness of the eye and how far the user look up, the sclera may or may not appear directly under the iris. If 
the initial snake be too far out from the sclera, they may stop short at glare spot or wrinkle near the eyelid 
a they constrict. More onus could be place on the person whose picture be be take to adjust themselves 
until their pose satisfies specific constraints, but such a procedure could lead to frustration. Instead of rely 
on the location of the pupil, eye detection algorithm [20, 35] could be use to standardize a region of interest 
around the eye; however, such technique fail when nearby facial feature be obstructed, a be the case with the 
BiliScreen accessories. 
One more approach that have be explore for sclera segmentation be the use of dedicate hardware. Cri- 

halmeanu and Ross [7] utilize near-infrared (NIR) light to make sclera segmentation straightforward. They 
observe that the skin have high NIR reflectance than the sclera since the skin have less water, which make the 
separation between the sclera from pale skin more apparent in NIR than in RGB. The use of dedicate hardware 
in BiliScreen beyond the our box or glass accessory be undesirable for cost and accessibility purposes. 
Overall, these issue motivate the need for a more automate solution. The sclera segmentation approach 

we propose for BiliScreen us two iteration of the GrabCut method [30]. The first iteration learns the color 
characteristic of the skin and remove the skin to isolate the eye. The second iteration isolates the sclerae by 
assume that they be the brightest region within the eye (not necessarily white). 

2.2 Jaundice Assessment 
The standard for measure bilirubin in the blood be through a blood draw call a total serum bilirubin (TSB). 
The more convenient alternative use in neonatal clinic be a transcutaneous bilirubinometer (TcB). Beyond 
these two methods, there be several researcher who have investigate bilirubin measurement via the digital 
photography of area susceptible to jaundice: the skin and eyes. 

Leartveravat [18] proposes a completely manual system for assess jaundice in a newborn’s skin. Photographs 
of the skin with a color calibration card be capture use a digital camera. Once the photo be uploaded to image 
edit software (e.g., Adobe Photoshop), the image be color-calibrated and convert to the CYMK color space. A 
technician then manually selects a pixel representative of the newborn’s skin, subtracts it yellow component 

Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 2, Article 20. Publication date: May 2017. 



BiliScreen: Smartphone-Based Scleral Jaundice Monitoring for Liver and Pancreatic Disorders • 20:5 

from it magenta component, and input that value into a linear regression to get a bilirubin estimate. The 
BiliCam system by de Greef et al. [10] also analyzes picture of a newborn’s skin with a color calibration card to 
estimate their bilirubin level. It differs from the work of Leartveravat in that BiliCam entail more complicate 
model that account for skin tone. 

Leung et al. [19] compare the performance that a system could achieve by analyze both the skin and the sclera 
for newborns. Similar to de Greef et al. and Leartveravat, the author manually select region correspond to 
the skin, sclera, and a color calibration card for their analyses. With a fairly modest linear regression model, the 
author achieve far good Pearson and Spearman correlation use the sclera (0.75 and 0.72) than use the skin 
(0.56 and 0.54). 

To the best of our knowledge, BiliScreen be the first non-invasive system to quantify an adult’s bilirubin 
level. BiliScreen analyzes the sclera because, a Leung et al. confirmed, the sclera be more sensitive to change 
in bilirubin than the skin. This be important because high precision be need for adults. Bilirubin level in 
healthy newborn may peak a high a 15.0 mg/dl [4], whereas bilirubin level for healthy adult be normally 
less than 1.3 mg/dl. BiliScreen be also completely automated, from the segmentation of the glass and sclera to 
the feature extraction and machine learning. Finally, BiliScreen benefit from the fact that healthy sclera color 
be independent of ethnicity, so less training data should be need in the long-term. 

2.3 Ocular Diagnostic Applications 
Pamplona et al. have developed several inexpensive attachment for smartphones to diagnose condition of the 
eye. Much like an eye chart, the hardware present stimulus to the user. Rather than converse with a clinician, 
the user interacts with their smartphone depend on what they see; this be an iterative procedure that go 
on until a result be reached. In NETRA [27], refractive error be identify by ask the user to align pattern 
project through a microlens display and pinhole. In CATRA [28], cataract be localize by scan the eye 
with a beam of collimate light and ask the user for feedback about the spread of the beam. EyeMITRA [17], 
be a wearable camera, varies slightly from the other two projects. It be meant for mobile retinal imaging, so 
it do not perform diagnosis on it own. The user be place within the loop of the system by be ask to 
focus on focal point show in the other eye, which in turn focus the camera on the opposite side. Others have 
developed hardware attachment for ocular diagnostics a well. D-Eye1 be a smartphone adapter for perform 
fundoscopy. Bastawrous et al. [3] and Giardini et al. [12] propose a number of attachment for diagnose visual 
acuity and glaucoma. Finally, Abdolvahabi et al. [1] discus the possibility for digital photography to catch the 
early onset of rare eye cancer in newborns; they found that if the common “red-eye” effect in the pupil be 
replace with a milky white color, it could indicate tumor in the back of the eye. 

3 DATA COLLECTION 
We collect image use the BiliScreen app with both the box and glass accessory to train BiliScreen’s 
model and evaluate their efficacy. Volunteers with normal bilirubin level be recruit from the University of 
Washington. Volunteers with vary bilirubin level (ranging from normal to elevated) be recruit from the 
University of Washington Medical Center. Below, we elaborate on the diversity of the participant pool. We then 
describe our data collection procedure, include the design of the BiliScreen accessory and our procedure for 
ground truth measurements. All facet of our study be approve by the University of Washington’s Institutional 
Review Board. 

Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 2, Article 20. Publication date: May 2017. 



20:6 • Mariakakis et al. 

Table 1. Participant demographic (N = 70) 

BILIRUBIN CLASSIFICATIONS - N (mean ± std) 
Normal (<1.3 mg/dl) 31 (0.6 ± 0.2 mg/dl) 
Borderline (1.3-3.0 mg/dl) 14 (2.1 ± 0.5 mg/dl) 
Elevated (>3.0 mg/dl) 25 (9.7 ± 5.9 mg/dl) 

3.1 Enrollment 
Our study include 70 volunteers. From the university, 18 be male and 13 be female. From the medical center, 
13 be male and 26 be female. Table 1 show the distribution of the total serum bilirubin test split across the 
two different populations. Note that the precision of the TSB be 0.1 mg/dl. 

Thresholds classify the concern warrant by a single bilirubin measurement can vary between clinics. For 
the purpose of BiliScreen, three class be defined: normal (<1.3 mg/dl), borderline (1.3-3.0 mg/dl), and elevate 
(>3.0 mg/dl). The 1.3 mg/dl threshold be use by the University of Washington Medical Center a their upper 
limit for a normal TSB measurement, while the 3.0 mg/dl threshold be base on the finding of Ruiz et al. [31] 
concern when jaundice be most apparent to clinicians. According to these thresholds, 31 participant have a 
normal bilirubin level, 14 have a borderline bilirubin level, and 25 have an elevate bilirubin level. Unsurprisingly, 
most of the university population have a normal bilirubin level. The lack of variation within that population be 
expected. Although the clinical upper threshold for normal bilirubin level be 1.3 mg/dl, value near 0.6 mg/dl be 
the norm. The medical center population provide a much wider spread of bilirubin levels, range from normal 
to elevated. 

3.2 Data Collection Procedure 
The data collection procedure for the BiliScreen app be the same for both populations, but the method of 
recruitment and collection of ground truth measurement be different. The participant from the university 
be volunteer recruit from email on public mail lists. After a research staff member collect data with 
the BiliScreen app (described in the next section), they be ask to undergo a TSB within 24 hours. Bilirubin 
can change over long period of time but remains stable within a day bar any serious conditions. 

The participant from the medical center be inpatient suffer from liver disease. A research staff member 
select candidate participant on two criteria. The first criterion be a record TSB blood test within 24 hours. 
Again, this be to ensure that the patient’s record bilirubin level match closely with their level at the time 
of data collection. The second criterion relies on the Model for End-stage Liver Disease (MELD) [36], a score 
system for assess the severity of chronic liver disease. The MELD score be a summary metric that combine 
three measure of a patient’s liver condition - TSB, serum creatinine, and the international normalize ratio 
for prothrombin time (INR) - with a high score indicate a high three-month mortality rate. There be no 
guarantee that a patient with a high MELD score have an elevate bilirubin level since TSB be only one component 
of the MELD score; however, a high MELD usually include an elevate TSB. The original recruitment criterion 
be a minimum MELD score of 14. This threshold be late lower to 6 in order to recruit more patient 
with borderline level (1.3-3.0 mg/dl) of bilirubin. If a patient satisfied the two recruitment criteria, they be 
approach by a research staff member and told about the study. Patients be enrol in the study if and only 
if they understood the study and give consent. 

Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 2, Article 20. Publication date: May 2017. 



BiliScreen: Smartphone-Based Scleral Jaundice Monitoring for Liver and Pancreatic Disorders • 20:7 

Fig. 2. (top) A 3D render of the BiliScreen box. The smartphone’s flash lie in the horizontal center of the box. The flash 
be cover with a neutral density filter and a diffuser to make the light more comfortable. (bottom) A render of the 
BiliScreen glasses. 

3.3 BiliScreen Accessories 
Physics-based model for color information typically consider an object’s visible color to be the combination 
of two components: a body reflection component, which describes the object’s color, and a surface reflection 
component, which describes the incident illuminant [15]. When use digital photography, color information 
that get store in image file be also impact by the camera sensor’s response to different wavelengths. For our 
study, we examine the efficacy of two different accessory to isolate the sclera’s body reflection component in 
different way (Fig. 2). 
The first accessory be a 3D-printed box reminiscent of a Google Cardboard headset2. There be no electrical 

connection between the phone and the box; the phone be simply slid into the box via a rectangular channel along 
the back. The channel at the back of the box also fix the placement of the phone relative to the participant’s face 
by center the phone’s camera and keep it at a fix distance. The box block out ambient light while 
allow the phone’s flash to provide the only illumination onto the eyes. From pilot studies, some participant 
found the flash to be overwhelmingly bright. A neutral density filter and a diffuser be place in front of the 
flash use a filter holder to soften the light slightly. The box use in our study be 3D-printed, but it could be 
make with an even cheaper material like cardboard (provided that it be sturdy enough to support the weight of 
the phone). By use the flash a the only illumination source on the sclera, the surface reflection component be 
kept constant for all images. This leaf the body reflection component and the camera sensor’s response a the 
only two component that affect the sclera’s appearance. For the sake of this study, all image be capture 
use the same device, hold the camera sensor’s response constant and leave the body reflection component 
a the only variable left. 

The second accessory (Fig. 2, bottom) be a custom pair of paper glasses, reminiscent of the 3D glass found at 
movie theaters. The glass have no lens inside their frames. Along the rim of the glass be various color 

1https://www.d-eyecare.com/ 
2https://vr.google.com/cardboard/ 

Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 2, Article 20. Publication date: May 2017. 

https://www.d-eyecare.com/ 


20:8 • Mariakakis et al. 

regions. The corner near the temple and the nose have small black square surround by the glasses’ white 
background. These square act a fiducials, similar to those see in QR codes. The rest of the region along the 
rim be the follow color (in no particular order): cyan, magenta, yellow, 17% gray, 33% gray, 50% gray, 67% 
gray, 83% gray, and black. The use of the color square be inspire by color calibration target card like the 
Macbeth ColorChecker [29]. Rather than keep the surface reflection component and the camera sensor’s 
response constant, the color square allow for all image to be normalize to the same references. The color 
along the rim of the glass be know a priori. This mean that their body reflection component be know and 
any deviation between their appearance and their true color be due to the surface reflection component and the 
camera sensor’s response. Section 4.3 explains the calibration procedure that be use to define a calibration matrix 
that best simulates the effect of the latter two color information components, which can late be apply to the 
sclerae themselves to reveal their true body reflection components. 

From a usability perspective, the glass be more convenient for the user and cheaper to manufacture. However, 
the color along the rim of the glass must always be consistent, both across time and different pairs. If the 
color be to fade over time, the color would become a change reference that could lead to inaccurate 
results. Although the box be bulkier, it requirement be far looser. The box’s main purpose be to block out 
ambient lighting; control over the precise placement of the smartphone be convenient for aspect of the automatic 
segmentation, but the box’s dimension do not require a strict precision a the glasses’ colors. 

From a technical perspective, the color calibration procedure for the glass can incur it own inaccuracies. In 
BiliScreen’s current state, though, the algorithm for the box accessory do not account for the camera sensor’s 
response. If user be to use a phone with a camera different from that of the iPhone SE, we can make no 
guarantee that color will appear the same between the two. Section 6.1 discus way for address this 
limitation. Even though the color calibration procedure for the glass may introduce noise, it allows for any 
device to be use without issue. The calibration procedure capture the effect of both the surface reflection 
component and the camera sensor’s response. 

3.4 BiliScreen Application 
All data be collect by a research staff member through a custom app on an iPhone SE. The image collect 
by the app be at a resolution of 1920×1080. The research staff member ensure that participant comply with 
the procedure and note any difficulty that participant have with the app and it accessories. 
The BiliScreen app developed for our study be design to collect data for both accessory in a similar 

manner. Before the use of either accessory, the smartphone’s flash be turn on. When use the box, the flash 
be necessary since it be the only way to make the eye visible within it. Keeping the flash constantly on rather 
than bursting it at the time of the picture be a consideration for participant comfort since the stark change in 
light can be unpleasant. When use the glasses, the flash be left on in case there be insufficient light in 
the room or the glass create a shadow on the participant’s face. 

After the flash be turn on, the research staff member place the smartphone in the BiliScreen box. A hole 
in the back of the box provide access to the screen for start and stop data collection. The app prompt 
the participant to look in four different direction - up, left, right, and straight ahead - one at a time while take 
a picture after each. Having the participant look in different direction expose different part of the sclera, 
some of which may have exhibit more jaundice than others. The participant be not ask to look downward 
since do so cover their eye with their eyelids. Once the picture be take inside the box, the research 
staff member remove the smartphone and held it approximately 0.5 m away from the participant’s face to take 
picture with the glasses. This distance be roughly how far away we would expect participant to hold their 
smartphones if they be take a selfie. The participant look at each direction for two trial per accessory, 
yield 2 BiliScreen accessory × 2 trial per accessory × 4 gaze direction per trial = 16 image per participant. 

Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 2, Article 20. Publication date: May 2017. 



BiliScreen: Smartphone-Based Scleral Jaundice Monitoring for Liver and Pancreatic Disorders • 20:9 

4 BILISCREEN ALGORITHM 

Fig. 3. The algorithm pipeline for both BiliScreen accessories. Images from both the box and the glass go through the same 
sclera segmentation, feature extraction, and machine learn step (with their own respective model and small parameter 
changes). Images gather with the glass must go through the extra step of glass segmentation and color calibration. 

Fig. 3 outline the high-level algorithm pipeline that transforms a BiliScreen image to a bilirubin estimate. We 
will provide further detail in this section on each of these steps, start with the segmentation of various region 
of interest, the transformation of those region into feature vectors, and finally the machine learn itself. 

4.1 Sclera Segmentation 
The first step to segment the sclera from BiliScreen image be to define region of interest where the sclera 
should be located. One way to logically identify these region would be to use Haar feature-based cascade 
classifier [20, 35] that be use in many application that require eye detection. However, off-the-shelf eye 
detector sometimes fail because feature around the eye (e.g., eyebrows) be obstruct by the BiliScreen 
box and glasses. To maintain consistency across images, region of interest be define through other method 
depend on the BiliScreen accessory in use. Within the BiliScreen box, the region of interest be define a 
rectangular bound box locate on the left and right half side of the box use predetermine pixel offset 
within the image. This be possible because the placement of the camera within the box be always the same. The 
offset be define such that the region of interest would cover various face placement and inter-pupillary 
distances. For the BiliScreen glasses, the region of interest be more precisely define a the region surround 
by the color square (refer to Section 4.2 for how those square be identified). 
Our approach to sclera segmentation relies on an algorithm call GrabCut [30], a technique for separate 

a foreground object from it background; the term “foreground” and “background” do not necessarily refer 
to the perceivable foreground and background of the image, but rather a region of interest versus everything 
else in the image. GrabCut treat the pixel of an image a node in a graph. The node be connect by edge 
that be weight accord to the pixels’ spatial and chromatic similarity. Nodes in the graph be assign 
one of four labels: definitely foreground, definitely background, possibly foreground, and possibly background. 
After initialization, graph cut [6, 13] be apply to re-assign node label such that the energy of the graph be 
minimized. Normally, GrabCut be an interactive technique that be typically initialize with a bound rectangle 
and then follow with user-drawn stroke that further clarify the object of interest. BiliScreen us GrabCut 
with a similar procedure, but without human intervention. 

Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 2, Article 20. Publication date: May 2017. 



20:10 • Mariakakis et al. 

Fig. 4. The procedure for sclera segmentation. The first iteration of GrabCut be initialize with several translate rectangle 
in parallel. The one that leaf a region that most resembles the eye be use a the region of interest for the second iteration 
of GrabCut. The second iteration of GrabCut us adaptive threshold to select the brightest region within the eye. 

Before segmentation, bilateral filter be apply to smooth local noise while maintain strong edges. For the 
first iteration of segmentation, the eye be extract use GrabCut with rectangle for initialization (Fig. 4, left). 
This not only limit the search space for the sclera, but also remove most of the skin around the eye, reduce 
any effect those pixel could have on color histogram or adaptive threshold late in the algorithm. The location 
of the eye within the image can vary, so rectangular initialization at different location be tested. To determine 
which output be most likely to only contain the eye, the segment region from each initialization be described 
use the calculation list in Table 2. As the second column indicates, some of the metric be meant to be 
minimized, while others be meant to be maximized. Those that be meant to be minimize be negate so that 
high value always imply that the region be more eye-like. The metric be combine use the Mahalanobis 
distance relative to all of the other segment regions. Overall, this calculation result in high distance for 
segment region that be small, elliptical, flat, and diverse in color, a well a rectangular initialization that 
likely do not crop out the eye. The segment region with the high distance win out and be pass along to 
the second part of the sclera segmentation algorithm. 

After the first iteration of GrabCut be applied, the pixel that be assign to the foreground be consider to 
be part of the eye, regardless of whether they be label a “definitely foreground” or “possibly foreground”. A 
second iteration of GrabCut be then use to extract the sclera from the eye (Fig. 4, right). The second iteration of 
GrabCut normally require user interaction. In BiliScreen, however, the GrabCut initialization can be bootstrapped 
automatically use adaptive and pre-defined thresholds. After convert the image to the HSL color space, the 
four possible pixel assignment be initialize a follows: 

• Definitely foreground: Top 90th-percentile of L channel value 
• Definitely background: Bottom 50th-percentile of L channel value 
• Possibly foreground: Otsu threshold [24] on L channel value 
• Possibly background: Inverse Otsu threhsold on L channel value 

Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 2, Article 20. Publication date: May 2017. 



BiliScreen: Smartphone-Based Scleral Jaundice Monitoring for Liver and Pancreatic Disorders • 20:11 

Table 2. Metrics use to rate a result of GrabCut a an eye 

Name Min/Max Description 
Area fraction Min The fraction of the region’s area over the total area of the 

region of interest 
Ellipse area fraction Max The fraction of the region’s area over the area of the 

ellipse that best fit the region 
Incline Min The incline of the ellipse that best fit the region 
Color variation Max The standard deviation of the color across the region 
Variation over border Min The standard deviation of the brightness value across the 

top and bottom border of the rectangle use to initialize 
GrabCut 

In case when a pixel satisfies multiple assignments, the strong assertion be prioritize (i.e., definitely 
foreground over possibly foreground). These assignment be base on the assumption that the brightest region 
in the eye should be the sclera. This assumption fails when glare appear within the eye, which be always the case 
with the BiliScreen box and sometimes the case with the BiliScreen glasses. Glare corresponds to high value in 
the lightness channel of the HSL image (L > 230). Pixels with glare be replace use inpainting, a reconstruction 
process that re-evaluates those pixels’ value via the interpolation of nearby pixels. Once GrabCut be run for the 
second time, the pixel that belong to the “definitely foreground” and “possibly foreground” label be selected. 
The result mask be then clean by a morphological close operation to remove any tiny regions. 

The distance between the smartphone and the person’s face change depend on which BiliScreen accessory 
be in use while the picture be be taken. The smartphone be at a fix distance of 13.5 cm from the person’s 
face when the BiliScreen box be in use and at a variable, farther distance when the BiliScreen glass be in use. 
Changes in distance can have a modest effect on the light because the flash imparts more light on the eye 
when it be closer to the face. However, this effect be constant with the BiliScreen box and be cancel out by 
the color calibration procedure for the BiliScreen glasses. The distance does, however, have a great effect on 
the parameter for segmentation. As the distance between the smartphone and the person’s face increases, the 
effective size of the eye in the image shrinks. The size of the rectangle use to initialize the first iteration of 
GrabCut have fix dimension for the BiliScreen box (∼600 × 200 px) and dynamic dimension accord to the 
size of the frame for the BiliScreen glass (∼90% of width × 60% of height). 

4.2 Glasses Segmentation 
The goal of the glass segmentation be to identify the border of the color square around the rim of the 
glass and the white portion at the bridge of the nose so that their color can be use for calibration. An example 
of correct segmentation be provide in Fig. 5. The process start with identify the fiducials at the corner of the 
glasses. The fiducials be design to be square-shaped, but unless they be view straight on, they can appear 
more a quadrilaterals. Black quadrilateral be found by convert the image to grayscale and filter it so 
that only the contour with four corner and a brightness value less than 60 be kept. The small quadrilateral 
correspond to the fiducials, while the others correspond to the outline of the color square around the rims. 
The fiducials be roughly one-fourth the size of the color squares. Therefore, quadrilateral that be less than 
half of the average quadrilateral area be classify a fiducials; the other quadrilateral be classify a color 
squares. To confirm that the fiducials belong to the glass and not something in the background, the algorithm 
check that the pixel immediately outside of their border be white. If any fiducials be not found because of 
glare or some other error, their location be interpolate or extrapolate base on the location of the discover 

Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 2, Article 20. Publication date: May 2017. 



20:12 • Mariakakis et al. 

Fig. 5. An example of correct segmentation for the glasses. The region over the bridge of the nose be use a a white reference 
for both sides. 

Fig. 6. Illustrations show how the position of know fiducials or color square can be use to (left) interpolate or 
(right) extrapolate the position of miss ones. 

fiducials and the know geometry of the glasses. The left side of Fig. 6 show an example of interpolation. When 
there be know fiducials that be along the same vertical and horizontal ax a where the miss fiducial 
should be, the corner of the miss fiducial can be estimate by use the intersection of those lines. The right 
side of Fig. 6 show an example of extrapolation. If there be not enough know fiducials to use interpolation, we 
rely on the know relative dimension of the glass to estimate where they would most likely lie. 
The position of the fiducials be then use to check the position of the color squares. The fiducials be 

connect with straight line to provide guide on which the other square should lie. Any quadrilateral found 
outside of those bound be discard a the background. The fiducials be then use to develop a one-to-one 
mapping between the name of the color square (e.g., left yellow, right 33% gray) and their location in the 
image. In the end, there should be two color square along each side of the lens and black patch at the far 
bottom corners. The location of the large black-bordered quadrilateral be compare to the expect position 
of the color squares. If the distance between a detect quadrilateral and the expect position of a color 
square be less than a quarter of the expect square’s width, the quadrilateral be match with the correspond 
label. There may not be enough detect black-bordered quadrilateral to assign a border to every square label. 
This can be attribute to, among other reasons, glare from the camera or ambient light that obscures black 
outlines. Like the miss fiducials, the miss color square can be found use a combination of interpolation 

Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 2, Article 20. Publication date: May 2017. 



BiliScreen: Smartphone-Based Scleral Jaundice Monitoring for Liver and Pancreatic Disorders • 20:13 

and extrapolation. After the square around the rim of the glass be found, the white rectangle that rest on 
top of the bridge of the nose be select use a specify offset from the rim to provide a white color reference. 

Both interpolation and extrapolation in this algorithm assume that the square be linearly arrange around the 
glasses. The glass be design to make interpolation and extrapolation straightforward, but there be case 
when user have to bend them so that they would fit comfortably on their faces. In these cases, it can be difficult to 
find fiducials and color square when quadrilateral detection have already failed. That be said, the advantage 
of the BiliScreen glass design be that there be square with the same color on each side. It be preferable to 
detect the square on the same side a the eye of interest since they good represent the light shone on that 
particular side, but if one of those square cannot be found, the other side can be use a a contingency. 

4.3 Glasses Color Calibration 
By identify the color square of the glasses, BiliScreen image can be normalize to a common reference. 
Doing so remove the effect of the ambient light and the camera sensor’s response, both of which can change 
the appearance of the sclera. 

The calibration procedure involves identify the calibration matrixC that best map the color of the glasses’ 
square observe in the image to their actual colors. More formally, defineO a the matrix of observe color and 
T a the matrix of target colors, where each row contains an RGB vector that corresponds to a color square. 
The matrix C defines the linear transform such that: 

 

TR1 TG1 TB1 
TR2 TG2 TB2 
... 

... 
... 

TRk TGk TBk 

 

= 

 

OR1 OG1 OB1 
OR2 OG2 OB2 
... 

... 
... 

ORk OGk OBk 

 

 

C11 C12 C13 
C21 C22 C23 
C31 C32 C33 

 
(1) 

Because image file be gamma-encoded to optimize the usage of bits, gamma correction must be apply to 
the observe color from the image so that linear operation on them be also linear. This be do by raise the 
value in O by a constant (γ = 2.2 for standard RGB image files). After a calibration matrix be applied, the gamma 
correction can be reverse by raise the value of the matrix to 1/γ . 
The calibration matrix C be calculate use an iterative least-squares approach detailed by Wolf [37]. The 

calibration matrix be first initialize under the assumption that the individual color channel be uncorrelated and 
only require a gain adjustment that would scale the mean value of the observe channel value to their targets: 

C = 

 

mean(TRi )/mean(ORi ) 0 0 
0 mean(TGi )/mean(OGi ) 0 
0 0 mean(TBi )/mean(OBi ) 

 
(2) 

For each iteration, the current calibration matrix be apply to the observe color to produce calibrate colors. 
The color represent by the row be convert to the CIELAB color space so that they can be compare to 
the target in T use the CIEDE2000 color error [32], the current standard for quantify color difference. A 
new calibration matrix C be compute that reduces the sum of square errors, and the process repeat until 
convergence. 
For BiliScreen, the row of the target color matrix T be define a the expect RGB color vector of the 

glasses’ square accord to their specification. The row of the observe color matrixO be compute by find 
the median vector in the HSL color space of the pixel within the bound of the square found in Section 4.2 
(excluding the fiducials) and convert the vector back to RGB. For a region R with N 3-dimensional colors, the 
median vector be define as: 

Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 2, Article 20. Publication date: May 2017. 



20:14 • Mariakakis et al. 

vm = argmin 
vi ∈R 

N∑ 
j=1 
∥vi −vj ∥2 (3) 

The median vector be prefer over take the mean or median across the channel independently because it 
guarantee that the result be a color that exists within the original image; by treat the channel independently, 
the combination of value in the three channel may not ever appear in the image. The difference between the 
two approach be typically insignificant when the region be uniform (as be the case with the color squares), but 
be a precaution take nonetheless. 
The calibration procedure be repeat for both eye use the color square closest to them. This be do 

because the ambient light effect be not always uniform; there may be a shadow or beam of light that creates 
a gradient across the face, make one side look slightly different from the other. There can also be case when a 
color square be wash out by glare from the smartphone’s flash. If the error between the color square and 
the expect color be 5 unit more than the error between the correspond color square on the opposite side 
and the expect color (color difference be unitless), the latter be used. We never encounter a case when square 
of the same color on opposite side of the face be simultaneously obstructed. If that be the case, however, 
that color could simply be thrown out of the calibration procedure. 

4.4 Feature Extraction 
Jaundice be characterize by yellow discoloration, so the feature extract from BiliScreen’s image should 
summarize the color of pixel belonging to the sclera. The color of the sclera be described use the median vector 
over the pixel that belong to the sclera for the same reason described at the end of Section 4.3. More often 
than not, the sclera contains other component like vessel or a gradient from the eye’s curvature. In these cases, 
aggregate the color channel independently can lead to a color that be not present in the sclera. For example, if 
an otherwise pristine sclera contains many blood vessels, take the mean of the color channel independently 
will represent the color of the sclera a a pinkish color; the median vector will represent it a white assume 
there be more white area than there be red. The median vector be also useful for when sclera segmentation include 
superfluous pixel outside of the sclera. Assuming most pixel belong to the sclera, those pixel do not factor in 
to the final sclera color. 

Table 3. Variations for feature extraction 

PIXEL SELECTION METHODS 
All pixel All pixel 
No glare L ≤ 220 in HSL space 
No glare or vessel L ≤ 220 and H ≥ 15 in HSL space 
No glare or eyelash 5 ≤ L ≤ 220 in HSL space 
No glare, vessels, or eyelash 5 ≤ L ≤ 220 and H ≥ 15 in HSL space 
COLOR SPACES 
RGB, HSL, HSV, L*a*b*, YCrCb 

There be two consideration that must be consider for feature extraction (Table 3). The first be which 
pixel be consider in the calculation. The most obvious answer be to use all the pixel that survive the sclera 
segmentation present in Section 4.1. As mention earlier, though, not all pixel within the boundary of the 
sclera actually represent the color of the sclera. Blood vessel and eyelash can add undesired complication to 
the data. The median vector be meant to alleviate their effects, but a an extra precaution, BiliScreen us the 5 

Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 2, Article 20. Publication date: May 2017. 



BiliScreen: Smartphone-Based Scleral Jaundice Monitoring for Liver and Pancreatic Disorders • 20:15 

different pixel selection method described in Table 3. The threshold for the different method be select 
empirically by examine image with prominent case of glare, vessels, and eyelashes. They be by no mean 
intend to capture all case of non-sclera pixels; in fact, they be kept conservative on purpose to ensure that 
enough pixel remain in the calculation. 
The second consideration for feature extraction be which color space be used. Images be save from the 

smartphone camera in the RGB color space. Converting the image to a different color space be simply a calculation 
across the three channel that express those number in a different way, something that various machine 
learn model and feature transformation technique can learn on their own. Nevertheless, explicitly carry 
out color conversion can rearrange the color data in such a way that few feature be needed. BiliScreen 
computes feature for the 5 different color space list in Table 3. Beyond feature from the various color spaces, 
BiliScreen also computes the pairwise-ratios of the three channel in RGB. The intuition behind these feature be 
that a yellower color will have low blue-to-red and blue-to-green ratios. 
BiliScreen computes color representation of the sclera use every combination of pixel selection method 

and color space. Each color have 3 channels, result in 5 pixel selection method × (5 color space × 3 channel 
per color space + 6 RGB ratios) = 105 feature per eye. Not all of the feature be use in the final model. Some 
pixel selection method across the same region can result in the same pixels, and some channel across color 
space represent the same information in similar manners. Automatic feature selection be use to select the most 
explanatory feature and eliminate redundant ones. The top 5% of the feature that explain the data accord 
to the mutual information score function be use in the final models. Mutual information measure the 
dependency between two random variable [16]. We find that the feature that best explain the data come from 
look at the ratio between the green and blue channel in the RGB color space. A healthy sclera should be 
white, which produce high value across all three color channels. Blue be the opposite of yellow, so a the blue 
value of a white color be reduced, it becomes more yellow. This mean that a high green-to-blue ratio implies a 
more jaundiced sclera. 

4.5 Machine Learning 
Separate model be developed for the two BiliScreen accessory to determine which would yield the good 
accuracy. The model use random forest regression and be train through 10-fold cross-validation across 
participants. Note from Table 1 that the distribution of bilirubin level be not evenly distributed; the healthy 
participant recruit from the university generally have similarly low value within 0.1 mg/dl, while the patient 
from the medical center have a far wider spread. The threshold use in BiliScreen split the participant such that 
the normal and elevate class have roughly equal size (31 vs. 25). The borderline class be roughly half a large 
(14), which be to be expect give that it be hard to catch such cases. To ensure that the training set be balance 
during cross-validation, split be assign use stratify sample across the three bilirubin level classes. To be 
more specific, the typical fold for our dataset include 3 participant with normal bilirubin levels, 1 participant 
with a borderline bilirubin level, and 3 participant with elevate bilirubin levels. 

The data collection procedure result in 2 trial per accessory × 4 gaze direction per trial = 8 image per 
accessory. Note that each image contains 2 eyes, lead to 16 eye image per accessory. Each eye be summarize 
with a feature vector that lead to it own bilirubin level prediction. For the result that be present in this 
paper, the estimate from the 8 image be average to produce a final bilirubin level estimate that be report 
back to the user. In the future, we plan to examine method for select the best subset of image and only use 
them in the calculations. 

5 RESULTS 
Our evaluation examines BiliScreen’s two major components: the segmentation algorithm and the sclera color- 
to-bilirubin level regression. We first examine the performance of the glasses’ and sclera segmentation. We then 

Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 2, Article 20. Publication date: May 2017. 



20:16 • Mariakakis et al. 

show how accurate BiliScreen can be, assume near-perfect segmentation of the glass and sclera, a well a 
how accurate BiliScreen be with the current segmentation algorithms. We conclude by frame the accuracy of 
BiliScreen a a classification problem, show how likely BiliScreen be to make the correct diagnostic decision. 

5.1 Segmentation 
All of the image be hand-annotated by the same researcher for ground truth. For the image take with 
the BiliScreen box, the sclerae for both eye be annotated; for the image take with the BiliScreen glasses, 
the sclerae of both eyes, the color squares, and the lens be annotated. The performance of BiliScreen’s 
segmentation algorithm can be described use precision and recall. The ground truth pixel annotate by the 
researcher be treat a targets. Precision defines the fraction of select pixel that be correct, while recall 
defines the fraction of correct pixel that be selected. A low precision with a high recall would imply that the 
algorithm selects most of the pixel that belong to the target, but also include several pixel outside of the target. 
A high precision with a low recall would imply that the algorithm only selects a fraction of the necessary pixels, 
but they be mostly within the target. 

5.1.1 Glasses Segmentation. Finding the general region of interest for the sclera when the box be in use be 
trivial; it be base on rough rectangle on either side of the box. For the BiliScreen glasses, however, the region of 
interest be define by the region within the glasses’ lenses. We found that the glass segmentation algorithm be 
able to locate the region of interest for the sclera with a mean precision of 94.0 ± 15.0% and a mean recall of 94.4 
± 15.1% across all image relative to the lens border define by the human annotator. Recall be more important 
than precision for this problem because, a a region of interest, it be okay for superfluous pixel to be include a 
long a those belonging to the lens be included. The first step of the sclera segmentation algorithm attempt to 
rule out pixel outside of the eye agnostic of whether they represent skin or something else. 
The glass segmentation algorithm be also important for locate the color square around the lens for 

color calibration. On average, the algorithm found the square with a mean precision of 83.5 ± 24.2% and a mean 
recall of 88.2 ± 24.1% across all images. Unlike the sclera region of interest, precision be more important than 
recall for the color square because superfluous pixel can add noise to the calculation that summarizes the 
pixel color to a single color value. Nevertheless, that be the specific reason for why the median vector be use over 
other aggregation functions. BiliScreen can tolerate mediocre precision a long a most of the pixel belong to 
the color squares, which be true even within a standard deviation of our results. BiliScreen also take advantage 
of the fact that there be a copy of each color square on both side of the face. The expect color of the square 
be know beforehand, so if a square on one side appear significantly different from the other with respect to 
the expect color, BiliScreen prioritizes the one that be closer to expectations. 

Many of the issue that arose for the glass segmentation can be attribute to their deformability. The glass 
be make from a thin cardstock that could bend if the glass be not large enough to fit on the participant’s 
head. If BiliScreen cannot find a square, the algorithm fit the square it have found to linear row and column 
and us their intersection to find the miss one. When the row and column be actually curves, line do not 
properly infer the squares’ locations. Higher-order polynomial could have be use to model the curvature, but 
most of the square require extrapolation rather than interpolation. That be to say, the location of the square 
have to be infer outside of the range of the available squares, so even higher-order function would not always 
properly locate squares. In the future, we plan on improve the design of the BiliScreen glass with a stiffer 
material and adjustable stem to avoid bending in the future. 

5.1.2 Sclera Segmentation. As be the case for the glasses, ground truth for the sclera segmentation come 
from manual annotations. Pixel perfect label be impossible by hand because of artifact like eyelash and 
blood vessel that encroach into the region. Nevertheless, those artifact be handle post-hoc during feature 
extraction, so neither the ground truth annotation nor the segmentation algorithm be require to handle them. 

Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 2, Article 20. Publication date: May 2017. 



BiliScreen: Smartphone-Based Scleral Jaundice Monitoring for Liver and Pancreatic Disorders • 20:17 

Table 4. Sclera segmentation result per eye 

Precision Recall 
Box 74.8 ± 34.1% 56.9 ± 28.6% 
Glasses 74.8 ± 35.0% 43.1 ± 27.1% 

Fig. 7. Example case of BiliScreen’s segmentation work (left) correctly and (right) incorrectly while the BiliScreen box 
be in use. These image come from individual who be not recruit for the study in order to protect the privacy of those 
participants. 

For sclera segmentation, a high precision with a low recall be also prefer over a low precision and a high 
recall. During the feature extraction phase, the color of the individual pixel be summarize into single color 
vector that describe the entire region. Having a small but correct region be likely to result in a similar calculation 
outcome, but include pixel outside of the target region can contribute noise to the result. Table 4 show the 
per-eye precision and recall for both BiliScreen accessories. The spread of these measure can be mislead since 
the performance of the algorithm be roughly binary; the segmentation algorithm either identifies a region that 
corresponds to the sclera and only the sclera, or it completely miss and identifies another region, though it 
be correct more often than it be not. Looking deeper into the results, we find that 57.1% of the image from the 
box be segment with ≥90% precision and 56.5% of the image with the glass be segment with ≥90% 
precision. Failures be not evenly distribute amongst all users. 
Fig. 7 show successful and unsuccessful case of sclera segmentation. For the most part, failure can be 

attribute to mistake in the first half of the sclera segmentation algorithm, which us GrabCut on the region of 
interest to locate the eye. In the first example of poor segmentation (third column of Fig. 7), a faint shadow be cast 
onto the top-right part of the sclera since it curve away from the smartphone’s flash. The sclera be assume to 

Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 2, Article 20. Publication date: May 2017. 



20:18 • Mariakakis et al. 

be the brightest part of the image. Therefore, the algorithm prefers the rectangular initialization that include the 
low half of the sclera, which be bright, and the region just below the eye, where the flash reflect off of the skin 
and back to the camera. In the second example of poor segmentation (fourth column of Fig. 7), the sclera have a 
naturally darker tint. Again, the flash produce a reflection under the eye, so the algorithm completely fails to 
select any part of it. 

The dataset include some user who squint or blink during the study. No attempt be make to manually 
curate images, and there be usually still enough expose sclera so that a human observer could barely pick out 
the correct region. Nevertheless, we plan on implement quality check in a future version of the BiliScreen 
app to handle such cases. For the sclera segmentation with the glasses, error can also be attribute to incorrect 
region of interest from the segmentation of the glass themselves. If BiliScreen could not the properly locate 
the glasses, then the algorithm make it best guess, which can hinder late part of the pipeline. This be another 
quality check that we believe will be necessary in the next version of the BiliScreen app. 

5.2 BiliScreen a a Measurement Tool 
Fig. 8 show the BiliScreen’s optimal performance for estimate a person’s bilirubin level when the exact 
boundary of the sclera be know a priori. Of course, this claim assumes that the color-calibration procedure for 
the glass and the feature extraction for both accessory properly capture the information need to properly 
describe the color of the sclera. Although there be likely aspect of improvement in these regards, we suspect 
that automatic segmentation be the large contributor of error since all calculation thereafter be dependent on 
it results. 

The result be present in two different arrangements. On the left, Fig. 8 show the correlation of BiliScreen’s 
prediction with the ground truth measurement gather from TSBs. The point be show on a log-scale for 
clarity since the distribution be bias towards low values. The dot line on the correlation plot indicate the 
1.3 mg/dl and 3.0 mg/dl threshold that separate the three group of measurements.With the optimal segmentation, 
the Pearson correlation coefficient between BiliScreen’s prediction and ground truth be 0.86 with the box and 
0.83 with the glasses. On the right, Fig. 8 show the Bland-Altman plot of the same measurements. Again, the 
x-axis show the ground truth measurement use a log-scale for clarity. With the box, BiliScreen estimate the 
user’s bilirubin level with a mean error of -0.17 ± 2.81 mg/dl. With the glasses, BiliScreen estimate the user’s 
bilirubin level with a mean error of -0.08 ± 3.10 mg/dl. 
The optimal model in their current state be more accurate for low level (<1.3 mg/dl) than they be for 

high level (>3.0 mg/dl). This can be attribute to the underlie distribution of bilirubin measurement for 
our participants’. Two participant return a TSB value great than 20 mg/dl, far beyond the threshold between 
borderline and elevate values. Since these participant be not thoroughly represent in our dataset, the 
optimal model underestimate their bilirubin level to fall more in line with the rest of the distribution. In general, 
high TSB value lead to large prediction error for this very reason. Comparing the box and glass accessories, 
the box yield good results. The box eliminates the effect of ambient light on the appearance of the sclera. 
The glass require the extra step of color calibration, which introduces it own error into the pipeline. 

The result show in Fig. 9 be present in the same manner a those in Fig. 8, but be calculate use 
BiliScreen’s automatic segmentation algorithm for the sclera and glasses. We anticipate that BiliScreen’s overall 
performance would degrade with the use of imperfect segmentation. Regarding the sclera segmentation, extra 
pixel almost always belong to the skin surround the eye. Skin often appear more yellow than the typical 
white of the sclera, so significant patch of skin can improperly lead to overestimation. The median color vector 
be use during feature extraction to counteract such behavior, but it be not sufficient for case when the majority 
of the extract region belongs to the skin. The prediction result use BiliScreen’s automatic segmentation 
algorithm confirm our hypothesis, particularly for the glasses. The Pearson correlation coefficient for picture 
take with the glass drop to 0.78, and the mean error of that model widens to 0.15 ± 3.55 mg/dl. To our surprise, 

Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 2, Article 20. Publication date: May 2017. 



BiliScreen: Smartphone-Based Scleral Jaundice Monitoring for Liver and Pancreatic Disorders • 20:19 

Fig. 8. The (left) correlation and (right) Bland-Altman plot for BiliScreen’s bilirubin measurement with the (top) box and 
(bottom) glass use the optimal sclera and glass segmentation. Note that the ax of the correlation plot be both in 
log-scale, a be the x-axis of the Bland-Altman plot. 

the Pearson correlation coefficient for the box rise to 0.89, and the mean error improves to -0.09 ± 2.76 mg/dl. A 
careful comparison of Fig. 8 against Fig. 9 reveals why this be the case. When the optimal segmentation be use 
to extract features, the model underestimate high TSB values. Because the addition of skin pixel can lead to 
overestimation, the underestimation be revert and those prediction be improved. The model still overestimate 
all users, include those with normal and borderline bilirubin levels, but the improvement on the elevate level 
outweighs the small error that be incur for those low levels. 

The result present up until this point use all 8 image for each accessory, come from the 4 gaze direction 
and the 2 trials. Asking the user to look in different direction provide different view of the sclera, some of 
which may exhibit more jaundice than others. Although these picture take less than a minute to collect in total, 
we recognize that request user for 8 image can be burdensome. Using the optimal segmentation results, we 
find that there be little disadvantage to use the image from a single gaze direction; the Pearson correlation 
coefficient for the box and glass accessory varies by no more than 0.05 for any give direction. 

Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 2, Article 20. Publication date: May 2017. 



20:20 • Mariakakis et al. 

Fig. 9. The (left) correlation and (right) Bland-Altman plot for BiliScreen’s bilirubin measurement with the (top) box and 
(bottom) glass use BiliScreen’s sclera and glass segmentation algorithms. Note that the ax of the correlation plot 
be both in log-scale, a be the x-axis of the Bland-Altman plot. 

Table 5 present the Pearson correlation coefficient and error for BiliScreen’s bilirubin measurement with the 
box and glass accessory use the system’s segmentation algorithm. Far more variation can be see use the 
automatic segmentation, particularly when use the glass and look straight ahead. This could be because 
when the person look straight ahead, the only part of the sclera that be expose be thin region near the 
frame of the glasses. These region be more likely to be cover in a shadow since they curve away from the 
camera and into the eye socket. The shadow not only affect segmentation, but also the color that be conveyed to 
the camera. Beyond this behavior, we do not believe there be any significant trend across different gaze directions. 
Incorporating more image into the final calculation allows BiliScreen to good tolerate an single image with 
incorrect segmentation. Sometimes, the result improve because incorrectly segment image be remove 
from the final calculation. Other times, the result worsen because those same image be the only one 
available for final calculation. 

Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 2, Article 20. Publication date: May 2017. 



BiliScreen: Smartphone-Based Scleral Jaundice Monitoring for Liver and Pancreatic Disorders • 20:21 

Table 5. BiliScreen measurement result across different subset of image 

BOX - Pearson correlation coefficient, mean error ± std error 
All image 0.89, -0.09 ± 2.76 mg/dl 
Looking up 0.84, -0.06 ± 3.03 mg/dl 
Looking left 0.85, -0.15 ± 2.89 mg/dl 
Looking right 0.82, -0.13 ± 3.21 mg/dl 
Looking straight ahead 0.87, -0.05 ± 2.78 mg/dl 
GLASSES - Pearson correlation coefficient, mean error ± std error 
All image 0.78, 0.15 ± 3.55 mg/dl 
Looking up 0.72, 0.06 ± 3.18 mg/dl 
Looking left 0.82, -0.06 ± 3.22 mg/dl 
Looking right 0.83, -0.31 ± 3.09 mg/dl 
Looking straight ahead 0.51, 0.28 ± 4.72 mg/dl 

Fig. 10. ROC curve show BiliScreen’s efficacy a a screen tool use the (left) box and (right) glass use the 
optimal sclera and glass segmentation. For the purpose of this analysis, normal bilirubin level be consider negative 
cases, while borderline and elevate level be consider positive cases. 

5.3 BiliScreen a a Classifier 
The previous analysis have show the accuracy with which BiliScreen can estimate a person’s bilirubin level. 
Accuracy be always important, especially for capture trend in the data. Nevertheless, the average user without 
a medical background be likely to be more concerned about how their estimate bilirubin level be classify rather 
than the value itself. In other words, if BiliScreen be to suggest that user with a borderline or elevate bilirubin 
level refer to a doctor for further tests, they would want assurance about BiliScreen’s sensitivity (true positive 
rate) and specificity (true negative rate). From the perspective of the user, we group borderline and elevate 
bilirubin level a positive case when the user would be refer to a doctor and normal bilirubin level a 
negative cases. 

Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 2, Article 20. Publication date: May 2017. 



20:22 • Mariakakis et al. 

Fig. 11. ROC curve show BiliScreen’s efficacy a a screen tool use the (left) box and (right) glass use BiliScreen’s 
sclera and glass segmentation algorithm. For the purpose of this analysis, normal bilirubin level be consider negative 
cases, while borderline and elevate level be consider positive cases. 

Fig. 10 show the ROC curve for BiliScreen a a classifier use the optimal sclera and glass segmentation. The 
area under the ROC curve (AUC) be 0.99 for the box and 0.98 for the glasses. Using the pre-determined threshold 
of 1.3 mg/dl use by the medical center, BiliScreen with the box achieves a sensitivity of 95.7% and a specificity of 
97.4%. The threshold that maximizes the accuracy be only 0.1 mg/dl higher, increase the sensitivity to 97.4% 
without a change to the specificity. Since the BiliScreen model with the glass be more prone to overestimate 
low bilirubin levels, it achieves a sensitivity of 100% and a specificity of only 71.4%. The threshold that optimizes 
accuracy lead to a sensitivity of 92.8% and a specificity of 94.3%. 
Fig. 11 show the same curve for BiliScreen a a classifier use the system’s segmentation algorithms. The 

AUC be 0.96 for the box and 0.95 for the glasses. Again, use the pre-determined threshold of 1.3 mg/dl lead to 
high sensitivity and low specificity since both model overestimate with the accidental incorporation of skin 
pixels. Using the optimal threshold that maximize accuracy, BiliScreen with the box achieves a sensitivity of 
89.7% and a specificity of 96.8%. With the glasses, BiliScreen have a sensitivity of 82.1% and a specificity of 96.1%. 

6 DISCUSSION 
Our goal be to develop a smartphone-based system that would estimate a person’s bilirubin level by quantify 
the extent of jaundice in their sclera. We believe that BiliScreen be the first step toward these goals. We design 
and evaluate two different accessory - a box and glass - that allow for the sclera’s true color to be measured. 
In our evaluation, we found that the box accessory perform good than the glasses, achieve a Pearson 
correlation of 0.89 and a mean error of -0.09 ± 2.76 mg/dl against a blood draw. As a classifier, the BiliScreen app 
and box accessory achieve a specificity of 89.7% and a sensitivity of 96.8%. 

6.1 Hardware 
The BiliScreen box be design to block out ambient lighting, allow the smartphone’s flash to replace an 
otherwise vary surface reflection component with a constant one. However, the model associate with the box 
do not account for different camera sensors. All of the data for this study be collect use the same iPhone 

Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 2, Article 20. Publication date: May 2017. 



BiliScreen: Smartphone-Based Scleral Jaundice Monitoring for Liver and Pancreatic Disorders • 20:23 

SE device. Should another device be used, the BiliScreen model for the box would need to account for the camera 
sensor’s response. This issue could be remedied in one of two ways. First, image could be gather from the 
different camera and separate model could be train for each of them. This would clearly be a time-consuming 
endeavor, but lead to result like the one present in the paper. An alternative approach would be to perform a 
one-time calibration procedure a prescribed in Section 4.3 use a color calibration card within the box. The 
result calibration matrix would then be store and apply on all image take with the same device. This 
could be do offline by a researcher with a collection of devices, or the user could be ask to do it before use 
the BiliScreen app. The color square from the BiliScreen glass could even be integrate into the BiliScreen 
box so that a separate color calibration card do not need to be purchased. 

The latter approach assumes that a calibration matrix can perfectly correct an image’s representation of color. 
Of course, this be the same assumption behind the BiliScreen glasses. If the assumption be not true, then the effect 
of the surface reflection component and the camera sensor’s response cannot be fully eliminated. We believe that 
this assumption hold well enough that the linger external effect on the sclera’s color be negligible, but have 
yet to conduct a formal study on the matter. 

6.2 Software 
Prior work have propose a variety of technique for sclera segmentation. However, we found that they be not 
suitable for people with jaundice either because they assume strict placement of the eye or that the color of the 
sclera would always be pale white. We developed a novel sclera segmentation algorithm that circumvents these 
issue while achieve a mean per-image precision of 74.8 ± 34.1% with the box and 74.8 ± 35.0% with the glasses. 
The median be much high than the mean in both case and the fact that the precision be great than 50% be 
sufficient for BiliScreen’s feature extraction, but we recognize that there may be other segmentation method 
that would achieve even good results. The technique we be most interested in pursue be fully convolutional 
neural network (FCNs) [21]. FCNs take advantage of regular convolutional network that have be train to 
reach astonishingly high accuracy at identify objects, only instead of the fully-connected layer at the end 
that produce object labels, FCNs use deconvolutions to achieve a label for every pixel. We believe we can train a 
similar network for our use case, though this would require far more label data than what have be acquire to 
this point. 
As mention in various part of the paper, optimization can be make throughout BiliScreen’s pipeline. We 

use the mutual information score function [16] to automatically select the top 5% of the feature that best 
explain the sclera color. In the future, we plan on manually examine the contribution of the feature and 
determine if certain feature calculation be redundant. The final bilirubin estimate be also base on all 8 image 
capture per accessory. Taking so many image can be burdensome for the user, but we also believe that get 
the different view of the sclera ensures that any region particularly affected by jaundice be captured. That 
be said, we have found that use all of the image only provide a small improvement to the final results. We 
plan on investigate this trade-off further. 

6.3 Future Applications 
BiliScreen do not directly ass a person’s risk of pancreatic cancer; it examines the sclera for jaundice, one of 
pancreatic cancer’s symptoms. Jaundice appear in other conditions, such a hepatitis and Gilbert’s syndrome. 
Examining if there be difference between the visible symptom of these disease warrant further investigation. 

The deployed implementation of BiliScreen depends on the target demographic for whom the app be designed. 
If BiliScreen be to be deployed a a screen application, we would prioritize notify user about the possible 
risk of pancreatic cancer, even at the cost of extra false positives. This would be implement by lower the 
decision threshold for classify a user’s bilirubin level to increase sensitivity and decrease specificity; for 
example, lower the decision threshold for BiliScreen with the box accessory improves it sensitivity from 89.7% 

Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 2, Article 20. Publication date: May 2017. 



20:24 • Mariakakis et al. 

to 95.2% while degrade the specificity from 96.8% to 71.2% (Fig. 11, left). The downside to this change be that 
BiliScreen could induce a great deal of stress by falsely inform user that they may have a condition a serious 
a pancreatic cancer. To combat this issue, BiliScreen could require multiple consistent, high measurement before 
prompt the user to consult a clinician. If BiliScreen be to be deployed a a disease management tool, the 
trend of the data would be most important to clinicians. 
Looking beyond jaundice, quantitative visual examination of the sclera can yield other fruitful observations. 

Osteogenesis imperfecta, a genetic disorder that result in brittle bones, produce a blue tinge in the sclera [33]. 
Diabetes result in few capillaries, dilate macrovessels, and change in the curvature in the cover of the 
sclera [25, 26]. Hyperemia and conjunctivis can affect both the amount and contrast of the blood vessel on the 
scleral surface [14]. BiliScreen’s sclera segmentation algorithm could be use a a start point for a system that 
search for these symptom and others. 

7 CONCLUSION 
Ubiquitous bilirubin assessment could have a significant impact on the current state of pancreatic cancer diagnosis. 
To this end, we have present BiliScreen, a smartphone app that analyzes digital photograph of the eye for 
the degree of jaundice that present in the sclera. We test two different accessory to be use in conjunction 
with BiliScreen to allow the sclera’s true color to be measured: a 3D-printed box that block out external light 
and a pair of glass that provide reference for color calibration. We evaluate BiliScreen in a study with 70 
individual with vary bilirubin level and found that the box accessory lead to good results. Using the box 
accessory lead to a Pearson correlation of 0.89 and a mean error of -0.09 ± 2.76 mg/dl against a blood draw. As a 
classifier, BiliScreen with the box be able to screen participant for further consultation with 89.7% specificity 
and 96.8%. sensitivity. It be our hope to continue building on our initial prototype of BiliScreen with improve 
models, a more convenient and automate smartphone app, and a longer-term study that capture trend of 
bilirubin levels. 

8 ACKNOWLEDGMENTS 
We thank the National Science Foundation and the Coulter Foundation for their funding. We thank Ellie Roberts 
for help collect data during the early stage of the project. We thank Mike Clarke for help design the 
BiliScreen glasses. Finally, we thank Elliot Saba, Ruth Ravichandran, Mohit Jain, and Edward Wang for provide 
their feedback on the work. 

REFERENCES 
[1] Alireza Abdolvahabi, Brandon W. Taylor, Rebecca L. Holden, Elizabeth V Shaw, Alex Kentsis, Carlos Rodriguez-Galindo, Shizuo Mukai, 

and Bryan F. Shaw. Colorimetric and longitudinal analysis of leukocoria in recreational photograph of child with retinoblastoma. 
PloS one, 8(10):e76677, oct 2013. 

[2] American Cancer Society. Cancer Facts & Figures 2016. Technical report, American Cancer Society, Atlanta, GA, 2016. 
[3] Andrew Bastawrous, Hillary K. Rono, Iain A. T. Livingstone, Helen A. Weiss, Stewart Jordan, Hannah Kuper, and Matthew J. Burton. 

Development and Validation of a Smartphone-Based Visual Acuity Test (Peek Acuity) for Clinical Practice and Community-Based 
Fieldwork. JAMA Ophthalmology, 133(8):930, aug 2015. 

[4] Vinod K Bhutani, Lois Johnson, and Emidio M Sivieri. Predictive ability of a predischarge hour-specific serum bilirubin for subsequent 
significant hyperbilirubinemia in healthy term and near-term newborns. Pediatrics, 103(1):6–14, 1999. 

[5] Giles Bond-Smith, Neal Banga, Toby M Hammond, and Charles J Imber. Pancreatic adenocarcinoma. BMJ, 344, 2012. 
[6] Yuri Y Boykov and Marie-Pierre Jolly. Interactive graph cut for optimal boundary & region segmentation of object in ND images. In 

Proc. ICCV ’01, volume 1, page 105–112. IEEE, 2001. 
[7] Simona Crihalmeanu and Arun Ross. Multispectral scleral pattern for ocular biometric recognition. Pattern Recognition Letters, 

33(14):1860–1869, 2012. 
[8] Abhijit Das, Umapada Pal, Miguel Angel Ferrer Ballester, and Michael Blumenstein. A new efficient and adaptive sclera recognition 

system. In 2014 IEEE Symposium on Computational Intelligence in Biometrics and Identity Management (CIBIM), page 1–8. IEEE, 

Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 2, Article 20. Publication date: May 2017. 



BiliScreen: Smartphone-Based Scleral Jaundice Monitoring for Liver and Pancreatic Disorders • 20:25 

dec 2014. 
[9] Abhijit Das, Umapada Pal, Miguel Angel Ferrer Ballester, and Michael Blumenstein. Sclera recognition use dense-SIFT. In International 

Conference on Intelligent Systems Design and Applications, ISDA, page 74–79. IEEE, dec 2014. 
[10] Lilian de Greef, Mayan Goel, Min Joon Seo, Eric C Larson, James W Stout, James A Taylor, and Shwetak N Patel. Bilicam: use mobile 

phone to monitor newborn jaundice. In Proc. UbiComp ’14, page 331–342, 2014. 
[11] Maria Syl D De La Cruz, Alisa P Young, and Mack T Ruffin. Diagnosis and management of pancreatic cancer. American family physician, 

89(8):626–32, apr 2014. 
[12] Mario E Giardini, Iain A T Livingstone, Stewart Jordan, Nigel M Bolster, Tunde Peto, Matthew Burton, and Andrew Bastawrous. A 

smartphone base ophthalmoscope. Proc. EMBC ’14, 2014:2177–2180, 2014. 
[13] Dorothy M Greig, Bruce T Porteous, and Allan H Seheult. Exact maximum a posteriori estimation for binary images. Series of the 

Royal Statistical Society, 51(2):271–279, 1989. 
[14] G. Heath. The episclera, sclera and conjunctiva. An overview of relevant ocular anatomy. Differential Diagnosis of Ocular Disease, 

9(2):36–42, 2006. 
[15] Gudrun J Klinker, Steven A Shafer, and Takeo Kanade. A physical approach to color image understanding. International Journal of 

Computer Vision, 4(1):7–38, 1990. 
[16] LF Kozachenko and NN Leonenko. Sample estimate of the entropy of a random vector. Problemy Peredachi Informatsii, 23(2):9–16, 

1987. 
[17] Everett Lawson, Jason Boggess, Siddharth Khullar, Alex Olwal, Gordon Wetzstein, and Ramesh Raskar. Computational retinal image 

via binocular couple and indirect illumination. In Proc. SIGGRAPH ’12, page 51, 2012. 
[18] Somsak Leartveravat. Transcutaneous bilirubin measurement in full term neonate by digital camera. Medical Journal of Srisaket Surin 

Buriram Hospitals, 24(1):105–118, 2009. 
[19] Terence S Leung, Karan Kapur, Ashley Guilliam, Jade Okell, Bee Lim, Lindsay W MacDonald, and Judith Meek. Screening neonatal 

jaundice base on the sclera color of the eye use digital photography. Biomedical optic express, 6(11):4529–4538, 2015. 
[20] Rainer Lienhart and Jochen Maydt. An extend set of Haar-like feature for rapid object detection. In Proceedings. International 

Conference on Image Processing, volume 1, page 0–3, 2002. 
[21] Jonathan Long, Evan Shelhamer, and Trevor Darrell. Fully convolutional network for semantic segmentation. In Proceedings of the 

IEEE Computer Society Conference on Computer Vision and Pattern Recognition, volume 07-12-June, page 3431–3440, mar 2015. 
[22] Dan L Longo, Anthony S Fauci, Dennis L Kasper, Stephen L Hauser, J Larry Jameson, and Joseph Loscalzo. 

Harrison’s Principles of Internal Medicine. 18th edition, 2006. 
[23] Marco Marcon, Eliana Frigerio, and Stefano Tubaro. Sclera segmentation for gaze estimation and iris localization in unconstrained 

images. In CompIMAGE, page 25–29, 2012. 
[24] Nobuyuki Otsu. A threshold selection method from gray-level histograms. IEEE Transactions on Systems, Man, and Cybernetics, 

9(1):62–66, jan 1979. 
[25] Christopher G Owen, Richard SB Newsom, Alicja R Rudnicka, Sarah A Barman, and E Goeffrey Woodward. Diabetes and the tortuosity 

of vessel of the bulbar conjunctiva. Ophthalmology, 115(6):e27–e32, 2008. 
[26] Christopher G Owen, Richard SB Newsom, Alicja R Rudnicka, and Tim J Ellis. Vascular response of the bulbar conjunctiva to diabetes 

and elevate blood pressure. Ophthalmology, 112(10):1801–1808, 2005. 
[27] Vitor F Pamplona, Ankit Mohan, Manuel M Oliveira, and Ramesh Raskar. NETRA: interactive display for estimate refractive error 

and focal range. ACM transaction on graphic (TOG), 29(4):77, 2010. 
[28] Vitor F Pamplona, Erick B Passos, Jan Zizka, Manuel M Oliveira, Everett Lawson, Esteban Clua, and Ramesh Raskar. Catra: cataract 

probe with a lightfield display and a snap-on eyepiece for mobile phones. In Proc. SIGGRAPH ’11, page 7–11, 2011. 
[29] Danny Pascale. RGB coordinate of the Macbeth ColorChecker. Technical report, 2006. 
[30] Carsten Rother, Vladimir Kolmogorov, and Andrew Blake. Grabcut: Interactive foreground extraction use iterate graph cuts. ACM 

Transactions on Graphics (TOG) ’04, 23(3):309–314, 2004. 
[31] Mario A Ruiz, Sammy Saab, and Leland S Rickman. The clinical detection of scleral icterus: observation of multiple examiners. Military 

medicine, 162(8):560–563, 1997. 
[32] Gaurav Sharma, Wencheng Wu, and Edul N. Dalal. The CIEDE2000 color-difference formula: Implementation notes, supplementary test 

data, and mathematical observations. Color Research and Application, 30(1):21–30, feb 2005. 
[33] DO Sillence, Alison Senn, and DM Danks. Genetic heterogeneity in osteogenesis imperfecta. Journal of medical genetics, 16(2):101–116, 

1979. 
[34] Audrey Vincent, Joseph Herman, Rich Schulick, Ralph HHruban, andMichael Goggins. Pancreatic cancer. The Lancet, 378(9791):607–620, 

aug 2011. 
[35] Paul Viola and Michael J Jones. Rapid object detection use a boost cascade of simple features. In Computer Vision and Pattern 

Recognition (CVPR), volume 1, page 511–518, 2001. 

Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 2, Article 20. Publication date: May 2017. 



20:26 • Mariakakis et al. 

[36] Russell Wiesner, Erick Edwards, Richard Freeman, Ann Harper, Ray Kim, Patrick Kamath, Walter Kremers, John Lake, Todd Howard, 
Robert M. Merion, Robert A. Wolfe, Ruud Krom, and United Network for Organ Sharing Liver Disease Severity Score Committee. Model 
for end-stage liver disease (MELD) and allocation of donor livers. Gastroenterology, 124(1):91–96, jan 2003. 

[37] Stephen Wolf. Color correction matrix for digital still and video image systems. page 1–40, 2003. 
[38] Zhi Zhou, Eliza Yingzi Du, N. Luke Thomas, and Edward J. Delp. A New Human Identification Method: Sclera Recognition. Systems, 

Man and Cybernetics, Part A: Systems and Humans, IEEE Transactions on, 42(3):571–583, may 2012. 

Received February 2017; accepted April 2017 

Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 2, Article 20. Publication date: May 2017. 


Abstract 
1 Introduction 
2 Related Work 
2.1 Sclera Imaging 
2.2 Jaundice Assessment 
2.3 Ocular Diagnostic Applications 

3 Data Collection 
3.1 Enrollment 
3.2 Data Collection Procedure 
3.3 BiliScreen Accessories 
3.4 BiliScreen Application 

4 BiliScreen Algorithm 
4.1 Sclera Segmentation 
4.2 Glasses Segmentation 
4.3 Glasses Color Calibration 
4.4 Feature Extraction 
4.5 Machine Learning 

5 Results 
5.1 Segmentation 
5.2 BiliScreen a a Measurement Tool 
5.3 BiliScreen a a Classifier 

6 Discussion 
6.1 Hardware 
6.2 Software 
6.3 Future Applications 

7 Conclusion 
8 Acknowledgments 
References 

