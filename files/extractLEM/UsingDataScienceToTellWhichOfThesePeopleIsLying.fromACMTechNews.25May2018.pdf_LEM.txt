






































Using data science to tell which of these people be lie : NewsCenter 


Using data science to tell which of these people be lie : NewsCenter 

Bob Marcotte 

May 22, 2018 

Researchers in computer scientist Ehsan Hoque's lab have create a game that have allow them to analyze more than 1 million frame 
of facial expressions, the large video dataset so far for understand how to tell if someone be lying. (University of Rochester photo 
/ J. Adam Fenster) 

Someone be fidget in a long line at an airport security gate. Is that person simply nervous about the wait? 

Or be this a passenger who have something sinister to hide? 

Even highly train Transportation Security Administration (TSA) airport security officer still have a hard time tell whether 
someone be lie or tell the truth – despite the billion of dollar and year of study that have be devote to the subject. 

Now, University of Rochester researcher be use data science and an online crowdsourcing framework call ADDR (Automated 
Dyadic Data Recorder) to further our understand of deception base on facial and verbal cues. 

They also hope to minimize instance of racial and ethnic profile that TSA critic contend occurs when passenger be pull aside 
under the agency’s Screening of Passengers by Observation Techniques (SPOT) program. 

“Basically, our system be like Skype on steroids,” say Tay Sen, a PhD student in the lab of Ehsan Hoque, an assistant professor of 
computer science. Sen collaborate closely with Karmul Hasan, another PhD student in the group, on two paper in IEEE Automated 
Face and Gesture Recognition and the Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquituous Technologies. The 
paper describe the framework the lab have use to create the large publicly available deception dataset so far – and why some smile 
be more deceitful than others. 

Game reveals the truth behind a smile 

Here’s how ADDR works: Two people sign up on Amazon Mechanical Turk, the crowdsourcing internet marketplace that match 
people to task that computer be currently unable to do. A video assigns one person to be the describer and the other to be the 
interrogator. 

The describer be then show an image and be instruct to memorize a many of the detail a possible. The computer instructs the 
describer to either lie or tell the truth about what they’ve just seen. The interrogator, who have not be privy to the instruction to the 
describer, then asks the describer a set of baseline question not relevant to the image. This be do to capture individual behavioral 
difference which could be use to develop a “personalized model.” The routine question include “what do you wear yesterday?” — 
to provoke a mental state relevant to retrieve a memory — and “what be 14 time 4?” — to provoke a mental state relevant to 
analytical memory. 

Play the game: Can you tell which person be lying? 

“A lot of time people tend to look a certain way or show some kind of facial expression when they’re remember things,” Sen said. 
“And when they be give a computational question, they have another kind of facial expression.” 

They be also question that the witness would have no incentive to lie about and that provide a baseline of that individual’s “normal” 
response when answer honestly. 

And, of course, there be question about the image itself, to which the witness give either a truthful or dishonest response. 

Using data science to tell which of these people be lie : NewsCenter http://www.rochester.edu/newscenter/data-science-facial-expressions-who... 

1 sur 2 01-06-18 à 08:32 



The entire exchange be record on a separate video for late analysis. 

1 million face 

An advantage of this crowdsourcing approach be that it allows researcher to tap into a far large pool of research participant – and 
gather data far more quickly – than would occur if participant have to be brought into a lab, Hoque says. Not have a standardize 
and consistent dataset with reliable ground truth have be the major setback for deception research, he says. With the ADDR 
framework,the researcher gather 1.3 million frame of facial expression from 151 pair of individual play the game, in a few 
week of effort. More data collection be underway in the lab. 

Data science be enable the researcher to quickly analyze all that data in novel ways. For example, they use automate facial feature 
analysis software to identify which action unit be be use in a give frame, and to assign a numerical weight to each. 

The researcher then use an unsupervised cluster technique — a machine learn method that can automatically find pattern 
without be assign any predetermine label or categories. 

“It told u there be basically five kind of smile-related ‘faces’ that people make when respond to questions,” Sen said. The one 
most frequently associate with lie be a high intensity version of the so-called Duchenne smile involve both cheek/eye and 
mouth muscles. This be consistent with the “Duping Delight” theory that “when you’re fooling someone, you tend to take delight in it,” 
Sen explained. 

More puzzle be the discovery that honest witness would often contract their eyes, but not smile at all with their mouths. “When 
we go back and replayed the videos, we found that this often happen when people be try to remember what be in an 
image,” Sen said. “This show they be concentrate and try to recall honestly.” 

The Duchenne smile – a smile that extends to the muscle of the eye – be most frequently associate with lying. 
(University of Rochester photo / J. Adam Fenster) 

Witnesses answer honestly will often contract their eyes, try to truthfully recall information. 
(University of Rochester photo / J. Adam Fenster) 

Next step 

So will these finding tip off liar to simply change their facial expressions? 

Not likely. The tell-tale strong Duchenne smile associate with lie involves “a cheek muscle you cannot control,” Hoque says. “It be 
involuntary.” 

The researcher say they’ve only scratch the surface of potential finding from the data they’re collected. 

Hoque, for example, be intrigue by the fact the interrogator unknowingly leak unique information when they be be lie to. For 
example, interrogator demonstrate more polite smile when they be be lie to. In addition, an interrogator be more likely to return 
a smile by a lie witness than a truth-teller. While more research need to be done, it be clear that look at the interrogators’ data 
reveals useful information and could have implication for how TSA officer be trained. 

“There be also possibility of use language to further decipher the ambiguity within microexpressions.” Hasan says. Hasan be 
currently explore this space. 

“In the end, we still want human to make the final decision,” Hoque says. “But a they be interrogating, it be important to provide 
them with some objective metric that they could use to further inform their decisions.” 

Kurtis Haut, Zachary Teicher, Minh Tran, Matthew Levin, and Yiming Yang – all student in the Hoque lab – also contribute to the 
research. 

Tags: data science, Department of Computer Science, Ehsan Hoque, featured-post-side, research find 

Category: Featured 

Using data science to tell which of these people be lie : NewsCenter http://www.rochester.edu/newscenter/data-science-facial-expressions-who... 

2 sur 2 01-06-18 à 08:32 


