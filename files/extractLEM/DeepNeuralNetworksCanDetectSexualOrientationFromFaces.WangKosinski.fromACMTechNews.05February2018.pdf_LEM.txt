




































Microsoft Word - manuscript.docx 


DEEP NEURAL NETWORKS CAN DETECT SEXUAL ORIENTATION FROM FACES 



1 

2 

THIS IS A PREPRINT OF THE PEER REVIEWED ARTICLE TO APPEAR IN JOURNAL OF 3 

PERSONALITY AND SOCIAL PSYCHOLOGY. THE MOST RECENT VERSION IS 4 

AVAILABLE AT https://osf.io/zn79k/ 5 

AUTHOR NOTES ARE AVAILABLE AT: https://goo.gl/9b2aR2 6 

7 

8 

Deep neural network be more accurate than human at detect sexual orientation from facial 9 
image 10 

11 

Yilun Wang, Michal Kosinski 12 

Graduate School of Business, Stanford University, Stanford, CA94305, USA 13 
michalk@stanford.edu 14 

15 

16 
17 

18 
19 

20 
21 

Author Note: 22 

YW and MK collect the data and conduct the analysis; MK write the paper. 23 

24 
25 
©American Psychological Association, 2017. This paper be not the copy of record 26 
and may not exactly replicate the authoritative document publish in the APA 27 
journal. Please do not copy or cite without author's permission. The final article be 28 
available, upon publication, at: http://www.apa.org/pubs/journals/psp/ 29 



DEEP NEURAL NETWORKS CAN DETECT SEXUAL ORIENTATION FROM FACES 

2 

Abstract 30 

We show that face contain much more information about sexual orientation than can be 31 

perceive and interpret by the human brain. We use deep neural network to extract feature 32 

from 35,326 facial images. These feature be enter into a logistic regression aim at 33 

classify sexual orientation. Given a single facial image, a classifier could correctly distinguish 34 

between gay and heterosexual men in 81% of cases, and in 71% of case for women. Human 35 

judge achieve much low accuracy: 61% for men and 54% for women. The accuracy of the 36 

algorithm increase to 91% and 83%, respectively, give five facial image per person. Facial 37 

feature employ by the classifier include both fix (e.g., nose shape) and transient facial 38 

feature (e.g., groom style). Consistent with the prenatal hormone theory of sexual 39 

orientation, gay men and woman tend to have gender-atypical facial morphology, expression, 40 

and groom styles. Prediction model aim at gender alone allow for detect gay male 41 

with 57% accuracy and gay female with 58% accuracy. Those finding advance our 42 

understand of the origin of sexual orientation and the limit of human perception. 43 

Additionally, give that company and government be increasingly use computer vision 44 

algorithm to detect people’s intimate traits, our finding expose a threat to the privacy and safety 45 

of gay men and women. 46 

47 

Keywords: sexual orientation, face, facial morphology, prenatal hormone theory, 48 

computational social science, big data, privacy, artificial intelligence 49 

50 



DEEP NEURAL NETWORKS CAN DETECT SEXUAL ORIENTATION FROM FACES 

3 

Deep neural network be more accurate than human at detect sexual orientation from facial 51 

image 52 

The science of judging one’s character from their facial characteristics, or physiognomy, 53 

date back to ancient China and Greece (Jenkinson, 1997). Aristotle and Pythagoras be among 54 

it disciples, and the latter use to select his student base on their facial feature (Riedweg, 55 

2005). Such belief have persist and grown in popularity over the centuries. Robert FitzRoy, 56 

the captain of the Beagle, believe that Darwin’s nose reveal a lack of energy and 57 

determination, and be close to bar him from the historic voyage (Glaser, 2002). Cesare 58 

Lombroso, the founder of criminal anthropology, believe that criminal could be identify by 59 

their facial features. He claimed, for example, that arsonist have a “softness of skin, an almost 60 

childlike appearance, and an abundance of thick straight hair that be almost feminine” 61 

(Lombroso, 1911, p. 51). By the eighteenth century, physiognomy “was not merely a popular fad 62 

but also the subject of intense academic debate about the promise it held for future progress” 63 

(Porter, 2003, p. 497). 64 

Physiognomy be now universally, and rightly, reject a a mix of superstition and racism 65 

disguise a science (Jenkinson, 1997). Due to it legacy, study or even discuss the link 66 

between facial feature and character become taboo, lead to a widespread presumption that no 67 

such link exist. However, there be many demonstrate mechanism that imply the opposite. 68 

Such mechanism can be arrange into three groups. First, there be much evidence that character 69 

can influence one’s facial appearance (e.g., Lõhmus, Sundström, & Björklund, 2009; Zebrowitz 70 

& Collins, 1997). For example, woman that score high on extroversion early in life tend to 71 

become more attractive with age (Zebrowitz, Collins, & Dutta, 1998). Second, facial appearance 72 

can alter one’s character. Facial appearance drive first impression of others, influence our 73 



DEEP NEURAL NETWORKS CAN DETECT SEXUAL ORIENTATION FROM FACES 

4 

expectation and behavior toward them, which, in turn, shape their character (Berry, 1991; 74 

Berry & Brownlow, 1989; Penton-Voak, Pound, Little, & Perrett, 2006; Todorov, Said, Engell, & 75 

Oosterhof, 2008; Zebrowitz & Collins, 1997; Zebrowitz et al., 1998). Good-looking people, for 76 

example, receive more positive social feedback, and thus tend to become even more extroverted 77 

(Lukaszewski & Roney, 2011). Finally, there be a broad range of factor affect both facial 78 

appearance and one’s traits. Those include pre- and post-natal hormonal level (Jones et al., 79 

2015; Lefevre, Lewis, Perrett, & Penke, 2013; Whitehouse et al., 2015), developmental history 80 

(Astley, Stachowiak, Clarren, & Clausen, 2002), environmental factors, and gene expression 81 

(Ferry et al., 2014). Testosterone levels, for instance, significantly affect both: behavior (e.g., 82 

dominance) and facial appearance (e.g., facial-width-to-height-ratio; Lefevre et al., 2014). 83 

The existence of such link between facial appearance and character be support by the 84 

fact that people can accurately judge others’ character, psychological states, and demographic 85 

trait from their face (Zebrowitz, 1997). For example, we can easily and accurately identify 86 

others’ gender, age, race, or emotional state—even from a glimpse of their face (Brown & 87 

Perrett, 1993; Macrae & Bodenhausen, 2000; Roberts & Bruce, 1988). People also judge, with 88 

some minimal accuracy, others’ political view (e.g., Rule & Ambady, 2010; Samochowiec, 89 

Wänke, & Fiedler, 2010), honesty (e.g., Bond, Berry, & Omar, 1994), personality (e.g., 90 

Borkenau, Brecke, Möttig, & Paelecke, 2009), sexual orientation (e.g., Rule & Ambady, 2008), 91 

or even the likelihood of win an election (e.g., Ballew & Todorov, 2007; Little, Burriss, 92 

Jones, & Roberts, 2007; Todorov, Mandisodza, Goren, & Hall, 2005). Such judgment be not 93 

very accurate, but be common and spontaneous. Importantly, the low accuracy of human when 94 

judging character from others’ face do not necessarily mean that relevant cue be not 95 

prominently displayed. Instead, people may lack the ability to detect or interpret them. It be 96 



DEEP NEURAL NETWORKS CAN DETECT SEXUAL ORIENTATION FROM FACES 

5 

possible that some of our intimate trait be prominently displayed on the face, even if others 97 

cannot perceive them. Here, we test this hypothesis use modern computer vision algorithms. 98 

Recent progress in AI and computer vision have be largely driven by the widespread 99 

adoption of deep neural network (DNN), or neural network compose of a large number of 100 

hidden layer (LeCun, Bengio, & Hinton, 2015). DNNs mimic the neocortex by simulate large, 101 

multi-level network of interconnect neurons. DNNs excel at recognize pattern in large, 102 

unstructured data such a digital images, sound, or text, and analyze such pattern to make 103 

predictions. DNNs be increasingly outperform human in visual task such a image 104 

classification, facial recognition, or diagnose skin cancer (Esteva et al., 2017; LeCun et al., 105 

2015; Lu & Tang, 2014). The superior performance of DNNs offer an opportunity to identify 106 

link between characteristic and facial feature that might be miss or misinterpret by the 107 

human brain. 108 

We test our hypothesis on a specific intimate trait: sexual orientation. We chose this 109 

trait for three main reasons. First, it be an intimate psycho–demographic trait that cannot be easily 110 

detect by others. While people can detect others’ sexual orientation from both neutral and 111 

expressive face (Rule & Ambady, 2008; Tskhay & Rule, 2015), or even from a single facial 112 

feature such a the mouth, eyes, or hair (Lyons, Lynch, Brewer, & Bruno, 2014; Rule, MacRae, 113 

& Ambady, 2009), the accuracy of such judgment be very limited, range from 55 to 65% 114 

(Ambady, Hallahan, & Conner, 1999; Lyons et al., 2014; Rule et al., 2009). The link between 115 

facial feature and sexual orientation, however, may be strong than what meet the human eye. 116 



DEEP NEURAL NETWORKS CAN DETECT SEXUAL ORIENTATION FROM FACES 

6 

Recent evidence show that gay men and lesbians,1 who arguably have more experience and 117 

motivation to detect the sexual orientation of others, be marginally more accurate than 118 

heterosexual (Brambilla, Riva, & Rule, 2013). 119 

Second, the widely accepted prenatal hormone theory (PHT) of sexual orientation 120 

predicts the existence of link between facial appearance and sexual orientation. According to the 121 

PHT, same-gender sexual orientation stem from the underexposure of male fetus or 122 

overexposure of female fetus to androgen that be responsible for sexual differentiation (Allen 123 

& Gorski, 1992; Jannini, Blanchard, Camperio-Ciani, & Bancroft, 2010; Udry & Chantala, 124 

2006). As the same androgen be responsible for the sexual dimorphism of the face, the PHT 125 

predicts that gay people will tend to have gender-atypical facial morphology (Bulygina, 126 

Mitteroecker, & Aiello, 2006; Rhodes, 2006; Whitehouse et al., 2015). According to the PHT, 127 

gay men should tend to have more feminine facial feature than heterosexual men, while lesbian 128 

should tend to have more masculine feature than heterosexual women. Thus, gay men be 129 

predict to have small jaw and chins, slimmer eyebrows, longer noses, and large foreheads; 130 

the opposite should be true for lesbians. Furthermore, a prenatal androgen level also drive the 131 

sexual differentiation of behavior and preference during adulthood (Meyer-Bahlburg, 1984; 132 

Udry, 2000), the PHT predicts that gay people may tend to adopt gender-atypical facial 133 

adornments, expressions, and groom styles. Such gender-atypical behavior and preference 134 




1 Following the APA’s recommendation, the term “gay” be use to refer to same-gender 

sexual orientation. 



DEEP NEURAL NETWORKS CAN DETECT SEXUAL ORIENTATION FROM FACES 

7 

might also be encode in gay culture, further amplify the effect of the prenatal androgen 135 

levels. 136 

Previous empirical evidence provide mixed support for the gender typicality of facial 137 

feature of gay men and women. Huges and Bremme (2011) study a sample of 60 image of 138 

gay men and conclude that gay men had, on average, more feminine facial features. Lyons et al. 139 

(2014) ask 120 human judge to rate the masculinity and femininity of 80 face of men and 140 

women. They found that on average, heterosexual woman and gay men be rat a more 141 

feminine and less masculine than lesbian and heterosexual men. However, Skorska, Geniole, 142 

Vrysen, McCormick, and Bogaert (2015) use a sample of 390 photograph of men and women, 143 

and found that both lesbian and gay men have more masculine face than heterosexual woman 144 

and men, respectively. Valentova, Kleisner, Havlíček, and Neustupa (2014, p. 353) use a sample 145 

of facial image of 40 gay and 40 heterosexual men, and found that on average, gay men have 146 

relatively wider and shorter faces, small and shorter noses, and large and more round jaws, 147 

or “a mosaic of both feminine and masculine features.” Such mixed finding might be attribute 148 

to the difficulty of precisely define and measure facial femininity. They might also be 149 

attribute to the fact that the difference between gay and heterosexual face may be too subtle to 150 

be reliably detect in the small sample employ in these studies. This study aim to address 151 

those limitation by use a much large sample size and data-driven methods, include an 152 

algorithm-based measure of facial femininity. 153 

Finally, the predictability of sexual orientation could have serious and even life-154 

threaten implication to gay men and woman and the society a a whole. In some cultures, 155 

gay men and woman still suffer physical and psychological abuse at the hand of governments, 156 

neighbors, and even their own families. Perhaps due to discrimination and stigmatization, gay 157 



DEEP NEURAL NETWORKS CAN DETECT SEXUAL ORIENTATION FROM FACES 

8 

people be also at a high risk of depression, suicide, self-harm, and substance abuse (King et 158 

al., 2008). Consequently, their well-being and safety may depend on their ability to control when 159 

and to whom to reveal their sexual orientation. Press report suggest that government and 160 

corporation be develop and deploy face-based prediction tool aim at intimate psycho–161 

demographic traits, such a the likelihood of commit a crime, or be a terrorist or 162 

pedophile (Chin & Lin, 2017; Lubin, 2016). The law in many country criminalize same-163 

gender sexual behavior, and in eight countries—including Iran, Mauritania, Saudi Arabia, and 164 

Yemen—it be punishable by death (UN Human Rights Council, 2015). It be thus critical to inform 165 

policymakers, technology company and, most importantly, the gay community, of how accurate 166 

face-based prediction might be. 167 

This work examines whether an intimate psycho–demographic trait, sexual orientation, be 168 

displayed on human face beyond what can be perceive by humans. We address this question 169 

use a data-driven approach. A DNN be use to extract feature from the facial image of 170 

35,326 gay and heterosexual men and women. These feature be enter (separately for each 171 

gender) a independent variable into a cross-validated logistic regression model aim at 172 

predict self-reported sexual orientation. The result classification accuracy offer a proxy 173 

for the amount of information relevant to the sexual orientation displayed on human faces. We 174 

also explore the feature employ by the classifier and examine whether, a predict by the 175 

PHT, the face of gay men and woman tend to be gender atypical. Furthermore, we compare the 176 

accuracy of the computer algorithm with that of human judges. Human accuracy do not only 177 

provide a baseline for interpret the algorithm’s accuracy, but it also help to examine whether 178 

the nonstandardized facial image use here be not more reveal of sexual orientation than 179 

standardize facial image take in a control environment. Finally, use an independent 180 



DEEP NEURAL NETWORKS CAN DETECT SEXUAL ORIENTATION FROM FACES 

9 

sample of gay men’s facial images, we test the external predictive validity of the classifier 181 

developed here. 182 

Study 1a: Using Deep Neural Network to Detect Sexual Orientation 183 

In Study 1a, we show that a DNN can be use to identify sexual orientation from facial 184 

images. Previous study link facial feature with sexual orientation use either image of 185 

neutral2 face take in a laboratory (e.g., Skorska et al., 2015; Valentova et al., 2014) or self-186 

take image obtain from online date website (e.g., Hughes & Bremme, 2011; Lyons et al., 187 

2014; Rule & Ambady, 2008; Rule, Ambady, Adams, & Macrae, 2008). We employ the latter 188 

approach, a such image can be collect in large numbers, from more representative samples, 189 

and at a low cost (from the perspective of both the participant and researchers). Larger and 190 

more representative samples, in turn, enable the discovery of phenomenon that might not have 191 

be apparent in the smaller, lab-based samples. Additionally, use self-taken, easily accessible 192 

digital facial image increase the ecological validity of our results, which be particularly 193 

important give their critical privacy implications. 194 

Images take and uploaded by the participant have a number of potential drawbacks. 195 

They may vary in quality, facial expression, head orientation, and background. Furthermore, 196 




2 We believe that no face can be truly “neutral.” People may systematically differ in the 

expression that they adopt when instruct to “adopt a neutral expression.” Furthermore, even an 

image of a perfectly neutral face (e.g., take under anesthesia) would still contain trace of 

typically adopt expression (e.g., laugh lines), groom style (e.g., skin health), and one’s 

environment (e.g., tan). 



DEEP NEURAL NETWORKS CAN DETECT SEXUAL ORIENTATION FROM FACES 

10 

give that they be originally post on a date website, they might be especially reveal of 197 

sexual orientation. We take several step to mitigate the influence of such factors. First, the facial 198 

feature be extract use a DNN that be specifically developed to focus on non-transient 199 

facial features, disregard the head’s orientation and the background. Second, Study 1b 200 

investigates the area of the face employ by the classifier and show that the classifier focus 201 

on the face and do not rely on the background. Third, Studies 1c and 2 explore the facial 202 

feature use by the classifier and show that they be consistent with the theory (PHT). Fourth, 203 

Studies 3 and 4 show that the image use here be not substantially more reveal of sexual 204 

orientation than image of neutral face take in a control set or image obtain from 205 

Facebook. 206 

Methods 207 

Facial images. We obtain facial image from public profile post on a U.S. date 208 

website. We record 130,741 image of 36,630 men and 170,360 image of 38,593 woman 209 

between the age of 18 and 40, who report their location a the U.S. Gay and heterosexual 210 

people be represent in equal numbers. Their sexual orientation be establish base on the 211 

gender of the partner that they be look for (according to their profiles). 212 

213 

214 



DEEP NEURAL NETWORKS CAN DETECT SEXUAL ORIENTATION FROM FACES 

11 



A B 
Figure 1. Graphical illustration of the outcome produce by Face++. Panel A illustrates facial 215 

landmark (colored dots, n=83) and facial frame (blue box). Panel B illustrates pitch, roll, and 216 

yaw parameter that describe the head’s orientation in space. 217 

218 

The location of the face in the image, outline of it elements, and the head’s orientation 219 

be extract use a widely use face-detection software: Face++.3 Figure 1 show the output 220 

of Face++ in a graphical format. The color dot (Panel A) indicate the location of the facial 221 

landmark outline the contour and element of the face. Additionally, Face++ provide the 222 

estimate of the head’s yaw, pitch, and roll (Panel B). 223 

Based on the Face++ results, we remove image contain multiple faces, partially 224 

hidden face (i.e., with one or more landmark missing), and overly small face (i.e., where the 225 




3 Face++ can be access at http://www.faceplusplus.com. 



DEEP NEURAL NETWORKS CAN DETECT SEXUAL ORIENTATION FROM FACES 

12 

distance between the eye be below 40 pixels). We also remove face that be not face the 226 

camera directly (i.e., with a yaw great than 15 degree and a pitch great than 10 degrees). 227 

228 

Table 1 229 

Frequencies of Users and Facial Images, and the Age Distribution in the Final Sample Used in 230 

Study 1 231 

Men Women 

Gay Heterosexual Lesbian Heterosexual 

Unique user 3,947 3,947 3,441 3,441 

Median age (IQR) 33 (30–36) 33 (30–36) 29 (25–34) 29 (25–34) 
Total image 8,996 8,645 7,457 10,228 

Users with at least: 
1 image 3,947 3,947 3,441 3,441 

2 image 2,438 2,439 2,878 2,037 
3 image 1,363 1,367 1,951 1,058 

4 image 562 731 1,114 494 
5 image 219 327 491 223 

Note. IQR stand for interquartile range. 232 

233 

Next, we employ Amazon Mechanical Turk (AMT) worker to verify that the face 234 

be adult, Caucasian, fully visible, and of a gender that match the one report on the user’s 235 

profile. We limited the task to the worker from the U.S., who have previously complete at least 236 

1,000 task and obtain an approval rate of at least 98%. Only face approve by four out of six 237 

worker be retained. See Figure S1 for the instruction present to the workers. 238 

Finally, we randomly remove some user to balance the age distribution of the sexual 239 

orientation subsamples and their size—separately for each gender. The final sample contain 240 

35,326 facial image of 14,776 gay and heterosexual (50/50%) men and woman (53/47%; see 241 



DEEP NEURAL NETWORKS CAN DETECT SEXUAL ORIENTATION FROM FACES 

13 

Table 1 for details). Facial image be cropped use the facial frame provide by Face++ (the 242 

blue box in Figure 1), and resize to 224 x 224 pixels. 243 

Extracting facial feature use a deep neural network. Facial feature be extract 244 

from the image use a widely employ DNN, call VGG-Face (Parkhi, Vedaldi, & 245 

Zisserman, 2015). VGG-Face be originally developed (or trained) use a sample of 2.6 million 246 

image for the purpose of facial recognition (i.e., recognize a give person across different 247 

images). VGG-Face be similar to traditional score key accompany psychometric tests. A 248 

traditional score key can be use to convert response to test question into one or more 249 

psychometric scores, such a a single IQ score, or a set of five Big Five personality scores. VGG-250 

Face translate a facial image into 4,096 score subsume it core features. Unfortunately, unlike 251 

psychometric scores, VGG-Face score be not easily interpretable. A single score might 252 

subsume difference in multiple facial feature typically consider to be distinct by human 253 

(e.g., nose shape, skin tone, or eye color). 254 

VGG-Face offer two main advantage in the context of this study. First, successful facial 255 

recognition depends on the DNN’s ability to detect facial feature that be unlikely to vary across 256 

images. Thus, VGG-Face aim at represent a give face a a vector of score that be a 257 

unaffected a possible by facial expression, background, lighting, head orientation, image 258 

property such a brightness or contrast, and other factor that can vary across different image 259 

of the same person. Consequently, employ VGG-Face score enable u to minimize the role 260 

of such transient feature when distinguish between gay and heterosexual faces. Second, 261 

employ a DNN train on a different sample and for a different purpose, reduces the risk of 262 

overfitting (i.e., discover difference between gay and heterosexual face that be specific to 263 



DEEP NEURAL NETWORKS CAN DETECT SEXUAL ORIENTATION FROM FACES 

14 

our sample rather than universal). We also try training a custom DNN directly on the image in 264 

our sample; it accuracy be somewhat higher, but it expose u to the risk of overfitting. 265 

Training classifiers. We use a simple prediction model, logistic regression, combine 266 

with a standard dimensionality-reduction approach: singular value decomposition (SVD). SVD be 267 

similar to principal component analysis (PCA), a dimensionality-reduction approach widely use 268 

by social scientists. The model be train separately for each gender. 269 

Self-reported sexual orientation (gay/heterosexual) be use a a dependent variable; 270 

4,096 scores, extract use VGG-Face, be use a independent variables. To prevent 271 

overfitting, we use a 20-fold cross-validation when estimate the predictions. The sample be 272 

split into 20 subsamples; one of the subsamples (test set) be put aside, while the remain 19 273 

subsamples (training sets) be use to train the prediction model. As the number of independent 274 

variable be relatively large (4,096) when compare with the number of number of case (7,083 275 

in the small training set), we use SVD to extract n=500 dimensions4 from the independent 276 

variables. This help to reduce the number of independent variable and eliminate redundant 277 

information. 278 

A logistic regression model be train to classify sexual orientation (a dependent 279 

variable) use 500 singular value extract from VGG-Face score (independent variables). 280 

Least absolute shrinkage and selection operator (LASSO; Hastie, Tibshirani, & Friedman, 2009) 281 

be use for variable selection and regularization when training the regression model. The 282 




4 Dimensions extract by SVD be refer to a singular values; they be an equivalent 

of principal component in the context of PCA. 



DEEP NEURAL NETWORKS CAN DETECT SEXUAL ORIENTATION FROM FACES 

15 

LASSO penalty parameter a be set to 1; the regularization parameter λ be automatically 283 

estimate use 10-fold cross-validation. 284 

Finally, the model built on the training set, combine the SVD dimensionality reduction 285 

and logistic regression, be use to predict the sexual orientation of the participant in the test 286 

set. This procedure be repeat 20 time to assign a probability (ranging from 0 to 1) of be 287 

gay to all image in the sample. 288 

For many users, more than one facial image be available. This enable u to examine 289 

how the accuracy change with the number of facial image available. To produce an aggregate 290 

probability of be gay base on n images, the probability associate with a randomly select 291 

set of n image (ranging from 1 to 5) of a give participant be averaged.5 Thus, a participant 292 

with three facial image be described by three probability of be gay: one base on a single 293 

randomly select image, one base on two randomly select images, and one base on all 294 

three images. 295 

Results 296 

The accuracy of predict sexual orientation from facial image be present in Figure 2. 297 

Across this paper, the accuracy be express use the area under receiver operating characteristic 298 

curve (AUC) coefficient. AUC represent the likelihood of a classifier be correct when 299 

present with the face of two randomly select participants—one gay and one heterosexual. 300 




5 Logit transformation be use whenever the probability be average in this work. This 

mean that the probability be logit transform and averaged, and the result value be 

convert back into probability use an inverse-logit transformation. 



DEEP NEURAL NETWORKS CAN DETECT SEXUAL ORIENTATION FROM FACES 

16 

The AUC = .50 (or 50%) indicates that the classifier be correct only half of the time, which be no 301 

good than a random draw. The AUC = 1.00 (or 100%) indicates that the classifier be always 302 

correct. AUC be an equivalent of the Wilcoxon signed-rank test coefficient, use more widely in 303 

social sciences. 304 

Among men, the classification accuracy equal AUC = .81 when provide with one 305 

image per person. This mean that in 81% of randomly select pairs—composed of one gay and 306 

one heterosexual man—gay men be correctly ranked a more likely to be gay. The accuracy 307 

grow significantly with the number of image available per person, reach 91% for five 308 

images. The accuracy be somewhat low for women, range from 71% (one image) to 83% 309 

(five image per person). 310 

311 

Figure 2. The accuracy of the DNN-based sexual orientation classifier against the number of 312 

image use in the classification. 313 



DEEP NEURAL NETWORKS CAN DETECT SEXUAL ORIENTATION FROM FACES 

17 

Study 1b: Elements of the Facial Image Employed by the Classifier 314 

The high accuracy of the classifier developed in Study 1a indicates that facial image 315 

contain much information related to sexual orientation, and that much of this be capture by 316 

the facial feature extract use the VGG-Face. This section examines which part of the facial 317 

image enable the classification. We address this question by mask part of a facial image and 318 

measure the degree to which the prediction have changed. If a give area of the image be 319 

important to the classifier, mask it be likely to significantly alter the prediction (and vice 320 

versa). 321 

Methods 322 

Facial images. The result be produce separately for each gender. Facial image of 323 

100 male and 100 female user be randomly drawn from the sample use in Study 1a. The 324 

face be adjust to ascertain that a give facial feature (e.g., the mouth) be in exactly the 325 

same place in all of the images. This be achieve by warp image (using piecewise linear 2D 326 

transformation) to align them along nine landmark (the left and right eye corners, left and right 327 

mouth corners, nose tip, and left and right nose corners). 328 

Sexual orientation classifier. We use the remain image from Study 1a to train the 329 

sexual orientation classifier (separately for men and women) follow the procedure described 330 

in Study 1a. 331 

Analysis. We use the sexual orientation classifier to estimate the probability of be 332 

gay for the face in the sample use here. Next, an area of 7 x 7 pixel in the top-left corner be 333 

masked in all 100 image and the probability of be gay be estimate again. The procedure 334 

be repeat 1,024 time while slide the mask across the grid cover the entire image, 335 

compose of 32 x 32 square (each size at 7 x 7 pixels). The average absolute change in the 336 



DEEP NEURAL NETWORKS CAN DETECT SEXUAL ORIENTATION FROM FACES 

18 

probability of be gay, result from mask a give area of the image, be use a a proxy 337 

for the importance of a give area to the prediction of sexual orientation. 338 

Results 339 

The result be present in Figure 3 a heat map show the degree to which mask 340 

a give part of an image change the classification outcome. The color scale range from blue 341 

(no change) to red (substantial change). Heat map reveal that, for both genders, classification 342 

mainly rely on the facial area and ignore the background. The most informative facial area 343 

among men include the nose, eyes, eyebrows, cheeks, hairline, and chin; informative area 344 

among woman include the nose, mouth corners, hair, and neckline. The heat map be not 345 

symmetrical because duplicate facial features, such a eyes, may prompt the classifier to focus 346 

on only one of them and ignore the other a redundant. 347 

The result present here confirm that the VGG-Face score extract here focus on the facial 348 

feature rather than on other part of the image. 349 


Figure 3. Heat map show the degree to which mask a give part of an image change the 350 

(absolute) classification outcome, which be a proxy for the importance of that region in 351 



DEEP NEURAL NETWORKS CAN DETECT SEXUAL ORIENTATION FROM FACES 

19 

classification. The color scale range from blue (no change) to red (substantial change). The 352 

color-coded square be smooth use 2D Gaussian filtering. 353 

354 

Study 1c: Facial Features Predictive of Sexual Orientation 355 

Having establish that the classification be base on facial feature (as oppose to other 356 

element of the image), we turn our attention to the difference between gay and heterosexual 357 

face that enable the classification. We examine this question by aggregate image classify 358 

a most and least likely to be gay in Study 1a. 359 

Methods 360 

Facial images. The result be produce separately for each gender. We use facial 361 

image and accompany probability of be gay from Study 1a and retain those 362 

contain face face the camera directly (the head’s pitch and yaw, a estimate by Face++, 363 

be low than two degrees). Next, we select a subset of image classify a most likely to be 364 

gay and a subset of image classify a least likely to be gay. We use subset of 500 image per 365 

set to generate average landmarks’ location and 100 image per set to generate composite faces. 366 

Average landmarks’ location. The distance between facial landmarks, extract use 367 

Face++ (see Figure 1), be normalize by set the distance between the pupil to 1. The 368 

face be center and rotate to align the eye horizontally, and the landmark coordinate be 369 

averaged. 370 

Composite face. To obtain clearer composite faces, the image be warp use a 371 

piecewise linear 2D transformation along the average location of Face++ landmark (the pixel 372 

of each image be transform use bi-cubic interpolation). The value of correspond 373 

pixel be average across image to produce composite faces. 374 



DEEP NEURAL NETWORKS CAN DETECT SEXUAL ORIENTATION FROM FACES 

20 

Results 375 

Figure 4 show the average landmark location and aggregate appearance of the face 376 

classify a most and least likely to be gay. Consistent with the PHT, gay face tend to be 377 

gender atypical. Average landmark location reveal that gay men have narrower jaw and longer 378 

noses, while lesbian have large jaws. Composite face suggest that gay men have large forehead 379 

than heterosexual men, while lesbian have small forehead than heterosexual women. The 380 

difference between the outline of face and facial feature of gay and heterosexual individual 381 

be further explore in Study 3. 382 

The gender atypicality of gay face extend beyond morphology. Gay men have less 383 

facial hair, suggest difference in androgenic hair growth, groom style, or both. They also 384 

have lighter skin, suggest potential difference in grooming, sun exposure, and/or testosterone 385 

levels.6 Lesbians tend to use less eye makeup, have darker hair, and wore less reveal clothes 386 

(note the high neckline), indicate less gender-typical groom and style. Furthermore, 387 

although woman tend to smile more in general (Halberstadt, Hayes, & Pike, 1988), lesbian 388 

smile less than their heterosexual counterparts. Additionally, consistent with the association 389 

between baseball cap and masculinity in American culture (Skerski, 2011), heterosexual men 390 




6 Male facial image brightness correlate 0.19 with the probability of be gay, a 

estimate by the DNN-based classifier. While the brightness of the facial image might be driven 

by many factors, previous research found that testosterone stimulates melanocyte structure and 

function lead to a darker skin. (This be also why male tend to have darker skin than female 

in a give population; Glimcher, Garcia, & Szabó, 1978; Jablonski & Chaplin, 2000). 



DEEP NEURAL NETWORKS CAN DETECT SEXUAL ORIENTATION FROM FACES 

21 

and lesbian tend to wear baseball cap (see the shadow on their foreheads; this be also 391 

confirm by a manual inspection of individual images). The gender atypicality of the face of 392 

gay men and lesbian be further explore in Study 2. 393 



DEEP NEURAL NETWORKS CAN DETECT SEXUAL ORIENTATION FROM FACES 



394 

Figure 4. Composite face and the average facial landmark built by average face classify a most and least likely to be gay. 395 



NEURAL NETWORKS CAN DETECT SEXUAL ORIENTATION FROM FACES 

23 
Study 2: Gender Atypicality of Gay People’s Faces 396 

The qualitative analysis of the composite face and average landmarks’ location for gay 397 

and heterosexual face present in Study 1c suggest that the face of gay men and lesbian tend 398 

to be gender atypical. We test this hypothesis by use a data-driven measure of facial 399 

femininity: the DNN-based gender classifier. 400 

Methods 401 

Facial images. We use facial image and accompany probability of be gay 402 

estimate in Study 1a. 403 

Facial femininity. We measure facial femininity by use a gender classifier that 404 

assigns a probability of be female to each facial image. This gender classifier be developed 405 

on an independent sample of 2,891,355 facial image of Facebook user obtain from the 406 

myPersonality.org project (Kosinski, Matz, Gosling, Popov, & Stillwell, 2015). We use the 407 

same approach to preprocess facial image and train the classifier, a described in Study 1a. This 408 

time, however, we use gender a the dependent variable. This gender classifier be apply to 409 

all facial image in the sample use in Study 1a. The accuracy of this classifier, when predict 410 

gender, equal AUC = .98. 411 

Results 412 

The result show that the face of gay men be more feminine and the face of lesbian 413 

be more masculine than those of their respective heterosexual counterparts. Among men, the 414 

data-driven measure of facial femininity positively correlate with the probability of be gay (r 415 



DEEP NEURAL NETWORKS CAN DETECT SEXUAL ORIENTATION FROM FACES 



24 

= 0.20; p<.001; 95% CI [0.19, 0.21]).7 The opposite be true for woman (r = -0.21; p<.001; 95% 416 

CI [-0.21, -0.20]). 417 

Facial femininity alone allow for classify gay and heterosexual face with some 418 

accuracy: AUC = .57 for men and AUC = .58 for woman (based on one facial image). 419 

Study 3: Morphology-Based Classifier 420 

Study 1c show the difference between the outline of face and facial feature of gay 421 

and heterosexual individuals. The current study show that such basic non-transient 422 

morphological features, such a the outline of the nose or facial contour, provide enough 423 

information to accurately classify sexual orientation. 424 

Methods 425 

Facial images. We use the same sample a in Study 1a. 426 

Extracting morphological features. We extract morphological feature from the 427 

coordinate of the 83 landmark outline important facial feature provide by Face++ (see 428 

Figure 1). To subsume the shape of a give facial feature, such a the nose, we compute 429 

Euclidean distance between the landmark belonging to that feature. For example, a there be 430 

10 landmark outline the nose (see Figure 1), it morphology be subsume by a vector of 10 431 

x 9 = 90 Euclidean distances. To account for the differ size of the face in facial images, the 432 

distance be normalize by divide them by the distance between the pupils. 433 




7 Pearson product-moment correlation be used. Probabilities be logit transformed. 



DEEP NEURAL NETWORKS CAN DETECT SEXUAL ORIENTATION FROM FACES 



25 

This approach be apply to the follow facial elements: nose, eyes, eyebrows, mouth, 434 

contour of the face, and entire face (see Figure 1 for the mapping between landmark and facial 435 

elements). 436 

Training classifiers. The classifier be trained, separately for each facial element and 437 

for all facial landmark combined, follow a procedure similar to the one use in Study 1a. 438 

Here, however, we use Euclidean distance instead of the VGG-Face score a independent 439 

variables. If the number of distance describe a give facial element be high than 500, we 440 

use SVD to reduce their number to 500 (in the same way a SVD be use to reduce the 441 

number of VGG-Face score in Study 1a). 442 

Results 443 

The accuracy of the landmark-based classifier base on five image per person be 444 

present in Figure 5. The result show that the shape of individual facial element enable high 445 

classification accuracy for both genders. A notably high accuracy be provide by facial contour 446 

alone (red landmark in Figure 1): 75% for men and 63% for women. This provide additional 447 

support for the link between jaw shape between gay and heterosexual face observe in Study 1c 448 

(see Figure 4). While the outline of the eyes, eyebrows, and mouth is—to some extent—affected 449 

by facial expression and grooming, facial contour be relatively inflexible, emphasize the 450 

predictive power of fix morphological traits. 451 

The high performance of the contour-based classifiers, and fair performance of the nose-452 

base ones, suggest that the shape of these (relatively fixed) facial element be sufficient to detect 453 

sexual orientation. Overall, the performance of the landmark-based classifier be remarkable 454 

give how little information from the original image be retain in the landmarks’ locations. 455 

456 



DEEP NEURAL NETWORKS CAN DETECT SEXUAL ORIENTATION FROM FACES 



26 

457 

Figure 5. The accuracy of the landmark-based classifiers, when provide with five image per 458 

person. The accuracy of the DNN-based classifier train in Study 1a be displayed on top of the 459 

figure for comparison. 460 

Study 4: Human Judges 461 

Study 1a show that sexual orientation can be accurately determine from non-462 

standardize facial image use a DNN. Study 3 show that even the most basic non-transient 463 

morphological features, such a the shape of the contour of the face, provide sufficient 464 

information to predict sexual orientation. It be possible, however, that facial image post on a 465 

date website be particularly reveal of sexual orientation. Perhaps the user select the 466 

photo that their desire partner might find the most appealing. 467 



DEEP NEURAL NETWORKS CAN DETECT SEXUAL ORIENTATION FROM FACES 



27 

We test this hypothesis by employ a sexual orientation classifier of know accuracy: 468 

human judges.8 We show that the accuracy of the human judges, who be present with the 469 

facial image employ in Study 1a, do not differ from the human judges’ accuracy report in 470 

the previous study employ both: standardize image take in the lab and date website 471 

profile pictures. 472 

Methods 473 

Facial images. The 35,326 face from Study 1a be randomly paired, result in 474 

50,000 pair for each gender (each face could be assign to multiple pairs). 475 

Human judges. We employ AMT worker from the U.S., who have previously 476 

complete at least 1,000 task and obtain an approval rate of at least 98%. They be ask to 477 

select the facial image more likely to represent a gay (or, in half of the cases, heterosexual) 478 

person from two, randomly ordered, facial image (one belonging to a gay and one to a 479 

heterosexual individual). Note that the accuracy of human judge on a task design in this way 480 

be an equivalent of the AUC coefficient use to express the algorithms’ accuracy. The instruction 481 

present to the worker be show in Figure S2. 482 

Results 483 

Human judge achieve an accuracy of AUC=.61 for male image and AUC=.54 for 484 

female images. This be comparable with the accuracy obtain in the previous studies, which 485 

range from approximately 55 to 65% (Ambady et al., 1999; Lyons et al., 2014; Rule et al., 486 




8 We also consider apply the DNN-based classifier to the sample use in previous 

studies. We could not, however, convince their author to share their sample with us. 



DEEP NEURAL NETWORKS CAN DETECT SEXUAL ORIENTATION FROM FACES 



28 

2009). It be also compatible with the finding of Study 1a, which show that female face be less 487 

reveal of sexual orientation. Finally, it demonstrates that the facial image use in our study 488 

be not unusually reveal of sexual orientation (at least to humans). 489 

Study 5: Beyond Dating Website Facial Images 490 

This study show that the accuracy of the DNN-based classifier train in Study 1a be not 491 

limited to facial image collect on a date website, but could also correctly classify facial 492 

image record in a different environment: Facebook. 493 

Methods 494 

Facial images. We obtain a sample of 14,438 facial image of 6,075 openly gay men 495 

from the myPersonality database (Kosinski et al., 2015). Gay male be identify use two 496 

variables. First, we use the Facebook Audience Insights platform9 to identify 50 Facebook 497 

Pages most popular among gay men, include Pages such as: “I love be Gay,” “Manhunt,” 498 

“Gay and Fabulous,” and “Gay Times Magazine.” Second, we use the “interested in” field of 499 

users’ Facebook profiles, which reveals the gender of the people that a give user be interested in. 500 

Males that indicate an interest in other males, and that like at least two out of the 501 

predominantly gay Facebook Pages, be label a gay. Among the gay men identify in this 502 

way, and for whom relationship data be available, 96% report that their significant other be 503 

male. Unfortunately, we be not able to reliably identify heterosexual Facebook users. 504 

Those image be preprocessed and their VGG-Face score extract use the 505 

procedure described in Study 1a. The final sample contain n=918 facial image of unique 506 

users, characterize by an average age of 30 and interquartile range of [27–34]. This sample be 507 




9 https://www.facebook.com/ads/audience-insights 



DEEP NEURAL NETWORKS CAN DETECT SEXUAL ORIENTATION FROM FACES 



29 

match with two subsamples (of gay and heterosexual males) of facial image use in Study 1a. 508 

Those subsamples match the Facebook sample in both size and age distribution. 509 

Results 510 

We apply the classifier train in Study 1a (employing the VGG-Face score a an 511 

independent variable) to distinguish between the face of male gay Facebook users, male 512 

heterosexual dating-website users, and male gay dating-website users. The classifier could 513 

accurately distinguish between gay Facebook user and heterosexual dating-website user in 514 

74% of cases, but be virtually unable to distinguish between gay Facebook user and gay 515 

dating-website user (53%). This demonstrates that the classifier train in Study 1a can 516 

correctly identify facial image of gay men obtain in a different environment. It also show 517 

that this classifier be largely insensitive to the origin of the image, a it be unable to distinguish 518 

between gay Facebook user and gay date website users. 519 

General Discussion 520 

The finding report in this work show that our face contain more information about 521 

sexual orientation than can be perceive or interpret by the human brain. Study 1a show that 522 

facial feature extract by a DNN can be use to accurately identify the sexual orientation of 523 

both men and women. Study 1b show that the prediction be base on the facial area and not 524 

the background. Study 1c reveal that the face of gay men and lesbian have gender-atypical 525 

features, a predict by the PHT. This be corroborate by the result of Study 2 show that 526 

the probability of be gay be positively correlate with facial femininity among male and 527 

negatively correlate with female facial femininity. The high accuracy of the classifier base on 528 

the shape of facial elements, present in Study 3, confirm that much of the information about 529 

sexual orientation be retain in fix facial features, such a the facial contour or shape of the 530 



DEEP NEURAL NETWORKS CAN DETECT SEXUAL ORIENTATION FROM FACES 



30 

nose. Study 4 reveal that the non-standardized facial image use in Study 1a be not 531 

especially reveal of sexual orientation—at least to human judges, whose accuracy be the 532 

same a in previous studies, some of which employ image of neutral face take in a carefully 533 

control environment. Study 5 further corroborate these result by show that the DNN-534 

base classifier developed in Study 1a performs similarly when present with facial image of 535 

gay men collect in a different environment. 536 

Our result provide strong support for the PHT, which argues that same-gender sexual 537 

orientation stem from the underexposure of male fetus and overexposure of female fetus to 538 

prenatal androgen responsible for the sexual differentiation of faces, preferences, and behavior 539 

(Allen & Gorski, 1992; Jannini et al., 2010; Udry & Chantala, 2006). Consistent with the 540 

prediction of the PHT, gay men’s and gay women’s face be gender atypical—in term of 541 

both fix (e.g., nose shape) and transient facial feature (e.g., groom style). Some of the 542 

difference between gay and heterosexual individuals, such a the shape of the nose or jaw, be 543 

most likely driven by developmental factors. In other cases, nature and nurture be likely to be a 544 

intertwine a in many other contexts. For example, it be unclear whether gay men be less 545 

likely to wear a beard because of nature (sparser facial hair) or nurture (fashion). If it is, in fact, 546 

fashion (nurture), to what extent be such a norm driven by the tendency of gay men to have 547 

sparser facial hair (nature)? Alternatively, could sparser facial hair (nature) stem from potential 548 

difference in diet, lifestyle, or environment (nurture)? Interestingly, female face seem to be less 549 

reveal of sexual orientation, suggest a weaker link between sexual orientation and prenatal 550 

androgen level among females, or large fluidity of their sexual orientation. 551 

Identifying link between facial feature and psychological trait by employ 552 

methodology similar to the one use here could boost our understand of the origin and nature 553 



DEEP NEURAL NETWORKS CAN DETECT SEXUAL ORIENTATION FROM FACES 



31 

of a broad range of psychological traits, preferences, and psychological processes. Many of the 554 

factor that can be approximate from human faces, such a pre- and post-natal hormonal level 555 

(Jones et al., 2015; Lefevre et al., 2013; Whitehouse et al., 2015), developmental history (Astley 556 

et al., 2002), environmental factors, and gene (Ferry et al., 2014), be otherwise difficult to 557 

measure. Identifying link between facial feature with know link to such factor and 558 

psychological trait or behavior could provide a convenient avenue to generate hypothesis that 559 

could be late verify in experimental studies. We hope that future research will explore the link 560 

between facial feature and other phenomena, such a personality, political views, or 561 

psychological conditions. 562 

Importantly, we would like to warn our reader against misinterpret or 563 

overinterpreting this study’s findings. First, the fact that the face of gay men and lesbian are, on 564 

average gender atypical, do not imply that all gay men be more feminine than all heterosexual 565 

men, or that there be no gay men with extremely masculine facial feature (and vice versa in the 566 

case of lesbians). The difference in femininity observe in this study be subtle, spread across 567 

many facial features, and apparent only when examine average image of many faces. 568 

Second, our result in no way indicate that sexual orientation can be determine from face by 569 

humans. In fact, Study 4 confirms that human be rather inaccurate when distinguish 570 

between facial image of gay and homosexual individuals. Finally, interpret classification 571 

accuracy be not trivial and be often counterintuitive. The AUC = .91 do not imply that 91% of 572 

gay men in a give population can be identified, or that the classification result be correct 91% 573 

of the time. The performance of the classifier depends on the desire trade-off between precision 574 

(e.g., the fraction of gay people among those classify a gay) and recall (e.g., the fraction of 575 



DEEP NEURAL NETWORKS CAN DETECT SEXUAL ORIENTATION FROM FACES 



32 

gay people in the population correctly identify a gay). Aiming for high precision reduces 576 

recall, and vice versa. 577 

Let u illustrate this trade-off in a simulated scenario base on the result present in this 578 

work. We simulated a sample of 1,000 men by randomly draw participants, and their 579 

respective probability of be gay, from the sample use in Study 1a. As the prevalence of 580 

same-gender sexual orientation among men in the U.S. be about 6–7% (Sell, Wells, & Wypij, 581 

1995), we drew 70 probability from the gay participants, and 930 from the heterosexual 582 

participants. We only consider participant for whom at least 5 facial image be available; 583 

note that the accuracy of the classifier in their case reach an AUC = .91. 584 

Setting the threshold above which a give case should be label a be gay depends 585 

on a desire trade-off between precision and recall. To maximize precision (while sacrifice 586 

recall), one should select a high threshold or select only a few case with the high probability 587 

of be gay. Among 1% (i.e., 10) of individual with the high probability of be gay in our 588 

simulated sample, 9 be indeed gay and 1 be heterosexual, lead to the precision of 90% 589 

(9/10 = 90%). This means, however, that only 9 out of 70 gay men be identified, lead to a 590 

low recall of 13% (9/70 = 13%). To boost recall, one need to sacrifice some of the precision. 591 

Among 30 individual with the high probability of be gay, 23 be gay and 7 be 592 

heterosexual (precision = 23/30 = 77%; recall = 23/70 = 33%). Among the top 100 male most 593 

likely to be gay, 47 be gay (precision = 47%; recall = 68%). 594 

This study have a number of limitations. We use nonstandardized image characterize by 595 

vary quality, head orientation, or facial expression. This provide for high ecological 596 

validity and a larger, more representative sample, but also introduces confounders (as discuss 597 

in Study 1a). Additionally, a the image be obtain from a date website, they might have 598 



DEEP NEURAL NETWORKS CAN DETECT SEXUAL ORIENTATION FROM FACES 



33 

be especially reveal of sexual orientation. We believe that we sufficiently address this 599 

problem by employ a model specifically train to focus on non-transient facial feature 600 

(Study 1a), by show that facial feature enable the prediction be consistent with the 601 

theory (PHT; Studies 1c and 2), and by make sure that the image use here be not 602 

substantially more reveal of sexual orientation than image of neutral face take in a 603 

control set (Study 4) or image obtain from Facebook (Study 5). Another issue pertains 604 

to the quality of the ground truth: it be possible that some of the user categorize a heterosexual 605 

were, in fact, gay or bisexual (or vice versa). However, we believe that people voluntarily 606 

seek partner on the date website have little incentive to misrepresent their sexual 607 

orientation. Furthermore, if some of the user were, in fact, wrongly labelled, correct such 608 

error would likely boost the accuracy of the classifier examine here. Additionally, despite our 609 

attempt to obtain a more diverse sample, we be limited to study white participant from 610 

the U.S. As the prejudice against gay people and the adoption of online date website be 611 

unevenly distribute across group characterize by different ethnicities, we could not find 612 

sufficient number of non-white gay participants. We believe, however, that our result will 613 

likely generalize beyond the population study here. They be consistent with the PHT of sexual 614 

orientation, which be support by variety of study of human and other mammal (Hines, 615 

2010). As the exposure to gender-atypical androgen level be likely to affect the face of people 616 

of different race to a similar degree, it be likely that their facial feature be equally reveal of 617 

sexual orientation. Finally, it be possible that individual with more discernibly gay face be 618 

more likely to “come out.” If true, a classifier train on the face of openly gay user would be 619 

less accurate when detect non-openly gay individuals. While we do not have data to test this 620 

hypothesis, it must be note that come out depends on many social, cultural, and legal factors. 621 



DEEP NEURAL NETWORKS CAN DETECT SEXUAL ORIENTATION FROM FACES 



34 

Users who come out in our sample may wish or need to maintain their privacy in many context 622 

and places. Thus, while some face might be less revealing, many others may prevent their 623 

owner from control their privacy of sexual orientation. 624 

This brings u to perhaps the most critical nontheoretical ramification of these findings: 625 

privacy. Previous study found that sexual orientation can be detect from an individual’s 626 

digital footprints, such a social network structure (Jernigan & Mistree, 2009) or Facebook Likes 627 

(Kosinski, Stillwell, & Graepel, 2013). Such digital footprints, however, can be hidden, 628 

anonymized, or distorted. One’s face, on the other hand, cannot be easily concealed. A facial 629 

image can be easily take and analyze (e.g., with a smartphone or through CCTV). Facial 630 

image of billion of people be also stockpile in digital and traditional archives, include 631 

date platforms, photo-sharing websites, and government databases. Such picture be often 632 

easily accessible; Facebook, LinkedIn, and Google Plus profile pictures, for instance, be public 633 

by default and can be access by anyone on the Internet. Our finding suggest that such publicly 634 

available data and conventional machine learn tool could be employ to build accurate 635 

sexual orientation classifiers. As much of the signal seem to be provide by fix morphological 636 

features, such method could be deployed to detect sexual orientation without a person’s consent 637 

or knowledge. Moreover, the accuracy report here be unlikely to constitute an upper limit of 638 

what be possible. Employing image of a high resolution, large number of image per person, 639 

large training set, and more powerful DNN algorithm (e.g., He, Zhang, Ren, & Sun, 2015) 640 

could further boost accuracy. 641 

Some people may wonder if such finding should be make public l they inspire the 642 

very application that we be warn against. We share this concern. However, a the 643 

government and company seem to be already deploy face-based classifier aim at 644 



DEEP NEURAL NETWORKS CAN DETECT SEXUAL ORIENTATION FROM FACES 



35 

detect intimate trait (Chin & Lin, 2017; Lubin, 2016), there be an urgent need for make 645 

policymakers, the general public, and gay community aware of the risk that they might be 646 

face already. Delaying or abandon the publication of these finding could deprive 647 

individual of the chance to take preventive measure and policymakers the ability to introduce 648 

legislation to protect people. Moreover, this work do not offer any advantage to those who may 649 

be develop or deploy classification algorithms, apart from emphasize the ethical 650 

implication of their work. We use widely available off-the-shelf tools, publicly available data, 651 

and method well know to computer vision practitioners. We do not create a privacy-invading 652 

tool, but rather show that basic and widely use method pose serious privacy threats. We hope 653 

that our finding will inform the public and policymakers, and inspire them to design 654 

technology and write policy that reduce the risk face by homosexual community across 655 

the world.10 656 

The grow digitalization of our life and rapid progress in AI continue to erode the 657 

privacy of sexual orientation and other intimate traits. Policymakers and technology company 658 

seem to believe that legislation and new technology offering individual more control over their 659 

digital footprint can reverse this trend. However, the digital environment be very difficult to 660 

police. Data can be easily move across borders, stolen, or record without users’ consent. 661 

Furthermore, even if user be give full control over their data, it be hard to imagine that they 662 

would not share anything publicly. Most people want some of their social medium posts, blogs, or 663 




10 The result report in this paper be shared, in advance, with several lead 

international LGBTQ organizations. 



DEEP NEURAL NETWORKS CAN DETECT SEXUAL ORIENTATION FROM FACES 



36 

profile to be public. Few would be willing to cover their face while in the public. As this and 664 

other study show (e.g., Kosinski et al., 2013), such willingly share digital footprint can be 665 

use to reveal intimate traits. Consequently, we believe that further erosion of privacy be 666 

inevitable, and the safety of gay and other minority who may be ostracize in some culture 667 

hinge on the tolerance of society and governments. The postprivacy world will be a much 668 

safer and hospitable place if inhabit by well-educated, tolerant people who be dedicate to 669 

equal rights. 670 

671 

Acknowledgments: The author thank Klaus Fiedler and other reviewer for their great 672 

comment on the early version of this manuscript. We would also like to thank Samuel Gosling, 673 

Robert Sternberg, Raphael Silberzahn, Martie Haselton, Amir Goldberg, Poruz Khambatta, 674 

Anonymous Gabriella, Jason Rentfrow, Kai Ruggeri, Pierre Dechant, Brent Roberts, David 675 

Mack, and Nicole Paulk for their critical reading of the early version of this manuscript. Also, 676 

we thank Isabelle Abraham for proofread and Mariia Vorobiova for graphical design. Finally, 677 

we would like to thank the creator of Face++ for allow u to use their software free of 678 

charge. 679 

680 



DEEP NEURAL NETWORKS CAN DETECT SEXUAL ORIENTATION FROM FACES 



37 

References 681 

Allen, L. S., & Gorski, R. A. (1992). Sexual orientation and the size of the anterior commissure 682 

in the human brain. Proceedings of the National Academy of Sciences, 89(15), 7199–7202. 683 

http://doi.org/10.1073/pnas.89.15.7199 684 

Ambady, N., Hallahan, M., & Conner, B. (1999). Accuracy of judgment of sexual orientation 685 

from thin slice of behavior. Journal of Personality and Social Psychology, 77(3), 538–547. 686 

http://doi.org/10.1037/0022-3514.77.3.538 687 

Astley, S. J., Stachowiak, J., Clarren, S. K., & Clausen, C. (2002). Application of the fetal 688 

alcohol syndrome facial photographic screen tool in a foster care population. The 689 

Journal of Pediatrics, 141(5), 712–717. http://doi.org/10.1067/mpd.2002.129030 690 

Ballew, C. C., & Todorov, A. (2007). Predicting political election from rapid and unreflective 691 

face judgments. Proceedings of the National Academy of Sciences of the United States of 692 

America, 104(46), 17948–17953. http://doi.org/10.1073/pnas.0705435104 693 

Berry, D. S. (1991). Accuracy in social perception: Contributions of facial and vocal information. 694 

Journal of Personality and Social Psychology, 61(2), 298–307. http://doi.org/10.1037/0022-695 

3514.61.2.298 696 

Berry, D. S., & Brownlow, S. (1989). Were the physiognomists right? Personality correlate of 697 

facial babyishness. Personality and Social Psychology Bulletin, 15(2), 266–279. 698 

http://doi.org/10.1177/0146167289152013 699 

Bond, C. F., Berry, D. S., & Omar, A. (1994). The kernel of truth in judgment of deceptiveness. 700 

Basic and Applied Social Psychology, 15(4), 523–534. 701 

http://doi.org/10.1207/s15324834basp1504_8 702 



DEEP NEURAL NETWORKS CAN DETECT SEXUAL ORIENTATION FROM FACES 



38 

Borkenau, P., Brecke, S., Möttig, C., & Paelecke, M. (2009). Extraversion be accurately 703 

perceive after a 50-ms exposure to a face. Journal of Research in Personality, 43(4), 703–704 

706. http://doi.org/10.1016/j.jrp.2009.03.007 705 

Brambilla, M., Riva, P., & Rule, N. O. (2013). Familiarity increase the accuracy of categorize 706 

male sexual orientation. Personality and Individual Differences, 55(2), 193–195. 707 

http://doi.org/10.1016/j.paid.2013.02.023 708 

Brown, E., & Perrett, D. I. (1993). What give a face it gender? Perception, 22(7), 829–840. 709 

http://doi.org/10.1068/p220829 710 

Bulygina, E., Mitteroecker, P., & Aiello, L. (2006). Ontogeny of facial dimorphism and pattern 711 

of individual development within one human population. American Journal of Physical 712 

Anthropology, 131(3), 432–443. http://doi.org/10.1002/ajpa.20317 713 

Chin, J., & Lin, L. (2017, June 26). China’s all-seeing surveillance state be reading it citizens’ 714 

faces. The Wall Street Journal. Retrieved from https://www.wsj.com 715 

Esteva, A., Kuprel, B., Novoa, R. A., Ko, J., Swetter, S. M., Blau, H. M., & Thrun, S. (2017). 716 

Dermatologist-level classification of skin cancer with deep neural networks. Nature, 717 

542(7639), 115–118. http://doi.org/10.1038/nature21056 718 

Ferry, Q., Steinberg, J., Webber, C., FitzPatrick, D. R., Ponting, C. P., Zisserman, A., & Nellåker, 719 

C. (2014). Diagnostically relevant facial gestalt information from ordinary photos. eLife, 720 

2014(3). http://doi.org/10.7554/eLife.02020.001 721 

Glaser, G. (2002). The Nose: A Profile of Sex, Beauty, and Survival. Simon and Schuster. 722 

Glimcher, M. E., Garcia, R. I., & Szabó, G. (1978). Organ culture of mammalian skin and the 723 

effect of ultraviolet light and testosterone on melanocyte morphology and function. 724 



DEEP NEURAL NETWORKS CAN DETECT SEXUAL ORIENTATION FROM FACES 



39 

Journal of Experimental Zoology, 204(2), 229–237. http://doi.org/10.1002/jez.1402040210 725 

Halberstadt, A. G., Hayes, C. W., & Pike, K. M. (1988). Gender and gender role difference in 726 

smile and communication consistency. Sex Roles, 19(9–10), 589–604. 727 

http://doi.org/10.1007/BF00289738 728 

Hastie, T., Tibshirani, R., & Friedman, J. (2009). The element of statistical learn (Vol. 1). 729 

New York: Springer series in statistics. http://doi.org/10.1007/b94608 730 

He, K., Zhang, X., Ren, S., & Sun, J. (2015). Deep Residual Learning for Image Recognition. 731 

arXiv Preprint arXiv:1512.03385v1, 7(3), 171–180. 732 

http://doi.org/10.3389/fpsyg.2013.00124 733 

Hines, M. (2010). Sex-related variation in human behavior and the brain. Trends in Cognitive 734 

Sciences, 14(10), 448–456. http://doi.org/10.1016/j.tics.2010.07.005 735 

Hughes, S. M., & Bremme, R. (2011). The effect of facial symmetry and sexually-dimorphic 736 

facial proportion on assessment of sexual orientation. Journal of Social, Evolutionary, and 737 

Cultural Psychology, 5(4), 214–230. http://doi.org/10.1037/h0099261 738 

Jablonski, N. G., & Chaplin, G. (2000). The evolution of human skin coloration. Journal of 739 

Human Evolution, 39(1), 57–106. http://doi.org/10.1006/jhev.2000.0403 740 

Jannini, E. A., Blanchard, R., Camperio-Ciani, A., & Bancroft, J. (2010). Male homosexuality: 741 

Nature or culture? The Journal of Sexual Medicine, 7(10), 3245–3253. 742 

http://doi.org/10.1111/j.1743-6109.2010.02024.x 743 

Jenkinson, J. (1997). Face facts: A history of physiognomy from ancient Mesopotamia to the end 744 

of the 19th century. The Journal Of Biocommunication, 24(3), 2–7. 745 



DEEP NEURAL NETWORKS CAN DETECT SEXUAL ORIENTATION FROM FACES 



40 

Jernigan, C., & Mistree, B. F. (2009). Gaydar: Facebook friendship expose sexual orientation. 746 

First Monday, 14(10). http://doi.org/10.5210/fm.v14i10.2611 747 

Jones, B. C., Hahn, A. C., Fisher, C. I., Wincenciak, J., Kandrik, M., Roberts, S. C., … 748 

DeBruine, L. M. (2015). Facial coloration track change in women’s estradiol. 749 

Psychoneuroendocrinology, 56, 29–34. http://doi.org/10.1016/j.psyneuen.2015.02.021 750 

King, M., Semlyen, J., Tai, S. S., Killaspy, H., Osborn, D., Popelyuk, D., & Nazareth, I. (2008). 751 

A systematic review of mental disorder, suicide, and deliberate self harm in lesbian, gay and 752 

bisexual people. BMC Psychiatry, 8, 70. http://doi.org/10.1186/1471-244X-8-70 753 

Kosinski, M., Matz, S. C., Gosling, S. D., Popov, V., & Stillwell, D. J. (2015). Facebook a a 754 

research tool for the social sciences: Opportunities, challenges, ethical considerations, and 755 

practical guidelines. American Psychologist, 70(6), 543–556. 756 

http://doi.org/10.1037/a0039210 757 

Kosinski, M., Stillwell, D. J., & Graepel, T. (2013). Private trait and attribute be predictable 758 

from digital record of human behavior. Proceedings of the National Academy of Sciences 759 

of the United States of America, 110(15), 5802–5805. 760 

http://doi.org/10.1073/pnas.1218772110 761 

LeCun, Y., Bengio, Y., & Hinton, G. (2015). Deep learning. Nature, 521(7553), 436–444. 762 

http://doi.org/10.1038/nature14539 763 

Lefevre, C. E., Lewis, G. J., Perrett, D. I., & Penke, L. (2013). Telling facial metrics: Facial 764 

width be associate with testosterone level in men. Evolution and Human Behavior, 34(4), 765 

273–279. http://doi.org/10.1016/j.evolhumbehav.2013.03.005 766 

Lefevre, C. E., Wilson, V. A. D., Morton, F. B., Brosnan, S. F., Paukner, A., & Bates, T. C. 767 



DEEP NEURAL NETWORKS CAN DETECT SEXUAL ORIENTATION FROM FACES 



41 

(2014). Facial width-to-height ratio relates to alpha status and assertive personality in 768 

capuchin monkeys. PLOS ONE, 9(4), e93369. http://doi.org/10.1371/journal.pone.0093369 769 

Little, A. C., Burriss, R. P., Jones, B. C., & Roberts, S. C. (2007). Facial appearance affect 770 

voting decisions. Evolution and Human Behavior, 28(1), 18–27. 771 

http://doi.org/10.1016/j.evolhumbehav.2006.09.002 772 

Lõhmus, M., Sundström, L. F., & Björklund, M. (2009). Dress for success: Human facial 773 

expression be important signal of emotions. Annales Zoologici Fennici, 46(1), 75–80. 774 

http://doi.org/10.5735/086.046.0108 775 

Lombroso, C. (1911). Criminal man. New York: GP Putnam. 776 

Lu, C., & Tang, X. (2014). Surpassing human-level face verification performance on LFW with 777 

GaussianFace. In Proceedings of the Twenty-Ninth AAAI Conference on Artificial 778 

Intelligence (pp. 3811–3819). Austin, TX: AAAI Press. Retrieved from 779 

http://arxiv.org/abs/1404.3840 780 

Lubin, G. (2016, October 12). Facial-profiling could be dangerously inaccurate and biased, 781 

expert warn. Business Insider. Retrieved from http://www.businessinsider.de/ 782 

Lukaszewski, A. W., & Roney, J. R. (2011). The origin of extraversion: Joint effect of 783 

facultative calibration and genetic polymorphism. Personality and Social Psychology 784 

Bulletin, 37(3), 409–421. http://doi.org/10.1177/0146167210397209 785 

Lyons, M., Lynch, A., Brewer, G., & Bruno, D. (2014). Detection of sexual orientation 786 

(“gaydar”) by homosexual and heterosexual women. Archives of Sexual Behavior, 43(2), 787 

345–352. http://doi.org/10.1007/s10508-013-0144-7 788 

Macrae, C. N., & Bodenhausen, G. V. (2000). Social cognition: Thinking categorically about 789 



DEEP NEURAL NETWORKS CAN DETECT SEXUAL ORIENTATION FROM FACES 



42 

others. Annual Review of Psychology, 51, 93–120. 790 

http://doi.org/10.1146/annurev.psych.51.1.93 791 

Meyer-Bahlburg, H. F. L. (1984). Psychoendocrine research on sexual orientation: Current status 792 

and future options. Progress in Brain Research, 61, 375–298. http://doi.org/10.1016/S0079-793 

6123(08)64448-9 794 

Parkhi, O. M., Vedaldi, A., & Zisserman, A. (2015). Deep Face Recognition. In X. Xie, M. W. 795 

Jones, & G. K. L. Tam (Eds.), Proceedings of the British Machine Vision Conference (p. 796 

41.1). Swansea, UK: BMVA Press. http://doi.org/10.5244/C.29.41 797 

Penton-Voak, I. S., Pound, N., Little, A. C., & Perrett, D. I. (2006). Personality judgment from 798 

natural and composite facial images: More evidence for a “kernel of truth” in social 799 

perception. Social Cognition, 24(5), 607–640. http://doi.org/10.1521/soco.2006.24.5.607 800 

Porter, R. (Ed.). (2003). The Cambridge history of science: Eighteenth-century science (Vol. 4). 801 

Cambridge, UK: Cambridge University Press. 802 

Rhodes, G. (2006). The evolutionary psychology of facial beauty. Annual Review of Psychology, 803 

57, 199–226. http://doi.org/10.1146/annurev.psych.57.102904.190208 804 

Riedweg, C. (2005). Pythagoras: His life, teaching, and influence. New York, NY: Cornell 805 

University Press. 806 

Roberts, T., & Bruce, V. (1988). Feature saliency in judging the sex and familiarity of faces. 807 

Perception, 17(4), 475–481. http://doi.org/10.1068/p170475 808 

Rule, N. O., & Ambady, N. (2008). Brief exposures: Male sexual orientation be accurately 809 

perceive at 50 ms. Journal of Experimental Social Psychology, 44(4), 1100–1105. 810 

http://doi.org/10.1016/j.jesp.2007.12.001 811 



DEEP NEURAL NETWORKS CAN DETECT SEXUAL ORIENTATION FROM FACES 



43 

Rule, N. O., & Ambady, N. (2010). Democrats and Republicans can be differentiate from their 812 

faces. PLoS ONE, 5(1), e8733. http://doi.org/10.1371/journal.pone.0008733 813 

Rule, N. O., Ambady, N., Adams, R., & Macrae, C. N. (2008). Accuracy and awareness in the 814 

perception and categorization of male sexual orientation. Journal of Personality and Social 815 

Psychology, 95(5), 1019–1028. http://doi.org/10.1037/a0013194 816 

Rule, N. O., MacRae, C. N., & Ambady, N. (2009). Ambiguous group membership be extract 817 

automatically from faces. Psychological Science, 20(4), 441–443. 818 

http://doi.org/10.1111/j.1467-9280.2009.02314.x 819 

Samochowiec, J., Wänke, M., & Fiedler, K. (2010). Political ideology at face value. Social 820 

Psychological and Personality Science, 1(3), 206–213. 821 

http://doi.org/10.1177/1948550610372145 822 

Sell, R. L., Wells, J. A., & Wypij, D. (1995). The prevalence of homosexual behavior and 823 

attraction in the United States, the United Kingdom and France: Results of national 824 

population-based samples. Archives of Sexual Behavior, 24(3), 235–248. 825 

http://doi.org/10.1007/BF01541598 826 

Skerski, J. (2011). Tomboy chic: Re-fashioning gender rebellion. Journal of Lesbian Studies, 827 

15(4), 466–479. http://doi.org/10.1080/10894160.2011.532031 828 

Skorska, M. N., Geniole, S. N., Vrysen, B. M., McCormick, C. M., & Bogaert, A. F. (2015). 829 

Facial structure predicts sexual orientation in both men and women. Archives of Sexual 830 

Behavior, 44(5), 1377–1394. http://doi.org/10.1007/s10508-014-0454-4 831 

Todorov, A., Mandisodza, A. N., Goren, A., & Hall, C. C. (2005). Inferences of competence from 832 

face predict election outcomes. Science, 308(5728), 1623–1626. 833 



DEEP NEURAL NETWORKS CAN DETECT SEXUAL ORIENTATION FROM FACES 



44 

http://doi.org/10.1126/science.1110589 834 

Todorov, A., Said, C. P., Engell, A. D., & Oosterhof, N. N. (2008). Understanding evaluation of 835 

face on social dimensions. Trends in Cognitive Sciences, 12(12), 455–460. 836 

http://doi.org/10.1016/j.tics.2008.10.001 837 

Tskhay, K. O., & Rule, N. O. (2015). Emotions facilitate the communication of ambiguous group 838 

memberships. Emotion, 15(6), 812–826. http://doi.org/10.1037/emo0000077 839 

Udry, J. R. (2000). Biological limit of gender construction. American Sociological Review, 840 

65(3), 443–457. http://doi.org/10.2307/2657466 841 

Udry, J. R., & Chantala, K. (2006). Masculinity–femininity predicts sexual orientation in men 842 

but not in women. Journal of Biosocial Science, 38(6), 797–809. 843 

http://doi.org/10.1017/S002193200500101X 844 

UN Human Rights Council. (2015). Discrimination and violence against individual base on 845 

their sexual orientation and gender identity. Retrieved from 846 

http://www.refworld.org/docid/5571577c4.html 847 

Valentova, J. V., Kleisner, K., Havlíček, J., & Neustupa, J. (2014). Shape difference between the 848 

face of homosexual and heterosexual men. Archives of Sexual Behavior, 43(2), 353–361. 849 

http://doi.org/10.1007/s10508-013-0194-x 850 

Whitehouse, A. J. O., Gilani, S. Z., Shafait, F., Mian, A., Tan, D. W., Maybery, M. T., … 851 

Eastwood, P. (2015). Prenatal testosterone exposure be related to sexually dimorphic facial 852 

morphology in adulthood. Proceedings of the Royal Society B: Biological Sciences, 853 

282(1816), 20151351. http://doi.org/10.1098/rspb.2015.1351 854 

Zebrowitz, L. A. (1997). Reading faces: Window to the soul? New direction in social 855 



DEEP NEURAL NETWORKS CAN DETECT SEXUAL ORIENTATION FROM FACES 



45 

psychology. Boulder, CO: Westview Press. 856 

Zebrowitz, L. A., & Collins, M. (1997). Accurate social perception at zero acquaintance: the 857 

affordances of a Gibsonian approach. Personality and Social Psychology Review, 1(3), 204–858 

223. http://doi.org/10.1207/s15327957pspr0103_2 859 

Zebrowitz, L. A., Collins, M., & Dutta, R. (1998). The relationship between appearance and 860 

personality across the life span. Personality and Social Psychology Bulletin, 24(7), 736–861 

749. http://doi.org/10.1177/0146167298247006 862 

863 



DEEP NEURAL NETWORKS CAN DETECT SEXUAL ORIENTATION FROM FACES 



46 

Supplementary Materials 864 

865 
Figure S1. Instructions give to AMT worker employ to remove incomplete, non-Caucasian, 866 

nonadult, and nonhuman male faces. We use similar instruction for female faces. 867 



DEEP NEURAL NETWORKS CAN DETECT SEXUAL ORIENTATION FROM FACES 



47 

868 

Figure S2. Instructions give to AMT worker employ to classify heterosexual and gay faces. 869 


