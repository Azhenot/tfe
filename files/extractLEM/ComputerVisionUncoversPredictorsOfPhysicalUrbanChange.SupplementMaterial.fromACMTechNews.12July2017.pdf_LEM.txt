









































Supporting Information: 
Computer Vision Uncovers Predictors of Physical Urban Change 

Nikhil Naik∗, Scott Duke Kominers, Ramesh Raskar, Edward L. Glaeser, and César A. Hidalgo 

Contents 

1. Data and Methods 1 
1.1. The Street View Image Dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 
1.2. Image Feature Extraction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 
1.3. Removal of Unsuitable Images . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 
1.4. Streetchange Calculation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 
1.5. Removing Erroneous Pairs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 
1.6. Image Quality and Streetchange . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 
1.7. Validating Streetchange . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 
1.8. Streetscore: Generalization Performance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 

2. Regressions 7 
2.1. Do Social Characteristics Predict Changes in Streetscore? . . . . . . . . . . . . . . . . . . . . . . 8 
2.2. The Filtering Hypothesis of Urban Change . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8 

3. Additional Examples and Map Visualizations 8 

1. Data and Methods 

Using a dataset consist of human-coded image comparisons, we train a computer vision algorithm to predict 
perceive safety of individual street scene (“Streetscore”); we then obtain “Streetchange” by compare that 
measurement across Street View image of the same location from 2007 (the “2007 image”) and 2014 (the “2014 
image”). 

1.1. The Street View Image Dataset 

We first describe the Street View image dataset use in this paper. We obtain 360◦ panorama image of 
streetscapes from five US city use the Google Street View Application Programming Interface (API). Each 
panorama be associate with a unique identifier (“panoid”), latitude, longitude, and time stamp (which specify 

∗E-mail: naik@fas.harvard.edu 

1 



the month and year of image capture). We extract an image cutout from each panorama by specify the head- 
ing and pitch of the camera relative to the Street View vehicle. We obtain a total of 1,645,760 image cutout 
for street block in Baltimore, Boston, Detroit, New York, and Washington DC, capture in year 2007 (the “2007 
panel”) and 2014 (the “2014 panel”). For the street block that lack image for either 2007 or 2014, we complete 
the “2007” and “2014” panel use image from the closest year for which data be available. As a result, 5% 
of the image in the “2007” panel be from either 2008 or 2009. Similarly, 12% of the image in the “2014” panel 
be from 2013. We match image cutout from the 2007 and 2014 panel by use their geographical location 
(i.e. latitude and longitude) and by choose the same head and pitch. This process give u image that show 
the same place, from the same point of view, but in different years. A large majority of image in our dataset be 
capture between the month of April and August, to avoid a change of season between the two image of the 
same location. 

Next, we describe the computer vision algorithm use for obtain Streetchange—a measure for physical urban 
change—from the 2007 and 2014 image panels. 

1.2. Image Feature Extraction 

Our computer vision algorithm work with a number of structure and unstructured feature of the image data: 
First, we use the Geometric Layout algorithm [1] to assign pixel-wise semantic label in four geometric classes: 
“ground,” “buildings,” “trees,” and “sky.” Next, we extract two different image feature separately for the pixel 
of the four geometric classes: 

• We generate a texton dictionary [2] by convolve the image with a Gaussian filter bank and cluster 
their response together; every pixel be then assign to the near cluster center, create a texton map. 
We compute 512-dimensional histogram with texton map of the four geometric classes. We call this 
feature Geometric Texton Histograms (GTH). 

• We calculate the GIST feature descriptor [3]—a global image feature that provide a low-dimensional 
representation of the spatial layout property of a scene—for each of the geometric classes. 

1.3. Removal of Unsuitable Images 

A small number of Street View image pair in the sample be unsuitable for comparison. In particular: some 
image be over-exposed, out of focus, or blurred; others have significant change in greenery coverage likely 
driven by seasonal change rather than urban foliage improvements. To eliminate these unsuitable pairs, we use 
a series of automate data cleaning methods: 

• First, we remove over-exposed images, which typically result from the sun shin directly into the camera. 
To identify over-exposed pixels, we convert each image to the CIELAB color space, in which the L 
channel represent lightness and a, b channel represent the color. The color channel be combine a 
C = (a, b)T . We compute an over-exposure valueM (between 0 and 1) at each pixel follow method 
introduce by Guo et al. [4]: At pixel i, 

Mi = 
1 

2 
· tanh 

( 
δ · 

( 
(Li − LT ) + (CT − ||Ci||2) 

)) 
, 

with the constant set to δ = 1/60, LT = 80, and CT = 40. We obtain the meanMskyi ofMi over all the 
pixel that belong to the “sky” geometric class, a predict by the Geometric Layout algorithm [1]. We 
discard the image pair in which at least one of the image i hadMskyi > 0.85, indicate over-exposure. 
We discard all image pair contain at least one over-exposed image. 

2 



2007 2014 2007 2014 

2007 2014 2007 2014 
Streetchange = +0.5934 Streetchange = +0.5960 

Streetchange = +0.2787 Streetchange = +0.7401 

Figure S1. The Streetchange algorithm be robust to large weather and seasonal changes. In this example, our algorithm 
assigns a small Streetchange value to the image pairs, even though there be a drastic change in weather between the two 
images. Images courtesy of Google, Inc. 

• Second, we remove image that be out-of-focus or contain motion blur. To detect such images, we 
compute the Absolute Central Moment (ACMO) of each image, a statistical measure that allows a simul- 
taneous optimization of both focus and exposure [5]. If the normalize value of ACMO be less than 0.2, 
we label the image a blurred. We discard all image pair contain at least one blur image. 

• Finally, we discard all image pair in which the number of pixel in the image occupy by the “tree” object 
class (again, a predict by the Geometric Layout algorithm [1]) change by more than 10% between the 
2007 image and the 2014 image. This process eliminate image pair in which only one of the image have 
significant occlusion of building by trees. 

1.4. Streetchange Calculation 

Having remove the image unsuitable for urban change detection, we predict the “Streetscores” of the remain- 
ing image use a support vector regression model train with computer vision feature and aggregate score 
obtain from the crowdsourced study by Salesses et al. [6], a described next. 

Salesses et al. [6] create an online crowdsourced game in which participant be show image of streetscapes 
randomly chosen from New York, Boston, Linz and Salzburg. Participants be ask to choose one of the two 
image in response to three questions: “Which place look safer?”, “Which place look more upper class?”, and 
“Which place look unique?”. In the Salesses et al. [6] study, 7,872 unique participant from 91 country provide 
186,188 comparison (“clicks”) of image pair drawn from a pool of 4,109 image for the question “Which place 
look safer?” 

Following Naik et al. [7], we convert the 186,188 pairwise comparison for the question “Which place look 
safer?” to ranked score use a Bayesian rank algorithm call Trueskill [8]. We call the Trueskill perceive 
safety score for each image that image’s Streetscore; these images’ Streetscores be “true scores” derive from 
aggregation of human assessments. We use the Streetscores obtain from human assessment to train a machine 
learn model that us the GTH and GIST feature of the correspond image (described in Section 1.2) to 
predict how human would score the perceive safety of Street View images. As we be only seek to predict 

3 



(a) Image Pairs with Location Errors - Examples 

2007 2014 

2007 2014 2007 2014 

2007 2014 
(b) Image Pairs with Significant Occlusion Errors - Examples 

Figure S2. A human operator eliminate the small fraction of invalid image pair contain location-coding error or signif- 
icant occlusion of building by large vehicles. Images courtesy of Google, Inc. 

the human perception of American cities, we restrict the training sample to the 2,920 human-coded image from 
New York and Boston. 

We use ν-Support Vector Regression (ν-SVR) [9] to predict image Streetscores. Given a set of training image 
with feature vector x and Streetscores q ∈ R, ν-SVR with a linear kernel generates a weight vector w and a bias 
term b under a set of constraints. The two variable (w, b) be use to predict the Streetscore for a new image with 
feature vector x′ by evaluate q′ = w · x′ + b. We measure the accuracy of our predictor use the Coefficient 
of Determination (R2). We obtain R2 = 0.57 over fivefold cross-validation on the training set. 

In this paper we drop the Geometric Color Histogram (GCH) feature use by Naik et al. [7], since GCH 
feature be more sensitive to weather change than GIST and texton histograms. Dropping the GCH features, 
however, do not substantially reduce the predictor accuracy—the R2 drop from 0.5884 to 0.5709. 

Next, we use the Streetscore predictor to calculate urban change from image pairs. As our predictor be a weight 
vector train use image feature on top of the four geometric class (ground, building, tree and sky), we be 
able to compute the contribution of each geometric class to the Streetscore of each image. We chose to discard the 
contribution of the “trees” and “sky” class since their score depend on the season and weather at the time of 
image capture. Note that the “trees” class contains only large tree (and not landscaping), allow u to account 
for change in the built environment due to landscape a part of the “ground” class. Figure S1 show example 
of image pair with large weather and seasonal change which have be accurately score by our algorithm. 

After compute the Streetscore for each image in a 2007–2014 image pair, we calculate “Streetchange” a the 
difference between the 2014 image’s Streetscore and the 2007 image’s Streetscore. 

1.5. Removing Erroneous Pairs 

While we be able to computationally eliminate pair contain over-exposed, blurred, or occlude images, 
we discover two additional source of error that make a small number of image pair invalid for Streetchange 
calculation. The first source of error be incorrect location information for one or both image in an image pair. 
For these images, the geographic coordinate (latitude and longitude) obtain from Google Street View do not 

4 



2007 2014 2007 2014 

2007 2014 2007 20142007 2014 
Streetchange = +0.6624 Streetchange = +0.8564 

Streetchange = +0.7432 Streetchange = +0.6184 

Figure S3. The Streetchange algorithm be robust to the change in Street View image quality between year 2007 and 2014. 
Images courtesy of Google, Inc. 

match with the actual geographic coordinate of the location at which the image be capture (Figure S2-(a)). 
The second source of error be partial or complete occlusion of building by large vehicle (Figure S2-(b)), which 
be not remove by the procedure described in Section 1.3. 

Our algorithm calculate a large positive or negative Streetchange value for image pair contain location- 
cod or vehicle-occlusion errors, since the two image in such pair look very different (Figure S2). Due to 
large variation in visual appearance within and across image pair that contain these errors, we be unable to 
automatically eliminate such image pair with a computer vision algorithm. Therefore, a human operator observe 
image pair whose Streetchange value be large than four standard deviation of change in Streetscore (which 
amount to only 1,849 image pair out of a total of 822,880—less than 0.23% of the sample). The operator 
manually eliminate image pair which contain location-coding error or vehicle-occlusion errors. 

1.6. Image Quality and Streetchange 

We also note that there be a difference in image quality between Street View image capture in year 2007 and 
Street View image from year 2008 or after (due to improvement in Google’s image hardware). But the 
Streetchange algorithm be robust to change in image quality from 2007 and 2014 (Figure S3) for a few reasons. 
First, a significant fraction of image in the training set be also from 2007, which help to mitigate the effect of 
change in image quality. Second, we process the image at a resolution of 400 × 300 pixels; the difference in 
quality be not significant at this resolution. Finally, a high fraction of 2007 Street View image (as compare to 
year 2014) tend to be over-exposed; but we discard such image from our calculations. 

1.7. Validating Streetchange 

We validate our final Streetchange measure use three sources: a survey on Amazon Mechanical Turk (AMT), 
a survey of graduate student in MIT’s School of Architecture and Planning, and data from Boston’s Planning and 
Development Authority. 

5 



Figure S4. Screenshot of the Amazon Mechanical Turk experimental interface use for validate Streetchange. Insets 
courtesy of Google, Inc. 

Validation with human observers: For the validation experiment on AMT, we select 1,565 image pair 
(roughly 1% of the final sample) use inverse transform sample on Streetchanges. We present AMT worker 
with two image pair side-by-side (Figure S4) drawn randomly from the 1,565 image pair and ask the follow 
question: 

Select the image pair that have the large change in buildings, street and sidewalks. Please ignore 
change in traffic, tree and weather. If the amount of change in the pair be similar, select “Almost 
the same”. 

We obtain 28,170 pairwise comparison for the 1,565 image pair from 116 users—36 pairwise comparison on 
average. We convert these pairwise comparison to ranked score use the Microsoft Trueskill algorithm [8]. 
Trueskill converges to a stable estimate of ranked score after 12–36 comparisons, so we have enough comparison 
to obtain accurate scores. We call this score AMT–Streetchange. A high value of AMT–Streetchange be indicative 
of a large absolute physical change in the image pair, a observe by the AMT users. 

Next, we obtain bin rank between 1 and 30 for both AMT–Streetchange and the absolute value of Streetchange 
output of our algorithm. Comparing the two, we found a Spearman’s rank correlation of 0.72 (p < 1 × 10−5) 
between them. These result indicate that the algorithm output on Streetchanges be consistent with human judg- 
ments on change in urban environment. 

For the validation experiment with graduate student in MIT’s School of Architecture and Planning, we present 
the student (number of participant = 3) with 100 image pairs, where 50 image pair contain large negative 
Streetchange and 50 image pair contain large positive Streetchange. We ask them to choose if the image pair 
show sign of positive change, negative change, or no change, and aggregate their response with a majority 
rule. The student agree with positive Streetchange (as score by our algorithm) for 88% of the image pair and 
they agree with negative Streetchange for 59% of the image pairs. The low agreement in the negative change 
be a result of student classify demolition of blight property a a positive change (while our algorithm 
tends to classify them a negative). 

6 



Table S1. Summary Statistics for the Boston Validation Experiment (Section 1.7) ( N = 222 ) 

Variables Description Mean SD Min Max 

Streetchange 2007–2014 Mean Streetchange 2007–2014 of 
all sample street block within a 
census tract 

1.290 0.509 −1.599 2.613 

Log Total Square Footage 
2012–2014 

Total square footage built per 
square mile within a census tract 

13.527 1.548 10.109 17.202 

Table S2. Streetscore: Generalization Performance (R2) 
XXXXXXXXXXXTrain 

Test 
New York Boston 

New York 0.5399 0.5033 
Boston 0.5028 0.5384 

Validation with infrastructure development data: In the third validation experiment, we test the relationship 
between improvement in Streetscore and improvement in infrastructure, use data on new development in 
Boston (for summary statistics, see Table S1). We collect data on all public and private building project 
from the Boston Planning and Development Agency (BPDA). We compute the total new square footage built 
per square mile for each census tract during the period 2012–2014 and test it relationship with Streetchange 
2007–2014. We expect census tract where more square footage be built during 2012–2014 to be associate 
with a high Streetchange, due to the physical improvement in these neighborhood between the 2007 and 2014 
image panels. And indeed, we find that infrastructure improvement be positively and significantly associate to 
Streetchange—one standard deviation increase in log total square footage corresponds to roughly half a standard 
deviation increase in Streetchange. We estimate: 

Streetchange 2007 − 2014 = 1.620 
(0.069) 

+ 
0.159∗∗∗ 

(0.035) 
· Log total square footage (1) 

These result provide empirical evidence for the connection between improvement in Streetscore and improve- 
ments in infrastructure. 

1.8. Streetscore: Generalization Performance 

Computer vision algorithm might have difficulty generalize to out-of-sample data. Since we compute Streetscores 
for image from Baltimore, Detroit, and Washington DC use an algorithm train with image from Boston and 
New York, we would like to estimate whether the Streetscore predictor can generalize without a significant drop 
in accuracy. So we perform an experiment where we train a Streetscore predictor use image just from New 
York and measure the accuracy of it prediction on Boston image in our dataset, and vice versa. We found that 
the R2 drop by only 0.036 on average during cross-city prediction (Table S2). 

2. Regressions 

We calculate Streetchange for 2007–2014 image pair sample uniformly from Baltimore, Boston, Detroit, New 
York, and Washington DC. Using tract boundary from the 2010 US Census, we aggregate 2007 Streetscore and 
2007–2014 Streetchange across each census tract. We obtain census tract characteristic data from the 2000 US 
Census, adjust to the 2010 census tract boundary [10]. For summary statistics, see Table S3. 

7 



2.1. Do Social Characteristics Predict Changes in Streetscore? 

We now present the cross-sectional demographic and economic correlate of the 2007 Streetscore and 2007–2014 
Streetchange (Table S4). For each census tract, we consider the follow socioeconomic indicator from the 
2000 US Census: population density, level of education, median income, housing price and rental costs, housing 
vacancy, race, and poverty. We find that the socioeconomic characteristic that best predict high Streetscore in 
2007—density and education—are also the best predictor of increase in Streetscore between 2007 and 2014. 
These relationship hold regardless of whether we control for the 2007 Streetscore or other variables. We find that 
other variables, such a income, housing prices, rent, race, and poverty have little or no predictive power in our 
context. 

2.2. The Filtering Hypothesis of Urban Change 

In addition to the invasion and tip hypothesis of urban change discuss in main text, we evaluate the filter 
hypothesis [11] of urban change. The filter hypothesis suggests cycle in which neighborhood gradually decay 
until they get upgraded. To test the hypothesis that building age shape streetscape change, we regress the 2007 
Streetscore and 2007–2014 Streetchange on the share of the building stock (as of the year 2000) built during 
different decades. The data grouped together all building erect before 1939. There be weak support for the 
filter hypothesis in our dataset (Table S5): we found that neighborhood with newer housing stock score 
high than neighborhood built in the 1950s. However, we cannot rule out the possibility that our find be also 
reflective of difference in the perception of various architectural styles, a neighborhood built before 1939 (prior 
to the widespread adoption of modernist architecture in the US) also score highly. 

3. Additional Examples and Map Visualizations 

Figures S5–S7 present additional example of positive Streetchange from the five city in our dataset. The exam- 
ples show that Streetchange be able to detect both upgrade and new construction. Figure S8 show additional 
example of negative Streetchange, which be associate with urban blight and decline in upkeep. 

Figures S9–S28 present map visualization for Log Population Density 2000, Share College Education 2000, 
Streetscore 2007, and Streetchange 2007–2014 for the five city in our dataset. 

References 

[1] Hoiem D, Efros AA, Hebert M (2008) Putting object in perspective. International Journal of Computer Vision 80(1):3– 
15. 

[2] Malik J, Belongie S, Leung T, Shi J (2001) Contour and texture analysis for image segmentation. International Journal 
of Computer Vision 43(1):7–27. 

[3] Oliva A, Torralba A (2001) Modeling the shape of the scene: A holistic representation of the spatial envelope. Interna- 
tional Journal of Computer Vision 42(3):145–175. 

[4] Guo D, Cheng Y, Zhuo S, Sim T (2010) Correcting over-exposure in photographs. IEEE Conference on Computer 
Vision and Pattern Recognition pp. 515–521. 

[5] Shirvaikar MV (2004) An optimal measure for camera focus and exposure. Southeastern Symposium on System Theory 
pp. 472–475. 

[6] Salesses P, Schechtner K, Hidalgo CA (2013) The collaborative image of the city: Mapping the inequality of urban 
perception. PLoS One 8(7):e68400. 

8 



[7] Naik N, Philipoom J, Raskar R, Hidalgo CA (2014) Streetscore – Predicting the perceive safety of one million 
streetscapes. IEEE Conference on Computer Vision and Pattern Recognition Workshops pp. 793–799. 

[8] Herbrich R, Minka T, Graepel T (2006) Trueskill: A Bayesian skill rating system. Advances in Neural Information 
Processing Systems pp. 569–576. 

[9] Schölkopf B, Smola AJ, Williamson RC, Bartlett PL (2000) New support vector algorithms. Neural Computation 
12(5):1207–1245. 

[10] Logan JR, Xu Z, Stults BJ (2014) Interpolating US decennial census tract data from a early a 1970 to 2010: A 
longitudinal tract database. The Professional Geographer 66(3):412–420. 

[11] Margolis SE (1982) Depreciation of housing: An empirical consideration of the filter hypothesis. Review of Eco- 
nomics and Statistics 64(1):90–96. 

9 



Table S3. Summary Statistics (N = 2513) 

Variables Description Mean SD Min Max 

Streetscore 2007 Mean Streetscore 2007 of all 
sample street block within a 
census tract 

7.757 2.587 1.681 18.93 

Streetchange 2007–2014 Mean Streetchange 2007–2014 of 
all sample street block within a 
census tract 

1.39 0.779 −4.076 6.121 

Log Population Density 2000 Log of population density within a 
census tract 

−4.655 1.22 −15.29 −2.48 

Share College Education 2000 Share of adult with a four-year 
college degree within a census 
tract 

0.254 0.216 0 1 

Log Median Income 2000 Log of median income of adult 
within a census tract 

4.54 0.206 3.884 5.276 

Log Monthly Rent 2000 Log of median monthly rent within 
a census tract 

6.40 0.390 4.595 7.601 

Log Housing Price 2000 Log of median housing price 
within a census tract 

5.223 0.311 3.938 6 

Poverty Rate 2000 Share of household under poverty 
line within a census tract 

0.218 0.137 0 1 

Share African-American 2000 Share of African-Americans within 
a census tract 

0.366 0.371 0 1 

Share Hispanic 2000 Share of Hispanics within a census 
tract 

0.192 0.221 0 0.927 

Share Vacant Units 2000 Share of vacant unit within a 
census tract 

0.036 0.055 0 0.348 

Share Built 1990-2000 Share of housing stock built during 
1990-2000 within a census tract 

0.587 0.874 0 1 

Share Built 1980-1989 Share of housing stock built during 
1980-1989 within a census tract 

0.404 0.573 0 0.659 

Share Built 1970-1979 Share of housing stock built during 
1970-1979 within a census tract 

0.694 0.744 0 0.719 

Share Built 1960-1969 Share of housing stock built during 
1960-1969 within a census tract 

0.123 0.983 0 1 

Share Built 1950-1959 Share of housing stock built during 
1950-1959 within a census tract 

0.164 0.105 0 0.748 

Share Built 1940-1949 Share of housing stock built during 
1940-1949 within a census tract 

0.171 0.956 0 0.815 

Share Built before 1940 Share of housing stock built before 
1940 within a census tract 

0.394 0.201 0 1 

All socioeconomic variable be from the 2000 US Census. Streetscore 2007 and Streetchange 2007–2014 be compute use the method 
described in Section 1 of this document. All data be aggregate at the census tract level. 

10 



Table S4. Relationship Between Social Characteristics and Changes in 
Streetscore 

Coefficient 
Independent Variables Streetscore 

2007 
Streetchange 
2007–2014 

Share College Education 2000 2.024*** 1.099*** 
(0.483) (0.162) 

Log Population Density 2000 0.765*** 0.080*** 
(0.097) (0.026) 

Log Median Income 2000 0.186 −0.118 
(0.920) (0.242) 

Log Monthly Rent 2000 1.191*** −0.149 
(0.260) (0.096) 

Log Housing Price 2000 0.986*** 0.175* 
(0.274) (0.090) 

Poverty Rate 2000 3.815*** 0.300 
(1.114) (0.312) 

Share African-American 2000 0.151 −0.002** 
(0.225) (0.001) 

Share Hispanic 2000 0.878** 0.312*** 
(0.365) (0.118) 

Share Vacant Units 2000 0.917*** 0.090*** 
(0.158) (0.033) 

Streetscore 2007 −0.012 
(0.013) 

All model control for city fix effects. ∗ ∗ ∗p < 0.01, ∗ ∗ p < 0.05, ∗p < 0.1 
Standard error correct for spatial correlation be in parentheses. Regressions be esti- 

mat with a constant that be not reported. 

11 



Table S5. Evidence of Filtering 

Coefficient 
Independent Variables Streetscore 

2007 
Streetchange 
2007–2014 

Share Built 1990-2000 4.390*** 0.410 
(1.422) (0.341) 

Share Built 1980-1989 4.638*** 0.677* 
(1.406) (0.346) 

Share Built 1970-1979 2.077** 0.079 
(0.948) (0.259) 

Share Built 1960-1969 2.367** 0.343 
(1.119) (0.288) 

Share Built 1940-1949 −0.195 -0.720** 
(1.227) (0.324) 

Share Built Before 1940 4.614*** 0.323* 
(0.618) (0.194) 

Streetscore 2007 0.000 
(0.014) 

Log Population Density 2000 0.106*** 
(0.033) 

Share College Education 2000 0.648*** 
(0.106) 

All model control for city fix effects. ∗ ∗ ∗p < 0.01, ∗ ∗ p < 0.05, ∗p < 0.1 
Standard error correct for spatial correlation be in parentheses. Regressions be 

estimate with a constant that be not reported. 

12 



2007 2014 2007 2014 

Figure S5. Additional example of positive Streetchange. The first three row show example from New York City. The next 
three row show example from Boston. Images courtesy of Google, Inc. 

13 



2007 2014 2007 2014 

Figure S6. Additional example of positive Streetchange. The first three row show example from Washington DC. The next 
three row show example from Baltimore. Images courtesy of Google, Inc. 

14 



2007 2014 2007 2014 

Figure S7. Additional example of positive Streetchange. All example from Detroit. Images courtesy of Google, Inc. 

2007 2014 2007 2014 

Figure S8. Additional example of negative Streetchange from the five city in our dataset. Images courtesy of Google, Inc. 

15 



Legend 

<12000 
12000 - 26400 
26400 - 45800 
45800 - 76000 
>76000 

Per Square Mile 

Figure S9. New York City: Log Population Density 2000. 
16 



0 - 8 
8 - 15 
15 - 23 
23 - 50 
50 - 100 

Legend 

Percent 

Figure S10. New York City: Share College Education 2000. 
17 



Legend 

0.0 - 5.4 
5.4 - 7.0 
7.0 - 8.3 
8.3 - 12.0 
12.0 - 18.9 

Streetscore 

Figure S11. New York City: Streetscore 2007. 
18 



Legend 

-4.7 - 0.8 
0.9 - 1.2 
1.2 - 1.5 
1.5 - 1.9 
1.9 - 6.2 

Streetchange 

Figure S12. New York City: Streetchange 2007–2014. 
19 



Legend 

<12000 
12000 - 26400 
26400 - 45800 
45800 - 76000 
>76000 

Per Square Mile 

Figure S13. Boston: Log Population Density 2000. 

20 



0 - 8 
8 - 15 
15 - 23 
23 - 50 
50 - 100 

Legend 

Percent 

Figure S14. Boston: Share College Education 2000. 

21 



Legend 

0.0 - 5.4 
5.4 - 7.0 
7.0 - 8.3 
8.3 - 12.0 
12.0 - 18.9 

Streetscore 

Figure S15. Boston: Streetscore 2007. 

22 



Legend 

-4.7 - 0.8 
0.9 - 1.2 
1.2 - 1.5 
1.5 - 1.9 
1.9 - 6.2 

Streetchange 

Figure S16. Boston: Streetchange 2007–2014. 

23 



Legend 

<12000 
12000 - 26400 
26400 - 45800 
45800 - 76000 
>76000 

Per Square Mile 

Figure S17. Washington DC: Log Population Density 2000. 

24 



0 - 8 
8 - 15 
15 - 23 
23 - 50 
50 - 100 

Legend 

Percent 

Figure S18. Washington DC: Share College Education 2000. 

25 



Legend 

0.0 - 5.4 
5.4 - 7.0 
7.0 - 8.3 
8.3 - 12.0 
12.0 - 18.9 

Streetscore 

Figure S19. Washington DC: Streetscore 2007. 

26 



Legend 

-4.7 - 0.8 
0.9 - 1.2 
1.2 - 1.5 
1.5 - 1.9 
1.9 - 6.2 

Streetchange 

Figure S20. Washington DC: Streetchange 2007–2014. 

27 



Legend 

<12000 
12000 - 26400 
26400 - 45800 
45800 - 76000 
>76000 

Per Square Mile 

Figure S21. Baltimore: Log Population Density 2000. 

28 



0 - 8 
8 - 15 
15 - 23 
23 - 50 
50 - 100 

Legend 

Percent 

Figure S22. Baltimore: Share College Education 2000. 

29 



Legend 

0.0 - 5.4 
5.4 - 7.0 
7.0 - 8.3 
8.3 - 12.0 
12.0 - 18.9 

Streetscore 

Figure S23. Baltimore: Streetscore 2007. 

30 



Legend 

-4.7 - 0.8 
0.9 - 1.2 
1.2 - 1.5 
1.5 - 1.9 
1.9 - 6.2 

Streetchange 

Figure S24. Baltimore: Streetchange 2007–2014. 

31 



Legend 

<12000 
12000 - 26400 
26400 - 45800 
45800 - 76000 
>76000 

Per Square Mile 

Figure S25. Detroit: Log Population Density 2000. 

32 



0 - 8 
8 - 15 
15 - 23 
23 - 50 
50 - 100 

Legend 

Percent 

Figure S26. Detroit: Share College Education 2000. 

33 



Legend 

0.0 - 5.4 
5.4 - 7.0 
7.0 - 8.3 
8.3 - 12.0 
12.0 - 18.9 

Streetscore 

Figure S27. Detroit: Streetscore 2007. 

34 



Legend 

-4.7 - 0.8 
0.9 - 1.2 
1.2 - 1.5 
1.5 - 1.9 
1.9 - 6.2 

Streetchange 

Figure S28. Detroit: Streetchange 2007–2014. 

35 


