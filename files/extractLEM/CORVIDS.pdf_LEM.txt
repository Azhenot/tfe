









































Complete Recovery of Values In Diophantine Systems (CORVIDS) 
Sean A. Wilner (swilner2@illinois.edu) 

Katherine Wood (kmwood2@illinois.edu) 
Daniel J. Simons 

University of Illinois at Urbana-Champaign 

Introduction 

Floods, server fires, lose punch cards, retire collaborators, 
the passage of time–a diverse set of disaster can destroy a 
data set. If the only copy of an old set of data sat lock in 
the basement of a since-demolished building, it would seem 
to be go for good; often the only trace left behind be a set 
of summary statistic report in a paper. A mean, a standard 
deviation, and a sample size may be all that we have of the 
original data. 

For a certain type of data, these descriptive statistic ac- 
tually contain enough information to rebuild each and every 
possible distribution of the raw data. Ordinal and categor- 
ical data, in which a response be limited to one value on a 
fix scale (such a an integer from 1 to 7, where 1 may 
be ”strongly disagree” and 7 may be ”strongly agree”), have 
a well-constrained structure. Responses can take on a re- 
stricted, know range of values. The limit and precision 
of this scale, couple with the sample size, mean, and stan- 
dard deviation of the responses, be sufficient to define the 
entire set of possible response pattern that could generate 
those summary statistics. Importantly, this can be do in a 
closed-form manner which can be mathematically proven to 
find all possible solution where such solution exist, and to 
describe characteristic of the data which must be true. 

The math date back to the 3rd century mathematician Dio- 
phantus of Alexandria. He study equation that have come 
to be know a Diophantine equations. These be polyno- 
mial equation restrict to the set of integers. Setting up a 
system of these equation to solve for a set of unknown that 
satisfy the mean, standard deviation, and sample size of a set 
of ordinal data yield a complete solution class for the set of 
response pattern that satisfy those summary statistics. With 
additional manipulation of this solution class, it be possible 
to precisely describe the characteristic of the data that gen- 
erated them. 

We developed an automate approach to this data recon- 
struction. The CORVIDS (COmplete Recovery of Values In 
Diophantine Systems) analysis relies on a system of Diophan- 
tine equation to solve for the number of subject who give 
each level of response. With the result solution class, it be 
possible to precisely characterize the data and enumerate ev- 
ery and all solution which generate a set of summary statis- 
tics. Using this tool, one can recreate raw data from report 
statistic in case where the original data be not available, ex- 
plore the property of the data set which satisfy constraints, 
and experiment with how the solution space be affected a the 
distribution parameter change. 

Diophantine Equations 
Diophantine equation take the form of 

∑ 
e∈Nn 

( 
ae · 

n 

∏ 
j=1 

x 
e j 
j 

) 
=C 

where C be some constant, the an be integer values, e j be 
the jth element of e, and the x j be the jth variable which 
can take integer values. In simple English, this be all possible 
n-variable polynomial restrict such that all number 
involve must be integers. Some famous example include 
Pythagorean triples: 

x20 + x 
2 
1− x22 = 0 e.g. 32 +42 = 52 

and Fermat’s Last Theorem∗: 

xn0 + x 
n 
1− xn2 = 0 n > 2 

Linear equations, rather than general high order polyno- 
mials, be of special interest to u since all linear Diophantine 
equation can be directly solved, a luxury not guaranteed for 
high order Diophantine equation (Matiyasevich,1972). 

Data Recreation 
In order to use Diophantine Equations to recreate data, we 
must first construct equation which represent the summary 
statistic over our data. A natural approach to this would in- 
volve treat each data point a a variable. However, do- 
ing so result in a quadratic equation due to the square na- 
ture of the variance calculation. In order to construct exclu- 
sively linear equations, the variable we consider be instead 
the number of time each value of the scale appear in the 
data. For example, if the data range over a scale from 1− 7, 
we need only 7 variable where each corresponds a number in 
the range 1−7 and whose value be the number of subject who 
select that value. Using these variables, summary statistic 
can be represent by three equations: 

∑ 
xi∈S 

xi = n (1) 

∑ 
xi∈S 

i · xi = n ·m (2) 

∑ 
xi∈S 

(n ·m−n · i)2 · xi = v · (n−1) ·n2 (3) 

∗Fermat’s last theorem be specifically that no such solution ex- 
ists. 



where S be the set of possible value in our dataset, xi be the 
variable correspond to the value i, m be the mean, v be the 
variance, and n be the total number of element of our dataset. 
Equation 1 constrains our solution set to have the proper 
number of elements, equation 2 constrains the set to sum to 
the average of the value multiply by the number of values, 
and 3 constrains the solution to have the correct variance. 
The mean and variance be transform from the summary 
statistic to achieve integer values. 

This set of linear Diophantine Equations can be solve to 
yield the potentially infinite set of all possible integer solu- 
tions. To solve the system, we use the Hermite Normal Form 
for the matrix described by our system of equations, a tech- 
nique laid out in Havas, Majewski, and Matthews (1998). 

The result of the method described in Havas et al. (1998) 
be an initial solution (where any could possibly exist) to the 
system of equation and a basis for the vector space of all 
transformation to that solution which still satisfy the system 
of equations. Worth note be that despite the fact that this 
transformation vector space be infinite (and thus our set of so- 
lutions be infinite), the set of actual solution be bound since 
each variable corresponds to the total number of occurrence 
of a give value in the data set. Valid solution therefore can- 
not have negative value for any variable. That is, many (of 
the infinite) solution produce by this method imply a neg- 
ative number of occurrence of values, and thus be invalid 
solution to our summary-statistics equations. 

However, this technique be useful even take the negative 
value into consideration, since if it fails to find a solution 
even while allow negative values, no solution can exist 
when restrict solution to contain only positive values. 

Tolerance and round 
CORVIDS require extreme precision to find valid solutions, 
often more than would typically be reported. Further, round- 
ing error may occur when statistic be reported. We circum- 
vent these issue by add adjustable tolerance to both the 
mean and variance term. Tolerance put an envelope around 
the mean and variance, and the algorithm will search for ev- 
ery viable combination of mean and variance within those 
envelope and attempt to find solution for all valid pairs. 

To find valid means, the program first calculates the fol- 
low range: 

m = n(mreported±η) 

where n be the sample size, mreported be the provide mean, 
and η be the tolerance. Any whole number in this range be a 
mean that could have be generate by the data. 

To find valid variances, the program make use of a math- 
ematical relationship that defines a possible variance for a 
give mean and sample size. Specifically, all valid variance 
can be reach by start at a valid variance and move in 
a step size of 

∆v = 
2 

n−1 
(4) 

(For a proof, see Appendix B). 
Let k = m(n) mod n † and s = 2n−1 , where n be the sample 

size and m be a valid mean. Then a valid initial variance is: 

vinit = 
(n− k)(m−bmc)2 +(k(dme−m)2) 

n−1 
(5) 

(for a proof see Appendix C) and follow from Equation 
4, we know that all valid variance must have the form 

v = vinit + p ·∆v 

= 
(n− k)(m−bmc)2 +(k(dme−m)2)+2p 

n−1 

for some integer p. 
Even for extremely large tolerances, utilize this rela- 

tionship allows the program to rapidly determine the valid 
mean/variance pairs. For each pair, CORVIDS check if any 
solution exist for the pair, even if it initially contains negative 
values; if not, the pair be discarded. If it do have a solution, 
a complete solve be then perform to see if it have a positive 
solution. These solution be returned. 

Bounds and require value 
Using the same procedure, it be possible to determine whether 
there be certain value that must be present for a solution to 
be possible. We eliminate certain value or range of value 
from the scale, and solve the system again for the same sam- 
ple size, mean, and variance. If, after eliminate portion of 
the scale, solution do not exist, it mean that there must be 
value there in all distributions. 

For example, if a give mean, standard deviation, and sam- 
ple size be no longer possible if the scale be restrict from 
2−7 instead of 1−7, then we can say with mathematical cer- 
tainty that for the data to be possible, there must be response 
with a value of 1. 

Forbidden value 
A similar logic applies to find value which be not pos- 
sible. Instead of eliminate possible values, however, they 
be fix at give points. Then, a system of equation be set 
up to solve for the new mean and variance with the give val- 
ues fixed. If no solution be possible, it mean that the data 
cannot have value at the specify points. 

For instance, data that be close to floor and have a very 
small mean and standard deviation may become impossible 
if a value be fix at the upper end of the scale. This mean 
that there be no solution which allow for a response at that 
value, for any possible data. 

Enumeration of all possible solution 
If the above manipulation do not sufficiently constrain the 
possible generate data, it be possible (often at appreciable 
computational expense) to exhaustively enumerate all possi- 
ble data which would generate the give summary statistics. 

†NB: m(n) be not necessarily 0 mod n since m be not necessarily 
an integer 



By manipulate the basis vector that comprise the solu- 
tion space, a provably complete list of all positive solution 
to the set of equation can be generated. A complete for- 
mal proof be give in Appendix A, but the general thrust of the 
proof be a follows: 

1. Linearly combine basis vector to produce an alternate ba- 
si such that each basis vector have one dimension on which 
it uniquely act with value one (all other basis vector be 
zero on that dimension) 

2. Linearly combine the new basis with the initial (potentially 
negative) solution vector such that the new solution vector 
be zero at every dimension which be uniquely act upon by 
some basis vector 

3. We can now combine the new basis vector with our new 
solution in a bound fashion to produce all viable solu- 
tions 

4. Since the sum of all dimension on which no basis vector 
uniquely act be -1 for each basis vector and n for our initial 
solution, our bound be a total of n addition of basis vector 
since any more addition of basis vector would produce 
a negative sum along the dimension not uniquely act 
upon (and thus a negative number). (N.B. no basis vec- 
tor can be subtract since this would introduce a negative 
value along the dimension on which it uniquely acts) 

Examples 
The case of the skewed data 
Let u consider result from a hypothetical survey. 20 sub- 
jects be ask to rate how much they like vegetable a 
a child on a 1 to 7 scale. Using R (R Core Team,2017) and 
the ‘truncnorm‘ package (Trautmann, Steuer, Mersmann, & 
Bornkamp,2014), we generate data with a strong skew to- 
ward the low end of the scale. The average response be 
1.85, with a standard deviation of 0.88 (0.875094, to be pre- 
cise). 

Given this low mean and standard deviation, most re- 
sponses be likely to be toward the ”dislike” end of the rat- 
ing scale. What pattern of response could yield this mean 
and standard deviation, and how similar would the possible 
pattern look? 

There be only 4 possible datasets that can generate these 
statistic (see Figure 1 and Table 1). All solution be ex- 
tremely similar to one another. The high possible value a 
data set can have be 5; these statistic become impossible if 
anyone be to really love vegetable a a child. The data 
originally generate corresponds to solution #1. 

CORVIDS reveals that not only be there few solution to 
these values, but also that the solution be extremely similar 
to one another. 

The case of the round error 
Let u assume a different sort of problem. Imagine another 
20-subject survey, this time with a mean response of 3.2 and 

Figure 1: A 3D histogram of the solution space for the skewed 
data. Frequency of the scale value be on the y-axis, while the 
value itself be on the x-axis. The z-axis be each separate solu- 
tion. In this case there be four solutions; due to the extreme 
skew of the data, none have a value above 5, and the solution 
that do contain a 5 have only 1 and 2 for it other values. 

Sol # 1 2 3 4 5 6 7 
1 8 8 3 1 0 0 0 
2 6 13 0 0 1 0 0 
3 9 5 6 0 0 0 0 
4 7 11 0 2 0 0 0 

Table 1: Number of respondent give each value for the 
skewed data. 

a standard deviation of 1.43637. However, let u say that the 
report standard deviation be incorrectly round down to 
1.43, instead of 1.44. 

CORVIDS have no trouble deal with this. Two decimal 
place be already insufficient precision, so we would have to 
set tolerance even if the statistic be correctly round to 
two decimal places. We recommend set the tolerance up 
to the report precision; here we would set the tolerance to± 
.01. CORVIDS will then search for all possible valid standard 
deviation between 1.42 and 1.44, and will therefore find the 
correct value. 

Running CORVIDS with this tolerance on the SD and no 
tolerance on the mean (since 3.2 be the exact value) result 
in one SD which can produce a solution, and indeed it be our 
original value: 1.43637. Despite the round error and the 
relatively generous envelope to search through, we be able 
not only to find solutions, but in this case find the original 
statistic a well (although it will not always be the case that 
only one value within the tolerance result in solutions; there 
may be several, and the high the tolerance the more likely 
there be to be multiple set of statistic for which solution 



exist). 
Because most statistic will not be report to the preci- 

sion necessary for CORVIDS, tolerance around the mean and 
standard deviation be built into the program. It be thus trivial 
to account for round errors, such a this one; we just need 
to widen the envelope around the give statistic. If any value 
result in solutions, CORVIDS will find them. 

The case of impossible value 
CORVIDS will also return no solution when none be pos- 
sible. Take the skewed data. Let u increase the sample size 
to 25, adjust the mean to 2, but retain a standard deviation of 
0.875094. It turn out that no combination of 25 value can 
produce that mean and standard deviation. 

Similarly, if we attempt to reconstruct value with a sample 
size of 20, a mean of 2, a standard deviation of 0.875094, and 
a scale from 2 - 7, we again see that such value be impossi- 
ble, even with a fairly generous SD tolerance of .01. 

Solutions a a function of parameter value 
In addition to straightforward data reconstruction, CORVIDS 
can be an exploratory tool. 

Let u consider a 1-7 scale with 20 response and a mean 
roughly in the center of the scale, and observe how the num- 
ber of solution change a the standard deviation increases. 

Mean SD # Sols 
3.1 0.5525063 2 
3.1 0.967906 16 
3.1 1.372665 57 
3.1 1.803505 97 
3.1 2.48998 16 
3.1 2.936163 1 

Table 2: The number of possible solution for different SD 
values. 

From Table 2 we can see that the number of solution have 
a U-shape when compare to the size of the standard devia- 
tion. At both very small and very large value for the standard 
deviation, the shape the data must take be constrained. For 
small values, all of the data point have to be cluster quite 
close to each other. For very large values, they have to be 
extremely far apart; the single solution for the large value 
of the standard deviation in Table 2 consists solely of 1 and 
7s. Between these two extremes, the number of possible solu- 
tions increase because the data have more pattern they can 
take. They could be relatively normally distributed, have val- 
ues either close to the mean and or very far away, and so on. 

By contrast, consider the same 1-7 scale with 20 responses, 
but this time hold the standard deviation fix and vary the 
mean. 

Table 3 show that even for the same standard deviation, 
where the mean be locate on the scale affect how many solu- 
tions can exist for that value. More solution exist for mean 
at the center of the scale, when data can vary on either side. 

Mean SD # Sols 
1.4 0.9947229 2 
2.6 0.9947229 14 
4.6 0.9947229 22 
6.6 0.9947229 2 

Table 3: The number of possible solution for different mean 
values. 

However, a the mean move towards the endpoint of the 
scale, there be less ”room” for data point to vary, and few 
solution exist. 

Python Implementation 
We have provide a Python implementation of 
the CORVIDS algorithm that provide the func- 
tionality described above, available on Github at 
https://github.com/katherinemwood/corvids/releases/tag/v1.0.0. 
The code can be download from source, or a stand-alone 
executable can be download and run. 

The source code provide three primary functions. The 
recreateData function take a argument the sample mean, 
the sample variance, the sample size, and the maximum and 
minimum of the scale. If solution exist, the function return 
all possible solution in a list. Optional argument include 
precision argument for the mean and variance; specify 
these will cause the function to test every valid mean and/or 
variance within the range specify by the give value ± pre- 
cision. These argument be useful for circumvent round- 
ing errors, or statistic that be report to an insufficient 
precision. If no tolerance be give for the values, CORVIDS 
may report that no solution exist when in fact valid solution 
exist at value that be close to those reported. 

This function can also check whether value be possible 
and whether solution remain possible under certain value 
constraints. These be optional argument that can be spec- 
ified and passed. To check whether a give solution be con- 
tained the solution space, it may be pass a the checkVals 
argument. 

The analyzeSkew function return a list of the skewness of 
each solution, the mean skew, and the standard deviation of 
skew. This can be use a a rough measure of the heterogene- 
ity of the solution space. 

The graphData function creates an interactive 3D his- 
togram of the solution space. Note that for large solution 
spaces, this can be an extremely slow and costly operation. 
For this reason, the function plot 40 solution at random by 
default.. 

The code run in multi-process mode by default to decrease 
runtime; this argument may be disabled. 

If the stand-alone executable be run, then all interaction 
occur through a GUI. The solution functionality (getting all 
possible solutions, check custom ranges, and force the 
inclusion of values) be available, a be the graphing. 



See the documentation accompany the code for more 
usage details. 

Comparison to other reconstruction tool 
Two extant method exist to reconstruct or otherwise test 
the plausibility of Likert-style data; a Bayesian linear-inverse 
model (Morey,2016) and SPRITE (Heathers,2017). Both of 
these method can be much faster than CORVIDS, especially 
for large scale and sample size or very generous tolerance 
around the mean and variance. SPRITE in particular be also 
more flexible than CORVIDS, capable of accept more pa- 
rameters and work with a great diversity of data types. 

However, each of these method be approximate. They rely 
on a form of random sampling, and therefore cannot guar- 
antee the completeness of their solution space in all cases. 
CORVIDS can make this guarantee; because it be closed-form 
and deterministic, whatever it return will be the only, and 
every, possible solution to the give summary statistic and 
it will give the same result every time it be run. If it report 
that no solution be possible for a give set of values, that be 
a mathematical certainty. 

Applications to non-Likert data 
Applying CORVIDS to Likert-scale type data be straightfor- 
ward. However, CORVIDS be not limited to this data type; it 
can deal with any type of data that fall on a restrict scale 
for which the response be integers. 

Consider a case in which the overall measure be average 
accuracy. 20 subject take a short, 10-item test, and get a 
score out of 10; this be then convert to a percent, and the 
overall average be taken. It might be report thus: “Subjects 
be relatively accurate overall, with an average of 69.5% 
and a standard deviation of 9.45%.” With a bit of tweaking, 
we can change this into something CORVIDS can solve. 

We know that the limit to our scale will be 0 to 10; a 
subject can either answer 0 item correctly, or they can get 
a perfect 10 out of 10 item correct. We convert the average 
percent into an average number of items; on average, sub- 
jects get 6.95 item correct (with a tolerance of .01), with a 
standard deviation of .945 item (and a tolerance of .001). 

When these value be pass to CORVIDS, it will re- 
turn 16 solutions. These solution tell u how many subject 
score each possible value (how many get 10/10, how many 
get 9/10, etc). See Figure 2 for a plot of these solutions. 

The follow criterion have to be met for CORVIDS to be 
able to solve a give set of data: 

1. The response scale must be fixed. There must be a mini- 
mum and maximum response value, either due to the nature 
of the scale (1 - 7 rating, 0 - 10 item correct) or because it 
be report (e.g., “the minimum score in our sample be 4, 
while the maximum be 17”). 

2. The value must be transformable to integers. If the data 
have discrete step and can be transform to integers, they 
can often be solved. For example, even if a scale accepts 

Figure 2: A 3D histogram of the solution space for the ac- 
curacy data. In this case, the response value be the number 
of item out of 10 that a subject answer correctly, and the 
frequency be how many subject achieve that score. 

fractional response such a .25, a long a the minimum 
step size be fix at .25, it can be transform to an integer 
scale by multiply it by 4. Even data that might appear to 
be continuous, such a weight or reaction time, might have 
a minimum step size due to the precision to which it can be 
measure (e.g. 1 gram, 10ms, .5 inches). 

3. The scale must be reasonably constrained. Certain val- 
ues, such a reaction time, in theory have a fix scale (per- 
hap any time faster than 250ms or longer than 2000ms be 
discarded, give a maximum and minimum) and a fix 
step size (1ms). If precision on the mean and standard de- 
viation be perfect, solve a scale of this size might take 
30 minutes. The require time will increase if tolerance be 
add and admits more mean/variance pair that have so- 
lutions. 

Conclusion 
The CORVIDS algorithm can fully reconstruct raw data from 
summary statistic alone. When data generate from a fix 
scale, one need only the limit and granularity of the scale 
(e.g. ”integers 1 to 7”), the mean of the data, the standard 
deviation or variance, and the number of subject collect in 
order to reconstruct every dataset which could have generate 
those summary statistics. 

CORVIDS can be use in a variety of ways. Reconstruc- 
tion be among it most useful; in case where enough informa- 
tion be report but the original data be unavailable, CORVIDS 
can return a set of solution that be guaranteed to contain the 
original data. CORVIDS can also be use in an exploratory 
way. In some cases, the solution will be quite constrain 
and similar to one another; for example, all of the solution 
will be quite skewed. CORVIDS can be use to explore the 
solution space, and examine which possibility remain when 



the scale be restrict or certain response value be require 
to be present. In the case of our example with highly skewed 
data, there be absolutely no response possible above a 5, 
for instance. CORVIDS can also be use to explore proper- 
tie of distributions; one can generate a set of data accord 
to certain values, and then explore how many other solution 
exist and what their property are. 

References 
Havas, G., Majewski, B. S., & Matthews, K. R. (1998). Ex- 

tend gcd and hermite normal form algorithm via lattice 
basis reduction. Experimental Mathematics, 7(2), 125– 
136. 

Heathers, J. (2017). Introducing sprite (and the 
case of the carthorse child). Available from 
https://hackernoon.com/introducing-sprite-and 
-the-case-of-the-carthorse-child-58683c2bfeb 

Likert, R. (1932). A technique for the measurement of atti- 
tudes. Archives of Psychology, 22(140), 1–55. 

Matiyasevich, Y. V. (1972). Diophantine sets. Russian Math- 
ematical Surveys, 27(5), 124–164. 

Morey, R. (2016). How to check likert scale 
summary for plausibility. Available from 
http://bayesfactor.blogspot.co.uk/2016/03 
/how-to-check-likert-scale-summaries-for.html 

R Core Team. (2017). R: A language and en- 
vironment for statistical computing. Available from 
https://www.R-project.org/ 

Trautmann, H., Steuer, D., Mersmann, O., & 
Bornkamp, B. (2014). truncnorm: Trun- 
cat normal distribution. Available from 
https://CRAN.R-project.org/package=truncnorm 
(R package version 1.0-7) 

Author Note 
DS originally pose the question of algorithmically recon- 
structing data. SW developed the algorithm, proofs, and 
Python implementation. KW discover the deterministic 
variance search, assist in test and debugging, and write 
the documentation. KW and SW draft the manuscript. All 
author critically edit the manuscript. 

Appendix A 
Formal Proof of completeness: 

Proof. We begin by assume a give initial solution vector 
(perhaps contain invalid negative values) call s1 and a 
basis call B1 of a vector space of transformation such that 
the action of any element of the vector space on our initial so- 
lution produce an additional solution (which may also con- 
tain invalid negative values). Our goal be to detail a method 
to produce all possible solutions, S, with exclusively positive 
integral value at every index. 

1. Any basis vector of a vector space may be replace by itself 
sum with a scalar multiple of any other basis vector, 

and the result new set of vector be a valid basis of the 
original vector space. 

2. Given a minimal basis (B1) of size m where each vector have 
dimensionality l, because of (1.), we can construct a new 
basis (B2) for the same vector space which have the property 
that of the rightmost (at least‡) m coordinates, exactly one 
have a value of 1 and the rest be all 0 where each 1 be at 
a different index (each vector restrict to these m unique 
index under consideration be orthogonal). Doing so may 
result in non-integral value at some dimension of some 
vectors, however, this do not cause any problem since 
any generate non-integral solution can be discard at 
the end. 

3. Using B2, we can manipulate our start solution s1 
(which may contain invalid negative values) such that the 
rightmost (at least) m coordinate be all zero to produce 
a new solution s2 (also potentially contain negative val- 
ues) 

4. B2 and s2 have several desirable properties: 

• Each vector in B2 have some dimension on which it 
uniquely act 
• No fractional scalar multiple of the basis element of 
B2 can ever preserve integer value (all valid action 
by B2 require integer multiple of the basis elements) 
since they have a value of 1 on the dimension that they 
uniquely act upon.§ 

• Any valid solution s3 must have the form 

s3 = s2 + ∑ 
bi∈B2 

ai ·bi 

where each ai > 0 since s2’s rightmost m value be all 
0 and each bi act uniquely and positively over exactly 
one of those rightmost values, if a basis vector be ever 
subtracted, it would introduce an invalid negative value 
which no other basis vector could compensate for. 

5. Since the action of any basis vector in B2 on s2 preserve 
it satisfaction of Equations 1 - 3, give that Equation 1 
require that the total sum of any produce s3 be n, the 
sum of the coordinate of every vector in B2 must be 0. 

6. Using (2.), we know that the sum of the last m coordinate 
be exactly 1. Combining this with (5.) we know that the 
first l−m coordinate must sum to -1 

7. Lastly, use the fact that s2 satisfies Equation 1 and have 
value of 0 for it rightmost m coordinates, the first l−m 

‡It can be the case that rather than m, the correct value may in 
fact be more than m when all basis vector be zero on some dimen- 
sion. However, this do not impact the proof or the algorithm in 
any way other than the superficial. 

§That is, if the action of a basis vector introduces a non-integer 
value along the dimension on which it uniquely acts, no other basis 
vector can “fix” it to an integer value. 



coordinate must sum to n. Thus for any valid solution s3 
a generate above, 

∑ 
i 

ai ≤ n 

. Thus, since each ai must be an integer, we can exhaus- 
tively enumerate and test all possible set of ais.¶‖ 

Appendix B 
Proof. Given some initial 

σ2init = 

n 
∑ 

l=1 
(xl−µ)2 

n−1 

let 

∑ 
l 6=i, j 

(xl−µ)2 =C 

1. 

σ2init = 
(xi−µ)2 +(x j−µ)2 +C 

n−1 

2. Generating a change in the data by increase one value 
and decrease another: 

σ2modi f ied = 
(xi−1−µ)2 +(x j +1−µ)2 +C 

n−1 

3. Taking the difference between these two yield the change 
in variance brought about by modify the dataset: 

∆σ2 = 
(x j +1−µ)2 +(xi−1−µ)2 +C− (xi−µ)2− (x j−µ)2−C 

n−1 
−→ 

∆σ2 = 
(xi−µ)2 +(x j−µ)2− (xi−µ)2− (x j−µ)2−2(xi−µ)+1+2(x j−µ)+1 

n−1 

Expanding the term and simplify yields: 

4. 

∆σ2 = 
2(xi− x j)+2 

n−1 
= 

2 
n−1 

· [(xi− x j)+1] 

meaning that the result variance change from move 
two value always have to be a multiple of 2/(n-1). 

¶In practice, we need not enumerate all combination up to n, 
and this search can be considerably optimize by search space prun- 
ing; however, it be still computationally expensive for many datasets. 
‖The theoretical time complexity for this be 

(n+m−1 
n 
) 

which 
grows quite quickly; however, in practice search space prune dras- 
tically improves performance 

Appendix C 
Proof. Given k = m · (n) mod n, ∗∗ where n be the sample 
size and m be the report sample mean, we will construct the 
dataset with a many subject a close to the mean a possible. 

k+n · bmc= m ·n 

k+ 
n−k 

∑ 
1 
bmc+ 

k 

∑ 
1 
bmc= m ·n 

Moving the k into the second summation yield 
n−k 

∑ 
1 
bmc+ 

k 

∑ 
1 
(bmc+1) = m ·n 

since bmc+1 = dme −→ 
n−k 

∑ 
1 
bmc+ 

k 

∑ 
1 
dme= m ·n 

And thus we know that a dataset with n−k value of bmc and 
k value of dme give u the desire mean of m. Computing 
the variance of this valid dataset, we obtain: 

v = 
(n− k) · (m−bmc)2 + k · (dme−m)2 

n−1 

∗∗If m be an integer, k = 0 and this exercise becomes trivial so we 
will assume m be not an integer 


