


















































Learning Certifiably Optimal Rule Lists for Categorical Data 

Elaine Angelino elaine@eecs.berkeley.edu 
Department of Electrical Engineering and Computer Sciences 
University of California, Berkeley, Berkeley, CA 94720 

Nicholas Larus-Stone nlarusstone@college.harvard.edu 
Daniel Alabi alabid@g.harvard.edu 
Margo Seltzer margo@eecs.harvard.edu 
School of Engineering and Applied Sciences 
Harvard University, Cambridge, MA 02138 

Cynthia Rudin cynthia@cs.duke.edu 
Department of Computer Science and Department of Electrical and Computer Engineering 

Duke University, Durham, NC 27708 

Abstract 

We present the design and implementation of a custom discrete optimization technique 
for building rule list over a categorical feature space. Our algorithm provide the optimal 
solution, with a certificate of optimality. By leverage algorithmic bounds, efficient data 
structures, and computational reuse, we achieve several order of magnitude speedup in 
time and a massive reduction of memory consumption. We demonstrate that our approach 
produce optimal rule list on practical problem in seconds. This framework be a novel 
alternative to CART and other decision tree methods. 

Keywords: Rule lists, Decision trees, Optimization, Interpretable model 

1. Introduction 

As machine learn continue to gain prominence in socially-important decision-making, 
the interpretability of predictive model remains a crucial problem. Our goal be to build 
model that be both highly predictive and easily understood by humans. We use rule lists, 
also know a decision lists, to achieve this goal. Rule list be list compose of if-then 
statements, which be easily interpreted; the rule give a reason for each prediction (Fig- 
ure 1). 

Constructing rule lists, or more generally, decision trees, have be a challenge for more 
than 30 years; most approach use greedy splitting technique (Rivest, 1987; Breiman 
et al., 1984; Quinlan, 1993). Recent approach use Bayesian analysis, either to find a locally 
optimal solution (Chipman et al., 1998) or to explore the search space (Letham et al., 2015; 
Yang et al., 2016). These approach achieve high accuracy while also manage to run 
reasonably quickly. However, despite the apparent accuracy of the rule list generate by 
these algorithms, there be no way to determine either if the generate rule list be optimal or 
how close it be to optimal. 

Optimality be important, because there be societal implication for a lack of optimality. 
Consider the recent ProPublica article on the COMPAS recidivism prediction tool (Larson 
et al., 2016). It highlight a case where a black-box, proprietary predictive model be be 
use for recidivism prediction. The author show that the COMPAS score be racially 

ar 
X 

iv 
:1 

70 
4. 

01 
70 

1v 
1 

[ 
st 

at 
.M 

L 
] 

6 
A 

pr 
2 

01 
7 



Angelino, Larus-Stone, Alabi, Seltzer, and Rudin 

if (age = 23− 25) ∧ (priors = 2− 3) then predict yes 
else if (age = 18− 20) then predict yes 
else if (sex = male) ∧ (age = 21− 22) then predict yes 
else if (priors > 3) then predict yes 
else predict no 

Figure 1: An example rule list that predicts two-year recidivism for the ProPublica dataset, 
found by CORELS. 

biased, but since the model be not transparent, no one (outside of the creator of COM- 
PAS) can determine the reason or extent of the bias (Larson et al., 2016), nor can anyone 
determine the reason for any particular prediction. By use COMPAS, user implicitly 
assume that a transparent model would not be sufficiently accurate for recidivism predic- 
tion, i.e., they assume that a black box model would provide good accuracy. We wonder 
whether there be indeed no transparent and sufficiently accurate model. Answering this 
question require solve a computationally hard problem. Namely, we would like to both 
find a transparent model that be optimal within a particular pre-determined class of model 
and produce a certificate of it optimality. This would enable one to say, for this problem 
and model class, with certainty and before resort to black box methods, whether there 
exists a transparent model. 

To that end, we consider the class of rule list assemble from pre-mined frequent item- 
set and search for an optimal rule list that minimizes a regularize risk function, R. This 
be a hard discrete optimization problem. Brute force solution that minimize R be compu- 
tationally prohibitive due to the exponential number of possible rule lists. However, this be 
a bad case bound that be not realize in practical settings. For realistic cases, it be possible 
to solve fairly large case of this problem to optimality, with the careful use of algorithms, 
data structures, and implementation techniques. 

We develop specialized tool from the field of discrete optimization and artificial intel- 
ligence. Specifically, we introduce a special branch-and-bound algorithm, call Certifiably 
Optimal RulE ListS (CORELS), that provide (1) the optimal solution, (2) a certificate 
of optimality, and (3) optionally, a collection of near-optimal solution and the distance 
between each such solution and the optimal one. The certificate of optimality mean that 
we can investigate how close other model (e.g., model provide by greedy algorithms) be 
to optimal. In particular, we can investigate if the rule list from probabilistic approach 
be nearly optimal or whether those approach sacrifice too much accuracy in the interest 
of speed. 

Within it branch-and-bound procedure, CORELS maintains a low bound on the 
minimum value of R that each incomplete rule list can achieve. This allows CORELS to 
prune an incomplete rule list (and every possible extension) if the bound be large than 
the error of the best rule list that it have already evaluated. The use of careful bound 
technique lead to massive prune of the search space of potential rule lists. It continue 
to consider incomplete and complete rule list until it have either examine or eliminate 
every rule list from consideration. Thus, CORELS terminates with the optimal rule list and 
a certificate of optimality. 

2 



Learning Certifiably Optimal Rule Lists for Categorical Data 

The efficacy of CORELS depends on how much of the search space our bound allow u 
to prune; we seek a tight low bound on R. The bound we maintain throughout execution be 
a maximum of several bounds, that come in three categories. The first category of bound be 
those intrinsic to the rule themselves. This category include bound state that each rule 
must capture sufficient data; if not, the rule list be provably non-optimal. The second type 
of bound compare a low bound on the value of R to that of the current best solution. 
This allows u to exclude part of the search space that could never be good than our 
current solution. Finally, our last type of bound be base on compare incomplete rule list 
that capture the same data and allow u to pursue only the most accurate option. This last 
class of bound be especially important – without our use of a novel symmetry-aware map, 
we be unable to solve most problem of reasonable scale. This symmetry-aware map keep 
track of the best accuracy over all observe permutation of a give incomplete rule list. 

We keep track of these bound use a modify prefix tree, a data structure also know 
a a trie. Each node in the prefix tree represent an individual rule; thus, each path in the 
tree represent a rule list such that the final node in the path contains metric about that 
rule list. This tree structure, together with a search policy and sometimes a queue, enables a 
variety of strategies, include breadth-first, best-first, and stochastic search. In particular, 
we can design different best-first strategy by customize how we order element in a 
priority queue. In addition, we be able to limit the number of node in the tree and thereby 
enable tune of space-time tradeoff in a robust manner. This tree structure be a useful way 
of organize the generation and evaluation of rule lists, and be parallelizable. 

We evaluate CORELS on a number of publicly available datasets. Our metric of success 
be 10-fold cross-validated prediction accuracy on a subset of the data. These datasets 
involve hundred of rule and thousand of observations. CORELS be generally able to 
find an optimal rule list in a matter of second and certify it optimality within about 10 
minutes. We show that we be able to achieve good or similar out-of-sample accuracy on 
these datasets compare to the popular greedy algorithms, CART and C4.5. 

CORELS target large (not massive) problems, where interpretability and certifiable op- 
timality be important. We illustrate the efficacy of our approach use (1) the ProPublica 
COMPAS dataset (Larson et al., 2016), for the problem of two-year recidivism prediction, 
and (2) the NYCLU 2014 stop-and-frisk dataset (New York Civil Liberties Union, 2014), to 
predict whether a weapon will be found on a stop individual who be frisk or searched. 
We produce certifiably optimal, interpretable rule list that achieve the same accuracy a 
approach such a random forests. This call into question the need for use of a proprietary, 
black box algorithm for recidivism prediction. 

Our implementation of CORELS be at https://github.com/nlarusstone/corels. 1 

2. Related Work 

We discus related literature in several subfields, and highlight two recent work that this 
paper build on. 

Interpretable Models: There be a grow interest in interpretable (transparent, compre- 
hensible) model because of their societal importance (see Rüping, 2006; Bratko, 1997; 

1. Our work overlap with the thesis present by Larus-Stone (2017). 

3 

https://github.com/nlarusstone/corels 


Angelino, Larus-Stone, Alabi, Seltzer, and Rudin 

Dawes, 1979; Vellido et al., 2012; Giraud-Carrier, 1998; Holte, 1993; Shmueli, 2010; Huys- 
man et al., 2011; Freitas, 2014). There be now regulation on algorithmic decision-making 
in the European Union on the “right to an explanation” (Goodman and Flaxman, 2016) 
that would legally require interpretability in predictions. 

Optimal Decision Tree Modeling : The body of work closest to ours be possibly that of 
optimal decision tree modeling. Since the late 1990’s, there have be research on building 
optimal decision tree use optimization technique (Bennett and Blue, 1996; Dobkin et al., 
1996), continue until the present (Farhangfar et al., 2008). A particularly interest paper 
along these line be that of Nijssen and Fromont (2010), who create a “bottom-up” way 
to form optimal decision trees. Their method performs an expensive search step, mining 
all possible leaf (rather than all possible rules), and us those leaf to form trees. 
Their method can lead to memory problems, but it be possible that these memory issue 
can be mitigate use the theorem in this paper. 2 Another work close to ours be that 
of Garofalakis et al. (2000), who introduce an algorithm to generate more interpretable 
decision tree by allow constraint to be place on the size of the decision tree. During 
tree construction, they bound the possible Minimum Description Length (MDL) cost of 
every different split at a give node. If every split at that node be more expensive than the 
actual cost of the current subtree, then that node can be pruned. In this way, they be able 
to prune the tree while construct it instead of just construct the tree and then prune 
at the end. They do not aim for optimal trees; they build tree that obey constraints, and 
find optimal subtrees within the tree that be built during the building phase. 

Greedy splitting and pruning: Unlike optimal decision tree methods, method like CART 
(Breiman et al., 1984) and C4.5 (Quinlan, 1993) do not perform exploration of the search 
space beyond greedy splitting. There be a huge number of algorithm in this class. 

Bayesian tree and rule list methods: Some of these approach that aim to explore the 
space of tree (Dension et al., 1998; Chipman et al., 2002, 2010) use Monte Carlo methods. 
However, the space of tree of a give depth be much large than the space of rule list of 
that same level of depth, and the tree within these algorithm be grown in a top-down 
greedy way. Because of this, the author note that their MCMC chain tend to reach only 
locally optimal solutions. This explains why Bayesian rule-based method (Letham et al., 
2015; Yang et al., 2016) have tend to be more successful in escape local minima. Our 
work build specifically on that of Yang et al. (2016). In particular, we use their library for 
efficiently represent and operating on bit vectors, and build on their bounds. Note that 
the RIPPER algorithm (Cohen, 1995) be similar to the Bayesian tree method in that it 
grows, prunes, and then locally optimizes. 

Rule learn methods: Most rule learn method be not design for optimality or 
interpretability, but for computational speed and/or accuracy. In associative classification 
(Vanhoof and Depaire, 2010; Liu et al., 1998; Li et al., 2001; Yin and Han, 2003), classifier 
be often form greedily from the top down a rule lists, or they be form by take the 
simple union of pre-mined rules, whereby any observation that fit into any of the rule 
be classify a positive. In inductive logic program (Muggleton and De Raedt, 1994), 
algorithm construct disjunctive normal form pattern via a set of operation (rather than 
use optimization). These approach be not appropriate for obtain a guarantee of 

2. There be no public version of their code for distribution a of this writing. 

4 



Learning Certifiably Optimal Rule Lists for Categorical Data 

optimality. Methods for decision list learn construct rule list iteratively in a greedy 
way (Rivest, 1987; Sokolova et al., 2003; Marchand and Sokolova, 2005; Rudin et al., 2013; 
Goessling and Kang, 2015); these too have no guarantee of optimality, and tend not to 
produce optimal rule list in general. Some method allow for interpretation of single rules, 
without construct rule list (McCormick et al., 2012). 

There be a tremendous amount of related work in other subfields that be too numerous 
to discus at length here. We have not discuss rule mining algorithm since they be part 
of an interchangeable preprocessing step for our algorithm and be deterministically fast 
(i.e., they will not generally slow our algorithm down). We also do not discus method that 
create disjunctive normal form models, e.g., logical analysis of data, and many associative 
classification methods. 

Related problem with interpretable list of rules: Beyond tree that be optimize for 
accuracy and sparsity, rule list have be developed for various applications, and with 
exotic type of constraints. For example, Falling Rule Lists (Wang and Rudin, 2015) be 
constrain to have decrease probability down the list a be rule list for dynamic treat- 
ment regime (Zhang et al., 2015) and cost-sensitive dynamic treatment regime (Lakkaraju 
and Rudin, 2017). Both Wang and Rudin (2015) and Lakkaraju and Rudin (2017) use Monte 
Carlo search to explore the space of rule lists. The method propose in this paper could po- 
tentially be adapt to handle these kind of interest problems. We be currently work 
on bound for Falling Rule Lists (Chen and Rudin, 2017) similar to those present here. 

Two work that this paper build on be those of Yang et al. (2016), and Rudin and 
Ertekin (2015). The work of Yang et al. provide the bit vector library and several idea 
that be use here, and we use their code a a start point. Their scalable Bayesian 
rule list (SBRL) method have us beyond those of CORELS because SBRL model be 
probabilistic, produce an estimate of P(Y = 1 |X) for any X, rather than a yes/no clas- 
sification. On the other hand, because the model be probabilistic, the bound depend on 
approximation involve gamma functions. Bounds for CORELS have no such approxima- 
tions and be substantially tighter. Yang et al. aim to find the optimal solution but do not 
aim to prove optimality. 

Both Yang et al. (2016) and Rudin and Ertekin (2015) contribute bound that we 
start from in this work, and in particular, the latter us the same objective a we do and 
have some of the same bounds, include the minimum support bound (§3.7, Theorem 10). 
However, Ertekin and Rudin’s work be for a different purpose, namely it be for building 
rule list that can be customized; since the author use mixed integer program (MIP), 
user can easily add constraint to the MIP and create rule list that obey these arbitrary 
constraints. As in our framework, their rule list be certifiably optimal. However, since 
generic MIP software be use without efficient bound and data structure like the one 
introduce here, much more time can be require to prove optimality and to find the 
optimal solution. 

3. Learning optimal rule list 

In this section, we present our framework for learn certifiably optimal rule lists. First, 
we define our set and useful notation (§3.1), follow by the objective function we 
seek to minimize (§3.2). Next, we describe the principal structure of our optimization algo- 

5 



Angelino, Larus-Stone, Alabi, Seltzer, and Rudin 

if (age = 23− 25)∧ (priors = 2− 3) then predict yes 
else if (age = 18− 20) then predict yes 
else if (sex = male)∧(age = 21−22) then predict yes 
else if (priors > 3) then predict yes 
else predict no 

if p1 then predict q1 
else if p2 then predict q2 
else if p3 then predict q3 
else if p4 then predict q4 
else predict q0 

Figure 2: The same 4-rule list d = (r1, r2, r3, r4, r0), a in Figure 1, that predicts two- 
year recidivism for the ProPublica dataset. Each rule be of the form rk = pk → qk, for 
all k = 0, . . . , 4. We also equivalently write d = (dp, δp, q0,K), where dp = (p1, p2, p3, p4), 
δp = (1, 1, 1, 1), q0 = 0, and K = 4. 

rithm (§3.3), which depends on a hierarchically structure objective low bound (§3.4). We 
then derive a series of additional bound that we incorporate into our algorithm because 
they enable aggressive prune of our state space. 

3.1 Rule list for binary classification 

We restrict our set to binary classification, where rule list be Boolean functions; this 
framework be straightforward to generalize to multi-class classification. Let {(xn, yn)}Nn=1 
denote training data, where xn ∈ {0, 1}J be binary feature and yn ∈ {0, 1} be labels. 
Let x = {xn}Nn=1 and y = {yn}Nn=1, and let xn,j denote the j-th feature of xn. 

A rule list d = (r1, r2, . . . , rK , r0) of length K ≥ 0 be a (K + 1)-tuple consist of K 
distinct association rules, rk = pk → qk, for k = 1, . . . ,K, follow by a default rule r0. 
Figure 2 illustrates a rule list, which for clarity, we sometimes call a K-rule list. An asso- 
ciation rule r = p→ q be an implication correspond to the conditional statement, “if p, 
then q.” In our setting, an antecedent p be a Boolean assertion that evaluates to either 
true or false for each datum xn, and a consequent q be a label prediction. For example, 
(xn,1 = 0) ∧ (xn,3 = 1)→ (yn = 1) be an association rule. The final default rule r0 in a rule 
list can be thought of a a special association rule p0 → q0 whose antecedent p0 simply 
asserts true. 

Let d = (r1, r2, . . . , rK , r0) be a K-rule list, where rk = pk → qk for each k = 0, . . . ,K. 
We introduce a useful alternate rule list representation: d = (dp, δp, q0,K), where we de- 
fine dp = (p1, . . . , pK) to be d’s prefix, δp = (q1, . . . , qK) ∈ {0, 1}K give the label predic- 
tions associate with dp, and q0 ∈ {0, 1} be the default label prediction. In Figure 1, d = 
(r1, r2, r3, r4, r0), and each rule be of the form rk = pk → qk, for all k = 0, . . . , 4; equivalently, 
d = (dp, δp, q0,K), where dp = (p1, p2, p3, p4), δp = (1, 1, 1, 1), q0 = 0, and K = 4. 

Let dp = (p1, . . . , pk, . . . , pK) be an antecedent list, then for any k ≤ K, we define dkp = 
(p1, . . . , pk) to be the k-prefix of dp. For any such k-prefix d 

k 
p, we say that dp start with d 

k 
p. 

For any give space of rule lists, we define σ(dp) to be the set of all rule list whose prefix 
start with dp: 

σ(dp) = {(d′p, δ′p, q′0,K ′) : d′p start with dp}. (1) 

If dp = (p1, . . . , pK) and d 
′ 
p = (p1, . . . , pK , pK+1) be two prefix such that d 

′ 
p start with dp 

and extends it by a single antecedent, we say that dp be the parent of d 
′ 
p and that d 

′ 
p be a 

child of dp. 

6 



Learning Certifiably Optimal Rule Lists for Categorical Data 

A rule list d classifies datum xn by provide the label prediction qk of the first rule rk 
whose antecedent pk be true for xn. We say that an antecedent pk of antecedent list dp 
capture xn in the context of dp if pk be the first antecedent in dp that evaluates to true 
for xn. We also say that a prefix capture those data capture by it antecedents; for a rule 
list d = (dp, δp, q0,K), data not capture by the prefix dp be classify accord to the 
default label prediction q0. 

Let β be a set of antecedents. We define cap(xn, β) = 1 if an antecedent in β capture 
datum xn, and 0 otherwise. For example, let dp and d 

′ 
p be prefix such that d 

′ 
p start 

with dp, then d 
′ 
p capture all the data that dp captures: 

{xn : cap(xn, dp)} ⊆ {xn : cap(xn, d′p)}. (2) 

Now let dp be an order list of antecedents, and let β be a subset of antecedent in dp. 
Let u define cap(xn, β | dp) = 1 if β capture datum xn in the context of dp, i.e., if the first 
antecedent in dp that evaluates to true for xn be an antecedent in β, and 0 otherwise. Thus, 
cap(xn, β | dp) = 1 only if cap(xn, β) = 1; cap(xn, β | dp) = 0 either if cap(xn, β) = 0, or if 
cap(xn, β) = 1 but there be an antecedent α in dp, precede all antecedent in β, such that 
cap(xn, α) = 1. For example, if dp = (p1, . . . , pk, . . . , pK) be a prefix, then 

cap(xn, pk | dp) = 

( 
k−1∧ 
k′=1 

¬ cap(xn, pk′) 

) 
∧ cap(xn, pk) (3) 

indicates whether antecedent pk capture datum xn in the context of dp. Now, define 
supp(β,x) to be the normalize support of β, 

supp(β,x) = 
1 

N 

N∑ 
n=1 

cap(xn, β), (4) 

and similarly define supp(β,x | dp) to be the normalize support of β in the context of dp, 

supp(β,x | dp) = 
1 

N 

N∑ 
n=1 

cap(xn, β | dp), (5) 

Next, we address how empirical data constrains rule lists. Given training data (x,y), an 
antecedent list dp = (p1, . . . , pK) implies a rule list d = (dp, δp, q0,K) with prefix dp, where 
the label prediction δp = (q1, . . . , qK) and q0 be empirically set to minimize the number 
of misclassification error make by the rule list on the training data. Thus for 1 ≤ k ≤ K, 
label prediction qk corresponds to the majority label of data capture by antecedent pk in 
the context of dp, and the default q0 corresponds to the majority label of data not capture 
by dp. In the remainder of our presentation, whenever we refer to a rule list with a particular 
prefix, we implicitly assume these empirically determine label predictions. 

Finally, we note that our approach leverage pre-mined rules, follow the methodology 
take by Letham et al. (2015) and Yang et al. (2016). One of the result we late prove 
implies a constraint that can be use a a filter during rule mining – antecedent must have 
at least some minimum support give by the low bound in Theorem 10. 

7 



Angelino, Larus-Stone, Alabi, Seltzer, and Rudin 

3.2 Objective function 

We define a simple objective function for a rule list d = (dp, δp, q0,K): 

R(d,x,y) = `(d,x,y) + λK. (6) 

This objective function be a regularize empirical risk; it consists of a loss `(d,x,y), mea- 
suring misclassification error, and a regularization term that penalizes longer rule lists. 
`(d,x,y) be the fraction of training data whose label be incorrectly predict by d. In 
our setting, the regularization parameter λ ≥ 0 be a small constant; e.g., λ = 0.01 can be 
thought of a add a penalty equivalent to misclassifying 1% of data when increase a 
rule list’s length by one association rule. 

3.3 Optimization framework 

Our objective have structure amenable to global optimization via a branch-and-bound frame- 
work. In particular, we make a series of important observation that each translates into a 
useful bound, and that together interact to eliminate large part of the search space. We 
will discus these in depth throughout the follow sections: 

• Lower bound on a prefix also hold for every extension of that prefix. (§3.4, Theorem 1) 

• We can sometimes prune all rule list that be longer than a give prefix, even without 
know anything about what rule will be place below that prefix. (§3.4, Lemma 2) 

• We can calculate a priori an upper bound on the maximum length of an optimal rule 
list. (§3.5, Theorem 6) 

• Each rule in an optimal rule list must have support that be sufficiently large. This allows 
u to construct rule list from frequent itemsets, while preserve the guarantee that 
we can find a globally optimal rule list from pre-mined rules. (§3.7, Theorem 10) 

• Each rule in an optimal rule list must predict accurately. In particular, the number of 
observation predict correctly by each rule in an optimal rule list must be above a 
threshold. (§3.7, Theorem 11) 

• We need only consider the optimal permutation of antecedent in a prefix; we can 
omit all other permutations. (§3.10, Theorem 17 and Corollary 18) 

• If multiple observation have identical feature and opposite labels, we know that any 
model will make mistakes. In particular, the number of mistake on these observation 
will be at least the number of observation with the minority label. (§3.14, Theorem 22) 

3.4 Hierarchical objective low bound 

We can decompose the misclassification error into two contribution correspond to the 
prefix and the default rule: 

`(d,x,y) ≡ `p(dp, δp,x,y) + `0(dp, q0,x,y), (7) 

8 



Learning Certifiably Optimal Rule Lists for Categorical Data 

where dp = (p1, . . . , pK) and δp = (q1, . . . , qK); 

`p(dp, δp,x,y) = 
1 

N 

N∑ 
n=1 

K∑ 
k=1 

cap(xn, pk | dp) ∧ 1[qk 6= yn] (8) 

be the fraction of data capture and misclassified by the prefix, and 

`0(dp, q0,x,y) = 
1 

N 

N∑ 
n=1 

¬ cap(xn, dp) ∧ 1[q0 6= yn] (9) 

be the fraction of data not capture by the prefix and misclassified by the default rule. 
Eliminating the latter error term give a low bound b(dp,x,y) on the objective, 

b(dp,x,y) ≡ `p(dp, δp,x,y) + λK ≤ R(d,x,y), (10) 

where we have suppress the low bound’s dependence on label prediction δp because 
they be fully determined, give (dp,x,y). Furthermore, a we state next in Theorem 1, 
b(dp,x,y) give a low bound on the objective of any rule list whose prefix start with dp. 

Theorem 1 (Hierarchical objective low bound) Define b(dp,x,y) a in (10). Also, 
define σ(dp) to be the set of all rule list whose prefix start with dp, a in (1). Let d = 
(dp, δp, q0,K) be a rule list with prefix dp, and let d 

′ = (d′p, δ 
′ 
p, q 
′ 
0,K 

′) ∈ σ(dp) be any rule 
list such that it prefix d′p start with dp and K 

′ ≥ K, then b(dp,x,y) ≤ R(d′,x,y). 

Proof Let dp = (p1, . . . , pK) and δp = (q1, . . . , qK); let d 
′ 
p = (p1, . . . , pK , pK+1, . . . , pK′) and 

δ′p = (q1, . . . , qK , qK+1, . . . , qK′). Notice that d 
′ 
p yield the same mistake a dp, and possibly 

additional mistakes: 

`p(d 
′ 
p, δ 
′ 
p,x,y) = 

1 

N 

N∑ 
n=1 

K′∑ 
k=1 

cap(xn, pk | d′p) ∧ 1[qk 6= yn] 

= 
1 

N 

N∑ 
n=1 

( 
K∑ 
k=1 

cap(xn, pk | dp) ∧ 1[qk 6= yn] + 
K′∑ 

k=K+1 

cap(xn, pk | d′p) ∧ 1[qk 6= yn] 

) 
≥ `p(dp, δp,x,y), (11) 

where we have use the fact that cap(xn, pk | d′p) = cap(xn, pk | dp) for 1 ≤ k ≤ K. It follow 
that 

b(dp,x,y) = `p(dp, δp,x,y) + λK 

≤ `p(d′p, δ′p,x,y) + λK ′ = b(d′p,x,y) ≤ R(d′,x,y). (12) 

To generalize, consider a sequence of prefix such that each prefix start with all previ- 
ous prefix in the sequence. It follow that the correspond sequence of objective low 

9 



Angelino, Larus-Stone, Alabi, Seltzer, and Rudin 

Algorithm 1 Branch-and-bound for learn rule lists. 

Input: Objective function R(d,x,y), objective low bound b(dp,x,y), set of antecedent 
S = {sm}Mm=1, training data (x,y) = {(xn, yn)}Nn=1, initial best know rule list d0 with 
objective R0 = R(d0,x,y) 
Output: Provably optimal rule list d∗ with minimum objective R∗ 

(dc, Rc)← (d0, R0) . Initialize best rule list and objective 
Q← queue( [ ( ) ] ) . Initialize queue with empty prefix 
while Q not empty do . Stop when queue be empty 

dp ← Q.pop( ) . Remove prefix dp from the queue 
if b(dp,x,y) < R 

c then . Bound: Apply Theorem 1 
R← R(d,x,y) . Compute objective of dp’s rule list d 
if R < Rc then . Update best rule list and objective 

(dc, Rc)← (d,R) 
end if 
for s in S do . Branch: Enqueue dp’s child 

if s not in dp then 
Q.push( (dp, s) ) 

end if 
end for 

end if 
end while 
(d∗, R∗)← (dc, Rc) . Identify provably optimal solution 

bound increase monotonically. This be precisely the structure require and exploit by 
branch-and-bound, illustrate in Algorithm 1. 

Specifically, the objective low bound in Theorem 1 enables u to prune the state 
space hierarchically. While execute branch-and-bound, we keep track of the current best 
(smallest) objective Rc, thus it be a dynamic, monotonically decrease quantity. If we 
encounter a prefix dp with low bound b(dp,x,y) ≥ Rc, then by Theorem 1, we needn’t 
consider any rule list d′ ∈ σ(dp) whose prefix d′p start with dp. For the objective of such a 
rule list, the current best objective provide a low bound, i.e., R(d′,x,y) ≥ b(d′p,x,y) ≥ 
b(dp,x,y) ≥ Rc, and thus d′ cannot be optimal. 

Next, we state an immediate consequence of Theorem 1. 

Lemma 2 (Objective low bound with one-step lookahead) Let dp be a K-prefix 
and let Rc be the current best objective. If b(dp,x,y) + λ ≥ Rc, then for any K ′-rule list 
d′ ∈ σ(dp) whose prefix d′p start with dp and K ′ > K, it follow that R(d′,x,y) ≥ Rc. 

Proof By the definition of the low bound (10), which include the penalty for longer 
prefixes, 

R(d′p,x, y) ≥ b(d′p,x,y) = `p(d′p,x,y) + λK ′ 

= `p(d 
′ 
p,x,y) + λK + λ(K 

′ −K) 
= b(dp,x,y) + λ(K 

′ −K) ≥ b(dp,x,y) + λ ≥ Rc. (13) 

10 



Learning Certifiably Optimal Rule Lists for Categorical Data 

Therefore, even if we encounter a prefix dp with low bound b(dp,x,y) ≤ Rc, a long 
a b(dp,x,y) + λ ≥ Rc, then we can prune all prefix d′p that start with and be longer 
than dp. 

3.5 Upper bound on prefix length 

The simplest upper bound on prefix length be give by the total number of available an- 
tecedents. 

Proposition 3 (Trivial upper bound on prefix length) Consider a state space of all 
rule list form from a set of M antecedents, and let L(d) be the length of rule list d. 
M provide an upper bound on the length of any optimal rule list d∗ ∈ argmindR(d,x,y), 
i.e., L(d) ≤M . 

Proof Rule list consist of distinct rule by definition. 

At any point during branch-and-bound execution, the current best objective Rc implies 
an upper bound on the maximum prefix length we might still have to consider. 

Theorem 4 (Upper bound on prefix length) Consider a state space of all rule list 
form from a set of M antecedents. Let L(d) be the length of rule list d and let Rc be the 
current best objective. For all optimal rule list d∗ ∈ argmindR(d,x,y) 

L(d∗) ≤ min 
(⌊ 

Rc 

λ 

⌋ 
,M 

) 
, (14) 

where λ be the regularization parameter. Furthermore, if dc be a rule list with objective 
R(dc,x,y) = Rc, length K, and zero misclassification error, then for every optimal rule 
list d∗ ∈ argmindR(d,x,y), if dc ∈ argmindR(d,x,y), then L(d∗) ≤ K, or otherwise if 
dc /∈ argmindR(d,x,y), then L(d∗) ≤ K − 1. 

Proof For an optimal rule list d∗ with objective R∗, 

λL(d∗) ≤ R∗ = R(d∗,x,y) = `(d∗,x,y) + λL(d∗) ≤ Rc. (15) 

The maximum possible length for d∗ occurs when `(d∗,x,y) be minimized; combine with 
Proposition 3 give bound (14). 

For the rest of the proof, let K∗ = L(d∗) be the length of d∗. If the current best rule 
list dc have zero misclassification error, then 

λK∗ ≤ `(d∗,x,y) + λK∗ = R(d∗,x,y) ≤ Rc = R(dc,x,y) = λK, (16) 

and thus K∗ ≤ K. If the current best rule list be suboptimal, i.e., dc /∈ argmindR(d,x,y), 
then 

λK∗ ≤ `(d∗,x,y) + λK∗ = R(d∗,x,y) < Rc = R(dc,x,y) = λK, (17) 

11 



Angelino, Larus-Stone, Alabi, Seltzer, and Rudin 

in which case K∗ < K, i.e., K∗ ≤ K − 1, since K be an integer. 

The latter part of Theorem 4 tell u that if we only need to identify a single instance of 
an optimal rule list d∗ ∈ argmindR(d,x,y), and we encounter a perfect K-prefix with zero 
misclassification error, then we can prune all prefix of length K or greater. 

Corollary 5 (Simple upper bound on prefix length) Let L(d) be the length of rule 
list d. For all optimal rule list d∗ ∈ argmindR(d,x,y), 

L(d∗) ≤ min 
(⌊ 

1 

2λ 

⌋ 
,M 

) 
. (18) 

Proof Let d = ((), (), q0, 0) be the empty rule list; it have objective R(d,x,y) = `(d,x,y) ≤ 
1/2, which give an upper bound on Rc. Combining with (14) and Proposition 3 give (18). 

For any particular prefix dp, we can obtain potentially tighter upper bound on prefix 
length for the family of all prefix that start with dp. 

Theorem 6 (Prefix-specific upper bound on prefix length) Let d = (dp, δp, q0,K) be 
a rule list, let d′ = (d′p, δ 

′ 
p, q 
′ 
0,K 

′) ∈ σ(dp) be any rule list such that d′p start with dp, and 
let Rc be the current best objective. If d′p have low bound b(d 

′ 
p,x,y) < R 

c, then 

K ′ < min 

( 
K + 

⌊ 
Rc − b(dp,x,y) 

λ 

⌋ 
,M 

) 
. (19) 

Proof First, note that K ′ ≥ K, since d′p start with dp. Now recall from (12) that 

b(dp,x,y) = `(d, δp,x,y) + λK ≤ `(d′, δ′p,x,y) + λK ′ = b(d′p,x,y), (20) 

and from (11) that `(d, δp,x,y) ≤ `(d′, δ′p,x,y). Combining these bound and rearrange 
give 

b(dp,x,y) + λ(K 
′ −K) ≤ b(d′p,x,y). (21) 

Combining (21) with b(d′p,x,y) < R 
c and Proposition 3 give (19). 

We can view Theorem 6 a a generalization of our one-step lookahead bound (Lemma 2), 
a (19) be equivalently a bound on K ′ −K, an upper bound on the number of remain 
‘steps’ correspond to an iterative sequence of single-rule extension of a prefix dp. No- 
tice that when d = ((), (), q0, 0) be the empty rule list, this bound replicates (14), since 
b(dp,x,y) = 0. 

3.6 Upper bound on the number of prefix evaluation 

In this section, we use our upper bound on prefix length from §3.5 to derive correspond 
upper bound on the number of prefix evaluation make by Algorithm 1. First, we present 
Theorem 7, in which we use information about the state of Algorithm 1’s execution to 

12 



Learning Certifiably Optimal Rule Lists for Categorical Data 

calculate, for any give execution state, upper bound on the number of additional prefix 
evaluation that might be require for the execution to complete. This number of remain 
evaluation be equal to the number of prefix that be currently in or will be insert into 
the queue. The relevant execution state depends on the current best objective Rc and 
information about prefix we be planning to evaluate, i.e., prefix in the queue Q of 
Algorithm 1. After Theorem 7, we present two weaker proposition that provide useful 
intuition. 

Theorem 7 (Fine-grain upper bound on remain prefix evaluations) Consider 
the state space of all rule list form from a set of M antecedents, and consider Algorithm 1 
at a particular instant during execution. Let Rc be the current best objective, let Q be the 
queue, and let L(dp) be the length of prefix dp. Define Γ(R 

c, Q) to be the number of remain 
prefix evaluations, then 

Γ(Rc, Q) ≤ 
∑ 
dp∈Q 

f(dp)∑ 
k=0 

(M − L(dp))! 
(M − L(dp)− k)! 

, (22) 

where 

f(dp) = min 

(⌊ 
Rc − b(dp,x,y) 

λ 

⌋ 
,M − L(dp) 

) 
. (23) 

Proof The number of remain prefix evaluation be equal to the number of prefix that 
be currently in or will be insert into queue Q. For any such prefix dp, Theorem 6 give 
an upper bound on the length of any prefix d′p that start with dp: 

L(d′p) ≤ min 
( 
L(dp) + 

⌊ 
Rc − b(dp,x,y) 

λ 

⌋ 
,M 

) 
≡ U(dp). (24) 

This give an upper bound on the number of remain prefix evaluations: 

Γ(Rc, Q) ≤ 
∑ 
dp∈Q 

U(dp)−L(dp)∑ 
k=0 

P (M − L(dp), k) = 
∑ 
dp∈Q 

f(dp)∑ 
k=0 

(M − L(dp))! 
(M − L(dp)− k)! 

. (25) 

Our first proposition below be a näıve upper bound on the total number of prefix evalua- 
tions over the course of Algorithm 1’s execution. It only depends on the number of rule and 
the regularization parameter λ; i.e., unlike Theorem 7, it do not use algorithm execution 
state to bound the size of the search space. 

Proposition 8 (Upper bound on the total number of prefix evaluations) Define 
Γtot(S) to be the total number of prefix evaluate by Algorithm 1, give the state space of 
all rule list form from a set S of M rules. For any set S of M rules, 

Γtot(S) ≤ 
K∑ 
k=0 

M ! 

(M − k)! 
, (26) 

where K = min(b1/2λc,M). 

13 



Angelino, Larus-Stone, Alabi, Seltzer, and Rudin 

Proof By Corollary 5, K ≡ min(b1/2λc,M) give an upper bound on the length of any 
optimal rule list. Since we can think of our problem a find the optimal selection and 
permutation of k out of M rules, over all k ≤ K, 

Γtot(S) ≤ 1 + 
K∑ 
k=1 

P (M,k) = 

K∑ 
k=0 

M ! 

(M − k)! 
. (27) 

Our next upper bound be strictly tighter than the bound in Proposition 8. Like Theo- 
rem 7, it us the current best objective and information about the length of prefix in the 
queue to constrain the length of prefix in the remain search space. However, Propo- 
sition 9 be weaker than Theorem 7 because it leverage only coarse-grain information from 
the queue. Specifically, Theorem 7 be strictly tighter because it additionally incorporates 
prefix-specific objective low bound information from prefix in the queue, which further 
constrains the length of prefix in the remain search space. 

Proposition 9 (Coarse-grain upper bound on remain prefix evaluations) 
Consider a state space of all rule list form from a set of M antecedents, and consider 
Algorithm 1 at a particular instant during execution. Let Rc be the current best objective, 
let Q be the queue, and let L(dp) be the length of prefix dp. Let Qj be the number of prefix 
of length j in Q, 

Qj = 
∣∣{dp : L(dp) = j, dp ∈ Q}∣∣ (28) 

and let J = argmaxdp∈Q L(dp) be the length of the long prefix in Q. Define Γ(R 
c, Q) to 

be the number of remain prefix evaluations, then 

Γ(Rc, Q) ≤ 
J∑ 
j=1 

Qj 

( 
K−j∑ 
k=0 

(M − j)! 
(M − j − k)! 

) 
, (29) 

where K = min(bRc/λc,M). 

Proof The number of remain prefix evaluation be equal to the number of prefix that 
be currently in or will be insert into queueQ. For any such remain prefix dp, Theorem 4 
give an upper bound on it length; defineK to be this bound: L(dp) ≤ min(bRc/λc,M) ≡ K. 
For any prefix dp in queue Q with length L(dp) = j, the maximum number of prefix that 
start with dp and remain to be evaluate is: 

K−j∑ 
k=0 

P (M − j, k) = 
K−j∑ 
k=0 

(M − j)! 
(M − j − k)! 

, (30) 

where P (T, k) denotes the number of k-permutations of T . This give an upper bound on 
the number of remain prefix evaluations: 

Γ(Rc, Q) ≤ 
J∑ 
j=0 

Qj 

( 
K−j∑ 
k=0 

P (M − j, k) 

) 
= 

J∑ 
j=0 

Qj 

( 
K−j∑ 
k=0 

(M − j)! 
(M − j − k)! 

) 
. (31) 

14 



Learning Certifiably Optimal Rule Lists for Categorical Data 

3.7 Lower bound on antecedent support 

In this section, we give two low bound on the normalize support of each antecedent in 
any optimal rule list; both be related to the regularization parameter λ. 

Theorem 10 (Lower bound on antecedent support) Let d∗ = (dp, δp, q0,K) be any 
optimal rule list with objective R∗, i.e., d∗ ∈ argmindR(d,x,y). For each antecedent pk 
in prefix dp = (p1, . . . , pK), the regularization parameter λ provide a low bound on the 
normalize support of pk, 

λ < supp(pk,x | dp). (32) 

Proof Let d∗ = (dp, δp, q0,K) be an optimal rule list with prefix dp = (p1, . . . , pK) and 
label δp = (q1, . . . , qK). Consider the rule list d = (d 

′ 
p, δ 
′ 
p, q 
′ 
0,K − 1) derive from d∗ by 

delete a rule pi → qi, therefore d′p = (p1, . . . , pi−1, pi+1, . . . , pK) and δ′p = (q1, . . . , qi−1, 
q′i+1, . . . , q 

′ 
K), where q 

′ 
k need not be the same a qk, for k > i and k = 0. 

The large possible discrepancy between d∗ and d would occur if d∗ correctly classify 
all the data capture by pi, while d misclassified these data. This give an upper bound: 

R(d,x,y) = `(d,x,y) + λ(K − 1) ≤ `(d∗,x,y) + supp(pi,x | dp) + λ(K − 1) 
= R(d∗,x,y) + supp(pi,x | dp)− λ 
= R∗ + supp(pi,x | dp)− λ (33) 

where supp(pi,x | dp) be the normalize support of pi in the context of dp, define in (5), 
and the regularization ‘bonus’ come from the fact that d be one rule shorter than d∗. 

At the same time, we must have R∗ < R(d,x,y) for d∗ to be optimal. Combining this 
with (33) and rearrange give (32), therefore the regularization parameter λ provide a 
low bound on the support of an antecedent pi in an optimal rule list d 

∗. 

Thus, we can prune a prefix dp if any of it antecedent do not capture more than a 
fraction λ of data, even if b(dp,x,y) < R 

∗. Notice that the bound in Theorem 10 depends on 
the antecedents, but not the label predictions, and thus doesn’t account for misclassification 
error. Theorem 11 give a tighter bound by leverage this additional information, which 
specifically tightens the upper bound on R(d,x,y) in (33). 

Theorem 11 (Lower bound on accurate antecedent support) Let d∗ be any opti- 
mal rule list with objective R∗, i.e., d∗ = (dp, δp, q0,K) ∈ argmindR(d,x,y). Let d∗ have 
prefix dp = (p1, . . . , pK) and label δp = (q1, . . . , qK). For each rule pk → qk in d∗, define ak 
to be the fraction of data that be capture by pk and correctly classified: 

ak ≡ 
1 

N 

N∑ 
n=1 

cap(xn, pk | dp) ∧ 1[qk = yn]. (34) 

15 



Angelino, Larus-Stone, Alabi, Seltzer, and Rudin 

The regularization parameter λ provide a low bound on ak: 

λ < ak. (35) 

Proof As in Theorem 10, let d = (d′p, δ 
′ 
p, q 
′ 
0,K − 1) be the rule list derive from d∗ by 

delete a rule pi → qi. Now, let u define `i to be the portion of R∗ due to this rule’s 
misclassification error, 

`i ≡ 
1 

N 

N∑ 
n=1 

cap(xn, pi | dp) ∧ 1[qi 6= yn]. (36) 

The large discrepancy between d∗ and d would occur if d misclassified all the data capture 
by pi. This give an upper bound on the difference between the misclassification error of d 
and d∗: 

`(d,x,y)− `(d∗,x,y) ≤ supp(pi,x | dp)− `i 

= 
1 

N 

N∑ 
n=1 

cap(xn, pi | dp)− 
1 

N 

N∑ 
n=1 

cap(xn, pi | dp) ∧ 1[qi 6= yn] 

= 
1 

N 

N∑ 
n=1 

cap(xn, pi | dp) ∧ 1[qi = yn] = ai, (37) 

where we define ai in (34). Relating this bound to the objective of d and d 
∗ give 

R(d,x,y) = `(d,x,y) + λ(K − 1) ≤ `(d∗,x,y) + ai + λ(K − 1) 
= R(d∗,x,y) + ai − λ 
= R∗ + ai − λ (38) 

Combining (38) with the requirement R∗ < R(d,x,y) give the bound λ < ai. 

Thus, we can prune a prefix if any of it rule do not capture and correctly classify 
at least a fraction λ of data. While the low bound in Theorem 10 be a sub-condition of 
the low bound in Theorem 11, we can still leverage both – since the sub-condition be 
easy to check, check it first can accelerate pruning. In addition to apply Theorem 10 
in the context of construct rule lists, we can furthermore apply it in the context of 
rule mining (§3.1). Specifically, it implies that we should only mine rule with normalize 
support great than λ; we need not mine rule with a small fraction of observations. In 
contrast, we can only apply Theorem 11 in the context of construct rule lists; it depends 
on the misclassification error associate with each rule in a rule list, thus it provide a low 
bound on the number of observation that each such rule must correctly classify. 

3.8 Upper bound on antecedent support 

In the previous section (§3.7), we prove low bound on antecedent support; in this section, 
we give an upper bound on antecedent support. Specifically, Theorem 12 show that an 
antecedent’s support in a rule list cannot be too similar to the set of data not capture by 
precede antecedent in the rule list. 

16 



Learning Certifiably Optimal Rule Lists for Categorical Data 

Theorem 12 (Upper bound on antecedent support) Let d∗ = (dp, δp, q0,K) be any 
optimal rule list with objective R∗, i.e., d∗ ∈ argmindR(d,x,y), and let dp = (p1, . . . , pj−1, 
pj , . . . , pK−1, pK) be it prefix. The last antecedent pK in dp have support 

supp(pK ,x | dp) ≤ 1− supp(dK−1p ,x)− λ, (39) 

where dK−1p = (p1, . . . , pK−1), with equality imply that there also exists a shorter optimal 

rule list d′ = (dK−1p , δ 
′ 
p, q 
′ 
0,K − 1) ∈ argmindR(d,x,y) with prefix dK−1p . For all k ≤ K − 1, 

every antecedent pk in dp have support less than the fraction of all data not capture by 
precede antecedents, by an amount great than the regularization parameter λ: 

supp(pk,x | dp) < 1− supp(dk−1p ,x)− λ, (40) 

where dk−1p = (p1, . . . , pk−1). 

Proof We begin by focus on the last antecedent in a rule list. Let d = (dp, δp, q0,K) 
be a rule list with prefix dp = (p1, . . . , pK) and objective R(d,x,y) ≤ R∗, where R∗ ≡ 
minD R(D,x,y) be the optimal objective. Also let d 

′ = (d′p, δ 
′ 
p, q 
′ 
0,K + 1) be a rule list whose 

prefix d′p = (p1, . . . , pK , pK+1) start with dp and end with a new antecedent pK+1. Sup- 
pose pK+1 in the context of d 

′ 
p capture nearly all data not capture by dp, except for a 

fraction � upper bound by the regularization parameter λ: 

1− supp(dp,x)− supp(pK+1,x | d′p) ≡ � ≤ λ. (41) 

Since d′p start with dp, it prefix misclassification error be at least a great; the only discrep- 
ancy between the misclassification error of d and d′ can come from the difference between 
the support of the set of data not capture by dp and the support of pK+1: 

|`(d′,x,y)− `(d,x,y)| ≤ 1− supp(dp,x)− supp(pK+1,x | d′p) = �. (42) 

The best outcome for d′ would occur if it misclassification error be small than that 
of d by �, therefore 

R(d′,x,y) = `(d′,x,y) + λ(K + 1) 

≥ `(d,x,y)− �+ λ(K + 1) = R(d,x,y)− �+ λ ≥ R(d,x,y) ≥ R∗. (43) 

d′ be an optimal rule list, i.e., d′ ∈ argminD R(D,x, y), if and only ifR(d′,x,y) = R(d,x,y) = 
R∗, which require � = λ. Otherwise, � < λ, in which case 

R(d′,x,y) ≥ R(d,x,y)− �+ λ > R(d,x,y) ≥ R∗, (44) 

i.e., d′ be not optimal. This prof the first half of Theorem 12. 
To finish, we prove the bound in (40) by contradiction. First, note that the data not 

capture by d′p have normalize support � ≤ λ, i.e., 

1− supp(d′p,x) = 1− supp(dp,x)− supp(pK+1,x | d′p) = � ≤ λ. (45) 

Thus for any rule list d′′ whose prefix d′′p = (p1, . . . , pK+1, . . . , pK′) start with d 
′ 
p and end 

with one or more additional rules, each additional rule pk have support supp(pk,x | d′′p) ≤ 

17 



Angelino, Larus-Stone, Alabi, Seltzer, and Rudin 

� ≤ λ, for all k > K + 1. By Theorem 10, all of the additional rule have insufficient sup- 
port, therefore d′′p cannot be optimal, i.e., d 

′′ /∈ argminD R(D,x,y). 

Similar to Theorem 10, our low bound on antecedent support, we can apply Theo- 
rem 12 in the context of both construct rule list and rule mining (§3.1). Theorem 12 
implies that if we only seek a single optimal rule list, then during branch-and-bound ex- 
ecution, we can prune a prefix if we ever add an antecedent with support too similar to 
the support of set of data not capture by the precede antecedents. One way to view 
this result be that if d = (dp, δp, q0,K) and d 

′ = (d′p, δ 
′ 
p, q 
′ 
0,K + 1) be rule list such that d 

′ 
p 

start with dp and end with an antecedent that capture all or nearly all data not capture 
by dp, then the new rule in d 

′ behaves similar to the default rule of d. As a result, the 
misclassification error of d′ must be similar to that of d, and any reduction may not be 
sufficient to offset the penalty for longer prefixes. Furthermore, Theorem 12 implies that 
we should only mine rule with normalize support less than 1− λ; we need not mine rule 
with a large fraction of observations. 

3.9 Antecedent rejection and it propagation 

In this section, we demonstrate further consequence of our low (§3.7) and upper bound 
(§3.8) on antecedent support, under a unified framework we refer to a antecedent rejection. 
Let dp = (p1, . . . , pK) be a prefix, and let pk be an antecedent in dp. Define pk to have in- 
sufficient support in dp if do not obey the bound in (32) of Theorem 10. Define pk to have 
insufficient accurate support in dp if it do not obey the bound in (35) of Theorem 11. 
Define pk to have excessive support in dp if it do not obey the appropriate bound in 
Theorem 12, i.e., either it’s the last antecedent and doesn’t obey (40), or it’s any other 
antecedent and doesn’t obey (39). If pk in the context of dp have insufficient support, insuffi- 
cient accurate support, or excessive support, let u say that prefix dp reject antecedent pK . 
Next, in Theorem 13, we describe large class of related rule list whose prefix all reject 
the same antecedent. 

Theorem 13 (Antecedent rejection propagates) For any prefix dp = (p1, . . . , pK), let 
φ(dp) denote the set of all prefix d 

′ 
p such that the set of all antecedent in dp be a subset 

of the set of all antecedent in d′p, i.e., 

φ(dp) = {d′p = (p′1, . . . , p′K′) s.t. {pk : pk ∈ dp} ⊆ {p′κ : p′κ ∈ d′p},K ′ ≥ K}. (46) 

Let d = (dp, δp, q0,K) be a rule list with prefix dp = (p1, . . . , pK−1, pK), such that dp reject 
it last antecedent pK , either because pK in the context of dp have insufficient support, insuf- 
ficient accurate support, or excessive support. Let dK−1p = (p1, . . . , pK−1) be the first K − 1 
antecedent of dp. Let D = (Dp,∆p, Q0, κ) be any rule list with prefix Dp = (P1, . . . , PK′−1, 
PK′ , . . . , Pκ) such that Dp start with D 

K′−1 
p = (P1, . . . , PK′−1) ∈ φ(dK−1p ) and antecedent 

PK′ = pK . It follow that prefix Dp reject PK′ for the same reason that dp reject pK , and 
furthermore, D cannot be optimal, i.e., D /∈ argmind† R(d†,x,y). 

Proof Combine Propositions 14, 15, and 16. 

18 



Learning Certifiably Optimal Rule Lists for Categorical Data 

Proposition 14 (Insufficient antecedent support propagates) First define φ(dp) a 
in (46), and let dp = (p1, . . . , pK−1, pK) be a prefix, such that it last antecedent pK have 
insufficient support, i.e., the opposite of the bound in (32): supp(pK ,x | dp) ≤ λ. Let dK−1p = 
(p1, . . . , pK−1), and let D = (Dp,∆p, Q0, κ) be any rule list with prefix Dp = (P1, . . . , PK′−1, 
PK′ , . . . , Pκ), such that Dp start with D 

K′−1 
p = (P1, . . . , PK′−1) ∈ φ(dK−1p ) and PK′ = pK . 

It follow that PK′ have insufficient support in prefix Dp, and furthermore, D cannot be 
optimal, i.e., D /∈ argmindR(d,x,y). 

Proof The support of pK in dp depends only on the set of antecedent in d 
K 
p = (p1, . . . , pK): 

supp(pK ,x | dp) = 
1 

N 

N∑ 
n=1 

cap(xn, pK | dp) = 
1 

N 

N∑ 
n=1 

( 
¬ cap(xn, dK−1p ) 

) 
∧ cap(xn, pK) 

= 
1 

N 

N∑ 
n=1 

( 
K−1∧ 
k=1 

¬ cap(xn, pk) 

) 
∧ cap(xn, pK) ≤ λ. 

(47) 

Similarly, the support of PK′ in Dp depends only on the set of antecedent in D 
K′ 
p = 

(P1, . . . , PK′): 

supp(PK′ ,x |Dp) = 
1 

N 

N∑ 
n=1 

cap(xn, PK′ |Dp) 

= 
1 

N 

N∑ 
n=1 

( 
¬ cap(xn, DK 

′−1 
p ) 

) 
∧ cap(xn, PK′) 

= 
1 

N 

N∑ 
n=1 

( 
K′−1∧ 
k=1 

¬ cap(xn, Pk) 

) 
∧ cap(xn, PK′) 

≤ 1 
N 

N∑ 
n=1 

( 
K−1∧ 
k=1 

¬ cap(xn, pk) 

) 
∧ cap(xn, PK′) 

= 
1 

N 

N∑ 
n=1 

( 
K−1∧ 
k=1 

¬ cap(xn, pk) 

) 
∧ cap(xn, pK) = supp(pK ,x | dp) ≤ λ. 

(48) 

The first inequality reflect the condition that DK 
′−1 

p ∈ φ(dK−1p ), which implies that the 
set of antecedent in DK 

′−1 
p contains the set of antecedent in d 

K−1 
p , and the next equality 

reflect the fact that PK′ = pK . Thus, P 
′ 
K have insufficient support in prefix Dp, therefore 

by Theorem 10, D cannot be optimal, i.e., D /∈ argmindR(d,x,y). 

Proposition 15 (Insufficient accurate antecedent support propagates) Let φ(dp) 
denote the set of all prefix d′p such that the set of all antecedent in dp be a subset of 
the set of all antecedent in d′p, a in (46). Let d = (dp, δp, q0,K) be a rule list with prefix 

19 



Angelino, Larus-Stone, Alabi, Seltzer, and Rudin 

dp = (p1, . . . , pK) and label δp = (q1, . . . , qK), such that the last antecedent pK have insuffi- 
cient accurate support, i.e., the opposite of the bound in (35): 

1 

N 

N∑ 
n=1 

cap(xn, pK | dp) ∧ 1[qK = yn] ≤ λ. (49) 

Let dK−1p = (p1, . . . , pK−1) and let D = (Dp,∆p, Q0, κ) be any rule list with prefix Dp = 

(P1, . . . , Pκ) and label ∆p = (Q1, . . . , Qκ), such that Dp start with D 
K′−1 
p = (P1, . . . , PK′−1) 

∈ φ(dK−1p ) and PK′ = pK . It follow that PK′ have insufficient accurate support in prefix Dp, 
and furthermore, D /∈ argmind† R(d†,x,y). 

Proof The accurate support of PK′ in Dp be insufficient: 

1 

N 

N∑ 
n=1 

cap(xn, PK′ |Dp) ∧ 1[QK′ = yn] 

= 
1 

N 

N∑ 
n=1 

( 
K′−1∧ 
k=1 

¬ cap(xn, Pk) 

) 
∧ cap(xn, PK′) ∧ 1[QK′ = yn] 

≤ 1 
N 

N∑ 
n=1 

( 
K−1∧ 
k=1 

¬ cap(xn, pk) 

) 
∧ cap(xn, PK′) ∧ 1[QK′ = yn] 

= 
1 

N 

N∑ 
n=1 

( 
K−1∧ 
k=1 

¬ cap(xn, pk) 

) 
∧ cap(xn, pK) ∧ 1[QK′ = yn] 

= 
1 

N 

N∑ 
n=1 

cap(xn, pK | dp) ∧ 1[QK′ = yn] 

≤ 1 
N 

N∑ 
n=1 

cap(xn, pK | dp) ∧ 1[qK = yn] ≤ λ. (50) 

The first inequality reflect the condition that DK 
′−1 

p ∈ φ(dK−1p ), the next equality reflect 
the fact that PK′ = pK . For the follow equality, notice that QK′ be the majority class 
label of data capture by PK′ in Dp, and qK be the majority class label of data capture 
by PK in dp, and recall from (48) that supp(PK′ ,x |Dp) ≤ supp(pK ,x | dp). By Theorem 11, 
D /∈ argmind† R(d†,x,y). 

Proposition 16 (Excessive antecedent support propagates) Define φ(dp) a in (46), 
and let dp = (p1, . . . , pK) be a prefix, such that it last antecedent pK have excessive support, 
i.e., the opposite of the bound in (39): 

supp(pK ,x | dp) ≥ 1− supp(dK−1p ,x)− λ, (51) 

where dK−1p = (p1, . . . , pK−1). Let D = (Dp,∆p, Q0, κ) be any rule list with prefix Dp = 

(P1, . . . , Pκ) such that Dp start with D 
K′−1 
p = (P1, . . . , PK′−1) ∈ φ(dK−1p ) and PK′ = pK . It 

follow that PK′ have excessive support in prefix Dp, and furthermore, D /∈ argmindR(d,x,y). 

20 



Learning Certifiably Optimal Rule Lists for Categorical Data 

Proof Since DK 
′ 

p = (P1, . . . , PK′) contains all the antecedent in dp, we have that 

supp(DK 
′ 

p ,x) ≥ supp(dp,x). (52) 

Expanding these two term give 

supp(DK 
′ 

p ,x) = supp(D 
K′−1 
p ,x) + supp(PK′ ,x |Dp) 

≥ supp(dp,x) = supp(dK−1p ,x) + supp(pK ,x | dp) ≥ 1− λ. (53) 

Rearranging give 

supp(PK′ ,x |Dp) ≥ 1− supp(DK 
′−1 

p ,x)− λ, (54) 

thus PK′ have excessive support in Dp. By Theorem 12, D /∈ argmindR(d,x,y). 

Theorem 13 implies potentially significant computational savings. During branch-and- 
bound execution, if we ever encounter a prefix dp = (p1, . . . , pK−1, pK) that reject it last 
antecedent pK , then we can prune dp. Furthermore, we can also prune any prefix d 

′ 
p whose 

antecedent contains the set of antecedent in dp, in almost any order, with the constraint 
that all antecedent in {p1, . . . , pK−1} precede pK . 

3.10 Equivalent support bound 

Let Dp be a prefix, and let ξ(Dp) be the set of all prefix that capture exactly the same 
data a Dp. Now, let d be a rule list with prefix dp in ξ(Dp), such that d have the minimum 
objective over all rule list with prefix in ξ(Dp). Finally, let d 

′ be a rule list whose prefix d′p 
start with dp, such that d 

′ have the minimum objective over all rule list whose prefix start 
with dp. Theorem 17 below implies that d 

′ also have the minimum objective over all rule list 
whose prefix start with any prefix in ξ(Dp). 

Theorem 17 (Equivalent support bound) Define σ(dp) to be the set of all rule list 
whose prefix start with dp, a in (1). Let d = (dp, δp, q0,K) be a rule list with prefix 
dp = (p1, . . . , pK), and let D = (Dp,∆p, Q0, κ) be a rule list with prefix Dp = (P1, . . . , Pκ), 
such that dp and Dp capture the same data, i.e., 

{xn : cap(xn, dp)} = {xn : cap(xn, Dp)}. (55) 

If the objective low bound of d and D obey b(dp,x,y) ≤ b(Dp,x,y), then the objective of 
the optimal rule list in σ(dp) give a low bound on the objective of the optimal rule list 
in σ(Dp): 

min 
d′∈σ(dp) 

R(d′,x,y) ≤ min 
D′∈σ(Dp) 

R(D′,x,y). (56) 

Proof We begin by define four related rule lists. First, let d = (dp, δp, q0,K) be a rule list 
with prefix dp = (p1, . . . , pK) and label δp = (q1, . . . , qK). Second, let D = (Dp,∆p, Q0, κ) 
be a rule list with prefix Dp = (P1, . . . , Pκ) that capture the same data a dp, and la- 
bel ∆p = (Q1, . . . , Qκ). Third, let d 

′ = (d′p, δ 
′ 
p, q 
′ 
0,K 

′) ∈ σ(dp) be any rule list whose prefix 

21 



Angelino, Larus-Stone, Alabi, Seltzer, and Rudin 

start with dp, such that K 
′ ≥ K. Denote the prefix and label of d′ by d′p = (p1, . . . , pK , 

pK+1, . . . , pK′) and δp = (q1, . . . , qK′), respectively. Finally, define D 
′ = (D′p,∆ 

′ 
p, Q 

′ 
0, κ 
′) ∈ 

σ(Dp) to be the ‘analogous’ rule list, i.e., whose prefix D 
′ 
p = (P1, . . . , Pκ, Pκ+1, . . . , Pκ′) = 

(P1, . . . , Pκ, pK+1, . . . , pK′) start with Dp and end with the same K 
′ −K antecedent 

a d′p. Let ∆ 
′ 
p = (Q1, . . . , Qκ′) denote the label of D 

′. 
Next, we claim that the difference in the objective of rule list d′ and d be the same a 

the difference in the objective of rule list D′ and D. Let u expand the first difference a 

R(d′,x,y)−R(d,x,y) = `(d′,x,y) + λK ′ − `(d,x,y)− λK 
= `p(d 

′ 
p, δ 
′ 
p,x,y) + `0(d 

′ 
p, q 
′ 
0,x,y)− `p(dp, δp,x,y)− `0(dp, q0,x,y) + λ(K ′ −K). 

Similarly, let u expand the second difference a 

R(D′,x,y)−R(D,x,y) = `(D′,x,y) + λκ′ − `(D,x,y)− λκ 
= `p(D 

′ 
p,∆ 

′ 
p,x,y) + `0(D 

′ 
p, Q 

′ 
0,x,y)− `p(Dp,∆p,x,y)− `0(Dp, Q0,x,y) + λ(K ′ −K), 

where we have use the fact that κ′ − κ = K ′ −K. 
The prefix dp and Dp capture the same data. Equivalently, the set of data that be not 

capture by dp be the same a the set of data that be not capture by Dp, i.e., 

{xn : ¬ cap(xn, dp)} = {xn : ¬ cap(xn, Dp)}. (57) 

Thus, the correspond rule list d and D share the same default rule, i.e., q0 = Q0, yield 
the same default rule misclassification error: 

`0(dp, q0,x,y) = `0(Dp, Q0,x,y). (58) 

Similarly, prefix d′p and D 
′ 
p capture the same data, and thus rule list d 

′ and D′ have the 
same default rule misclassification error: 

`0(dp, q0,x,y) = `0(Dp, Q0,x,y). (59) 

At this point, to demonstrate our claim relate the objective of d, d′, D, and D′, what 
remains be to show that the difference in the misclassification error of prefix d′p and dp be 
the same a that between D′p and Dp. We can expand the first difference a 

`p(d 
′ 
p, δ 
′ 
p,x,y)− `p(dp, δp,x,y) = 

1 

N 

N∑ 
n=1 

K′∑ 
k=K+1 

cap(xn, pk | d′p) ∧ 1[qk 6= yn], (60) 

where we have use the fact that since d′p start with dp, the first K rule in d 
′ 
p make the 

same mistake a those in dp. Similarly, we can expand the second difference a 

`p(D 
′ 
p,∆ 

′ 
p,x,y)− `p(Dp,∆p,x,y) = 

1 

N 

N∑ 
n=1 

κ′∑ 
k=κ+1 

cap(xn, Pk |D′p) ∧ 1[Qk 6= yn] 

= 
1 

N 

N∑ 
n=1 

K′∑ 
k=K+1 

cap(xn, pk |D′p) ∧ 1[Qk 6= yn] 

= 
1 

N 

N∑ 
n=1 

K′∑ 
k=K+1 

cap(xn, pk | d′p) ∧ 1[qk 6= yn] (61) 

= `p(d 
′ 
p, δ 
′ 
p,x,y)− `p(dp, δp,x,y). 

22 



Learning Certifiably Optimal Rule Lists for Categorical Data 

To justify the equality in (61), we observe first that prefix D′p and d 
′ 
p start with κ and K 

antecedents, respectively, that capture the same data. Second, prefix D′p and d 
′ 
p end with 

exactly the same order list of K ′ −K antecedents, therefore for any k = 1, . . . ,K ′ −K, 
antecedent Pκ+k = pK+k inD 

′ 
p capture the same data a pK+k capture in d 

′ 
p. It follow that 

the correspond label be all equivalent, i.e., Qκ+k = qK+k, for all k = 1, . . . ,K 
′ −K, and 

consequently, the prefix misclassification error associate with the last K ′ −K antecedent 
of d′p be the same a that of D 

′ 
p. We have therefore show that the difference between the 

objective of d′ and d be the same a that between D′ and D, i.e., 

R(d′,x,y)−R(d,x,y) = R(D′,x,y)−R(D,x,y). (62) 

Next, suppose that the objective low bound of d and D obey b(dp,x,y) ≤ b(Dp,x,y), 
therefore 

R(d,x,y) = `p(dp, δp,x,y) + `0(dp, q0,x,y) + λK 

= b(dp,x,y) + `0(dp, q0,x,y) 

≤ b(Dp,x,y) + `0(dp, q0,x,y) = b(Dp,x,y) + `0(Dp, Q0,x,y) = R(D,x,y). 
(63) 

Now let d∗ be an optimal rule list with prefix constrain to start with dp, 

d∗ ∈ argmin 
d†∈σ(dp) 

R(d†,x,y), (64) 

and let K∗ be the length of d∗. Let D∗ be the analogous κ∗-rule list whose prefix start 
with Dp and end with the same K 

∗ −K antecedent a d∗, where κ∗ = κ+K∗ −K. 
By (62), 

R(d∗,x,y)−R(d,x,y) = R(D∗,x,y)−R(D,x,y). (65) 

Furthermore, we claim that D∗ be an optimal rule list with prefix constrain to start 
with Dp, 

D∗ ∈ argmin 
D†∈σ(Dp) 

R(D†,x,y). (66) 

To demonstrate (66), we consider two separate scenarios. In the first scenario, prefix dp 
and Dp be compose of the same antecedents, i.e., the two prefix be equivalent up to a 
permutation of their antecedents, and a a consequence, κ = K and κ∗ = K∗. Here, every 
rule list d′′ ∈ σ(dp) that start with dp have an analogue D′′ ∈ σ(Dp) that start with Dp, 
such that d′′ and D′′ obey (62), and vice versa, and thus (66) be a direct consequence of (65). 

In the second scenario, prefix dp and Dp be not compose of the same antecedents. 
Define φ = {pk : (pk ∈ dp) ∧ (pk /∈ Dp)} to be the set of antecedent in dp that be not in Dp, 
and define Φ = {Pk : (Pk ∈ Dp) ∧ (Pk /∈ dp)} to be the set of antecedent in Dp that be not 
in dp; either φ 6= ∅, or Φ 6= ∅, or both. 

Suppose φ 6= ∅, and let p ∈ φ be an antecedent in φ. It follow that there exists a subset 
of rule list in σ(Dp) that do not have analogue in σ(dp). Let D 

′′ ∈ σ(Dp) be such a rule 
list, such that it prefix D′′p = (P1, . . . , Pκ, . . . , p, . . . ) start with Dp and contains p among 

23 



Angelino, Larus-Stone, Alabi, Seltzer, and Rudin 

it remain antecedents. Since p capture a subset of the data that dp captures, and Dp 
capture the same data a dp, it follow that p doesn’t capture any data in D 

′′ 
p , i.e., 

1 

N 

N∑ 
n=1 

cap(xn, p |D′′p) = 0 ≤ λ. (67) 

By Theorem 10, antecedent p have insufficient support in D′′, and thus D′′ cannot be op- 
timal, i.e., D′′ /∈ argminD†∈σ(Dp)R(D 

†,x,y). By a similar argument, if Φ 6= ∅ and P ∈ Φ, 
and d′′ ∈ σ(dp) be any rule list whose prefix start with dp and contains antecedent P , then d′′ 
cannot be optimal, i.e., d′′ /∈ argmind†∈σ(dp)R(d 

†,x,y). 
To finish justify claim (66) for the second scenario, first define 

τ(dp,Φ) ≡ {d′′ = (d′′p, δ′′p , q′′0 ,K ′′) : d′′ ∈ σ(dp) and pk /∈ Φ,∀pk ∈ d′′p} ⊂ σ(dp) (68) 

to be the set of all rule list whose prefix start with dp and don’t contain any antecedent 
in Φ. Now, recognize that the optimal prefix in τ(dp,Φ) and σ(dp) be the same, i.e., 

argmin 
d†∈τ(dp,Φ) 

R(d†,x,y) = argmin 
d†∈σ(dp) 

R(d†,x,y), (69) 

and similarly, the optimal prefix in τ(Dp, φ) and σ(Dp) be the same, i.e., 

argmin 
D†∈τ(Dp,φ) 

R(D†,x,y) = argmin 
D†∈σ(Dp) 

R(D†,x,y). (70) 

Since we have show that every d′′ ∈ τ(dp,Φ) have a direct analogue D′′ ∈ τ(Dp, φ), such 
that d′′ and D′′ obey (62), and vice versa, we again have (66) a a consequence of (65). 

We can now finally combine (63) and (66) to obtain 

min 
d′∈σ(dp) 

R(d′,x,y) = R(d∗,x,y) ≤ R(D∗,x,y) = min 
D′∈σ(Dp) 

R(D′,x,y). (71) 

Thus, if prefix dp and Dp capture the same data, and their objective low bound obey 
b(dp,x,y) ≤ b(Dp,x,y), Theorem 17 implies that we can prune Dp. Next, in Sections 3.11 
and 3.12, we highlight and analyze the special case of prefix that capture the same data 
because they contain the same antecedents. 

3.11 Permutation bound 

Let P = {pk}Kk=1 be a set of K antecedents, and let Π be the set of all K-prefixes corre- 
sponding to permutation of antecedent in P . Now, let d be a rule list with prefix dp in Π, 
such that d have the minimum objective over all rule list with prefix in Π. Finally, let d′ 

be a rule list whose prefix d′p start with dp, such that d 
′ have the minimum objective over all 

rule list whose prefix start with dp. Corollary 18 below, which can be view a special 
case of Theorem 17, implies that d′ also have the minimum objective over all rule list whose 
prefix start with any prefix in Π. 

24 



Learning Certifiably Optimal Rule Lists for Categorical Data 

Corollary 18 (Permutation bound) Let π be any permutation of {1, . . . ,K}, and de- 
fine σ(dp) = {(d′p, δ′p, q′0,K ′) : d′p start with dp} to be the set of all rule list whose prefix 
start with dp. Let d = (dp, δp, q0,K) and D = (Dp,∆p, Q0,K) denote rule list with prefix 
dp = (p1, . . . , pK) and Dp = (pπ(1), . . . , pπ(K)), respectively, i.e., the antecedent in Dp cor- 
respond to a permutation of the antecedent in dp. If the objective low bound of d and D 
obey b(dp,x,y) ≤ b(Dp,x,y), then the objective of the optimal rule list in σ(dp) give a 
low bound on the objective of the optimal rule list in σ(Dp): 

min 
d′∈σ(dp) 

R(d′,x,y) ≤ min 
D′∈σ(Dp) 

R(D′,x,y). (72) 

Proof Since prefix dp and Dp contain the same antecedents, they both capture the same 
data. Thus, we can apply Theorem 17. 

Thus if prefix dp and Dp have the same antecedents, up to a permutation, and their 
objective low bound obey b(dp,x,y) ≤ b(Dp,x,y), Corollary 18 implies that we can 
prune Dp. We call this symmetry-aware pruning, and we illustrate the subsequent compu- 
tational saving next in §3.12. 

3.12 Upper bound on prefix evaluation with symmetry-aware prune 

Here, we present an upper bound on the total number of prefix evaluation that account for 
the effect of symmetry-aware prune (§3.11). Since every subset of K antecedent generates 
an equivalence class of K! prefix equivalent up to permutation, symmetry-aware prune 
dramatically reduces the search space. 

First, notice that Algorithm 1 describes a breadth-first exploration of the state space of 
rule lists. Now suppose we integrate symmetry-aware prune into our execution of branch- 
and-bound, so that after evaluate prefix of length K, we only keep a single best prefix 
from each set of prefix equivalent up to a permutation. 

Theorem 19 (Upper bound on prefix evaluation with symmetry-aware pruning) 
Consider a state space of all rule list form from a set S of M antecedents, and consider 
the branch-and-bound algorithm with symmetry-aware pruning. Define Γtot(S) to be the total 
number of prefix evaluated. For any set S of M rules, 

Γtot(S) ≤ 1 + 
K∑ 
k=1 

1 

(k − 1)! 
· M ! 

(M − k)! 
, (73) 

where K = min(b1/2λc,M). 

Proof By Corollary 5, K ≡ min(b1/2λc,M) give an upper bound on the length of any 
optimal rule list. The algorithm begin by evaluate the empty prefix, follow by M pre- 
fix of length k = 1, then P (M, 2) prefix of length k = 2, where P (M, 2) be the number of 
size-2 subset of {1, . . . ,M}. Before proceed to length k = 3, we keep only C(M, 2) pre- 
fix of length k = 2, where C(M,k) denotes the number of k-combinations of M . Now, the 

25 



Angelino, Larus-Stone, Alabi, Seltzer, and Rudin 

number of length k = 3 prefix we evaluate be C(M, 2)(M − 2). Propagating this forward 
give 

Γtot(S) ≤ 1 + 
K∑ 
k=1 

C(M,k − 1)(M − k + 1) = 1 + 
K∑ 
k=1 

1 

(k − 1)! 
· M ! 

(M − k)! 
. (74) 

Γtot(S) ≤ 1 + 
K∑ 
k=1 

C(M,k − 1)(M − k + 1). (75) 

Pruning base on permutation symmetry thus yield significant computational savings. 
Let u compare, for example, to the näıve number of prefix evaluation give by the upper 
bound in Proposition 8. If M = 100 and K = 5, then the näıve number be about 9.1× 109, 
while the reduce number due to symmetry-aware prune be about 3.9× 108, which be 
small by a factor of about 23. If M = 1000 and K = 10, the number of evaluation fall 
from about 9.6× 1029 to about 2.7× 1024, which be small by a factor of about 360,000. 

While 1024 seem infeasibly enormous, it do not represent the number of rule list we 
evaluate. As we show in our experiment (§6), our permutation bound in Corollary 18 and 
our other bound together conspire to reduce the search space to a size manageable on a 
single computer. The choice of M = 1000 and K = 10 in our example above corresponds to 
the state space size our effort target. K = 10 rule represent a (heuristic) upper limit on 
the size of an interpretable rule list, and M = 1000 represent the approximate number of 
rule with sufficiently high support (Theorem 10) we expect to obtain via rule mining (§3.1). 

3.13 Similar support bound 

We now present a relaxation of our equivalent support bound from Theorem 17. Note that 
our implementation (§5) do not currently leverage the bound in Theorem 20. 

Theorem 20 (Similar support bound) Define σ(dp) to be the set of all rule list whose 
prefix start with dp, a in (1). Let dp = (p1, . . . , pK) and Dp = (P1, . . . , Pκ) be prefix 
that capture nearly the same data. Specifically, define ω to be the normalize support of data 
capture by dp and not capture by Dp, i.e., 

ω ≡ 1 
N 

N∑ 
n=1 

¬ cap(xn, Dp) ∧ cap(xn, dp). (76) 

Similarly, define Ω to be the normalize support of data capture by Dp and not capture 
by dp, i.e., 

Ω ≡ 1 
N 

N∑ 
n=1 

¬ cap(xn, dp) ∧ cap(xn, Dp). (77) 

26 



Learning Certifiably Optimal Rule Lists for Categorical Data 

We can bound the difference between the objective of the optimal rule list in σ(dp) and 
σ(Dp) a follows: 

min 
D†∈σ(Dp) 

R(D†,x,y)− min 
d†∈σ(dp) 

R(d†,x,y) ≥ b(Dp,x,y)− b(dp,x,y)− ω − Ω, (78) 

where b(dp,x,y) and b(Dp,x,y) be the objective low bound of d and D, respectively. 

Proof We begin by define four related rule lists. First, let d = (dp, δp, q0,K) be a rule list 
with prefix dp = (p1, . . . , pK) and label δp = (q1, . . . , qK). Second, let D = (Dp,∆p, Q0, κ) 
be a rule list with prefix Dp = (P1, . . . , Pκ) and label ∆p = (Q1, . . . , Qκ). Define ω a 
in (76) and Ω a in (77), and require that ω,Ω ≤ λ. Third, let d′ = (d′p, δ′p, q′0,K ′) ∈ σ(dp) 
be any rule list whose prefix start with dp, such that K 

′ ≥ K. Denote the prefix and la- 
bel of d′ by d′p = (p1, . . . , pK , pK+1, . . . , pK′) and δp = (q1, . . . , qK′), respectively. Finally, 
define D′ = (D′p,∆ 

′ 
p, Q 

′ 
0, κ 
′) ∈ σ(Dp) to be the ‘analogous’ rule list, i.e., whose prefix D′p = 

(P1, . . . , Pκ, Pκ+1, . . . , Pκ′) = (P1, . . . , Pκ, pK+1, . . . , pK′) start with Dp and end with the 
same K ′ −K antecedent a d′p. Let ∆′p = (Q1, . . . , Qκ′) denote the label of D′. 

The small possible objective for D′, in relation to the objective of d′, reflect both 
the difference between the objective low bound of D and d and the large possible 
discrepancy between the objective of d′ and D′. The latter would occur if d′ misclassified 
all the data correspond to both ω and Ω while D′ correctly classify this same data, 
thus 

R(D′,x,y) ≥ R(d′,x,y) + b(Dp,x,y)− b(dp,x,y)− ω − Ω. (79) 

Now let D∗ be an optimal rule list with prefix constrain to start with Dp, 

D∗ ∈ argmin 
D†∈σ(Dp) 

R(D†,x,y), (80) 

and let κ∗ be the length of D∗. Also let d∗ be the analogous K∗-rule list whose prefix start 
with dp and end with the same κ 

∗ − κ antecedent a D∗, where K∗ = K + κ∗ − κ. By (79), 

min 
D†∈σ(Dp) 

R(D†,x,y) = R(D∗,x,y) 

≥ R(d∗,x,y) + b(Dp,x,y)− b(dp,x,y)− ω − Ω 
≥ min 

d†∈σ(dp) 
R(d†,x,y) + b(Dp,x,y)− b(dp,x,y)− ω − Ω. (81) 

Theorem 20 implies that if prefix dp and Dp be similar, and we know the optimal 
objective of rule list start with dp, then 

min 
D′∈σ(Dp) 

R(D′,x,y) ≥ min 
d′∈σ(dp) 

R(d′,x,y) + b(Dp,x,y)− b(dp,x,y)− χ 

≥ Rc + b(Dp,x,y)− b(dp,x,y)− χ, (82) 

27 



Angelino, Larus-Stone, Alabi, Seltzer, and Rudin 

where Rc be the current best objective, and χ be the normalize support of the set of data 
capture either exclusively by dp or exclusively by Dp. It follow that 

min 
D′∈σ(Dp) 

R(D′,x,y) ≥ Rc + b(Dp,x,y)− b(dp,x,y)− χ ≥ Rc (83) 

if b(Dp,x,y)− b(dp,x,y) ≥ χ. To conclude, we summarize this result and combine it with 
our notion of lookahead from Lemma 2. During branch-and-bound execution, if we demon- 
strate that mind′∈σ(dp)R(d 

′,x,y) ≥ Rc, then we can prune all prefix that start with any 
prefix D′p in the follow set:{ 

D′p : b(D 
′ 
p,x,y) + λ− b(dp,x,y) ≥ 

1 

N 

N∑ 
n=1 

cap(xn, dp)⊕ cap(xn, D′p) 

} 
. (84) 

3.14 Equivalent point bound 

The bound in this section quantify the following: If multiple observation that be not 
capture by a prefix dp have identical feature and opposite labels, then no rule list that 
start with dp can correctly classify all these observations. For each set of such observations, 
the number of mistake be at least the number of observation with the minority label within 
the set. 

Consider a dataset {(xn, yn)}Nn=1 and also a set of antecedent {sm}Mm=1. Define dis- 
tinct datapoints to be equivalent if they be capture by exactly the same antecedents, 
i.e., xi 6= xj be equivalent if 

1 

M 

M∑ 
m=1 

1[cap(xi, sm) = cap(xj , sm)] = 1. (85) 

Notice that we can partition a dataset into set of equivalent points; let {eu}Uu=1 enumerate 
these sets. Now define θ(eu) to be the normalize support of the minority class label with 
respect to set eu, e.g., let 

eu = {xn : 1[cap(xn, sm) = cap(xi, sm)]}, (86) 

and let qu be the minority class label among point in eu, then 

θ(eu) = 
1 

N 

N∑ 
n=1 

1[xn ∈ eu] ∧ 1[yn = qu]. (87) 

The existence of equivalent point set with non-singleton support yield a tighter ob- 
jective low bound that we can combine with our other bounds; a our experiment demon- 
strate (§6), the practical consequence can be dramatic. First, for intuition, we present a 
general bound in Proposition 21; next, we explicitly integrate this bound into our framework 
in Theorem 22. 

Proposition 21 (General equivalent point bound) Let d = (dp, δp, q0,K) be a rule 
list, then 

R(d,x,y) ≥ 
U∑ 
u=1 

θ(eu) + λK. (88) 

28 



Learning Certifiably Optimal Rule Lists for Categorical Data 

Proof Recall that the objective be R(d,x,y) = `(d,x,y) + λK, where the misclassification 
error `(d,x,y) be give by 

`(d,x,y) = `0(dp, q0,x,y) + `p(dp, δp,x,y) 

= 
1 

N 

N∑ 
n=1 

( 
¬ cap(xn, dp) ∧ 1[q0 6= yn] + 

K∑ 
k=1 

cap(xn, pk | dp) ∧ 1[qk 6= yn] 

) 
. (89) 

In the context of the rule list d, each set of equivalent point be classify by either a specific 
antecedent pk in d, or the default rule p0. For a set of equivalent point u, the rule list d 
correctly classifies either point that have the majority class label, or point that have 
the minority class label. Thus, d misclassifies a number of point in u at least a great a 
the number of point with the minority class label. To translate this into a low bound 
on `(d,x,y), we first sum over all set of equivalent points, and then for each such set, count 
difference between class label and the minority class label of the set, instead of counting 
mistakes: 

`(d,x,y) 

= 
1 

N 

U∑ 
u=1 

N∑ 
n=1 

( 
¬ cap(xn, dp) ∧ 1[q0 6= yn] + 

K∑ 
k=1 

cap(xn, pk | dp) ∧ 1[qk 6= yn] 

) 
∧ 1[xn ∈ eu] 

≥ 1 
N 

U∑ 
u=1 

N∑ 
n=1 

( 
¬ cap(xn, dp) ∧ 1[yn = qu] + 

K∑ 
k=1 

cap(xn, pk | dp) ∧ 1[yn = qu] 

) 
∧ 1[xn ∈ eu]. 

(90) 

Next, we factor out the indicator for equivalent point set membership, which yield a term 
that sum to one, because every datum be either capture or not capture by prefix dp. 

`(d,x,y) = 
1 

N 

U∑ 
u=1 

N∑ 
n=1 

( 
¬ cap(xn, dp) + 

K∑ 
k=1 

cap(xn, pk | dp) 

) 
∧ 1[xn ∈ eu] ∧ 1[yn = qu] 

= 
1 

N 

U∑ 
u=1 

N∑ 
n=1 

(¬ cap(xn, dp) + cap(xn, dp)) ∧ 1[xn ∈ eu] ∧ 1[yn = qu] 

= 
1 

N 

U∑ 
u=1 

N∑ 
n=1 

1[xn ∈ eu] ∧ 1[yn = qu] = 
U∑ 
u=1 

θ(eu), (91) 

where the final equality applies the definition of θ(eu) in (87). Therefore, R(d,x,y) = 
`(d,x,y) + λK ≥ 

∑U 
u=1 θ(eu) + λK. 

Now, recall that to obtain our low bound b(dp,x,y) in (10), we simply delete the 
default rule misclassification error `0(dp, q0,x,y) from the objective R(d,x,y). Theorem 22 
obtains a tighter objective low bound via a tighter low bound on the default rule mis- 
classification error, 0 ≤ b0(dp,x,y) ≤ `0(dp, q0,x,y). 

29 



Angelino, Larus-Stone, Alabi, Seltzer, and Rudin 

Theorem 22 (Equivalent point bound) Let d be a rule list with prefix dp and low 
bound b(dp,x,y), then for any rule list d 

′ ∈ σ(d) whose prefix d′p start with dp, 

R(d′,x,y) ≥ b(dp,x,y) + b0(dp,x,y), (92) 

where 

b0(dp,x,y) = 
1 

N 

U∑ 
u=1 

N∑ 
n=1 

¬ cap(xn, dp) ∧ 1[xn ∈ eu] ∧ 1[yn = qu]. (93) 

Proof We derive a low bound on the default rule misclassification error `0(dp, q0,x,y), 
analogous to the low bound (90) on the misclassification error `(d,x,y) in the proof of 
Proposition 21. As before, we sum over all set of equivalent points, and then for each such 
set, we count difference between class label and the minority class label of the set, instead 
of counting mistake make by the default rule: 

`0(dp, q0,x,y) = 
1 

N 

N∑ 
n=1 

¬ cap(xn, dp) ∧ 1[q0 6= yn] 

= 
1 

N 

U∑ 
u=1 

N∑ 
n=1 

¬ cap(xn, dp) ∧ 1[q0 6= yn] ∧ 1[xn ∈ eu] 

≥ 1 
N 

U∑ 
u=1 

N∑ 
n=1 

¬ cap(xn, dp) ∧ 1[yn = qu] ∧ 1[xn ∈ eu] = b0(dp,x,y), (94) 

where the final equality come from the definition of b0(dp,x,y) in (93). Since we can write 
the objective R(d,x,y) a the sum of the objective low bound b(dp,x,y) and default rule 
misclassification error `0(dp, q0,x,y), apply (94) give a low bound on R(d,x,y): 

R(d,x,y) = `p(dp, δp,x,y) + `0(dp, q0,x,y) + λK = b(dp,x,y) + `0(dp, q0,x,y) 

≥ b(dp,x,y) + b0(dp,x,y). (95) 

It follow that for any rule list d′ ∈ σ(d) whose prefix d′p start with dp, we have 

R(d′,x,y) ≥ b(d′p,x,y) + b0(d′p,x,y). (96) 

Finally, we show that the low bound on R(d,x,y) in (95) be not great than the low 
bound on R(d′,x,y) in (96). First, let u define 

Υ(d′p,K,x,y) ≡ 
1 

N 

U∑ 
u=1 

N∑ 
n=1 

K′∑ 
k=K+1 

cap(xn, pk | d′p) ∧ 1[xn ∈ eu] ∧ 1[yn = qu]. (97) 

30 



Learning Certifiably Optimal Rule Lists for Categorical Data 

Now, we write a low bound on b(d′p,x,y) with respect to b(dp,x,y): 

b(d′p,x,y) = `p(d 
′ 
p, δp,x,y) + λK 

′ = 
1 

N 

N∑ 
n=1 

K′∑ 
k=1 

cap(xn, pk | d′p) ∧ 1[qk 6= yn] + λK ′ 

= `p(dp, δp,x,y) + λK + 
1 

N 

N∑ 
n=1 

K′∑ 
k=K 

cap(xn, pk | d′p) ∧ 1[qk 6= yn] + λ(K ′ −K) 

= b(dp,x,y) + 
1 

N 

N∑ 
n=1 

K′∑ 
k=K+1 

cap(xn, pk | d′p) ∧ 1[qk 6= yn] + λ(K ′ −K) 

= b(dp,x,y) + 
1 

N 

U∑ 
u=1 

N∑ 
n=1 

K′∑ 
k=K+1 

cap(xn, pk | d′p) ∧ 1[qk 6= yn] ∧ 1[xn ∈ eu] + λ(K ′ −K) 

≥ b(dp,x,y) + 
1 

N 

U∑ 
u=1 

N∑ 
n=1 

K′∑ 
k=K+1 

cap(xn, pk | d′p) ∧ 1[yn = qu] ∧ 1[xn ∈ eu] + λ(K ′ −K) 

= b(dp,x,y) + Υ(d 
′ 
p,K,x,y) + λ(K 

′ −K). (98) 

Next, we write b0(dp,x,y) with respect to b0(d 
′ 
p,x,y), 

b0(dp,x,y) = 
1 

N 

U∑ 
u=1 

N∑ 
n=1 

¬ cap(xn, dp) ∧ 1[xn ∈ eu] ∧ 1[yn = qu] 

= 
1 

N 

U∑ 
u=1 

N∑ 
n=1 

( 
¬ cap(xn, d′p) + 

K′∑ 
k=K+1 

cap(xn, pk | d′p) 

) 
∧ 1[xn ∈ eu] ∧ 1[yn = qu] 

= b0(d 
′ 
p,x,y) + 

1 

N 

U∑ 
u=1 

N∑ 
n=1 

K′∑ 
k=K+1 

cap(xn, pk | d′p) ∧ 1[xn ∈ eu] ∧ 1[yn = qu], (99) 

thus rearrange give 

b0(d 
′ 
p,x,y) = b0(dp,x, y)−Υ(d′p,K,x,y). (100) 

Combining (96) with first (100) and then (98) gives: 

R(d′,x,y) ≥ b(d′p,x,y) + b0(d′p,x,y) 
= b(d′p,x,y) + b0(dp,x, y)−Υ(d′p,K,x,y) 
≥ b(dp,x,y) + Υ(d′p,K,x,y) + λ(K ′ −K) + b0(dp,x, y)−Υ(d′p,K,x,y) 
= b(dp,x,y) + b0(dp,x, y) + λ(K 

′ −K) ≥ b(dp,x,y) + b0(dp,x,y). (101) 

31 



Angelino, Larus-Stone, Alabi, Seltzer, and Rudin 

4. Incremental computation 

For every prefix dp evaluate during Algorithm 1’s execution, we compute the objective 
low bound b(dp,x,y) and sometimes the objective R(d,x,y) of the correspond rule 
list d. These calculation be the dominant computation with respect to execution time. 
This motivates our use of a highly optimize library, design by Yang et al. (2016) for 
represent rule list and perform operation encounter in evaluate function of rule 
lists. Furthermore, we exploit the hierarchical nature of the objective function and it low 
bound to compute these quantity incrementally throughout branch-and-bound execution. 
In this section, we provide explicit expression for the incremental computation that be 
central to our approach. Later, in §5, we describe a cache data structure for support our 
incremental framework in practice. 

For completeness, before present our incremental expressions, let u begin by write 
down the objective low bound and objective of the empty rule list, d = ((), (), q0, 0), the 
first rule list evaluate in Algorithm 1. Since it prefix contains zero rules, it have zero prefix 
misclassification error and also have length zero. Thus, the empty rule list’s objective low 
bound be zero: 

b((),x,y) = `p((), (),x,y) + λ · 0 = 0. (102) 

Since none of the data be capture by the empty prefix, the default rule corresponds to 
the majority class, and the objective corresponds to the default rule misclassification error: 

R(d,x,y) = `(d,x,y) + λ · 0 = `p((), (),x,y) + `0((), q0,x,y) 
= b((),x,y) + `0((), q0,x,y) = `0((), q0,x,y). (103) 

Now, we derive our incremental expression for the objective function and it low 
bound. Let d = (dp, δp, q0,K) and d 

′ = (d′p, δ 
′ 
p, q 
′ 
0,K + 1) be rule list such that prefix dp = 

(p1, . . . , pK) be the parent of d 
′ 
p = (p1, . . . , pK , pK+1). Let δp = (q1, . . . , qK) and δ 

′ 
p = (q1, . . . , 

qK , qK+1) be the correspond labels. The hierarchical structure of Algorithm 1 enforces 
that if we ever evaluate d′, then we will have already evaluate both the objective and ob- 
jective low bound of it parent, d. We would like to reuse a much of these computation a 
possible in our evaluation of d′. We can write the objective low bound of d′ incrementally, 
with respect to the objective low bound of d: 

b(d′p,x,y) = `p(d 
′ 
p, δ 
′ 
p,x,y) + λ(K + 1) 

= 
1 

N 

N∑ 
n=1 

K+1∑ 
k=1 

cap(xn, pk | d′p) ∧ 1[qk 6= yn] + λ(K + 1) (104) 

= `p(dp, δp,x,y) + λK + λ+ 
1 

N 

N∑ 
n=1 

cap(xn, pK+1 | d′p) ∧ 1[qK+1 6= yn] 

= b(dp,x,y) + λ+ 
1 

N 

N∑ 
n=1 

cap(xn, pK+1 | d′p) ∧ 1[qK+1 6= yn] 

= b(dp,x,y) + λ+ 
1 

N 

N∑ 
n=1 

¬ cap(xn, dp) ∧ cap(xn, pK+1) ∧ 1[qK+1 6= yn]. (105) 

32 



Learning Certifiably Optimal Rule Lists for Categorical Data 

Thus, if we store b(dp,x,y), then we can reuse this quantity when compute b(d 
′ 
p,x,y). 

Transforming (104) into (105) yield a significantly simpler expression that be a function of 
the store quantity b(dp,x,y). For the objective of d 

′, first let u write a näıve expression: 

R(d′,x,y) = `(d′,x,y) + λ(K + 1) = `p(d 
′ 
p, δ 
′ 
p,x,y) + `0(d 

′ 
p, q 
′ 
0,x,y) + λ(K + 1) 

= 
1 

N 

N∑ 
n=1 

K+1∑ 
k=1 

cap(xn, pk | d′p) ∧ 1[qk 6= yn] + 
1 

N 

N∑ 
n=1 

¬ cap(xn, d′p) ∧ 1[q′0 6= yn] + λ(K + 1). 

(106) 

Instead, we can compute the objective of d′ incrementally with respect to it objective low 
bound: 

R(d′,x,y) = `p(d 
′ 
p, δ 
′ 
p,x,y) + `0(d 

′ 
p, q 
′ 
0,x,y) + λ(K + 1) 

= b(d′p,x,y) + `0(d 
′ 
p, q 
′ 
0,x, y) 

= b(d′p,x,y) + 
1 

N 

N∑ 
n=1 

¬ cap(xn, d′p) ∧ 1[q′0 6= yn] 

= b(d′p,x,y) + 
1 

N 

N∑ 
n=1 

¬ cap(xn, dp) ∧ (¬ cap(xn, pK+1)) ∧ 1[q′0 6= yn]. (107) 

The expression in (107) be much simpler than the näıve one in (106), and be a function 
of b(d′p,x,y), which we compute in (105). Though we could compute the objective of d 

′ 

incrementally with respect to that of d, do so would in practice require that we also 
store R(d,x,y); we prefer the approach suggest by (107) since it avoids this additional 
storage overhead. 

We present an incremental branch-and-bound procedure in Algorithm 2, and show the 
incremental computation of the objective low bound (105) and objective (107) a two 
separate function in Algorithms 3 and 4, respectively. In Algorithm 2, we use a cache to 
store prefix and their objective low bounds. Algorithm 2 additionally reorganizes the 
structure of Algorithm 1 to group together the computation associate with all child 
of a particular prefix. This have two advantages. The first be to consolidate cache queries: all 
child of the same parent prefix compute their objective low bound with respect to the 
parent’s store value, and we only require one cache ‘find’ operation for the entire group 
of children, instead of a separate query for each child. The second be to shrink the queue’s 
size: instead of add all of a prefix’s child a separate queue elements, we represent 
the entire group of child in the queue by a single element. Since the number of child 
associate with each prefix be close to the total number of possible antecedents, both of these 
effect can yield significant savings. For example, if we be try to optimize over rule list 
form from a set of 1000 antecedents, then the maximum queue size in Algorithm 2 will 
be small than that in Algorithm 1 by a factor of nearly 1000. 

5. Implementation 

We implement our algorithm use a collection of optimize data structures: a trie (prefix 
tree), a symmetry-aware map, and a queue. The trie act like a cache, keep track of 

33 



Angelino, Larus-Stone, Alabi, Seltzer, and Rudin 

Algorithm 2 Incremental branch-and-bound for learn rule lists, for simplicity, from a 
cold start. We explicitly show the incremental objective low bound and objective function 
in Algorithms 3 and 4, respectively. 

Input: Objective function R(d,x,y), objective low bound b(dp,x,y), set of antecedent 
S = {sm}Mm=1, training data (x,y) = {(xn, yn)}Nn=1, regularization parameter λ 
Output: Provably optimal rule list d∗ with minimum objective R∗ 

dc ← ((), (), q0, 0) . Initialize current best rule list with empty rule list 
Rc ← R(dc,x,y) . Initialize current best objective 
Q← queue( [ ( ) ] ) . Initialize queue with empty prefix 
C ← cache( [ ( ( ) , 0 ) ] ) . Initialize cache with empty prefix and it objective low bound 
while Q not empty do . Optimization complete when the queue be empty 

dp ← Q.pop( ) . Remove a prefix dp from the queue 
b(dp,x,y)← C.find(dp) . Look up dp’s low bound in the cache 
u← ¬ cap(x, dp) . Bit vector indicate data not capture by dp 
for s in S do . Evaluate all of dp’s child 

if s not in dp then 
Dp ← (dp, s) . Branch: Generate child Dp 
v← u ∧ cap(x, s) . Bit vector indicate data capture by s in Dp 
b(Dp,x,y)← b(dp,x,y) + λ + IncrementalLowerBound(v,y, N) 
if b(Dp,x,y) < R 

c then . Bound: Apply bound from Theorem 1 
R(D,x,y)← b(Dp,x,y) + IncrementalObjective(u,v,y, N) 
if R(D,x,y) < Rc then 

(dc, Rc)← (D,R(D,x,y)) . Update current best rule list and objective 
end if 
Q.push(Dp) . Add Dp to the queue 
C.insert(Dp, b(Dp,x,y)) . Add Dp and it low bound to the cache 

end if 
end if 

end for 
end while 
(d∗, R∗)← (dc, Rc) . Identify provably optimal rule list and objective 

rule list we have already evaluated. Each node in the trie contains metadata associate 
with that correspond rule list; the metadata consists of bookkeeping information such 
a what child rule list be feasible and the low bound and accuracy for that rule list. We 
also track the best observe minimum objective and it associate rule list. 

The symmetry-aware map support symmetry-aware pruning. We implement this use 
the C++ STL unordered map, to map all permutation of a set of antecedent to a key, 
whose value contains the best order of those antecedent (i.e., the prefix with the small- 
est low bound). Every antecedent be associate with an index, and we call the numerically 
sort order of a set of antecedent it canonical order. Thus by query a set of antecedent 
by it canonical order, all permutation map to the same key. The symmetry-aware map 
dominates memory usage for problem that explore longer prefixes. Before insert per- 

34 



Learning Certifiably Optimal Rule Lists for Categorical Data 

Algorithm 3 Incremental objective low bound (105) use in Algorithm 2. 

Input: Bit vector v ∈ {0, 1}N indicate data capture by s, the last antecedent in Dp, 
bit vector of class label y ∈ {0, 1}N , number of observation N 
Output: Component of D’s misclassification error due to data capture by s 

function IncrementalLowerBound(v,y, N) 
nv = sum(v) . Number of data capture by s, the last antecedent in Dp 
w← v ∧ y . Bit vector indicate data capture by s with label 1 
nw = sum(w) . Number of data capture by s with label 1 
if nw/nv > 0.5 then 

return (nv − nw)/N . Misclassification error of the rule s→ 1 
else 

return nw/N . Misclassification error of the rule s→ 0 
end if 

end function 

Algorithm 4 Incremental objective function (107) use in Algorithm 2. 

Input: Bit vector u ∈ {0, 1}N indicate data not capture by Dp’s parent prefix, bit 
vector v ∈ {0, 1}N indicate data not capture by s, the last antecedent in Dp, bit 
vector of class label y ∈ {0, 1}N , number of observation N 
Output: Component of D’s misclassification error due to it default rule 

function IncrementalObjective(u,v,y, N) 
f ← u ∧ ¬v . Bit vector indicate data not capture by Dp 
nf = sum(f) . Number of data not capture by Dp 
g← f ∧ y . Bit vector indicate data not capture by Dp with label 1 
ng = sum(w) . Number of data not captued by Dp with label 1 
if nf/ng > 0.5 then 

return (nf − ng)/N . Default rule misclassification error with label 1 
else 

return ng/N . Default rule misclassification error with label 0 
end if 

end function 

mutation Pi into the symmetry-aware map, we check if there exists a permutation Pj of Pi 
already in the map. If the low bound of Pi be good than that of Pj , we update the map 
and remove Pj and it subtree from the trie. Otherwise we do nothing (i.e., we do not insert 
Pi into the symmetry-aware map or the trie). 

We use a queue to store all of the leaf of the trie that still need to be explored. We order 
entry in the queue to implement several different policies. A first-in-first-out (FIFO) queue 
implement breadth-first search (BFS), and a priority queue implement best-first search. 
Example priority queue policy include order by the low bound, the objective, or a 
custom metric that map prefix to real values. We also support a stochastic exploration 

35 



Angelino, Larus-Stone, Alabi, Seltzer, and Rudin 

process that bypass the need for a queue by instead follow random path from the root 
to leaves. We find that order by the low bound and other priority metric often lead 
to a shorter runtime than use BFS. 

Mapping our algorithm to our data structure produce the follow execution strategy. 
While the trie contains unexplored leaves, a schedule policy selects the next prefix to 
extend. Then, for every antecedent that be not already in this prefix, we calculate the low 
bound, objective, and other metric for the rule list form by append the antecedent 
to the prefix. If the low bound of the new rule list be less than the current minimum 
objective, we insert that rule list into the symmetry-aware map, trie, and queue, and, if 
relevant, update the current minimum objective. If the low bound be great than the 
minimum objective, then no extension of this rule list could possibly be optimal, thus we 
do not insert the new rule list into the tree or queue. We also leverage our other bound 
from §3 to aggressively prune the search space. 

During execution, we garbage collect the trie. Each time we update the minimum ob- 
jective, we traverse the trie in a depth-first manner, delete all subtrees of any node with 
low bound large than the current minimum objective. At other times, when we encounter 
a node with no children, we prune upwards–deleting that node and recursively traverse 
the tree towards the root, delete any childless nodes. This garbage collection allows u 
to constrain the trie’s memory consumption, though in our experiment we observe the 
minimum objective to decrease only a small number of times. 

Our implementation of CORELS be at https://github.com/nlarusstone/corels. 

6. Experiments 

Our experimental analysis address five questions: (1) How do CORELS’ accuracy com- 
pare to other algorithms? (2) How do CORELS’ model size compare to other algorithms? 
(3) How rapidly do the objective function converge? (4) How rapidly do CORELS prune 
the search space? (5) How much do each of the implementation optimization contribute 
to CORELS’ performance? 

All result that we present be execute on a server with two Intel Xeon E5-2699 v4 
(55 MB cache, 2.20 GHz) processor and 448 GB RAM. Except where we mention a memory 
constraint, all experiment can run comfortably on small machines, e.g., a laptop with 
16GB RAM. 

Our evaluation focus on two socially-important prediction problem associate with 
recent, publicly-available datasets: 

• Predicting which individual in the ProPublica COMPAS dataset (Larson et al., 2016) 
recidivate within two years. 

• Using the NYCLU 2014 stop-and-frisk dataset (New York Civil Liberties Union, 2014) 
to predict whether a weapon will be found on a stop individual who be frisk or 
searched. 

Our choice of and approach to the second problem be inspire by the work of Goel et al. 
(2016), who develop regression model to analyze racial disparity in New York City’s stop- 
and-frisk policy, for a similar, large dataset. In particular, the author arrive at a simple 

36 

https://github.com/nlarusstone/corels 


Learning Certifiably Optimal Rule Lists for Categorical Data 

if (location = transit authority) then predict yes 
else if (stop reason = suspicious object) then predict yes 
else if (stop reason = suspicious bulge) then predict yes 
else predict no 

Figure 3: An example rule list that predicts whether a weapon will be found on a stop 
individual who be frisk or searched, for the NYCLU stop-and-frisk dataset. This be the 
most common optimal rule list found by CORELS across 10 cross-validation folds; the others 
contain the same rules, up to a permutation. 

GL 
M 

SV 
M 

Ad 
aB 

oo 
st 
CA 

RT 
C4 

.5 RF 

RI 
PP 

ER 
SB 

RL 

CO 
RE 

LS 
0.63 

0.65 

0.67 

0.69 

0.71 

A 
cc 

u 
ra 

cy 

Recidivism prediction (ProPublica) 

GL 
M 

SV 
M 

Ad 
aB 

oo 
st 
CA 

RT 
C4 

.5 RF 
SB 

RL 

CO 
RE 

LS 
0.62 

0.65 

0.68 

0.71 

0.74 

Weapon prediction (NYCLU) 

Figure 4: Comparison of CORELS and a panel of eight other algorithms: logistic regres- 
sion (GLM), support vector machine (SVM), AdaBoost, CART, C4.5, random forest (RF), 
RIPPER, scalable Bayesian rule list (SBRL). Test accuracy mean (white squares), stan- 
dard deviation (error bars), and value (colors correspond to folds), for 10-fold cross- 
validation experiments. Left: Two-year recidivism prediction for the ProPublica COMPAS 
dataset. For CORELS, we use regularization parameter λ = 0.005. Right: Weapon predic- 
tion for the NYCLU stop-and-frisk dataset. For CORELS, we use λ = 0.01. Note that we 
be unable to execute RIPPER for the NYCLU problem. 

and interpretable heuristic that could potentially help police officer more effectively decide 
when to frisk and/or search stop individuals, i.e., when such intervention be likely to 
discover criminal possession of a weapon. 

We first ran a 10-fold cross validation experiment use CORELS and eight other al- 
gorithms: logistic regression, support vector machines, AdaBoost, CART, C4.5, random 
forests, RIPPER, and scalable Bayesian rule list (SBRL). 3 We use standard R packages, 
with default parameter settings, for the first seven algorithms. 4 

Figures 1 and 3 show example optimal rule list that CORELS learns for the ProPublica 
and NYCLU datasets, respectively. While our goal be to provide illustrative examples, and 
not to provide a detailed analysis nor to advocate for the use of these specific models, we 
note that these rule list be short and easy to understand. In particular, the three-rule list 
for weapon prediction in Figure 3 have the spirit of the heuristic strategy present by Goel 

3. For SBRL, we use the C implementation at https://github.com/Hongyuy/sbrlmod. 
4. For CART, C4.5 (J48), and RIPPER, i.e., the tree and rule list learn algorithms, we use the imple- 

mentation from the R package rpart, RWeka, and caret, respectively. By default, CART us complexity 
parameter cp = 0.01, and C4.5 us complexity parameter C = 0.25. 

37 

https://github.com/Hongyuy/sbrlmod 


Angelino, Larus-Stone, Alabi, Seltzer, and Rudin 

0 5 10 15 20 25 30 35 
Model size 

0.60 

0.62 

0.64 

0.66 

0.68 

0.70 

A 
cc 

u 
ra 

cy 

Two-year recidivism prediction (ProPublica dataset) 

CORELS (.005) 

CORELS (.01) 

CORELS (.02) 

RIPPER 

SBRL 

CART (.001) 

CART (.003) 

CART (.01) 

CART (.03) 

CART (.1) 

C4.5 (.05) 

C4.5 (.15) 

C4.5 (.25) 

C4.5 (.35) 

C4.5 (.45) 

0 5 10 15 20 25 30 35 40 45 50 55 
Model size 

0.63 

0.65 

0.67 

0.69 

0.71 

0.73 

0.75 

A 
cc 

u 
ra 

cy 

Weapon prediction (NYCLU stop-and-frisk dataset) 

CORELS (.0025) 

CORELS (.01) 

CORELS (.04) 

SBRL 

CART (.001) 

CART (.003) 

CART (.01) 

CART (.1) 

Figure 5: Training and test accuracy a a function of model size. For CORELS, CART, 
and C4.5, we vary the regularization parameter λ, and complexity parameter cp and C, 
respectively; number within parenthesis in the legend indicate parameter values. Note 
that the CART implementation set cp = 0.01 by default, and C4.5 us C = 0.25. Legend 
marker and error bar indicate mean and standard deviations, respectively, of test accuracy 
across cross-validation folds. Small circle mark associate training accuracy means. Top: 
Two-year recidivism prediction for the ProPublica COMPAS dataset. None of the model 
exhibit significant overfitting: mean training accuracy never exceeds mean test accuracy by 
more than about 0.01. Bottom: Weapon prediction for the NYCLU stop-and-frisk dataset. 
Only CART with cp = 0.001 significantly overfits. We do not depict C4.5, which find large 
model (> 100 leaves) and dramatically overfits for all test parameters. 

et al. (2016) that combine three stop criterion and be base on a reduce version of their 
full regression model. 

Figure 4 show that there be no statistically significant difference in algorithm ac- 
curacies. In fact, the difference between fold be far large than the difference between 
algorithms. We conclude that CORELS produce model whose accuracy be comparable to 
those found via other algorithms. 

Figure 5 summarizes difference in accuracy and model size for CORELS and other 
tree (CART, C4.5) and rule list (RIPPER, SBRL) learn algorithms. For both problems, 
CORELS can learn short rule list without sacrifice accuracy. 

38 



Learning Certifiably Optimal Rule Lists for Categorical Data 

10-3 10-2 10-1 100 101 102 103 104 
0.0 

0.1 

0.2 

0.3 

0.4 

0.5 

V 
a 
lu 

e 

1 

2 3 4 

Execution progress 

Objective (CORELS) 

Lower bound (CORELS) 

Lower bound (w/o equivalent point bound) 

10-3 10-2 10-1 100 101 102 103 104 

Time (s) 

0 

50 

100 

150 

lo 
g 
1 
0 
(S 

iz 
e 
) 

Size of remain search space 

w/o equivalent point bound 

CORELS 

Figure 6: CORELS with (lines) and without (dashes) the equivalent point bound (Theo- 
rem 22). Top: Objective value (thin line) and low bound (thick line) for CORELS, a a 
function of wall clock time (log scale). Numbered hatch mark along the trace of the ob- 
jective value indicate when the length of the best know rule list changes, and be label 
by the new length. CORELS quickly achieves the optimal value (star marker), and certi- 
fies optimality when the low bound match the objective value. A separate execution 
of CORELS without the equivalent point bound remains far from complete, and it low 
bound (dashed line) far from the optimum. Bottom: blog10 Γ(Rc, Q)c, a a function of wall 
clock time (log scale), where Γ(Rc, Q) be the upper bound on remain search space size 
(Theorem 7). 

In the remainder, we show result use the ProPublica dataset. The solid line in 
Figure 6 illustrate how both the objective (top) and the size of the remain search space 
(bottom) decrease a CORELS executes. The objective drop quickly, achieve the optimal 
value within 10 seconds. CORELS certifies optimality in less than 6 minute – the objective 
low bound of the remain search space steadily converges to the optimal objective a 
the search space shrinks. 

Finally, we determine the efficacy of each of our bound and data structure optimiza- 
tions. Both panel of Figure 6 also highlight a separate execution of CORELS without the 
equivalent point bound. After nearly 3 hours, the execution be still far from complete; in 
particular, the low bound be far from the optimum objective value. Table 1 provide sum- 
mary statistic for experiment use the full CORELS implementation and five variant 
that each remove a specific optimization. Figure 7 present a view of the same experi- 
ments. These plot depict the number of prefix of a give length in the queue during the 
algorithm’s execution. 

39 



Angelino, Larus-Stone, Alabi, Seltzer, and Rudin 

Removed component ttotal (min) topt (s) itotal (×106) Qmax (×106) Kmax 
none (CORELS) 5.5 (1.6) 8 (2) 1.7 (0.4) 1.3 (0.4) 5-6 
priority queue (BFS) 6.7 (2.2) 4 (1) 1.9 (0.6) 1.5 (0.5) 5-6 
support bound 10.2 (3.4) 13 (4) 2.7 (0.8) 2.2 (0.7) 5-6 
symmetry-aware map 58.6 (23.3) 23 (6) 16.0 (5.9) 14.5 (5.7) 5-6 
lookahead bound 71.9 (23.0) 9 (2) 18.5 (5.9) 16.3 (5.3) 6-7 
equivalent pt bound >134 >7168* >800 >789 ≥10 

Table 1: Per-component performance improvement. The column report total execution 
time, time to optimum, number of queue insertions, maximum queue size, and maximum 
evaluate prefix length. The first row show CORELS; subsequent row show variant that 
each remove a specific implementation optimization or bound. (We be not measure the 
cumulative effect of remove a sequence of components.) All row represent complete 
executions, except for the final row, in which each execution be terminate due to memory 
constraints, once the size of the cache reach 8× 108 elements, after consume 390-410GB 
RAM. In all but the final row and column, we report mean (and standard deviations) over 
10 cross-validation folds; in the final row, we report the minimum value across folds. 
* Only 4 out of 10 fold achieve the optimum before be terminated. 

10-4 10-3 10-2 10-1 100 101 102 103 104 
100 

101 

102 

103 

104 

105 

106 

107 

108 

C 
o 
u 
n 
t 

1 2 3 4 

T ≡ 149 s 

CORELS 

10-4 10-3 10-2 10-1 100 101 102 103 104 
100 

101 

102 

103 

104 

105 

106 

107 

108 

1 2 3 4 

176 s ≈ 1.2 T 

No priority queue 

10-4 10-3 10-2 10-1 100 101 102 103 104 
100 

101 

102 

103 

104 

105 

106 

107 

108 

1 2 3 4 

270 s ≈ 1.8 T 

No support bound 

10-4 10-3 10-2 10-1 100 101 102 103 104 

Time (s) 

100 

101 

102 

103 

104 

105 

106 

107 

108 

C 
o 
u 
n 
t 

1 2 3 4 

1340 s ≈ 9.0 T 

No symmetry-aware map 

10-4 10-3 10-2 10-1 100 101 102 103 104 

Time (s) 

100 

101 

102 

103 

104 

105 

106 

107 

108 

1 2 3 4 5 

1759 s ≈ 12 T 

No lookahead bound 

10-4 10-3 10-2 10-1 100 101 102 103 104 

Time (s) 

100 

101 

102 

103 

104 

105 

106 

107 

108 

1 2 3 4 5 6 7 8 9 

> 9532 s ≈ 64 T 

No equivalent point bound 

Figure 7: Logical queue composition. Numbers of prefix in the queue (log scale), label 
and color by length, a a function of wall clock time (log scale), for full CORELS (top 
left), and five variant that each remove a specific implementation optimization or bound. 
The gray shade fill in the area beneath the total number of queue element for CORELS, 
i.e., the sum over all length in the top left figure. For comparison, we replicate the same 
gray region in the other three subfigures. For each execution, we indicate the total time 
both in seconds, and relative to the full CORELS implementation (T = 149 s). 

40 



Learning Certifiably Optimal Rule Lists for Categorical Data 

7. Conclusion 

CORELS be an efficient and accurate algorithm for construct provably optimal rule lists. 
Optimality be particularly important in domain where model interpretability have social 
consequences, e.g., recidivism prediction. While achieve optimality on such discrete op- 
timization problem be computationally hard in general, we aggressively prune our prob- 
lem’s search space via a suite of bounds. This make realistically size problem tractable. 
CORELS be amenable to parallelization, which should allow it to scale to even large prob- 
lems. 

Acknowledgments 

E.A. be support by the Miller Institute for Basic Research in Science, University of Cal- 
ifornia, Berkeley, and be host by Prof. M.I. Jordan at RISELab. C.D.R. be support in 
part by MIT-Lincoln Labs. E.A. would like to thank E. Jonas, E. Kohler, and S. Tu for 
early implementation guidance, A. D’Amour for point out the work by Goel et al. (2016), 
J. Schleier-Smith and E. Thewalt for helpful conversations, and member of RISELab, SAIL, 
and the UC Berkeley Database Group for their support and feedback. We thank H. Yang 
and B. Letham for share advice and code for processing data and mining rules. 

References 

K. P. Bennett and J. A. Blue. Optimal decision trees. Technical report, R.P.I. Math Report 
No. 214, Rensselaer Polytechnic Institute, 1996. 

I. Bratko. Machine learning: Between accuracy and interpretability. In Learning, Networks 
and Statistics, volume 382 of International Centre for Mechanical Sciences, page 163– 
177. Springer Vienna, 1997. ISBN 978-3-211-82910-3. 

L. Breiman, J. H. Friedman, R. A. Olshen, and C. J. Stone. Classification and Regression 
Trees. Wadsworth, 1984. 

C. Chen and C. Rudin. Optimized fall rule list and softly fall rule lists. Work in 
progress, 2017. 

H. A. Chipman, E. I. George, and R. E. McCulloch. Bayesian CART model search. Journal 
of the American Statistical Association, 93(443):935–948, 1998. 

H. A. Chipman, E. I. George, and R. E. McCulloch. Bayesian treed models. Machine 
Learning, 48(1/3):299–320, 2002. 

H. A. Chipman, E. I. George, and R. E. McCulloch. BART: Bayesian additive regression 
trees. The Annals of Applied Statistics, 4(1):266–298, 2010. 

W. W. Cohen. Fast effective rule induction. In Twelfth International Conference on Machine 
Learning (ICML), page 115–123, 1995. 

41 



Angelino, Larus-Stone, Alabi, Seltzer, and Rudin 

R. M. Dawes. The robust beauty of improper linear model in decision making. American 
Psychologist, 34(7):571–582, 1979. 

D. Dension, B. Mallick, and A.F.M. Smith. A Bayesian CART algorithm. Biometrika, 85 
(2):363–377, 1998. 

D. Dobkin, T. Fulton, D. Gunopulos, S. Kasif, and S. Salzberg. Induction of shallow decision 
trees, 1996. 

A. Farhangfar, R. Greiner, and M. Zinkevich. A fast way to produce optimal fixed-depth 
decision trees. In International Symposium on Artificial Intelligence and Mathematics 
(ISAIM 2008), 2008. 

A. A. Freitas. Comprehensible classification models: a position paper. ACM SIGKDD 
Explorations Newsletter, 15(1):1–10, 2014. 

M. Garofalakis, D. Hyun, R. Rastogi, and K. Shim. Efficient algorithm for construct 
decision tree with constraints. In Proceedings of the Sixth ACM SIGKDD International 
Conference on Knowledge Discovery and Data Mining (KDD’98), page 335–339, 2000. 

C. Giraud-Carrier. Beyond predictive accuracy: What? In Proceedings of the ECML-98 
Workshop on Upgrading Learning to Meta-Level: Model Selection and Data Transforma- 
tion, page 78–85, 1998. 

S. Goel, J. M. Rao, and R. Shroff. Precinct or prejudice? Understanding racial disparity 
in New York City’s stop-and-frisk policy. Ann. Appl. Stat., 10(1):365–394, 03 2016. 

M. Goessling and S. Kang. Directional decision lists. Preprint at arXiv:1508.07643, Aug 
2015. 

B. Goodman and S. Flaxman. EU regulation on algorithmic decision-making and a “right 
to explanation”. Preprint at arXiv:1606.08813, 2016. 

R. C. Holte. Very simple classification rule perform well on most commonly use datasets. 
Machine Learning, 11(1):63–91, 1993. 

J. Huysmans, K. Dejaeger, C. Mues, J. Vanthienen, and B. Baesens. An empirical evaluation 
of the comprehensibility of decision table, tree and rule base predictive models. Decision 
Support Systems, 51(1):141–154, 2011. 

H. Lakkaraju and C. Rudin. Cost-sensitive and interpretable dynamic treatment regime 
base on rule lists. In Proceedings of the Artificial Intelligence and Statistics (AISTATS), 
2017. 

J. Larson, S. Mattu, L. Kirchner, and J. Angwin. How we analyze the COMPAS recidivism 
algorithm. ProPublica, 2016. 

N. L. Larus-Stone. Learning Certifiably Optimal Rule Lists: A Case For Discrete Optimiza- 
tion in the 21st Century. 2017. Undergraduate thesis, Harvard College. 

42 



Learning Certifiably Optimal Rule Lists for Categorical Data 

B. Letham, C. Rudin, T. H. McCormick, and D. Madigan. Interpretable classifier use 
rule and Bayesian analysis: Building a good stroke prediction model. Annals of Applied 
Statistics, 9(3):1350–1371, 2015. 

W. Li, J. Han, and J. Pei. CMAR: Accurate and efficient classification base on multiple 
class-association rules. IEEE International Conference on Data Mining, page 369–376, 
2001. 

B. Liu, W. Hsu, and Y. Ma. Integrating classification and association rule mining. In Pro- 
ceedings of the 4th International Conference on Knowledge Discovery and Data Mining, 
KDD ’98, page 80–96, 1998. 

M. Marchand and M. Sokolova. Learning with decision list of data-dependent features. 
Journal of Machine Learning Research, 6:427–451, 2005. 

T. H. McCormick, C. Rudin, and D. Madigan. Bayesian hierarchical rule model for 
predict medical conditions. The Annals of Applied Statistics, 6:652–668, 2012. 

S. Muggleton and L. De Raedt. Inductive logic programming: Theory and methods. The 
Journal of Logic Programming, 19:629–679, 1994. 

New York Civil Liberties Union. Stop-and-frisk data, 2014. http://www.nyclu.org/ 
content/stop-and-frisk-data. 

S. Nijssen and E. Fromont. Optimal constraint-based decision tree induction from itemset 
lattices. Data Mining and Knowledge Discovery, 21(1):9–51, 2010. ISSN 1384-5810. 

J. R. Quinlan. C4.5: Programs for Machine Learning. Morgan Kaufmann, 1993. 

R. L. Rivest. Learning decision lists. Machine Learning, 2(3):229–246, November 1987. 

C. Rudin and S. Ertekin. Learning optimize list of rule with mathematical programming. 
Unpublished, 2015. 

C. Rudin, B. Letham, and D. Madigan. Learning theory analysis for association rule and 
sequential event prediction. Journal of Machine Learning Research, 14:3384–3436, 2013. 

S. Rüping. Learning interpretable models. PhD thesis, Universität Dortmund, 2006. 

G. Shmueli. To explain or to predict? Statistical Science, 25(3):289–310, August 2010. ISSN 
0883-4237. 

M. Sokolova, M. Marchand, N. Japkowicz, and J. Shawe-Taylor. The decision list machine. 
In Advances in Neural Information Processing Systems, volume 15 of NIPS ’03, page 
921–928, 2003. 

K. Vanhoof and B. Depaire. Structure of association rule classifiers: A review. In Proceedings 
of the International Conference on Intelligent Systems and Knowledge Engineering, ISKE 
’10, page 9–12, 2010. 

43 

http://www.nyclu.org/content/stop-and-frisk-data 
http://www.nyclu.org/content/stop-and-frisk-data 


Angelino, Larus-Stone, Alabi, Seltzer, and Rudin 

A. Vellido, J. D. Mart́ın-Guerrero, and P. J.G. Lisboa. Making machine learn model 
interpretable. In Proceedings of the European Symposium on Artificial Neural Networks, 
Computational Intelligence and Machine Learning, 2012. 

F. Wang and C. Rudin. Falling rule lists. In Proceedings of Artificial Intelligence and 
Statistics (AISTATS), 2015. 

H. Yang, C. Rudin, and M. Seltzer. Scalable Bayesian rule lists. Preprint at 
arXiv:1602.08610, 2016. 

X. Yin and J. Han. CPAR: Classification base on predictive association rules. In Pro- 
ceedings of the 2003 SIAM International Conference on Data Mining, ICDM ’03, page 
331–335, 2003. 

Y. Zhang, E. B. Laber, A. Tsiatis, and M. Davidian. Using decision list to construct 
interpretable and parsimonious treatment regimes. Preprint at arXiv:1504.07715, April 
2015. 

44 


1 Introduction 
2 Related Work 
3 Learning optimal rule list 
3.1 Rule list for binary classification 
3.2 Objective function 
3.3 Optimization framework 
3.4 Hierarchical objective low bound 
3.5 Upper bound on prefix length 
3.6 Upper bound on the number of prefix evaluation 
3.7 Lower bound on antecedent support 
3.8 Upper bound on antecedent support 
3.9 Antecedent rejection and it propagation 
3.10 Equivalent support bound 
3.11 Permutation bound 
3.12 Upper bound on prefix evaluation with symmetry-aware prune 
3.13 Similar support bound 
3.14 Equivalent point bound 

4 Incremental computation 
5 Implementation 
6 Experiments 
7 Conclusion 

