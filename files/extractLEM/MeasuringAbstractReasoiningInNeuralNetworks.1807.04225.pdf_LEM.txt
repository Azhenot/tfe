









































Measuring abstract reason in neural network 

David G.T. Barrett * 1 Felix Hill * 1 Adam Santoro * 1 Ari S. Morcos 1 Timothy Lillicrap 1 

Abstract 
Whether neural network can learn abstract rea- 
soning or whether they merely rely on superficial 
statistic be a topic of recent debate. Here, we 
propose a dataset and challenge design to probe 
abstract reasoning, inspire by a well-known hu- 
man IQ test. To succeed at this challenge, model 
must cope with various generalisation ‘regimes’ 
in which the training and test data differ in clearly- 
define ways. We show that popular model such 
a ResNets perform poorly, even when the train- 
ing and test set differ only minimally, and we 
present a novel architecture, with a structure de- 
sign to encourage reasoning, that do signifi- 
cantly better. When we vary the way in which the 
test question and training data differ, we find that 
our model be notably proficient at certain form 
of generalisation, but notably weak at others. We 
further show that the model’s ability to generalise 
improves markedly if it be train to predict sym- 
bolic explanation for it answers. Altogether, 
we introduce and explore way to both measure 
and induce strong abstract reason in neural 
networks. Our freely-available dataset should mo- 
tivate further progress in this direction. 

1. Introduction 
Abstract reason be a hallmark of human intelligence. A 
famous example be Einstein’s elevator thought experiment, 
in which Einstein reason that an equivalence relation 
exists between an observer fall in uniform acceleration 
and an observer in a uniform gravitational field. It be the 
ability to relate these two abstract concept that allow 
him to derive the surprising prediction of general relativity, 
such a the curvature of space-time. 

A human’s capacity for abstract reason can be estimate 

*Equal contribution, order by surname. 1DeepMind, London, 
United Kingdom. Correspondence to: <{barrettdavid; felixhill; 
adamsantoro}@google.com>. 

Proceedings of the 35 th International Conference on Machine 
Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 
by the author(s). 

A B C D 

E F G H 

A B C D 

E F G H 
(a) (b) 

C 
on 

te 
xt 

P 
an 

el 
s 

An 
sw 

er 
P 

an 
el 

s 

+1 

+1 

XOR(panel 1, panel 2) 

Figure 1. Raven-style Progressive Matrices. In (a) the underly- 
ing abstract rule be an arithmetic progression on the number of 
shape along the columns. In (b) there be an XOR relation on the 
shape position along the row (panel 3 = XOR(panel 1, panel 2)). 
Other feature such a shape type do not factor in. A be the correct 
choice for both. 

surprisingly effectively use simple visual IQ tests, such 
a Raven’s Progressive Matrices (RPMs) (Figure 1) (Raven 
et al., 1938). The premise behind RPMs be simple: one must 
reason about the relationship between perceptually obvious 
visual feature – such a shape position or line color – to 
choose an image that completes the matrix. For example, 
perhaps the size of square increase along the rows, and 
the correct image be that which adheres to this size relation. 
RPMs be strongly diagnostic of abstract verbal, spatial and 
mathematical reason ability, discriminate even among 
population of highly educate subject (Snow et al., 1984). 

Since one of the goal of AI be to develop machine with 
similar abstract reason capability to humans, to aid sci- 
entific discovery for instance, it make sense to ask whether 
visual IQ test can help to understand learn machines. 
Unfortunately, even in the case of human such test can be 
invalidate if subject prepare too much, since test-specific 
heuristic can be learn that shortcut the need for generally- 
applicable reason (Te Nijenhuis et al., 2001; Flynn, 1987). 
This potential pitfall be even more acute in the case of neural 
networks, give their strike capacity for memorization 

ar 
X 

iv 
:1 

80 
7. 

04 
22 

5v 
1 

[ 
c 

.L 
G 

] 
1 

1 
Ju 

l 2 
01 

8 



Measuring abstract reason in neural network 

(Zhang et al., 2016) and ability to exploit superficial statisti- 
cal cue (Jo & Bengio, 2017; Szegedy et al., 2013). 

Nonetheless, we contend that visual intelligence test can 
help to good understand learn and reason in ma- 
chine (Fleuret et al., 2011), provide they be couple with 
a principled treatment of generalisation. Suppose we be 
concerned with whether a model can robustly infer the no- 
tion of ‘monotonically increasing’. In it most abstract form, 
this principle can apply to the quantity of shape or lines, or 
even the intensity of their colour. We can construct training 
data that instantiates this notion for increase quantity 
or size and we can construct test data that only involves 
increase colour intensities. Generalisation to the test set 
would then be evidence of an abstract and flexible applica- 
tion of what it mean to monotonically increase. In this way, 
a dataset with explicitly define abstract semantics (e.g., 
relations, attributes, pixels, etc.), allows u to curate train- 
ing and test set that precisely probe the generalisation 
dimension of abstract reason in which we be interested. 

To this end, we have developed a large dataset of abstract 
visual reason question where the underlie abstract se- 
mantics can be precisely controlled. This approach allows u 
to address the follow questions: (1) Can state-of-the-art 
neural network find solution – any solution – to complex, 
human-challenging abstract reason task if train with 
plentiful training data? (2) If so, how well do this capac- 
ity generalise when the abstract content of training data be 
specifically control for? 

To begin, we describe and motivate our dataset, outline a 
procedure for automatic generation of data, and detail the 
generalisation regime we chose to explore. Next, we estab- 
lish a number of strong baselines, and show that well know 
architecture that use only convolutions, such a ResNet-50 
(He et al., 2016), struggle. We design a novel variant of 
the Relation Network (Santoro et al., 2017; Raposo et al., 
2017), a neural network with specific structure design to 
encourage relation-level comparison and reasoning. We 
found that this model substantially outperforms other well- 
know architectures. We then study this top-performing 
model on our propose generalisation test and find that 
it generalises well in certain test regime (e.g. apply 
know abstract relationship in novel combinations), but 
fails notably in others (such a apply know abstract 
relationship to unfamiliar entities). Finally, we propose a 
mean to improve generalisation: the use of auxiliary train- 
ing to encourage our model to provide an explanation for it 
solutions. 

2. Procedurally generate matrix 
In 1936 the psychologist John Raven introduce the now 
famous human IQ test: Raven’s Progressive Matrices (RPM) 

(a) (b) 

Unary (progression on shape number) 

Binary (XOR on line type) 

Ternary (consistent union on shape type) 

{ {, , 

Figure 2. A difficult PGM and a depiction of relation types. (a) 
a challenge puzzle with multiple relation and distractor infor- 
mation. (b) a possible categorization of relation type base on 
how the panel be consider when compute the relation: for 
unary, a function be compute on one panel to produce the sub- 
sequent panel; for binary, two independently sample panel be 
consider in conjunction to produce a third panel; and for ternary, 
all three panel adhere to some rule, such a all contain shape 
from some common set, regardless of order. 

(Raven et al., 1938). RPMs consist of an incomplete 3× 3 
matrix of context image (see figure 1), and some (typically 
8) candidate answer images. The subject must decide which 
of the candidate image be the most appropriate choice to 
complete the matrix. 

It be thought that much of the power of RPMs a diagnos- 
tic of human intelligence derives from the way they probe 
eductive or fluid reason (Jaeggi et al., 2008). Since no 
definition of an ‘appropriate” choice be provided, it be in pos- 
sible in principle to come up with a reason support any 
of the candidate answers. To succeed, however, the subject 
must ass all candidate answers, all plausible justification 
for those answers, and identify the answer with the strong 
justification. In practice, the right answer tends to be the one 
that can be explain with the simplest justification use 
the basic relation underlie the matrices. 

Although Raven hand-designed each of the matrix in his 
tests, late research typically employ some structure 
generative model to create large number of questions. In 
this setting, a potential answer be correct if it be consistent 
with the underlie generative model, and success rest on 
the ability to invert the model. 

2.1. Automatic generation of PGMs 

Here we describe our process for create RPM-like matri- 
ces. We call our dataset the Procedurally Generated Matri- 
ce (PGM) dataset. To generate PGMs, we take inspiration 
from Carpenter et al. (1990), who identify and catalogue 



Measuring abstract reason in neural network 

the relation that commonly underlie RPMs, a well a 
Wang & Su (2015), who outline one process for create 
an automatic generator. 

The first step be to build an abstract structure for the matrices. 
This be do by randomly sample from the follow 
primitive sets: 

• relation type (R, with element r): progression, 
XOR, OR, AND, consistent union1 

• object type (O, with element o): shape, line 
• attribute type (A, with element a): size, type, 
colour, position, number 

The structure S of a PGM be a set of triples, S = {[r, o, a] : 
r ∈ R, o ∈ O, a ∈ A}. These triple determine the chal- 
lenge pose by a particular matrix. For instance, if S con- 
tains the triple [progression, shape, colour], 
the PGM will exhibit a progression relation, instantiate 
on the colour (greyscale intensity) of shapes. Challenging 
PGMs exhibit relation govern by multiple such triples: 
we permit up to four relation per matrix (1 ≤ |S| ≤ 4). 

Each attribute type a ∈ A (e.g. colour) can take one 
of a finite number of discrete value v ∈ V (e.g. 10 inte- 
gers between [0, 255] denote greyscale intensity). So a 
give structure have multiple realisation depend on the 
randomly chosen value for the attribute types, but all of 
these realisation share the same underlie abstract chal- 
lenge. The choice of r constrains the value of v that can be 
realized. For instance, if r be progression, the value 
of v must strictly increase along row or column in the 
matrix, but can vary randomly within this constraint. See 
the appendix for the full list of relations, attribute types, 
values, their hierarchical organisation, and other statistic 
of the dataset. 

We use Sa to denote the set of attribute among the triple 
in S . After set value for the colour attribute, we then 
choose value for all other attribute a 6∈ Sa in one of two 
ways. In the distract setting, we allow these value to 
vary at random provide that they do not induce any further 
meaningful relations. Otherwise, the a 6∈ Sa take a single 
value that remains consistent across the matrix (for example, 
perhaps all the shape be the exact same size). Randomly 
vary value across the matrix be a type of distraction 
common to Raven’s more difficult Progressive Matrices. 

Thus, the generation process consists of: (1) Sampling 1- 
4 triples, (2) Sampling value v ∈ V for each a ∈ Sa, 
adhere to the associate relation r, (3) Sampling value 
v ∈ V for each a 6∈ Sa, ensure no spurious relation be 
induced, (4) Rendering the symbolic form into pixels. 

1Consistent union be a relation wherein the three panel contain 
element from some common set, e.g., shape type {square, circle, 
triangle }. The order of the panel contain the element do 
not matter. 

2.2. Generalisation Regimes 

Generalisation in neural network have be subject of lot of 
recent debate, with some emphasise the success (LeCun 
et al., 2015) and others the failure (Garnelo et al., 2016; 
Lake & Baroni, 2017; Marcus, 2018). Our choice of regime 
be inform by this, but be in no way exhaustive. 

(1) Neutral In both training and test sets, the structure 
S can contain any triple [r, o, a] for r ∈ R, o ∈ O and 
a ∈ A. The training and test set be disjoint, but this 
separation be at the level of the input variable (i.e., the 
pixel manifestation of the matrices). 

(2) Interpolation; (3) Extrapolation As in the neutral 
split, S consist of any triple [r, o, a]. For interpolation, 
in the training set, when a = colour or a = size (the 
order attributes), the value of a be restrict to even- 
indexed member of the discrete set Va, whereas in the test 
set only odd-indexed value be permitted. For extrapo- 
lation, the value of a be restrict to the low half of 
their discrete set of value Va during training, whereas in 
the test set they take value in the upper half. Note that all 
S contain some triple [r, o, a] with a = colour or a = 
size. Thus, generalisation be require for every question 
in the test set. 

(4) Held-out Attribute shape-colour or (5) 
line-type S in the training set contain no 
triple with o = shape and a = colour. All structure 
govern puzzle in the test set contain at least one triple 
with o = shape and a = colour. For comparison, we 
include a similar split in which triple be held-out if 
o = line and a = type. 

6: Held-out Triples In our dataset, there be 29 possible 
unique triple [r, o, a]. We allocate seven of these for the 
test set, at random, but such that each of the a ∈ A be 
represent exactly once in this set. These held-out triple 
never occur in question in the training set, and every S 
in the test set contain at least one of them. 

7: Held-out Pairs of Triples All S contain at least two 
triples, of which 400 be viable2 ([r1, o1, a1], [r2, o2, a2]) = 
(t1, t2). We randomly allocate 360 to the training set and 
40 to the test set. Members (t1, t2) of the 40 held-out pair 
do not occur together in structure S in the training set, 
and all structure S have at least one such pair (t1, t2) a a 
subset. 

2Certain triples, such a [progression, shape, 
number] and [progression, shape, XOR] cannot 
occur together in the same PGM 



Measuring abstract reason in neural network 

8: Held-out Attribute Pairs S contain at least two 
triples. There be 20 (unordered) viable pair of attribute 
(a1, a2) such that for some ri, oi, ([r1, o1, a1], [r2, o2, a2]) 
be a viable triple pair. ([r1, o1, a1], [r2, o2, a2]) = (t1, t2). 
We allocate 16 of these pair for training and four for 
testing. For a pair (a1, a2) in the test set, S in the training 
set contain triple with a1 and a2. In the test set, all S 
contain triple with a1 and a2. 

3. Models and Experimental Setup 
We first compare the performance of several standard deep 
neural network on the neutral split of the PGM dataset. 
We also developed a novel architecture base on Relation 
Networks (Santoro et al., 2017), that we call the Wild Rela- 
tion Network (WReN), name in recognition of Mary Wild 
who contribute to the development of Raven’s progressive 
matrix along with her husband John Raven. 

The input consist of the eight context panel and eight 
multiple-choice panels. Each panel be an 80 × 80 pixel 
image; so, the panel be present a a set of 16 feature 
maps. 

Models be train to produce the label of the correct 
miss panel a an output answer by optimise a softmax 
cross entropy loss. We train all network by stochastic 
gradient descent use the ADAM optimiser (Kingma & Ba, 
2014). For each model, hyper-parameters be chosen use 
a grid sweep to select the model with small loss estimate 
on a held-out validation set. We use the validation loss 
for early-stopping and we report performance value on a 
held-out test set. For hyper-parameter setting and further 
detail on all model see appendix A. 

CNN-MLP: We implement a standard four layer convo- 
lutional neural network with batch normalization and ReLU 
non-linearities (LeCun et al., 2015). The set of PGM input 
panel be treat a a set of separate greyscale input fea- 
ture map for the CNN. The convolve output be pass 
through a two-layer, fully connect MLP use a ReLU 
non-linearity between linear layer and dropout of 0.5 on the 
penultimate layer. Note that this be the type of model apply 
to Raven-style sequential reason question by Hoshen & 
Werman (2017). 

ResNet: We use a standard implementation of the 
ResNet-50 architecture a described in He et al. (2016). 
As before, each of the context panel and multiple-choice 
panel be treat a an input feature map. We also train a 
selection of ResNet variants, include ResNet-101, ResNet- 
152, and several custom-built small ResNets. The best 
perform model be ResNet-50. 

LSTM: We implement a standard LSTM module 
(Hochreiter & Schmidhuber, 1997), base on Zaremba et al. 
(2014). Since LSTMs be design to process input sequen- 
tially, we first pass each panel (context panel and multi- 
ple choice panels) sequentially and independently through 
a small 4-layer CNN, tag the CNN’s output with a one- 
hot label indicate the panel’s position (the top left PGM 
panel be tag with label 1, the top-middle PGM panel be 
tag with label 2 etc.), and pass the result sequence 
of label embeddings to the LSTM. The final hidden state 
of the LSTM be pass through a linear layer to produce 
logits for the softmax cross entropy loss. The network be 
train use batch normalization after each convolutional 
layer and drop-out be apply to the LSTM hidden state. 

Wild Relation Network (WReN): Our novel WReN 
model (fig. 3) apply a Relation Network module (San- 
toro et al., 2017) multiple time to infer the inter-panel 
relationships. 

The model output a 1-d score sk for a give candidate 
multiple-choice panel, with label k ∈ [1, 8]. The choice 
with the high score be select a the answer a use a 
softmax function σ across all scores: a = σ([s1, . . . , s8]). 
The score of a give multiple-choice panel be evaluate 
use a Relation Network (RN): 

sk = RN(Xk) 

= fφ 

( ∑ 
y,z∈Xk 

gθ(y, z) 
) 
, (1) 

where Xk = {x1, x2, ..., x8} 
⋃ 
{ck}, ck be the vector repre- 

sentation of the multiple choice panel k, and xi the repre- 
sentation of context panel i. The input vector representa- 
tions be produce by processing each panel independently 
through a small CNN and tag it with a panel label, sim- 
ilar to the LSTM processing described above, follow by a 
linear projection. The function fφ and gθ be MLPs. 

The structure of the WReN model be well match to the 
problem of abstract reasoning, because it form representa- 
tions of pair-wise relation (using gθ), in this case, between 
each context panel and a give multiple choice candidate, 
and between context panel themselves. The function fφ 
integrates information about context-context relation and 
context-multiple-choice relation to provide a score. Also 
the WReN model calculates a score for each multiple-choice 
candidate independently, allow the network to exploit 
weight-sharing across multiple-choice candidates. 

Wild-ResNet: We also implement a novel variant of the 
ResNet architecture in which one multiple-choice candidate 
panel, along with the eight context panel be provide a 
input, instead of provide all eight multiple-choices and 
eight context panel a input a in the standard ResNet. In 



Measuring abstract reason in neural network 

Co 
nte 

xt 
Pa 

ne 
l 

Choice Panel B 

Score-B 

... + 

Co 
nte 

xt 
Pa 

ne 
l 

Choice Panel A 

CNN 

RN 

Score-A 

Panel Embeddings 

... 

Panel 
Embedding 

Pairs 

+ 

softmax Answer: A 

meta-target 
prediction 

.64 

.22 

+ sigmoid 

Figure 3. WReN model A CNN process each context panel and an individual answer choice panel independently to produce 9 vector 
embeddings. This set of embeddings be then pass to an RN, whose output be a single sigmoid unit encode the “score” for the associate 
answer choice panel. 8 such pass be make through this network (here we only depict 2 for clarity), one for each answer choice, and the 
score be put through a softmax function to determine the model’s predict answer. 

this way, the Wild-ResNet be design to provide a score for 
each candidate panel, independent of the other candidates. 
The candidate with the high score be the output answer. 
This be similar to the WReN model described above, but 
use a ResNet instead of a Relation Network for compute 
a candidate score. 

Context-blind ResNet: A fully-blind model should be at 
chance performance level, which for the PGM task be 12.5%. 
However, sufficiently strong model can learn to exploit 
statistical regularity in multiple-choice problem use 
the choice input alone, without consider the context 
(Johnson et al., 2017). To understand the extent to which 
this be possible, we train a ResNet-50 model with only 
the eight multiple-choice panel a input. 

3.1. Training on auxiliary information 

We explore auxiliary training a a mean to improve 
generalisation performance. We hypothesize that a model 
train to predict the relevant relation, object and attribute 
type involve in each PGM might develop representation 
that be more amenable to generalisation. To test this, we 
construct “meta-targets” encode the relation, object 
and attribute type present in PGMs a a binary string. 
The string be of length 12, with element follow 
the syntax: (shape, line, color, number, 
position, size, type, progression, XOR, 
OR, AND, consistent union). We encode each 
triple in this binary form, then perform an OR operation 
across all binary-encoded triple to produce the meta- 
target. That is, OR([101000010000], [100100010000]) = 
[101100010000]. The model then predict these label 

use a sigmoid unit for each element, train with cross 
entropy. A scale factor β determine the influence 
of this loss relative to the loss compute for the answer 
panel targets: Ltotal = Ltarget + βLmeta-target. We set β to 
a non-zero value when we wish to explore the impact of 
auxiliary meta-target training. 

4. Experiments 
4.1. Comparing model on PGM question 

We first compare all model on the Neutral train/test split, 
which corresponds most closely to traditional supervise 
learn regimes. Perhaps surprisingly give their effec- 
tiveness a powerful image processors, CNN model fail 
almost completely at PGM reason problem (Table 1), 
achieve performance marginally good than our baseline - 
the context-blind ResNet model which be blind to the con- 
text and train on only the eight candidate answers. The 
ability of the LSTM to consider individual candidate panel 
in sequence yield a small improvement relative to the 
CNN. The best perform ResNet variant be ResNet-50, 
which outperform the LSTM. ResNet-50 have significantly 
more convolutional layer than our simple CNN model, and 
hence have a great capacity for reason about it input 
features. 

The best perform model be the WReN model. This 
strong performance may be partly due to the Relation Net- 
work module, which be be design explicitly for rea- 
soning about the relation between objects, and partly due 
to the score structure. Note that the score structure 
be not sufficient to explain the improve performance a 



Measuring abstract reason in neural network 

(a) (b) 

Figure 4. The effect of distraction. In both PGMs, the un- 
derlying structure S be [[shape, colour, consistent 
union]], but (b) include distraction on shape-number, 
shape-type, line-color, and line-type. 

the WReN model substantially outperform the best Wild- 
ResNet model, which also have a score structure. 

4.2. Performance on different question type 

Questions involve a single [r, o, a] triple be easy 
than those involve multiple triples. Interestingly, PGMs 
with three triple prove more difficult than those with 
four. Although the problem be apparently more complex 
with four triples, there be also more available evidence for 
any solution. Among PGMs involve a single triple, OR 
(64.7%) prove to be an easy relation than XOR (53.2%). 
PGMs with structure involve line (78.3%) be easy 
than those involve shape (46.2%) and those involve 
shape-number be much easy (80.1%) than those 
involve shape-size (26.4%).This suggests that the 
model struggle to discern fine-grained difference in size 
compare to more salient change such a the absence or 
presence of lines, or the quantity of shapes. For more detail 
of performance by question type, see Appendix Tables 7, 8. 

4.3. Effect of distractors 

The result report thus far be on question that include 
distractor attribute value (see Fig. 4). The WReN model 
perform notably good when these distractors be re- 
move (79.3% on the validation and 78.3% on the test set, 
compare with 63.0% and 62.6% with distractors). 

4.4. Generalisation 

We compare the best perform WReN model on each of 
the generalisation regime (Table 1), and observe notable 
difference in the ability of the model to generalise. Interpo- 

lation be the least problematic regime (generalisation error 
14.6%). Note that performance on both the Interpolation 
and Extrapolation training set be high than on the neu- 
tral training set because certain attribute (size, colour) 
have half a many value in those cases, which reduces the 
complexity of the task.3 

After Interpolation, the model generalise best in regime 
where the test question involve novel combination of oth- 
erwise familiar [r, o, a] triple (Held-out Attribute Pairs and 
Held-out Triple Pairs). This indicates that the model learn 
to combine relation and attributes, and do not simply mem- 
orize combination of triple a distinct structure in their 
own right. However, bad generalisation in the case of 
Held-out Triples suggests that the model be less able to in- 
duce the meaning of unfamiliar triple from it knowledge of 
their constituent components. Moreover, it could not under- 
stand relation instantiate on entirely novel attribute (Held- 
out line-type , Held-out shape-colour). The bad 
generalisation be observe on the Extrapolation regime. 
Given that these question have the same abstract semantic 
structure a interpolation questions, the failure to generalise 
may stem from the model’s failure to perceive input outside 
of the range of it prior experience. 

4.5. Effect of auxiliary training 

We then explore the impact of auxiliary training on ab- 
stract reason and generalisation by training our model 
with symbolic meta target a described in Section 3.1. In 
the neutral regime, we found that auxiliary training lead to 
a 13.9% improvement in test accuracy. Critically, this im- 
provement in the overall ability of the model to capture 
the data also apply to other generalisation regimes. The 
difference be clearest in the case where the model be 
require to recombine familiar triple into novel combina- 
tions: (56.3% accuracy on Held-out triple pairs, up from 
41.9%, and 51.7% accuracy on Held-out attribute pairs, up 
from 27.2%). Thus, the pressure to represent abstract se- 
mantic principle such that they can be decode simply into 
discrete symbolic explanation seem to improve the ability 
of the model to productively compose it knowledge. This 
find aligns with previous observation about the benefit 
of discrete channel for knowledge representation (Andreas 
et al., 2016) and the benefit of induce explanation or 
rationale (Ling et al., 2017). 

4.6. Analysis of auxiliary training 

In addition to improve performance, training with meta- 
target provide a mean to measure which shapes, attributes, 

3Since test question focus on held-out phenomena, test set in 
different regime may have differ underlie complexity. Ab- 
solute performance cannot therefore be compare across different 
regimes. 



Measuring abstract reason in neural network 

β = 0 β = 10 

Model Test (%) Regime Val. (%) Test (%) Diff. Val. (%) Test (%) Diff. 
WReN 62.6 Neutral 63.0 62.6 -0.6 77.2 76.9 -0.3 

Wild-ResNet 48.0 Interpolation 79.0 64.4 -14.6 92.3 67.4 -24.9 
ResNet-50 42.0 H.O. Attribute Pairs 46.7 27.2 -19.5 73.4 51.7 -21.7 

LSTM 35.8 H.O. Triple Pairs 63.9 41.9 -22.0 74.5 56.3 -18.2 
CNN + MLP 33.0 H.O. Triples 63.4 19.0 -44.4 80.0 20.1 -59.9 
Blind ResNet 22.4 H.O. line-type 59.5 14.4 -45.1 78.1 16.4 -61.7 

H.O. shape-colour 59.1 12.5 -46.6 85.2 13.0 -72.2 
Extrapolation 69.3 17.2 -52.1 93.6 15.5 -78.1 

Table 1. Performance of all model on the neutral split (left), and generalisation performance of the WReN model (right) with generalisation 
regime order accord to generalisation error for β = 0. Context-blind ResNet generalisation test performance for all regime be 
give in Table 9 of the Appendix. (Diff: difference between test and validation performance, H.O:“Held-out”) 

and relation the model believe be present in a give PGM, 
provide insight into the model’s decisions. Using these 
predictions, we ask how the WReN model’s accuracy var- 
ied a a function of it meta-target predictions. Unsurpris- 
ingly, the WReN model achieve a test accuracy of 87.4% 
when it meta-target prediction be correct, compare to 
only 34.8% when it prediction be incorrect. 

The meta-target prediction can be broken down into pre- 
diction of object, attribute, and relation types. We lever- 
age these fine-grained prediction to ask how the WReN 
model’s accuracy varied a a function of it prediction on 
each of these property independently. The model accu- 
racy increase somewhat when the shape meta-target pre- 
diction be correct (78.2%) compare to be incorrect 
(62.2%), and when attribute meta-target prediction be cor- 
rect (79.5%) compare to be incorrect (49.0%). How- 
ever, for the relation property, the difference between a 
correct and incorrect meta-target prediction be substantial 
(86.8% vs. 32.1%). This result suggests that predict the 
relation property correctly be most critical to task success. 

The model’s prediction certainty, define a the mean ab- 
solute difference of the meta-target prediction from 0.5, 
be predictive of the model’s performance, suggest that 
the meta-target prediction certainty be an accurate measure 
of the model’s confidence in an answer choice (Figure 5; 
qualitatively similar for sub-targets; Appendix Figures 6-8). 

5. Related work 
Various computational model for solve RPMs have be 
propose in the cognitive science literature (see (Lovett & 
Forbus, 2017) for a thorough review). The emphasis in these 
study be on understand the operation and comparison 
commonly apply by humans. They typically factor out 
raw perception in favour of symbolic inputs, and hard-code 
strategy described by cognitive theories. In contrast, we 

Figure 5. Relationship between answer accuracy and meta- 
target prediction certainty for the WReN model (β = 10). The 
WReN model be more accurate when it be more confident about 
it meta-target predictions. Certainty be define a the mean 
absolute difference of the meta-target prediction from 0.5. 

consider model that process input from raw pixel and 
study how they infer, from knowledge of the correct answer, 
the process and representation necessary to resolve the 
task. Much a we do, Hoshen & Werman (2017) train 
neural network to complete the row or column of Raven- 
style matrix from raw pixels. They found that a CNN- 
base model induced visual relation such a rotation or 
reflection, but they do not address the problem of resolve 
complete RPMs. Our experiment show that such model 
perform poorly on full RPM questions. Moreover, Hoshen 
& Werman (2017) do not study generalisation to question 
that differ substantively from their training data. Wang & Su 
(2015) present a method for automatically generate Raven- 
style matrix and verify their generator on humans, but do 
not attempt any modelling. Our method for automatically 
generate RPM-style question borrow extensively from 
the insight in that work. 

There be prior work emphasise both the advantage (Clark 
& Etzioni, 2016) and limitation (Davis, 2014) of apply- 



Measuring abstract reason in neural network 

ing standardize test in AI (see Marcus et al. (2016) and 
contribute article for a review). Approaches base on stan- 
dardized test generally focus on measure the general 
knowledge of systems, while we focus on models’ ability 
to generalize learn information. 

6. Discussion 
One of the long-standing goal of artificial intelligence be to 
develop machine with abstract reason capability that 
equal or good those of humans. Though there have also be 
substantial progress in both reason and abstract represen- 
tation learn in neural net (Botvinick et al., 2017; LeCun 
et al., 2015; Higgins et al., 2016; 2017), the extent to which 
these model exhibit anything like general abstract reason- 
ing be the subject of much debate (Garnelo et al., 2016; Lake 
& Baroni, 2017; Marcus, 2018). The research present 
here be therefore motivate by two main goals. (1) To 
understand whether, and (2) to understand how, deep neural 
network might be able to solve abstract visual reason 
problems. 

Our answer to (1) be that, with important caveats, neural 
network can indeed learn to infer and apply abstract reason- 
ing principles. Our best perform model learn to solve 
complex visual reason questions, and to do so, it need 
to induce and detect from raw pixel input the presence of 
abstract notion such a logical operation and arithmetic 
progressions, and apply these principle to never-before 
observe stimuli. Importantly, we found that the architec- 
ture of the model make a critical difference to it ability to 
learn and execute such processes. While standard visual- 
processing model such a CNNs and ResNets perform 
poorly, a model that promote the representation of, and 
comparison between part of the stimulus perform very 
well. We found way to improve this performance via addi- 
tional supervision: the training outcome and the model’s 
ability to generalise be improve if it be require to 
decode it representation into symbol correspond to 
the reason behind the correct answer. 

When consider (2), it be important to note that our model 
be solve a very different problem from that solve by 
human subject take Raven-style IQ tests. The model’s 
world be highly constrained, and it experience consist 
of a small number of possible relation instantiate in finite 
set of attribute and value across hundred of thousand 
of examples. It be highly unlikely that the model’s solution 
match those apply by successful humans. This difference 
becomes clear when we study the ability of the model to 
generalise. Unlike humans, who must transfer knowledge 
distil from their experience in everyday life to the un- 
familiar set of visual reason problems, our model 
exhibit transfer across question set with a high degree 
of perceptual and structural uniformity. When require to 

interpolate between know attribute values, and also when 
apply know abstract content in unfamiliar combina- 
tions, the model generalise notably well. Even within 
this constrain domain, however, they perform strikingly 
poorly when require to extrapolate to input beyond their 
experience, or to deal with entirely unfamiliar attributes. 

In this latter behaviour, the model differs in a crucial way 
from humans; a human that could apply a relation such a 
XOR to the colour of line would almost certainly have no 
trouble apply it to the colour of shapes. On the other 
hand, even the human ability to extend apparently well- 
define principle to novel object have limits; this be pre- 
cisely why RPMs be such an effective discriminator of 
human IQ. For instance, a human subject might be uncertain 
what it mean to apply XOR to the size or shape of set of 
objects, even if he or she have learn to do so perfectly in 
the case of colors. 

An important contribution of this work be the introduction 
of the PGM dataset, a a tool for study both abstract 
reason and generalisation in models. Generalisation be 
a multi-faceted phenomenon; there be no single, objective 
way in which model can or should generalise beyond their 
experience. The PGM dataset provide a mean to measure 
the generalization ability of model in different ways, each 
of which may be more or less interest to researcher 
depend on their intend training setup and applications. 

Designing and instantiate meaningful train/test distinc- 
tions to study generalisation in the PGM dataset be simpli- 
fied by the objective semantics of the underlie generative 
model. Similar principle could be apply to more natural- 
istic data, particularly with crowdsourced human input. For 
instance, image processing model could be train to iden- 
tify black horse and test on whether they can detect white 
horses, or train to detect fly seagulls, fly sparrow 
and nest seagulls, and test on the detection of nest 
sparrows. This approach be take for one particular gener- 
alisation regime by Ramakrishnan et al. (2017), who test 
VQA model on image contain object that be not 
observe in the training data. The PGM dataset extends and 
formalises this approach, with regime that focus not only 
on how model could respond to novel factor or class in 
the data, but also novel combination of know factor etc. 

In the next stage of this research, we will explore strategy 
for improve generalisation, such a meta-learning, and 
will further explore the use of richly structured, yet gener- 
ally applicable, inductive biases. We also hope to develop a 
deeper understand of the solution learn by the WReN 
model when solve Raven-style matrices. Finally, we wish 
to end by invite our colleague across the machine learn- 
ing community to participate in our new abstract reason 
challenge. 



Measuring abstract reason in neural network 

ACKNOWLEDGMENTS 

We would like to thank David Raposo, Daniel Zoran, Murray 
Shanahan, Sergio Gomez, Yee Whye Teh and Daan Wierstra 
for helpful discussion and all the DeepMind team for their 
support. 

References 
Andreas, J., Klein, D., and Levine, S. Modular multitask re- 

inforcement learn with policy sketches. arXiv preprint 
arXiv:1611.01796, 2016. 

Botvinick, M., Barrett, D., Battaglia, P., de Freitas, N., 
Kumaran, D., Leibo, J., Lillicrap, T., Modayil, J., Mo- 
hamed, S., Rabinowitz, N., et al. Building machine that 
learn and think for themselves: Commentary on lake et 
al., behavioral and brain sciences, 2017. arXiv preprint 
arXiv:1711.08378, 2017. 

Carpenter, P. A., Just, M. A., and Shell, P. What one intelli- 
gence test measures: a theoretical account of the process- 
ing in the raven progressive matrix test. Psychological 
review, 97(3):404, 1990. 

Clark, P. and Etzioni, O. My computer be an honor student- 
but how intelligent be it? standardize test a a measure 
of ai. AI Magazine, 37(1):5–12, 2016. 

Davis, E. The limitation of standardize science test a 
benchmark for artificial intelligence research: Position 
paper. arXiv preprint arXiv:1411.1629, 2014. 

Fleuret, F., Li, T., Dubout, C., Wampler, E. K., Yantis, S., 
and Geman, D. Comparing machine and human on a 
visual categorization test. Proceedings of the National 
Academy of Sciences, 108(43):17621–17625, 2011. 

Flynn, J. R. Massive iq gain in 14 nations: What iq test 
really measure. Psychological bulletin, 101(2):171, 1987. 

Garnelo, M., Arulkumaran, K., and Shanahan, M. Towards 
deep symbolic reinforcement learning. arXiv preprint 
arXiv:1609.05518, 2016. 

He, K., Zhang, X., Ren, S., and Sun, J. Deep residual learn- 
ing for image recognition. In Proceedings of the IEEE 
conference on computer vision and pattern recognition, 
pp. 770–778, 2016. 

Higgins, I., Matthey, L., Pal, A., Burgess, C., Glorot, X., 
Botvinick, M., Mohamed, S., and Lerchner, A. beta- 
vae: Learning basic visual concept with a constrain 
variational framework. 2016. 

Higgins, I., Sonnerat, N., Matthey, L., Pal, A., Burgess, 
C. P., Botvinick, M., Hassabis, D., and Lerchner, A. Scan: 
learn abstract hierarchical compositional visual con- 
cepts. arXiv preprint arXiv:1707.03389, 2017. 

Hochreiter, S. and Schmidhuber, J. Long short-term memory. 
Neural Comput., 9(8):1735–1780, November 1997. ISSN 
0899-7667. doi: 10.1162/neco.1997.9.8.1735. 

Hoshen, D. and Werman, M. Iq of neural networks. arXiv 
preprint arXiv:1710.01692, 2017. 

Jaeggi, S. M., Buschkuehl, M., Jonides, J., and Perrig, W. J. 
Improving fluid intelligence with training on work 
memory. Proceedings of the National Academy of Sci- 
ences, 105(19):6829–6833, 2008. 

Jo, J. and Bengio, Y. Measuring the tendency of cnns 
to learn surface statistical regularities. arXiv preprint 
arXiv:1711.11561, 2017. 

Johnson, J., Hariharan, B., van der Maaten, L., Fei-Fei, L., 
Zitnick, C. L., and Girshick, R. Clevr: A diagnostic 
dataset for compositional language and elementary visual 
reasoning. In Computer Vision and Pattern Recogni- 
tion (CVPR), 2017 IEEE Conference on, pp. 1988–1997. 
IEEE, 2017. 

Kingma, D. P. and Ba, J. Adam: A method for stochastic 
optimization. arXiv preprint arXiv:1412.6980, 2014. 

Lake, B. M. and Baroni, M. Still not systematic af- 
ter all these years: On the compositional skill of 
sequence-to-sequence recurrent networks. arXiv preprint 
arXiv:1711.00350, 2017. 

LeCun, Y., Bengio, Y., and Hinton, G. Deep learning. nature, 
521(7553):436, 2015. 

Ling, W., Yogatama, D., Dyer, C., and Blunsom, P. Pro- 
gram induction by rationale generation: Learning to solve 
and explain algebraic word problems. arXiv preprint 
arXiv:1705.04146, 2017. 

Lovett, A. and Forbus, K. Modeling visual problem solve 
a analogical reasoning. Psychological review, 124(1):60, 
2017. 

Marcus, G. Deep learning: A critical appraisal. arXiv 
preprint arXiv:1801.00631, 2018. 

Marcus, G., Rossi, F., and Veloso, M. Beyond the turing 
test. Ai Magazine, 37(1):3–4, 2016. 

Ramakrishnan, S. K., Pal, A., Sharma, G., and Mittal, A. 
An empirical evaluation of visual question answer for 
novel objects. arXiv preprint arXiv:1704.02516, 2017. 

Raposo, D., Santoro, A., Barrett, D., Pascanu, R., Lilli- 
crap, T., and Battaglia, P. Discovering object and their 
relation from entangle scene representations. 2017. 

Raven, J. C. et al. Raven’s progressive matrices. Western 
Psychological Services, 1938. 



Measuring abstract reason in neural network 

Santoro, A., Raposo, D., Barrett, D. G., Malinowski, M., 
Pascanu, R., Battaglia, P., and Lillicrap, T. A simple neu- 
ral network module for relational reasoning. In Advances 
in neural information processing systems, pp. 4974–4983, 
2017. 

Snow, R. E., Kyllonen, P. C., and Marshalek, B. The topog- 
raphy of ability and learn correlations. Advances in 
the psychology of human intelligence, 2(S 47):103, 1984. 

Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, 
D., Goodfellow, I., and Fergus, R. Intriguing property of 
neural networks. arXiv preprint arXiv:1312.6199, 2013. 

Te Nijenhuis, J., Voskuijl, O. F., and Schijve, N. B. Practice 
and coach on iq tests: Quite a lot of g. International 
Journal of Selection and Assessment, 9(4):302–308, 2001. 

Wang, K. and Su, Z. Automatic generation of raven pro- 
gressive matrices. In Twenty-Fourth International Joint 
Conference on Artificial Intelligence, 2015. 

Zaremba, W., Sutskever, I., and Vinyals, O. Recurrent neural 
network regularization. arXiv preprint arXiv:1409.2329, 
2014. 

Zhang, C., Bengio, S., Hardt, M., Recht, B., and Vinyals, O. 
Understanding deep learn require rethink general- 
ization. arXiv preprint arXiv:1611.03530, 2016. 



Measuring abstract reason in neural network 

A. Appendix 
A.1. PGM Dataset 

Altogether there be 1.2M training set questions, 20K vali- 
dation set questions, and 200K test set questions. 

When create the matrix we aim to use the full Carte- 
sian productR×A for construction structure S . However, 
some relation-attribute combination be problematic, such 
a a progression on line type, and some attribute interact in 
interest way (such a number and position, which be 
in some sense tied), restrict the type of relation we can 
apply to these attributes. The final list of relevant relation 
per attribute type, broken down by object type (shape vs. 
line) is: 

shape: 
size: progression, XOR, OR, AND, consistent union 
color: progression, XOR, OR, AND, consistent union 
number: progression, consistent union 
position: XOR, OR, AND 
type: progression, XOR, OR, AND, consistent union 

line: 
color: progression, XOR, OR, AND, consistent union 
type: XOR, OR, AND, consistent union 

Since the number and position attribute type be tie (for 
example, have an arithmetic progression on number whilst 
have an XOR relation on position be not possible), we for- 
bid number and position from co-occurring in the same ma- 
trix. Otherwise, all other ((r, o, a), (r, o, a)) combination 
occur unless specifically control for in the generalisa- 
tion regime. 

We create a similar list for possible value for a give 
attribute: 

shape: 
color: 10 evenly space greyscale intensity in [0, 1] 
size: 10 scale factor evenly space in [0, 1] 4 
number: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 
position ((x, y) coordinate in a (0, 1) plot): 

(0.25, 0.75), 
(0.75, 0.75), 
(0.75, 0.25), 
(0.25, 0.25), 
(0.5, 0.5), 
(0.5, 0.25), 
(0.5, 0.75), 
(0.25, 0.5), 
(0.75, 0.5) 

type: circle, triangle, square, pentagon, hexagon, 
4The actual specific value use for size be number particular 

to the matplotlib implementation of the plots, and hence depend 
on the scale of the plot and axes, etc. 

octagon, star 

line: 
color: 10 evenly space greyscale intensity in [0, 1] 
type: diagonal down, diagonal up, vertical, horizontal, 

diamond, circle 

A.2. Examples of Raven-style PGMs 

Given the radically different way in which visual reason 
test be apply to human (no prior experience) and to our 
model (controlled training and test splits), we believe it 
would be mislead to provide a human baseline for our 
results. However, for a sense of the difficulty of the task, 
we present here a set of 18 question generate from the 
neutral splits. Note that the value be filter for human 
readability. In the dataset there be 10 greyscale intensity 
value for shape and line colour and 10 size for each shape. 
In the following, we restrict to 4 clearly-distinct value for 
each of these attributes. Best view on a digital monitor, 
zoom in (see next page). Informal human test reveal 
wide variability: participant with a lot of experience with 
the test could score well (> 80%), while others who come 
to the test blind would often fail to answer all the questions. 



Measuring abstract reason in neural network 

A B C D 

E F G H 

A B C D 

E F G H 

A B C D 

E F G H 

(1) (2) (3) 

A B C D 

E F G H 

A B C D 

E F G H 

A B C D 

E F G H 

(4) (5) (6) 

A B C D 

E F G H 

A B C D 

E F G H 

A B C D 

E F G H 

(7) (8) (9) 



Measuring abstract reason in neural network 

A B C D 

E F G H 

A B C D 

E F G H 

A B C D 

E F G H 

(10) (11) (12) 

A B C D 

E F G H 

A B C D 

E F G H 

A B C D 

E F G H 

(13) (14) (15) 

A B C D 

E F G H 

A B C D 

E F G H 

(16) (17) (18) 

A B C D 

E F G H 



Measuring abstract reason in neural network 

B. Model detail 
Here we provide additional detail for all our models, includ- 
ing the exact hyper-parameter setting that we considered. 
Throughout this section, we will use the notation [x, y, z, w] 
to describe CNN and MLP size. For a CNN, this notation 
refers to the number of kernel per layer: x kernel in the 
first layer, y kernel in the second layer, z kernel in the 
third layer and w kernel in the fourth layer. For the MLP, it 
refers to the number of unit per layer: x unit in the first 
layer, y unit in the second layer, z unit in the third layer 
and w unit in the fourth layer. 

All model be train use the Adam optimiser, with 
expoential decay rate parameter β1 = 0.9, β2 = 0.999, � = 
10−8. We also use a distribute training setup, use 4 
GPU-workers per model. 

hyper-parameters 
CNN kernel [64, 64, 64, 64] 

CNN kernel size 3× 3 
CNN kernel stride 2 

MLP hidden-layer size 1500 
MLP drop-out fraction 0.5 

Batch Size 16 
Learning rate 0.0003 

Table 2. CNN-MLP hyper-parameters 

hyper-parameters 
Batch Size 32 

Learning rate 0.0003 

Table 3. ResNet-50 and context-blind ResNet hyper-parameters 

hyper-parameters 
CNN kernel [8, 8, 8, 8] 

CNN kernel size 3× 3 
CNN kernel stride 2 

LSTM hidden layer size 96 
Drop-out fraction 0.5 

Batch Size 16 
Learning rate 0.0001 

Table 4. LSTM hyper-parameters 

hyper-parameters 
CNN kernel [32, 32, 32, 32] 

CNN kernel size 3× 3 
CNN kernel stride 2 

RN embed size 256 
RN gθ MLP [512, 512, 512, 512] 
RN fφ MLP [256, 256, 13] 

Drop-out fraction 0.5 
Batch Size 32 

Learning rate 0.0001 

Table 5. WReN hyper-parameters 

hyper-parameters 
Batch Size 16 

Learning rate 0.0003 

Table 6. Wild-ResNet hyper-parameters 



Measuring abstract reason in neural network 

C. Results 

# Relations WReN (%) Blind (%) 
One 68.5 23.6 
Two 51.1 21.2 

Three 44.5 22.1 
Four 48.4 23.5 
All 62.6 22.8 

Table 7. WReN test performance and Context-Blind ResNet per- 
formance after training on the neutral PGM dataset, broken down 
accord to the number of relation per matrix. 

WReN (%) Blind (%) 
OR 64.7 30.1 

AND 63.2 17.2 
consistent union 60.1 28.0 

progression 55.4 15.7 
XOR 53.2 20.2 

number 80.1 18.1 
position 77.3 27.5 

type 61.0 28.1 
color 58.9 18.7 
size 26.4 16.3 
line 78.3 27.5 

shape 46.2 18.6 
All Single Relations 68.5 23.6 

Table 8. WReN test performance and Context-Blind ResNet per- 
formance for single-relation PGM question after training on the 
neutral PGM dataset, broken down accord to the relation type, 
attribute type and object type in a give matrix. 

Figure 6. Relationship between answer accuracy and shape 
meta-target prediction certainty. The WReN model (β = 10) 
be more accurate when confident about it meta-target predictions. 
Certainty be define a the mean absolute difference of the pre- 
diction from 0.5. 

Figure 7. Relationship between answer accuracy and attribute 
meta-target prediction certainty 

Figure 8. Relationship between answer accuracy and relation 
meta-target prediction certainty 



Measuring abstract reason in neural network 

Test (%) 

Regime β = 0 β = 10 
Neutral 22.4 13.5 

Interpolation 18.4 12.2 
H.O. Attribute Pairs 12.7 12.3 

H.O. Triple Pairs 15.0 12.6 
H.O. Triples 11.6 12.4 

H.O. line-type 14.4 12.6 
H.O. shape-colour 12.5 12.3 

Extrapolation 14.1 13.0 

Table 9. Performance of the Context-blind Resnet model for all 
the generalization regimes, in the case where there be an additional 
auxiliary meta-target (β = 10) and in the case where there be no 
auxiliary meta-target (β = 0). Note that most of these value be 
either close to chance or slightly above chance, indicate that 
this baseline model struggle to learn solution that generalise 
good than a random guess solution. For several generalisation 
regime such a Interplolation, H.O Attribute Pairs, H.O. Triples 
and H.O Triple Pairs the generalisation performance of the WReN 
model report in Table 1 be far great than the generalisation per- 
formance of our context-blind baseline, indicate that the WReN 
generalisation cannot be account for with a context-blind solu- 
tion. 



Measuring abstract reason in neural network 

Figure 9. Answer key to puzzle in section A.2 


