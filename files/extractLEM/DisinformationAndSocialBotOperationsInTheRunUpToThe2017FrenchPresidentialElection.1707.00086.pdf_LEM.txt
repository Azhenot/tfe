









































Microsoft Word - ferrara2017.docx 


DISINFORMATION AND SOCIAL BOT 
OPERATIONS IN THE RUN UP TO THE 2017 
FRENCH PRESIDENTIAL ELECTION 
EMILIO FERRARA 
UNIVERSITY OF SOUTHERN CALIFORNIA, INFORMATION SCIENCES INSTITUTE 

ABSTRACT 
Recent account from researchers, journalists, a well a federal investigators, reach a unanimous 
conclusion: social medium be systematically exploit to manipulate and alter public opinion. Some 
disinformation campaign have be coordinate by mean of bots, social medium account control by 
computer script that try to disguise themselves a legitimate human users. In this study, we describe one 
such operation occur in the run up to the 2017 French presidential election. We collect a massive 
Twitter dataset of nearly 17 million post occur between April 27 and May 7, 2017 (Election Day). We 
then set to study the MacronLeaks disinformation campaign: By leverage a mix of machine learn and 
cognitive behavioral model techniques, we separate human from bots, and then study the activity 
of the two group take independently, a well a their interplay. We provide a characterization of both the 
bot and the user who engage with them, and oppose it to those user who didn't. Prior interest of 
disinformation adopter pinpoint to the reason of scarce success of this campaign: the user who engage 
with MacronLeaks be mostly foreigner with preexist interest in alt-right topic and alternative news 
media, rather than French user with diverse political views. Concluding, anomalous account usage pattern 
suggest the possible existence of a black-market for reusable political disinformation bots. 

INTRODUCTION 
Social medium have be extensively praise for their power to democratize online conversation. Whether in 
the context of civil movement (Howard, et al., 2011; González-Bailón, et al., 2011; Tufekci & Wilson, 
2012; González-Bailón, et al., 2013; Tufekci, 2014; Bastos, et al., 2014), political outreach (Bond, et al., 
2012; Bakshy, et al., 2015), public health intervention (Centola, 2010; Dredze, 2012; Korda & Itani, 2013), 
or situational awareness (Sasaki, et al., 2010; Merchant, et al., 2011; Signorini, et al., 2011; Paul & Dredze, 
2011), platform like Twitter and Facebook play a central role in the modern information ecosystem. 
However, such powerful tool can also be abuse for nefarious purpose (Ferrara, 2015): Extremist group 
use social medium for radical propaganda and recruitment effort (Ferrara, 2017); stock market manipulator 
have create concert effort to game financial system (Ferrara, 2015); conspiracy group orchestrate 
campaign to distribute fake scientific article to support anti-vaccination and other anti-science movements, 
create massive public health issue (Bessi, et al., 2015; Del Vicario, et al., 2016). Of great concern for 
democracy be another form of social medium manipulation: The rise of popularity of bot and disinformation 
in the context of political propaganda (El-Khalili, 2013; Bessi & Ferrara, 2016; Ferrara, et al., 2016; Shorey 
& Howard, 2016; Kollanyi, et al., 2016; Marwick & Lewis, 2017). 

lphilippe 
Texte tapé à la machine 
Really bad graph :) Excel !!! Not sharp enough !!! 
Must be reviewed! 



Researchers warn about the potential for abuse of the social medium ecosystem for political propaganda a 
decade ago (Howard, 2006; Hwang, et al, 2012). The early report of coordinate attack against political 
candidate on social medium date back to 2010 (Metaxas & Mustafaraj, 2012; Ratkiewicz, et al., 2011a; 
Ratkiewicz, et al., 2011b). Since then, an increase account of such event have be record in the context 
of several elections, both in the United States (Bessi & Ferrara, 2016; Kollanyi, et al., 2016; Shorey & 
Howard, 2016; Wolley, 2016; Wolley & Howard, 2016; Marwick & Lewis, 2017; Wang, et al., 2017), and 
all over the world, include in South America (Forelle, et al., 2015; Suárez-Serrato, et al., 2016), the U.K. 
(Howard & Kollanyi, 2016), and Italy (Cresci, et al., 2017). One common trait of these campaign be the 
adoption of automation tool to generate large volume of social medium post to support, or attack, candidates. 

Although automate social medium accounts, refer to a social bot or sock puppets, have in some 
instance be use for social good (Savage, et al., 2016; Mønsted, et al., 2017; Shirado, & Christakis, 
2017), in this study we will refer exclusively to those use with the intent to deceive and manipulate. 
Another form of artificial support express on social medium be via fake followers, often inactive account 
that be only use to increase the online popularity and/or visibility (e.g., the followership) of a public figure 
(Marwick & Lewis, 2017). Fake follower be not subject of this study due to their inactivity. 

On the onset of the 2016 U.S. presidential election, a rather new phenomenon be observed, in concert with 
social bot and hyper-partisan campaigns: the spread of fake news and the coordination of disinformation 
campaign (Allcott & Gentzkow, 2017; Marwick & Lewis, 2017; Mele, et al., 2017). The adoption of 
automate device such a social bot in the context of disinformation campaign be particularly concern 
because there be the potential to reach a critical mass large enough to dominate the public discourse and 
alter public opinion (Ferrara, et al., 2016; Woolley & Howard, 2016; Marwick & Lewis, 2017); this could 
steer the public’s attention away from fact and redirect it toward manufactured, plant information.1 

In this paper, we focus on another pivotal recent political event, namely the 2017 French presidential 
election of May 7, 2017. We aim to describe the social medium dynamic related to one potentially disruptive 
disinformation campaign that occur in the run up to the election, know a “MacronLeaks”. In the 
following, we provide a brief account of the event related to MacronLeaks a they unfolded. 

The popular 4chan.org message board host several large yet ephemeral discussion threads. A popular board 
be the “/pol/” (i.e., politics) community. Partly due to it anonymity features, partly because inactive 
discussion thread be quickly and automatically archive by the platform itself, 4chan.org have be 
reportedly function a an effective incubator of alt-right and alt-right online communities, most 
prominently in the United States (Marwick & Lewis, 2017). Among the thread related to the 2017 French 
election, the most popular be one center around coordinate cyber-attacks aim at revel sensitive 
information about then-presidential candidate Emmanuel Macron (En Marche!, 2017). 

Significant user participation guaranteed the generation of a wealth of allegedly incriminate material: 
while most document be manufacture and their false nature be easily identifiable,2 on Friday May 5, 
2017 one user anonymously share an email dump contain “Correspondence, documents, and photo 
from Macron and his team.”3 Shortly after it appearance, a link to the “/pol/” anonymous post be share 
on Twitter by alt-right activist Jack Posobiec, which contribute to amplify the ongoing disinformation 
campaign object of this study.4 Ultimately, the leak document be share on Twitter by WikiLeaks’ 
official account itself, although with the disclosure that their authenticity be unverified – this make the 
campaign go viral. 



DEFINING DISINFORMATION IN THE CONTEXT OF THIS STUDY 
The notion of “disinformation campaign” use in this work warrant a rigorous definition. We consider 
MacronLeaks an instance of disinformation a it exhibit two necessary ingredient namely, first, the 
unverified nature of the share information, and second the coordinate effort behind it sharing. 

The unverified nature of the leak document make this information qualify for the traditional definition 
of “rumor” (Allport & Postman, 1947). The document circulate online have be refer to a evidence 
of Macron’s tax fraud and other illicit activities. The accuracy and relevance of these leak document 
have be extensively debate for week after the fact. The conclusion from official investigation be that, 
although the leak document be not manufactured, there be no evidence to support the allegations: most 
of the conclusion drawn by the 4chan.org community be base on erroneous translation from French, 
a well a bias interpretation (or trivial misunderstanding) of French law (En Marche!, 2017). 

The voluntary spread of a rumor by mean of an orchestrate effort make it a disinformation campaign 
(Del Vicario, et al., 2016). In this case, 4chan.org serve a incubator for the initial attempt to smear the 
candidate by manufacturing, planting, or leak allegedly incriminate documents. In addition, one major 
find of this work, that we will discus in detail later, be the uncover of a social bot operation that 
occur in the run up to Election Day aim at amplify even further the viral share of disinformation 
and email leaks. 

SUMMARY OF CONTRIBUTIONS 
In the rest of this manuscript, we will detail the methodological approach to data collection and analysis, 
and discus the finding and contribution of this work, which we summarize a follows: 

• We monitor the Twitter stream between April 27 and May 7, 2017 (Election Day), and collect 
a very large dataset contain nearly 17 million tweet related to the 2017 French presidential 
election. Within it, we identify the subset related to the MacronLeaks disinformation campaign. 

• By exploit combination of machine learn technique and cognitive behavioral modeling, we 
identify human and social bot participate to the campaign. We study the characteristic of 
both class of user independently, a well a their interplay. 

• We discover that prior user interest reveal the reason of scarce success of the MacronLeaks 
campaign: the user who engage with it be mostly foreigner belonging to the alt-right Twitter 
community, rather than French user (i.e., potential voters). 

• Finally, we uncovered that account use to support then-presidential candidate Trump before the 
2016 U.S. election have be brought back from a limbo of inactivity (since November 2016) to 
join the MacronLeaks disinformation campaign. Such anomalous usage pattern point to the 
possible existence of a black-market for reusable political-disinformation bots. 

METHODS 
DATA COLLECTION 
By follow a consolidated strategy, which we previously use to study the 2016 U.S. Presidential election 
(Bessi and Ferrara, 2016), we manually select a set of hashtags and keywords. The list by construction 
contains a roughly equal number of term associate with each of the two candidates, namely Marine Le 



Pen and Emmanuel Macron, and various general election-related terms: we finally define 23 terms, list 
in Table 1. The compilation of this list be also inform by early report by Oxford researcher about the 
most prominent election-related term (Desigaud, et al., 2017; Howard, et al., 2017). 

We monitor the Twitter stream and collect data by use the Twitter Search API, from April 27 to the 
end of election day, on May 7, 2017: this allow u to uninterruptedly collect all tweet contain any of 
the search terms. The data collection infrastructure ran inside USC server to ensure resilience and 
scalability. We chose to use the Twitter Search API (https://dev.twitter.com/rest/public/search) to make 
sure that we obtain all tweet that contain the search term of interest post during the data collection 
period, rather than a sample of unfiltered tweets: this precaution avoids incur in know sample issue 
related to collect data use the Twitter Stream API (https://dev.twitter.com/streaming/overview) rather 
than the Twitter Search API (Morstatter, et al., 2013). 

This procedure yield a large dataset contain approximately 17 million unique tweets, post by 
2,068,728 million unique users. The timeline of the volume of post tweets, down to the resolution of 
minutes, be illustrate in Figure 1 – and it will be discuss more thoroughly in the Data Analysis section. 

Within this set, we further identify the subset of tweet associate with the MacronLeaks campaign. Using 
the report from various news article a well a by manual inspection, we use the follow key term to 
isolate tweet belonging to the campaign: #MacronLeaks, #MacronGate, #SortonsMacron, #Bayrougate, 
and #RejoignezMarine. All tweet contain any such term constitute the MacronLeaks corpus that we 
will analyze in detail in this work. Nearly 350 thousand such tweet exist, out of about 17 million overall 
tweets, make the MacronLeaks campaign a small drop (i.e., about 2% of the total) in the ocean of 
information regard the presidential election. Overall, 99,378 user post tweet in the MacronLeaks 
corpus. 

BOT DETECTION TECHNIQUES 
One of the most daunt task in social medium analysis be determine whether a user account be control 
by a human or a software (i.e., a bot). A great deal of research aim to address this issue, include our own 
effort (Ferrara, et al., 2016; Varol, et al., 2017) and others’ (Messias, et al., 2013; Yang, et al., 2014; Gilani, 
et al., 2015; Subrahmanian, et al., 2016). 

In this realm, Botometer6 (formerly BotOrNot) represents, a of today, the only openly accessible solution 
(Davis, et al., 2016). It consists of an Application Programming Interface (API) developed in Python which 
allows to programmatically interact with the underlie machine learn system. Botometer have be 
proven quite accurate in detect social bot (Davis, et al., 2016; Varol, et al., 2017), 

However, the public interface of Botometer have two limitation that prevent u to use it in this project: 
the framework relies on the Twitter API to collect recent data about the account to inspect. The Twitter 
API imposes very strict query rate limits, therefore make it impossible to analyze more than a few 
thousand account with the public Botometer Python API. In this study, our goal be to detect bot in a very 
large population of over 2 million users, require an ad hoc large-scale bot detection solution. The second 
limitation be once again derive by the Twitter API: when Botometer inspects an account that have be 
either suspended, protected, quarantined, or deleted, the Twitter API do not provide any detail about it, 
render Botometer unable to make any determination. Since this study will show that a significant portion 
of bot account involve in MacronLeaks have be either suspended, quarantined, or delete shortly after 
Election Day (May 7, 2017), Botometer would not represent a suitable tool to analyze them. 



OUR BOT DETECTION APPROACH 
For the reason mention above, we decide to implement a simple yet accurate bot-detection algorithm 
reflect the follow requirements: 

• The algorithm be accurate yet scalable and can be use to classify the over 2 million user present 
in our dataset in a reliable yet timely manner; this will address the scalability issue of Botometer. 

• The algorithm can use historical tweet and account metadata collect and available in our dataset 
to determine bot and humans, without the need to query the Twitter API for recent data; this will 
address the limit impose by the Twitter API and allow u to analyze all users, not only the active 
one at the time of inspection, but also the suspended, protected, quarantined, and delete accounts. 

• The algorithm build on top of the insight and lesson learn from the development of Botometer. 

Botometer’s underlie machine-learning framework generates a set of over one thousand features, 
span content and network structure, temporal activity, user profile data, and sentiment analysis. These 
indicator be aggregate and analyze to determine the likelihood that the inspect account be a bot. 
Feature analysis reveal that the two most important class of feature to detect social bot be the metadata 
and usage statistic associate with a user account (Davis, et al., 2016; Varol, et al., 2017). We previously 
illustrate (Bessi and Ferrara, 2017) that the follow indicator provide the strong signal to separate 
human from, in particular, political bots: (i) whether the public Twitter profile look like the default one 
or it be customize (it require human effort to customize a profile, therefore bot be more likely to exhibit 
the default setting); (ii) absence of geographical metadata (humans often use smartphones and the Twitter 
iPhone/Android App, which record the physical location of the mobile device a digital footprint); and, 
(iii) activity statistic such a total number of tweet and frequency of post (bots exhibit incessant activity 
and excessive amount of tweets), proportion of retweets over original tweet (bots retweet content much 
more frequently than generate new tweets), proportion of follower over followees (bots usually have 
less follower and more followees), the number of time a user have be add to a public list – human 
user be often consider more influential (Aral, & Walker, 2012) and their content more “contagious” 
(Kramer, et al., 2014; Ferrara & Yang, 2015a; Ferrara & Yang, 2015b; Mønsted, et al., 2017), etc. 

DETECTION ALGORITHM AND FEATURES 
Considering these insights, we use the follow user metadata and activity feature to create a simple yet 
effective bot detection algorithm:7 

1) “statuses_count”: number of tweet post by the give user; 
2) “followers_count”: number of follower of the give user; 
3) “friends_count”: number of followees (friends) of the give user; 
4) “favourites_count”: number of favorited tweet of the give user; 
5) “listed_count”: number of time the give user have be add to a list; 
6) “default_profile”: binary field that indicates whether the user profile have the default set or not; 
7) “geo_enabled”: binary field that indicates whether the geo-coordinates of the user be available; 
8) “profile_use_background_image”: binary field that indicates whether the user profile have the 

default image or a custom one; 
9) “verified”: binary field that indicates whether the account have be verify by Twitter; verify 

account be consider to belong without doubt to humans.8 
10) “protected”: binary field that indicates whether the account have be set a protected.9 



As for machine learn models, we test a variety of algorithm readily available in the Python toolbox 
name scikit-learn (Pedregosa, et al., 2011). 

In line with the consideration above, we consider the ability of the algorithm to deal with large datasets, 
which exclude some computationally more demand algorithm (e.g., Support Vector Machines) and 
we benchmarked the follow methods: Logistic Regression, Decision Trees, various ensemble method 
(Random Forests, AdaBoost, ExtraTrees, etc.), K-nearest neighbors, Stochastic Gradient Descent, and 
finally two-layer neural networks. 

For performance evaluation, we use two standard metric commonly adopt in machine learn research, 
namely accuracy and AUC-ROC (Area Under the Receiver Operating Characteristic curve) (Bishop, 2016). 
Both score range between zero and one, the large the better, with one indicate perfect classification. 

We set up a traditional supervise learn task, constitute of three phases, namely models’ training, 
validation (a.k.a. performance evaluation), and finally, classification of the user in the Twitter French 
election dataset. 

The first step require u to train each model with label example of the two class of user to detect 
(i.e., human and bots). To this purpose, we use two datasets contain over five thousand of positive 
(bots) and negative (humans) example of Twitter user in each category. The former training dataset be 
associate with Botometer (Varol, et al., 2017); the latter one be a label dataset provide by Cresci and 
collaborator (Cresci, 2017). 

For performance evaluation, to calculate the accuracy and AUC-ROC score of all models, we use the 
approach of 10-fold cross-validation. This procedure split the training data into ten equally-sized set of 
data-points (preserving the balance of positive and negative data-points of the original dataset): one of these 
fold be hold out for validation (i.e., performance evaluation) and the remainder be use for training the 
model (the procedure be iterate 10 times, each hold out a different fold, and then average the accuracy 
and AUC-ROC score obtain across the ten round of cross validation). 

All model achieve very good performance, above 80% in both accuracy and AUC-ROC scores. The top 
three model in term of performance be Random Forests (93% accuracy, 92% AUC-ROC), AdaBoost 
(92% accuracy and AUC-ROC), and Logistic Regression (92% accuracy, 89% AUC-ROC). The latter also 
be over one order of magnitude faster than nearly any other model (only Stochastic Gradient Descent be 
comparable in term of speed but significantly bad in term of performance). 

For the reason above, we decide to use Logistic Regression a reference model for bot detection purpose 
in the rest of this study. We retrain a full Logistic Regression model on the ten, simple metadata and 
activity feature described above, use all the available label training data. Finally, we use it to classify 
all two million user in the Twitter French election dataset. An in-depth analysis of our finding follows. 

DATA ANALYSIS 
TIMELINE OF EVENTS AND ONLINE DISCUSSION DYNAMICS 
We start by explore the timeline of the general election-related discussion on Twitter. The broader 
discussion that we collect concern the two candidates, Marine Le Pen and Emmanuel Macron, and span 
the period from April 27 to May 7, 2017. The discussion revolves around the 23 key term list in Table 



1 (Desigaud, et al., 2017; Howard, et al., 2017) and account for roughly 16.65 million tweets. Figure 1 
illustrates the timeline of the volume of such tweets, at the granularity of the minute, and with GMT-0 time 
zone alignment. Let u discus first the dash grey line (left axis): this show the volume of generic 
election-related discussion. Note that the presidential election occur on May 07, 2017. The discussion 
exhibit common circadian activity pattern and a slightly upwards trend in proximity to Election Day. 
Some spike do occur, namely on May 3 and on May 7, 2017. Aside from the obvious uptake in discussion 
on Election Day (i.e., spike on May 7) driven by the offline events, the previous spike occur at night 
time on May 3, 2017 again in response to an offline event, namely after the televise political debate that 
saw Le Pen face Macron.10 Otherwise, the number of tweet per minute average between 300 and 1,500 
during the day, and quickly approach de facto zero overnight, consistently throughout the entire 
observation window. 

Figure 1 also illustrates with the purple solid line (right axis) the volume associate with MacronLeaks. 
One should first note that the volume be nearly an order of magnitude lesser than the general election-related 
discussion. However, the temporal pattern of this campaign be substantially different from the general 
conversation. First, the campaign be substantially silent for the entire period till early May. We can easily 
pinpoint to the inception of the campaign on Twitter, which occurs in the afternoon of April 30. After that, 
a surge in the volume of tweets, peak at nearly 300 per minute, happens in the run up to Election Day, 
between May 5 and May 6, 2017. It have be already report by prior research (Metaxas & Mustafaraj, 
2012) that such disinformation campaign peak between one and two day before elections. It be also worth 
note that such a peak be nearly comparable in scale to the volume of the regular discussion, suggest 
that for a brief interval of time (roughly 48 hours) the MacronLeaks disinformation campaign acquire 
significant collective attention, which in turn could have potentially have disastrous effect in term of public 
opinion manipulation. 

To understand the main topic of conversation and the main actor therein involved, in Table 2 and Table 
3 we report the list of top 20 hashtags and mention users, respectively, with the associate number of 
tweet produce during our observation window. From Table 2 we can observe that many term that we 
use a keywords for data collection appear highly ranked in this list a well (cf. Table 1). Macron canalize 
by far the large volume of tweets, with #Macron appear in over 1.5 million tweets. Comparatively, the 
official hashtags of Marine Le Pen, namely #LePen, accrue less than one third of that. Macron’s prominent 
presence in the discussion be due in part to organic attention, and in part because of disinformation: 
#MacronLeaks and #MacronGate, the two main hashtags related to the disinformation campaign, feature 
prominently in this top 20 list and appear cumulatively in about 350,000 tweet in our dataset. More detail 
about this appear in the next section. Finally, the list demonstrates the high quality of our data collection 
strategy: all hashtags in the list be strictly related to the election conversation (we manually scrutinize up 
to the top 100 hashtags and result be consistent with very little noise add a we go down the ranking). 

As far a the top mention users, the rank be intuitively lead by the two official account of the candidates, 
with Macron accrue nearly 30% more mention than Le Pen. Several account follow, divide by a large 
gap. The list includes: 

• Other prominent politician such a Nicolas Dupont-Aignan, Florian Philippot, Jean-Luc 
Mélenchon, Marion Maréchal-Le Pen, and even US presidential candidate Hillary Clinton, a well 
a several official party Twitter accounts. 



• Traditional news medium accounts, include news channel like BFMTV, Quotidien (@qofficiel), 
a well a prominent journalist like Hugo Clément. 

• American alt-right medium personality like InfoWars’ editor Paul Joseph Watson (@prisonplanet), 
alt-right activist and The Rebel’s correspondent Jack Posobiec, a well a WikiLeaks. All these 
actor be prominently involve with share and discuss the MacronLeaks contents. 

In the next two sections, we will focus on the MacronLeaks campaign and study social bot operation and 
characteristics; afterwards, we will describe the behavior of human and bot user a well a their 
interactions. These analysis will shed light on the dynamic of the MacronLeaks disinformation operations. 

MACRONLEAKS BOTS AND THEIR CHARACTERISTICS 
By use a Logistic Regression model train on the ten metadata and activity feature described above, 
we obtain very accurate user classification on the cross-validated test (92% accuracy, 89% AUC-ROC). 
We adopt this model to detect all bot and separate them from human user in our dataset. In the following, 
however, we will focus exclusively on the MacronLeaks corpus, the subset of our Twitter data that contains 
nearly 350,000 tweet post by nearly one hundred thousand distinct users.11 

Out of 99,378 user involve in MacronLeaks, our model classify 18,324 of them a social bots, and the 
remainder of 81,054 a human users. The fraction of social bot amount for about 18% of the total user 
involve in the campaign, which be extremely consistent with result from previous study – e.g., our 
analysis of the 2016 U.S. Presidential election uncovered that roughly 15% of the user involve in the 
Twitter conversation be bots, and account for about 20% of the total tweet (Bessi & Ferrara, 2016). 

To provide a rigorous and thorough assessment of the quality of the bot detection results, next we provide 
first some example of the result generate by our bot detection model (cf. Table 4), and then a broader 
statistical characterization of the distinctive feature exhibit by the bot a oppose to human users. 

Table 4 show the list of the top 15 Twitter account detect a social bot in the MacronLeaks corpus by 
our Logistic Regression model. They be sort by the number of tweet they post during our observation 
window. We manually investigate the status of these account at the time of our investigation (end of May 
2017): The column “Status” report whether the account be still active, or otherwise they have be 
delete by the owner, or suspend or “quarantined” by Twitter.12 Whether an account have be deleted, 
suspended, or quarantined, it be a strong indicator that the account have be involve in activity in violation 
of Twitter’s Terms of Service: for example social bots, when detect by the platform’s algorithms, get 
systematically shut down; user who share information incompatible with Twitter’s ToS can get report 
by others, then scrutinize by Twitter’s anti-abuse team, and suspend or quarantine if found in violation. 

Remarkably, among the top 15 social bot detect by our framework, 4 account have be so far deleted, 
7 have be suspended, and 2 have be quarantine by Twitter. Two account be still active, and they 
may be the result of misclassification. Overall, this example of manual verification suggests that we 
obtain 13 correct bot out of 15 detected, an accuracy of nearly 87% which be compatible with the cross- 
validation benchmark (92% accuracy, 89% AUC-ROC). Further inspection of highly-ranked account be 
consistent with this accuracy performance. 

In general, we have already extensively observe in our prior work how detect bot “in the wild” be a 
much more challenge task than traditional machine learn “exercises” where performance be measure 
on validation test set for which label be know (Ferrara, et al., 2016; Varol, et al., 2017). This discrepancy 
happens for a couple of reasons, most prominently because oftentimes bot use during traditional training- 



validation benchmark be of the same or similar types, while in the wild (i.e., in the real Twitter world) 
one can expect that thousand of variant of social bot may exist. Our detection framework seem to 
perform well in real-world detection. We hypothesize that this happens for two reasons. First, the 
framework benefit from it simplicity: Logistic Regression be a very simple linear model, and we limit the 
model to learn only over ten user metadata and activity feature, so overfitting issue be limited). Second, 
to train our model we use a mixture of various type of bot provide by multiple study (Varol, et al., 
2017; Cresci, et al., 2017). 

Let u provide some characteristic of the 13 hand-verified bot in Table 4: 

• All account exhibit a disproportionate number of tweet contain the MacronLeaks keywords, 
generate over the first week of May 2017. 

• 12 out of 13 bot (all except @Yhesum) appear to have a very limited number of followers, 
suggest that their creator do not emphasize the importance of the social network dimension, 
which have proven to be a central component of success and influence of bot operation in prior 
study (Bessi & Ferrara, 2016; Ferrara, et al., 2016). The only exception (@Yhesum) instead 
appear to adopt the well-known automatic reciprocal follow-back strategy (i.e., retain a friend 
who follow back an automatically-initiated bot followership), a suggest by the very large and 
balance number of friend and follower (nearly ten thousand). 

• Two suspicious group of bot account with similar name appear: 
o A first class of bot be name *2020 (where * be a randomly generate name, e.g., 

gunbuster2020, dixneuf2020, etc.). Four such “2020” bot appear in the top 15 and they all 
exhibit similar activity statistics. Further manual scrutiny reveal the existence of three 
additional “2020” bot in the MacronLeaks corpus, which be less active but still identical 
in behavioral pattern to the four in the top 15 list. 

o A second class of bot be name *_1337 (where * be a randomly generate name, e.g., 
Geoff_1337 and jerry_1337). Further scrutiny reveal the exist of five other “_1337” 
less active bots. It be worth note that 1337 spell leet, which stand for “elite” and 
represent an alternative alphabet that be primarily use by hack internet communities.13 

In the Discussion and Conclusions section, we will present some additional insight about our finding 
related to the activity and characteristic of some of the bot we discovered. We will show some evidence 
in support of the hypothesis that online market of reusable political disinformation bot may exist:14 some 
of the bot account we uncovered be create at the begin of November 2016, shortly before the 2016 
U.S. Presidential election, and use only for a week to support of alt-right narratives; then they “went dark”, 
show no activity till early May, in support of alt-right agenda and the MacronLeaks disinformation 
campaign in the context of the 2017 French Presidential election. Evidence of such device be in other 
contexts, e.g., in case of crises, have be already report (Starbird, et al., 2014; Nied, et al., 2017). 

We enrich our analysis by provide a statistical characterization of the discover bots, and we contrast it 
to the account identify a human user by our framework. To this purpose, in Figure 2 and Figure 3 we 
show two boxplot distribution of the activity and metadata feature respectively of the human user and 
the social bot present in the MacronLeaks Twitter corpus. We focus only on the five discrete features, 
namely number of tweet (statuses_count), number of follower (followers_count), number of friend 
(friends_count), number of favorite (favourites_count), and number of time list (listed_count); thus, we 



exclude the other five binary features, i.e., default_profile, geo_enabled, profile_use_background_image, 
verified, and protected. 

Some strong statistical difference clearly emerge: Along all dimensions, the social bot involve in 
MacronLeaks appear a less active than the human users. Pairwise comparison between bot and human 
of the distribution of these five feature yield additional insights: 

• Bots post on average 2.86 MacronLeaks-related tweet (s = 10.3), while human post 3.81 (s 
= 9.68). A t-test and a Mann-Whitney test yield respectively p-values of 10-18 and 3-80. 

• Bots obtain on average 1,382 follower (s = 22,282), while human have 2,510 (s = 28,542). T- 
test and Mann-Whitney test score respectively p-values of 3-05 and zero. 

• Bots friended on average 1,058 user (s = 12,190), while human have on average 1,403 friend 
(s = 3,656). T-test and Mann-Whitney yield p-values of 2-04 and zero. 

• Bots favorited on average 228 tweet (s = 924), while human have on average 13,774 favorite 
(s = 27,001). Both t-test and Mann-Whitney p-values be zero. 

• Finally, bot have be list on average on 7.42 list (s = 90.3) and human instead on 77.64 (s 
= 560.2). T-test yield a p-value of 2-62 and Mann-Whitney a p-value of zero. 

All p-values indicate that the pair of distribution differ statistically very significantly. It be worth note 
that all distribution be broad and skewed, exhibit a power-law like behavior. For a visual example, 
refer to Figure 6, which will be discuss in detail in the next section. 

These result warrant further discussion. Recent literature report extensively on traditional type of social 
bot whose automate activity can be easily detect because it yield very high volume of tweets, 
especially retweets, due to incessant post and re-sharing operation (Ferrara, et al., 2016; Bessi & Ferrara, 
2016). These be historically consider effective strategy a they aim at flood the platform with 
campaign-related content and canalize collective attention. However, in the case of MacronLeaks the 
historic trend appear to be reversed: Bots seem to try “fly under the radars”, post comparable or less 
content than human in the same conversation. We hypothesize that this can be a strategy to avoid detection 
and suspension from the platform. 

We finally investigate whether any correlation between user activity and metadata emerge that could 
indicate further anomalous behavioral pattern in bot a oppose to human users. To this aim, in Figure 4 
we show the feature Pearson correlation heat map for human user (top), and social bot (bottom figure) – 
exclusively for those account involve in the MacronLeaks disinformation campaign. Two very different 
picture emerge: for human user (N = 81,054) no strong pairwise feature correlation occur, a measure 
by the Pearson correlation coefficient, except for a strong correlation (r = 0.79) between the number of 
follower a human user have and the number of time it appear in public list (cf. Figure 4, top). These two 
feature be intuitively correlate because more influential user with more follower be add to public 
list more frequently than less influential user with few followers. 

A very different picture emerges from the pairwise feature correlation of bot account (N = 18,324). The 
strong correlation (cf. Figure 4, bottom) appear between the number of friend and the number of time 
these bot appear in list (Pearson coefficient r = 0.81): this indicates that the more user a bot follow the 
more often it appear in public list of other users, suggest a self-promotion mechanism commonly 
adopt by bots. The second strong correlation emerges between the number of follower and friend 
(Pearson coefficient r = 0.65), indicate that on average the bot in the MacronLeaks corpus engage in 



automatic, reciprocal follower-friend link (one example of such behavior be the bot @Yhesum of Table 
4). To complete the cluster of correlate pair of features, number of friend and favorite correlate with a 
coefficient r = 0.61, and number of favorite and list appearance correlate with a coefficient of r = 0.41, 
both indicate strong correlate pattern of systematic behavior in the bots. 

Overall, our analysis highlight example of bot involve in MacronLeaks a well a provide a 
statistical characterization of their activity and metadata feature use by our framework to detect them. In 
the next section, we will explore more in detail the behavior of both bot and human user involve in 
MacronLeaks a well a their interactions. 

HUMAN AND BOT BEHAVIOR AND HUMAN-BOT INTERACTIONS 
Like in the previous section, we here first provide a temporal characterization of the Twitter activity, this 
time specifically related to MacronLeaks, for both bot and human accounts. In Figure 5, we show the 
timeline of the volume of tweet generate (granularity of one minute), respectively by human user (dashed 
grey line) and social bot (solid purple line), between April 27, 2017 and May 7, 2017, and related to 
MacronLeaks. The amount of activity be substantially very close to zero until May 5, 2017, in line with the 
first coordination effort a well a the information leak spur from other social platform like 4chan.org, 
a discuss in the introduction. Spikes in bot-generated content often appear to slightly precede spike in 
human posts, suggest that bot can trigger cascade of disinformation. At peak, the volume of bot- 
generate tweet be comparable with the that of human-generated one (the plot, however, do not 
differentiate between humans’ retweets of bot-generated content, a oppose to tweet organically 
generate by human users). 

Let u investigate human-bot interaction further, and specifically determine what be the characteristic of 
the bot that be more frequently retweeted. To this aim, in Table 5 we report a list of ten social bot 
frequently retweeted by human users. Intuitively, some account overlap with the list of most active bot 
report in Table 4 – e.g., the @Yhesum bot, which we discuss extensively before, accrue many 
retweets. All the account in Table 5 be suspended, deleted, or quarantine by Twitter at the time of this 
write (early June 2017): this corroborates the suspect that the account be involve in the incriminate 
activities. The example of Table 5 warrant further discussion, which will allow u to dig more into the 
detail of the strategy adopt by the bot and their effectiveness. 

For each of the example bot account appear in Table 5, we calculate the number of follower these 
account have prior to MacronLeaks (more precisely, the first time they appear in our dataset) a oppose to 
at the end of the observation window (i.e., relative to their last tweet in our dataset). What emerges be that 
six out of ten bot accrue a significant and large number of follower during the MacronLeaks 
disinformation campaign. A few of these example account have zero or nearly no follower when they first 
appear in the conversation, and manual verification indicates that the account be explicitly create on 
purpose to disseminate MacronLeaks tweets. It be worth note that be active in such a type of 
disinformation campaign appear to be an effective strategy to accrue visibility: several account obtain 
thousand of follower – in our example bot of Table 5, we notice increase up to nearly fifteen thousand 
follower accumulate in the span of less than one week. Another interest fact that be worth note be 
that the number of retweets receive by the bot do not seem to be strongly correlate with the total 
amount of MacronLeaks tweet post by each bot. The effectiveness of these bots, if measure in term 
of number of accrue retweets, appear to be independent of their sheer activity: this suggests that other 
factors, such a the position of the bot in the social network, the different type of message they post 



and their narrative and language, a well a the type of human target they aim at influencing, be all 
ingredient that potentially play a role in bots’ strategies. 

To dig further into the type of user involve in MacronLeaks and contrast that to the user participate 
exclusively to the general election-related discussion, we extract the most frequent word occur in 
the tweet produce in these two corpora. In Table 6 we show a example the top 16 most frequent token 
term (i.e., individual word obtain after remove stop word and other commonly occur terms) 
occur in the tweet of the two corpora. Excluding the name of the two candidate that be prominently 
feature in both corpora, by contrast the two column stark difference emerge: on the left side of Table 
6, which represent general-election frequent terms, we observe several French word that strongly relate 
to the upcoming voting, e.g., voter (to cast one’s vote, in French), vote (“to vote”, in French a in English), 
fait (fact, or event, in French), faire (“to do”, “to make”, “to take”, etc.), tout (all), Français (French), débat 
(debate), etc. On the right side of Table 6 we see no such a language characterization, which strongly 
suggests the fact that the MacronLeaks disinformation campaign be limited mostly to an English-speaking 
audience, and fail to percolate in the French-speaking Twitter community. The most frequent word 
speak along the direction of the main narrative that be tailor around the allege illicit activity and tax 
fraud of the now-president Macron. Interestingly, the word campaign itself be prominently feature in 
fourth position with over twenty thousand distinct occurrences, suggest the nature of the operation itself. 

To corroborate this hypothesis, we extract the most frequent term appear in the self-reported profile 
description that Twitter user can decide to include in their accounts. By use the same filter criteria, 
in Table 7 we report a example the top 16 word token ranked by frequency of appearance in the Twitter 
profile of user involve respectively in MacronLeaks (right column) a oppose to exclusively in the 
general election-related discussion (left column). Table 7 provide again a staggeringly different picture: 
most word occur in the profile of user not involve in MacronLeaks campaign be in French, while 
emblematically the top two key term of MacronLeaks’ user be MAGA (“Make America Great Again”, 
the motto of US President Trump), a well a Trump itself. While the left column be suggestive of term 
that individual interested in French politics would likely adopt to describe themselves – politique (politics), 
patriote (patriot), Français (French), contre (against), gauche (left), droite (right), etc. – the right side 
feature similar key term in English (conservative, patriot, god, pro-, American, America, Christian, 
politics, anti-, life, supporter, country, etc.), which would clearly characterize a right-leaning English- 
speaking, American audience. This suggests that the large majority of user involve in MacronLeaks have 
prior interest in American politics, in right-wing narratives, and in alt-right political agenda. Manual 
inspection of many of these account confirm this hypothesis; it also further reveal that some account 
label a bot involve in MacronLeaks be also active in the alt-right campaign lead to the 2016 
U.S. Presidential election and be label a bot in our previous study a well (Bessi & Ferrara, 2016). 

We next analyze the type of information source that the users, respectively human and bots, most 
frequently refer to in their tweets. To this purpose, in Table 8 we show for illustrative example the list 
of the top 10 URLs that have be tweet within the general election discussion. We will consider this a 
a baseline for comparison and contrast it to the top tweet URLs show in Table 9, and discuss later. 
Our extensive analysis highlight that most URLs appear in the general election-related discussion be 
of the follow three types: 

1. Pointers to tweet of either presidential candidate, (Macron and Le Pen), or to tweet of other 
prominent politician (e.g., Nicolas Dupont-Aignan); 

2. Pointers to article publish in establish news medium (Le Figaro, The Guardian, Le Monde); 



3. Pointers to influential user on external medium channel (e.g., YouTube, etc.), a well a journalist 
and other influential user on Twitter. 

Let u look at the MacronLeaks corpus next. Table 9 show the list of top 10 URLs tweet within the 
MacronLeaks campaign. In stark contrast with the general election-related discussion, the list of top 
tweet URLs contains a mix of: 

1. Links to hyper-partisan news outlets: the top tweet URL point to a story appear on The 
Gateway Pundit (an alt-right news media) claim that leak document be original and 
credible. Other highly-tweeted story appear again on The Gateway Pundit a well a on other alt- 
right website like Zero Hedge and GotNews and support the allegation of Macron’s financial 
fraud and illicit activities. 

2. Links to leak data dumps: the second most tweet URL be the link to the archive.is file that 
contains the data of the leak documents; this file have be extensively circulate on other 
platform like 4chan.org and be share thousand of time on Twitter a well; and, finally, 

3. URLs point to fake news websites: some blogposts (e.g., on blogspot.dk) qualify a fake news 
a they seem to be design exclusively for financial profit, rather than for political reasons, e.g., 
in the case of alt-right news medium site like Breitbart News, Infowars, The Gateway Pundit, etc. 
Pointers to fake news story proliferate even further down the list of highly-retweeted URLs.s 

We conclude this analysis section by provide a statistical characterization of the corpus’ features. In 
Figure 6 we show two set of probability distributions, relative to the MacronLeaks tweet corpus (cf., top 
figure), which contains 347 thousand tweets, and an equal-sized random sample of tweet related to the 
general French election discussion post during the same period (cf., bottom figure). 

In this order, each plot shows: 

A. The distribution of the total number of tweet post by each user in the give corpus; 
B. The distribution of number of total word token in the give tweet corpus; 
C. The distribution of number of total word token in the user profiles’ descriptions; 
D. The distribution of the number of tweets’ languages; 
E. The distribution of the number of distinct hashtags; 
F. The distribution of the number of distinct user mentions; and finally, 
G. The distribution of the number of distinct URLs, appear in the corpus. 

Before contrast the result for the two corpora, let u provide an intuitive explanation of these features. 

We consider the number of tweet a an indicator of volume of activity in a discussion: we hypothesize 
that in a bot-driven conversation, highly active account (due to automation) will contribute give this 
distribution a fatter tail than in an organic discussion. 

The feature B and C warrant an explanation on their construction: for each corpus (i.e., MacronLeaks and 
general discussion, respectively), we calculate the frequency of appearance of each word in the tweet (B) 
a well a in the user profile description (C). Word distribution enjoy some characteristic distributions, 
e.g., the Zipf law that suggests that the ranked word frequency should obey a Zipfian distribution (Adamic, 
2000). Our intuition be that the heavier the fat tail of such a distribution, the less diverse a tweet corpus be 
(respectively, the user profile appear in it), because a fatter tail indicates the appearance of some 
extremely popular word (in either the tweet or the user profile descriptions). 



Feature D simply indicates how many different language appear in a corpus, and the frequency of tweet 
in that language. A more diverse discussion should encompass more languages. We hypothesize that the 
rank of the language be also instrumental to determine the audience mainly involve in that discussion. 

The last three features, E, F, and G, indicate the number of distinct hashtags, user mentions, and URLs 
appear in the give corpus. More diverse conversation will have lighter tail than discussion dominate 
by the pervasive frequency of some of these entities. 

Let u now discus the finding that emerge from Figure 6, follow the order of feature present above: 
for what concern the distribution of the total number of tweet post by each user in the two corpus (cf., 
distribution A, i.e., the solid blue line), we can see that in MacronLeaks the tail of the distribution reach 
roughly 103, indicate the presence of some extremely prolific account (either human or bots); in contrast, 
such distribution characterize the general discussion exhibit a small slope and thus peak at around 
102, suggest that only a minority of user post more than one hundred tweet in the entire corpus. This 
be in line with the intuition that bot-driven discussion exhibit a fatter tail in the characteristic activity-related 
distribution (e.g., number of post tweet per user). 

Distributions B (i.e., the dash red line) and C (i.e., dash orange line) be very similar one another in 
both corpora. These distribution reflect the frequency of occurrence of word terms, whose generation and 
interpretation have be extensively discuss above in reference to Table 6 and Table 7, which report 
example of word token appear in the tweet and in the users’ profile descriptions, respectively. Once 
again, the slope of the curve relative to MacronLeaks be large than that of the general discussion, 
suggest the presence of more prominent word that appear more frequently in the tweet a well a in 
the profile of user in MacronLeaks. This be consistent with the example show in Table 6 and Table 7, 
which nicely illustrate two byproduct effect of this phenomenon: 

1. The most frequent word in both ranking appear about 25% more in MacronLeaks than in the 
general discussion: “Macron” appear 133K time in MacronLeaks, but only 109K time in the 
general discussion; similarly, “MAGA” (top ranked in Table 7: right column) appear nearly 18K 
time in MacronLeaks’ user descriptions, a oppose to “France” (top ranked in Table 7: left 
column) that appear about 13K time in the profile of general discussion users. 

2. As one scroll down the ranking, give a position in the ranking, term in MacronLeaks corpus tent 
to have high frequency of occurrence of equally ranked term in the general election. For 
example, the tenth term in Table 6 be fait, which appear 11,023 time in the general election- 
related discussion, and fake that appear 12,404 in MacronLeaks. Similarly, the twentieth term in 
Table 7 be droite, which appear 3,871 time in the general discussion, and country that appear 
5,272 time in MacronLeaks. The same applies to nearly all entry in the rest of the rankings. 

These result corroborate our intuition that fatter distribution tail suggest less diversity in the tweet corpus, 
or in the profile of the user therein appearing. In MacronLeaks this indicates the emergence of popular 
word strongly evocative of the corpus’ narrative and prominently feature by a relatively large number 
of user with respect to the general election-related discussion. 

Yet in Figure 6, Distribution D provide a view into the diversity of language feature in each corpus. 
Intuitively, a more diverse conversation that be more inclusive of a variety of groups, a well a that attracts 
international attention, would feature a large number of languages. MacronLeaks once again show a fatter 
tail suggest that the conversation be less diverse in term of language give that many tweet appear in 
one extremely popular language. Further analysis reveals an interest fact: in MacronLeaks, most tweet 



(N=177,695) be in English, while French be only second (N=135,397); in stark difference, in the equal- 
size random sample of general conversation, French emerges by far a the most prominent language 
(N=242,422), while English come second with a large gap (N=73,409). This suggest that the main 
participant to MacronLeaks be not in the French-speaking community, but rather in the English- 
speak American user base. This may be one explanation associate with the scarce success of the 
disinformation campaign to affect French voters. 

Our analysis concludes with a summary of interpretation of the last three distributions, E, F, and G, which 
indicate the number of distinct hashtags, user mentions, and URLs respectively. For each of these 
distribution it be possible to observe systematically roughly one order of magnitude difference in favor of 
the MacronLeaks ones, which exhibit fatter tail indicate less diverse corpus whose tweet be dominate 
by fewer, more popular hashtags, mentions, and URLs, if contrast with the general discussion. If one 
considers URLs, a an example, the result be reflect in Table 8 and Table 9 and a similar analysis 
regard rank and frequency of the term can be do a for what concerned distribution B and Table 
6 and Table 7: the top URLs in MacronLeaks be systematically more frequent than equally-ranked URLs 
in the general discussion. 

DISCUSSION AND CONCLUSIONS 
In this paper, we provide an extensive statistical analysis of the MacronLeaks disinformation campaign 
that occur in the run up to the 2017 French presidential election. Using a mix of state-of-the-art machine 
learn technique and cognitive heuristic for bot detection, in combination with data-driven insights, and 
consider a reconstruction of event a they unfolded, we uncovered some characteristic of the 
disinformation campaign, it main drivers, and it human audience. We contrast these result against the 
general election-related conversation that we use a baseline to pinpoint to difference and anomalies. 

Our result highlight a few interest phenomena: first, we advanced the hypothesis that a black market 
of reusable political disinformation bot may exist. Similar suggestion have be advanced by other study 
(Starbird, et al., 2014; Nied, et al., 2017); however, our work be the first to identify the presence of bot that 
exist during the 2016 U.S. Presidential election campaign period to support alt-right narratives, go dark 
after November 8, 2016, and come back into use in the run up day to the 2017 French presidential election. 

In conclusion, our finding also demonstrate that the prior interest of user engage in MacronLeaks may 
be reveal of the reason of scarce success of the campaign at affect the French vote outcome: most 
of the audience of MacronLeaks campaign be the English-speaking American alt-right community, rather 
than French users; this be in stark contrast with the baseline general conversation, which involve 
systematically and significantly more French user (thus, likely French voters), which exhibit a clear 
trend in favor of support now-president Emmanuel Macron. 

In the future, we will try to draw similarity and difference in the context of computational political 
propaganda phenomena, focus on a variety of election and politics-related contemporary event to 
understand how online social medium can be manipulated, and what be the quantifiable consequence of 
successful such attempts. 





NOTES 
1. While the exact dynamic of event in the context of the 2016 U.S. election at the time of this 

write (June 2017) still remain unclear, and be subject of ongoing federal investigations, sufficient 
evidence have be mount to support the idea that foreign governments, a well a organization 
with vested interests, may have meddle with the election process, either via influence campaigns, 
or by mean of spear phishing attack aim at steal private information of voter either for 
retaliation and blackmailing purposes. 

2. See: https://www.cnet.com/news/macron-french-presidential-campaign-says-it-was-hacked/ 
3. See: http://www.bbc.com/news/blogs-trending-39845105 
4. See: http://www.thedailybeast.com/the-twitter-bots-who-tried-to-steal-france 
5. See: https://www.buzzfeed.com/craigsilverman/partisan-fb-pages-analysis 
6. Botometer be publicly available at: https://botometer.iuni.iu.edu/ 
7. We here use a nomenclature of tweets’ feature consistent with that of the Twitter API; See official 

documentation a reference: https://dev.twitter.com/overview/api/tweets 
8. Twitter account verification process described at: https://support.twitter.com/articles/119135 
9. About public and protect tweets: https://support.twitter.com/articles/14016 
10. Timeline of event lead to the election: http://www.businessinsider.com/france-is-having-one- 

of-its-strangest-presidential-elections-timeline-2017-5 
11. A broader analysis of social bot operation in the entire French election dataset be left for future 

work. This be mostly because a thorough validation of the bot classification result require a 
significant amount of manual investigation for quality assurance. Therefore, scale up the effort 
to very large corpus (in our case, 2 million user overall) require significant additional resources. 

12. Twitter can take two different countermeasure toward suspicious accounts: the more radical 
solution be an account suspension, which yield the deletion of the account and all tweet ever 
post by that user. A softer solution be the so-called “quarantine”: the give account be label a 
suspicious and user on the platform must go through an extra step of verification to access their 
content. The owner of a quarantine account can also try appeal to Twitter to get reinstated. 

13. See: https://en.wikipedia.org/wiki/Leet 
14. See: http://www.businessinsider.com/twitter-bots-and-fake-accounts-2013-11 

ABOUT THE AUTHOR 
Dr. Emilio Ferrara be Research Assistant Professor at the University of Southern California, Research 
Leader at the USC Information Sciences Institute, and Principal Investigator of the USC Machine 
Intelligence and Data Science (MINDS). His research focus on characterize information diffusion in 
online social networks, detect and prevent abuse in such systems. He be name 2015 IBM Watson 
Big Data Influencer, he be recipient of the 2016 Complex System Society Junior Scientific Award, and he 
receive the 2016 DARPA Young Faculty Award. E-mail: emiliofe@usc.edu 

ACKNOWLEDGEMENTS 
This work be support in part by the Air Force Office of Scientific Research. The funder have no role in 
study design, data collection and analysis, manuscript preparation, or decision to publish. 



REFERENCES 
Adamic, L. A. (2000). Zipf, power-laws, and pareto-a rank tutorial. Xerox Palo Alto Research Center, 

Palo Alto, CA, http://ginger.hpl.hp.com/shl/papers/ranking/ranking.html 

Allcott, H., & Gentzkow, M. (2017). Social medium and fake news in the 2016 election (No. w23089). 
National Bureau of Economic Research. 

Allport, G. W., & Postman, L. (1947). The psychology of rumor. Oxford Press 

Aral, S., & Walker, D. (2012). Identifying influential and susceptible member of social networks. Science, 
337(6092). 

Bakshy, E., Messing, S., & Adamic, L. A. (2015). Exposure to ideologically diverse news and opinion on 
Facebook. Science, 348(6239). 

Bastos, M. T., da Cunha Recuero, R., & da Silva Zago, G. (2014). Taking tweet to the streets: A spatial 
analysis of the Vinegar Protests in Brazil. First Monday, 19(3). 

Bessi, A., & Ferrara, E. (2016). Social bot distort the 2016 US Presidential election online discussion. First 
Monday, 21(11). 

Bessi, A., Coletto, M., Davidescu, G. A., Scala, A., Caldarelli, G., & Quattrociocchi, W. (2015). Science 
v conspiracy: Collective narrative in the age of misinformation. PloS one, 10(2), e0118093. 

Bishop, C. M. (2006). Pattern recognition. Machine Learning, 128, 1-58. 

Bond, R. M., Fariss, C. J., Jones, J. J., Kramer, A. D., Marlow, C., Settle, J. E., & Fowler, J. H. (2012). A 
61-million-person experiment in social influence and political mobilization. Nature, 489(7415). 

Centola, D. (2010). The spread of behavior in an online social network experiment. science, 329(5996), 
1194-1197. 

Cresci, S., Di Pietro, R., Petrocchi, M., Spognardi, A., & Tesconi, M. (2017). The paradigm-shift of social 
spambots: Evidence, theories, and tool for the arm race. WWW '17 Companion Proceedings of the 
26th International Conference on World Wide Web Companion, pp. 963-972. Perth, Australia 

Davis, C. A., Varol, O., Ferrara, E., Flammini, A., & Menczer, F. (2016). BotorNot: A system to evaluate 
social bots. In Proceedings of the 25th International Conference Companion on World Wide Web. 

Del Vicario, M., Bessi, A., Zollo, F., Petroni, F., Scala, A., Caldarelli, G., Stanley, H.E. & Quattrociocchi, 
W. (2016). The spread of misinformation online. Proceedings of the National Academy of Sciences, 
113(3), 554-559. 

Desigaud, C., Howard, P. N., Bradshaw, S., Kollanyi, B., & Bolsover, G. (2017). Junk News and Bots 
during the French Presidential Election: What Are French Voters Sharing Over Twitter in Round Two?. 
COMPROP Data Memo 2017.4. 

Dredze, M. (2012). How social medium will change public health. IEEE Intelligent Systems, 27(4), 81-84. 

El-Khalili, S. (2013). Social medium a a government propaganda tool in post-revolutionary Egypt. First 
Monday, 18(3). 

En Marche! (2017). Communiqué de presse - En Marche a été victime d’une action de piratage massive et 
coordonnée. https://en-marche.fr/article/communique-presse-piratage 



Ferrara, E. (2015). Manipulation and abuse on social media. ACM SIGWEB Newsletter, (Spring), 4. 

Ferrara, E., & Yang, Z. (2015a). Quantifying the effect of sentiment on information diffusion in social 
media. PeerJ Computer Science, 1, e26. 

Ferrara, E., & Yang, Z. (2015b). Measuring emotional contagion in social media. Plos One 10 (11), 
e0142390. 

Ferrara, E., Varol, O., Davis, C., Menczer, F., & Flammini, A. (2016). The rise of social bots. 
Communications of the ACM, 59(7), 96-104. 

Ferrara, E. (2017). Contagion Dynamics of Extremist Propaganda in Social Networks. Information Sciences 
(in press). Available at SSRN: https://ssrn.com/abstract=2982259 

Forelle, M. C., Howard, P. N., Monroy-Hernández, A., & Savage, S. (2015). Political bot and the 
manipulation of public opinion in Venezuela. 

Freitas, C., Benevenuto, F., Ghosh, S., & Veloso, A. (2015). Reverse engineering socialbot infiltration 
strategy in Twitter. In Proceedings of the 2015 IEEE/ACM International Conference on Advances in 
Social Networks Analysis and Mining. ACM. 

Gilani, Z., Wang, L., Crowcroft, J., Almeida, M., & Farahbakhsh, R. (2016, April). Stweeler: A Framework 
for Twitter Bot Analysis. In Proceedings of the 25th International Conference Companion on World 
Wide Web (pp. 37-38). International World Wide Web Conferences Steering Committee. 

González-Bailón, S., Borge-Holthoefer, J., Rivero, A., & Moreno, Y. (2011). The dynamic of protest 
recruitment through an online network. Scientific report (1). 

González-Bailón, S., Borge-Holthoefer, J., & Moreno, Y. (2013). Broadcasters and hidden influentials in 
online protest diffusion. American Behavioral Scientist. 

Hwang, T., Pearce, I., & Nanis, M. (2012). Socialbots: Voices from the fronts. Interactions, 19(2). 

Howard, P. N. (2006). New medium campaign and the manage citizen. Cambridge University Press. 

Howard, P. N., & Kollanyi, B. (2016). Bots, #Strongerin, and #Brexit: Computational Propaganda During 
the UK-EU Referendum. Available at SSRN: https://ssrn.com/abstract=2798311 

Howard, P. N., Duffy, A., Freelon, D., Hussain, M. M., Mari, W., & Maziad, M. (2011). Opening close 
regimes: what be the role of social medium during the Arab Spring?. Project on Information Technology 
and Political Islam Data Memo 2011. 

Howard, P. N., Bradshaw, S., Kollanyi, B., Desigaud, C., & Bolsover, G. (2017). Junk News and Bots 
during the French Presidential Election: What Are French Voters Sharing Over Twitter?. COMPROP 
Data Memo 2017.3. 

Kollanyi, B. (2016). Where Do Bots Come From? An Analysis of Bot Codes Shared on GitHub. 
International Journal of Communication, 10(20). 

Kollanyi, B., Howard, P. N., & Woolley, S. C. (2016). Bots and Automation over Twitter during the First 
U.S. Presidential Debate. Data Memo 2016.1. Oxford, UK: Project on Computational Propaganda. 

Korda, H., & Itani, Z. (2013). Harnessing social medium for health promotion and behavior change. Health 
promotion practice, 14(1), 15-23. 



Kramer, A. D., Guillory, J. E., & Hancock, J. T. (2014). Experimental evidence of massive-scale emotional 
contagion through social networks. Proceedings of the National Academy of Sciences, 111(24), 8788- 
8790. 

Marwick, A., & Lewis, R. (2017). Media Manipulation and Disinformation Online. Data & Society 
Research Institute. 

Mele, N., Lazer, D., Baum, M., Grinberg, N., Friedland, L., Joseph, K., ... & Mattsson, C. (2017). 
Combating Fake News: An Agenda for Research and Action. 

Merchant, R. M., Elmer, S., & Lurie, N. (2011). Integrating social medium into emergency-preparedness 
efforts. New England Journal of Medicine, 365(4), 289-291. 

Messias, J., Schmidt, L., Oliveira, R., & Benevenuto, F. (2013). You follow my bot! Transforming robot 
into influential user in Twitter. First Monday, 18(7). 

Metaxas, P. T., & Mustafaraj, E. (2012). Social medium and the elections. Science, 338(6106). 

Mønsted, B., Sapieżyński, P., Ferrara, E., & Lehmann, S. (2017). Evidence of Complex Contagion of 
Information in Social Media: An Experiment Using Twitter Bots. arXiv preprint arXiv:1703.06027. 

Morstatter, F., Pfeffer, J., Liu, H., & Carley, K. M. (2013). Is the sample good enough? Comparing data 
from Twitter's stream API with Twitter's firehose. Seventh International AAAI Conference on 
Weblogs and Social Media. 

Nied, A. C., Stewart, L., Spiro, E., & Starbird, K. (2017). Alternative Narratives of Crisis Events: 
Communities and Social Botnets Engaged on Social Media. In Companion of the 2017 ACM 
Conference on Computer Supported Cooperative Work and Social Computing (pp. 263-266). ACM. 

Paul, M. J., & Dredze, M. (2011). You be what you Tweet: Analyzing Twitter for public health. 
Proceedings of the Fifth International AAAI Conference on Weblogs and Social Media, pp. 265-272. 

Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., ... & Vanderplas, J. (2011). 
Scikit-learn: Machine learn in Python. Journal of Machine Learning Research, 12(Oct), 2825-2830. 

Ratkiewicz, J., Conover, M., Meiss, M., Gonçalves, B., Flammini, A., & Menczer, F. (2011a). Detecting 
and Tracking Political Abuse in Social Media. 5th International AAAI Conference on Weblogs and 
Social Media. 

Ratkiewicz, J., Conover, M., Meiss, M., Gonçalves, B., Patil, S., Flammini, A., & Menczer, F. (2011b). 
Truthy: mapping the spread of astroturf in microblog streams. In Proceedings of the 20th international 
conference companion on World Wide Web. ACM. 

Sakaki, T., Okazaki, M., & Matsuo, Y. (2010). Earthquake shake Twitter users: real-time event detection 
by social sensors. In Proceedings of the 19th international conference on World wide web (pp. 851- 
860). ACM. 

Savage, S., Monroy-Hernandez, A., & Höllerer, T. (2016). Botivist: Calling Volunteers to Action use 
Online Bots. In Proceedings of the 19th ACM Conference on Computer-Supported Cooperative Work 
& Social Computing (pp. 813-822). ACM. 

Shirado, H., & Christakis, N. A. (2017). Locally noisy autonomous agent improve global human 
coordination in network experiments. Nature, 545(7654), 370-374. 



Shorey, S., & Howard, P. N. (2016). Automation, Big Data and Politics: A Research Review. International 
Journal of Communication, 10(24). 

Signorini, A., Segre, A. M., & Polgreen, P. M. (2011). The use of Twitter to track level of disease activity 
and public concern in the US during the influenza A H1N1 pandemic. PloS one, 6(5), e19467. 

Starbird, K., Maddock, J., Orand, M., Achterman, P., & Mason, R. M. (2014). Rumors, false flags, and 
digital vigilantes: Misinformation on twitter after the 2013 boston marathon bombing. iConference 
2014 Proceedings. 

Suárez-Serrato, P., Roberts, M. E., Davis, C., & Menczer, F. (2016). On the influence of social bot in 
online protests. In International Conference on Social Informatics (pp. 269-278). Springer International 
Publishing. 

Subrahmanian, V. S., Azaria, A., Durst, S., Kagan, V., Galstyan, A., Lerman, K., Zhu, L., Ferrara, E., 
Flammini, A., Menczer, F. (2016). The DARPA Twitter bot challenge. Computer 49, IEEE. 

Tufekci, Z., & Wilson, C. (2012). Social medium and the decision to participate in political protest: 
Observations from Tahrir Square. Journal of Communication, 62(2), 363-379. 

Tufekci, Z. (2014). Engineering the public: Big data, surveillance and computational politics. First Monday, 
19(7). 

Varol, O., Ferrara, E., Davis, C., Menczer, F., & Flammini, A. (2017). Online Human-Bot Interactions: 
Detection, Estimation, and Characterization. International AAAI Conference on Web and Social Media. 

Woolley, S. C. (2016). Automating power: Social bot interference in global politics. First Monday, 21(4). 

Woolley, S. C., & Howard, P. N. (2016). Political Communication, Computational Propaganda, and 
Autonomous Agents—Introduction. International Journal of Communication, 10(9). 

Wang, Y., Li, Y., & Luo, J. (2017). Deciphering the 2016 US Presidential Campaign in the Twitter Sphere: 
A Comparison of the Trumpists and Clintonists. International AAAI Conference on Web and Social 
Media. 

Yang, Z., Wilson, C., Wang, X., Gao, T., Zhao, B. Y., & Dai, Y. (2014). Uncovering social network sybils 
in the wild. ACM Transactions on Knowledge Discovery from Data (TKDD), 8(1). 








TABLES 


France2017 LePen JeVoteMacron EnMarche 

Marine2017 Le Pen JeVote MacronPresident 

AuNomDuPeuple MarineLePen Presidentielle2017 #France 

FrenchElection FrenchPresidentialElection ElectionFracaise @MLP_officiel 

FrenchElections JeChoisisMarine JamaisMacron @EmmanuelMacron 

Macron JeVoteMarine Macron2017 

Table 1. List of 23 keywords whose stream we continuously collect from April 27, 2017 to May 7, 2017. 





Hashtag No. Tweets Hashtag (cont.) No. Tweets (cont.) 

#Macron 1,521,425 #fn 127,336 

#Presidentielle2017 652,563 #JeVote 126,075 

#LePen 447,365 #Marine2017 119,274 

#France 378,234 #debat2017 118,069 

#2017LeDebat 273,304 #2017LeDébat 98,862 

#MacronLeaks 255,491 #MacronGate 93,235 

#MarineLePen 184,442 #JeVoteMacron 83,081 

#Whirlpool 170,347 #MacronPresident 72,184 

#EnMarche 128,613 #JamaisMacron 72,140 

#FrenchElection 127,705 #Elysee2017 59,421 

Table 2. List of top 20 hashtags and associate number of tweet produce between April 27, 2017 and 
May 7, 2017 (election day). 





Mention No. Tweets Mention (cont.) No. Tweets (cont.) 

@emmanuelmacron 1,284,627 @hugoclement 66,001 

@mlp_officiel 981,219 @enmarchefr 62,468 

@bfmtv 213,421 @hillaryclinton 61,982 

@dupontaignan 178,995 @marion_m_le_pen 61,651 

@prisonplanet 136,874 @sofiakkar 58,074 

@qofficiel 112,423 @v_of_europe 56,998 

@f_philippot 95,696 @jeunesmacron 54,927 

@jlmelenchon 89,334 @flwjrm 50,982 

@jackposobiec 76,419 @youtube 50,631 

@wikileaks 69,718 @tf1lejt 50,628 

Table 3. List of top 20 mention users, and associate number of tweet produce between April 27, 2017 
and May 7, 2017 (election day). 





Username Tweets Followers Friends Favorites Listed Status* 

Vote__Marine 737 9 61 85 0 DELETED 

DonTreadOnMemes 427 24 35 371 1 DELETED 

BrandonJBarber 328 4 135 0 1 DELETED 

Geoff_1337 286 14 13 19 0 SUSPENDED 

N********* 252 31 99 270 4 Active 

07_mai_2017 225 169 231 0 3 DELETED 

gunbuster2020 221 10 87 574 0 SUSPENDED 

dixneuf2020 213 15 81 570 0 SUSPENDED 

bluecanti2020 204 10 88 575 0 SUSPENDED 

shogouki2020 203 13 86 573 0 SUSPENDED 

D********* 199 2,515 1,676 77 29 Active 

Yhesum 191 9,476 9,599 223 96 SUSPENDED 

jerry_1337 152 5 12 0 0 SUSPENDED 

Subocean 102 26 87 9 3 QUARANTINED 

protegerlepeupl 92 1 62 60 0 QUARANTINED 

Table 4. List of the top 15 Twitter account detect a social bot by our algorithm and sort accord 
to the number of MacronLeaks post they tweet between April 27, 2017 and May 7, 2017 (election day). 
* The column “Status” report whether, a of the date of this write (end of May 2017), the account be 
active or be be suspended, deleted, or “quarantined” by Twitter. Out of the top 15 social bot detect by 
our framework, 4 account have be so far deleted, 7 have be suspended, and 2 have be quarantine 
by Twitter. Two account be still active (their usernames be redact to preserve user privacy). 







Username Retweeted Tweets Followers before Followers after Status* 

Yhesum 291 786 21 9,476 SUSPENDED 

lou_justine92 119 213 219 2,297 DELETED 

trololo451 93 94 7 10 DELETED 

doubtallthought 43 431 377 1,833 QUARANTINED 

chadashworth 43 5 14,833 15,205 DELETED 

jewishhotjean 39 422 46 14,033 DELETED 

sebasqien 38 447 31 6,633 DELETED 

blufor2 30 3 0 1 DELETED 

_loup_gar 29 65 2 769 DELETED 

lerenardfrance 25 22 6 16 DELETED 

Table 5. Ten example of social bot frequently retweeted by human users. *All these account be 
suspended, deleted, or quarantine by Twitter at the time of this write (early June 2017). 





Generic election-related discussion MacronLeaks campaign 

Token Frequency Token Frequency 

Macron 109,734 Macron 133,708 

Pen 80,789 French 28,668 

Marine 43,101 France 27,280 

France 24,971 campaign 22,585 

Emmanuel 15,793 email 19,206 

French 13,463 Pen 15,463 

voter 13,094 WikiLeaks 14,493 

vote 11,394 document 14,269 

plus 11,204 tax 12,591 

fait 11,023 fake 12,404 

faire 9,237 election 12,159 

LePen 8,717 medium 10,053 

election 7,311 leak 9,643 

Français 6,535 vote 9,641 

tout 6,497 discover 8,927 

débat 5,930 evasion 8,854 

Table 6. Top 16 most frequent token term occur in the tweet of user respectively active in the general 
election-related discussion or in the MacroLeaks campaign. 





Generic election-related discussion MacronLeaks campaign 

Token Frequency Token Frequency 

France 13,204 MAGA 17,853 

politique 7,731 Trump 17,796 

love 6,241 France 15,437 

patriote 5,578 love 12,345 

marine2017 5,576 conservative 10,657 

Trump 5,116 marine2017 8,503 

vie 5,104 patriot 8,280 

monde 5,041 marine 7,386 

tweet 4,874 god 7,297 

fan 4,713 proud 6,931 

Français 4,667 pro 6,880 

news 4,488 American 6,777 

contre 4,359 America 6,774 

anti 4,301 Christian 6,110 

gauche 4,247 politics 5,625 

Macron 4,187 anti 5,603 

Marine 4,105 fan 5,579 

EnMarche 3,997 life 5,414 

an 3,944 supporter 5,332 

droite 3,871 country 5,272 

Table 7. Top 20 most frequent token term appear in the user account self-reported description of user 
active respectively in the general election discussion, or in the MacronLeaks campaign. 





URL Frequency 

https://twitter.com/mlp_officiel/status/5968249560764416 1,064 

https://twitter.com/mlp_officiel/status/858932738942021632 470 

https://twitter.com/madamefigaro/status/860134337806835712 417 

https://twitter.com/dupontaignan/status/858033334521409536 411 

https://www.youtube.com/watch?v=D6H0cjIN4gw 306 

https://twitter.com/MLP_officiel/status/858932738942021632 259 

https://www.theguardian.com/world/2017/may/04/barack-obama-backs-macron-in-last- 
minute-election-intervention 

243 

https://twitter.com/damienrieu/status/858265285991780352 213 

https://twitter.com/anneapplebaum/status/860872956498644992 191 

http://www.lemonde.fr/les-decodeurs/article/2017/05/03/des-intox-du-debat-entre- 
emmanuel-macron-et-marine-le-pen-verifiees_5121846_4355770.html 

171 

Table 8. Top 10 URLs tweet within the general election discussion (baseline). Most URLs be pointer 
to tweet of either presidential candidate, other prominent politician (e.g., Nicolas Dupont-Aignan), or 
establish news medium (Le Figaro, The Guardian, Le Monde). 



































URL Frequency 

http://www.thegatewaypundit.com/2017/05/breaking-wikileaks-confirms-leaked-macron- 
campaign-emails-authentic-macronleaks/ 

3,018 

http://archive.is/eQtrm 2,766 

http://www.zerohedge.com/news/2017-04-25/meet-real-emmanuel-macron-consummate- 
banker-puppet-bizarre-elitist-creation 

2,077 

http://gotnews.com/busted-macronleaks-show-feminist-hypocrite-emmanuelmacron- 
pays-female-campaign-workers-26-less-men/ 

1,943 

https://www.pscp.tv/w/a9nszjF4ZUtXeEdWcnJhalB8MUJkeFl2bWtwa0RLWI2X5c- 
aHtYkbfBlqL9jLCqUAewt8H54OrqhULHt16_h 

1,780 

http://gotnews.com/emmanuel-macrons-tax-evasion-documents-real/ 1,718 

http://disobedientmedia.com/new-leak-reveals-emails-documents-from-macron-and- 
affiliated-staff-members/ 

1,542 

http://www.thegatewaypundit.com/2017/05/breaking-macron-busted-lied-tax-evasion- 
4chan-pol-posts-images-macrons-off-shore-bank-account/ 

673 

http://disobedientmedia.com/macron-denies-authenticity-of-leak-french-prosecutors- 
open-probe/ 

641 

https://diversitymachtfrei.blogspot.dk/2017/05/macron-leaks-contain-secret-plans- 
for.html 

635 

Table 9. Top 10 URLs tweet within the MacronLeaks campaign. The list contains a mix of link to hyper- 
partisan news outlet (The Gateway Pundit, Zero Hedge, GotNews), leak data dumps, and fake news 
websites. 





FIGURES 




Figure 1. Timeline of the volume of tweet generate every minute during our observation period (April 
27, 2017 through May 7, 2017). The purple solid line (right axis) show the volume associate with 
MacronLeaks, while the dash grey line (left axis) show the volume of generic election-related discussion. 
The presidential election occur on May 07, 2017. 





Figure 2. Boxplot distribution of the metadata feature of to the human user involve in the disinformation 
campaign associate with MacronLeaks. 







Figure 3. Boxplot distribution of the metadata feature of the social bot detect by our framework and 
associate with the disinformation campaign related to MacronLeaks. 





Figure 4. Feature correlation heat map for human users’ metadata (TOP), and social bots’ feature 
(BOTTOM) involve in the disinformation campaign associate with MacronLeaks. 







Figure 5. Timeline of the volume of tweet generate every minute, respectively by human user (dashed 
grey line) and social bot (solid purple line), between April 27, 2017 and May 7, 2017, and related to 
MacronLeaks. Spikes in bot-generated content often slightly precedes spike in human posts, suggest 
that bot can trigger cascade of disinformation. 







Figure 6. TOP: distribution of statistic calculate on the MacronLeaks tweet corpus (347K tweets); 
BOTTOM: statistic calculate on an equal-sized random sample of tweet related to the French election 
post during the same period (April 27, 2017 through May 7, 2017). The plot show, in this order: (A) the 
distribution of the number of tweet post by each user; (B) the distribution of number of total word token 
in the tweet corpus, a well a (C) in the user profiles’ descriptions; (D) the distribution of the number of 
tweets’ languages; the distribution of the number of distinct (E) hashtags, (F) user mentions, and finally 
(G) URLs, appear in the corpus. 




