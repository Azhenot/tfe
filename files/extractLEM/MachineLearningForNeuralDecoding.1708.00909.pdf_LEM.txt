









































Microsoft Word - decoding_arxiv.docx 


Machine 
learn 
for 
neural 
decode 




Joshua 
I. 
Glaser1,2*, 
Raeed 
H. 
Chowdhury3,4, 
Matthew 
G. 
Perich3,4, 
Lee 
E. 
Miller2-­‐4, 
and 
Konrad 
P. 

Kording2-­‐7 




1. Interdepartmental 
Neuroscience 
Program, 
Northwestern 
University, 
Chicago, 
IL, 
USA 


2. Department 
of 
Physical 
Medicine 
and 
Rehabilitation, 
Northwestern 
University 
and 
Shirley 
Ryan 
Ability 
Lab, 


Chicago, 
IL, 
USA 


3. Department 
of 
Physiology, 
Northwestern 
University, 
Chicago, 
IL, 
USA 

4. Department 
of 
Biomedical 
Engineering, 
Northwestern 
University, 
Chicago, 
IL, 
USA 

5. Department 
of 
Applied 
Mathematics, 
Northwestern 
University, 
Chicago, 
IL, 
USA 

6. Department 
of 
Neuroscience, 
University 
of 
Pennsylvania, 
Philadelphia, 
IL, 
USA 

7. Department 
of 
Biomedical 
Engineering, 
University 
of 
Pennsylvania, 
Philadelphia, 
IL, 
USA 


* 
Contact: 
j-­‐glaser@u.northwestern.edu 




Abstract: 

While 
machine 
learn 
tool 
have 
be 
rapidly 
advancing, 
the 
majority 
of 
neural 
decode 
approach 
still 

use 
last 
century’s 
methods. 
Improving 
the 
performance 
of 
neural 
decode 
algorithm 
allows 
u 
to 
good 

understand 
what 
information 
be 
contain 
in 
the 
brain, 
and 
can 
help 
advance 
engineering 
application 
such 

a 
brain 
machine 
interfaces. 
Here, 
we 
apply 
modern 
machine 
learn 
techniques, 
include 
neural 
network 

and 
gradient 
boosting, 
to 
decode 
from 
spike 
activity 
in 
1) 
motor 
cortex, 
2) 
somatosensory 
cortex, 
and 
3) 

hippocampus. 
We 
compare 
the 
predictive 
ability 
of 
these 
modern 
method 
with 
traditional 
decode 

method 
such 
a 
Wiener 
and 
Kalman 
filters. 
Modern 
methods, 
in 
particular 
neural 
network 
and 
ensembles, 

significantly 
outperform 
the 
traditional 
approaches. 
For 
instance, 
for 
all 
of 
the 
three 
brain 
areas, 
an 
LSTM 

decoder 
explain 
over 
40% 
of 
the 
unexplained 
variance 
from 
a 
Wiener 
filter. 

These 
result 
suggest 
that 

modern 
machine 
learn 
technique 
should 
become 
the 
standard 
methodology 
for 
neural 
decoding. 
We 

provide 
code 
to 
facilitate 
wider 
implementation 
of 
these 
methods. 





Introduction: 

Decoding 
be 
a 
critical 
tool 
for 
understand 
how 

neural 
signal 
relate 
to 
the 
outside 
world. 
It 
can 
be 

use 
to 
determine 
how 
much 
information 
the 
brain 

contains 
about 
an 
external 
variable 
(e.g. 
sensation 

or 
movement) 
[1-­‐3], 
and 
how 
this 
information 

differs 
across 
brain 
area 
[4-­‐6], 
experimental 

condition 
[7, 
8], 
disease 
state 
[9], 
and 
more. 
It 
be 

also 
useful 
in 
engineering 
contexts, 
such 
a 
for 
brain 

machine 
interface 
(BMIs), 
where 
signal 
from 

motor 
cortex 
be 
use 
to 
control 
computer 
cursor 

[10], 
robotic 
arm 
[11], 
and 
muscle 
[12]. 
Decoding 

be 
a 
central 
tool 
for 
neural 
data 
analysis. 



Because 
decode 
be 
simply 
a 
regression 
or 

classification 
problem, 
many 
method 
can 
be 
use 

for 
neural 
decoding. 
Despite 
the 
many 
recent 

advance 
in 
machine 
learn 
techniques, 
it 
be 
still 


very 
common 
to 
use 
traditional 
method 
such 
a 

linear 
regression. 
Using 
modern 
machine 
learn 

tool 
for 
neural 
decode 
would 
likely 
significantly 

boost 
performance, 
and 
might 
allow 
deeper 
insight 

into 
neural 
function. 



Here, 
we 
compare 
many 
different 
machine 
learn 

method 
to 
decode 
information 
from 
neural 
spike 

activity. 

We 
predict 
movement 
velocity 
from 

macaque 
motor 
cortex 
and 
sensorimotor 
cortex, 

and 
location 
in 
space 
from 
rat 
hippocampus. 
In 
all 

brain 
regions, 
modern 
methods, 
in 
particular 
neural 

network 
and 
ensembles, 
lead 
to 
the 
high 

accuracy 
decoding, 
even 
for 
limited 
amount 
of 

data. 

We 
provide 
code 
so 
that 
others 
can 
easily 
use 

all 
the 
decode 
method 
we 
tested. 











Methods: 



Tasks 
and 
brain 
regions: 


Decoding 
movement 
velocity 
from 
the 
motor 

cortex 
and 
somatosensory 
cortex: 
In 
our 

“random-­‐target” 
experiment 
[8], 
monkey 
move 
a 

planar 
manipulandum 
that 
control 
a 
cursor 
on 

the 
screen 
(Fig. 
1a). 
The 
monkey 
continuously 

reach 
to 
new 
target 
that 
be 
present 
with 
a 

brief 
hold 
period 
between 
reaches. 
After 
training, 

the 
monkey 
be 
surgically 
implant 
with 
96-­‐ 
channel 
Utah 
electrode 
array 
(Blackrock 

Microsystems, 
Salt 
Lake 
City, 
UT) 
to 
record 
the 

extracellular 
activity 
of 
cortical 
neurons. 
In 
one 

experiment 
[8], 
we 
record 
from 
both 
primary 

motor 
cortex 
(M1) 
and 
dorsal 
premotor 
cortex 

(PMd) 
and 
combine 
neuron 
from 
both 
areas. 
In 

another 
experiment 
we 
record 
from 
area 
2 
of 

primary 
somatosensory 
cortex 
(S1) 
[13]. 
From 
both 

brain 
regions, 
we 
aim 
to 
predict 
the 
x 
and 
y 

component 
of 
movement 
velocity. 
The 
record 

from 
motor 
cortex 
be 
21 
minutes, 
and 
contain 

164 
neurons. 
The 
mean 
and 
median 
fire 
rates, 

respectively, 
be 
6.7 
and 
3.4 
spike 
/ 
sec. 
The 

record 
from 
S1 
be 
51 
minutes, 
and 
contain 

52 
neurons. 
The 
mean 
and 
median 
fire 
rates, 

respectively, 
be 
9.3 
and 
6.3 
spike 
/ 
sec. 

Decoding 
position 
from 
the 
hippocampus: 
We 

use 
a 
dataset 
from 
CRCNS, 
in 
which 
rat 
chase 

reward 
on 
a 
square 
platform 
(Fig. 
1b) 
[14, 
15]. 

Extracellular 
recording 
be 
make 
from 
layer 
CA1 

of 
dorsal 
hippocampus 
(HC). 
We 
aim 
to 
predict 

the 
x 
and 
y 
position 
of 
the 
rat. 
The 
record 
from 

HC 
be 
93 
minutes, 
and 
contain 
58 
neurons. 
We 

exclude 
neuron 
with 
few 
than 
100 
spike 
over 

the 
duration 
of 
the 
experiment, 
result 
in 
46 

neurons. 
These 
neuron 
have 
mean 
and 
median 

fire 
rates, 
respectively, 
of 
1.7 
and 
0.2 
spike 
/ 
sec. 



General 
Decoding 
methods: 


Decoding 
movement 
velocity 
from 
the 
motor 

cortex 
and 
somatosensory 
cortex: 
We 
predict 

the 
average 
velocity 
(x 
and 
y 
components) 
in 
50 
m 

bins. 
Neural 
spike 
train 
use 
for 
decode 
be 

also 
put 
into 
50 
m 
bins. 
In 
motor 
cortex, 
we 
use 

700 
m 
of 
neural 
activity 
(13 
bin 
before 
and 
the 

concurrent 
bin) 
to 
predict 
the 
current 
movement 

velocities, 
a 
the 
primary 
interest 
be 
in 
investigate 

how 
motor 
cortex 
causally 
affect 
movement. 
In 

somatosensory 
cortex, 
we 
use 
650 
m 

surround 
the 
movement 
(6 
bin 
before, 
the 

concurrent 
bin, 
and 
6 
bin 
after), 
a 
neural 
activity 


have 
be 
show 
both 
precede 
and 
follow 

movement 
[16]. 

Decoding 
position 
from 
the 
hippocampus: 
We 

aim 
to 
predict 
the 
position 
(x 
and 
y 
coordinates) 

of 
the 
rat 
in 
200 
m 
bins. 
Neural 
spike 
train 
use 

for 
decode 
be 
also 
put 
into 
200 
m 
bins. 
We 

use 
2 
second 
of 
surround 
neural 
activity 
(4 

bin 
before, 
the 
concurrent 
bin, 
and 
5 
bin 
after) 
to 

predict 
the 
current 
position. 


Scoring 
Metric: 
To 
determine 
the 
goodness 
of 
fit, 


we 
use 


!! 

R2 =1− 
ŷ 
i 
− y 

i( ) 
2 

i 
∑ 

y 
i 
− y( )2 

i 
∑ 

, 
where 
!!ŷi 
be 
the 


predict 
values, 
!yi 
be 
the 
true 
value 
and 
!y 
be 

the 
mean 
value. 
This 
formulation 
of 
R2 
(which 
be 
the 

fraction 
of 
variance 
account 
for, 
rather 
than 
the 

Pearson’s 
correlation 
coefficient 
square 
[17]) 
can 

be 
negative 
on 
the 
test 
set 
due 
to 
overfitting 
on 
the 

training 
set. 
The 
report 
R2 
value 
be 
the 
average 

across 
the 
x 
and 
y 
component 
of 
velocity 
or 

position. 

Cross-­‐validation: 
When 
determine 
the 
R2 
for 

every 
method 
(Fig. 
3), 
we 
use 
10 
fold 
cross-­‐ 
validation. 
For 
each 
fold, 
we 
split 
the 
data 
into 
a 

training 
set 
(80% 
of 
data), 
a 
contiguous 
validation 

set 
(10% 
of 
data), 
and 
a 
contiguous 
test 
set 

(10% 
of 
data). 
For 
each 
fold, 
decoder 
be 
train 

to 
minimize 
the 
mean 
square 
error 
between 
the 

predict 
and 
true 
velocities/positions 
of 
the 

training 
data. 
We 
found 
the 
algorithm 

hyperparameters 
that 
lead 
to 
the 
high 
R2 
on 
the 

validation 
set 
use 
Bayesian 
optimization 
[18]. 

That 
is, 
we 
fit 
many 
model 
on 
the 
training 
set 
with 

different 
hyperparameters 
and 
calculate 
the 
R2 
on 

the 
validation 
set. 
Then, 
use 
the 
hyperparameters 

that 
lead 
to 
the 
high 
validation 
set 
R2, 
we 

calculate 
the 
R2 
value 
on 
the 
test 
set. 
Error 
bar 

on 
the 
test 
set 
R2 
value 
be 
compute 
across 

cross-­‐validation 
folds. 

Bootstrapping: 
When 
determine 
how 

performance 
scale 
a 
function 
of 
data 
size 
(Fig. 
5), 

we 
use 
a 
single 
test 
set 
and 
validation 
set, 
and 

vary 
amount 
of 
training 
data 
that 
directly 

precede 
the 
validation 
set. 

The 
test 
and 
validation 

set 
be 
5 
minute 
long 
for 
motor 
and 

somatosensory 
cortices, 
and 
7.5 
minute 
for 

hippocampus. 
To 
get 
error 
bars, 
we 
resampled 
from 

the 
test 
set. 
Because 
of 
the 
high 
correlation 
between 

temporally 
adjacent 
samples, 
we 
didn’t 
resample 




randomly 
from 
all 
example 
(which 
would 
create 

highly 
correlate 
resamples). 
Instead, 
we 
separate 

the 
test 
set 
into 
20 
temporally 
distinct 
subsets, 
S1-­‐ 
S20 
(i.e., 
S1 
be 
from 
t=1 
to 
t=T/20, 
S2 
be 
from 
t=T/20 

to 
t=2T/20, 
etc., 
where 
T 
be 
the 
end 
time), 
that 
be 

more 
nearly 
independent 
of 
each 
other. 
We 
then 

resampled 
combination 
of 
these 
20 
subset 
(e.g. 
S5, 

S13, 
… 
S2) 
1000 
time 
to 
get 
confidence 
interval 
of 

R2 
values. 

Preprocessing: 
The 
training 
input 
be 
normalize 

(z-­‐scored). 
The 
training 
output 
be 
zero-­‐centered 

(mean 
subtracted), 
except 
in 
support 
vector 

regression, 
where 
the 
output 
be 
z-­‐scored. 
The 

validation/testing 
input 
and 
output 
be 

preprocessed 
use 
the 
preprocessing 
parameter 

from 
the 
training 
set. 



Specific 
Decoders: 

Kalman 
Filter: 
In 
the 
Kalman 
filter, 
the 
hidden 

state 
at 
time 
t 
be 
a 
linear 
function 
of 
the 
hidden 
state 

at 
time 
t-­‐1, 
plus 
a 
matrix 
characterize 
the 

uncertainty. 

The 
observation 
(measurement) 
at 

time 
t 
be 
a 
linear 
function 
of 
the 
hidden 
state 
at 
time 

t 
(plus 
noise). 
At 
every 
time 
point, 
to 
update 
the 

estimate 
hidden 
state, 
the 
update 
derive 
from 

the 
current 
measurement 
and 
the 
previous 
hidden 

state 
be 
combined. 
During 
this 
combination, 
the 

noise 
matrix 
give 
a 
high 
weight 
to 
the 
less 

uncertain 
information. 
We 
use 
a 
Kalman 
filter 

similar 
to 
that 
implement 
in 
[19]. 
In 
the 
Kalman 

filter, 
the 
measurement 
be 
the 
neural 
spike 
trains, 

and 
the 
hidden 
state 
be 
the 
kinematics 
(x 
and 
y 

component 
of 
position, 
velocity, 
and 
acceleration). 

We 
have 
one 
hyperparameter 
which 
differ 
from 

the 
implementation 
in 
[19]. 
This 
parameter 

determine 
the 
noise 
matrix 
associate 
with 
the 

transition 
in 
kinematic 
state 
(Q 
in 
[19]). 
We 

divide 
the 
empirical 
noise 
matrix 
of 
training 
data 

(used 
in 
[19]) 
by 
the 
hyperparameter 
scalar 
C. 

The 

rationale 
for 
this 
addition 
be 
that 
neuron 
have 

temporal 
correlations, 
which 
make 
it 
desirable 
to 

have 
a 
parameter 
that 
allows 
change 
the 
weight 

of 
the 
new 
neural 
evidence. 

Interestingly, 
the 

introduction 
of 
this 
parameter 
make 
a 
big 

difference 
for 
the 
hippocampus 
dataset 
(Fig. 
S1). 

We 
also 
allow 
for 
a 
lag 
between 
the 
neural 
data 

and 
predict 
kinematics. 
The 
lag 
and 

hyperparameter 
be 
determine 
base 
on 

validation 
set 
performance. 


Wiener 
Filter: 
The 
Wiener 
filter 
us 
multiple 

linear 
regression 
to 
predict 
the 
output 
from 

multiple 
time 
bin 
of 
every 
neurons’ 
spikes. 
That 
is, 

the 
output 
be 
assume 
to 
be 
a 
linear 
mapping 
of 
the 


number 
of 
spike 
in 
the 
relevant 
time 
bin 
from 

every 
neuron 
(Fig. 
1c,d). 
Here, 
separate 
model 

be 
use 
to 
predict 
the 
x 
and 
y 
component 
of 
the 

kinematics. 

Wiener 
Cascade: 
The 
Wiener 
cascade 
(also 
know 

a 
a 
linear 
nonlinear 
model) 
fit 
a 
linear 
regression 

(the 
Wiener 
filter) 
follow 
by 
a 
fit 
static 

nonlinearity 
(e.g. 
[20]). 
This 
allows 
for 
a 
nonlinear 

relationship 
between 
the 
input 
and 
the 
output, 
and 

assumes 
that 
this 
nonlinearity 
be 
purely 
a 
function 

of 
the 
linear 
output. 
Here, 
a 
in 
the 
Wiener 
Filter, 

the 
input 
be 
neurons’ 
spike 
rate 
over 
relevant 

time 
bins. 
The 
nonlinear 
component 
be 
a 

polynomial 
with 
degree 
determine 
on 
the 

validation 
set. 
Separate 
model 
be 
use 
to 

predict 
the 
x 
and 
y 
component 
of 
the 
kinematics. 

Support 
Vector 
Regression: 
In 
support 
vector 

machine 
regression 
(SVR) 
[21], 
the 
input 
be 

project 
into 
a 
high 
dimensional 
space 
use 
a 

nonlinear 
kernel, 
and 
then 
linearly 
mapped 
from 

this 
space 
to 
the 
output 
to 
minimize 
an 
objective 

function 
[21]. 
Here, 
we 
use 
standard 
support 

vector 
regression 
(SVR) 
with 
a 
radial 
basis 
function 

kernel 
to 
predict 
the 
kinematics 
from 
the 
neurons’ 

spike 
rate 
in 
each 
bin. 
We 
set 
hyperparameters 
for 

the 
penalty 
of 
the 
error 
term 
and 
the 
maximum 

number 
of 
iterations. 
Separate 
model 
be 
use 
to 

predict 
the 
x 
and 
y 
component 
of 
the 
kinematics. 

XGBoost: 
XGBoost 
(Extreme 
Gradient 
Boosting) 

[22] 
be 
an 
implementation 
of 
gradient 
boost 
trees. 

For 
the 
regression 
problem, 
gradient 
boost 
fit 

many 
regression 
trees. 
Each 
subsequent 
regression 

tree 
be 
fit 
to 
the 
residual 
of 
the 
previous 
fit. 

Regression 
tree 
create 
nonlinear 
mapping 
from 

the 
input 
to 
output. 
Here, 
we 
use 
the 
XGBoost 
to 

predict 
the 
kinematics 
from 
the 
neurons’ 
spike 

rate 
in 
each 
bin. 
We 
set 
hyperparameters 
for 
the 

maximum 
depth 
of 
the 
tree, 
number 
of 
trees, 
and 

learn 
rate. 
Separate 
model 
be 
use 
to 
predict 

the 
x 
and 
y 
component 
of 
the 
kinematics. 

Feedforward 
Neural 
Network: 
A 
feedforward 

neural 
net 
connects 
the 
input 
to 
sequential 
layer 

of 
hidden 
unit 
via 
linear 
mapping 
follow 
by 

output 
nonlinearities. 
This 
can 
allow 
for 
mapping 

complex 
nonlinear 
function 
from 
input 
to 
output. 

Here, 
use 
the 
Keras 
library 
[23], 
we 
create 
a 
fully 

connect 
(dense) 
feedforward 
neural 
network 

with 
2 
hidden 
layer 
and 
rectify 
linear 
unit 


activation 
after 
each 
hidden 
layer. 
We 
require 
the 

number 
of 
hidden 
unit 
in 
each 
layer 
to 
be 
the 

same. 
We 
set 
hyperparameters 
for 
the 
number 
of 

hidden 
unit 
in 
the 
layers, 
amount 
of 
dropout 
[24], 

and 
number 
of 
training 
epochs. 
We 
use 
the 
Adam 




algorithm 
[25] 
a 
the 
optimization 
routine. 
This 

neural 
network, 
and 
all 
neural 
network 
below 
have 

2 
output 
units. 
That 
is, 
the 
same 
network 
predict 

the 
x 
and 
y 
component 
rather 
than 
there 
be 
2 

separate 
networks. 
The 
input 
be 
still 
the 
number 

of 
spike 
in 
each 
bin 
from 
every 
neuron. 
Note 
that 

we 
refer 
to 
feedforward 
neural 
network 
a 
a 

“modern” 
technique, 
despite 
their 
have 
be 

around 
for 
many 
decades, 
due 
to 
their 
current 

resurgence 
and 
the 
modern 
method 
for 
training 

the 
networks. 

Simple 
RNN: 
In 
a 
standard 
recurrent 
neural 

network 
(RNN), 
the 
hidden 
state 
be 
a 
linear 

combination 
of 
the 
input 
and 
the 
previous 
hidden 

state. 
This 
hidden 
state 
be 
then 
run 
through 
an 

output 
nonlinearity, 
and 
linearly 
mapped 
to 
the 

output. 
RNNs, 
unlike 
feedforward 
neural 
networks, 

allow 
temporal 
change 
in 
the 
system 
to 
be 

model 
explicitly. 
Here, 
use 
the 
Keras 
library 

[23], 
we 
create 
a 
neural 
network 
architecture 

where 
the 
spike 
input 
from 
all 
neuron 
be 
fed 

into 
a 
standard 
recurrent 
neural 
network 
(Fig. 
1e). 

The 
unit 
from 
this 
recurrent 
layer 
be 
fed 

through 
a 
rectify 
linear 
unit 
nonlinearities, 
and 

fully 
connect 
to 
an 
output 
layer 
with 
2 
unit 
(x 

and 
y 
velocity 
or 
position 
components). 
We 
set 

hyperparameters 
for 
the 
number 
of 
units, 
amount 


of 
dropout, 
and 
number 
of 
training 
epochs. 
We 
use 

RMSprop 
[26] 
a 
the 
optimization 
routine. 

Gated 
Recurrent 
Unit: 
Gated 
recurrent 
unit 

(GRUs) 
[27] 
be 
a 
more 
complex 
type 
of 
recurrent 

neural 
network. 
It 
have 
gate 
units, 
which 
in 
practice 

allow 
for 
good 
learn 
of 
long-­‐term 
dependencies. 

For 
implementation, 
all 
method 
be 
the 
same 
a 

for 
the 
“Simple 
RNN”, 
except 
Gated 
Recurrent 
Units 

be 
use 
rather 
than 
a 
traditional 
RNN. 


Long 
Short 
Term 
Memory 
Network: 
Like 
the 
GRU, 

the 
long 
short 
term 
memory 
(LSTM) 
network 
[28] 

be 
a 
more 
complex 
recurrent 
neural 
network 
with 

gate 
unit 
that 
allow 
long-­‐term 
dependency 
to 
be 

capture 
better. 
The 
LSTM 
have 
more 
parameter 

than 
the 
GRU. 
For 
implementation, 
all 
method 

be 
the 
same 
a 
for 
the 
“Simple 
RNN”, 
except 

LSTMs 
be 
used. 


Ensemble: 
Ensemble 
method 
combine 
the 

prediction 
from 
several 
other 
methods, 
and 
thus 

have 
the 
potential 
to 
leverage 
the 
different 
benefit 

of 
the 
method 
contain 
within 
the 
ensemble. 

Here, 
use 
the 
prediction 
from 
all 
decoder 
except 

the 
Kalman 
filter 
(which 
have 
a 
different 
format) 
a 

inputs, 
we 
predict 
the 
output 
use 
the 

feedforward 
neural 
network 
described 
above. 


Code: 
Python 
code 
for 
all 
method 
be 
available 
at 

https://github.com/KordingLab/Neural_Decoding 












Figure 
1: 
Tasks 
and 
Decoding 
Schematic 

a) 
In 
the 
task 
for 
decode 
from 
motor 
and 
somatosensory 
cortices, 
monkey 
move 
a 
planar 
manipulandum 
that 

control 
a 
cursor 
on 
the 
screen. 
The 
monkey 
continuously 
reach 
to 
new 
target 
that 
be 
presented, 
with 
a 
brief 

hold 
period 
between 
reach 
[8]. 
b) 
In 
the 
task 
for 
decode 
from 
hippocampus, 
rat 
chase 
reward 
on 
a 
square 

platform. 
c) 
To 
decode 
(predict) 
the 
output 
in 
a 
give 
time 
bin, 
we 
use 
the 
fire 
rate 
of 
all 
N 
neuron 
in 
B 
time 
bins. 

In 
this 
schematic, 
N=4 
and 
B=3 
(one 
bin 
precede 
the 
output, 
one 
concurrent 
bin, 
and 
one 
follow 
bin). 
In 
our 
data, 

we 
predict 
two 
output 
from 
each 
brain 
region 
(x 
and 
y 
component 
of 
velocity 
from 
motor 
and 
somatosensory 

cortex, 
and 
x 
and 
y 
component 
of 
position 
from 
hippocampus). 
For 
each 
region, 
the 
number 
of 
neuron 
and 
time 
bin 




use 
for 
decode 
be 
described 
in 
Methods. 
Also, 
note 
that 
this 
schematic 
do 
not 
apply 
for 
the 
Kalman 
Filter 
decoder. 


d) 
For 
the 
non-­‐recurrent 
decoder 
(Wiener 
Filter, 
Wiener 
Cascade, 
Support 
Vector 
Regression, 
XGBoost, 
and 

Feedforward 
Neural 
Network), 
this 
be 
a 
standard 
machine 
learn 
regression 
problem 
where 
N 
x 
B 
feature 
(the 
fire 

rate 
of 
each 
neuron 
in 
each 
relevant 
time 
bin) 
be 
use 
to 
predict 
the 
output. 
e) 
For 
the 
recurrent 
decoder 
(simple 

recurrent 
neural 
network, 
GRUs, 
LSTMs), 
to 
predict 
an 
output, 
we 
use 
N 
features, 
with 
temporal 
connection 
across 
B 

bins. 
A 
schematic 
of 
a 
recurrent 
neural 
network 
predict 
a 
single 
output 
be 
on 
the 
right. 





Results 



We 
investigate 
how 
the 
choice 
of 
machine 
learn 

technique 
affect 
decode 
performance 
(Fig. 
1) 

use 
a 
plethora 
of 
common 
machine 
learn 

methods. 
These 
range 
from 
historical 
linear 

technique 
(e.g., 
the 
Wiener 
filter) 
to 
modern 

machine 
learn 
technique 
(e.g., 
neural 
network 

and 
ensemble 
of 
techniques). 
We 
test 
the 

performance 
of 
all 
these 
technique 
across 
datasets 

from 
motor 
cortex, 
somatosensory 
cortex, 
and 

hippocampus. 



We 
aim 
to 
understand 
the 
performance 
of 
the 

method 
when 
fit 
to 
neural 
data. 
First, 
in 
order 
to 

get 
a 
qualitative 
impression 
of 
the 
performance, 
we 

plot 
the 
output 
of 
each 
decode 
method 
for 

each 
of 
the 
three 
datasets 
(Fig. 
2). 
In 
these 

examples, 
the 
modern 
methods, 
such 
a 
the 
LSTM 

and 
ensemble, 
appear 
to 
outperform 
traditional 

methods, 
such 
a 
the 
Wiener 
and 
Kalman 
filters, 
a 

the 
prediction 
be 
slightly 
closer 
to 
the 
true 

output. 
Next, 
we 
quantitatively 
compare 
the 

methods. 
In 
all 
three 
brain 
areas, 
modern 
machine 

learn 
method 
outperform 
traditional 

decode 
method 
(Fig. 
3). 
In 
particular, 
neural 

network 
and 
the 
ensemble 
lead 
to 
the 
best 

performance, 
while 
the 
Wiener 
or 
Kalman 
Filter 
lead 

to 
the 
bad 
performance. 
In 
fact, 
the 
LSTM 
decoder 

explain 
over 
40% 
of 
the 
unexplained 
variance 

from 
a 
Wiener 
filter 
(R2’s 
of 
0.88, 
0.86, 
0.62 
vs. 
0.78, 

0.75, 
0.35). 
Additionally, 
the 
feedforward 
neural 


network 
do 
almost 
a 
well 
a 
the 
LSTM 
in 
all 
brain 

areas. 
Across 
cases, 
the 
ensemble 
method 
add 
a 

reliable, 
but 
small 
increase 
to 
the 
explain 

variance. 
Modern 
machine 
learn 
method 
lead 
to 

significant 
increase 
in 
predictive 
power. 



While 
modern 
machine 
learn 
method 
yield 

the 
best 
performance 
on 
our 
full 
datasets, 
it 
be 

possible, 
because 
of 
their 
great 
complexity, 
that 

they 
would 
not 
work 
well 
with 
less 
data. 
Thus, 
we 

test 
the 
feedforward 
neural 
network 
and 
LSTM 

(two 
modern 
method 
that 
work 
particularly 

well), 
along 
with 
the 
Wiener 
and 
Kalman 
filters, 
on 

vary 
amount 
of 
data. 
Even 
with 
limited 
data, 
the 

modern 
method 
work 
very 
well. 
With 
only 
2 

minute 
of 
training 
data 
for 
motor 
and 

somatosensory 
cortices, 
and 
15 
minute 
of 

hippocampus 
data, 
both 
modern 
method 

outperform 
both 
traditional 
method 
(Fig. 
4,5). 


When 
decrease 
the 
amount 
of 
training 
data 

further, 
to 
only 
1 
minute 
for 
motor 
and 

somatosensory 
cortex 
and 
7.5 
minute 
for 

hippocampus 
data, 
the 
Kalman 
filter 
sometimes 

perform 
comparably 
to 
the 
modern 
methods. 

Still, 
the 
modern 
method 
significantly 

outperform 
the 
Wiener 
Filter 
(Fig. 
5). 
Thus, 
even 

for 
limited 
data, 
modern 
machine 
learn 
method 

can 
yield 
significant 
gain 
in 
decode 
performance. 











Figure 
2: 
Example 
Decoder 
Results 

Example 
decode 
result 
from 
motor 
cortex 
(left), 
somatosensory 
cortex 
(middle), 
and 
hippocampus 
(right), 
for 
all 
ten 

method 
(top 
to 
bottom). 
Ground 
truth 
trace 
be 
in 
black, 
while 
decoder 
result 
be 
in 
various 
colors. 













Figure 
3: 
Decoder 
Result 
Summary 

R2 
value 
be 
report 
for 
all 
decoder 
(different 
colors) 
for 
each 
brain 
area 
(top 
to 
bottom). 
Error 
bar 
represent 
the 

mean 
+/-­‐ 
SEM 
across 
cross-­‐validation 
folds. 
X’s 
represent 
the 
R2 
value 
of 
each 
cross-­‐validation 
fold. 

Note 
the 
different 

y-­‐axis 
limit 
for 
the 
hippocampus 
dataset. 











Figure 
4: 
Example 
result 
with 
limited 
training 
data 

Using 
only 
2 
minute 
of 
training 
data 
for 
motor 
cortex 
and 
somatosensory 
cortex, 
and 
15 
minute 
of 
training 
data 
for 

hippocampus, 
we 
train 
two 
traditional 
method 
(Wiener 
filter 
and 
Kalman 
filter), 
and 
two 
modern 
method 

(feedforward 
neural 
network 
and 
LSTM). 
Example 
decode 
result 
be 
show 
from 
motor 
cortex 
(left), 
somatosensory 

cortex 
(middle), 
and 
hippocampus 
(right), 
for 
these 
method 
(top 
to 
bottom). 
Ground 
truth 
trace 
be 
in 
black, 
while 

decoder 
result 
be 
in 
the 
same 
color 
a 
previous 
figures. 










Figure 
5: 
Decoder 
result 
with 
vary 
amount 
of 
training 
data 

Using 
vary 
amount 
of 
training 
data, 
we 
train 
two 
traditional 
method 
(Wiener 
filter 
and 
Kalman 
filter), 
and 
two 

modern 
method 
(feedforward 
neural 
network 
and 
LSTM). 
R2 
value 
be 
report 
for 
these 
decoder 
(different 
colors) 

for 
each 
brain 
area 
(top 
to 
bottom). 
Error 
bar 
be 
68% 
confidence 
interval 
(meant 
to 
approximate 
the 
SEM) 
produce 

via 
bootstrapping, 
a 
we 
use 
a 
single 
test 
set. 
Values 
with 
negative 
R2s 
be 
not 
shown. 
Also 
note 
the 
different 
y-­‐axis 

limit 
for 
the 
hippocampus 
dataset. 









Discussion: 

Here 
we 
test 
the 
performance 
of 
a 
large 
number 

of 
decode 
technique 
on 
three 
different 
neural 

decode 
problems. 
We 
found 
that, 
across 
datasets, 

neural 
network 
outperform 
traditional 
methods. 

An 
ensemble 
method 
provide 
only 
minor 

additional 
predictive 
power. 
The 
strong 

performance 
of 
neural 
network 
even 
persist 
for 

small 
datasets 
with 
a 
little 
a 
one 
minute 
of 

training 
data. 




We 
find 
it 
particularly 
interest 
that 
the 
neural 

network 
method 
work 
so 
well 
with 
limited 
data, 

which 
be 
counter 
to 
the 
common 
perception. 
We 

believe 
the 
explanation 
be 
simply 
the 
size 
of 

networks. 
For 
instance, 
our 
network 
have 
on 
the 

order 
of 
100 
thousand 
parameters, 
while 
common 

network 
for 
image 
classification 
(e.g. 
[29]) 
can 

have 
on 
the 
order 
of 
100 
million 
parameters. 
Thus, 

the 
reasonable 
size 
of 
our 
network 
(hundreds 
of 

hidden 
units) 
likely 
allow 
for 
excellent 
prediction 

with 
limited 
data 
[30]. 



It 
be 
also 
intrigue 
that 
the 
feedforward 
neural 

network 
do 
almost 
a 
well 
a 
the 
LSTM 
and 
good 

than 
the 
standard 
RNN, 
consider 
the 
recent 

attention 
to 
treat 
the 
brain 
a 
a 
dynamical 

system 
[31]. 
For 
the 
motor 
and 
somatosensory 

cortex 
decoding, 
it 
be 
possible 
that 
the 
highly 

train 
monkey 
yield 
a 
stereotype 
temporal 

relationship 
between 
neural 
activity 
and 
movement 

that 
a 
feedforward 
neural 
network 
could 
effectively 

capture. 
It 
would 
be 
interest 
to 
compare 
the 

performance 
of 
feedforward 
and 
recurrent 
neural 

network 
on 
less 
constrain 
behavior. 




In 
order 
to 
find 
the 
best 
hyperparameters 
for 
the 

decode 
algorithms, 
we 
use 
a 
Bayesian 

optimization 
routine 
[18] 
to 
search 
the 

hyperparameter 
space 
(see 
Methods). 
Still, 
it 
be 

possible 
that 
some 
of 
the 
decode 
algorithm 
do 

not 
use 
the 
optimal 
hyperparameters, 
which 
could 

have 
lower 
overall 
accuracy. 
Moreover, 
for 

several 
method 
we 
do 
not 
fit 
all 
available 

hyperparameters. 
We 
do 
this 
in 
order 
to 
simplify 

the 
use 
of 
these 
methods, 
in 
order 
to 
decrease 

computational 
runtime 
during 
hyperparameter 

optimization, 
and 
because 
add 
additional 

hyperparameters 
do 
not 
appear 
to 
improve 

accuracy. 
For 
example, 
for 
the 
neural 
net 
we 
use 

dropout 
but 
not 
L1 
or 
L2 
regularization, 
and 
for 

XGBoost 
we 
use 
less 
than 
half 
the 
available 


hyperparameters 
for 
avoid 
overfitting. 
While 
our 

preliminary 
test 
with 
additional 

hyperparameters 
do 
not 
appear 
to 
significantly 

change 
the 
results, 
it 
be 
possible 
that 
we 
have 
not 

achieve 
optimal 
performance 
of 
our 
methods. 



While 
we 
have 
test 
standard 
algorithm 
on 
three 

different 
datasets, 
it 
be 
possible 
that 
the 
relative 

performance 
of 
algorithm 
differs 
on 
other 
datasets. 

However, 
many 
datasets 
in 
neuroscience 
share 

basic 
property 
with 
those 
we 
used. 
Most 
be 

similar 
in 
length 
(tens 
of 
minute 
to 
a 
couple 

hours), 
simply 
because 
the 
length 
of 
a 
record 

session 
be 
usually 
limited 
by 
both 
the 
patience 
of 
the 

animal 
and 
the 
experimentalist. 
Moreover, 
most 

variable 
of 
interest 
have 
similar 
relevant 

timescales, 
where 
movement, 
speech, 
vision, 
and 

many 
other 
phenomenon 
unfold 
on 
a 
timescale 
of 

hundred 
of 
millisecond 
to 
seconds. 
We 
thus 

expect 
that 
similar 
result 
would 
be 
obtain 
for 

other 
spike 
datasets. 



We 
have 
decode 
from 
spike 
data, 
but 
it 
be 

possible 
that 
the 
problem 
of 
decode 
from 
other 

data 
modality 
be 
different. 
One 
main 
driver 
of 
a 

difference 
may 
be 
the 
distinct 
level 
of 
noise. 
For 

example, 
fMRI 
signal 
have 
far 
high 
noise 
level 

than 
spikes. 
As 
the 
noise 
level 
go 
up, 
linear 

technique 
become 
more 
appropriate, 
which 
may 

ultimately 
lead 
to 
a 
situation 
where 
the 
traditional 

linear 
technique 
become 
superior. 
Applying 
the 

same 
analysis 
we 
do 
here 
across 
different 
data 

modality 
be 
an 
important 
next 
step. 



All 
our 
decode 
be 
do 
“offline,” 
meaning 
that 

the 
decode 
occur 
after 
the 
recording, 
and 
be 

not 
part 
of 
a 
control 
loop. 
This 
type 
of 
decode 
be 

useful 
for 
determine 
how 
information 
in 
a 

particular 
brain 
area 
relates 
to 
an 
external 
variable. 

However, 
for 
engineering 
application 
such 
a 
BMIs 

[32, 
33], 
the 
goal 
be 
to 
decode 
information 
(e.g., 

predict 
movements) 
in 
real 
time. 
Our 
result 
here 

may 
not 
apply 
a 
directly 
to 
online 
decode 

situations, 
since 
the 
subject 
be 
ultimately 
able 
to 

adapt 
to 
imperfection 
in 
the 
decoder. 
In 
that 
case, 

even 
relatively 
large 
decoder 
performance 

difference 
may 
be 
irrelevant. 
An 
additional 

challenge 
for 
online 
application 
be 
computational 

runtime, 
which 
we 
have 
not 
address 
here. 
In 
the 

future, 
it 
would 
be 
valuable 
to 
test 
modern 
machine 




learn 
technique 
for 
decode 
in 
online 

application 
(as 
in 
[34]). 



While 
modern 
machine 
learn 
method 
provide 

an 
increase 
in 
decode 
accuracy, 
it 
be 
important 
to 

be 
careful 
with 
the 
scientific 
interpretation 
of 

decode 
results. 
Decoding 
can 
tell 
u 
how 
much 

information 
a 
neural 
population 
have 
about 
a 

variable 
X. 
However, 
high 
decode 
accuracy 
do 

not 
mean 
that 
a 
brain 
area 
be 
directly 
involve 
in 

processing 
X, 
or 
that 
X 
be 
the 
purpose 
of 
the 
brain 

area. 
For 
example, 
with 
a 
powerful 
decoder, 
it 
could 

be 
possible 
to 
accurately 
classify 
image 
base 
on 

recording 
from 
the 
retina, 
since 
the 
retina 
have 

information 
about 
all 
visual 
space. 
However, 
this 

do 
not 
mean 
that 
the 
primary 
purpose 
of 
the 

retina 
be 
image 
classification. 
Moreover, 
even 
if 
the 

neural 
signal 
come 
before 
the 
external 
variable, 
it 

do 
not 
mean 
that 
it 
be 
causally 
involved. 
For 

example, 
information 
could 
be 
in 
somatosensory 

cortex 
prior 
to 
movement 
due 
to 
an 
efference 
copy 

from 
M1. 
Thus, 
researcher 
should 
constrain 

interpretation 
to 
be 
about 
the 
information 
in 

neural 
populations, 
and 
how 
it 
may 
vary 
across 

brain 
regions, 
experimental 
conditions, 
or 
time 

intervals. 



We 
decode 
continuous 
value 
variables. 
The 
same 

method 
can 
be 
use 
for 
classification 
tasks, 
which 

often 
use 
classic 
decoder 
such 
a 
logistic 

regression 
and 
support 
vector 
machines. 
While 


here 
we 
have 
not 
demonstrate 
the 
benefit 
of 

modern 
machine 
learn 
method 
for 

classification, 
our 
available 
code 
can 
easily 
be 

modify 
to 
allow 
user 
to 
do 
classification. 



Neural 
engineering 
have 
a 
history 
of 
develop 

specialized 
algorithm 
meant 
to 
increase 
the 

performance 
of 
decoder 
[35-­‐37]. 
However, 
these 

algorithm 
be 
not 
typically 
test 
against 
state 
of 

the 
art 
machine 
learn 
algorithms. 
Along 
with 
this 

manuscript, 
we 
have 
release 
a 
package 
to 
do 

neural 
decode 
use 
all 
the 
described 
methods, 

make 
it 
be 
easy 
to 
compare 
with 
any 
new 

algorithm. 
Our 
hunch 
be 
that 
it 
will 
be 
hard 
for 

specialized 
algorithm 
to 
compete 
with 
the 

standard 
algorithm 
developed 
by 
a 
massive 

community 
in 
machine 
learning. 





Acknowledgements: 

We 
would 
like 
to 
thank 
Pavan 
Ramkumar 
for 
help 

with 
code 
development. 
For 
funding, 
JG 
would 
like 

to 
thank 
NIH 
F31 
EY025532 
and 
NIH 
T32 

HD057845. 
MP 
would 
like 
to 
thank 
NIH 
F31 

NS092356 
and 
NIH 
T32 
HD07418. 
RC 
would 
like 
to 

thank 
NIH 
R01 
NS095251 
and 
DGE-­‐1324585. 
LM 

would 
like 
to 
thank 
NIH 
R01 
NS074044 
and 
NIH 

R01 
NS095251. 
KK 
would 
like 
to 
thank 
NIH 
R01 

NS074044, 
NIH 
R01 
NS063399 
and 
NIH 
R01 

EY021579. 













References 




1. 
Raposo 
D, 
Kaufman 
MT, 
Churchland 
AK. 
A 
category-­‐free 
neural 
population 
support 
evolve 
demand 
during 

decision-­‐making. 
Nature 
neuroscience. 
2014;17(12):1784-­‐92. 

2. 
Rich 
EL, 
Wallis 
JD. 
Decoding 
subjective 
decision 
from 
orbitofrontal 
cortex. 
Nature 
neuroscience. 

2016;19(7):973-­‐80. 

3. 
Hung 
CP, 
Kreiman 
G, 
Poggio 
T, 
DiCarlo 
JJ. 
Fast 
readout 
of 
object 
identity 
from 
macaque 
inferior 
temporal 

cortex. 
Science. 
2005;310(5749):863-­‐6. 

4. 
Quiroga 
RQ, 
Snyder 
LH, 
Batista 
AP, 
Cui 
H, 
Andersen 
RA. 
Movement 
intention 
be 
good 
predict 
than 
attention 

in 
the 
posterior 
parietal 
cortex. 
J 
Neurosci. 
2006;26(13):3615-­‐20. 

5. 
Hernández 
A, 
Nácher 
V, 
Luna 
R, 
Zainos 
A, 
Lemus 
L, 
Alvarez 
M, 
et 
al. 
Decoding 
a 
perceptual 
decision 
process 

across 
cortex. 
Neuron. 
2010;66(2):300-­‐14. 

6. 
van 
der 
Meer 
MA, 
Johnson 
A, 
Schmitzer-­‐Torbert 
NC, 
Redish 
AD. 
Triple 
dissociation 
of 
information 
processing 
in 

dorsal 
striatum, 
ventral 
striatum, 
and 
hippocampus 
on 
a 
learn 
spatial 
decision 
task. 
Neuron. 
2010;67(1):25-­‐32. 

7. 
Dekleva 
BM, 
Ramkumar 
P, 
Wanda 
PA, 
Kording 
KP, 
Miller 
LE. 
Uncertainty 
lead 
to 
persistent 
effect 
on 
reach 

representation 
in 
dorsal 
premotor 
cortex. 
eLife. 
2016;5:e14316. 
doi: 
10.7554/eLife.14316. 

8. 
Glaser 
JI, 
Perich 
MG, 
Ramkumar 
P, 
Miller 
LE, 
Kording 
KP. 
Population 
Coding 
Of 
Conditional 
Probability 

Distributions 
In 
Dorsal 
Premotor 
Cortex. 
bioRxiv. 
2017:137026. 

9. 
Weygandt 
M, 
Blecker 
CR, 
Schäfer 
A, 
Hackmack 
K, 
Haynes 
J-­‐D, 
Vaitl 
D, 
et 
al. 
fMRI 
pattern 
recognition 
in 

obsessive–compulsive 
disorder. 
Neuroimage. 
2012;60(2):1186-­‐93. 

10. 
Serruya 
MD, 
Hatsopoulos 
NG, 
Paninski 
L, 
Fellows 
MR, 
Donoghue 
JP. 
Brain-­‐machine 
interface: 
Instant 
neural 

control 
of 
a 
movement 
signal. 
Nature. 
2002;416(6877):141-­‐2. 

11. 
Collinger 
JL, 
Wodlinger 
B, 
Downey 
JE, 
Wang 
W, 
Tyler-­‐Kabara 
EC, 
Weber 
DJ, 
et 
al. 
High-­‐performance 

neuroprosthetic 
control 
by 
an 
individual 
with 
tetraplegia. 
The 
Lancet. 
2013;381(9866):557-­‐64. 

12. 
Ethier 
C, 
Oby 
ER, 
Bauman 
MJ, 
Miller 
LE. 
Restoration 
of 
grasp 
follow 
paralysis 
through 
brain-­‐controlled 

stimulation 
of 
muscles. 
Nature. 
2012;485(7398):368-­‐71. 
doi: 
10.1038/nature10987. 
PubMed 
PMID: 
22522928; 

PubMed 
Central 
PMCID: 
PMCPMC3358575. 

13. 
Benjamin 
AS, 
Fernandes 
HL, 
Tomlinson 
T, 
Ramkumar 
P, 
VerSteeg 
C, 
Miller 
L, 
et 
al. 
Modern 
machine 
learn 
far 

outperforms 
GLMs 
at 
predict 
spikes. 
bioRxiv. 
2017:111450. 

14. 
Mizuseki 
K, 
Sirota 
A, 
Pastalkova 
E, 
Buzsáki 
G. 
Theta 
oscillation 
provide 
temporal 
window 
for 
local 
circuit 

computation 
in 
the 
entorhinal-­‐hippocampal 
loop. 
Neuron. 
2009;64(2):267-­‐80. 

15. 
Mizuseki 
K, 
Sirota 
A, 
Pastalkova 
E, 
Buzsáki 
G. 
Multi-­‐unit 
recording 
from 
the 
rat 
hippocampus 
make 
during 

open 
field 
foraging. 
2009. 
doi: 
http://dx.doi.org/10.6080/K0Z60KZ9. 

16. 
London 
BM, 
Miller 
LE. 
Responses 
of 
somatosensory 
area 
2 
neuron 
to 
actively 
and 
passively 
generate 
limb 

movements. 
Journal 
of 
neurophysiology. 
2013;109(6):1505-­‐13. 

17. 
Fagg 
AH, 
Ojakangas 
GW, 
Miller 
LE, 
Hatsopoulos 
NG. 
Kinetic 
trajectory 
decode 
use 
motor 
cortical 
ensembles. 

IEEE 
Transactions 
on 
Neural 
Systems 
and 
Rehabilitation 
Engineering. 
2009;17(5):487-­‐96. 

18. 
Snoek 
J, 
Larochelle 
H, 
Adams 
RP, 
editors. 
Practical 
bayesian 
optimization 
of 
machine 
learn 
algorithms. 

Advances 
in 
neural 
information 
processing 
systems; 
2012. 

19. 
Wu 
W, 
Black 
MJ, 
Gao 
Y, 
Serruya 
M, 
Shaikhouni 
A, 
Donoghue 
J, 
et 
al., 
editors. 
Neural 
decode 
of 
cursor 
motion 

use 
a 
Kalman 
filter. 
Advances 
in 
neural 
information 
processing 
systems; 
2003. 

20. 
Pohlmeyer 
EA, 
Solla 
SA, 
Perreault 
EJ, 
Miller 
LE. 
Prediction 
of 
upper 
limb 
muscle 
activity 
from 
motor 
cortical 

discharge 
during 
reaching. 
Journal 
of 
neural 
engineering. 
2007;4(4):369. 

21. 
Chang 
C-­‐C, 
Lin 
C-­‐J. 
LIBSVM: 
a 
library 
for 
support 
vector 
machines. 
ACM 
Transactions 
on 
Intelligent 
Systems 
and 

Technology 
(TIST). 
2011;2(3):27. 

22. 
Chen 
T, 
Guestrin 
C, 
editors. 
Xgboost: 
A 
scalable 
tree 
boost 
system. 
Proceedings 
of 
the 
22Nd 
ACM 
SIGKDD 

International 
Conference 
on 
Knowledge 
Discovery 
and 
Data 
Mining; 
2016: 
ACM. 

23. 
Chollet 
F. 
Keras. 
2015. 

24. 
Srivastava 
N, 
Hinton 
GE, 
Krizhevsky 
A, 
Sutskever 
I, 
Salakhutdinov 
R. 
Dropout: 
a 
simple 
way 
to 
prevent 
neural 

network 
from 
overfitting. 
Journal 
of 
Machine 
Learning 
Research. 
2014;15(1):1929-­‐58. 

25. 
Kingma 
D, 
Ba 
J. 
Adam: 
A 
method 
for 
stochastic 
optimization. 
arXiv 
preprint 
arXiv:14126980. 
2014. 

26. 
Tieleman 
T, 
Hinton 
G. 
Lecture 
6.5-­‐RmsProp: 
Divide 
the 
gradient 
by 
a 
run 
average 
of 
it 
recent 
magnitude. 

COURSERA: 
Neural 
Networks 
for 
Machine 
Learning. 
2012. 

27. 
Cho 
K, 
Van 
Merriënboer 
B, 
Gulcehre 
C, 
Bahdanau 
D, 
Bougares 
F, 
Schwenk 
H, 
et 
al. 
Learning 
phrase 

representation 
use 
RNN 
encoder-­‐decoder 
for 
statistical 
machine 
translation. 
arXiv 
preprint 
arXiv:14061078. 
2014. 

28. 
Hochreiter 
S, 
Schmidhuber 
J. 
Long 
short-­‐term 
memory. 
Neural 
computation. 
1997;9(8):1735-­‐80. 

29. 
Krizhevsky 
A, 
Sutskever 
I, 
Hinton 
GE, 
editors. 
Imagenet 
classification 
with 
deep 
convolutional 
neural 
networks. 

Advances 
in 
neural 
information 
processing 
systems; 
2012. 




30. 
Zhang 
C, 
Bengio 
S, 
Hardt 
M, 
Recht 
B, 
Vinyals 
O. 
Understanding 
deep 
learn 
require 
rethink 

generalization. 
arXiv 
preprint 
arXiv:161103530. 
2016. 

31. 
Shenoy 
KV, 
Sahani 
M, 
Churchland 
MM. 
Cortical 
control 
of 
arm 
movements: 
a 
dynamical 
system 
perspective. 

Annu 
Rev 
Neurosci. 
2013;36:337-­‐59. 
doi: 
10.1146/annurev-­‐neuro-­‐062111-­‐150509. 
PubMed 
PMID: 
23725001. 

32. 
Kao 
JC, 
Stavisky 
SD, 
Sussillo 
D, 
Nuyujukian 
P, 
Shenoy 
KV. 
Information 
system 
opportunity 
in 
brain–machine 

interface 
decoders. 
Proceedings 
of 
the 
IEEE. 
2014;102(5):666-­‐82. 

33. 
Nicolas-­‐Alonso 
LF, 
Gomez-­‐Gil 
J. 
Brain 
computer 
interfaces, 
a 
review. 
Sensors. 
2012;12(2):1211-­‐79. 

34. 
Sussillo 
D, 
Nuyujukian 
P, 
Fan 
JM, 
Kao 
JC, 
Stavisky 
SD, 
Ryu 
S, 
et 
al. 
A 
recurrent 
neural 
network 
for 
closed-­‐loop 

intracortical 
brain–machine 
interface 
decoders. 
Journal 
of 
neural 
engineering. 
2012;9(2):026027. 

35. 
Kao 
JC, 
Nuyujukian 
P, 
Ryu 
SI, 
Churchland 
MM, 
Cunningham 
JP, 
Shenoy 
KV. 
Single-­‐trial 
dynamic 
of 
motor 
cortex 

and 
their 
application 
to 
brain-­‐machine 
interfaces. 
Nature 
communications. 
2015;6. 

36. 
Corbett 
E, 
Perreault 
E, 
Koerding 
K, 
editors. 
Mixture 
of 
time-­‐warped 
trajectory 
model 
for 
movement 
decoding. 

Advances 
in 
Neural 
Information 
Processing 
Systems; 
2010. 

37. 
Kao 
JC, 
Nuyujukian 
P, 
Ryu 
SI, 
Shenoy 
KV. 
A 
high-­‐performance 
neural 
prosthesis 
incorporate 
discrete 
state 

selection 
with 
hidden 
Markov 
models. 
IEEE 
Transactions 
on 
Biomedical 
Engineering. 
2017;64(4):935-­‐45. 














Supplemental 
Figure 
1. 
Kalman 
Filter 
Versions 

R2 
value 
be 
report 
for 
different 
version 
of 
the 
Kalman 
Filter 
for 
each 
brain 
area 
(top 
to 
bottom). 
On 
the 
left 
(in 

more 
transparent 
cyan), 
the 
Kalman 
Filter 
be 
implement 
a 
in 
[19]. 
On 
the 
right 
(in 
more 
opaque 
cyan), 
the 
Kalman 

Filter 
be 
implement 
with 
an 
extra 
parameter 
that 
scale 
the 
noise 
matrix 
associate 
with 
the 
transition 
in 
kinematic 

state 
(see 
Methods). 
This 
version 
with 
the 
extra 
parameter 
be 
the 
one 
use 
in 
the 
main 
text. 
Error 
bar 
represent 
the 

mean 
+/-­‐ 
SEM 
across 
cross-­‐validation 
folds. 
X’s 
represent 
the 
R2 
value 
of 
each 
cross-­‐validation 
fold. 

Note 
the 
different 

y-­‐axis 
limit 
for 
the 
hippocampus 
dataset. 





