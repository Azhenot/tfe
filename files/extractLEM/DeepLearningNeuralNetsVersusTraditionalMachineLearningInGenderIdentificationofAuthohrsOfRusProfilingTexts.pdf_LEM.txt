


























































































Deep Learning neural net versus traditional machine learn in gender identification of author of RusProfiling text 


ScienceDirect 

Available online at www.sciencedirect.com 

Procedia Computer Science 123 (2018) 424–431 

1877-0509 © 2018 The Authors. Published by Elsevier Ltd. This be an open access article under the CC BY-NC-ND license 
(http://creativecommons.org/licenses/by-nc-nd/3.0/). 
Peer-review under responsibility of the scientific committee of the 8th Annual International Conference on Biologically Inspired 
Cognitive Architectures 
10.1016/j.procs.2018.01.065 

8th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2017 

10.1016/j.procs.2018.01.065 1877-0509 

© 2018 The Authors. Published by Elsevier Ltd. This be an open access article under the CC BY-NC-ND license 
(http://creativecommons.org/licenses/by-nc-nd/3.0/). 
Peer-review under responsibility of the scientific committee of the 8th Annual International Conference on 
Biologically Inspired Cognitive Architectures 

This space be reserve for the Procedia header, do not use it 

Deep Learning neural net versus traditional machine 

learn in gender identification of author of RusProfiling 

text 

Alexander Sboev1,2, Ivan Moloshnikov1, Dmitry Gudovskikh1, Anton 
Selivanov1, Roman Rybka1, and Tatiana Litvinova1,3 

1 National Research Centre ’Kurchatov Institute’, Moscow, Russian Federation 
2 MEPhI National Research Nuclear University, Moscow, Russian Federation 

3 Voronezh State Pedagogical University, Voronezh, Russian Federation 
sag111@mail.ru, ivan-rus@yandex.ru, dvgudovskikh@gmail.com, 

aaselivanov.10.03@gmail.com, rybkarb@gmail.com, centr ru yaz@mail.ru 

Abstract 
In this paper we compare accuracy of solve the task of gender identification of RusPro- 

filing text without gender deception on base of two type of data-driven model approaches: 
on the one hand, well-known conventional machine learn algorithms, such a Support Vec- 
tor machine, Gradient Boosting; and, on the other hand, the set of Deep Learning neuronets, 
such a neuronet topology with convolution, fully-connected, and Long Short-Term Memory 
layers, etc. The dependence of effectiveness of these model on the feature selection and on 
their representation be investigated. The obtain F1-score of 88% establishes the state of the 
art in the gender identification task with the RusProfiling corpus. 

Keywords: gender identification, neural networks, natural language processing, data-driven model 

1 Introduction 

In the current practice there be two class of data-driven model applicable to the gender iden- 
tification task: conventional machine learn algorithm like Support Vector Machine (SVM) 
,Gradient boost and the set of Deep Learning neuronets with the convolution, the long 
shortterm memory layer (LSTM), etc. The contemporary level of accuracies, reach on the 
task be different for different languages. Results of the PAN 2017 competition [1] give the 
main milestone in the question what be the state of the art for such language a Arabic, En- 
glish,Portuguese, Spanish. One of the PAN 2017 task be the gender identification of Twitter 
texts. The competition corpus consist of 500 tweet of 100 authors. The dataset be divide 
into 60% (300 texts) for training and 40% (200 texts) for testing. The best result for English 
and Spanishwere obtain use the Linear Support Vector Machine, see [2]. Input text be 

1 

This space be reserve for the Procedia header, do not use it 

Deep Learning neural net versus traditional machine 

learn in gender identification of author of RusProfiling 

text 

Alexander Sboev1,2, Ivan Moloshnikov1, Dmitry Gudovskikh1, Anton 
Selivanov1, Roman Rybka1, and Tatiana Litvinova1,3 

1 National Research Centre ’Kurchatov Institute’, Moscow, Russian Federation 
2 MEPhI National Research Nuclear University, Moscow, Russian Federation 

3 Voronezh State Pedagogical University, Voronezh, Russian Federation 
sag111@mail.ru, ivan-rus@yandex.ru, dvgudovskikh@gmail.com, 

aaselivanov.10.03@gmail.com, rybkarb@gmail.com, centr ru yaz@mail.ru 

Abstract 
In this paper we compare accuracy of solve the task of gender identification of RusPro- 

filing text without gender deception on base of two type of data-driven model approaches: 
on the one hand, well-known conventional machine learn algorithms, such a Support Vec- 
tor machine, Gradient Boosting; and, on the other hand, the set of Deep Learning neuronets, 
such a neuronet topology with convolution, fully-connected, and Long Short-Term Memory 
layers, etc. The dependence of effectiveness of these model on the feature selection and on 
their representation be investigated. The obtain F1-score of 88% establishes the state of the 
art in the gender identification task with the RusProfiling corpus. 

Keywords: gender identification, neural networks, natural language processing, data-driven model 

1 Introduction 

In the current practice there be two class of data-driven model applicable to the gender iden- 
tification task: conventional machine learn algorithm like Support Vector Machine (SVM) 
,Gradient boost and the set of Deep Learning neuronets with the convolution, the long 
shortterm memory layer (LSTM), etc. The contemporary level of accuracies, reach on the 
task be different for different languages. Results of the PAN 2017 competition [1] give the 
main milestone in the question what be the state of the art for such language a Arabic, En- 
glish,Portuguese, Spanish. One of the PAN 2017 task be the gender identification of Twitter 
texts. The competition corpus consist of 500 tweet of 100 authors. The dataset be divide 
into 60% (300 texts) for training and 40% (200 texts) for testing. The best result for English 
and Spanishwere obtain use the Linear Support Vector Machine, see [2]. Input text be 

1 

This space be reserve for the Procedia header, do not use it 

Deep Learning neural net versus traditional machine 

learn in gender identification of author of RusProfiling 

text 

Alexander Sboev1,2, Ivan Moloshnikov1, Dmitry Gudovskikh1, Anton 
Selivanov1, Roman Rybka1, and Tatiana Litvinova1,3 

1 National Research Centre ’Kurchatov Institute’, Moscow, Russian Federation 
2 MEPhI National Research Nuclear University, Moscow, Russian Federation 

3 Voronezh State Pedagogical University, Voronezh, Russian Federation 
sag111@mail.ru, ivan-rus@yandex.ru, dvgudovskikh@gmail.com, 

aaselivanov.10.03@gmail.com, rybkarb@gmail.com, centr ru yaz@mail.ru 

Abstract 
In this paper we compare accuracy of solve the task of gender identification of RusPro- 

filing text without gender deception on base of two type of data-driven model approaches: 
on the one hand, well-known conventional machine learn algorithms, such a Support Vec- 
tor machine, Gradient Boosting; and, on the other hand, the set of Deep Learning neuronets, 
such a neuronet topology with convolution, fully-connected, and Long Short-Term Memory 
layers, etc. The dependence of effectiveness of these model on the feature selection and on 
their representation be investigated. The obtain F1-score of 88% establishes the state of the 
art in the gender identification task with the RusProfiling corpus. 

Keywords: gender identification, neural networks, natural language processing, data-driven model 

1 Introduction 

In the current practice there be two class of data-driven model applicable to the gender iden- 
tification task: conventional machine learn algorithm like Support Vector Machine (SVM) 
,Gradient boost and the set of Deep Learning neuronets with the convolution, the long 
shortterm memory layer (LSTM), etc. The contemporary level of accuracies, reach on the 
task be different for different languages. Results of the PAN 2017 competition [1] give the 
main milestone in the question what be the state of the art for such language a Arabic, En- 
glish,Portuguese, Spanish. One of the PAN 2017 task be the gender identification of Twitter 
texts. The competition corpus consist of 500 tweet of 100 authors. The dataset be divide 
into 60% (300 texts) for training and 40% (200 texts) for testing. The best result for English 
and Spanishwere obtain use the Linear Support Vector Machine, see [2]. Input text be 

1 

This space be reserve for the Procedia header, do not use it 

Deep Learning neural net versus traditional machine 

learn in gender identification of author of RusProfiling 

text 

Alexander Sboev1,2, Ivan Moloshnikov1, Dmitry Gudovskikh1, Anton 
Selivanov1, Roman Rybka1, and Tatiana Litvinova1,3 

1 National Research Centre ’Kurchatov Institute’, Moscow, Russian Federation 
2 MEPhI National Research Nuclear University, Moscow, Russian Federation 

3 Voronezh State Pedagogical University, Voronezh, Russian Federation 
sag111@mail.ru, ivan-rus@yandex.ru, dvgudovskikh@gmail.com, 

aaselivanov.10.03@gmail.com, rybkarb@gmail.com, centr ru yaz@mail.ru 

Abstract 
In this paper we compare accuracy of solve the task of gender identification of RusPro- 

filing text without gender deception on base of two type of data-driven model approaches: 
on the one hand, well-known conventional machine learn algorithms, such a Support Vec- 
tor machine, Gradient Boosting; and, on the other hand, the set of Deep Learning neuronets, 
such a neuronet topology with convolution, fully-connected, and Long Short-Term Memory 
layers, etc. The dependence of effectiveness of these model on the feature selection and on 
their representation be investigated. The obtain F1-score of 88% establishes the state of the 
art in the gender identification task with the RusProfiling corpus. 

Keywords: gender identification, neural networks, natural language processing, data-driven model 

1 Introduction 

In the current practice there be two class of data-driven model applicable to the gender iden- 
tification task: conventional machine learn algorithm like Support Vector Machine (SVM) 
,Gradient boost and the set of Deep Learning neuronets with the convolution, the long 
shortterm memory layer (LSTM), etc. The contemporary level of accuracies, reach on the 
task be different for different languages. Results of the PAN 2017 competition [1] give the 
main milestone in the question what be the state of the art for such language a Arabic, En- 
glish,Portuguese, Spanish. One of the PAN 2017 task be the gender identification of Twitter 
texts. The competition corpus consist of 500 tweet of 100 authors. The dataset be divide 
into 60% (300 texts) for training and 40% (200 texts) for testing. The best result for English 
and Spanishwere obtain use the Linear Support Vector Machine, see [2]. Input text be 

1 

This space be reserve for the Procedia header, do not use it 

Deep Learning neural net versus traditional machine 

learn in gender identification of author of RusProfiling 

text 

Alexander Sboev1,2, Ivan Moloshnikov1, Dmitry Gudovskikh1, Anton 
Selivanov1, Roman Rybka1, and Tatiana Litvinova1,3 

1 National Research Centre ’Kurchatov Institute’, Moscow, Russian Federation 
2 MEPhI National Research Nuclear University, Moscow, Russian Federation 

3 Voronezh State Pedagogical University, Voronezh, Russian Federation 
sag111@mail.ru, ivan-rus@yandex.ru, dvgudovskikh@gmail.com, 

aaselivanov.10.03@gmail.com, rybkarb@gmail.com, centr ru yaz@mail.ru 

Abstract 
In this paper we compare accuracy of solve the task of gender identification of RusPro- 

filing text without gender deception on base of two type of data-driven model approaches: 
on the one hand, well-known conventional machine learn algorithms, such a Support Vec- 
tor machine, Gradient Boosting; and, on the other hand, the set of Deep Learning neuronets, 
such a neuronet topology with convolution, fully-connected, and Long Short-Term Memory 
layers, etc. The dependence of effectiveness of these model on the feature selection and on 
their representation be investigated. The obtain F1-score of 88% establishes the state of the 
art in the gender identification task with the RusProfiling corpus. 

Keywords: gender identification, neural networks, natural language processing, data-driven model 

1 Introduction 

In the current practice there be two class of data-driven model applicable to the gender iden- 
tification task: conventional machine learn algorithm like Support Vector Machine (SVM) 
,Gradient boost and the set of Deep Learning neuronets with the convolution, the long 
shortterm memory layer (LSTM), etc. The contemporary level of accuracies, reach on the 
task be different for different languages. Results of the PAN 2017 competition [1] give the 
main milestone in the question what be the state of the art for such language a Arabic, En- 
glish,Portuguese, Spanish. One of the PAN 2017 task be the gender identification of Twitter 
texts. The competition corpus consist of 500 tweet of 100 authors. The dataset be divide 
into 60% (300 texts) for training and 40% (200 texts) for testing. The best result for English 
and Spanishwere obtain use the Linear Support Vector Machine, see [2]. Input text be 

1 

Deep Learning neuronet model versus traditional machine learn . . . Sboev et al. 

represent a frequency vector of character 2,3,4-grams and word forms, such a bigram 
and trigrams.Then the frequency be replace by the measure 1 + log(term − frequency), 
which show the best result. For the Arabic language, the best model [3] be base on a 
representation of text a a vector contain combination of character, word and POS n-grams 
with emojis, character flooding, sentiment words. Logistic regression be use for training the 
classifier. Deep learn approach in [4] show the best result on the Portuguese language. 
The author apply Recurrent Neural Networks (RNN) for word and Convolutional Neural 
Networks (CNN) for characters. Thereby, two representation of different level for a single mes- 
sage be obtained. They be combine and classify by gender, use attention mechanism, 
max-pooling layer, and fully-connected layer. The word embeddings layer be preliminarily 
train with the skip-gram. For character embed layer, weight be randomly initialize 
with a uniform distribution. 

So, accord to the result of the competition [3], traditional method of ML show the 
best result for English, Spanish, and Arabic languages, while deep learn be the winner for 
Portuguese. The aim of this paper be to find out which approach would be good for Russian. 
We use different corpora, described in detail in section 2, with different set of input feature 
described in section 3.1. Among the corpus create with offline respondents, there be one 
collect by crowdsourcing on the Web, and another goal of the paper be to compare the result 
obtain on different corpus and to ass the possibility of further use of crowdsourcing. The 
algorithm we use, traditional machine learn one and deep learn topologies, be present 
in section 3.2. Results of calculation and their discussion be in section 4 and 5. 

Part name Total Men Women Avg. 
length(M) 

Avg. 
length(W) 

Male 
author 

Female 
author 

GI(or) 394 125 269 123.38 107.82 47 92 
GI(bal) 250 125 125 123.38 111.19 47 74 

Table 1: Statistics of the Gender imitation text corpus. 

Part name Total Men Women Avg. 
length(M) 

Avg. 
length(W) 

Male 
author 

Female 
author 

GI cs(or) 3204 1161 2043 75.16 77.21 280 438 
GI cs(bal) 2322 1161 1161 75.16 78.89 280 265 
GI c A B(or) 2134 772 1362 75.35 77.21 279 438 
GI c A B(bal) 1544 772 772 75.35 78.91 279 264 

Table 2: Statistic of the Gender imitation crowdsource text corpus. 

Part name Total Men Women Avg. 
length(M) 

Avg. 
length(W) 

Male 
author 

Female 
author 

original 1033 641 392 60.42 66.49 641 392 
balance 784 392 392 58.61 66.49 392 392 

Table 3: Statistics of the RusPer text corpus. 

2 

http://crossmark.crossref.org/dialog/?doi=10.1016/j.procs.2018.01.065&domain=pdf 


Alexander Sboev et al. / Procedia Computer Science 123 (2018) 424–431 425 

© 2018 The Authors. Published by Elsevier Ltd. This be an open access article under the CC BY-NC-ND license 
(http://creativecommons.org/licenses/by-nc-nd/3.0/). 
Peer-review under responsibility of the scientific committee of the 8th Annual International Conference on 
Biologically Inspired Cognitive Architectures 

This space be reserve for the Procedia header, do not use it 

Deep Learning neural net versus traditional machine 

learn in gender identification of author of RusProfiling 

text 

Alexander Sboev1,2, Ivan Moloshnikov1, Dmitry Gudovskikh1, Anton 
Selivanov1, Roman Rybka1, and Tatiana Litvinova1,3 

1 National Research Centre ’Kurchatov Institute’, Moscow, Russian Federation 
2 MEPhI National Research Nuclear University, Moscow, Russian Federation 

3 Voronezh State Pedagogical University, Voronezh, Russian Federation 
sag111@mail.ru, ivan-rus@yandex.ru, dvgudovskikh@gmail.com, 

aaselivanov.10.03@gmail.com, rybkarb@gmail.com, centr ru yaz@mail.ru 

Abstract 
In this paper we compare accuracy of solve the task of gender identification of RusPro- 

filing text without gender deception on base of two type of data-driven model approaches: 
on the one hand, well-known conventional machine learn algorithms, such a Support Vec- 
tor machine, Gradient Boosting; and, on the other hand, the set of Deep Learning neuronets, 
such a neuronet topology with convolution, fully-connected, and Long Short-Term Memory 
layers, etc. The dependence of effectiveness of these model on the feature selection and on 
their representation be investigated. The obtain F1-score of 88% establishes the state of the 
art in the gender identification task with the RusProfiling corpus. 

Keywords: gender identification, neural networks, natural language processing, data-driven model 

1 Introduction 

In the current practice there be two class of data-driven model applicable to the gender iden- 
tification task: conventional machine learn algorithm like Support Vector Machine (SVM) 
,Gradient boost and the set of Deep Learning neuronets with the convolution, the long 
shortterm memory layer (LSTM), etc. The contemporary level of accuracies, reach on the 
task be different for different languages. Results of the PAN 2017 competition [1] give the 
main milestone in the question what be the state of the art for such language a Arabic, En- 
glish,Portuguese, Spanish. One of the PAN 2017 task be the gender identification of Twitter 
texts. The competition corpus consist of 500 tweet of 100 authors. The dataset be divide 
into 60% (300 texts) for training and 40% (200 texts) for testing. The best result for English 
and Spanishwere obtain use the Linear Support Vector Machine, see [2]. Input text be 

1 

This space be reserve for the Procedia header, do not use it 

Deep Learning neural net versus traditional machine 

learn in gender identification of author of RusProfiling 

text 

Alexander Sboev1,2, Ivan Moloshnikov1, Dmitry Gudovskikh1, Anton 
Selivanov1, Roman Rybka1, and Tatiana Litvinova1,3 

1 National Research Centre ’Kurchatov Institute’, Moscow, Russian Federation 
2 MEPhI National Research Nuclear University, Moscow, Russian Federation 

3 Voronezh State Pedagogical University, Voronezh, Russian Federation 
sag111@mail.ru, ivan-rus@yandex.ru, dvgudovskikh@gmail.com, 

aaselivanov.10.03@gmail.com, rybkarb@gmail.com, centr ru yaz@mail.ru 

Abstract 
In this paper we compare accuracy of solve the task of gender identification of RusPro- 

filing text without gender deception on base of two type of data-driven model approaches: 
on the one hand, well-known conventional machine learn algorithms, such a Support Vec- 
tor machine, Gradient Boosting; and, on the other hand, the set of Deep Learning neuronets, 
such a neuronet topology with convolution, fully-connected, and Long Short-Term Memory 
layers, etc. The dependence of effectiveness of these model on the feature selection and on 
their representation be investigated. The obtain F1-score of 88% establishes the state of the 
art in the gender identification task with the RusProfiling corpus. 

Keywords: gender identification, neural networks, natural language processing, data-driven model 

1 Introduction 

In the current practice there be two class of data-driven model applicable to the gender iden- 
tification task: conventional machine learn algorithm like Support Vector Machine (SVM) 
,Gradient boost and the set of Deep Learning neuronets with the convolution, the long 
shortterm memory layer (LSTM), etc. The contemporary level of accuracies, reach on the 
task be different for different languages. Results of the PAN 2017 competition [1] give the 
main milestone in the question what be the state of the art for such language a Arabic, En- 
glish,Portuguese, Spanish. One of the PAN 2017 task be the gender identification of Twitter 
texts. The competition corpus consist of 500 tweet of 100 authors. The dataset be divide 
into 60% (300 texts) for training and 40% (200 texts) for testing. The best result for English 
and Spanishwere obtain use the Linear Support Vector Machine, see [2]. Input text be 

1 

This space be reserve for the Procedia header, do not use it 

Deep Learning neural net versus traditional machine 

learn in gender identification of author of RusProfiling 

text 

Alexander Sboev1,2, Ivan Moloshnikov1, Dmitry Gudovskikh1, Anton 
Selivanov1, Roman Rybka1, and Tatiana Litvinova1,3 

1 National Research Centre ’Kurchatov Institute’, Moscow, Russian Federation 
2 MEPhI National Research Nuclear University, Moscow, Russian Federation 

3 Voronezh State Pedagogical University, Voronezh, Russian Federation 
sag111@mail.ru, ivan-rus@yandex.ru, dvgudovskikh@gmail.com, 

aaselivanov.10.03@gmail.com, rybkarb@gmail.com, centr ru yaz@mail.ru 

Abstract 
In this paper we compare accuracy of solve the task of gender identification of RusPro- 

filing text without gender deception on base of two type of data-driven model approaches: 
on the one hand, well-known conventional machine learn algorithms, such a Support Vec- 
tor machine, Gradient Boosting; and, on the other hand, the set of Deep Learning neuronets, 
such a neuronet topology with convolution, fully-connected, and Long Short-Term Memory 
layers, etc. The dependence of effectiveness of these model on the feature selection and on 
their representation be investigated. The obtain F1-score of 88% establishes the state of the 
art in the gender identification task with the RusProfiling corpus. 

Keywords: gender identification, neural networks, natural language processing, data-driven model 

1 Introduction 

In the current practice there be two class of data-driven model applicable to the gender iden- 
tification task: conventional machine learn algorithm like Support Vector Machine (SVM) 
,Gradient boost and the set of Deep Learning neuronets with the convolution, the long 
shortterm memory layer (LSTM), etc. The contemporary level of accuracies, reach on the 
task be different for different languages. Results of the PAN 2017 competition [1] give the 
main milestone in the question what be the state of the art for such language a Arabic, En- 
glish,Portuguese, Spanish. One of the PAN 2017 task be the gender identification of Twitter 
texts. The competition corpus consist of 500 tweet of 100 authors. The dataset be divide 
into 60% (300 texts) for training and 40% (200 texts) for testing. The best result for English 
and Spanishwere obtain use the Linear Support Vector Machine, see [2]. Input text be 

1 

This space be reserve for the Procedia header, do not use it 

Deep Learning neural net versus traditional machine 

learn in gender identification of author of RusProfiling 

text 

Alexander Sboev1,2, Ivan Moloshnikov1, Dmitry Gudovskikh1, Anton 
Selivanov1, Roman Rybka1, and Tatiana Litvinova1,3 

1 National Research Centre ’Kurchatov Institute’, Moscow, Russian Federation 
2 MEPhI National Research Nuclear University, Moscow, Russian Federation 

3 Voronezh State Pedagogical University, Voronezh, Russian Federation 
sag111@mail.ru, ivan-rus@yandex.ru, dvgudovskikh@gmail.com, 

aaselivanov.10.03@gmail.com, rybkarb@gmail.com, centr ru yaz@mail.ru 

Abstract 
In this paper we compare accuracy of solve the task of gender identification of RusPro- 

filing text without gender deception on base of two type of data-driven model approaches: 
on the one hand, well-known conventional machine learn algorithms, such a Support Vec- 
tor machine, Gradient Boosting; and, on the other hand, the set of Deep Learning neuronets, 
such a neuronet topology with convolution, fully-connected, and Long Short-Term Memory 
layers, etc. The dependence of effectiveness of these model on the feature selection and on 
their representation be investigated. The obtain F1-score of 88% establishes the state of the 
art in the gender identification task with the RusProfiling corpus. 

Keywords: gender identification, neural networks, natural language processing, data-driven model 

1 Introduction 

In the current practice there be two class of data-driven model applicable to the gender iden- 
tification task: conventional machine learn algorithm like Support Vector Machine (SVM) 
,Gradient boost and the set of Deep Learning neuronets with the convolution, the long 
shortterm memory layer (LSTM), etc. The contemporary level of accuracies, reach on the 
task be different for different languages. Results of the PAN 2017 competition [1] give the 
main milestone in the question what be the state of the art for such language a Arabic, En- 
glish,Portuguese, Spanish. One of the PAN 2017 task be the gender identification of Twitter 
texts. The competition corpus consist of 500 tweet of 100 authors. The dataset be divide 
into 60% (300 texts) for training and 40% (200 texts) for testing. The best result for English 
and Spanishwere obtain use the Linear Support Vector Machine, see [2]. Input text be 

1 

This space be reserve for the Procedia header, do not use it 

Deep Learning neural net versus traditional machine 

learn in gender identification of author of RusProfiling 

text 

Alexander Sboev1,2, Ivan Moloshnikov1, Dmitry Gudovskikh1, Anton 
Selivanov1, Roman Rybka1, and Tatiana Litvinova1,3 

1 National Research Centre ’Kurchatov Institute’, Moscow, Russian Federation 
2 MEPhI National Research Nuclear University, Moscow, Russian Federation 

3 Voronezh State Pedagogical University, Voronezh, Russian Federation 
sag111@mail.ru, ivan-rus@yandex.ru, dvgudovskikh@gmail.com, 

aaselivanov.10.03@gmail.com, rybkarb@gmail.com, centr ru yaz@mail.ru 

Abstract 
In this paper we compare accuracy of solve the task of gender identification of RusPro- 

filing text without gender deception on base of two type of data-driven model approaches: 
on the one hand, well-known conventional machine learn algorithms, such a Support Vec- 
tor machine, Gradient Boosting; and, on the other hand, the set of Deep Learning neuronets, 
such a neuronet topology with convolution, fully-connected, and Long Short-Term Memory 
layers, etc. The dependence of effectiveness of these model on the feature selection and on 
their representation be investigated. The obtain F1-score of 88% establishes the state of the 
art in the gender identification task with the RusProfiling corpus. 

Keywords: gender identification, neural networks, natural language processing, data-driven model 

1 Introduction 

In the current practice there be two class of data-driven model applicable to the gender iden- 
tification task: conventional machine learn algorithm like Support Vector Machine (SVM) 
,Gradient boost and the set of Deep Learning neuronets with the convolution, the long 
shortterm memory layer (LSTM), etc. The contemporary level of accuracies, reach on the 
task be different for different languages. Results of the PAN 2017 competition [1] give the 
main milestone in the question what be the state of the art for such language a Arabic, En- 
glish,Portuguese, Spanish. One of the PAN 2017 task be the gender identification of Twitter 
texts. The competition corpus consist of 500 tweet of 100 authors. The dataset be divide 
into 60% (300 texts) for training and 40% (200 texts) for testing. The best result for English 
and Spanishwere obtain use the Linear Support Vector Machine, see [2]. Input text be 

1 

Deep Learning neuronet model versus traditional machine learn . . . Sboev et al. 

represent a frequency vector of character 2,3,4-grams and word forms, such a bigram 
and trigrams.Then the frequency be replace by the measure 1 + log(term − frequency), 
which show the best result. For the Arabic language, the best model [3] be base on a 
representation of text a a vector contain combination of character, word and POS n-grams 
with emojis, character flooding, sentiment words. Logistic regression be use for training the 
classifier. Deep learn approach in [4] show the best result on the Portuguese language. 
The author apply Recurrent Neural Networks (RNN) for word and Convolutional Neural 
Networks (CNN) for characters. Thereby, two representation of different level for a single mes- 
sage be obtained. They be combine and classify by gender, use attention mechanism, 
max-pooling layer, and fully-connected layer. The word embeddings layer be preliminarily 
train with the skip-gram. For character embed layer, weight be randomly initialize 
with a uniform distribution. 

So, accord to the result of the competition [3], traditional method of ML show the 
best result for English, Spanish, and Arabic languages, while deep learn be the winner for 
Portuguese. The aim of this paper be to find out which approach would be good for Russian. 
We use different corpora, described in detail in section 2, with different set of input feature 
described in section 3.1. Among the corpus create with offline respondents, there be one 
collect by crowdsourcing on the Web, and another goal of the paper be to compare the result 
obtain on different corpus and to ass the possibility of further use of crowdsourcing. The 
algorithm we use, traditional machine learn one and deep learn topologies, be present 
in section 3.2. Results of calculation and their discussion be in section 4 and 5. 

Part name Total Men Women Avg. 
length(M) 

Avg. 
length(W) 

Male 
author 

Female 
author 

GI(or) 394 125 269 123.38 107.82 47 92 
GI(bal) 250 125 125 123.38 111.19 47 74 

Table 1: Statistics of the Gender imitation text corpus. 

Part name Total Men Women Avg. 
length(M) 

Avg. 
length(W) 

Male 
author 

Female 
author 

GI cs(or) 3204 1161 2043 75.16 77.21 280 438 
GI cs(bal) 2322 1161 1161 75.16 78.89 280 265 
GI c A B(or) 2134 772 1362 75.35 77.21 279 438 
GI c A B(bal) 1544 772 772 75.35 78.91 279 264 

Table 2: Statistic of the Gender imitation crowdsource text corpus. 

Part name Total Men Women Avg. 
length(M) 

Avg. 
length(W) 

Male 
author 

Female 
author 

original 1033 641 392 60.42 66.49 641 392 
balance 784 392 392 58.61 66.49 392 392 

Table 3: Statistics of the RusPer text corpus. 

2 



426 Alexander Sboev et al. / Procedia Computer Science 123 (2018) 424–431Deep Learning neuronet model versus traditional machine learn . . . Sboev et al. 

Part name Total Men Women Avg. 
length(M) 

Avg. 
length(W) 

Male 
author 

Female 
author 

Reviews(or) 1033 641 392 60.42 66.49 641 392 
Reviews(bal) 784 392 392 58.61 66.49 392 392 
FB(or) 250 136 114 1381.87 1395.82 136 114 
FB(bal) 228 114 114 1382.58 1395.82 114 114 
FB split(or) 1617 868 749 197.36 195.19 
FB split(bal) 1498 749 749 200.86 195.19 
Tw(or) 1541 998 543 1721.91 1638.18 998 543 
Tw(bal) 1086 543 543 1746.76 1638.18 543 543 
Tw split(or) 7512 5062 2450 298.37 315.13 - - 
Tw split(bal) 4900 2450 2450 298.45 315.13 - - 
LJ(or) 11 6 5 52812.5 63049.8 6 5 
LJ(bal) 10 5 5 50463 63049.8 5 5 
LJ split(or) 3256 1632 1624 193.91 193.74 - - 
LJ split(bal) 3248 1624 1624 164.27 163.74 - - 

Table 4: Statistics of the RusProfiling text corpus. 

2 Used corpus 

We use several corpora, have different number of authors, texts, and text length. For this 
reason the original corpus be balance by the number of text by woman and men. The 
statistic of the use datasets, original and balanced, be present in Tables 1-4. The Russian 
Gender imitation (GI) (Table 1) corpus consists of specially write author texts[5]. Each 
author chose a topic from a list of four: a letter to a friend, a self-description for a date site, 
a complaint about the bos or about a tour, and then be instruct to write three text on 
the same topic: text A - in the author’s natural style, text B - a someone of the opposite sex, 
text C - a someone else of the same sex. GI crowdsource (GI cs) (Table 2) contains text 
collect by crowdsourcing platform to extend the GI corpus. It be collect the same way 
and have the same subset a GI. We single out the subcorpus of texts: GI c a b denotes 
the part of GI c without the C text (similar to GI type C). RusPer (RusPer)(Table 3) 
be a Russian-language corpus [6] of write text label with data on their authors. Each 
text have a metadata like gender, age, personalities, education level, neuropsychological test 
data, etc. This paper us a part of the corpus, consist of text on two topics: letter to a 
friend and picture descriptions. RusProfiling (RusProf)(Table 4) corpus [7] contains text 
collect from different social medium platform a Twitter, Facebook and LiveJournal, along with 
Reviews - the set of review collect manually. This data set be divide into subsamples, 
which allows to study how the feature of the corpus influence the quality of the model and 
to evaluate the possibility of cross-genre classification. Some subsamples of RusProf be 
divide into two sets. In the first set all message be merge into one text for each author: 
Twitter(Tw) - 1000 twitter message for each user, LJ - the set of blog text from LiveJournal, 
FB - message from FaceBook walls. In the second set, after combine each user message into 
one text, it be separate into document of 15 sentences. These subsamples be denote a 
Tw split, LJ split, and FB split. We also conduct an evaluation of the model with the 
corpus preliminarily balance by the author’s gender. These result be note ‘original (or)’ 
or ‘balanced(bal)’ respectively next to the name of the corpus in the table further. 

3 

Deep Learning neuronet model versus traditional machine learn . . . Sboev et al. 

3 Methods 

3.1 Features 

The follow set of feature be use in our work in combination with different models: 

TF-IDF for n-grams(TF-IDF): The vector of n-gram frequencies, characterize a docu- 
ment d, be obtain by apply by the TF-IDF formula tf − idf(t, d) = tf(t, d) × idf(t) 
to each n-gram t of the collection D. Here t be a character n-gram from 3 to 8 character 
long, tf(t, d) be the number of time t occurs in d; idf(t) = log 1+nd1+df(d,t) +1. Here nd be the 

total number of texts, and df(d, t) be the number of text that contain t. Only n-grams 
that exist in more than 100 text be used. We use different value of minimal df(d, t) in 
the range from 1 to 10. 

Char n-grams(Char). To represent a document a a vector, the frequency of encounter 
symbolic n-grams range from 1 to 8 be calculated. 

GRM-1: each word be encode by a 49-dimensional binary vector of morphological properties. 
The size of a document be fix at 300 words: longer text be clipped, and shorter text 
be extend with null vectors. 

GRM-2: each word be again encode by a 49-dimensional morphological property vector, but 
then all the vector of a text be concatenated, form a vector of the length 14700. 

Word2vec. This be an already exist model that be preliminarily train on a collection 
of random Russian web page crawl in December 2014, contains 9 million document 
in total. Corpus size be 660, 628, 738 tokens. Model be train use the Continuous 
Skip-Gram algorithm. Vector dimensionality be set to 500, window size 2. Lemmas 
occur less than 30 time be ignore [8]. 

Sequences feature (Seq. feat): Texts be represent a sequence of word with a full set of 
morphological tag (person, gender, part of speech, etc.) along with the type of syntactic 
relation with a parent, all one-hot encoded. 

3.2 Models 

3.2.1 Conventional machine learn method 

Support vector machine (SVM). We use the classifier base on a support vector machine 
with linear kernel. The follow hyperparameters be used: regularization parameter C = 1, 
L2−norm use in the penalization and square hinge-loss function. Gradient boosting(GB) 
classifier be train with the follow parameters: learn rate be 0.05, the number of 
boost stage to perform be 300, the minimum number of sample to split an internal node be 
19, the maximum depth of the tree be 12. 

3.2.2 Neural network topology 

Model 1 be base on convolution and fully connect layers: Convolutional Neural Net- 
work (CNN): 128 neurons, window size = 2, activation function = Relu;Maxpooling 
layer: window = 4, step = 4; CNN: 128 neurons, window = 2, activation function = 
Relu; Maxpooling layer: window = 4, step = 4; CNN: 128 neurons, window = 2, 
activation function = Relu; Maxpooling layer: window = 4, step = 4; CNN: 128 

4 



Alexander Sboev et al. / Procedia Computer Science 123 (2018) 424–431 427Deep Learning neuronet model versus traditional machine learn . . . Sboev et al. 

Part name Total Men Women Avg. 
length(M) 

Avg. 
length(W) 

Male 
author 

Female 
author 

Reviews(or) 1033 641 392 60.42 66.49 641 392 
Reviews(bal) 784 392 392 58.61 66.49 392 392 
FB(or) 250 136 114 1381.87 1395.82 136 114 
FB(bal) 228 114 114 1382.58 1395.82 114 114 
FB split(or) 1617 868 749 197.36 195.19 
FB split(bal) 1498 749 749 200.86 195.19 
Tw(or) 1541 998 543 1721.91 1638.18 998 543 
Tw(bal) 1086 543 543 1746.76 1638.18 543 543 
Tw split(or) 7512 5062 2450 298.37 315.13 - - 
Tw split(bal) 4900 2450 2450 298.45 315.13 - - 
LJ(or) 11 6 5 52812.5 63049.8 6 5 
LJ(bal) 10 5 5 50463 63049.8 5 5 
LJ split(or) 3256 1632 1624 193.91 193.74 - - 
LJ split(bal) 3248 1624 1624 164.27 163.74 - - 

Table 4: Statistics of the RusProfiling text corpus. 

2 Used corpus 

We use several corpora, have different number of authors, texts, and text length. For this 
reason the original corpus be balance by the number of text by woman and men. The 
statistic of the use datasets, original and balanced, be present in Tables 1-4. The Russian 
Gender imitation (GI) (Table 1) corpus consists of specially write author texts[5]. Each 
author chose a topic from a list of four: a letter to a friend, a self-description for a date site, 
a complaint about the bos or about a tour, and then be instruct to write three text on 
the same topic: text A - in the author’s natural style, text B - a someone of the opposite sex, 
text C - a someone else of the same sex. GI crowdsource (GI cs) (Table 2) contains text 
collect by crowdsourcing platform to extend the GI corpus. It be collect the same way 
and have the same subset a GI. We single out the subcorpus of texts: GI c a b denotes 
the part of GI c without the C text (similar to GI type C). RusPer (RusPer)(Table 3) 
be a Russian-language corpus [6] of write text label with data on their authors. Each 
text have a metadata like gender, age, personalities, education level, neuropsychological test 
data, etc. This paper us a part of the corpus, consist of text on two topics: letter to a 
friend and picture descriptions. RusProfiling (RusProf)(Table 4) corpus [7] contains text 
collect from different social medium platform a Twitter, Facebook and LiveJournal, along with 
Reviews - the set of review collect manually. This data set be divide into subsamples, 
which allows to study how the feature of the corpus influence the quality of the model and 
to evaluate the possibility of cross-genre classification. Some subsamples of RusProf be 
divide into two sets. In the first set all message be merge into one text for each author: 
Twitter(Tw) - 1000 twitter message for each user, LJ - the set of blog text from LiveJournal, 
FB - message from FaceBook walls. In the second set, after combine each user message into 
one text, it be separate into document of 15 sentences. These subsamples be denote a 
Tw split, LJ split, and FB split. We also conduct an evaluation of the model with the 
corpus preliminarily balance by the author’s gender. These result be note ‘original (or)’ 
or ‘balanced(bal)’ respectively next to the name of the corpus in the table further. 

3 

Deep Learning neuronet model versus traditional machine learn . . . Sboev et al. 

3 Methods 

3.1 Features 

The follow set of feature be use in our work in combination with different models: 

TF-IDF for n-grams(TF-IDF): The vector of n-gram frequencies, characterize a docu- 
ment d, be obtain by apply by the TF-IDF formula tf − idf(t, d) = tf(t, d) × idf(t) 
to each n-gram t of the collection D. Here t be a character n-gram from 3 to 8 character 
long, tf(t, d) be the number of time t occurs in d; idf(t) = log 1+nd1+df(d,t) +1. Here nd be the 

total number of texts, and df(d, t) be the number of text that contain t. Only n-grams 
that exist in more than 100 text be used. We use different value of minimal df(d, t) in 
the range from 1 to 10. 

Char n-grams(Char). To represent a document a a vector, the frequency of encounter 
symbolic n-grams range from 1 to 8 be calculated. 

GRM-1: each word be encode by a 49-dimensional binary vector of morphological properties. 
The size of a document be fix at 300 words: longer text be clipped, and shorter text 
be extend with null vectors. 

GRM-2: each word be again encode by a 49-dimensional morphological property vector, but 
then all the vector of a text be concatenated, form a vector of the length 14700. 

Word2vec. This be an already exist model that be preliminarily train on a collection 
of random Russian web page crawl in December 2014, contains 9 million document 
in total. Corpus size be 660, 628, 738 tokens. Model be train use the Continuous 
Skip-Gram algorithm. Vector dimensionality be set to 500, window size 2. Lemmas 
occur less than 30 time be ignore [8]. 

Sequences feature (Seq. feat): Texts be represent a sequence of word with a full set of 
morphological tag (person, gender, part of speech, etc.) along with the type of syntactic 
relation with a parent, all one-hot encoded. 

3.2 Models 

3.2.1 Conventional machine learn method 

Support vector machine (SVM). We use the classifier base on a support vector machine 
with linear kernel. The follow hyperparameters be used: regularization parameter C = 1, 
L2−norm use in the penalization and square hinge-loss function. Gradient boosting(GB) 
classifier be train with the follow parameters: learn rate be 0.05, the number of 
boost stage to perform be 300, the minimum number of sample to split an internal node be 
19, the maximum depth of the tree be 12. 

3.2.2 Neural network topology 

Model 1 be base on convolution and fully connect layers: Convolutional Neural Net- 
work (CNN): 128 neurons, window size = 2, activation function = Relu;Maxpooling 
layer: window = 4, step = 4; CNN: 128 neurons, window = 2, activation function = 
Relu; Maxpooling layer: window = 4, step = 4; CNN: 128 neurons, window = 2, 
activation function = Relu; Maxpooling layer: window = 4, step = 4; CNN: 128 

4 



428 Alexander Sboev et al. / Procedia Computer Science 123 (2018) 424–431Deep Learning neuronet model versus traditional machine learn . . . Sboev et al. 

neurons, window = 2, activation function = Relu; GlobalMaxPooling; Dropout 0.5; 
Fully-connected MLP layer: 128 neurons, activation function = Relu; Dropout 0.5; 
Output layer - MLP: activation function = softmax. 

Model 2 . The concept of Stacked Bidirectional LSTM neural network architecture be in- 
spired by [9], who show the possibility of use such an architecture for character 
prediction, machine translation and image classification tasks. The peculiarity of this 
network worth note be that the first branching on LSTM return sequence that be 
further concatenated. It consists of the follow layers: CNN: 30 neurons, window 
size = 3, activation function = ReLU. The input be pad so that the output have the 
same length a the original input (futher denote a pad = ’same’); Maxpooling 
layer: window = 2; CNN: 30 neurons, window size = 3, activation function = Relu, 
pad = ’same’; Maxpooling layer: window = 2; CNN: 30 neurons, window size 
= 3, activation function = Relu, pad = ’same’; Maxpooling layer: window = 2; 
leftLSTM: 30 neurons, and the last output in the full sequence be return (further de- 
note by ’return sequence’) and in parallel rightLSTM: 30 neurons, the input sequence 
be process backwards and the reverse full sequence be return (further denote a 
’go backwards’); Concatenate: leftLSTM and rightLSTM; leftLSTM 2: 30 neuron 
and in parallel rightLSTM 2: 30 neurons, ”go backwards”; Concatenate: leftLSTM 2 
and rightLSTM 2; Dropout 0.5; Dense: 10 neurons, activation function = ”tanh”; 
Dropout 0.5; Output layer - Dense: 2 neurons, activation function = ’softmax’. 

Model 3 . The architecture of this neural network have be adapt from the work [10]. Net- 
work topology: CNN: 30 neurons, window size = 3, activation function = Relu. The 
input be pad so that the output have the same length a the original input (futher 
denote a pad = ”same”); Maxpooling layer: window = 2; CNN: 30 neurons, 
window size = 3, activation function = Relu, pad = “same’; Maxpooling layer: 
window = 2; CNN: 30 neurons, window size = 3, activation function = Relu, pad = 
’same’;Maxpooling layer: window = 2; leftLSTM: 30 neuron and in parallel rightL- 
STM: 30 neurons, ”go backwards”; Concatenate: leftLSTM and rightLSTM; Dropout 
0.5, Dense: 5 neurons, activation function = ’tanh’; Dropout 0.5; Output layer - 
Dense: 2 neurons, activation function = ’softmax’. 

Network training be perform with early stop (if the error on the validation set grows 
during 15 epochs, then stop). After training the weight from the best model be loaded. We 
use the Rmsprop algorithm [11] and learn rate of 0.001. 

4 Experiments 

Evaluations of F1 score (F1 mean) and mean deviation (F1 std) be obtained. In case of 
Conventional machine learn alghoritms all the training data have be use to fit models. 
F1 std be calculate on base of 10 different cycle of training and test of single configu- 
ration. The training dataset be split 5 time into 80% to train and 20% to validate. The 
F1 mean and the F1 std be calculate on the base of these split data sets. The baseline be 
calculate accord to the size of classes, and be F1-score=0.59 for the original, unbalanced 
test dataset and F1-score=0.5 for the balance test dataset. Results obtain with training 
on ’a’ and ’b’ GI subset be of especial interest, in spite of their low accuracy. By exclud- 
ing the ’c’ subset we balance the training set by the number of actual-gender sample and 
opposite-gender-mimicking samples. The reason be that, when actual-gender sample (’a’ and 

5 

Deep Learning neuronet model versus traditional machine learn . . . Sboev et al. 

# Train datasets Model Features F1 F1 std Delta 
(bl 
0.59) 

1 RusPer; GI A,B,C Model 2 GRM-1 0.73 0.04 0.14 
2 RusPer; GI A,B,C Model 3 GRM-1 0.76 0.07 0.17 
3 RusPer; GI A,B Model 2 GRM-1 0.65 0.1 0.06 
4 GI cs; GI A,B,C SVM Char 0.74 0.04 0.15 
5 GI cs; GI A GB GRM-2 0.76 0.19 0.17 
6 RusPer Model 3 GRM-1 0.78 0.04 0.19 
7 GI c a GB TF-IDF 0.74 0.03 0.15 
16 GI cs; RusPer; Re- 

views; Tw split; LJ split; 
FB split 

Model 1 Seq. feat 0.86 0.03 0.27 

17 RusPer; Reviews; 
Tw split; LJ split; 
FB split 

Model 1 Seq. feat 0.82 0.03 0.23 

18 GI c Model 1 Seq. feat 0.85 0.03 0.26 
19 Tw split, LJ split, 

FB split 
Model 1 Seq. feat 0.81 0.03 0.22 

20 GI cs; RusPer; Reviews Model 1 Seq. feat 0.87 0.03 0.28 
21 RusPer; Reviews Model 1 Seq. feat 0.79 0.02 0.2 
22 GI c a b Model 1 Seq. feat 0.84 0.03 0.25 

Table 5: Results of experiment on imbalanced datasets. 

’c’ subsets) dominate over opposite-gender-mimicking sample (’b’ subset), the network learns 
the straightforward gender-indicating morphological feature (like genus in Russian). And, vice 
versa, if gender-deceptive sample dominate over actual-gender ones, the network still relies on 
the straightforward morphological features, just revert them. So, by balance the training 
set by the number of actual-gender and gender-deceptive samples, we aim to make the network 
ignore the straightforward gender-indicating feature and infer the deeper, non-trivial ones. 

5 Results 

Tables 5, 6 demonstrates the F1 score of achieve models, train on different set of imbalanced 
and balance training datasets respectively. The Model 1 give the best result of 88% ± 3%, 
that be about 30% more than the bl. The best model base on the conventional Gradient 
Boosting algorithm give the result of 70% ± 7%, which be 20% above bl. The efficiency of 
SVM model learn directly depends on the training set size be show in Fig 1. The gain in 
F1 while the set size variate from 10% to 100% be about 12%. 

6 Conclusion 

The present approach base on deep neural network with CNN layer prove to be well- 
found for solve the problem of identify the gender of a text author. In our previous 
works, a neural network be present on the basis of a combination of CNN and LSTM [12], 

6 



Alexander Sboev et al. / Procedia Computer Science 123 (2018) 424–431 429Deep Learning neuronet model versus traditional machine learn . . . Sboev et al. 

neurons, window = 2, activation function = Relu; GlobalMaxPooling; Dropout 0.5; 
Fully-connected MLP layer: 128 neurons, activation function = Relu; Dropout 0.5; 
Output layer - MLP: activation function = softmax. 

Model 2 . The concept of Stacked Bidirectional LSTM neural network architecture be in- 
spired by [9], who show the possibility of use such an architecture for character 
prediction, machine translation and image classification tasks. The peculiarity of this 
network worth note be that the first branching on LSTM return sequence that be 
further concatenated. It consists of the follow layers: CNN: 30 neurons, window 
size = 3, activation function = ReLU. The input be pad so that the output have the 
same length a the original input (futher denote a pad = ’same’); Maxpooling 
layer: window = 2; CNN: 30 neurons, window size = 3, activation function = Relu, 
pad = ’same’; Maxpooling layer: window = 2; CNN: 30 neurons, window size 
= 3, activation function = Relu, pad = ’same’; Maxpooling layer: window = 2; 
leftLSTM: 30 neurons, and the last output in the full sequence be return (further de- 
note by ’return sequence’) and in parallel rightLSTM: 30 neurons, the input sequence 
be process backwards and the reverse full sequence be return (further denote a 
’go backwards’); Concatenate: leftLSTM and rightLSTM; leftLSTM 2: 30 neuron 
and in parallel rightLSTM 2: 30 neurons, ”go backwards”; Concatenate: leftLSTM 2 
and rightLSTM 2; Dropout 0.5; Dense: 10 neurons, activation function = ”tanh”; 
Dropout 0.5; Output layer - Dense: 2 neurons, activation function = ’softmax’. 

Model 3 . The architecture of this neural network have be adapt from the work [10]. Net- 
work topology: CNN: 30 neurons, window size = 3, activation function = Relu. The 
input be pad so that the output have the same length a the original input (futher 
denote a pad = ”same”); Maxpooling layer: window = 2; CNN: 30 neurons, 
window size = 3, activation function = Relu, pad = “same’; Maxpooling layer: 
window = 2; CNN: 30 neurons, window size = 3, activation function = Relu, pad = 
’same’;Maxpooling layer: window = 2; leftLSTM: 30 neuron and in parallel rightL- 
STM: 30 neurons, ”go backwards”; Concatenate: leftLSTM and rightLSTM; Dropout 
0.5, Dense: 5 neurons, activation function = ’tanh’; Dropout 0.5; Output layer - 
Dense: 2 neurons, activation function = ’softmax’. 

Network training be perform with early stop (if the error on the validation set grows 
during 15 epochs, then stop). After training the weight from the best model be loaded. We 
use the Rmsprop algorithm [11] and learn rate of 0.001. 

4 Experiments 

Evaluations of F1 score (F1 mean) and mean deviation (F1 std) be obtained. In case of 
Conventional machine learn alghoritms all the training data have be use to fit models. 
F1 std be calculate on base of 10 different cycle of training and test of single configu- 
ration. The training dataset be split 5 time into 80% to train and 20% to validate. The 
F1 mean and the F1 std be calculate on the base of these split data sets. The baseline be 
calculate accord to the size of classes, and be F1-score=0.59 for the original, unbalanced 
test dataset and F1-score=0.5 for the balance test dataset. Results obtain with training 
on ’a’ and ’b’ GI subset be of especial interest, in spite of their low accuracy. By exclud- 
ing the ’c’ subset we balance the training set by the number of actual-gender sample and 
opposite-gender-mimicking samples. The reason be that, when actual-gender sample (’a’ and 

5 

Deep Learning neuronet model versus traditional machine learn . . . Sboev et al. 

# Train datasets Model Features F1 F1 std Delta 
(bl 
0.59) 

1 RusPer; GI A,B,C Model 2 GRM-1 0.73 0.04 0.14 
2 RusPer; GI A,B,C Model 3 GRM-1 0.76 0.07 0.17 
3 RusPer; GI A,B Model 2 GRM-1 0.65 0.1 0.06 
4 GI cs; GI A,B,C SVM Char 0.74 0.04 0.15 
5 GI cs; GI A GB GRM-2 0.76 0.19 0.17 
6 RusPer Model 3 GRM-1 0.78 0.04 0.19 
7 GI c a GB TF-IDF 0.74 0.03 0.15 
16 GI cs; RusPer; Re- 

views; Tw split; LJ split; 
FB split 

Model 1 Seq. feat 0.86 0.03 0.27 

17 RusPer; Reviews; 
Tw split; LJ split; 
FB split 

Model 1 Seq. feat 0.82 0.03 0.23 

18 GI c Model 1 Seq. feat 0.85 0.03 0.26 
19 Tw split, LJ split, 

FB split 
Model 1 Seq. feat 0.81 0.03 0.22 

20 GI cs; RusPer; Reviews Model 1 Seq. feat 0.87 0.03 0.28 
21 RusPer; Reviews Model 1 Seq. feat 0.79 0.02 0.2 
22 GI c a b Model 1 Seq. feat 0.84 0.03 0.25 

Table 5: Results of experiment on imbalanced datasets. 

’c’ subsets) dominate over opposite-gender-mimicking sample (’b’ subset), the network learns 
the straightforward gender-indicating morphological feature (like genus in Russian). And, vice 
versa, if gender-deceptive sample dominate over actual-gender ones, the network still relies on 
the straightforward morphological features, just revert them. So, by balance the training 
set by the number of actual-gender and gender-deceptive samples, we aim to make the network 
ignore the straightforward gender-indicating feature and infer the deeper, non-trivial ones. 

5 Results 

Tables 5, 6 demonstrates the F1 score of achieve models, train on different set of imbalanced 
and balance training datasets respectively. The Model 1 give the best result of 88% ± 3%, 
that be about 30% more than the bl. The best model base on the conventional Gradient 
Boosting algorithm give the result of 70% ± 7%, which be 20% above bl. The efficiency of 
SVM model learn directly depends on the training set size be show in Fig 1. The gain in 
F1 while the set size variate from 10% to 100% be about 12%. 

6 Conclusion 

The present approach base on deep neural network with CNN layer prove to be well- 
found for solve the problem of identify the gender of a text author. In our previous 
works, a neural network be present on the basis of a combination of CNN and LSTM [12], 

6 



430 Alexander Sboev et al. / Procedia Computer Science 123 (2018) 424–431Deep Learning neuronet model versus traditional machine learn . . . Sboev et al. 

# Train datasets Model Features F1 F1 std Delta 
(bl 0.5) 

1 GI c a b GB TF-IDF 0.65 0.03 0.06 
2 GI c a GB TF-IDF 0.78 0.02 0.19 
3 GI c a SVM TF-IDF 0.73 0.02 0.14 
4 GI cs; RusPer; Re- 

views; Tw split; LJ split; 
FB split. 

Model 1 Seq. feat 0.88 0.03 0.38 

5 RusPer; Reviews; 
Tw split; LJ split; 
FB split; 

Model 1 Seq. feat 0.84 0.02 0.34 

6 GI c Model 1 Seq. feat 0.87 0.03 0.37 
7 Tw split; LJ split; 

FB split; 
Model 1 feature 0.82 0.02 0.32 

8 Tw; LJ; FB Model 1 Seq. feat 0.77 0.04 0.27 
9 GI cs; RusPer; Reviews Model 1 Seq. feat 0.88 0.03 0.38 
10 RusPer; Reviews Model 1 Seq. feat 0.79 0.03 0.29 
11 GI c a b Model 1 Seq. feat 0.86 0.03 0.36 
12 GI c a GB TF-IDF 0.79 0.02 0.29 

Table 6: Results of experiment on balance datasets. 

0.45 

0.5 

0.55 

0.6 

0.65 

0.7 

0.75 

0.8 

0.2 0.4 0.6 0.8 1 

F 
1- 
sc 
or 
e 

Training dataset size, % 

SVM 
Baseline 

Figure 1: Dependence of estimation of SVM from the size of training set. 

in which the achieve F1-score of 86% and the increase in comparison with bl of 23% correspond 
to the result obtain in this work. So, our result show that the state of the art in gender 
identification task with the RusProf corpus be about 88% with the superiority of deep learn 
model (Convolutional neural network - Model 1). Another consequence of the work be that the 
use of the collect corpus GI c allows to increase the accuracy of the task of identify gender 
of non-deceptive Russian texts. This be prove by training on the Crowdsoursing corpus with 
test on the GI corpus. So, this allows to exploit the same approach for text with gender 
decepton in the future. 

7 

Deep Learning neuronet model versus traditional machine learn . . . Sboev et al. 

Acknowledgements 

This research be support by the Russian Science Foundation, project No 16-18-10050. This 
work have be carry out use compute resource of the federal collective usage center 
Complex for Simulation and Data Processing for Mega-science Facilities at NRC ’Kurchatov 
Institute’, http://ckp.nrcki.ru/ 

References 

[1] Francisco Rangel, Paolo Rosso, Martin Potthast, and Benno Stein. Overview of the 5th author 
profile task at pan 2017: Gender and language variety identification in twitter. Working Notes 
Papers of the CLEF, 2017. 

[2] Angelo Basile, Gareth Dwyer, Maria Medvedeva, Josine Rawee, Hessel Haagsma, and Malvina 
Nissim. N-gram: New groningen author-profiling model. arXiv preprint arXiv:1707.03764, 2017. 

[3] Matej Martinc, Iza Škrjanec, Katja Zupan, and Senja Pollak. Pan 2017: Author profiling-gender 
and language variety prediction. Cappellato et al.[13], 2017. 

[4] Yasuhide Miura, Tomoki Taniguchi, Motoki Taniguchi, and Tomoko Ohkuma. Author profile 
with word+ character neural attention network. Cappellato et al.[13]. 

[5] Tatiana Litvinova, Pavel Seredin, Olga Litvinova, and Olga Zagorovskaya. Differences in type– 
token ratio and part-of-speech frequency in male and female russian write texts. In Proceedings 
of the Workshop on Stylistic Variation, page 69–73, 2017. 

[6] Tatiana Litvinova, Olga Litvinlova, Olga Zagorovskaya, Pavel Seredin, Aleksandr Sboev, and Olga 
Romanchenko. ”ruspersonality”: A russian corpus for authorship profile and deception detection. 
In Intelligence, Social Media and Web (ISMW FRUCT), 2016 International FRUCT Conference 
on, page 1–7. IEEE, 2016. 

[7] RusProfiling Lab. Rusprofiling corpus of russian texts. [online], 2017. http://rusprofilinglab. 
ru/rusprofiling-at-pan/corpus/. 

[8] Andrey Kutuzov and Elizaveta Kuzmenko. Building web-interfaces for vector semantic model 
with the webvectors toolkit. EACL 2017, page 99, 2017. 

[9] Nal Kalchbrenner, Ivo Danihelka, and Alex Graves. Grid long short-term memory. arXiv preprint 
arXiv:1507.01526, 2015. 

[10] Eliyahu Kiperwasser and Yoav Goldberg. Simple and accurate dependency parse use bidirec- 
tional lstm feature representations. arXiv preprint arXiv:1603.04351, 2016. 

[11] Lin Wu, Chunhua Shen, and Anton van den Hengel. Personnet: Person re-identification with deep 
convolutional neural networks. arXiv preprint arXiv:1601.07255, 2016. 

[12] Aleksandr Sboev, Tatiana Litvinova, Irina Voronina, Dmitry Gudovskikh, and Roman Rybka. 
Deep learn network model to categorize text accord to author’s gender and to identify text 
sentiment. In Computational Science and Computational Intelligence (CSCI), 2016 International 
Conference on, page 1101–1106. IEEE, 2016. 

8 



Alexander Sboev et al. / Procedia Computer Science 123 (2018) 424–431 431Deep Learning neuronet model versus traditional machine learn . . . Sboev et al. 

# Train datasets Model Features F1 F1 std Delta 
(bl 0.5) 

1 GI c a b GB TF-IDF 0.65 0.03 0.06 
2 GI c a GB TF-IDF 0.78 0.02 0.19 
3 GI c a SVM TF-IDF 0.73 0.02 0.14 
4 GI cs; RusPer; Re- 

views; Tw split; LJ split; 
FB split. 

Model 1 Seq. feat 0.88 0.03 0.38 

5 RusPer; Reviews; 
Tw split; LJ split; 
FB split; 

Model 1 Seq. feat 0.84 0.02 0.34 

6 GI c Model 1 Seq. feat 0.87 0.03 0.37 
7 Tw split; LJ split; 

FB split; 
Model 1 feature 0.82 0.02 0.32 

8 Tw; LJ; FB Model 1 Seq. feat 0.77 0.04 0.27 
9 GI cs; RusPer; Reviews Model 1 Seq. feat 0.88 0.03 0.38 
10 RusPer; Reviews Model 1 Seq. feat 0.79 0.03 0.29 
11 GI c a b Model 1 Seq. feat 0.86 0.03 0.36 
12 GI c a GB TF-IDF 0.79 0.02 0.29 

Table 6: Results of experiment on balance datasets. 

0.45 

0.5 

0.55 

0.6 

0.65 

0.7 

0.75 

0.8 

0.2 0.4 0.6 0.8 1 

F 
1- 
sc 
or 
e 

Training dataset size, % 

SVM 
Baseline 

Figure 1: Dependence of estimation of SVM from the size of training set. 

in which the achieve F1-score of 86% and the increase in comparison with bl of 23% correspond 
to the result obtain in this work. So, our result show that the state of the art in gender 
identification task with the RusProf corpus be about 88% with the superiority of deep learn 
model (Convolutional neural network - Model 1). Another consequence of the work be that the 
use of the collect corpus GI c allows to increase the accuracy of the task of identify gender 
of non-deceptive Russian texts. This be prove by training on the Crowdsoursing corpus with 
test on the GI corpus. So, this allows to exploit the same approach for text with gender 
decepton in the future. 

7 

Deep Learning neuronet model versus traditional machine learn . . . Sboev et al. 

Acknowledgements 

This research be support by the Russian Science Foundation, project No 16-18-10050. This 
work have be carry out use compute resource of the federal collective usage center 
Complex for Simulation and Data Processing for Mega-science Facilities at NRC ’Kurchatov 
Institute’, http://ckp.nrcki.ru/ 

References 

[1] Francisco Rangel, Paolo Rosso, Martin Potthast, and Benno Stein. Overview of the 5th author 
profile task at pan 2017: Gender and language variety identification in twitter. Working Notes 
Papers of the CLEF, 2017. 

[2] Angelo Basile, Gareth Dwyer, Maria Medvedeva, Josine Rawee, Hessel Haagsma, and Malvina 
Nissim. N-gram: New groningen author-profiling model. arXiv preprint arXiv:1707.03764, 2017. 

[3] Matej Martinc, Iza Škrjanec, Katja Zupan, and Senja Pollak. Pan 2017: Author profiling-gender 
and language variety prediction. Cappellato et al.[13], 2017. 

[4] Yasuhide Miura, Tomoki Taniguchi, Motoki Taniguchi, and Tomoko Ohkuma. Author profile 
with word+ character neural attention network. Cappellato et al.[13]. 

[5] Tatiana Litvinova, Pavel Seredin, Olga Litvinova, and Olga Zagorovskaya. Differences in type– 
token ratio and part-of-speech frequency in male and female russian write texts. In Proceedings 
of the Workshop on Stylistic Variation, page 69–73, 2017. 

[6] Tatiana Litvinova, Olga Litvinlova, Olga Zagorovskaya, Pavel Seredin, Aleksandr Sboev, and Olga 
Romanchenko. ”ruspersonality”: A russian corpus for authorship profile and deception detection. 
In Intelligence, Social Media and Web (ISMW FRUCT), 2016 International FRUCT Conference 
on, page 1–7. IEEE, 2016. 

[7] RusProfiling Lab. Rusprofiling corpus of russian texts. [online], 2017. http://rusprofilinglab. 
ru/rusprofiling-at-pan/corpus/. 

[8] Andrey Kutuzov and Elizaveta Kuzmenko. Building web-interfaces for vector semantic model 
with the webvectors toolkit. EACL 2017, page 99, 2017. 

[9] Nal Kalchbrenner, Ivo Danihelka, and Alex Graves. Grid long short-term memory. arXiv preprint 
arXiv:1507.01526, 2015. 

[10] Eliyahu Kiperwasser and Yoav Goldberg. Simple and accurate dependency parse use bidirec- 
tional lstm feature representations. arXiv preprint arXiv:1603.04351, 2016. 

[11] Lin Wu, Chunhua Shen, and Anton van den Hengel. Personnet: Person re-identification with deep 
convolutional neural networks. arXiv preprint arXiv:1601.07255, 2016. 

[12] Aleksandr Sboev, Tatiana Litvinova, Irina Voronina, Dmitry Gudovskikh, and Roman Rybka. 
Deep learn network model to categorize text accord to author’s gender and to identify text 
sentiment. In Computational Science and Computational Intelligence (CSCI), 2016 International 
Conference on, page 1101–1106. IEEE, 2016. 

8 


