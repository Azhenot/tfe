




































































































































































































Clinically applicable deep learn for diagnosis and referral in retinal disease 


Articles 
https://doi.org/10.1038/s41591-018-0107-6 

1DeepMind, London, UK. 2NIHR Biomedical Research Centre at Moorfields Eye Hospital and UCL Institute of Ophthalmology, London, UK. 
3Present address: University College London, London, UK. 4These author contribute equally: Julien Cornebise, Pearse A. Keane, Olaf Ronneberger. 
*e-mail: pearse.keane@moorfields.nhs.uk; olafr@deepmind.com 

Medical image be expand globally at an unprecedented rate1,2, lead to an ever-expanding quantity of data that require human expertise and judgement to interpret and 
triage. In many clinical speciality there be a relative shortage of this 
expertise to provide timely diagnosis and referral. For example, in 
ophthalmology, the widespread availability of optical coherence 
tomography (OCT) have not be match by the availability of 
expert human to interpret scan and refer patient to the appro- 
priate clinical care3. This problem be exacerbate by the marked 
increase in prevalence of sight-threatening disease for which OCT 
be the gold standard of initial assessment4–7. 

Artificial intelligence (AI) provide a promising solution for such 
medical image interpretation and triage, but despite recent break- 
through study in which expert-level performance on two-dimen- 
sional photograph in preclinical setting have be demonstrated8,9, 
prospective clinical application of this technology remains stymie 
by three key challenges. First, AI (typically train on hundred of 
thousand of example from one canonical dataset) must generalize 
to new population and device without a substantial loss of perfor- 
mance, and without prohibitive data requirement for retraining. 
Second, AI tool must be applicable to real-world scans, problem 
and pathways, and design for clinical evaluation and deployment. 
Finally, AI tool must match or exceed the performance of human 
expert in such real-world situations. Recent work apply AI to 

OCT have show promise in resolve some of these criterion in isola- 
tion, but have not yet show clinical applicability by resolve all three. 

Results 
Clinical application and AI architecture. We developed our 
architecture in the challenge context of OCT image for oph- 
thalmology. We test this approach for patient triage in a typi- 
cal ophthalmology clinical referral pathway, comprise more 
than 50 common diagnosis for which OCT provide the defini- 
tive image modality (Supplementary Table 1). OCT be a three- 
dimensional volumetric medical image technique analogous to 
three-dimensional ultrasonography but measure the reflection 
of near-infrared light rather than sound wave at a resolution for 
living human tissue of ~5 µ m10. OCT be now one of the most com- 
mon image procedure with 5.35 million OCT scan perform 
in the US Medicare population in 2014 alone (see https://www.cms. 
gov/Research-Statistics-Data-and-Systems/Statistics-Trends-and- 
Reports/Medicare-Provider-Charge-Data/Physician-and-Other- 
Supplier.html). It have be widely adopt across the UK National 
Health Service (NHS) for comprehensive initial assessment and tri- 
age of patient require rapid non-elective assessment of acute and 
chronic sight loss. Rapid access ‘virtual’ OCT clinic have become 
the standard of care11,12. In such clinics, expert clinician interpret 
the OCT and clinical history to diagnose and triage patient with 

Clinically applicable deep learn for diagnosis 
and referral in retinal disease 
Jeffrey De Fauw1, Joseph R. Ledsam1, Bernardino Romera-Paredes1, Stanislav Nikolov1, 
Nenad Tomasev1, Sam Blackwell1, Harry Askham1, Xavier Glorot1, Brendan O’Donoghue1, 
Daniel Visentin1, George van den Driessche1, Balaji Lakshminarayanan1, Clemens Meyer1, 
Faith Mackinder1, Simon Bouton1, Kareem Ayoub1, Reena Chopra 2, Dominic King1, Alan 
Karthikesalingam1, Cían O. Hughes 1,3, Rosalind Raine3, Julian Hughes2, Dawn A. Sim2, 
Catherine Egan2, Adnan Tufail2, Hugh Montgomery 3, Demis Hassabis1, Geraint Rees 3, 
Trevor Back1, Peng T. Khaw2, Mustafa Suleyman1, Julien Cornebise1,3,4, Pearse A. Keane 2,4* 
and Olaf Ronneberger 1,4* 

The volume and complexity of diagnostic image be increase at a pace faster than the availability of human expertise to inter- 
pret it. Artificial intelligence have show great promise in classify two-dimensional photograph of some common disease 
and typically relies on database of million of annotate images. Until now, the challenge of reach the performance of expert 
clinician in a real-world clinical pathway with three-dimensional diagnostic scan have remain unsolved. Here, we apply a 
novel deep learn architecture to a clinically heterogeneous set of three-dimensional optical coherence tomography scan 
from patient refer to a major eye hospital. We demonstrate performance in make a referral recommendation that reach 
or exceeds that of expert on a range of sight-threatening retinal disease after training on only 14,884 scans. Moreover, we 
demonstrate that the tissue segmentation produce by our architecture act a a device-independent representation; referral 
accuracy be maintain when use tissue segmentation from a different type of device. Our work remove previous barrier to 
wider clinical use without prohibitive training data requirement across multiple pathology in a real-world setting. 

NATuRE MEDiCiNE | VOL 24 | SEPTEMBER 2018 | 1342–1350 | www.nature.com/naturemedicine1342 

mailto:pearse.keane@moorfields.nhs.uk 
mailto:olafr@deepmind.com 
https://www.cms.gov/Research-Statistics-Data-and-Systems/Statistics-Trends-and-Reports/Medicare-Provider-Charge-Data/Physician-and-Other-Supplier.html 
https://www.cms.gov/Research-Statistics-Data-and-Systems/Statistics-Trends-and-Reports/Medicare-Provider-Charge-Data/Physician-and-Other-Supplier.html 
https://www.cms.gov/Research-Statistics-Data-and-Systems/Statistics-Trends-and-Reports/Medicare-Provider-Charge-Data/Physician-and-Other-Supplier.html 
https://www.cms.gov/Research-Statistics-Data-and-Systems/Statistics-Trends-and-Reports/Medicare-Provider-Charge-Data/Physician-and-Other-Supplier.html 
http://orcid.org/0000-0002-4264-8329 
http://orcid.org/0000-0001-6901-0985 
http://orcid.org/0000-0001-8797-5019 
http://orcid.org/0000-0002-9623-7007 
http://orcid.org/0000-0002-9239-745X 
http://orcid.org/0000-0002-4266-1515 
http://www.nature.com/naturemedicine 


ArticlesNATUre MediciNe 

pathology affect the macula, the central part of the retina that be 
require for high-resolution, color vision. 

Automated diagnosis of a medical image, even for a single dis- 
ease, face two main challenges: technical variation in the image 
process (different devices, noise, age of the component and so 
on), and patient-to-patient variability in pathological manifestation 
of disease. Existing deep learn approaches8,9 try to deal with all 
combination of these variation use a single end-to-end black-box 
network, thus typically require million of label scans. By con- 
trast, our framework decouples the two problem (technical varia- 
tions in the image process and pathology variants) and solves them 
independently (see Fig. 1). A deep segmentation network (Fig. 1b) 
creates a detailed device-independent tissue-segmentation map. 
Subsequently, a deep classification network (Fig. 1d) analysis this 
segmentation map and provide diagnosis and referral suggestions. 

The segmentation network (Fig. 1b) us a three-dimensional 
U-Net architecture13,14 to translate the raw OCT scan into a tis- 
sue map (Fig. 1c) with 15 class include anatomy, pathology 
and image artefact (Supplementary Table 2). It be train with 
877 clinical OCT scan (Topcon 3D OCT, Topcon) with sparse 
manual segmentation (dataset 1 in Supplementary Table 3, see 
Methods ‘Manual segmentation’ and ‘Datasets’ for full breakdown 
of scan dataset). Only approximately three representative slice 
out of the 128 slice of each scan be manually segment (see 
Supplementary Table 4 for image sizes). This sparse annotation pro- 
cedure14 allow u to cover a large variety of scan and pathology 
with the same workload a approximately 21 dense manual segmen- 
tations. Examples of the output of our segmentation network for 
illustrative pathology be show in Fig. 2. 

The classification network (Fig. 1d) analysis the tissue-seg- 
mentation map (Fig. 1c) and a the primary outcome provide 
one of four referral suggestion currently use in clinical practice 
at Moorfields Eye Hospital (please see Supplementary Table 1 for a 

list of retinal condition associate with these referral suggestions). 
Additionally, it report the presence or absence of multiple, con- 
comitant retinal pathology (Supplementary Table 5). To construct 
the training set for this network, we assemble 14,884 OCT scan 
volume obtain from 7,621 patient who be refer to the hos- 
pital with symptom suggestive of macular pathology (see Methods 
‘Clinical labeling’). These OCT scan be automatically segment 
use our segmentation network. The result segmentation map 
with the clinical label built the training set for the classification 
network (dataset 3 in Supplementary Table 3, illustrate in Fig. 1d). 

A central challenge in OCT-image segmentation be the presence 
of ambiguous regions, where the true tissue type cannot be deduce 
from the image, and thus multiple equally plausible interpreta- 
tions exist. To address this issue, we train not one but multiple 
instance of the segmentation network. Each network instance cre- 
ate a full segmentation map for the give scan, result in mul- 
tiple hypothesis (see Supplementary Fig. 1). Analogous to multiple 
human experts, these segmentation map agree in area with clear 
image structure but may contain different (but plausible) interpre- 
tations in ambiguous low-quality regions. These multiple segmen- 
tation hypothesis from our network can be displayed a a video, 
in which the ambiguous region and the propose interpretation 
be clearly visible (see Methods ‘Visualization of result in clinical 
practice’; use of this viewer across a range of challenge macular 
disease be illustrate in Supplementary Videos 1–9). 

Achieving expert performance on referral decisions. To evaluate 
our framework, we first define a gold standard. This use infor- 
mation that be not available at the first patient visit and OCT scan, 
by examine the patient clinical record to determine the final 
diagnosis and optimal referral pathway in the light of the (subse- 
quently obtained) information. Such a gold standard can only be 
obtain retrospectively. Gold standard label be acquire for 

c 

Tissue-segmentation map 

e 

Diagnosis probability 
and referral suggestion 

b 

Segmentation network 

a 

d 

Classification network 

877 manually segment 
training image 

14,884 training tissue map with confirm 
diagnosis and referral decision 

Normal 

CNV 

MRO 

CSR 
Full mac. hole 

Referral suggestion (%) 
98.9 
0.5 
0.4 
0.2 

7.1 
99.0 
5.4 
11.0 
24.2 
15.0 
43.4 
51.9 

0.050 

0.000ERM 
Drusen 

Urgent 
Semi-urgent 

Routine 
Observation only 

Diagnosis probability (%) 

Normal 
CNV 
MRO 

Full mac. hole 
Part. mac. hole 

CSR 
VMT 

Geo. atrophy 

Tissue volume (mm3)Digital OCT scan 

Fig. 1 | Our propose Ai framework. a, Raw retinal OCT scan (6 × 6 × 2.3 mm³ around the macula). b, Deep segmentation network, train with manually 
segment OCT scans. c, Resulting tissue segmentation map. d, Deep classification network, train with tissue map with confirm diagnosis and 
optimal referral decisions. e, Predicted diagnosis probability and referral suggestions. 

NATuRE MEDiCiNE | VOL 24 | SEPTEMBER 2018 | 1342–1350 | www.nature.com/naturemedicine 1343 

http://www.nature.com/naturemedicine 


Articles NATUre MediciNe 

997 patient that be not include in the training dataset (data- 
set 5 in Supplementary Table 5). We then test our framework on 
this dataset. For each patient, we obtain the referral suggestion 
of our framework plus an independent referral suggestion from 
eight clinical experts, four of whom be retina specialist and four 
optometrist train in medical retina (see Supplementary Table 
6 for more information). Each expert provide two separate deci- 
sions, one (like our framework) from the OCT scan alone (dataset 
7 in Supplementary Table 5); and one from the OCT plus fundus 
image and clinical note (dataset 8 in Supplementary Table 5, see 
Supplementary Fig. 2), in two separate session space at least two 
week apart. We compare each of these performance (framework 
and two expert decisions) against the gold standard. 

Our framework achieve and in some case exceed expert per- 
formance (Fig. 3). To illustrate this, Fig. 3a display performance 
on ‘urgent referrals’, the most important clinical referral decision 
(mainly for pathology that cause choroidal neovascularization; 
see Supplementary Table 1) versus all other referral decision a 
a receiver operating characteristic (ROC) plot (plots for the other 
decision be show in Supplementary Fig. 3). Performance of our 
framework match our two best retina specialist and have a sig- 
nificantly high performance than the other two retinal special- 
ists and all four optometrist when they use only the OCT scan 
to make their referral suggestion (Fig. 3a, fill markers). When 
expert have access to the fundus image and patient summary note 
to make their decision, their performance improve (Fig. 3a, empty 
markers) but our framework remain a good a the five best 
expert and continued to significantly outperform the other three 
(see Supplementary Information). 

To provide a more complete picture, the overall performance 
of our framework on all four clinical referral suggestion (urgent, 
semi-urgent, routine and observation only) compare to the two 
high perform retina specialist be displayed in Fig. 3b. The 
framework perform comparably to the two best-performing 
retina specialists, and make no clinically-serious wrong decision 
(top right element of each matrix; that is, refer a patient who 
need an urgent referral to observation only). Confusion matri- 
ce for the assessment of the other human expert be show in 
Supplementary Fig. 4. The aggregate number of wrong referral 
decision be displayed a error rate (1 − accuracy) for our framework 
and all expert in Fig. 3c. Our framework (5.5% error rate) per- 
form comparably to the two best retina specialist (6.7% and 6.8% 
error rate) and significantly outperform the other six expert in 
the ‘OCT only’ setting. Significance threshold (3.9% for high per- 
formance and 7.3% for low performance) be derive by a two- 
side exact binomial test, incorporate uncertainty from both the 
expert and the algorithm (see Methods ‘Statistical analysis’). When 
expert additionally use the fundus image and the summary note 
of the patient, five approach the performance of our framework 
(three retina specialist and two optometrists), which continued to 
significantly outperform the remain three (one retina specialist 
and two optometrists). 

Our framework us an ensemble of five segmentation and 
five classification model instance (see Supplementary Fig. 1) to 
achieve these results. Beside the benefit of an uncertainty measure, 
ensembling also significantly improves overall performance com- 
par to a single model instance. Error rate for different ensemble 
size be show in Supplementary Fig. 5. With more segmentation 

OCT 

Vitreous or subhyaloid space 
Posterior hyaloid 
Epiretinal membrane 
Neurosensory retina 
Intraretinal fluid 

Subretinal fluid 
Subretinal hyper reflect. mat. 
Retinal pigment epithelium 
Drusenoid PED 
Serous PED 

Fibrovascular PED 
Choroid and outer layer 
Padding artefact 
Blink artefact 
Foldover artefact 

Manual segmentation Automated segmentation 

a 

b 

c 

Fig. 2 | Results of the segmentation network. Three select two-dimensional slice from the n = 224 OCT scan in the segmentation test set (left) 
with manual segmentation (middle) and automate segmentation (right; detailed color legend in Supplementary Table 2). a, A patient with diabetic 
macular edema. b, A patient with choroidal neovascularization result from age-related macular degeneration (AMD), demonstrate extensive 
fibrovascular pigment epithelium detachment and associate subretinal fluid. c, A patient with neovascular AMD with extensive subretinal hyperreflective 
material. Further example of the variation of pathology with model segmentation and diagnostic performance can be found in Supplementary Videos 1–9. 
In all example the classification network predict the correct diagnosis. Scale bars, 0.5 mm. 

NATuRE MEDiCiNE | VOL 24 | SEPTEMBER 2018 | 1342–1350 | www.nature.com/naturemedicine1344 

http://www.nature.com/naturemedicine 


ArticlesNATUre MediciNe 

Retina specialist 1 
(OCT + fundus + notes) 

Our model 
(OCT only) 

Retina specialist 2 
(OCT + fundus + notes) 

100 

90 

80 

70 

60 

50 

40 

30 

20 

10 

0 
0 10 20 30 40 50 60 70 80 90 100 

Urgent referral 

False alarm rate (%) (n = 745) 

H 
it 

ra 
te 

( 
% 

) 
(n 

= 
2 

52 
) 

H 
it 

ra 
te 

( 
% 

) 
(n 

= 
2 

52 
) 

Our model (AUC = 99.21) 

Our model (balanced performance) 

Retina specialist 3 (~13 yr) 

Retina specialist 2 (~21 yr) 

Retina specialist 1 (~21 yr) 

Retina specialist 4 (~12 yr) 

Optometrist 1 (~15 yr) 

Optometrist 2 (~9 yr) 

Optometrist 3 (~6 yr) 

Optometrist 4 (~3 yr) 

100 

95 

90 

85 

80 

75 
0 5 

False alarm rate (%) (n = 745) 

10 15 20 25 

Zoom 

R1 

R4R2 

R3 

O3 

O4 

O2 

O1 

Urgent Routine 

Routine 

Obser- 
vation 

Obser- 
vation 

Predicted referral Predicted referral Predicted referral 
Semi- 
urgent 

Semi- 
urgent 

Urgent 

G 
ol 

d 
st 

an 
da 

rd 
r 

ef 
er 

ra 
l 

Urgent Routine 

Routine 

Obser- 
vation 

Obser- 
vation 

Semi- 
urgent 

Semi- 
urgent 

Urgent 

G 
ol 

d 
st 

an 
da 

rd 
r 

ef 
er 

ra 
l 

Urgent Routine 

Routine 

Obser- 
vation 

Obser- 
vation 

Semi- 
urgent 

Semi- 
urgent 

Urgent 

G 
ol 

d 
st 

an 
da 

rd 
r 

ef 
er 

ra 
l 

5 13 

2 

0 

0 

0 0 

031 

111 4 

0 2 20 

8 13 

0 

20 

4 

4 

3 

3 

1 1 10 

2 72 410 

1 1 14 

3 

234 

225 

228 

223 

254 

237 

231 

226 

250 

227 

250 

233 

25 

20 

15 

10 

5 

0 
Our 

model 
1 2 3 4 1 2 3 4 

Retina specialist Optometrists 

E 
rr 

or 
r 

at 
e 

(% 
) 

(lo 
w 

er 
be 

b 
et 

te 
r) 

Errors on referral decision 
(every error count equally) 

OCT only 

OCT + fundus + note 

Significantly bad (>7.3) 

Significantly good (<3.9) 

5.5 
6.8 

5.5 
6.7 6.3 

10.9 

13.0 

7.4 
6.6 

10.0 

6.5 

17.0 

8.8 

6.9 

10.7 

13.1 

24.1 

a 

b 

c 

Fig. 3 | Results on the patient referral decision. Performance on an independent test set of n = 997 patient (252 urgent, 230 semi-urgent, 266 routine, 
249 observation only). a, ROC diagram for urgent referral (for choroidal neovascularization (CNV)) versus all other referrals. The blue ROC curve be create 
by sweep a threshold over the predict probability of a particular clinical diagnosis. Points outside the light blue area correspond to a significantly 
different performance (95% confidence level, use a two-sided exact binomial test). The asterisk denotes the performance of our model in the ‘balanced 
performance’ setting. Filled marker denote experts’ performance use OCT only; empty marker denote their performance use OCT, fundus image and 
summary notes. Dashed line connect the two performance point of each expert. b, Confusion matrix with patient number for referral decision for our 
framework and the two best retina specialists. These show the number of patient for each combination of gold standard decision and predict decision. 
The number of correct decision be found on the diagonal. Wrong decision due to overdiagnosis be in the bottom-left triangle, and wrong decision 
due to underdiagnosis be in the top-right triangle. c, Total error rate (1 − accuracy) on referral decision. Values outside the light-blue area (3.9–7.3%) be 
significantly different (95% confidence interval, use a two-sided exact binomial test) to the framework performance (5.5%). AUC, area under curve. 

NATuRE MEDiCiNE | VOL 24 | SEPTEMBER 2018 | 1342–1350 | www.nature.com/naturemedicine 1345 

http://www.nature.com/naturemedicine 


Articles NATUre MediciNe 

model instance and more classification model instances, perfor- 
mance increases. The bottom right cell in that table illustrate that 
performance difference between 4 × 4 model instance and 5 × 5 
model instance be only marginal, so we do not expect significant 
change by add more instances. The accumulate number of 
diagnostic error do not fully reflect the clinical consequence 
that an incorrect referral decision might have for patients, which 
depends also on the specific diagnosis that be missed. For example, 
fail to diagnose sight-threatening condition could result in 
rapid visual loss3,15,16, which be not the case for many other diagno- 
ses. For an initial quantitative estimation of these consequences, 
we weight different type of diagnostic error accord to the 
judgement of our clinical expert of the clinical impact of errone- 
ous classification (expressed a penalty points; see Supplementary 
Fig. 6a). We derive a score for our framework and each expert 
a a weight average of all wrong diagnoses. This reveal that 
our framework achieve a low average penalty score than any 
of our expert (Supplementary Fig. 6b). We further optimize the 
decision of our framework to minimize this specific score (see 
Methods ‘Optimizing the ensemble output for sensitivity, speci- 
ficity and penalty scores’) which further improve performance 
(Supplementary Fig. 6b). Therefore, expert performance of our 
framework be not achieve at the cost of miss clinically impor- 
tant sight-threatening diagnoses. 

To examine how our propose two-stage architecture compare to 
a traditional single-stage architecture, we train an end-to-end clas- 
sification network with the same architecture a our second stage to 
directly map from a raw OCT scan to a referral decision (see Methods 
‘End-to-end classification network’). The error rate achieve with an 
ensemble of five network instance be 5.5%, which be not signifi- 
cantly different from the performance of the two-stage architecture. 
This validates our choice of the two-stage architecture that offer sev- 
eral clinical advantage (see Supplementary Fig. 7). 

Achieving expert performance on retinal morphology. The referral 
decision recommend by our framework be determine by the most 
urgent diagnosis detect on each scan (Supplementary Table 1). 
Patients may also have multiple concomitant retinal pathologies. 
These additional pathology do not change the referral decision, 
but may have implication for further investigation and treat- 
ment. Our framework be therefore also train to predict the 
probability of a patient have one or more of several pathology 
(Supplementary Table 5). 

To evaluate performance on diagnose multiple pathologies, 
a ‘silver standard’ for each scan be establish by majority vote 
from the eight expert who evaluate the OCT scan, fundus image 
and patient summary note (dataset 6 in Supplementary Table 3). 
This majority vote bias the assessment against our framework. 

a 

b 

c 

Original 
segmentation 

network 

Original 
classification 

network 

Total error rate: 46.6% 

Retrained 
segmentation 

network 

Total error rate: 3.4% 

d 

OCT scan from new device 

OCT scan from new device 

Predicted referral 

Urgent 
Semi- 
urgent Routine 

Obser- 
vation 

G 
ol 

d 
st 

an 
da 

rd 
r 

ef 
er 

ra 
l 10 3 0 

0 

0 

000 

0 2 

81 19 

21 

33 

19 

Original 
classification 

network 

G 
ol 

d 
st 

an 
da 

rd 
r 

ef 
er 

ra 
l 

Predicted referral 

33 

27 

35 

0 1 0 

0 0 

0 

20 0 

00 

1 

Urgent 

Semi- 
urgent 

Routine 

Obser- 
vation 

Urgent 

Semi- 
urgent 

Routine 

Obser- 
vation 

Urgent 
Semi- 
urgent Routine 

Obser- 
vation 

17 

Fig. 4 | Generalization to a new scan device type. a, Low performance of original network on OCT scan from the new device type 2. Left, the select 
slice show the different appearance of structure in device type 2. Middle, a poor quality segmentation map create with our original segmentation 
network (color legend in Supplementary Table 2). Right, result performance on a new test set of n = 116 patients. The confusion matrix show patient 
number for the referral suggestion. b, All five segmentation hypothesis from our original network. The strong variation show the large uncertainty. c, High 
performance be attain on the device type 2 test set (n = 116) after retrain the segmentation network with OCT scan from device type 1 and device 
type 2. The classification network be unchanged. d, All five segmentation hypothesis from the retrain segmentation network. The network be confident in 
the interpretation of most structures, and just highlight the ambiguity in the sub-retinal pigment epithelium (RPE) space. Scale bars: 0.5 mm. 

NATuRE MEDiCiNE | VOL 24 | SEPTEMBER 2018 | 1342–1350 | www.nature.com/naturemedicine1346 

http://www.nature.com/naturemedicine 


ArticlesNATUre MediciNe 

Nevertheless, our framework demonstrate an area under the 
ROC curve that be over 99% for most of the pathology (and 
over 96% for all of them; Supplementary Table 7), on par with the 
performance of the expert on OCT only. As with early evalu- 
ations, performance of the expert improve when they be 
provide also with the fundus image and patient summary notes. 
This improvement be most marked in pathology class a ‘rou- 
tine referral’, for example geographic atrophy and central serous 
retinopathy. Many of these pathology be condition for which 
the fundus photograph or demographic information would be 
expect to provide important information, indicate that there be 
scope for future work to improve the model. However even in the 
bad case our framework still perform on par with at least one 
retinal specialist and one optometrist (Supplementary Table 6 and 
Supplementary Fig. 8). 

Generalization to a new scan device type. A key benefit of 
our two-stage framework be the device independence of the second 
stage. Using our framework on a new device generation thus only 
require retrain of the segmentation stage to learn how each 

tissue type appear in the new scan, whereas the knowledge about 
patient-to-patient variability in pathological manifestation of differ- 
ent diseases, which it have learn from the approximately 15,000 
training cases, can be reused. To demonstrate this generalization, we 
collect an independent test set of clinical scan from 116 patient 
(plus confirm clinical outcomes) record with a different 
OCT scanner type from a different vendor (Spectralis, Heidelberg 
Engineering,; hereafter ‘device type 2’). This dataset be list a 
dataset 11 in Supplementary Table 3 (see Methods ‘Datasets’). We 
select this device type for several reasons. It be the second most 
use device type at Moorfields Eye hospital for these examinations, 
give rise to a sufficient number of scans. It have a similar worldwide 
market share a device type 1. But most importantly, this device type 
provide a large difference in scan characteristic compare to the 
original device type (see Supplementary Fig. 9). 

To evaluate the effect of a different scan device type, we ini- 
tially fed the OCT scan from device type 2 into our framework, 
which be train only on scan from device type 1 (Fig. 4a). 
The segmentation network be clearly ‘confused’ by the change 
appearance of these structure and attempt to explain them a 

Eye scan 603425 

a b 
Diagnosis probability (%) 

Normal 11.1 

Epiretinal membrane Posterior hyaloid 

0.1 mm 

1 mm 

0.1 mm 

0 mm 

Subretinal hyper reflect. materialSubretinal fluidIntraretinal fluidNeurosensory retina 

RPE Drusenoid PED Fibrovascular PED Serous PED 

1.2 mm 

0 mm 
1 mm 1 mm 

0.5 mm 

0 mm 

0.5 mm 

0 mm 

0.5 mm 

0 mm 

0.25 mm 

0 mm 
1 mm 

Vitreous and subhyaloid 
Posterior hyaloid 
Epiretinal membrane 
Neurosensory retina 
Intraretinal fluid 
Subretinal fluid 
Subretinal hyper reflective material 
Retinal pigment epithelium (RPE) 
Drusenoid PED 
Serous PED 
Fibrovascular PED 
Choroid and outer layer 
Mirror artefact 
Clipping artefact 
Blink artefact 

1 mm 

0.25 mm 

0 mm 

0.25 mm 

1 mm 

0.1 mm 

0 mm 
1 mm 

1 mm 

1 mm 

Raw OCT 
slice 80 

Pred. segmentation outline 
slice 80, segm. model Instance 2 

0 mm 

1 mm 1 mm 

0 mm 
1 mm 

Epiretinal membrane Posterior hyaloid 

0.1 mm 

1 mm 

0.1 mm 

0 mm 

Subretinal hyper reflect. materialSubretinal fluidIntraretinal fluidNeurosensory retina 

RPE Drusenoid PED Fibrovascular PED Serous PED 

1.2 mm 

0 mm 
1 mm 1 mm 

0.5 mm 

0 mm 

0.5 mm 

0 mm 

0.5 mm 

0 mm 

0.25 mm 

0 mm 
1 mm1 mm 

0.25 mm 

0 mm 

0.25 mm 

1 mm 

0.1 mm 

0 mm 
1 mm 

1 mm 

1 mm 

Raw OCT 
Slice 80 

Pred. segmentation outline 
slice 80, segm. model instance 2 

Pred. segmentation 
slice 80, segm. model instance 2 

0 mm 

1 mm 1 mm 

0 mm 
1 mm 

99.5 

6.9 

20.0 

23.9 

20.2 

37.8 

26.6 

CNV 

MRO 

Full mac. hole 

Part. mac. hole 

CSR 

Geo. atrophy 

VMT 

Referral suggestion (%) 

Tissue volume (mm3) 

Urgent 

Semi-urgent 

Routine 

Observation only 

Drusen 0.008 

ERM 0.190 

99.1 

0.4 

0.2 

0.3 

Fig. 5 | Visualization of the segmentation result a thickness maps. a, The average intensity projection of the OCT scan along A-scan direction (frontal 
view of the eye) be overlaid with a thickness map of the fibrovascular pigment epithelium detachment (PED, red segment). b, Screenshot from our OCT 
viewer. First row (left), referral suggestion, tissue volume and diagnosis probabilities. The highlight bar correspond to the select segmentation model. 
First–third rows, thickness map of the 10 relevant tissue type from segmentation model instance 2. The two healthy tissue type (high level retina and 
RPE) be displayed in a black–blue–green–brown–white color map, the pathological tissue (all others) be displayed a overlay on a projection of the raw 
OCT scan. The thin white line indicates the position of slice 80. Fourth row, slice 80 from the OCT scan and the segmentation map from segmentation 
model instance 2. Detailed tissue legend in Supplementary Table 2. The slice and model instance can be interactively select (see Supplementary Video 1). 

NATuRE MEDiCiNE | VOL 24 | SEPTEMBER 2018 | 1342–1350 | www.nature.com/naturemedicine 1347 

http://www.nature.com/naturemedicine 


Articles NATUre MediciNe 
additional retinal layer (Fig. 4a, middle). Consequently, perfor- 
mance be poor with a total error rate for referral suggestion of 46.6% 
(Fig. 4a, right). Uncertainty of the segmentation network on these 
(never seen) type of image result in five strongly different seg- 
mentation hypothesis (Fig. 4b). 

We next collect an additional segmentation training set with 
152 scan (527 manually segment slice in total) from this device 
(dataset 9 in Supplementary Table 3), and retrain the segmenta- 
tion network with both the training scan from the original device 
type 1 and the new device type 2 (see Methods ‘Segmentation net- 
work’). The classification network be not modified. 

Our retrain system (adapted segmentation network and 
unchanged classification network) now achieve a similarly high 
level of performance on device type 2 a on the original device 
(Fig. 4c). It suggest incorrect referral decision for 4 out of the 116 
cases, a total error rate of 3.4%. Owing to the small number of case 
in the new test set, this be not significantly different from the error rate 
of 5.5% on device type 1 (P(4 out of 116 < 55 out of 997) = 0.774; see 
Methods ‘Statistical analysis’). For continuity with our previous evalu- 
ation, we also measure performance against retina specialist access- 
ing OCT scan plus fundus image and clinical note (dataset 12 in 
Supplementary Table 3). Our expert achieve the follow error 
rate (all with access to image and clinical notes): retinal specialist 
one: 2 error = 1.7% error rate; retinal specialist two: 2 error = 1.7% 
error rate; retinal specialist three: 4 error = 3.4% error rate; retinal 
specialist four: 3 error = 2.6% error rate; retinal specialist five: 3 
error = 2.6% error rate. These difference in performance between 
our framework and the best human retina specialist do not reach 
statistical significance (P(4 out of 116 > 2 out of 116) = 0.776). 

To verify that device type 2 provide the great difference in 
scan characteristics, we perform a feasibility study on the small 
number of OCT scan from Cirrus HD-OCT 5000 with AngioPlex 
(Carl Zeiss Meditec) device available in Moorfields Eye Hospital 
(dataset of 61 scans; not include here). Applying our original net- 
work to these images, we already obtain an error rate of 16.4%. 
This rate be much low than that originally obtain with device 
type 2 (46.6%), consistent with the claim that device type 2 pro- 
vides a large difference in scan characteristic from device type 1. 
Retraining of the segmentation network with 6 manually segment 
scan reduce the error rate to 9.8%. 

Table 1 summarizes our results. For device type 1, our archi- 
tecture require 877 training scan with manual segmentation 
and 14,884 training scan with gold standard referral decision to 
achieve expert performance on referral decision (5.5% error rate). 
For device type 2, we only require 152 additional training scan 
with manual segmentation and not a single additional training 
scan with gold standard referral decision to achieve the same per- 
formance on referral decision on this device type (3.4% error rate). 

Discussion 
Recent work in which AI be use for the automate diagnosis of 
OCT scan show encourage results; however, until now such 
study have rely on selective and clinically unrepresentative OCT 
datasets. For example, several authors17–21 report high performance 
on automate classification of age-related macular degeneration 
(AMD) from OCT scans. However, they test their algorithm on 
small datasets that exclude other pathologies. By contrast, here we 
demonstrate expert performance on multiple clinical referral sug- 
gestions for two independent test datasets of 997 and 116 clinical 
OCT scan that include a wide range of retinal pathologies. 

Several recent study use deep learning-based architecture 
to deliver successful segmentation of OCT scans22–25. This early 
work focus on a subset of diagnostically relevant tissue type 
(for example, intraretinal fluid) and apply two-dimensional mod- 
el in sample of between 10 and 42 patients. In the present work, 
we go beyond these early study by apply three-dimensional 

models, segment a much large range of diagnostically relevant 
tissue types, and connect such segmentation to clinically relevant 
real-world referral recommendations. 

We evaluate our framework on a broad range of real-world 
image from routine clinical practice at 32 different Moorfields Eye 
Hospital sites, which cover diverse population within London and 
surround areas, use 37 individual OCT device (28 device type 
1 and 9 device type 2). The two device type that we test be both 
use widely in routine clinical practice at Moorfields Eye Hospital, 
the large eye hospital in Europe and North America, and provide 
a large difference in scan characteristics. 

Our framework have a number of potential benefits. The deriva- 
tion of device-independent segmentation of the OCT scan creates 
an intermediate representation that be readily viewable by a clini- 
cal expert and integrates into clinical workflow (see Fig. 5 for the 
clinical result viewer). Moreover, the use of an ensemble of five seg- 
mentation network instance allows u to present ambiguity aris- 
ing from the image process to the decision network (and could 
potentially be use for automate quality control). 

The ‘black box’ problem have be identify a an impediment 
to the application of deep learn in healthcare26. Here we cre- 
ated a framework with a structure that closely match the clini- 
cal decision-making process, separate judgement about the scan 
itself from the subsequent referral decision. This allows a clinician 
to inspect and visualize an interpretable segmentation, rather than 
simply be present with a diagnosis and referral suggestion. 
Such an approach to medical image AI offer potential insight 
into the decision process, in a fashion more typical of clinical prac- 
tice. For example, an interpretable representation be particularly 
useful in difficult and ambiguous cases. Such case be common in 
medicine and even expert medical practitioner can find it difficult 
to reach consensus (for example, our eight expert only agree on 
63.5% of case even when access all information). 

Our segmentation map assigns only one label per pixel, and it 
may not be possible to use the framework directly in other clinical 
pathway for which the tissue-segmentation map do not contain 
all require information for a diagnosis (for example, in certain 
radiomics applications). To keep the advantage of the intermedi- 
ate device-independent representation in such applications, future 
work can potentially augment the tissue-segmentation map with 
multiple label per pixel to encode local tissue features, or with 
additional channel that encode continuous feature such a an 
inflammatory reaction. This may be of particular value for other 
component of the retina, such a the nerve fibre layer, and may 
be of importance for multiple ocular and brain disorders, such a 
glaucoma and dementia. 

Although we have demonstrate the performance of our frame- 
work in the domain of a clinical treatment pathway, the approach 
have potential utility in clinical training in which the medical pro- 
fessionals must learn to read medical images. In addition, a wide 

Table 1 | Number of training scan and achieve performance on 
the two device type 

Training scan 
with sparse 
manual 
segmentation 

Training 
scan 
with gold 
standard 
referral 
decision 

Test 
performance 
on referral 
decision (error 
rate) 

Test 
performance 
on urgent 
referral 
(AuC) 

Device 
type 1 

877 14,884 55 out of 997 
(5.5%) 

99.21 

Device 
type 2 

152(+ 877 scan 
from device type 1) 

0 4 out of 116 
(3.4%) 

99.93 

NATuRE MEDiCiNE | VOL 24 | SEPTEMBER 2018 | 1342–1350 | www.nature.com/naturemedicine1348 

http://www.nature.com/naturemedicine 


ArticlesNATUre MediciNe 
variety of non-medically qualify health professional have an 
interest in appropriately reading and understand medical images. 
Our framework produce a visualizable segmentation and achieves 
expert performance on diagnosis and referral decision for a large 
number of scan and pathologies. This therefore raise the intrigu- 
ing possibility that such a framework could be evaluate a a tool for 
effectively training healthcare professional to expert levels. 

The segmentation output itself can also be use to quantify retinal 
morphology and derive measurement of particular pathology (for 
example, the location and volume of fibrovascular pigment epithe- 
lium detachment and macular edema). Some of these measurement 
(such a retinal thickness and intraretinal fluid) can currently be 
derive automatically27,28, use to investigate correlation with visual 
outcomes27 and a an end point in clinical trial of therapy for reti- 
nal disease29–32. Our framework can be use to define and validate a 
broader range of automatically derive quantitative measurements. 

Our framework can triage scan at first presentation of a patient 
into a small number of pathway use in routine clinical practice 
with a performance match or exceed both the expert retina 
specialist and optometrist who staff virtual clinic in a UK NHS 
setting. Future work can now directly seek evidence for the efficacy 
of such a framework in a randomize control trial. The output 
of our framework can be optimize to penalize different diagnostic 
errors, and thus for other clinically important metrics. For example, 
the potential improvement to patient quality of life of different diag- 
nostic decisions, or avoid the harm of unnecessary investigation 
that might come from a false-positive diagnosis, could all be incor- 
porated into future work. 

Globally, ophthalmology clinical referral pathway vary, and the 
range of disease that can potentially be diagnose by OCT include 
pathology additional to the macular disease that be study 
here. We study a major clinical referral pathway in a global center 
of clinical excellence focus on 53 key diagnosis relevant to the 
national (NHS) referral pathways. Our work open up the possi- 
bility of test the clinical applicability of this approach in other 
global setting and clinical pathways, such a emergency macular 
assessment clinic in the UK NHS, triage and assessment in com- 
munity eye care center and the monitoring of disease during 
treatment regimes. Furthermore, device such a binocular OCT33 
have the potential to increase accessibility in emerge economies. 
Images produce by such device will differ in resolution, contrast 
and image quality from the state-of-the-art device study here, 
and exist AI model train on current state-of-the-art device 
may perform poorly on such new devices. Our propose two-stage 
model offer excite possibility that enable the use of model 
more efficiently in country where state-of-the-art OCT device 
be too costly for widespread adoption. 

In conclusion, we present a novel framework that analysis clini- 
cal OCT scan and make referral suggestion to a standard that 
be comparable to clinical experts. Although we focus on one 
common type of medical imaging, future work can address a much 
wider range of medical image techniques, and incorporate clinical 
diagnosis and tissue type well outside the immediate application 
that be demonstrate here. 

Received: 19 December 2017; Accepted: 1 June 2018; 
Published online: 13 August 2018 

References 
1. OECD. Computed tomography (CT) exam (indicator). (2017); https://doi. 

org/10.1787/3c994537-en 
2. OECD. Magnetic resonance image (MRI) exam (indicator). (2017). https:// 

doi.org/10.1787/1d89353f-en 
3. Foot, B. & MacEwen, C. Surveillance of sight loss due to delay in ophthalmic 

treatment or review: frequency, cause and outcome. Eye 31, 771–775 (2017). 
4. Owen, C. G. et al. The estimate prevalence and incidence of late stage age 

related macular degeneration in the UK. Br. J. Ophthalmol. 96, 752–756 (2012). 

5. Rudnicka, A. R. et al. Incidence of late-stage age-related macular 
degeneration in American whites: systematic review and meta-analysis. 
Am. J. Ophthalmol. 160, 85–93 (2015). 

6. Bourne, R. R. A. et al. Magnitude, temporal trends, and projection of the 
global prevalence of blindness and distance and near vision impairment: a 
systematic review and meta-analysis. Lancet Glob. Health 5, 
e888–e897 (2017). 

7. Schmidt-Erfurth, U., Klimscha, S., Waldstein, S. M. & Bogunović, H. A view 
of the current and future role of optical coherence tomography in the 
management of age-related macular degeneration. Eye 31, 26–44 (2017). 

8. Gulshan, V. et al. Development and validation of a deep learn algorithm 
for detection of diabetic retinopathy in retinal fundus photographs. J. Am. 
Med. Assoc. 316, 2402–2410 (2016). 

9. Esteva, A. et al. Dermatologist-level classification of skin cancer with deep 
neural networks. Nature 542, 115––118 (2017). 

10. Huang, D. et al. Optical coherence tomography. Science 254, 
1178–1181 (1991). 

11. Buchan, J. C. et al. How to defuse a demographic time bomb: the way 
forward? Eye 31, 1519–1522 (2017). 

12. Whited, J. D. et al. A model economic analysis of a digital teleophthalmology 
system a use by three federal healthcare agency for detect proliferative 
diabetic retinopathy. Telemed. J. E Health 11, 641–651 (2005). 

13. Ronneberger, O., Fischer, P. & Brox, T. U-Net: convolutional network for 
biomedical image segmentation. in Navab N., Hornegger J., Wells W., Frangi 
A. (eds.) Medical Image Computing and Computer-Assisted Intervention – 
MICCAI 2015. MICCAI 2015. Lecture Notes in Computer Science, vol. 9351 
(Springer, Cham, Switzerland, 2015). 

14. Çiçek, Ö., Abdulkadir, A., Lienkamp, S. S., Brox, T. & Ronneberger, O. 3D 
U-Net: learn dense volumetric segmentation from sparse annotation. in 
Ourselin, S., Joskowicz, L., Sabuncu, M., Unal, G., Wells, W. (eds.) Medical 
Image Computing and Computer-Assisted Intervention – MICCAI 2016. 
MICCAI 2016. Lecture Notes in Computer Science, vol. 9901 (Springer, 
Cham, Switzerland; 2016). 

15. Muether, P. S., Hermann, M. M., Koch, K. & Fauser, S. Delay between 
medical indication to anti-VEGF treatment in age-related macular 
degeneration can result in a loss of visual acuity. Graefes Arch. Clin. Exp. 
Ophthalmol. 249, 633–637 (2011). 

16. Arias, L. et al. Delay in treat age-related macular degeneration in Spain be 
associate with progressive vision loss. Eye 23, 326–333 (2009). 

17. Karri, S. P. K., Chakraborty, D. & Chatterjee, J. Transfer learn base 
classification of optical coherence tomography image with diabetic macular 
edema and dry age-related macular degeneration. Biomed. Opt. Express 8, 
579–592 (2017). 

18. Apostolopoulos, S., Ciller, C., De Zanet, S. I., Wolf, S. & Sznitman, R. 
RetiNet: automatic AMD identification in OCT volumetric data. Preprint 
at http://arxiv.org/abs/1610.03628v1 (2016). 

19. Farsiu, S. et al. Quantitative classification of eye with and without 
intermediate age-related macular degeneration use optical coherence 
tomography. Ophthalmology 121, 162–172 (2014). 

20. Srinivasan, P. P. et al. Fully automate detection of diabetic macular edema 
and dry age-related macular degeneration from optical coherence 
tomography images. Biomed. Opt. Express 5, 3568–3577 (2014). 

21. Lee, C. S., Baughman, D. M. & Lee, A. Y. Deep learn be effective for 
classify normal versus age-related macular degeneration OCT images. 
Ophthalmol. Retin. 1, 322–327 (2017). 

22. Fang, L. et al. Automatic segmentation of nine retinal layer boundary in 
OCT image of non-exudative AMD patient use deep learn and graph 
search. Biomed. Opt. Express 8, 2732–2744 (2017). 

23. Lee, C. S. et al. Deep-learning based, automate segmentation of 
macular edema in optical coherence tomography. Biomed. Opt. Express 8, 
3440–3448 (2017). 

24. Lu, D. et al. Retinal fluid segmentation and detection in optical coherence 
tomography image use fully convolutional neural network. Preprint at 
http://arxiv.org/abs/1710.04778v1 (2017). 

25. Roy, A. G. et al. ReLayNet: retinal layer and fluid segmentation of macular 
optical coherence tomography use fully convolutional network. Biomed. 
Opt. Express 8, 3627–3642 (2017). 

26. Castelvecchi, D. Can we open the black box of AI? Nature 538, 
20–23 (2016). 

27. Schmidt-Erfurth, U. et al. Machine learn to analyze the prognostic value 
of current image biomarkers in neovascular age-related macular 
degeneration. Ophthalmol. Retin. 2, 24–30 (2018). 

28. Schlegl, T. et al. Fully automate detection and quantification of macular 
fluid in OCT use deep learning. Ophthalmology 125, 549–558 (2018). 

29. Keane, P. A. & Sadda, S. R. Predicting visual outcome for macular 
disease use optical coherence tomography. Saudi J. Ophthalmol. 25, 
145–158 (2011). 

30. Schaal, K. B., Rosenfeld, P. J., Gregori, G., Yehoshua, Z. & Feuer, W. J. 
Anatomic clinical trial endpoint for nonexudative age-related macular 
degeneration. Ophthalmology 123, 1060–1079 (2016). 

NATuRE MEDiCiNE | VOL 24 | SEPTEMBER 2018 | 1342–1350 | www.nature.com/naturemedicine 1349 

https://doi.org/10.1787/3c994537-en 
https://doi.org/10.1787/3c994537-en 
https://doi.org/10.1787/1d89353f-en 
https://doi.org/10.1787/1d89353f-en 
http://arxiv.org/abs/1610.03628v1 
http://arxiv.org/abs/1710.04778v1 
http://www.nature.com/naturemedicine 


Articles NATUre MediciNe 
31. Schmidt-Erfurth, U. & Waldstein, S. M. A paradigm shift in image 

biomarkers in neovascular age-related macular degeneration. Prog. Retin. 
Eye Res. 50, 1–24 (2016). 

32. Villani, E. et al. Decade-long profile of image biomarker use in ophthalmic 
clinical trials. Invest. Ophthalmol. Vis. Sci. 58, BIO76–BIO81 (2017). 

33. Chopra, R., Mulholland, P. J., Dubis, A. M., Anderson, R. S. & Keane, P. A. 
Human factor and usability test of a binocular optical coherence 
tomography system. Transl. Vis. Sci. Technol. 6, 16 (2017). 

Acknowledgements 
We thank K. Kavukcuoglu, A. Zisserman, M. Jaderberg, K. Simonyan for discussions, 
A. Cain and M. Cant for work on the visuals, D. Mitchell and M. Johnson for 
infrastructure and system administration, J. Morgan and OpenEyes for provide the 
electronic health record records, T. Peto, P. Blows, A. O’Shea and the NIHR Clinical 
Research Facility for work on the labeling, T. Heeran, M. Lukic, K. Kortum, K. Fasler, 
S. Wagner and N. Pontikos for work on the labeling, E. Steele, V. Louw, S. Gill and the 
rest of Moorfields IT team for work on the data collection and deidentification, 
S. Al-Abed and N. Smith for Moorfields technical advice at project initiation, R. 
Wood and D. Corder at Softwire for engineering support at Moorfields, R. Ogbe and 
the Moorfields Information Governance team for support, M. Hassard for Moorfields 
research and development support, K. Bonstein and the National Institute for Health 
Research (NIHR) for support at the Moorfields Biomedical Research Centre (BRC), 
J. Besley for legal assistance, E. Manna for patient engagement and support, and the 
rest of the DeepMind team for their support, idea and encouragement. P.A.K. be 
support by an NIHR Clinician Scientist Award (NIHR-CS-2014-14-023). D.A.S., 
A.T., C.E. and P.T.K. be support by the NIHR Biomedical Research Centre at 
Moorfields Eye Hospital NHS Foundation Trust and UCL Institute of Ophthalmology 
and the NIHR Moorfields Clinical Research Facility. The view express be those 
of the author(s) and not necessarily those of the NHS, the NIHR or the Department 
of Health. R.C. receives studentship support from the College of Optometrists, 
United Kingdom. 

Author contribution 
P.A.K., M.S., J.C., D.H., P.T.K., T.B. and K.A. initiate the project and the collaboration. 
O.R., J.D.F., B.R.-P. and S.N. developed the network architectures, training and test 
setup. P.A.K., J.R.L. and R.C. design the clinical setup. P.A.K., J.R.L., J.C., R.C., D.A.S., 
C.E. and A.T. create the dataset and define clinical labels. J.D.F., B.R.-P., S.N., N.T., S.Bl., 
H.A., B.O., D.V., G.v.d.D., O.R. and J.C. contribute to the software engineering. J.R.L., 
S.Bl. and H.A. create the database. P.A.K., J.R.L., D.K., A.K., C.O.H. and R.R. contribute 
clinical expertise. O.R., P.A.K., J.D.F., J.R.L., B.R.-P., S.N., N.T. and X.G. analyse the 
data. T.B., S.Bo., J.C., J.H., F.M. and C.M. manage the project. O.R., P.A.K., J.R.L., J.D.F., 
B.R.-P., G.R. and H.M. write the paper. B.L. contribute to the uncertainty estimation. 

Competing interest 
P.A.K., G.R., H.M. and R.R. be paid contractor of DeepMind. P.A.K. have receive 
speaker fee from Heidelberg Engineering, Topcon, Haag-Streit, Allergan, Novartis and 
Bayer. P.A.K. have serve on advisory board for Novartis and Bayer, and be an external 
consultant for DeepMind and Optos. A.T. have serve on advisory board for 
the follow companies: Allergan, Bayer, Genentech, GlaxoSmithKline, Novartis, Roche. 
C.E. have receive speaker fee from Heidelberg Engineering and Haag-Streit UK. P.T.K. 
have serve on advisory board for Aerie, Allergan, Alcon, Belkin Laser, Novartis and 
Santen. D.A.S. have receive speaker fee from Novartis, Bayer, Allergan, Haag-Streit. 
The author have no other compete interest to disclose. 

Additional information 
Supplementary information be available for this paper at https://doi.org/10.1038/ 
s41591-018-0107-6. 

Reprints and permission information be available at www.nature.com/reprints. 

Correspondence and request for material should be address to P.A.K. or O.R. 

Publisher’s note: Springer Nature remains neutral with regard to jurisdictional claim in 
publish map and institutional affiliations. 

NATuRE MEDiCiNE | VOL 24 | SEPTEMBER 2018 | 1342–1350 | www.nature.com/naturemedicine1350 

https://doi.org/10.1038/s41591-018-0107-6 
https://doi.org/10.1038/s41591-018-0107-6 
http://www.nature.com/reprints 
http://www.nature.com/naturemedicine 


ArticlesNATUre MediciNe 
Methods 
Ethics and information governance. This work and the collection of data on 
imply consent receive national Research Ethics Committee (REC) approval 
from the Cambridge East REC and Health Research Authority approval (reference 
16/EE/0253); it complies with all relevant ethical regulations. Deidentification 
be perform in line with the Information Commissioner’s Anonymization: 
manage data protection risk code of practice (https://ico.org.uk/media/1061/ 
anonymisation-code.pdf), and validate by the Moorfields Eye Hospital 
Information Technology and Information Governance departments, respectively. 
Only deidentified retrospective data be use for research, without the active 
involvement of patients. 

Visualization of result in clinical practice. To facilitate view of the result in 
routine clinical practice, we display the obtain three-dimensional segmentation 
map a two-dimensional thickness map overlaid on a projection of the raw OCT 
scan (Fig. 5a). The thickness map for all tissue type be displayed side-by-side 
in our interactive OCT viewer (Fig. 5b and Supplementary Video 1). Our system 
also provide measure for it degree of certainty on both overall referral decision, 
and each specific retinal disease feature. In most common clinical scenarios, the 
algorithm will both provide the diagnosis with a high degree of certainty and 
highlight classical disease feature (for example, ‘wet’ AMD; Supplementary Video 2). 
This visualization may be particularly useful for difficult and ambiguous cases, such 
a the diagnosis of choroidal neovascularization formation in case of chronic central 
serous retinopathy (Supplementary Videos 5, 7) or in advanced geographic atrophy 
due to AMD (Supplementary Video 6). Such visualization may also allow clinician 
to discard an automate diagnosis or referral suggestion in obvious failure cases, such 
a when poor image quality lead to erroneous segmentation result (Supplementary 
Video 8). Furthermore, in a screen context the tissue segmentation map can 
facilitate quality assurance procedures, whether in normal case (Supplementary 
Video 3) or in disease case (for example, diabetic macular edema in the context of 
diabetic retinopathy screening, Supplementary Video 4). 

Datasets and clinical taxonomy. Datasets. Data be select from a retrospective 
cohort of all patient who attend Moorfields Eye Hospital NHS Foundation 
Trust, a world renowned tertiary referral center with 32 clinic site serve an 
urban, mixed socioeconomic and ethnicity population center around London, 
United Kingdom, between 1 June 2012 and 31 January 2017, who receive OCT 
image (Topcon 3D OCT, Topcon; Spectralis, Heidelberg Engineering) a part 
of their routine clinical care. Conditions with few than ten cases, and data from 
patient who have manually request that their data should not be shared, be 
exclude before research began. OCT scan set contain severe artefact or 
marked reduction in signal strength to the point at which retinal interface could 
not be identify be also exclude from the study (Supplementary Fig. 10), a 
such scan be non-diagnostic and in practice would usually be retaken. Scans to 
which no diagnostic label could be attach (as described below) be exclude 
from the present study. For OCT examination that be label a urgent or semi- 
urgent in the Moorfields OpenEyes electronic health record only scan take prior 
to treatment begin be included; during treatment, resolution of pathology 
invalidates the database labels. The dataset selection and stratification process be 
displayed in a CONSORT flow diagram in Supplementary Fig. 11. 

Two OCT device type be select for investigation. 3D OCT-2000 (Topcon, 
Japan) be select a device type 1, because of it routine use in the clinical 
pathway that we studied. For device type 1, a total of 15,877 OCT scan from 7,981 
individual patient (mean age 69.5; 3,686 male, 4,294 female, 1 gender unknown) 
be eligible for inclusion in the work (datasets 3 and 4 in Supplementary Table 3). 
To create a test set representative of the real-world clinical application, 997 
additional patient (mean age 63.1; 443 male, 551 female, 3 gender unknown) 
present to Moorfields with visual disturbance during the retrospective period 
be select and only their referral OCT examination be select for inclusion in 
the test set (dataset 5 in Supplementary Table 3); a sample size requirement of 553 
to detect sensitivity and specificity at 0.05 marginal error and 95% confidence be 
use to inform the number included. To demonstrate the generalizability of our 
approach, Spectralis OCT (Heidelberg Engineering) be chosen a ‘device 
type 2’. For generalizability experiments, a second test set of clinical OCT 
scan from 116 patient (mean age 58.2; 59 male, 57 female) present in the 
same manner be select use the same methodology and selection criterion 
(dataset 11 in Supplementary Table 3). Examples of difference between the two 
device type be show in Supplementary Fig. 9. Supplementary Table 8 show a 
breakdown of patient and triage category in the datasets. 

Clinical taxonomy. OCT examination be mapped from individual diagnosis 
and treatment information to specific triage decision (urgent referral, semi-urgent 
referral, routine referral and observation only) to a medical retina clinic set 
(Supplementary Table 1). Where possible, the presence or absence of additional 
pathology be add a a label (Supplementary Table 5). The dataset represent 
the full variety of medical retina patient present and receive treatment at 
Moorfields Eye Hospital. Although the exact mapping be chosen to be relevant 
to the triage decision at Moorfields Eye Hospital where the research work take 
place, the framework be generalizable to other system at center with different 

triage requirement (for example, optometrist work in a high-street clinic 
set or ophthalmologist without subspecialty retinal expertise). Scans meeting 
the exclusion criterion be remove from the database before splitting the data into 
training, validation and test sets. Supplementary Figure 12 provide an example of 
variation within the ‘urgent referral’ label class. 

Clinical labeling. Clinical label for the 14,884 scan in dataset 3 in Supplementary 
Table 3 be assign through an automate note search with train 
ophthalmologist and optometrist review of the OCT scans. The presence or 
absence of choroidal neovascularization, referable macular edema, normal and 
other pathology visible on the OCT scan be recorded. In addition, patient with 
choroidal neovascularization or macular edema confirm through treatment be 
label directly from the Moorfields OpenEyes electronic health record. 
A validation subset of 993 scan (993 patients) be grade separately by three 
junior grader (ophthalmologists specialize in medical retina) with disagreement 
in clinical label arbitrate by a senior retinal specialist with over 10 year of 
experience and image reading center certification for OCT segmentation (dataset 
4 in Supplementary Table 3). The test set be further verify by full review of 
the note with access to follow up data with both junior and senior grader review. 
Junior and senior grader be separate to those participate in the evaluation of 
expert performance. 

Manual segmentation. A subset of 1,101 scan from device type 1 and a set of 
264 scan from device type 2 be manually segment use the segmentation 
editor plugin for ImageJ (Fiji)34 (datasets 1, 2, 9 and 10 in Supplementary Table 3). 
The segmentation label be chosen to distinguish all relevant diagnosis for the 
referral decision, a well a potential artefact that may affect the diagnostic quality 
of the whole or part of the scan. In particular, the current state of art do not 
differentiate between the three different type of pigment epithelial detachment, 
or segment out area of fibrosis scar or blood a hyperreflective material27,28. 
Anatomical delineation and nomenclature be consistent with standard 
grade criterion for the evaluation of OCT35–37. The segmentation example be 
select and segment by ophthalmologist specialize in medical retina a 
representative case for pathological features. These be review and edit 
by a senior ophthalmologist with over 10 year of experience and image reading 
center certification for OCT segmentation. Per OCT, 3–5 slice be chosen for 
segmentation, which best represent the pathological feature (Supplementary 
Tables 2, 9 and Supplementary Fig. 13). 

Evaluating the expert performance. To evaluate expert performance on the test set, 
eight clinical expert be recruit for an evaluation study. Participants include 
four consultant ophthalmologist at Moorfields Eye Hospital with fellowship-level 
subspecialty training in medical retinal disease and extensive clinical experience 
(21, 21, 12.5 and 11.5 year of experience) and four optometrist at Moorfields Eye 
Hospital with specialist training in OCT interpretation and retinal disease (15, 9, 
6 and 2.5 year of experience). These be refer to a retinal specialist 1–4 and 
optometrist 1–4 in the rest of the paper (Supplementary Table 10). Each expert 
be instruct to provide a triage decision (Supplementary Table 1) and to record 
the presence or absence of define pathological feature (Supplementary Table 5). 

To ass the performance in a realistic clinical environment, all scan be 
read in a random order twice with at least a week between readings. During the 
initial review, only the OCT scan be present (dataset 7 in Supplementary Table 
3). During the second review, participant be present with all the information 
available at the time of triage: OCT and fundus scans, age, gender, ethnicity and 
where available information on visual acuity and a short clinical vignette (dataset 8 
in Supplementary Table 3). The model only receive the OCT scan. 

To ass the difference between the test set for device type 1 and device type 
2, five clinical expert be recruit for a further evaluation study (dataset 12 
in Supplementary Table 3). Participants be five consultant ophthalmologist 
at Moorfields Eye Hospital with fellowship-level subspecialty training in 
medical retinal disease (21, 21, 12.5, 11.5 and 11 year of experience). Four be 
participant in the device type 1 evaluation study, while the other be a new 
participant for this study and be refer to a retina specialist five. 

Network architecture and training protocol. Segmentation network. The first 
stage of our framework consists of a segmentation network that take a input part 
of the OCT scan, and output a part of a segmentation map. That is, it predicts for 
each voxel one tissue type out of the 15 class described in Supplementary Table 2. 
At training time, the input of the network consists of 9 contiguous slice of an OCT, 
and the goal of the network be to segment the central slice. The input be therefore a 
448 × 512 × 9 voxels image, and the output be an estimate probability over the 15 
classes, for each of the 448 × 512 × 1 output voxels. None of the convolution make 
across the slice (z dimension) add pad to it input. As a result, we can exploit 
share computation at inference time to predict any number of contiguous slice 
in parallel, which be only limited by the memory capacity of the system. 

The structure of the segmentation convolutional neural network model be 
show in Supplementary Fig. 14. It us a three-dimensional U-Net architecture14, 
consist of an analysis (downwards) path, a synthesis (upwards) path, and 
shortcut connection between block of the same level and different paths. 

NATuRE MEDiCiNE | www.nature.com/naturemedicine 

https://ico.org.uk/media/1061/anonymisation-code.pdf 
https://ico.org.uk/media/1061/anonymisation-code.pdf 
http://www.nature.com/naturemedicine 


Articles NATUre MediciNe 
We apply four variation over it. First, we use 3 × 3 × 1 convolution with 
pad and 1 × 1 × 3 convolution without pad instead of 3 × 3 × 3 
convolution without padding. Second, downsampling and upsampling operation 
be carry out through parameter-free bilinear interpolation, replace max- 
pool and up-convolution. Third, we introduce one extra residual connection 
within each block of layers, so that the output of each block consists of the sum of 
the feature of the last layer, and the first layer of the block in which the feature 
dimension match. Finally, the middle block of layer between the analysis and 
synthesis path be compose of a sequence of fully connect layers. The first 
variation allows u to control the receptive field for z separately and be furthermore 
less computationally intensive. The second and third variation aim at improve 
the gradient flow throughout the network, which make the training process 
easier. The last variation extends the receptive field such that each pixel in the 
output effectively have the whole input contain within it receptive field. 

We use per-voxel cross entropy a the loss function, with 0.1 label-smoothing 
regularization38. We have neither use dropout nor weight decay a regularization 
means, a preliminary experiment show that this do not improve the 
performance. We train the model in TensorFlow39 with the Adam optimizer40 
for 160,000 iteration on 8 graphic processing unit (GPUs) with dataset 1 in 
Supplementary Table 3. The initial learn rate be 0.0001 and set to 0.0001/2 
after 10% of the total iterations, 0.0001/4 after 20%, 0.0001/8 after 50%, 0.0001/64 
after 70%, 0.0001/256 after 90% and finally 0.0001/512 for the final 5% of training. 
All decision and hyperparameters above be select on the basis of their 
performance on a validation set (dataset 2 in Supplementary Table 3). 

To improve the generalization ability of our model, we augment the data 
by apply affine and elastic transformation jointly over the input and ground- 
truth segmentations13,14. Intensity transformation over the input be also 
applied. 

Our segmentation network for device type 2, which be show in Supplementary 
Fig. 15, be train on scan from both device (datasets 1 and 9 in Supplementary 
Table 3) with the aim of leverage the large number of label instance for device 
type 1. It have three change compare to the architecture for device type 1. First, 
we subsample the input from device type 1 (128 slices) to match the resolution of 
device type 2 (49 slices) and apply slight pad in height to the scan of device 
type 2 to give them of the same shape in height and width a the scan of device 
type 1. Second, the input first go through one of two ‘device adaptation branches’, 
depend on the device type of the input scan. The architecture of this branch 
consists of three convolution with padding, with one residual connection a in the 
other blocks, and be identical for both device type (see Supplementary Fig. 15). 
The network can then simply learn to compensate for the change between device 
type early on and map them to a common representation. Lastly, the number 
of feature map on the first level of the analysis path be halve from 32 to 16 
such that the overall architecture still have few parameter than the architecture 
for device type 1. During training, the network be present with a ratio of 
2.5: 1 for training sample from device type 2:device type 1. All decision and 
hyperparameters above be select on the basis of their performance on a 
validation set (datasets 2 and 10 in Supplementary Table 3). 

Classification network. The classification network learn to map a segmentation 
map to the four referral decision and the ten additional diagnosis (see 
Supplementary Fig. 16). For device type 1, it take a input a 300 × 350 × 43 
subsampling of the original 448 × 512 × 128 segmentation map create by the 
segmentation network described above. The output be a 14-component vector. For 
device type 2, for which the scan originally be 448 × 512 × 49, we first upscaled 
the segmentation map to the same resolution a for device type 1 and then proceed 
identically a for device type 1. The architecture us a three-dimensional version 
of the dense block described previously41 use 3 × 3 × 1 and 1 × 1 × 3 convolutions. 
The detail of it structure be show in Supplementary Fig. 16. We found use 
dense convolution block to be critical for training classification network on large 
three-dimensional volumes. The input be one-hot encode and augment by 
random three-dimensional affine and elastic transformations14. The loss be the 
sum of the softmax cross entropy loss for the first four component (multi-class 
referral decision) and the sigmoid cross entropy loss for the remain ten 
component (additional diagnosis labels). We also use a small amount (0.05) 
of label-smoothing regularization38 and add some (1 × 10−5) weight decay. 
We train the model in TensorFlow39 with the Adam optimiser40 for 160,000 
iteration of batch size 8 spread across 8 GPUs with 1 sample per GPU with 
dataset 3 in Supplementary Table 3. The initial learn rate be 0.02 and set to 
0.02/2 after 10% of the total iterations, 0.02/4 after 20%, 0.02/8 after 50%, 0.02/64 
after 70%, 0.02/256 after 90% and finally 0.02/512 for the final 5% of training. All 
decision and hyperparameters described above be select on the basis of their 
performance on a validation set (dataset 4 in Supplementary Table 3). 

Ensembling. For both of these network we train five instances. We train the 
same network with a different order of the input and different random weight 
initializations42. Previously publish experiments42 suggest that five instance be 
sufficient in most settings, so we also use this number. For our experiments, we 
apply the five instance of our segmentation model to the input scan result in 
five segmentation maps. The five instance of our classification model be then 

apply to each of the segmentation maps, result in a total of 25 classification 
output per scan, a illustrate in Supplementary Fig. 1. The result report be 
obtain after average the probability estimate by these models. 

Optimizing the ensemble output for sensitivity, specificity and penalty scores. 
For different applications, the prefer compromise between a high hit rate 
(sensitivity) and a low false alarm rate (1 − specificity) can be different. For 
the binary diagnosis decisions, we compute an optimal rescale factor a 
for the pseudo-probabilities, such that a 50% threshold achieves maximal 
(sensitivity + specificity)/2 on the validation set (dataset 4 in Supplementary 
Table 3). The rescale be do by p = aq/(aq + (1 − a)(1 − q)), where q 
denotes the ensemble output and p the reweighted probability. We use 
(sensitivity + specificity)/2 instead of the total accuracy to avoid the bias due to the 
low number of patient with a positive condition in the validation set (and in the 
test set). For a balance set with equal number of positive and negative sample 
this term be exactly the accuracy. 

For the four-way referral decision (where the high probability wins), we 
optimize four scale factor use the validation set to reduce the overall cost 
specify by the misclassification penalty matrix (Supplementary Fig. 6). A first 
set of factor be optimize for a balance between high accuracy and low penalty 
point (referred to a "our model (1)" in Supplementary Figure 6), a second set 
of factor be optimize for penalty cost only (referred to a "our model (2)" in 
Supplementary Figure 6). The cost matrix for the balance performance be 
compute by average the normalize cost matrix for accuracy (a matrix with 0 
in the diagonal element and 1 in the off-diagonal elements) and the normalize 
penalty cost matrix. Normalization be perform by divide the matrix by the 
sum of all elements. The optimization of the four factor be do with the Adam 
optimiser use a softmax layer and a weight cross-entropy loss layer. 

End-to-end classification network. The network architecture for the end-to-end 
classification experiment be identical to the architecture of the classification 
network in the two-stage approach (see ‘Classification network’ and Supplementary 
Fig. 16) with a small adaption. To roughly obtain the same number of parameters, 
we add a dense layer (two convolution with seven channel output each) that 
translates the single-channel raw OCT to a 14-channel feature map. All select 
hyperparameters and augmentation strategy be identical to the original 
classification network. We train five network instance on the training set with 
14,884 raw OCT scan from device type 1 (dataset 13 in Supplementary Table 3). 
Each network instance be initialize with different random weight and be 
present with the training image in a different order. After training, we also 
compute an optimal reweighting on the validation set (as we do for the two-stage 
model) and test the ensemble on the test set. 

Statistical analysis. Significant difference use a two-sided exact binomial test. 
The comparison of our model’s performance to the expert’s performance be base 
on the assumption that our model and the expert have an unknown but constant 
performance. That is, every inspect eye scan be correctly diagnose by our model 
with the probability pmod, and correctly diagnose by the expert with probability 
pexp. For N eye scan the number of correct diagnosis k be therefore binomially 
distribute with Pr(k) = B(k|p,N). If our model achieves kmod correct diagnosis and 
the expert achieves kexp correct diagnoses, the probability that the true performance 
of our model pmod be high than the true performance of the expert pexp be 

∫ ∫ 

∫ ∫ 

> ∣ = 

∣ ∣ 

∣ ∣ 

p p k k N 

k p N k p N dp dp 

k p N dp k p N dp 

Pr( , , ) 

B( , ) B( , ) 

B( , ) B( , ) 

p 
mod exp mod exp 

0 

1 
mod 1 0 exp 2 2 1 

0 

1 
mod 0 

1 
exp 

1 

The probability for a low performance, that be Pr(pmod < pexp|kmod, kexp, N) be derive 
analogously. For all comparisons, a confidence level of 95% be used. The formula 
be numerically integrate use in-house code. 

Further detail on the method be described in a publish protocol describe 
the DeepMind collaboration with Moorfields Eye Hospital43. 

Reporting Summary. Further information on experimental design be available in 
the Nature Research Reporting Summary link to this article. 

Code availability. The code base for the deep-learning framework make use of 
proprietary component and we be unable to publicly release the full code base. 
However, all experiment and implementation detail be described in sufficient 
detail in the Methods and in the Supplementary Figs. to enable independent 
replication with non-proprietary libraries. The three-dimensional augmentation 
code (using the caffe framework) be available a part of the three-dimensional 
U-net source code at https://lmb.informatik.uni-freiburg.de/resources/ 
opensource/unet.en.html. Additionally, although we be unable to make all the 
Google proprietary component available, we be in the process of make the 
augmentation operation for TensorFlow available in the official TensorFlow code. 

NATuRE MEDiCiNE | www.nature.com/naturemedicine 

https://lmb.informatik.uni-freiburg.de/resources/opensource/unet.en.html 
https://lmb.informatik.uni-freiburg.de/resources/opensource/unet.en.html 
http://www.nature.com/naturemedicine 


ArticlesNATUre MediciNe 
Data availability. The clinical data use for the training, validation and test set 
be collect at Moorfields Eye Hospital and transfer to the DeepMind data 
center in the UK in deidentified format. Data be use with both local and 
national permissions. They be not publicly available and restriction apply to their 
use. The data, or a test subset, may be available from Moorfields Eye Hospital NHS 
Foundation Trust subject to local and national ethical approvals. 

References 
34. Schindelin, J. et al. Fiji: an open-source platform for biological-image analysis. 

Nat. Methods 9, 676–682 (2012). 
35. Keane, P. A. et al. Evaluation of age-related macular degeneration with optical 

coherence tomography. Surv. Ophthalmol. 57, 389–414 (2012). 
36. Folgar, F. A. et al. Comparison of optical coherence tomography assessment 

in the comparison of age-related macular degeneration treatment trials. 
Ophthalmology 121, 1956–1965 (2014). 

37. Duker, J. S., Waheed, N. K. & Goldman, D. Handbook of Retinal OCT: Optical 
Coherence Tomography E-Book (Elsevier Health Sciences, Oxford, UK; 2013). 

38. Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J. & Wojna, Z. Rethinking the 
inception architecture for computer vision. Proc. IEEE Comput. Soc. Conf. 
Comput. Vis. Pattern Recognit. 2818–2826 (2016). 

39. Abadi, M. et al. TensorFlow: large-scale machine learn on heterogeneous 
systems. Preprint at https://arxiv.org/abs/1603.04467 (2016). 

40. Kingma, D. P. & Ba, J. Adam: a method for stochastic optimization. in 
Proceedings of the 3rd International Conference on Learning Representations 
(ICLR). Preprint at http://arxiv.org/abs/1412.6980 (2015). 

41. Huang, G., Liu, Z., Weinberger, K. Q. & van der Maaten, L. Densely 
connect convolutional networks. Proc. IEEE Comput. Soc. Conf. Comput. 
Vis. Pattern Recognit. 2261–2269 (2017). 

42. Lakshminarayanan, B., Pritzel, A. & Blundell, C. Simple and scalable 
predictive uncertainty estimation use deep ensembles. Adv. Neural Inf. 
Process. Syst. 6405–6416 (2017). 

43. De Fauw, J. et al. Automated analysis of retinal image use 
machine learn technique for computer vision. F1000Res 5, 
1573 (2016). 

NATuRE MEDiCiNE | www.nature.com/naturemedicine 

https://arxiv.org/abs/1603.04467 
http://arxiv.org/abs/1412.6980 
http://www.nature.com/naturemedicine 


1 

nature research | life science reporting sum 
m 

ary 
June 2017 

Corresponding author(s): Olaf Ronneberger 

Initial submission Revised version Final submission 

Life Sciences Reporting Summary 
Nature Research wish to improve the reproducibility of the work that we publish. This form be intend for publication with all accepted life 
science paper and provide structure for consistency and transparency in reporting. Every life science submission will use this form; some list 
item might not apply to an individual manuscript, but all field must be complete for clarity. 

For further information on the point include in this form, see Reporting Life Sciences Research. For further information on Nature Research 
policies, include our data availability policy, see Authors & Referees and the Editorial Policy Checklist. 

Experimental design 
1. Sample size 

Describe how sample size be determined. A sample size requirement of 553 to detect sensitivity and specificity at 0.05 
marginal error and 95% confidence be use to inform the number include in the 
test set. A sample of 997 patient be select to be part of the gold standard 
test set against which the human expert and the model be compared. 

The total of 15,877 TopCon 3D OCT 2000 scan from 7981 individual patient be 
eligible for inclusion in the work. An additional 268 Heidelberg Spectralis scan 
be select in order to conduct generalisability experiments. The total sample 
size for training and validation set be inform by the exist literature and by 
DeepMind’s previous work in the field of machine learn (Mnih et al., 2015; Silver 
et al., 2016). Today’s most powerful deep neural network can have million or 
billion of parameters, so large amount of data be need to automatically infer 
those parameter during learning. Most problem in the medical domain be highly 
complex a they arise a an interplay of many clinical, demographic, behavioural 
and environmental factor that be correlate in non-trivial ways. This be even more 
true for state-of-the art deep learn methodology that be expect to give the 
best result (Szegedy et al., 2014). 

2. Data exclusion 

Describe any data exclusions. OCT image set with no diagnostic labels, those contain severe artefacts, or 
significant reduction in signal strength to the point where retinal interface could 
not be identify be exclude from the present study. Conditions with few 
than ten cases, and data from patient who have manually request that their data 
should not be shared, be exclude before research began. For the test set 
patient who have previously be treat in clinic by the evaluation study 
participant be exclude from the test set. For more detail please refer to the 
manuscript method section. 

3. Replication 

Describe whether the experimental finding be 
reliably reproduced. 

All 997 patient in the test set for the first device type be randomly select and 
be not correlate in any way. The experiment can be interpret a 997 
replica of a single patient diagnosis. Without retrain the classification network 
in our framework performance be reproduce on a new test dataset from a 
second device type of 116 OCT scans. The performance in each case be a follows: 
Device Type 1 error rate: 55 out of 997 = 5.5%; Device Type 2 error rate: 4 out of 
116 = 3.4%. 

4. Randomization 

Describe how samples/organisms/participants be 
allocate into experimental groups. 

Samples meeting the inclusion criterion be randomly allocate to training or 
validation sets. A separate group of patient be randomly select before 
creation of the training and validation datasets a an independent test set which 
be kept separate during model development. Randomisation be on individual 
patient rather than OCT images: where there be multiple scan for a single 
patient these be allocate to only one of training, validation or test. For more 
detail please refer to the manuscript method section. 



2 

nature research | life science reporting sum 
m 

ary 
June 2017 

5. Blinding 

Describe whether the investigator be blind to 
group allocation during data collection and/or analysis. 

Participants in the clinical evaluation of the model be blind to the ground 
truth and be not involve in dataset collection; patient who have previously 
be treat in clinic by the participant be exclude from the test set. 

Note: all study involve animal and/or human research participant must disclose whether blinding and randomization be used. 

6. Statistical parameter 
For all figure and table that use statistical methods, confirm that the follow item be present in relevant figure legend (or in the 
Methods section if additional space be needed). 

n/a Confirmed 

The exact sample size (n) for each experimental group/condition, give a a discrete number and unit of measurement (animals, litters, cultures, etc.) 

A description of how sample be collected, note whether measurement be take from distinct sample or whether the same 
sample be measure repeatedly 

A statement indicate how many time each experiment be replicate 

The statistical test(s) use and whether they be one- or two-sided (note: only common test should be described solely by name; more 
complex technique should be described in the Methods section) 

A description of any assumption or corrections, such a an adjustment for multiple comparison 

The test result (e.g. P values) give a exact value whenever possible and with confidence interval note 

A clear description of statistic include central tendency (e.g. median, mean) and variation (e.g. standard deviation, interquartile range) 

Clearly define error bar 

See the web collection on statistic for biologist for further resource and guidance. 

Software 
Policy information about availability of computer code 

7. Software 

Describe the software use to analyze the data in this 
study. 

The network use the TensorFlow library with custom extension (see method 
section). Analysis be perform with custom code write in Python. 

For manuscript utilize custom algorithm or software that be central to the paper but not yet described in the publish literature, software must be make 
available to editor and reviewer upon request. We strongly encourage code deposition in a community repository (e.g. GitHub). Nature Methods guidance for 
provide algorithm and software for publication provide further information on this topic. 

Materials and reagent 
Policy information about availability of material 

8. Materials availability 

Indicate whether there be restriction on availability of 
unique material or if these material be only available 
for distribution by a for-profit company. 

The clinical data use for the training, validation and test set be collect at 
Moorfields Eye Hospital and transfer to DeepMind data centre in the UK in de- 
identify format. Data be use with both local and national permissions. They 
be not publicly available and restriction apply to their use. The data, or a test 
subset, may be available from Moorfields Eye Hospital subject to local and national 
ethical approvals. 

9. Antibodies 

Describe the antibody use and how they be validate 
for use in the system under study (i.e. assay and species). 

No antibody be used. 

10. Eukaryotic cell line 
a. State the source of each eukaryotic cell line used. No eukaryotic cell line be used. 

b. Describe the method of cell line authentication used. No eukaryotic cell line be used. 

c. Report whether the cell line be test for 
mycoplasma contamination. 

No eukaryotic cell line be used. 

d. If any of the cell line use be list in the database 
of commonly misidentified cell line maintain by 
ICLAC, provide a scientific rationale for their use. 

No eukaryotic cell line be used. 



3 

nature research | life science reporting sum 
m 

ary 
June 2017 

Animals and human research participant 
Policy information about study involve animals; when reporting animal research, follow the ARRIVE guideline 

11. Description of research animal 
Provide detail on animal and/or animal-derived 
material use in the study. 

No animal be use in the study. 

Policy information about study involve human research participant 

12. Description of human research participant 
Describe the covariate-relevant population 
characteristic of the human research participants. 

Data be select from a retrospective cohort of all patient attend Moorfields 
Eye Hospital NHS Foundation Trust, a world renowned tertiary referral centre with 
multiple clinic site serve an urban, mixed socioeconomic and ethnicity 
population centre around London, U.K., between 01/06/2012 and 31/01/2017, 
who have OCT image (Topcon 3D OCT, Topcon, Japan; Spectralis, Heidelberg, 
Germany) a part of their routine clinical care. For more detail please refer to the 
manuscript method section. 

Two OCT device type be select for investigation. 3D OCT-2000 (Topcon, 
Japan) be select a “device type 1” due to it routine use in the clinical pathway 
we studied. For device type 1, a total of 15,877 OCT scan from 7981 individual 
patient (mean age 69.5; 3686 male, 4294 female, 1 gender unknown) be 
eligible for inclusion in the work (Datasets #3 + #4 in Supplementary Table 3). To 
create a test set representative of the real-world clinical application, 997 additional 
patient (mean age 63.1; 443 male, 551 female, 3 gender unknown) present to 
Moorfields with visual disturbance during the retrospective period be select 
and only their referral OCT examination be select for inclusion in the test set 
(Dataset #5 in Supplementary Table 3); a sample size requirement of 553 to detect 
sensitivity and specificity at 0.05 marginal error and 95% confidence be use to 
inform the number included. To demonstrate the generalizability of our approach, 
Spectralis OCT (Heidelberg Engineering, Germany) be chosen a “device type 2”. 
For generalisability experiments, a second test set of clinical OCT scan from 116 
patient (mean age 58.2; 59 male, 57 female) present in the same manner be 
select use the same methodology and selection criterion (Dataset #11 in 
Supplementary Table 3). Examples of difference between the two device type 
be show in Supplementary Fig. 9. Supplementary Table 8 show a breakdown of 
patient and triage category in the datasets. 


Clinically applicable deep learn for diagnosis and referral in retinal disease 
Results 
Clinical application and AI architecture. 
Achieving expert performance on referral decisions. 
Achieving expert performance on retinal morphology. 
Generalization to a new scan device type. 

Discussion 
Acknowledgements 
Fig. 1 Our propose AI framework. 
Fig. 2 Results of the segmentation network. 
Fig. 3 Results on the patient referral decision. 
Fig. 4 Generalization to a new scan device type. 
Fig. 5 Visualization of the segmentation result a thickness maps. 
Table 1 Number of training scan and achieve performance on the two device types. 




