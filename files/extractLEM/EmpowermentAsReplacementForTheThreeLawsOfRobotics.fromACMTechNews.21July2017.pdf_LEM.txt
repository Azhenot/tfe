






































Frontiers | Empowerment As Replacement for the Three Laws of Robotics | Robotics and AI 


The great ubiquity of robot creates a need for generic guideline for robot behavior. 

We focus less on how a robot can technically achieve a predefined goal and more on 

what a robot should do in the first place. Particularly, we be interested in the question 

how a heuristic should look like, which motivates the robot’s behavior in interaction 

with human agents. We make a concrete, operational proposal a to how the 

information-theoretic concept of empowerment can be use a a generic heuristic to 

quantify concepts, such a self-preservation, protection of the human partner, and 

respond to human actions. While elsewhere we study involve single-agent 

scenario in detail, here, we present proof-of-principle scenario demonstrate how 

empowerment interpret in light of these perspective allows one to specify core 

concept with a similar aim a Asimov’s Three Laws of Robotics in an operational way. 

Frontiers | Empowerment As Replacement for the Three Laws of Robotics | Robotics and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/full 

1 sur 33 21/07/2017 19:08 



Importantly, this route do not depend on have to establish an explicit verbalize 

understand of human language and convention in the robots. Also, it incorporates 

the ability to take into account a rich variety of different situation and type of robotic 

embodiment. 

One of the trend of modern robotics be to extend the role of robot beyond be a specifically 

design machine with a clearly define functionality that operates accord to a confine 

specification or safely separate from humans. Instead, robot increasingly share living and work 

space with human and act a servants, companions, and co-workers. In the future, these robot 

will have to deal with increasingly complex and novel situations. Thus, their operation will 

require to be guide by some form of generic, high instruction level to be able to deal with 

previously unknown and unplanned-for situation in an effective way. 

Once robotic control have to cope with more than replay meticulously pre-arranged action 

sequences, or the execution of a predefined set of task a a reaction to a specify situation, the 

need arises for generic yet formalize guideline which the robot can use to generate action and 

preference base on the current situation and the robot’s concrete embodiment. 

We propose that any such guideline should address the follow three issues. First, “robot 

initiative”: we expect the principle to be generic enough for the robot to be able to apply them to 

novel situations. In particular, the robot should not only be able to respond accord to 

predefined situation but also be able to generate new goal and directive a need in new 

situations. Second, break action equivalence: how should a robot choose between several 

different action when all produce essentially the same desire outcome, only in different ways? 

Can we formulate good secondary criterion that the robot should optimize in addition, once it can 

ensure that the primary job get done? Finally, safety around robots: the default approach often 

involves a “kill switch,” i.e., the drastic and crude step of shut down the robot and stop all 

it actuators. This rudimentary response be often undesirable, e.g., when the robot be carry out 

a vital function where an immediate shutdown would lead to harm a human or itself, or when, to 

maintain safety and prevent damage, the robot be require to act rather than to stop acting. In 

summary, we propose that there be a pronounce need for generic, situation-aware guideline that 

can inform and generate robot behavior. 

Science Fiction literature, an often productive vehicle to explore idea about the future, have come 

across this problem in it countless speculation about the role of robot in society. Arguably, the 

best-known suggestion for generic rule for robot behavior be Asimov’s Three Laws of Robotics 

(Asimov, 1942): 

1. A robot may not injure a human be or, through inaction, allow a human be to come to 

harm. 

2. A robot must obey the order give to it by human beings, except where such order would 

Frontiers | Empowerment As Replacement for the Three Laws of Robotics | Robotics and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/full 

2 sur 33 21/07/2017 19:08 



conflict with the First Law. 

3. A robot must protect it own existence a long a such protection do not conflict with the 

First or Second Law. 

While there be ample room to discus the technicality and implication of the Three Laws 

(McCauley, 2007; Anderson, 2008; Murphy and Woods, 2009), we believe most people would 

agree with the general sentiment of the rules; Asimov himself argue that these rule be not 

particularly novel, but govern the design of any kind of tool humanity produce (Asimov, 1981). 

Asimov state that he aim to capture basic requirement of tools, namely, safety, compliance, 

and robustness, and his Three Laws be an attempt to explicitly express these property in 

language. But one central problem in adapt these rule to current-day robot be the scant 

semantic comprehension of rule express in natural language. 

In part, this be base on fundamental AI problems, such a determine the scope and context 

pertinent to such rule by robot or AIs in general (Dennett, 1984). Another AI-philosophical 

problem raise the question on how to assign meaning to the semantic concept (Coradeschi et 

al., 2013). Since robot usually have a radically different perspective to humans, and hence a 

different perceptual reality, it remains doubtful if robot and human could have a common 

language. Already simple, and common concepts, such a “harm,” cannot be naively related to the 

robot’s perspective. Subsequently, it be difficult to build robot that understand what constitutes 

harm and thus can avoid inflict it. 

Even if we be to somehow imbue a robot with a human-level understand of human 

language, we would still face the more pragmatic problem that human language carry intrinsic 

ambiguity. One example of this be the legal domain, where human will argue what exactly 

constitutes “harm” in legal cases, demonstrate that there be no unambiguous understand of 

this term that could just be apply in a technical fashion. Relatively simple sentences, such a the 

amendment of the US constitution have spawn decade of interpretation. Also, several of 

Asimov’s story illustrate how robot find loophole in their interpretation of the Three Laws 

that defy human expectations. Because of all previously mention problems, current-day robot 

be unable to generate action or behavior comply with natural language directives, such a 

“protect human life” or “do no harm.” Even great demand in regard to natural language 

processing be pose by the Second Law which require the robot to be able to interpret any order. 

This require a robust, unambiguous understand of human language that cannot even be 

realize by humans. 

In this paper, we have a similar aim a Asimov have with his Three Laws; however, rather than 

exactly reproduce the Laws, we propose a formal, non language-based method to capture the 

underlie property of robot a tools. Instead of employ language, we suggest to use the 

information-theoretic measure of empowerment (Klyubin et al., 2008) in particular, and 

potential causal information flow (Ay and Polani, 2008) in general, a a heuristic to produce 

characteristic behavioral phenomenology which can be interpret a correspond to the 

Three Laws in certain, crucial aspects. Note that we do not expect to reproduce the precise 

behavior associate with the Three Laws, but rather to capture essential intuition we have about 

Frontiers | Empowerment As Replacement for the Three Laws of Robotics | Robotics and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/full 

3 sur 33 21/07/2017 19:08 



how the Three Laws should operate; those which cause u to agree with them in the first place. 

Importantly, we do not argue that the propose heuristic give a complete and sufficient account 

for ethical robot behavior. Rather, at this stage, we consider property such a safety, 

compliance, and robustness a secondary to the main robot mission. This be very much in line 

with the idea of robot a servant and companion put forward in the “principles of robotics” 

(Boden et al., 2011). In contrast, principle such a Tilden’s Laws of Robotics that focus solely on 

the robot a autonomous, self-preserving life forms—basically living machine (Hasslacher and 

Tilden, 1995)—are expressly not in the scope of this article. Nevertheless, we like to point out 

exist work that link empowerment to the idea of autonomous and living system 

(Guckelsberger and Salge, 2016). 

Centrally, we propose here that the empowerment formalism offer an operational and 

quantifiable route to technically realize some of the idea behind the Three Laws in a generic 

fashion. To this end, we will first introduce the idea behind empowerment. We will then proceed 

to give both a formal definition and the different empowerment perspectives. We will then discus 

how these different perspective correspond to concepts, such a self-preservation, compliance, 

and safety. Finally, we will discus extensions, challenges, and future work need to fully realize 

this approach on actual robots. 

Empowerment be an information-theoretic quantity that capture how much an agent be in 

control of the world it can perceive. It be formalize by the information-theoretic channel capacity 

between the agent’s actuation during a give time interval and the effect on it sensory 

perception at a time follow this interval. Empowerment be introduce by Klyubin et al. 

(2005) to provide agent with a generic, a prioristic intrinsic motivation that might act a a 

step stone toward more complex behavior. An information-theoretic measure, it quantifies 

how much potential causal influence an agent have on the world it can perceive. Empowerment 

be motivate by the idea to unify several seemingly disparate drive of organism of multiple 

level of complexity, such a maintain a good internal sugar level, stay healthy, become a 

leader in a gang, accumulate money, etc. (Klyubin et al., 2008). While all these drive enhance 

survivability in one way or another, one unify theme that tie them together be maintain 

and enhance one’s ability to act and control the environment. Empowerment attempt to 

capture this notion in an operational formalism; in this paper, we specifically want to 

demonstrate how this principle can serve a a cognitive heuristic to generate behavior in the spirit 

of the Three Laws of Robotics. For this, we consider empowerment from different, but related 

perspectives. 

To motivate empowerment and gain a good understanding, let u first take a brief look at the 

background, before move on to the formal definition. Oesterreich (1979) argues that agent 

should act so that their action lead to perceivably different outcomes, which he call “efficiency 

divergence” (“Effizienzdivergenz” in German). In the ideal case, different action should lead to 

Frontiers | Empowerment As Replacement for the Three Laws of Robotics | Robotics and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/full 

4 sur 33 21/07/2017 19:08 



different perceivable outcomes. Von Foerster (2003) famously state “I shall act always so a to 

increase the total number of choices,” argue that a state where many option be open to an 

agent be preferable. Furthermore, Seligman (1975) argues that human who be force to be in a 

state where one’s action appear to have random outcome or no outcome variation at all suffer 

mental health problems. This relates to more recent empirical study by Trendafilov and Murray- 

Smith (2013), which indicate that human in a control task associate a low level of 

empowerment with frustration and perform good in situation where they be highly 

empowered. More recently, idea similar to empowerment have also emerge in physic 

(Wissner-Gross and Freer, 2013), propose a closely related action principle; the latter is, 

however, motivate by the hypothesize thermodynamic Maximum Entropy Production Principle 

instead of be base on evolutionary and psychological arguments. 

In essence, empowerment formalizes a “motivation for effectance, personal causation, 

competence, and self-determination,” which be consider to be one area of intrinsic motivation 

by Oudeyer and Kaplan (2007), Oudeyer et al. (2007). Intrinsic motivation be a term introduce 

by Ryan and Deci (2000) as: “[…] the do of an activity for it inherent satisfaction rather than 

for some separable consequence.” In the last decades, a number of method have be suggest 

to artificially generate behavior of a similar nature a have be hypothesize about intrinsically 

motivate organisms. Among these be Artificial Curiosity (Schmidhuber, 1991), Learning 

Progress (Oudeyer and Kaplan, 2007), Predictive Information (Ay et al., 2008), Homeokinesis 

(Der et al., 1999), or the Autotelic Principle (Steels, 2004). Not all of them be related to personal 

causation, most be more focus on the “reduction of cognitive dissonance” and on “optimal 

incongruity.” But all of them be to some extent intrinsic to the idea of agency itself, and they all 

share a set of property that make them well suit to imbue agent and robot with generic, 

motivate behavior without reliance on an externally define reward structure. They usually be 

• task-independent, 

• computable from the agent’s perspective, 

• directly applicable to many different sensorimotor configurations, without or with little external 

tuning, and 

• sensitive to and reflective of different agent embodiments. 

The task-independence demarcates this approach from most classical AI techniques, such a 

reinforcement learn (Sutton and Barto, 1998); the general idea be not to solve any particular 

task well, or to be able to learn how to do a specific task well, but instead to offer an incentive for 

behavior even if there be currently no specific task the agent need to attend to. In the case of 

empowerment, the behavior generate turn out to coincide well with the idea of robot self- 

preservation. 

The computability from an agent’s perspective be an essential requirement. If some form of 

Frontiers | Empowerment As Replacement for the Three Laws of Robotics | Robotics and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/full 

5 sur 33 21/07/2017 19:08 



intrinsic motivation be to be realize by an organism or deployed onto an autonomous robot, then 

the organism/robot need to be able to evaluate this measure from it own perspective, i.e., base 

on it own sensor input. This relies on a notion of Umwelt by von Uexküll (1909), because any 

intrinsic preference relation will be define with respect to the agent’s experience, i.e., it 

perceive dynamic between the agent’s sensor and actuators; the latter, in turn, arises from the 

interplay of the environment and the embody agent. This be closely related to the concept of a 

“counterworld” (Gegenwelt (von Uexküll, 1909)), the internal mirror of the Umwelt, but one 

that only capture functional circles, those relation where action relate to relevant feedback 

from the environment. Empowerment fit with this approach, a it do not require an explicit, 

full world model that try to capture the whole environment, but only a short-term forward 

model that relates it current action and context (typically a sensor-based belief about the 

current state) to the subsequent sensor state which be expect to result from these actions. 

Ziemke and Sharkey (2001) provide a more in-depth explanation of the Umwelt concept and also 

provide an overview of modern robotic approaches, such a the Subsumption Architecture by 

Brooks (1986) that realizes robot control a a hierarchy of functional circles. Empowerment, and 

to a large extent also the other mention intrinsic motivation measures, be usually compatible 

with these bottom-up approach with minimal model focus on immediate action–perception 

loops. 

The next property of intrinsic motivation be the ability to cope with different, quite disparate 

sensorimotor configurations. This be highly desirable for the definition of general behavioral 

guideline for robots. This mean not have to define them separately for every robot or change 

them manually every time the robot’s morphology changes. The applicability to different 

sensorimotor configuration combine with the requirement of task-independence be the central 

requirement for such a principle to be universal. More precisely: to be universal, a driver for 

intrinsic motivation should ideally operate in essentially the same manner and arise from the 

same principles, regardless of the particular embodiment or particular situation. A measure of 

this kind can then identify “desirable” change in both situation (e.g., in the context of behavior 

generation) and embodiment (e.g., in the context of development or evolution). For example, 

while most empowerment work focus on state evaluation and action generation, some work 

also considers it use for sensor or actuator evolution (Klyubin et al., 2008). 

Furthermore, this implies that a measure for intrinsic motivation should not just remain 

generically computable, but also be sensitive to different morphologies. The challenge be to define 

a value function in such a way that it stay meaningful when the situation or the embodiment of 

the agent changes. An illustrative example here be study where an agent have the ability to move 

and place block in a simulated world (Salge et al., 2014a). Driven by empowerment 

maximization, the agent change the world in such a way that the result structure end up 

reflect the particular embodiment of the agent. 

To sum up this section, if we want to use an intrinsic motivation measure a a surrogate for what 

Pfeifer and Bongard (2006) call a value function in the context of embody robotics, then we 

propose it need to fulfill these criteria. Here, we specifically concentrate on empowerment, since 

Frontiers | Empowerment As Replacement for the Three Laws of Robotics | Robotics and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/full 

6 sur 33 21/07/2017 19:08 



it have be show to be a suitable candidate to produce the desire behavior; furthermore, many 

of it relevant property have already be study in some detail now (Salge et al., 2014c). 

However, we would like to emphasize that the concept to be developed below be not limited to 

empowerment in their application, but might also be adaptable to alternative intrinsic motivation 

methodology in order to provide operational safety principle for robots. 

To make our subsequent study precise, we now give a formal definition of empowerment. 

Empowerment be formalize a the maximal potential causal flow (Ay and Polani, 2008) from an 

agent’s actuator to an agent’s sensor at a late point in time. This can be formalize in the term 

of information theory a channel capacity (Shannon, 1948). 

To compute empowerment, we model the agent–world interaction a a perception–action loop a 

in Figure 1. In Figure 1, we be look at a time-discrete model, where an agent interacts with the 

world. An agent chooses an action A for the next time step base on it sensor input S in the 

current time step t. This influence the state of R (in the next time step), which in turn 

influence the sensor input S of the agent at that time step. The cycle then repeat itself, with 

the agent choose another action in A . Note that, in a more general model, this choice of 

action might also be influence by some internal state of the agent which carry information 

about the agent’s past. 

(http://www.frontiersin.org/files/Articles/260425/frobt-04-00025-HTML/image_m 
/frobt-04-00025-g001.jpg) 
Figure 1. The perception–action loop visualize a a Causal Bayesian network (Pearl, 

2000). S be the sensor, A be the actuator, and R represent the rest of the system. The index t indicates the time at which 
the variable be considered. This model be a minimal model for a simple memoryless agent. The red arrow indicate the 
direction of the potential causal flow relevant for 3-step empowerment. If empowerment be measured, the input to each 
of the action be freely chosen, disconnect from the sensor input, but inside the 3-step horizon the action may 
expressly be correlated—see also discussion in Klyubin et al. (2008). 

For the computation of empowerment, we consider this perception–action loop a tell u how 

action may potentially influence a state in the future, and by influence we emphatically mean not 

the actual outcome of the concrete trajectory that the agent takes, but rather the potential future 

outcome at the give time horizon t + 3, i.e., the distribution of outcome that could be 

generate by actuation, start from time t. The most straightforward interpretation be a a 

probabilistic communication channel where the agent transmits information about action A , 

A , A through a channel and considers how much of it be reflect in the outcome in S . The 

maximal influence of an agent’s action on it future sensor state (again, not it actual actions, 

t t 

t+1 

t+1 

t+1 

t 

t+1 t+2 t+3 

Frontiers | Empowerment As Replacement for the Three Laws of Robotics | Robotics and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/full 

7 sur 33 21/07/2017 19:08 



but it potential actions) can now be model formally a Shannon channel capacity: what the 

agent may possibly (but need not) transmit over the channel—or, in fact, what the agent may (but 

need not) have change in the environment, at the end of it 3-step action sequence. 

Empowerment be then define a the channel capacity between the agent’s actuator A in a 

sequence of time step and it own sensor S at a late point in time. For example, if we look at 

empowerment in regard to just the next time step, then empowerment can be express a 

(1) 

Note that the maximization implies that it be calculate under the assumption that the controller 

which chooses the action sequence (A ) be completely free to act from time t onward (but 

permit to correlate the actions) and be not bound to a particular behavior strategy p(a|s, r). 

Furthermore, empowerment be a state-dependent quantity, a it depends on the state r in which 

the consideration of potential future be initiated. Instead of an externally observable objective 

state r, one could also consider empowerment base on a purely agent-intrinsic “context” state 

derive from early agent experience (Klyubin et al., 2008) without conceptual changes. For 

simplicity and clarity, we will here discus only empowerment landscape depend on 

“objective” state r. We also assume for the begin of the paper that the agent have somehow 

previously acquire a sufficiently accurate local forward model p(s |a , s ). We will late discus 

the general difficulty and implication of the model acquisition itself. 

Empowerment be define for both discrete and continuous variables. However, while it be possible 

to directly determine the channel capacity for the discrete case use the Blahut–Arimoto 

Algorithm (Arimoto, 1972; Blahut, 1972) to compute a channel capacity achieve distribution 

p*(a|r), this algorithm cannot be straightforwardly apply to the continuous case. There exist 

adaptation for empowerment calculation in the continuum, though. Jung et al. (2011) use 

Monte-Carlo Integration to approximate empowerment, but this method be very computationally 

expensive. A significantly faster method approximates empowerment of a continuous channel by 

treat it a a linear channel with add independently and identically distribute (i.i.d.) 

Gaussian noise (Salge et al., 2012). 

When talk about an empowerment-maximizing agent, it must be emphasize that the 

distribution p*(a|r) achieve the channel capacity be not the one that an empowerment- 

maximize agent actually us to choose it next action. The capacity-achieving distribution be 

only utilized to compute the empowerment value of world states; for each such state, an 

empowerment value be thus computed, which defines a pseudo-utility landscape on the state 

space. For the actual action, the agent chooses a greedy strategy with respect to this pseudo- 

utility: it chooses it action a to locally maximize the empowerment of the next state it will visit. 

To illustrate, an agent might prefer a state where it would have the option to jump off a cliff. 

𝔈(r) := C( → r) ≡ I( ; r).At St+1 
∣ 

∣ 
∣ max 

p( r)at ∣∣ 
St+1 At 

∣ 

∣ 
∣ 

t t 

t+1 t t 

Frontiers | Empowerment As Replacement for the Three Laws of Robotics | Robotics and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/full 

8 sur 33 21/07/2017 19:08 



However, assume that the agent would break from the fall or have to tortuously climb up again, 

the agent would not actually select the action that would cause it to fall off the cliff; it will just 

want to posse the option. Importantly, this require the agent to have a correct forward model 

of what will happen when step off the cliff. If there be noise in the dynamics, this will, on the 

other hand, lead empowerment to pull the agent slightly away from the cliff, a the agent in this 

case cannot ensure that it would not accidentally fall off the cliff. This be similar to on-policy 

reinforcement learning. 

In past work, two main strategy have be used. Greedy empowerment maximization basically 

considers all possible action in the current state and then computes the successor state (or state 

distributions) for each of those actions. Then, empowerment be calculate for each of those 

successor states. The successor state with the high empowerment be selected, and the agent 

then performs the action lead to the chosen successor state. In case each action have a 

distribution of successor states, then the action with the high average successor state 

empowerment be selected. This have the advantage that the agent only need to compute the 

empowerment for the immediate successor state in the future. 

Alternatively, the agent could compute the empowerment value for each possible state of the 

world, or a subset thereof. The agent could then determine the state with the maximal 

empowerment and then plan a sequence of action to get to this state (Leu et al., 2013). This 

solution is, of course, infeasible in general. 

Here, however, we will, in accordance with the latter principle, generally present the compute 

empowerment value a an empowerment map, because it give an overview over what behavior 

would be prefer in either case. The map visualizes both the local gradient and the optima. The 

behavior result from these map would then be either an agent that act in order to climb up 

the local gradient or to reach a global optimum. 

In this section, we outline how we can use the empowerment formalism to capture the essential 

aspect of the Three Laws. For this, we look at a system that contains both a human and a robotic 

agent. The Causal Bayesian Network from Figure 2 show the combine perception–action loop 

of both a human and a robot. There be a jointly accessible world R that both the human and 

robotic agent can perceive and act upon with their respective sensor and actuator variables. In 

such a system, it be possible to define different empowerment perspectives: here, we will look at 

robot empowerment, human empowerment, and human-to-robot transfer empowerment. 

(http://www.frontiersin.org/files/Articles/260425/frobt-04-00025-HTML/image_m/frobt-04-00025-g002.jpg) 
Figure 2. The time-unrolled perception–action loop with two agent visualize a a Bayesian Network. S be the robot 

Frontiers | Empowerment As Replacement for the Three Laws of Robotics | Robotics and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/full 

9 sur 33 21/07/2017 19:08 



sensor, S the human sensor, A be the robot actuator, A be the human actuator, and R 
represent the rest of the system. The index t indicates the time at which the variable be 
considered. The arrow be causal connection of the Bayesian networks, the dot and 
dash line denote the three type of causal information flow relevant to the three type 
of empowerment discuss in the text. The red dot arrow indicate the direction of the 

potential causal flow relevant for 3-step robot empowerment, the blue dot arrow denotes human empowerment, 
and the dash purple line indicates the human-to-robot transfer empowerment. 

Robot empowerment be define a the channel capacity with respect to the robot’s actuator A 

and sensor S. This be the classical empowerment perspective. The robot choose action to 

maximize robot empowerment lead to behavior that preserve and enhances the robot ability to 

act and affect be surroundings. The propose, therefore, that robot empowerment can provide a 

heuristic for self-preservation and reliability. 

Human Empowerment be similarly define a the channel capacity with respect to the human’s 

actuator A and sensor S . The difference here be that it be still the robot that chooses it own 

action a to maximize the human’s empowerment. This should create robot behavior aim at 

preserve and enhance the human’s ability to act. This provide a heuristic that ultimately 

protects the human from environmental influence that would destroy the human or reduce it 

ability to act. It also creates behavior that aim to enhance the human’s access and influence on 

the world and keep the robot from hinder or harm the human directly. This heuristic 

somewhat corresponds to the First Law and provide a degree of safety. 

Human-to-robot transfer empowerment be define a the channel capacity from the human’s 

actuator A to the robot’s sensor S. This capture the potential causal flow from the human’s 

action to the world perceive by the robot. If the robot act to maximize this value, it will 

maintain something we like to call operational proximity. It will keep the robot close to the 

human in a way where close do not necessarily mean physically close, but close so that the 

human can affect the robot. Furthermore, transfer empowerment can also be raise by the robot 

act reliable, i.e., react in a predictable manner to the human’s actions. This enhances the 

human ability to act and would allow for the human to use certain action to direct the robot. We 

propose, therefore, that this heuristic capture certain aspect of reliability and compliance, 

without directly reproduce the Second Law of robotics. 

In combination these three heuristic should provide an operationalized motivation for robot to 

act in a way that reflect the sentiment behind the Three Laws of Robotics. The core of this idea 

be initially suggest by Salge et al. (2014b). Guckelsberger et al. (2016) have late use similar 

perspective (they use transfer empowerment in the opposite direction) to generate companion 

behavior for a non-player character (NPC) in a dungeon crawler game. 

Robot empowerment be the potential causal information flow from the robot’s actuator to the 

robot’s sensor at a late point in time. In this perspective, the human be simply include in the 

h h 

h h 

h 

Frontiers | Empowerment As Replacement for the Three Laws of Robotics | Robotics and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/full 

10 sur 33 21/07/2017 19:08 



external part of the perception–action loop of the robot. From the robot’s perspective, all 

variable pertain to the human be subsume in R. The human’s influence on the transition 

probability from A to S become relevant to it only a part of the robot’s “Umwelt” and a such 

they be integrate into the robot’s local forward model. Therefore, we expect robot 

empowerment behavior to be similar to what be observe in exist work on single agent 

empowerment maximization (Klyubin et al., 2005, 2008; Salge et al., 2014c), where 

empowerment behavior aim to maintain the agent’s freedom of operation and, indirectly, it 

survivability. 

Typical empowerment-driven behavior can be seen, e.g., in control problems, where 

empowerment maximization balance a pendulum and a double pendulum, and also stabilizes a 

bicycle (Jung et al., 2011). We emphasize that in these example no external reward need to be 

specified, and empowerment derives directly from the intrinsic dynamic of the system. In other 

words, empowerment identifies the balance position a goal without an external specification 

of a goal, because these state offer the great degree of simultaneous control and predictability. 

Notably, empowerment have a tendency to drive the agent away from state where it would 

become inoperational, correspond to a breakdown or “death” of an organism. Importantly, 

this do not require an external penalty for death, a breakdown or death be directly 

represent in the formalism via the vanish of empowerment. Typically, a negative 

empowerment gradient can serve a an alert to the agent that it be in danger of move toward 

destructive (or loss-of-control) state (Salge et al., 2014a). Guckelsberger and Salge (2016) 

summarize a lot of the self-preservation aspect of empowerment and argue that empowerment 

maximization can lead to autopoesis (Maturana and Varela, 1991). 

More concretely relevant for the present argument be the work by Leu et al. (2013), picture in 

Figure 3, where a physical robot us the 2D-map of it environment to create an empowerment 

map to modulate it navigation. While the robot realize it primary objective to follow a human, 

it also try to maintain it own empowerment, thereby avoid to get stuck or to navigate into a 

tight passage which would reduce it ability to act. In the experiment, the reaction of the 

environment to the robot’s action be learnt use Gaussian process models. The human-following 

behavior itself be hard-coded and the human behavior itself be not cover by the model. 

Frontiers | Empowerment As Replacement for the Three Laws of Robotics | Robotics and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/full 

11 sur 33 21/07/2017 19:08 



(http://www.frontiersin.org/files/Articles/260425/frobt-04-00025-HTML/image_m 
/frobt-04-00025-g003.jpg) 
Figure 3. Empowerment-driven robot follower a described in Leu et al. (2013). The 
robot try to follow the human while try to maintain it empowerment in the obstacled 

environment. By try to maintain empowerment, the robot keep away from obstacle and wall and, furthermore, 
avoids passing through the narrow passage separate it from the human because it would constrain it movement. The 
left subfigure show the experimental setup, with a scale empowerment map on the bottom left. The top left show the 
robot’s view, use for track the human. The right subfigure show the room layout with empowerment map 
overlaid; right: gradient vector field of the scale empowerment map, scale by Euclidean distance to the human to 
induce follow behavior. 

While the human-in-the-loop can be treated, from the robot’s perspective, a just another part of 

the environment, we can modify our question and ask how the maximization of robot 

empowerment will affect the human or what kind of interactive behavior will result from this? 

Consider Figure 4, depict a simplify model of the set-up in Figure 3. The figure show that, 

once we simulate the human behavior a part of the model, the robot’s empowerment be 

drastically reduce around the human. First, in this particular scenario the robot’s safety 

shutdown turn it off in proximity to the human, and it empowerment drop to zero. So the 

human can perform (move) action that will obliterate the robot’s empowerment. Other setup 

will have a different and possibly less drastic response, but in any case the presence of the human 

impact the robot’s empowerment. Notably, if the robot’s result sensor state can be influence 

by the human’s actions, it be possible for the human to disturb the outcome of the robot’s 

behavior. Depending on how well the robot can predict the human’s action, the anticipate 

outcome, i.e., it sensor state at the time horizon, will be more or less noisy. Empowerment 

selectively avoids interaction with unpredictable agent (Salge et al., 2013) and generally noisy, 

unpredictable situations. It lower the robot’s control over it own environment and thereby it 

sensor input; this loss of predictable control express itself in a loss of empowerment. 

(http://www.frontiersin.org/files/Articles/260425/frobt-04-00025-HTML/image_m 
/frobt-04-00025-g004.jpg) 
Figure 4. Robot empowerment (in grayscale: dark—low, bright—high) dependent on the 
robot position. Obstacles in blue. Two different human (yellow circle) behavior model be 
considered. If the robot would be within the safety shutdown distance (red circle), it be not 

able to act. The red dot be the endpoint of the 2,000 random human action trajectory use for possible action 
predictions, the two graph differ in the assume distribution of human movement in the next three steps. If one 
compare the empowerment close to the safety shutdown distance, one can see that the assume human behavior 
influence the estimate empowerment while all other aspect of the simulation remain unchanged. 

The effect of this can be see in Figure 4, where the robot empowerment landscape be change 

Frontiers | Empowerment As Replacement for the Three Laws of Robotics | Robotics and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/full 

12 sur 33 21/07/2017 19:08 



purely by a different human behavior model. On the right, we have a more accurate model of the 

predict human behavior, which also assumes that the human move toward the upper left. This 

move the shutdown zone where the robot empowerment vanishes and at the same time also 

“sharpens” the contrast between the high- and low-empowered areas. The sharper contrast be a 

result of the reduce amount of noise be inject by the human into the robot’s perception– 

action loop. 

A reliably predictable human would also allow the robot to maintain a high empowerment 

closer to the human if it would stay south-west of the human, basically opposite of the human 

predict movement direction. In general, obtain a good human model can increase the 

robot’s perceive model-based empowerment by reduce the human noise and by provide a 

good estimate which state in close proximity to the human be less likely to become 

disempowering. 

A related phenomenon be observe in a study by Guckelsberger et al. (2016), where three 

different empowerment perspective be use to control a NPC companion in a NetHack-like 

dungeon crawler game. In one simulation, the player be able to shoot an arrow which would kill 

the NPC. This cause the empowerment-driven NPC agent to always avoid stand in the 

direction of the player. The NPC’s world model assume that all action of the player be equally 

likely, and therefore, assume that there be a chance that the player would kill the NPC. This lead 

to a tendency to avoid the player. Guckelsberger et al. show that this could be mitigate by a 

“trust” assumption, basically change the player model a to assume the player to be benevolent 

to the NPC and would not perform an action that would lead to a loss of all NPC empowerment 

(i.e., kill the NPC). This make the NPC less inclined to flee from the player. Applied to a real 

robot, this trust assumption would make sure that the robot would focus on mitigate actual 

possible threat rather than have to hedge against malevolent or even just negligent human 

action (“friendly fire”). 

Better model acquisition be necessary for an agent to gage whether or not to avoid humans, 

depend on their cooperation, unpredictability, or antagonism. But empowerment 

maximization offers, by itself, not a direct incentive toward or away from human interaction. It be 

possible to imagine that the human could perform action that would increase or preserve the 

robot or NPCs empowerment, such a feed or repairing/healing it. This would then likely 

create a drive toward the human, if this be model in viable timescales. In absence of any specific 

possible benefit provide by the human, however, the agent driven by empowerment alone be not 

automatically drawn toward interact with a human and be likely to drift away over time. This 

will be address in the other perspective below. 

In short, we propose to maximize robot empowerment to generate behavior by which the robot 

strives toward self-preservation. Specifically, become inoperational corresponds to vanish 

empowerment. In turn, have high empowerment mean that the robot have a high influence on 

the world it can perceive, imply a high readiness to respond to a variety of challenge that 

might emerge. We propose this principle, namely, maximize empowerment, a a generic 

measure a a plausible proxy for produce behavior in the spirit of the Third Law, a it will cause 

Frontiers | Empowerment As Replacement for the Three Laws of Robotics | Robotics and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/full 

13 sur 33 21/07/2017 19:08 



the robot to strive away from state where it expect to be destroyed or inoperational, and to 

strive toward state where it achieves the maximum potential effect. Robot empowerment 

maximization thus act to some extent a a surrogate for a drive toward self-preservation. 

We now turn to human empowerment. Human empowerment be define in analogy to robot 

empowerment a the potential causal flow from the human’s actuator to the human’s sensors. 

The robot be now part of the external component of the perception–action loop of the human. 

Maximizing, or at least preserve human empowerment have similar effect to the previous case: 

keep it at a high value implies maintain the human’s influence on the world and avoid 

situation which would hinder or disable the human agent. A central difference to the previous 

case be that the human empowerment be make dependent on the robot; in other words, now the 

robot aim to maximize the empowerment of another agent rather than it own. 

Figure 5 show another continuous 2D scenario, this time involve a laser. The laser would block 

the human’s movement, but be harmless to the robot and can be block by it. The grayscale 

color this time indicates the value of the human empowerment, but still depend on the 

robot’s position. Notably, the high empowerment be achieve when the robot be in the white 

area. This be where the robot block the laser come from the right side, permit the human to 

move past the laser barrier. Driven by maximization of human empowerment, the robot would, 

therefore, prefer to move in front of the laser. Importantly, note that high human empowerment 

value for the robot in this area only become pronounce when the human be close to the laser 

barrier (as be the case in the figure, the human position denote by the yellow circle). This mean 

that the drive to block the laser only emerges at all when the human be actually in a position to 

pas it. 

(http://www.frontiersin.org/files/Articles/260425/frobt-04-00025-HTML/image_m 
/frobt-04-00025-g005.jpg) 
Figure 5. Human empowerment (in grayscale: dark—low, bright—high) dependent on 
the robot’s position. In this simulation, a laser (indicated by the red line) block the 
human’s movement, but the laser can be occlude by the robot body. Thus, Human 
empowerment be the high for robot position toward the right wall where the robot 
block the laser and thereby allows the human a great range of movement. 

We can also see in Figure 5 that position in the area directly around the human produce low 

human empowerment. This be because the robot would partially block the human movement if it 

be in these position close to the human. Also note that the empowerment landscape for the 

Frontiers | Empowerment As Replacement for the Three Laws of Robotics | Robotics and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/full 

14 sur 33 21/07/2017 19:08 



robot be further away from the human be flat. Here, the robot be so far away that it do not 

interact in any way with the human’s action–perception loop, and therefore, it exact position have 

no influence on the human’s empowerment. 

For another illustrative example of the effect of consider human empowerment-driven robots, 

consider the NPC (non-person character; autonomous, computer-controlled player in a video 

games) in the dungeon crawler game scenario from Guckelsberger and Salge (2016). Here, the 

NPC avoids stand directly next to the (human) player, a this would block the player’s 

movement. If enemy be present that be predict to shoot and kill the player, the NPC strives 

to kill these enemy to save the player. This can be combine with a maximization of the NPC’s 

own empowerment. Figure 6 show a sequence of NPC action that arise from combine the 

different heuristics. Here, the heuristic be a linear combination of the different empowerment 

types. As a result, the NPC will first save itself (as the human player have more health) and then it 

remove the two enemies. This complex behavior emerges from a greedy maximization of the 

linear combination of the different empowerment perspectives. 

(http://www.frontiersin.org/files/Articles/260425/frobt-04-00025-HTML/image_m 
/frobt-04-00025-g006.jpg) 
Figure 6. Companion (C) and player (P), both purple, be threaten simultaneously by 

two enemy (E), both red. The image represent the successive moves: the companion escape it own death, rescue 
the player, and finally defends itself. Left: combine heuristic for 2-step empowerment (see text), lighter color 
indicate high empowerment. Arrows indicate shooting. Figure take from Guckelsberger and Salge (2016), 
reproduce with permission. 

In this section, we consider human empowerment maximization (in the variant of be 

influence by the artificial agent rather than the human). Using this variant a driver lead to a 

number of desirable behaviors. It prevents the robot from obstruct the human, for example, by 

get too close or by interfere with the human’s actions. Both would be noticeable in the 

human empowerment value, because they would either constrain accessibility to state around 

the human, or inject noise in the human’s perception–action loop. In addition to that, the robot 

act a to enhance or maintain the human’s empowerment, through “proactive”-appearing 

activities, represent in above example by remove a barrier from the environment or by 

neutralize a threat that would destroy or maim the human or even just impede their freedom of 

movement. In this sense, human empowerment maximization can be plausibly interpret a a 

driver for the agent toward protect the human and support their agenda. 

A number of caveat remain: to compute the human empowerment value, the robot not only 

need a sufficient forward model but also need to be able to identify the human agent in the 

environment, their possible actions, and how the human perceives the world via their sensor and 

Frontiers | Empowerment As Replacement for the Three Laws of Robotics | Robotics and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/full 

15 sur 33 21/07/2017 19:08 



what they be able to do with their actuators. This be not a trivial problem; however, it 

nevertheless have the advantage that it offers, in some ways, a “portable” and operational model 

route. While it depends on a sufficiently reliable algorithm for detect human and plausible, if 

strongly abstracted, model for human perception and actuation, once these be provided, the 

principle be applicable to a wide range of scenarios. The present proposal suggest possible route 

toward an operational implementation of a “do not cause harm to a human” and a “do not permit 

harm to be cause to a human” principle, provide one can endow the artificial agent with 

a—what could loosely be termed—“proto-empathetic” perspective of the human’s situation. 

Another critical limitation to the applicability of the formalism be the time horizon, which be the 

central free parameter in the empowerment computation. While a robot driven by human 

empowerment maximization might stop a bullet, or a fall into a pit, it would need to extend it 

time horizon massively to account for thing that would be undesirable for the human in the 

short-term, but be advantageous in the long run. To illustrate, consider the analogy from human 

lawmaking, where freedom to act on the short scale be curtail in an effort to limit long-term 

damage (e.g., in environmental policies). The principle a discuss in this section is, therefore, 

best suit for interaction that have to avoid obstruction or interference by a robot in the short 

term and with immediate consequences. That be said, nothing in the formalism prevents one— 

in principle—to be able to account for long-term effects. To do so in practice will require 

extend the method to deal with longer time-scales and level of hierarchies. 

As the third and last variant, we consider transfer empowerment. Transfer empowerment be 

define a the potential causal information flow from the action of one agent to the sensor of 

another. One of the motivation for it development be to counter the lack of the two previous 

perspective to provide an incentive that keep the robot/companion from drift away from the 

human. The aim be to add an incentive for the robot to remain at the human’s service. This be 

achieve by require that the human’s action can influence the sensory input of the robot. 

Figure 7 show the human-to-robot (HtR) transfer empowerment, i.e., we consider the human 

movement a the empowerment-inducing action set and the empowerment-relevant sensor input 

be give by the robot positions. Here, we employ the safety shutdown mechanism at the fix 

distance a a simple illustrative proxy for other, potentially more complex influence that the 

human may have on the robot. In our case, the shutdown mechanism allows the human to 

selectively disable the robot, by move toward or away from it. This creates a direct causal 

influence from the human to the robot. Consequently, this generates a ring of high HtR transfer 

empowerment around the human. In general, any form of influence of the human on the 

perception of the robot will produce a modulation of the HtR transfer empowerment landscape. 

By maximize this value, the robot would try to remain in a domain where the human can affect 

it. 

Frontiers | Empowerment As Replacement for the Three Laws of Robotics | Robotics and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/full 

16 sur 33 21/07/2017 19:08 



(http://www.frontiersin.org/files/Articles/260425/frobt-04-00025-HTML/image_m 
/frobt-04-00025-g007.jpg) 
Figure 7. A visualization of the human-to-robot (HtR) transfer empowerment dependent 
on robot position (dark—low, light—high). This simulation show a slightly elevate 
human-to-robot transfer empowerment around the human agent (yellow) at the 
shutdown distance (red circle). This be because the human can move toward or away from 
the robot, thereby have the potential to stop the robot. This creates a potential causal 
flow from the human’s action to the robot’s sensors, which in this case measure the robot 
position. Here, the physical proximity of the human allows it to directly influence the 

robot’s state. 

This effect can alternatively be obtain by the analogous robot-to-human transfer 

empowerment; this be demonstrate in Guckelsberger and Salge (2016), see Figure 8. Here, the 

companion try to maximize the causal influence it action have on the human player’s input 

state, which also cause it to remain close to the player. This particular variant of empowerment 

help to overcome the persistent problem that the companion would not follow the player 

through narrow corridors, a they be strongly constrain it empowerment. 

(http://www.frontiersin.org/files/Articles/260425/frobt-04-00025-HTML/image_m 
/frobt-04-00025-g008.jpg) 
Figure 8. Two room scenario from Guckelsberger and Salge (2016), reproduce with 

permission. (A) Companion empowerment, n = 2. (B) Companion-player transfer empowerment, n = 2. (C) Coupled 
empowerment with movement trace, n = 2. In the last subfigure (C), the companion agent C be driven by a combination 
of it own empowerment and transfer empowerment from companion to player (values show in grayscale, bright 
—high, dark—low). If only companion empowerment be drive the agent, a in subfigure (A), then the companion do 
not enter the corridor, a it narrowness will low the agent’s own empowerment. With the addition of transfer 
empowerment, however, the companion begin to maintain operational proximity, and thus follow the player also 
through the narrow corridor. This can be see in the movement trace of both player and agent. 

So, in regard to create player-following behavior, both direction of transfer empowerment 

seem to be suitable. But, look at the causal Bayesian network representation in Figure 9, we 

can see that there be in principle two different way how the human’s action can affect the 

robot’s sensor (and vice versa). One way be for the human’s action to directly change the world R 

in a way that will be perceive by the robot. The other way be for the human to also affect the 

world R, but then for the robot to detect this change via it own sensors, and react base on this 

input, change part of R itself. In the second case, the information flow through the internal 

part of the perception–action loop of the robot—in the first case it do not. An example of the 

Frontiers | Empowerment As Replacement for the Three Laws of Robotics | Robotics and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/full 

17 sur 33 21/07/2017 19:08 



second case can be see in Figure 10, where the robot move in the same direction a the human, 

if there be a direct line of sight between the two agents. This result in a high transfer 

empowerment in those area where the human can be see by the robot. Obtaining this high 

transfer empowerment require the robot to react reliably to certain human actions. 

(http://www.frontiersin.org/files/Articles/260425/frobt-04-00025-HTML/image_m 
/frobt-04-00025-g009.jpg) 
Figure 9. The time-unrolled perception–action loop of two agents, color to visualize 
the different pathway potential causal flow can be realized. The red dash line indicate 
the causal flow from the human actuator at time t to the robot’s sensor variable S at 

time t + 3, which contributes to human-to-robot transfer empowerment. This potential causal flow can be realize by 
direct human influence on the environment R (one exemplary path show in blue). Alternatively, the human can 
influence the environment R, and the robot can then perceive this change, react to it by choose an appropriate action 
A and thereby influence it perceive environment itself. One exemplary path be show in orange. The dash arrow 
be those use by both pathways. 

(http://www.frontiersin.org/files/Articles/260425/frobt-04-00025-HTML/image_m 
/frobt-04-00025-g010.jpg) 
Figure 10. A visualization of the human-to-robot (HtR) transfer empowerment 
dependent on robot position (dark—low, light—high). In this scenario, the robot will 
mirror the human’s movement if it have a direct line of sight. This creates a high amount of 
potential causal flow through the robot where the latter see the human. It result in 
comparatively high transfer empowerment in those area where the robot have both a 
direct line of sight to the human (yellow) and be not shut down by close proximity to the 
human. The high transfer empowerment be attain at a distance, but in an area where 

the robot can see and react to the human; with this, the robot provide the human with operational proximity, i.e., the 
ability to influence the robot’s result state. 

The distinction between the two pathway for transfer empowerment, directly through the 

environment and through the internal part of the other agent’s perception–action loop, also 

provide u with reason to prefer human-to-robot transfer empowerment over transfer 

empowerment in the other direction. In human-to-robot transfer empowerment, the internal 

pathway be through the agent; so the robot can consider adjust it behavior, i.e., the way it 

responds with action to sensor inputs, in order to increase the transfer empowerment. In the 

robot-to-human transfer empowerment, the internal pathway be through the human, which the 

robot cannot optimize and the human should ideally not be burden with optimizing. So, if one 

seek to elicit a reliable reaction of the robot to the human’s action, then human-to-robot transfer 

empowerment should be the quantity to optimize. 

Aht t+3 

Frontiers | Empowerment As Replacement for the Three Laws of Robotics | Robotics and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/full 

18 sur 33 21/07/2017 19:08 



Another difference between the two direction of transfer empowerment becomes evident when 

we compare Figures 4 and 7. Both show the same simulation, but depict HtR- and robot 

empowerment, respectively. The area with high HtR transfer empowerment be exactly the same 

area where the robot empowerment around the human begin to drop. This be because while the 

human here gain control over the robot’s position, the latter loses this very control. 

Controllability of a specific share variable in the environment be a limited resource, and if one 

agent have full control of it, the other agent consequently have none. This be another reason why the 

use of transfer empowerment be usually preferable in the human-to-robot direction, namely, a to 

not provide an incentive for the robot to take control away from the human. 

The different scenario we look at also illustrate the idea of “operational proximity” that 

transfer empowerment captures. The influence of one agent on another do not necessarily 

depend on physical proximity, but rather on both agents’ embodiment, here in the form of their 

action and sensor perceptions. While in one scenario the human could stop the robot by physical 

proximity, in the other they could direct the robot along their line of sight. In the dungeon 

example, the companion need proximity to directly affect the player by block or shoot it, 

but one could also instead imagine a situation where the NPC would push a button far away or 

block a laser somewhere else to affect the environment of the player. Maximizing transfer 

empowerment try to attain this operational rather than physical proximity. In turn, operational 

proximity act a a necessary precondition for any interaction and coordination between the 

agents. To interact, one agent have to be able to perceive the change of the world induced by the 

other agent. Vanishing transfer empowerment would mean that not even this basic level of 

interaction be possible. 

Furthermore, HtR transfer empowerment maximization also creates an incentive to reliably react 

to the human actions. In detail, this mean increase the transfer empowerment further by 

allow for some potential causal flow through the internal part of the robot’s perception–action 

loop. Note that for the empowerment calculation, it do not matter how precisely robot action 

be match to human actions; all that count be that by consistently respond in the same way 

the robot effectively extends the human’s empowerment in the world. The robot react to the 

human expands the influence of the latter on the world, because the human’s action be 

amplify by the robot’s actions. An additional effect be that, if a robot reliably reacts to the 

human’s actions, the human can learn this relationship and use it own action a proto-gestures 

to control the robot. On the one hand, this be still far remove from give explicit verbal order to 

the robot, a described in the Second Law. On the other hand, such a reliable reaction of the robot 

to human action would permit human to “learn” a command language consist of certain 

behavior and gesture that would then cause the robot to respond in a desire way. 

Summarizing the section, while the maximization of transfer empowerment do not precisely 

capture the Second Law, it creates operational proximity between the human and the robot, and 

thereby the basis for further interaction; together with the enhancement of human 

empowerment, it set the foundation for the human to have the maximum amount of option 

available. Furthermore, if the robot behavior itself be include in the computation of transfer 

Frontiers | Empowerment As Replacement for the Three Laws of Robotics | Robotics and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/full 

19 sur 33 21/07/2017 19:08 



empowerment to be optimized, then this would provide an additional route to amplify the 

human’s action in the world, namely by virtue of manipulate the robot via action and proto- 

gesture which make use of an implicitly learnt understand of the internal control of the robot. 

The core aim of this article be to suggest three empowerment perspective and to propose that 

these allow—in principle—for a formalization and operationalization of idea roughly 

correspond to the Three Laws of Robotics (not in order): the self-preservation of a robot, the 

protection of the robot’s human partner, and the robot supporting/expanding the human’s 

operational capabilities. Empowerment endows a state space cum transition dynamic with a 

generic pseudo-utility function that serf a a rich preference landscape without require an 

explicit, externally define reward structure; on the other hand, where desired, it can be 

combine with explicit task-dependent rewards. Empowerment can be use a both a generic and 

intrinsic value function. It serf not only a a warn indicator that one be approach the 

boundary of the viability domain (i.e., be close to area of imminent breakdown/destruction) 

but also imbues the interior of the viability domain with additional preference structure in 

advance of any task-specific utility. This, together with the property outline in Section 2.1 

about intrinsic motivations, suggests empowerment a a useful drive principle for an embody 

robot. 

For the practical application of the present formalism to real and more complex robot–human 

interaction scenarios, still a number of issues, such a computability and model acquisition need 

to be addressed. The follow discussion outline suggestion on how some of these challenge 

can be overcome and the problem still to be solve to deploy the present heuristic on real- 

world scenarios. 

Extending the idea present here from simple abstract model into the domain of practical 

robotics immediately raise the question of computability. In the classical empowerment 

formalism, computation time scale dramatically with an increase in sensor and actuator state 

and with an extension of the temporal horizon. In discrete domains, previous work have 

demonstrate a number of way a to how to speed up the computation: one be the 

impoverish empowerment approach by Anthony et al. (2011). Here, one only considers the 

most “meaningful” action sequence to generate the empowerment, prune away the others, and 

then building up longer action sequence by extend only those meaningful action sequences. 

A simple alternative option be to just sample a subset of all action sequence and compute 

empowerment base on this sample to get a heuristic estimate for the actual value (Salge et al., 

2014a). This approach only work effectively in a system with discrete state and deterministic 

dynamic that do not spread out too much. 

Frontiers | Empowerment As Replacement for the Three Laws of Robotics | Robotics and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/full 

20 sur 33 21/07/2017 19:08 



Earlier, we mention a fast approximation method for continuous variable (Salge et al., 2012). 

This assumes that the local transition can be sufficiently well approximate by a Gaussian 

channel. Another recent and fast approximation for Gaussian channel us variance propagation 

methods, implement use neural network (Karl et al., 2015). Another promising approach 

utilize neural network be present by Mohamed and Jimenez Rezende (2015) and provide 

not only considerable speed-ups but also have the advantage of work without an explicit 

forward model. 

With the establishment of empowerment a a viable and useful intrinsic motivation driver for 

artificial agent in a battery of proof-of-principle scenario over the last years, it have become 

evident that it be well warrant to invest effort into improve and speed up empowerment 

computation for realistically size scenarios. The previous list of method show that a promising 

range of approach to speed up empowerment computation already exists and that such 

approximation may well be viable. We have, therefore, ground to believe that future work will 

find even good way to scale empowerment computation up, thus render it more suitable to 

deployment on practically relevant robotic systems. 

Traditional method for empowerment calculation crucially require the agent to have an 

interventional forward model (Salge et al., 2012). So far, we have sidestep this question of 

model acquisition, mostly because the acquisition of the local interventional model to compute 

empowerment can be treat a a separate problem which can be solve in different way by 

exist method (Dearden and Demiris, 2005; Nguyen-Tuong and Peters, 2011). 

First, one would learn the local causal dynamic of agent–world interaction; from this one can 

then compute empowerment which, a a second step, provide an intrinsic reward or pseudo- 

utility function which be associate with the different world state distinguishable to the agent. As 

example, previous work in the continuous domain demonstrate how Gaussian Process learner 

(Rasmussen and Williams, 2006) can learn the local dynamic of a system on the fly while 

empowerment base on these incrementally improved, experience-based model can then be 

use to control invert pendulum model (Jung et al., 2011) or even a physical robot (Leu et al., 

2013). 

Whether the forward model be prespecified or learnt during the run, empowerment will generally 

drive the agent toward state with more options. However, if train during the run of the agent, 

the model will in general also include uncertainty on the outcome of actions. Such uncertainty 

“devalues” any option available in this state and will lead to a reduction of empowerment. This 

reduction be irrespective of whether the uncertainty be due to “objective” noise in the environment 

and unpredictability (e.g., due to another agent) or due to internal model error stem from 

insufficient training. From the point of view of empowerment both effect be equivalent. 

The first class of uncertainty (environmental uncertainty) will tend to drive the agent away from 

noisy or unpredictable area to comparatively more predictable one if the available option be 

Frontiers | Empowerment As Replacement for the Three Laws of Robotics | Robotics and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/full 

21 sur 33 21/07/2017 19:08 



otherwise equivalent, or reduce the value of richer option set when they can be only 

unpredictably invoked. The second class of uncertainty (model uncertainty) will—in the initial 

phase of the training—cause empowerment to devalue state where the model cannot resolve the 

available options. This have consequence for a purely empowerment-driven exploration of rich, 

but non-obvious interaction patterns; a prominent candidate for such a scenario would be 

learn the behavior of other agents, a long a they be comparatively reliable. 

The intertwine of learn and empowerment-driven behavior can thus be expect to produce 

a number of meta-effects on top of the already discuss dynamics. This could range from 

exhibit a very specific type of exploratory behavior; moreover, such agent might initially be 

averse to encounter complex novel dynamic and other agents. On the other hand, by 

modulate the learn process and experience of an agent a well a it sensory resolution or 

“scope of attention” depend on the situation, one could guide the agent toward develop the 

desire sensitivities. 

Such a process would, in a way, be reminiscent of the socialization of animal and human to 

ensure that they develop an appropriate sense for the social dynamic of the world they live in. 

This, together with the early discussion in this paper, invite the hypothesis that, to be confident 

of the safety of an autonomous robot the follow be essential: not only do this machine need to 

be “other-aware,” but if that “other-awareness” be to be learnt while enjoy to a large extent the 

level of autonomy that an intrinsic motivation model provides, it will be essential for the machine 

to undergo a suitably organize socialization process. 

As a technical note, we remark that the type of model require for empowerment computation 

only need to relate the action and current sensor state to the expect subsequent sensor state 

and do not require the complete world mechanics. In fact, empowerment can be base on the 

general, but purely intrinsic Predictive State Representations (PSR) formalism (Singh et al., 

2004; Anthony et al., 2013). This make it suitable for application to recent robotic approach 

(Maye and Engel, 2013) interested in the idea of sensorimotor contingency (O’Regan and Noë, 

2001); this work considers the understand of the world to be built up by immediate interaction 

with it and learn which action change and which do not change the agent’s perception. This 

offer a route to deploy empowerment already on very simple robot with the aim of gradually 

building an “understanding” of the world from the bottom up. 

One central property of empowerment be that the formalism remains practically unchanged for 

different incarnation of robot or agent and have very few parameters; the time horizon be the 

only one for discrete empowerment. However, there be one, less obvious, “parameter” which have 

only be briefly discuss in the previous literature (Salge et al., 2014c) and only hint at in the 

last section: the question of sensor and actuator selection in the model. 

By consider only certain sensor variables, one can reduce the state space and speed up 

computation immensely. However, one also influence the outcome of the computation by 

Frontiers | Empowerment As Replacement for the Three Laws of Robotics | Robotics and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/full 

22 sur 33 21/07/2017 19:08 



basically assign which distinction between state of the world should be consider relevant. 

An agent with positional sensor will only care about mobility, while an agent with visual sensor 

might also care about be in a state with different reachable views. In the simplest models, we 

often just assume that the agent perceives the whole world. In biological examples, we can lean on 

the idea of evolutionary adaptation (i.e., Jeffery (2005)), argue that sensor that would register 

state irrelevant to the agent would disappear, leave only relevant sensors. Meanwhile, on a 

robot, we usually have a generous selection of sensors, and we might not consider all of them to 

be relevant. However, for parsimonious design, or in imitation of a hypothesize principle of 

parsimony in biology (Laughlin et al., 1998), it might be opportune to limit oneself to select 

essentially those sensor associate with capability worth preserving. Similarly, when 

consider the human empowerment, model the appropriate human sensor will make a big 

difference to which operational capacity of the human, and which form of influence on the 

world, will be protect by the robot. 

This becomes even more of an issue when consider transfer empowerment which be basically 

an example of use partial sensor selection to focus on relevant properties. If both the human 

and the robot could fully sense the environment, then the human empowerment and the human- 

to-robot transfer empowerment would be identical, a both the human and the robot sensor 

would capture exactly the same information. In the continuous 2D example present in this 

paper, we consider the human’s sensor to only capture the human’s position, and the robot 

sensor to only capture the robot’s position, so their perception would be distinct. In the NPC AI 

example by Guckelsberger and Salge (2016), the player and companion have sensor that perceive 

the world around it within a certain distance, and always relative to their own position. That is, 

they detect the content of the field directly to the east of the player, rather than specify the field of 

interest by a coordinate value such a 3.1. 

If we extend the human’s sensor to the extent that the human could sense at least everything 

that the robot can sense, then the sensor relevant for transfer empowerment would be a subset of 

human empowerment. We could then just compute human empowerment and capture both 

potential causal flow at the same time. But by splitting the sensor variables, we basically 

compute partial sensor empowerment, once for the sensor pertain to the human state and 

once with a selection of sensor pertain to the robot state. In a real world scenario the 

embody perspective of both the human and the robot usually lead to different perception of the 

world. Both have limited sensor and a a result there be a natural distinction between their 

respective sensor inputs. When use simulated environment, on the other hand, it be often easy 

to give all agent access to the whole world state. In this case it becomes necessary to limit the 

sensor of the different agent to introduce this split, before one be able to differentiate between 

the two different heuristics. This separation of human and human-to-robot empowerment allows 

for the prioritization of human empowerment over transfer empowerment. In general, we would 

expect one bit of human empowerment to be more valuable than one bit of human-to-robot 

empowerment and, therefore, aim to retain this distinction. 

Frontiers | Empowerment As Replacement for the Three Laws of Robotics | Robotics and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/full 

23 sur 33 21/07/2017 19:08 



Whenever different variant of some evaluation function exist which cover different aspect of a 

phenomenon and these aspect be combined, one be left with the question how to weight them 

against each other. In the present case, this would mean balance the three type of 

empowerment. The analogy with the Three Laws might suggest a clear hierarchy, where one 

would first maximize human empowerment and then only consider the other heuristics. 

However, give that one can always expect some minimal non-trivial gradient to exist in the first, 

such a lexicographic order would basically lead to only maximize human empowerment 

above all else, completely override the other measures. 

On the other hand, go back to Figure 6, we saw that the companion, when face with a threat 

to itself and the player, choose to first save itself from death, while permit minor damage to 

the player, and only then proceed to remove the threat to the player. While this clearly violates 

the strict hierarchy of the Three Laws, such a course of action might well be in the rational 

interest of the player, since it might be worthwhile to trade the minor loss of a life point for still 

have a companion (all this, of course, presumes that the agent’s forward model be correct that 

the enemy shoot the human once will not seriously damage the latter; but such dilemmata be 

also present in mission-critical human decision-making under uncertainty). 

This conceptual tension be also present in the original Three Laws. Consider a 

gedankenexperiment where a robot be face with two options: (A) inflict minor harm, such a a 

scratch, on a single human or (B) by avoid that, permit the destruction of all (perfectly 

peaceful) robot on earth. In a strict interpretation, the Laws would dictate to chose option (B), 

but we might be inclined to consider that there must be some amount of harm so negligible that 

(A) would seem the good option than cause a regression to a robotic “Stone Age.” 

But how could we capture this insight with our three previously developed heuristics? We can, of 

course, consider a straightforward weight sum of the three heuristics, define some trade-off 

between the three value in the usual manner. But this approach inevitably raise the question 

whether there would be some distinct non-arbitrary trade-off. 

The previous analogy be instructive. The problem be that option (B), the destruction of all robots, 

would create a lot of more significant problem further down the line than the single scratch of 

option A. It would result in the loss of all robot able to carry out the human commands, and 

there would be few robot to protect and save human in the future (they would have to be 

rebuilt, absorb significant productive work, before—if at all—reaching original levels). 

Both of these problem be reflect in human empowerment on longer timescales. In fact, we 

would suggest that all three heuristics, and actually also the original Three Laws, reflect the idea 

that one core reason why human build and program robot be actually to increase their very own 

empowerment, their very own option for the future. We already argue that transfer 

empowerment, the second heuristic, extends human empowerment further into the world, 

because the robot amplifies the human’s action and their impact on the world. Similarly, robot 

Frontiers | Empowerment As Replacement for the Three Laws of Robotics | Robotics and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/full 

24 sur 33 21/07/2017 19:08 



that preserve themselves, a by follow the third heuristic, make sure that they preserve or 

extend the human’s empowerment further. 

The first heuristic be already directly about human empowerment maximization itself. So, in 

essence, the two other heuristics, robot empowerment and transfer empowerment, can be see a 

a form of meta-heuristics for ultimate human empowerment maximization. We conjecture that 

both the behavior of the second and the third heuristic might emerge once one maximizes the 

human empowerment with a sufficiently long temporal horizon. For example, the robot could 

realize, with a good enough model of the future, that it need to keep itself functional in order to 

prevent harm to the human in the future. So, basically, we hypothesize that the Second and Third 

Law might manifest themselves a a short term proxy for a suitable longer term optimization of 

human empowerment. If so, it may be that this would help define a natural trade-off: in our 

example, the robot might calculate that, by prevent destruction of all robot on earth, at cost of 

inflict a small scratch on a human, it would prevent many more and bad injury of human 

in the future by the thus rescue robots. 

One final remark: in this paper we have not consider true multi-agent empowerment. The 

reason for this be subtle: empowerment so far be usually compute a an open-loop channel 

capacity. The future (potential) action sequence consider for empowerment be basically 

execute without react to the change sensor state inside the time horizon. In other words, 

empowerment be compute a the channel capacity between fixed-length “open-loop” action 

sequence and the future sensor observation. In choose these action sequences, intermediate 

sensor observation be not take into account. Thus the agent do not react to particular 

development in the environment while probe the potential future actions. 

This make it impossible to formally account for instantaneously react to another agent’s 

action during the computation of the potential futures, since this model selects action only at 

the begin and then only evaluates how the will affect the world at the end of the action run. 

However, we show early that transfer empowerment can be massively enhance by react 

to the human’s actions. This indicates strongly that it would be important to model empowerment 

with “reactive” action sequences, i.e., empowerment where action sequence be express in 

closed-loop form and which instantaneously react to other agent (or even change in the 

environment) while still inside the time horizon of the probed futures. 

These various aspect of the implementation of empowerment indicate a number of strategy to 

render it a useful tool to operationalize the Three Laws in a transparent way. Furthermore, they 

also may offer a pathway demonstrate how also other class of intrinsic motivation measure 

might be adapt to achieve the fusion of the desirable autonomy of robot with the requirement 

of the Three Laws. 

Frontiers | Empowerment As Replacement for the Three Laws of Robotics | Robotics and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/full 

25 sur 33 21/07/2017 19:08 



CS and DP developed the original idea. CS write and ran the simulation and draft the paper. 

DP advise during the development of the simulation and co-wrote the paper. 

The author declare that the research be conduct in the absence of any commercial or 

financial relationship that could be construe a a potential conflict of interest. 

The author would like to acknowledge support by the EC H2020-641321 socSMCs FET Proactive 

project, the H2020-645141 WiMUST ICT-23-2014 Robotics project, and the European Union 

Horizon 2020 research and innovation program under the Marie Sklodowska-Curie grant 

(705643). The author also thank Cornelius Glackin and Christian Guckelsberger for helpful 

discussions. 

Anderson, S. L. (2008). Asimov’s “three law of robotics” and machine metaethics. Ai Soc. 22, 477–493. doi: 
10.1007/s00146-007-0094-5 

CrossRef Full Text (https://doi.org/10.1007/s00146-007-0094-5) | Google Scholar (http://scholar.google.com 
/scholar_lookup?title=Asimov’s+“three+laws+of+robotics”+and+machine+metaethics&author=S.+L.+Anderson&jour- 
nal=Ai+Soc.&publication_year=2008&volume=22&pages=477–493&doi=10.1007/s00146-007-0094-5) 

Anthony, T., Polani, D., and Nehaniv, C. (2013). General self-motivation and strategy identification: case study base on 
Sokoban and Pac-Man. IEEE Trans. Comput. Intell. AI Games PP, 1. doi:10.1109/TCIAIG.2013.2295372 

CrossRef Full Text (https://doi.org/10.1109/TCIAIG.2013.2295372) | Google Scholar (http://scholar.google.com 
/scholar_lookup?title=General+self-motivation+and+strategy+identification:+case+studies+based+on+Sokoban+and+Pac- 
Man&author=T.+Anthony&author=D.+Polani&author=C.+Nehaniv&journal=IEEE+Trans.+Comput.+Intell.+AI+Games& 
publication_year=2013&pages=1&doi=10.1109/TCIAIG.2013.2295372) 

Anthony, T., Polani, D., and Nehaniv, C. L. (2011). “Impoverished empowerment: ‘meaningful’ action sequence generation 
through bandwidth limitation,” in Advances in Artificial Life. Darwin Meets von Neumann – 10th European Conference, 
ECAL 2009, Budapest, Hungary, September 13–16, 2009, Revised Selected Papers, Part II, Volume 5778 of Lecture Notes in 
Computer Science, ed G. Kampis, I. Karsai, and E. Szathmáry (Budapest, Hungary: Springer), 294–301. 

Google Scholar (http://scholar.google.com/scholar_lookup?title=“Impoverished+empowerment:+‘meaningful’+action+se- 
quence+generation+through+bandwidth+limitation,”&author=T.+Anthony&author=D.+Polani&author=C.+L.+Nehaniv& 
conference=Advances+in+Artificial+Life.+Darwin+Meets+von+Neumann+–+10th+European+Confer- 
ence,+ECAL+2009,+Budapest,+Hungary,+September+13–16,+2009,+Revised+Selected+Papers,+Part+II,+Vol- 
ume+5778+of+Lecture+Notes+in+Computer+Science&publication_year=2011&pages=294–301) 

Arimoto, S. (1972). An algorithm for compute the capacity of arbitrary discrete memoryless channels. IEEE Trans. Info. 
Theory 18, 14–20. doi:10.1109/TIT.1972.1054753 

CrossRef Full Text (https://doi.org/10.1109/TIT.1972.1054753) | Google Scholar (http://scholar.google.com 
/scholar_lookup?title=An+algorithm+for+computing+the+capacity+of+arbitrary+discrete+memoryless+channels&au- 
thor=S.+Arimoto&journal=IEEE+Trans.+Info.+Theory&publication_year=1972&volume=18&pages=14–20&doi=10.1109 

Frontiers | Empowerment As Replacement for the Three Laws of Robotics | Robotics and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/full 

26 sur 33 21/07/2017 19:08 



/TIT.1972.1054753) 

Asimov, I. (1942). Runaround. Astound. Sci. Fiction 29, 94–103. 

Google Scholar (http://scholar.google.com/scholar_lookup?title=Runaround&author=I.+Asimov&journal=As- 
tound.+Sci.+Fiction&publication_year=1942&volume=29&pages=94–103) 

Asimov, I. (1981). The three laws. Compute 18, 18. 

Google Scholar (http://scholar.google.com/scholar_lookup?title=The+three+laws&author=I.+Asimov&journal=Compute& 
publication_year=1981&volume=18&pages=18) 

Ay, N., Bertschinger, N., Der, R., Güttler, F., and Olbrich, E. (2008). Predictive information and explorative behavior of 
autonomous robots. Eur. Phys. J. B Condens. Matter Complex Syst. 63, 329–339. doi:10.1140/epjb/e2008-00175-0 

CrossRef Full Text (https://doi.org/10.1140/epjb/e2008-00175-0) | Google Scholar (http://scholar.google.com 
/scholar_lookup?title=Predictive+information+and+explorative+behavior+of+autonomous+robots&author=N.+Ay&au- 
thor=N.+Bertschinger&author=R.+Der&author=F.+Güttler&author=E.+Olbrich&journal=Eur.+Phys.+J.+B+Condens.+Mat- 
ter+Complex+Syst.&publication_year=2008&volume=63&pages=329–339&doi=10.1140/epjb/e2008-00175-0) 

Ay, N., and Polani, D. (2008). Information flow in causal networks. Adv. Complex Syst. 11, 17–41. 
doi:10.1142/S0219525908001465 

CrossRef Full Text (https://doi.org/10.1142/S0219525908001465) | Google Scholar (http://scholar.google.com 
/scholar_lookup?title=Information+flows+in+causal+networks&author=N.+Ay&author=D.+Polani&journal=Adv.+Com- 
plex+Syst.&publication_year=2008&volume=11&pages=17–41&doi=10.1142/S0219525908001465) 

Blahut, R. (1972). Computation of channel capacity and rate-distortion functions. IEEE Trans. Info. Theory 18, 460–473. 
doi:10.1109/TIT.1972.1054855 

CrossRef Full Text (https://doi.org/10.1109/TIT.1972.1054855) | Google Scholar (http://scholar.google.com 
/scholar_lookup?title=Computation+of+channel+capacity+and+rate-distortion+functions&author=R.+Blahut&jour- 
nal=IEEE+Trans.+Info.+Theory&publication_year=1972&volume=18&pages=460–473&doi=10.1109/TIT.1972.1054855) 

Boden, M., Bryson, J., Caldwell, D., Dautenhahn, K., Edwards, L., Kember, S., et al. (2011). “Principles of robotics,” in The 
United Kingdoms Engineering and Physical Sciences Research Council (EPSRC) (Web Publication). Available at: 
https://www.epsrc.ac.uk/research/ourportfolio/themes/engineering/activities/principlesofrobotics/ (https://www.ep- 
src.ac.uk/research/ourportfolio/themes/engineering/activities/principlesofrobotics/) 

Google Scholar (http://scholar.google.com/scholar_lookup?title=“Principles+of+robotics,”&author=M.+Boden&au- 
thor=J.+Bryson&author=D.+Caldwell&author=K.+Dautenhahn&author=L.+Edwards&author=S.+Kember&publica- 
tion_year=2011) 

Brooks, R. (1986). A robust layer control system for a mobile robot. IEEE J. Robot. Auto. 2, 14–23. 
doi:10.1109/JRA.1986.1087032 

CrossRef Full Text (https://doi.org/10.1109/JRA.1986.1087032) | Google Scholar (http://scholar.google.com 
/scholar_lookup?title=A+robust+layered+control+system+for+a+mobile+robot&author=R.+Brooks&journal=IEEE+J.+Ro- 
bot.+Auto.&publication_year=1986&volume=2&pages=14–23&doi=10.1109/JRA.1986.1087032) 

Coradeschi, S., Loutfi, A., and Wrede, B. (2013). A short review of symbol ground in robotic and intelligent systems. 
Künstliche Intell. 27, 129–136. doi:10.1007/s13218-013-0247-2 

CrossRef Full Text (https://doi.org/10.1007/s13218-013-0247-2) | Google Scholar (http://scholar.google.com 
/scholar_lookup?title=A+short+review+of+symbol+grounding+in+robotic+and+intelligent+systems&author=S.+Corade- 
schi&author=A.+Loutfi&author=B.+Wrede&journal=Künstliche+Intell.&publication_year=2013&volume=27& 
pages=129–136&doi=10.1007/s13218-013-0247-2) 

Dearden, A., and Demiris, Y. (2005). “Learning forward model for robots,” in Proceedings of the 19th International Joint 
Conference on Artificial Intelligence (Edinburgh: Morgan Kaufmann Publishers Inc.), 1440–1445. 

Google Scholar (http://scholar.google.com/scholar_lookup?title=“Learning+forward+models+for+robots,”&au- 
thor=A.+Dearden&author=Y.+Demiris&conference=Proceedings+of+the+19th+International+Joint+Conference+on+Artifi- 
cial+Intelligence&publication_year=2005&pages=1440–1445) 

Dennett, D. C. (1984). “Cognitive wheels: the frame problem of AI,” in Minds, Machines and Evolution, ed. C. Hookway 
(Cambridge, MA: Cambridge University Press), 129–150. 

Google Scholar (http://scholar.google.com/scholar_lookup?title=“Cognitive+wheels:+the+frame+problem+of+AI,”&au- 

Frontiers | Empowerment As Replacement for the Three Laws of Robotics | Robotics and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/full 

27 sur 33 21/07/2017 19:08 



thor=D.+C.+Dennett&publication_year=1984&pages=129–150) 

Der, R., Steinmetz, U., and Pasemann, F. (1999). Homeokinesis: A New Principle to Back up Evolution with Learning. 
Leipzig: Max-Planck-Inst. für Mathematik in den Naturwiss. 

Google Scholar (http://scholar.google.com/scholar_lookup?title=Homeokinesis:+A+New+Principle+to+Back+up+Evolu- 
tion+with+Learning&author=R.+Der&author=U.+Steinmetz&author=F.+Pasemann&publication_year=1999) 

Guckelsberger, C., and Salge, C. (2016). “Does empowerment maximisation allow for enactive artificial agents?” in 
Proceedings of the 15th International Conference on the Synthesis and Simulation of Living Systems (ALIFE’16), Cancun. 

Google Scholar (http://scholar.google.com/scholar_lookup?title=“Does+empowerment+maximisation+allow+for+enac- 
tive+artificial+agents?”&author=C.+Guckelsberger&author=C.+Salge&conference=Proceedings+of+the+15th+Interna- 
tional+Conference+on+the+Synthesis+and+Simulation+of+Living+Systems+(ALIFE’16)&publication_year=2016) 

Guckelsberger, C., Salge, C., and Colton, S. (2016). “Intrinsically motivate general companion npc via couple 
empowerment maximisation,” in IEEE Conference on Computational Intelligence and Games (CIG) (Santorini: IEEE). 

Google Scholar (http://scholar.google.com/scholar_lookup?title=“Intrinsically+motivated+general+compan- 
ion+npcs+via+coupled+empowerment+maximisation,”&author=C.+Guckelsberger&author=C.+Salge&author=S.+Colton& 
conference=IEEE+Conference+on+Computational+Intelligence+and+Games+(CIG)&publication_year=2016) 

Hasslacher, B., and Tilden, M. W. (1995). Living machines. Rob. Auton. Syst. 15, 143–169. 
doi:10.1016/0921-8890(95)00019-C 

CrossRef Full Text (https://doi.org/10.1016/0921-8890(95)00019-C) | Google Scholar (http://scholar.google.com 
/scholar_lookup?title=Living+machines&author=B.+Hasslacher&author=M.+W.+Tilden&journal=Rob.+Auton.+Syst.&pub- 
lication_year=1995&volume=15&pages=143–169&doi=10.1016/0921-8890(95)00019-C) 

Jeffery, W. R. (2005). Adaptive evolution of eye degeneration in the Mexican blind cavefish. J. Hered. 96, 185–196. 
doi:10.1093/jhered/esi028 

PubMed Abstract (http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&Cmd=ShowDetailView& 
TermToSearch=15653557) | CrossRef Full Text (https://doi.org/10.1093/jhered/esi028) | Google Scholar 
(http://scholar.google.com/scholar_lookup?title=Adaptive+evolution+of+eye+degeneration+in+the+Mexican+blind+cave- 
fish&author=W.+R.+Jeffery&journal=J.+Hered.&publication_year=2005&volume=96&pages=185–196&doi=10.1093 
/jhered/esi028&pmid=15653557) 

Jung, T., Polani, D., and Stone, P. (2011). Empowerment for continuous agent environment systems. Adapt. Behav. 19, 16. 
doi:10.1177/1059712310392389 

CrossRef Full Text (https://doi.org/10.1177/1059712310392389) | Google Scholar (http://scholar.google.com 
/scholar_lookup?title=Empowerment+for+continuous+agent+environment+systems&author=T.+Jung&author=D.+Polani& 
author=P.+Stone&journal=Adapt.+Behav.&publication_year=2011&volume=19&pages=16&doi=10.1177 
/1059712310392389) 

Karl, M., Bayer, J., and van der Smagt, P. (2015). Efficient empowerment. arXiv preprint arXiv:1509.08455. Available at: 
https://arxiv.org/abs/1509.08455 (https://arxiv.org/abs/1509.08455) 

Google Scholar (http://scholar.google.com/scholar_lookup?title=Efficient+empowerment.+arXiv+pre- 
print+arXiv:1509.08455&author=M.+Karl&author=J.+Bayer&author=P.+van+der+Smagt&publication_year=2015) 

Klyubin, A., Polani, D., and Nehaniv, C. (2005). “Empowerment: a universal agent-centric measure of control,” in The 2005 
IEEE Congress on Evolutionary Computation, Vol. 1 (Edinburgh: IEEE), 128–135. 

Google Scholar (http://scholar.google.com/scholar_lookup?title=“Empowerment:+a+universal+agent-centric+mea- 
sure+of+control,”&author=A.+Klyubin&author=D.+Polani&author=C.+Nehaniv&publication_year=2005&volume=1) 

Klyubin, A., Polani, D., and Nehaniv, C. (2008). Keep your option open: an information-based drive principle for 
sensorimotor systems. PLoS ONE 3:e4018. doi:10.1371/journal.pone.0004018 

PubMed Abstract (http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&Cmd=ShowDetailView& 
TermToSearch=19107219) | CrossRef Full Text (https://doi.org/10.1371/journal.pone.0004018) | Google Scholar 
(http://scholar.google.com/scholar_lookup?title=Keep+your+options+open:+an+information-based+driving+princi- 
ple+for+sensorimotor+systems&author=A.+Klyubin&author=D.+Polani&author=C.+Nehaniv&journal=PLoS+ONE&publi- 
cation_year=2008&volume=3&pages=e4018&doi=10.1371/journal.pone.0004018&pmid=19107219) 

Laughlin, S. B., de Ruyter van Steveninck, R. R., and Anderson, J. C. (1998). The metabolic cost of neural information. Nat. 
Neurosci. 1, 36–41. doi:10.1038/236 

Frontiers | Empowerment As Replacement for the Three Laws of Robotics | Robotics and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/full 

28 sur 33 21/07/2017 19:08 



PubMed Abstract (http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&Cmd=ShowDetailView& 
TermToSearch=10195106) | CrossRef Full Text (https://doi.org/10.1038/236) | Google Scholar (http://scholar.google.com 
/scholar_lookup?title=The+metabolic+cost+of+neural+information&author=S.+B.+Laughlin&au- 
thor=R.+R.+de+Ruyter+van+Steveninck&author=J.+C.+Anderson&journal=Nat.+Neurosci.&publication_year=1998&vol- 
ume=1&pages=36–41&doi=10.1038/236&pmid=10195106) 

Leu, A., Ristic-Durrant, D., Slavnic, S., Glackin, C., Salge, C., Polani, D., et al. (2013). “Corbys cognitive control architecture 
for robotic follower,” in IEEE/SICE International Symposium on System Integration (SII) (Taipei: IEEE), 394–399. 

Google Scholar (http://scholar.google.com/scholar_lookup?title=“Corbys+cognitive+control+architecture+for+robotic+fol- 
lower,”&author=A.+Leu&author=D.+Ristic-Durrant&author=S.+Slavnic&author=C.+Glackin&author=C.+Salge&au- 
thor=D.+Polani&conference=IEEE/SICE+International+Symposium+on+System+Integration+(SII)&publica- 
tion_year=2013&pages=394–399) 

Maturana, H. R., and Varela, F. J. (1991). Autopoiesis and Cognition: The Realization of the Living, Vol. 42. Springer. 

Google Scholar (http://scholar.google.com/scholar_lookup?title=Autopoiesis+and+Cognition:+The+Realiza- 
tion+of+the+Living&author=H.+R.+Maturana&author=F.+J.+Varela&publication_year=1991&volume=42) 

Maye, A., and Engel, A. K. (2013). Extending sensorimotor contingency theory: prediction, planning, and action generation. 
Adapt. Behav. 21, 423–436. doi:10.1177/1059712313497975 

CrossRef Full Text (https://doi.org/10.1177/1059712313497975) | Google Scholar (http://scholar.google.com 
/scholar_lookup?title=Extending+sensorimotor+contingency+theory:+prediction,+planning,+and+action+generation&au- 
thor=A.+Maye&author=A.+K.+Engel&journal=Adapt.+Behav.&publication_year=2013&volume=21&pages=423–436& 
doi=10.1177/1059712313497975) 

McCauley, L. (2007). Ai Armageddon and the three law of robotics. Ethics Inf. Technol. 9, 153–164. 
doi:10.1007/s10676-007-9138-2 

CrossRef Full Text (https://doi.org/10.1007/s10676-007-9138-2) | Google Scholar (http://scholar.google.com 
/scholar_lookup?title=Ai+Armageddon+and+the+three+laws+of+robotics&author=L.+McCauley&jour- 
nal=Ethics+Inf.+Technol.&publication_year=2007&volume=9&pages=153–164&doi=10.1007/s10676-007-9138-2) 

Mohamed, S., and Jimenez Rezende, D. (2015). “Variational information maximisation for intrinsically motivate 
reinforcement learning,” in Advances in Neural Information Processing Systems 28, ed C. Cortes, N. Lawrence, D. Lee, M. 
Sugiyama, R. Garnett, and R. Garnett (Montreal: Curran & Associates Inc.), 2116–2124. 

Google Scholar (http://scholar.google.com/scholar_lookup?title=“Variational+information+maximisation+for+intrinsi- 
cally+motivated+reinforcement+learning,”&author=S.+Mohamed&author=D.+Jimenez+Rezende&publication_year=2015& 
pages=2116–2124) 

Murphy, R. R., and Woods, D. D. (2009). Beyond Asimov: the three law of responsible robotics. IEEE Intell. Syst 24, 14–20. 
doi:10.1109/MIS.2009.69 

CrossRef Full Text (https://doi.org/10.1109/MIS.2009.69) | Google Scholar (http://scholar.google.com/scholar_lookup?ti- 
tle=Beyond+Asimov:+the+three+laws+of+responsible+robotics&author=R.+R.+Murphy&author=D.+D.+Woods&jour- 
nal=IEEE+Intell.+Syst&publication_year=2009&volume=24&pages=14–20&doi=10.1109/MIS.2009.69) 

Nguyen-Tuong, D., and Peters, J. (2011). Model learn for robot control: a survey. Cogn. Process. 12, 319–340. 
doi:10.1007/s10339-011-0404-1 

PubMed Abstract (http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&Cmd=ShowDetailView& 
TermToSearch=21487784) | CrossRef Full Text (https://doi.org/10.1007/s10339-011-0404-1) | Google Scholar 
(http://scholar.google.com/scholar_lookup?title=Model+learning+for+robot+control:+a+survey&author=D.+Nguyen- 
Tuong&author=J.+Peters&journal=Cogn.+Process.&publication_year=2011&volume=12&pages=319–340&doi=10.1007 
/s10339-011-0404-1&pmid=21487784) 

Oesterreich, R. (1979). Entwicklung eines Konzepts der objectiven Kontrolle und Kontrollkompetenz. Ein 
handlungstheoretischer Ansatz. Ph.D. thesis, Technische Universität, Berlin. 

Google Scholar (http://scholar.google.com/scholar_lookup?title=Entwicklung+eines+Konzepts+der+objectiven+Kon- 
trolle+und+Kontrollkompetenz.+Ein+handlungstheoretischer+Ansatz&author=R.+Oesterreich&publication_year=1979) 

O’Regan, J. K., and Noë, A. (2001). A sensorimotor account of vision and visual consciousness. Behav. Brain Sci. 24, 
939–973. doi:10.1017/S0140525X01000115 

PubMed Abstract (http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&Cmd=ShowDetailView& 

Frontiers | Empowerment As Replacement for the Three Laws of Robotics | Robotics and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/full 

29 sur 33 21/07/2017 19:08 



TermToSearch=12239892) | CrossRef Full Text (https://doi.org/10.1017/S0140525X01000115) | Google Scholar 
(http://scholar.google.com/scholar_lookup?title=A+sensorimotor+account+of+vision+and+visual+consciousness&au- 
thor=J.+K.+O’Regan&author=A.+Noë&journal=Behav.+Brain+Sci.&publication_year=2001&volume=24&pages=939–973& 
doi=10.1017/S0140525X01000115&pmid=12239892) 

Oudeyer, P.-Y., and Kaplan, F. (2007). What be intrinsic motivation? A typology of computational approaches. Front. 
Neurorobot. 1:6. doi:10.3389/neuro.12.006.2007 

PubMed Abstract (http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&Cmd=ShowDetailView& 
TermToSearch=18958277) | CrossRef Full Text (https://doi.org/10.3389/neuro.12.006.2007) | Google Scholar 
(http://scholar.google.com/scholar_lookup?title=What+is+intrinsic+motivation?+A+typology+of+computational+ap- 
proaches&author=P.+Y.+Oudeyer&author=F.+Kaplan&journal=Front.+Neurorobot.&publication_year=2007&volume=1& 
pages=6&doi=10.3389/neuro.12.006.2007&pmid=18958277) 

Oudeyer, P.-Y., Kaplan, F., and Hafner, V. (2007). Intrinsic motivation system for autonomous mental development. IEEE 
Trans. Evol. Comput. 11, 265–286. doi:10.1109/TEVC.2006.890271 

CrossRef Full Text (https://doi.org/10.1109/TEVC.2006.890271) | Google Scholar (http://scholar.google.com 
/scholar_lookup?title=Intrinsic+motivation+systems+for+autonomous+mental+development&author=P.+Y.+Oudeyer&au- 
thor=F.+Kaplan&author=V.+Hafner&journal=IEEE+Trans.+Evol.+Comput.&publication_year=2007&volume=11& 
pages=265–286&doi=10.1109/TEVC.2006.890271) 

Pearl, J. (2000). Causality: Models, Reasoning and Inference. Cambridge, UK: Cambridge University Press. 

Google Scholar (http://scholar.google.com/scholar_lookup?title=Causality:+Models,+Reasoning+and+Inference&au- 
thor=J.+Pearl&publication_year=2000) 

Pfeifer, R., and Bongard, J. (2006). How the Body Shapes the Way We Think: A New View of Intelligence. Cambridge, MA: 
MIT Press. 

Google Scholar (http://scholar.google.com/scholar_lookup?ti- 
tle=How+the+Body+Shapes+the+Way+We+Think:+A+New+View+of+Intelligence&author=R.+Pfeifer&author=J.+Bon- 
gard&publication_year=2006) 

Rasmussen, C., and Williams, C. (2006). Gaussian Processes for Machine Learning. Cambridge, MA: MIT Press, 1. 

Google Scholar (http://scholar.google.com/scholar_lookup?title=Gaussian+Processes+for+Machine+Learning&au- 
thor=C.+Rasmussen&author=C.+Williams&publication_year=2006) 

Ryan, R. M., and Deci, E. L. (2000). Intrinsic and extrinsic motivations: classic definition and new directions. Contemp. 
Educ. Psychol. 25, 54–67. doi:10.1006/ceps.1999.1020 

PubMed Abstract (http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&Cmd=ShowDetailView& 
TermToSearch=10620381) | CrossRef Full Text (https://doi.org/10.1006/ceps.1999.1020) | Google Scholar 
(http://scholar.google.com/scholar_lookup?title=Intrinsic+and+extrinsic+motivations:+classic+definitions+and+new+di- 
rections&author=R.+M.+Ryan&author=E.+L.+Deci&journal=Contemp.+Educ.+Psychol.&publication_year=2000&vol- 
ume=25&pages=54–67&doi=10.1006/ceps.1999.1020&pmid=10620381) 

Salge, C., Glackin, C., and Polani, D. (2012). Approximation of empowerment in the continuous domain. Adv. Complex Syst. 
16, 1250079. doi:10.1142/S0219525912500798 

CrossRef Full Text (https://doi.org/10.1142/S0219525912500798) | Google Scholar (http://scholar.google.com 
/scholar_lookup?title=Approximation+of+empowerment+in+the+continuous+domain&author=C.+Salge&au- 
thor=C.+Glackin&author=D.+Polani&journal=Adv.+Complex+Syst.&publication_year=2012&volume=16&pages=1250079& 
doi=10.1142/S0219525912500798) 

Salge, C., Glackin, C., and Polani, D. (2013). “Empowerment and state-dependent noise-an intrinsic motivation for avoid 
unpredictable agents,” in Advances in Artificial Life, ECAL, Vol. 12, 118–125. Available at: https://mitpress.mit.edu/sites/de- 
fault/files/titles/content/ecal13/ch018.html (https://mitpress.mit.edu/sites/default/files/titles/content/ecal13/ch018.html) 

Google Scholar (http://scholar.google.com/scholar_lookup?title=“Empowerment+and+state-dependent+noise-an+intrin- 
sic+motivation+for+avoiding+unpredictable+agents,”&author=C.+Salge&author=C.+Glackin&author=D.+Polani&publica- 
tion_year=2013&volume=12&pages=118–125) 

Salge, C., Glackin, C., and Polani, D. (2014a). Changing the environment base on empowerment a intrinsic motivation. 
Entropy 16, 2789. doi:10.3390/e16052789 

CrossRef Full Text (https://doi.org/10.3390/e16052789) | Google Scholar (http://scholar.google.com/scholar_lookup?ti- 

Frontiers | Empowerment As Replacement for the Three Laws of Robotics | Robotics and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/full 

30 sur 33 21/07/2017 19:08 



tle=Changing+the+environment+based+on+empowerment+as+intrinsic+motivation&author=C.+Salge&au- 
thor=C.+Glackin&author=D.+Polani&journal=Entropy&publication_year=2014a&volume=16&pages=2789&doi=10.3390 
/e16052789) 

Salge, C., Glackin, C., and Polani, D. (2014b). “Empowerment: a route towards the three law of robotics,” in Seventh 
International Workshop on Guided Self-Organization. Freiburg. Available at: http://ml.informatik.uni-freiburg.de/events 
/gso14/index (http://ml.informatik.uni-freiburg.de/events/gso14/index) 

Google Scholar (http://scholar.google.com/scholar_lookup?title=“Empowerment:+a+route+to- 
wards+the+three+laws+of+robotics,”&author=C.+Salge&author=C.+Glackin&author=D.+Polani&conference=Seventh+In- 
ternational+Workshop+on+Guided+Self-Organization&publication_year=2014b) 

Salge, C., Glackin, C., and Polani, D. (2014c). “Empowerment – an introduction,” in Guided Self-Organization: Inception 
(Springer). Available at: https://link.springer.com/chapter/10.1007/978-3-642-53734-9_4?no-access=true 
(https://link.springer.com/chapter/10.1007/978-3-642-53734-9_4?no-access=true) 

Google Scholar (http://scholar.google.com/scholar_lookup?title=“Empowerment+–+an+introduction,”&author=C.+Salge& 
author=C.+Glackin&author=D.+Polani&publication_year=2014c) 

Schmidhuber, J. (1991). “Curious model-building control systems,” in IEEE International Joint Conference on Neural 
Networks (Singapore: IEEE), 1458–1463. 

Google Scholar (http://scholar.google.com/scholar_lookup?title=“Curious+model-building+control+systems,”&au- 
thor=J.+Schmidhuber&conference=IEEE+International+Joint+Conference+on+Neural+Networks&publication_year=1991& 
pages=1458–1463) 

Seligman, M. E. (1975). Helplessness: On Depression, Development, and Death. New York, NY: WH Freeman/Times 
Books/Henry Holt & Co. 

Google Scholar (http://scholar.google.com/scholar_lookup?title=Helplessness:+On+Depression,+Develop- 
ment,+and+Death&author=M.+E.+Seligman&publication_year=1975) 

Shannon, C. E. (1948). A mathematical theory of communication. Bell Syst. Tech. J. 27, 623–656. 
doi:10.1002/j.1538-7305.1948.tb00917.x 

CrossRef Full Text (https://doi.org/10.1002/j.1538-7305.1948.tb00917.x) | Google Scholar (http://scholar.google.com 
/scholar_lookup?title=A+mathematical+theory+of+communication&author=C.+E.+Shannon&jour- 
nal=Bell+Syst.+Tech.+J.&publication_year=1948&volume=27&pages=623–656&doi=10.1002/j.1538-7305.1948.tb00917.x) 

Singh, S., James, M. R., and Rudary, M. R. (2004). “Predictive state representations: a new theory for model dynamical 
systems,” in Proceedings of the Twentieth Conference on Uncertainty in Artificial Intelligence (UAI), Banff, 512–519. 

Google Scholar (http://scholar.google.com/scholar_lookup?title=“Predictive+state+representations:+a+new+the- 
ory+for+modeling+dynamical+systems,”&author=S.+Singh&author=M.+R.+James&author=M.+R.+Rudary&confer- 
ence=Proceedings+of+the+Twentieth+Conference+on+Uncertainty+in+Artificial+Intelligence+(UAI)&publica- 
tion_year=2004&pages=512–519) 

Steels, L. (2004). “The autotelic principle,” in Embodied Artificial Intelligence: International Seminar, Dagstuhl Castle, 
Germany, July 7–11, 2003. Revised Papers, ed F. Iida, R. Pfeifer, L. Steels, and Y. Kuniyoshi (Berlin, Heidelberg: Springer), 
231–242. 

Google Scholar (http://scholar.google.com/scholar_lookup?title=“The+autotelic+principle,”&author=L.+Steels&publica- 
tion_year=2004&pages=231–242) 

Sutton, R. S., and Barto, A. G. (1998). Reinforcement Learning. Cambridge, MA: MIT Press. 

Google Scholar (http://scholar.google.com/scholar_lookup?title=Reinforcement+Learning&author=R.+S.+Sutton&au- 
thor=A.+G.+Barto&publication_year=1998) 

Trendafilov, D., and Murray-Smith, R. (2013). “Information-theoretic characterization of uncertainty in manual control,” in 
2013 IEEE International Conference on Systems, Man, and Cybernetics (SMC), Manchester, 4913–4918. 

Google Scholar (http://scholar.google.com/scholar_lookup?title=“Information-theoretic+characterization+of+uncer- 
tainty+in+manual+control,”&author=D.+Trendafilov&author=R.+Murray-Smith&conference=2013+IEEE+Interna- 
tional+Conference+on+Systems,+Man,+and+Cybernetics+(SMC)&publication_year=2013&pages=4913–4918) 

von Foerster, H. (2003). Disorder/Order: Discovery or Invention? Understanding Understanding Book Subtitle Essays on 
Cybernetics and Cognition. New York: Springer, 273–282. 

Frontiers | Empowerment As Replacement for the Three Laws of Robotics | Robotics and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/full 

31 sur 33 21/07/2017 19:08 



Google Scholar (http://scholar.google.com/scholar_lookup?title=Disorder/Order:+Discovery+or+Invention?+Understand- 
ing+Understanding+Book+Subtitle+Essays+on+Cybernetics+and+Cognition&author=H.+von+Foerster&publica- 
tion_year=2003) 

von Uexküll, J. (1909). Umwelt und Innenwelt der Tiere. Berlin: Springer. 

Google Scholar (http://scholar.google.com/scholar_lookup?title=Umwelt+und+Innenwelt+der+Tiere&au- 
thor=J.+von+Uexküll&publication_year=1909) 

Wissner-Gross, A., and Freer, C. (2013). Causal entropic forces. Phys. Rev. Lett. 110, 168702. 
doi:10.1103/PhysRevLett.110.168702 

PubMed Abstract (http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&Cmd=ShowDetailView& 
TermToSearch=23679649) | CrossRef Full Text (https://doi.org/10.1103/PhysRevLett.110.168702) | Google Scholar 
(http://scholar.google.com/scholar_lookup?title=Causal+entropic+forces&author=A.+Wissner-Gross&author=C.+Freer& 
journal=Phys.+Rev.+Lett.&publication_year=2013&volume=110&pages=168702&doi=10.1103/PhysRevLett.110.168702& 
pmid=23679649) 

Ziemke, T., and Sharkey, N. E. (2001). A stroll through the world of robot and animals: apply Jakob von Uexküll’s theory 
of meaning to adaptive robot and artificial life. Semiotica 134, 701–746. doi:10.1515/semi.2001.050 

CrossRef Full Text (https://doi.org/10.1515/semi.2001.050) | Google Scholar (http://scholar.google.com/scholar_lookup?ti- 
tle=A+stroll+through+the+worlds+of+robots+and+animals:+applying+Jakob+von+Uexküll’s+theory+of+mean- 
ing+to+adaptive+robots+and+artificial+life&author=T.+Ziemke&author=N.+E.+Sharkey&journal=Semiotica&publica- 
tion_year=2001&volume=134&pages=701–746&doi=10.1515/semi.2001.050) 

Frontiers | Empowerment As Replacement for the Three Laws of Robotics | Robotics and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/full 

32 sur 33 21/07/2017 19:08 



Frontiers | Empowerment As Replacement for the Three Laws of Robotics | Robotics and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/full 

33 sur 33 21/07/2017 19:08 


