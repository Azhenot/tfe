






































Deception Detection in Videos | DARE 


Deception Detection in Videos | DARE 

We present a system for covert automate deception detection use 

information available in a video. We study the importance of different 

modality like vision, audio and text for this task. On the vision side, 

our system us classifier train on low level video feature which 

predict human micro-expressions. We show that prediction of high- 

level micro-expressions can be use a feature for deception 

prediction. Surprisingly, IDT (Improved Dense Trajectory) feature 

which have be widely use for action recognition, be also very good 

at predict deception in videos. We fuse the score of classifier train 

on IDT feature and high-level micro-expressions to improve 

performance. MFCC (Mel-frequency Cepstral Coefficients) feature 

from the audio domain also provide a significant boost in performance, 

while information from transcript be not very beneficial for our system. 

Using various classifiers, our automate system obtains an AUC of 

0.877 (10-fold cross-validation) when evaluate on subject which be 

not part of the training set. Even though state-of-the-art method use 

human annotation of micro-expressions for deception detection, our 

fully automate approach outperforms them by 5%. When combine 

with human annotation of micro-expressions, our AUC improves to 

0.922. We also present result of a user-study to analyze how well do 

average human perform on this task, what modality they use for 

deception detection and how they perform if only one modality be 

accessible. 

Paper 

Zhe Wu, Bharat Singh, Larry S. Davis, V. S. Subrahmanian 

Deception Detection in Videos 

in AAAI 2018 

Demo 

Try our demo! You can select a video and click load to see our 

prediction. Also check the prediction under different modalities! We 

Deception Detection in Videos | DARE https://doubaibai.github.io/DARE/ 

1 sur 3 11-01-18 à 10:55 



also show score for other video in the same validation split. 

Predictions of different micro-expressions be also presented. Thanks 

for Maksim Bolonkin’s help! 

Framework 

Experimental Results 

We evaluate our automate deception detection approach on a real-life 

deception detection database (Perez-Rosas et al. 2015). 

Deception Detection Results 

User Study 

To test human performance on this task, we perform two user study 

use AMT (Amazon Mechanical Turk). In one user study, subject be 

show only one modality (i.e. image, audio, transcripts) without access 

Deception Detection in Videos | DARE https://doubaibai.github.io/DARE/ 

2 sur 3 11-01-18 à 10:55 



to other modalities. In the other study, subject be ask to make a 

prediction for the whole video with access to all modalities. We also ask 

which modality contributes the most in their decision. 

The importance of modality in make decision (what human think). 

Human performance in deception detection use different modality 

be compare with our automate system and our system with Ground 

Truth micro-expressions. 

Deception Detection in Videos | DARE https://doubaibai.github.io/DARE/ 

3 sur 3 11-01-18 à 10:55 


