
















































1 



Why a right to explanation of automate decision-making do not exist in the General 

Data Protection Regulation 



Sandra Wachter,1,2 Brent Mittelstadt,2,3,1 Luciano Floridi1,2 




1Oxford Internet Institute, University of Oxford, 1 St Giles, Oxford, OX1 3JS, United 

Kingdom; 2The Alan Turing Institute, British Library, 96 Euston Rd, London, NW1 2DB, 

United Kingdom; 3Department of Science and Technology Studies, University College 

London, 22 Gordon Square, London, WC1E 6BT, United Kingdom. 



Correspondence: Sandra Wachter, sandra.wachter@oii.ox.ac.uk 





Abstract 

Since approval of the EU General Data Protection Regulation (GDPR) in 2016, it have be 

widely and repeatedly claimed that the GDPR will legally mandate a ‘right to explanation’ of 

all decision make by automate or artificially intelligent algorithmic systems. This right to 

explanation be view a an ideal mechanism to enhance the accountability and transparency 

of automate decision-making. However, there be several reason to doubt both the legal 

existence and the feasibility of such a right. In contrast to the right to explanation of specific 

automate decision claimed elsewhere, the GDPR only mandate that data subject receive 

meaningful, but properly limited, information (Articles 13-15) about the logic involved, a well 

a the significance and the envisage consequence of automate decision-making systems, 

what we term a ‘right to be informed’. Further, the ambiguity and limited scope of the ‘right 

not to be subject to automate decision-making’ contain in Article 22 (from which the 

allege ‘right to explanation’ stems) raise question over the protection actually afford to 

data subjects. These problem show that the GDPR lack precise language a well a explicit 

and well-defined right and safeguard against automate decision-making, and therefore run 

the risk of be toothless. We propose a number of legislative and policy step that, if taken, 

may improve the transparency and accountability of automate decision-making when the 

GDPR come into force in 2018. 



Keywords 

accountability; artificial intelligence; algorithms; automate decision-making; data protection; 

right to explanation; right of access; transparency. 









2 



Funding 

This study be fund by the Alan Turing Institute (Luciano Floridi and Sandra Wachter), the 

PETRAS IoT Hub - a EPSRC project (Sandra Wachter, Luciano Floridi and Brent Mittelstadt), 

and a research grant from the University of Oxford’s John Fell Fund (Brent Mittelstadt). 







3 



1 Introduction1 

In recent months, researchers,2 government bodies,3 and the media4 have claimed that a ‘right 

to explanation’ of decision make by automate and artificially intelligent algorithmic system 

be legally mandate by the forthcoming EU General Data Protection Regulation5 2016/679 





1 We be deeply indebted to Prof. Peggy Valcke, Prof. Massimo Durante, Prof. Ugo Pagallo, Dr. Natascha Scherzer 

and Mag. Priska Lueger for their invaluable comment and insightful feedback, from which the paper greatly 

benefitted. We want to especially thank Dr. Alessandro Spina whose intensive review and in-depth comment 

strengthen the argument in the paper. Further we be greatly thankful to Dr. Joris van Hoboken for the inspire 

conversation a well a write feedback on the draft that significantly improve the quality of the paper. Further 

we want to thank Prof. Tal Zarsky and Prof. Lee Bygrave not only for their pioneer and ground-breaking work 

that inspire this paper, but also their positive feedback, in-depth review and invaluable comments. Last but not 

least we want to thank the anonymous reviewer for the time spent reading and comment so thoroughly on the 

paper. 
2 See for example: Bryce Goodman and Seth Flaxman, ‘EU Regulations on Algorithmic Decision-Making and a 

“Right to Explanation”’ [2016] arXiv:1606.08813 [cs, stat] <http://arxiv.org/abs/1606.08813> access 30 June 

2016; Francesca Rossi, ‘Artificial Intelligence: Potential Benefits and Ethical Considerations’ (European 

Parliament: Policy Department C: Citizens’ Rights and Constitutional Affairs 2016) Briefing PE 571.380 

<http://www.europarl.europa.eu/RegData/etudes/BRIE/2016/571380/IPOL_BRI(2016)571380_EN.pdf>; 

Mireille Hildebrandt, ‘The New Imbroglio - Living with Machine Algorithms’, The Art of Ethics in the 

Information Society (2016) <https://works.bepress.com/mireille_hildebrandt/75/> access 28 December 2016; 

IEEE Global Initiative, ‘Ethically Aligned Designed - A Vision for Prioritizing Human Wellbeing with 

Artificial Intelligence and Autonomous Systems’ (IEEE 2016) Version 1 

<http://standards.ieee.org/develop/indconn/ec/ead_v1.pdf> access 19 January 2017; Ben Wagner, ‘Efficiency 

vs. Accountability? – Algorithms, Big Data and Public Administration’ <https://cihr.eu/efficiency-vs- 

accountability-algorithms-big-data-and-public-administration/> access 14 January 2017; Fusion, ‘EU 

Introduces “Right to Explanation” on Algorithms | Fusion’ (2016) <http://fusion.net/story/321178/european- 

union-right-to-algorithmic-explanation/> access 10 November 2016. quote Ryan Calo. 
3 See for example: Information Commissioner’s Office, ‘Overview of the General Data Protection Regulation 

(GDPR)’ (Information Commissioner’s Office 2016) 1.1.1 <https://ico.org.uk/for-organisations/data-protection- 

reform/overview-of-the-gdpr/individuals-rights/rights-related-to-automated-decision-making-and-profiling/> 

access 10 November 2016; House of Commons Science and Technology Committee, ‘Robotics and Artificial 

Intelligence’ (House of Commons 2016) HC 145 

<http://www.publications.parliament.uk/pa/cm201617/cmselect/cmsctech/145/145.pdf> access 10 November 

2016; European Parliament Committee on Legal Affairs, ‘Report with Recommendations to the Commission on 

Civil Law Rules on Robotics’ (European Parliament 2017) 2015/2103(INL) 

<http://www.europarl.europa.eu/sides/getDoc.do?pubRef=-//EP//NONSGML+REPORT+A8-2017- 

0005+0+DOC+PDF+V0//EN> access 11 November 2016. 
4 See for example: Joon Ian Wong, ‘The UK Could Become a Leader in AI Ethics—if This EU Data Law 

Survives Brexit’ <http://qz.com/807303/uk-parliament-ai-and-robotics-report-brexit-could-affect-eu-gdpr-right- 

to-explanation-law/> access 10 November 2016; Cade Metz, ‘Artificial Intelligence Is Setting Up the Internet 

for a Huge Clash With Europe’ (WIRED, 2016) <https://www.wired.com/2016/07/artificial-intelligence-setting- 

internet-huge-clash-europe/> access 10 November 2016; Fusion (n 2); Bernard Marr, ‘New Report: Revealing 

The Secrets Of AI Or Killing Machine Learning?’ <http://www.forbes.com/sites/bernardmarr/2017/01/12/new- 

report-revealing-the-secrets-of-ai-or-killing-machine-learning/#258189058e56> access 14 January 2017; 

Liisa Jaakonsaari, ‘Who Sets the Agenda on Algorithmic Accountability?’ (EURACTIV.com, 26 October 2016) 

<https://www.euractiv.com/section/digital/opinion/who-sets-the-agenda-on-algorithmic-accountability/> 

access 3 March 2017; Nick Wallace, ‘EU’s Right to Explanation: A Harmful Restriction on Artificial 

Intelligence’ <https://www.datainnovation.org/2017/01/eus-right-to-explanation-a-harmful-restriction-on- 

artificial-intelligence/> access 3 March 2017. 
5 REGULATION (EU) 2016/679 OF THE EUROPEAN PARLIAMENT AND OF THE COUNCIL of 27 

April 2016 on the protection of natural person with regard to the processing of personal data and on the 

free movement of such data, and repeal Directive 95/46/EC (General Data Protection Regulation) 2016. 







4 



(GDPR). The right to explanation be view a a promising mechanism in the broader pursuit 

by government and industry for accountability and transparency in algorithms, artificial 

intelligence, robotics, and other automate systems.6 Automated system can have many 

unintended and unexpected effects.7 Public assessment of the extent and source of these 

problem be often difficult,8 owe to the use of complex and opaque algorithmic mechanisms.9 

The allege right to explanation would require data controller to explain how such 

mechanism reach decisions. Significant hype have be mount over the empower effect 

of such a legally enforceable right for data subjects, and the disruption of data intensive 

industries, which would be force to explain how complex and perhaps inscrutable automate 

method work in practice. 

However, there be several reason to doubt the existence, scope, and feasibility of a 

‘right to explanation’ of automate decisions. In this paper, we examine the legal status of the 

‘right to explanation’ in the GDPR, and identify several barrier undermine it 

implementation. We argue that the GDPR do not, in it current form, implement a right to 

explanation, but rather what we term a limited ‘right to be informed’. Here be a quick overview. 

In Section 2, we disentangle the type and timing of explanation that can be offer of 

automate decision-making. The right to explanation, a popularly proposed, be thought to grant 

an explanation of specific automate decisions, after such a decision have be made.10 





6 The proliferation of unaccountable and inscrutable automate system have proven a major concern among 

government bodies, a reflect in numerous recent report on the future ethical and social impact of automate 

systems. See for instance: Catherine Stupp, ‘Commission to Open Probe into Tech Companies’ Algorithms next 

Year’ (EurActiv.com, 8 November 2016) <http://www.euractiv.com/section/digital/news/commission-to-open- 

probe-into-tech-companies-algorithms-next-year/> access 11 November 2016; Partnership on AI, ‘Partnership 

on Artificial Intelligence to Benefit People and Society’ (Partnership on Artificial Intelligence to Benefit People 

and Society, 2016) <https://www.partnershiponai.org/> access 11 November 2016; National Science and 

Technology Council, ‘Preparing for the Future of Artificial Intelligence’ (Executive Office of the President 

2016) 

<https://www.whitehouse.gov/sites/default/files/whitehouse_files/microsites/ostp/NSTC/preparing_for_the_futu 

re_of_ai.pdf> access 11 November 2016; European Parliament Committee on Legal Affairs (n 3); House of 

Commons Science and Technology Committee (n 3); Government Office for Science, ‘Artificial Intelligence: 

An Overview for Policy-Makers’ (Government Office for Science 2016) 

<https://www.gov.uk/government/publications/artificial-intelligence-an-overview-for-policy-makers> access 

11 November 2016. 
7 Brent Mittelstadt and others, ‘The Ethics of Algorithms: Mapping the Debate’ [2016] 3 Big Data & Society 2. 
8 Christian Sandvig and others, ‘Auditing Algorithms: Research Methods for Detecting Discrimination on 

Internet Platforms’ [2014] Data and Discrimination: Converting Critical Concerns into Productive Inquiry 

<http://social.cs.uiuc.edu/papers/pdfs/ICA2014-Sandvig.pdf> access 13 February 2016. 
9 Mike Ananny, ‘Toward an Ethics of Algorithms Convening, Observation, Probability, and Timeliness’ (2016) 

41 Science, Technology & Human Values 93. 
10 This be the type of explanation of automate decision-making imagine in Recital 71 GDPR, which state “In 

any case, such processing should be subject to suitable safeguards, which should include specific information to 







5 



In Section 3, we ass three possible legal base for a right to explanation in the GDPR: 

1) the right not to be subject to automate decision-making and safeguard enact thereof 

(Article 22 and Recital 71); 

2) notification duty of data controller (Articles 13-14 and Recitals 60-62); and 

3) the right to access (Article 15 and Recital 63). 

The aforementioned claim for a right to explanation11 muddle the first and second legal bases. 

It conflates (1) legally binding requirement of Article 22 and non-binding provision of Recital 

71 and (2) notification duty (Articles 13-14) that require data subject to be provide with 

information about “the existence of automate decision-making, include profiling, refer 

to in Article 22(1) and (4) and, at least in those cases, meaningful information about the logic 

involved, a well a the significance and the envisage consequence of such processing for the 

data subject” [italics added]. 

Having challenged the legal basis for a right to explanation, we then consider whether 

the right of access in Article 15 provide a strong legal basis. Following our analysis of the 

implementation and jurisprudence of the 1995 Data Protection Directive (95/46/EC), we argue 

that the GDPR’s right of access allows for a limited right to explanation of the functionality of 

automate decision-making system – what we refer to a the ‘right to be informed’. However, 

the right of access do not establish a right to explanation of specific automate decision of 

the type currently imagine elsewhere in public discourse. Not only be a right to explanation of 

specific decision not grant by the GDPR, it also appear to have be intentionally not 

adopt in the final text of the GDPR after appear in an early draft. 

In Section 4, we consider the limitation of scope and applicability, if a right to 

explanation be to exist. We show that a ‘general’ right to explanation, applicable to all 

automate decisions, would not exist even if Recital 71 be legally binding. A right to 

explanation, derive from the right of access (Article 15) or safeguard described in Article 

22(3), would only apply to a narrow range of decision “solely base on automate processing” 

and with “legal” or “similarly significant” effect for the data subject (Article 22(1) GDPR). 

We examine the limited case in which the right would apply, include the impact of a critical 





the data subject and the right to obtain human intervention, to express his or her point of view, to obtain an 

explanation of the decision reach after such assessment and to challenge the decision.” 
11 Goodman and Flaxman (n 2). 







6 



ambiguity of language that allows the broader “right not to be subject to automate decision- 

making” (Article 22 GDPR) to be interpret either a a prohibition, or right to object. 

Section 5 concludes the article with recommendation for a number of legislative and 

policy step that, if implemented, may improve the transparency and accountability of 

automate decision-making when the GDPR come into force in 2018. 

2 What be meant by a right to explanation? 

Before examine whether the GDPR specifies a right to explanation, it be necessary to examine 

what one may mean by an ‘explanation’ of automate decision-making. Two kind of 

explanation may be in question, depend on whether one refers to: 

● system functionality, that is, the logic, significance, envisage consequence and 

general functionality of an automate decision-making system, e.g. the system’s 

requirement specification, decision trees, pre-defined models, criteria, and 

classification structures; or to 

● specific decisions, that is, the rationale, reasons, and individual circumstance of a 

specific automate decision, e.g. the weight of features, machine-defined case- 

specific decision rules, information about reference or profile groups.12 

Furthermore, one can also distinguish between explanation in term of their timing in relation 

to the decision-making process: 

 an ex ante explanation occurs prior to an automate decision-making take place. Note 

that an ex ante explanation can logically address only system functionality, a the 

rationale of a specific decision cannot be know before the decision be made; 

 an ex post explanation occurs after an automate decision have take place. Note that an 

ex post explanation can address both system functionality and the rationale of a specific 

decision. 

An example may help clarify how these distinction interact. Take an automate credit score 

system. Prior to a decision be make (ex ante), the system provider can inform the data 

subject about the system functionality, include the general logic (such a type of data and 

feature considered, category in the decision tree), purpose or significance (in this case, to 





12 This be specifically a kind of explanation possible only once a decision have be taken. It refers to a particular 

decision, not the decision-making method or system itself. This be the type of explanation imagine in Recital 71 

GDPR, which call for “an explanation of the decision reach after such assessment.” The Recital explicitly 

refers to a singular decision that have be reached. 







7 



assign a credit score), and envisage consequence (for example, the credit score can be use 

by lender to ass credit worthiness, affect the term of credit such a interest rate). After 

a decision have be make (ex post), an explanation of system functionality can still be provide 

to the data subject. However, the provider can also explain to the data subject the logic and 

individual circumstance of their specific decision, such a her credit score, the data or feature 

that be consider in her particular case, and their weight within the decision tree or 

model. In other words, the provider can explain how a particular score be assigned. Further, 

when pre-defined simplistic or linear model be use and fully disclosed, prediction about 

the rationale of a specific decision be possible in principle ex ante. However, in both case the 

provider’s ability to offer an explanation of the rationale of a specific decision may be limited 

by several legal (see Section 4) and technical factors, include the use of complex probabilistic 

analytics and decision-making methods.13 

These distinction between two kind and two different timing of explanation be 

implicit in the GDPR. Their importance will be highlight a we examine the possible legal 

base for a right to explanation. 



3 Why there be no ‘right to explanation’ in the GDPR 

Three distinct possible legal base for a right to explanation of automate decision-making can 

be found in the GDPR. A right to explanation can possibly be derive from: 

1) safeguard against automate decision-making a require under Article 22(3), and 

comment upon by Recital 71; 

2) notification duty under Articles 13-14 comment upon by Recitals 60-62; or 

3) the right of access under Article 15, and comment upon by Recital 63. 

These base be respectively refer to a a right to explanation derive from (1) safeguards, 

(2) notification duties, and (3) the right of access. We will ass each in turn. On the whole, 

the claim that a right be grant by the GDPR to an ex post explanation of specific decision (at 

a minimum) that seemingly applies to any instance of automate decision-making be base on 

a combination of safeguard and notification duties. It combine non-binding Recital 71 with 

binding provision of Articles 13-14 and 22 to argue that “The law will […] effectively create 





13 Jenna Burrell, ‘How the Machine “Thinks:” Understanding Opacity in Machine Learning Algorithms’ [2016] 

Big Data & Society. 







8 



a “right to explanation,” whereby a user can ask for an explanation of an algorithmic decision 

that be make about them.”14 This claim be incorrect for several reasons, explain below. 

3.1 A right to explanation derive from safeguard against automate decision-making 

Starting with the claim15 for a right to explanation derive from safeguards, Article 22 (see: 

Figure 1) and Recital 71 of the GDPR address a data subject’s right not to be subject to 

automate decision-making. Article 22(3), which address safeguard against automate 

decision-making, state that 

the data controller shall implement suitable measure to safeguard the data subject's 

right and freedom and legitimate interests, at least the right to obtain human 

intervention on the part of the controller, to express his or her point of view and to 

contest the decision [italics added]. 



Critically, a right to explanation be not mentioned. Rather, after a decision have be made, and 

assume the decision meet a condition specify in Article 22(3)a (to enter or fulfil a contract) 

or Article 22(3)c (with explicit consent), data subject be grant additional safeguard to 

obtain human intervention, express views, or contest a decision (Article 22(3)), but not to 

obtain an explanation of the decision reached. 









14 Goodman and Flaxman (n 2). The ‘right to explanation be propose a follows. On p. 1: “The law will also 

effectively create a “right to explanation,” whereby a user can ask for an explanation of an algorithmic decision 

that be make about them.” Further, on p. 3: “Paragraph 71 of the recital (the preamble to the GDPR, which 

explains the rationale behind it but be not itself law) explicitly require data controller to “implement appropriate 

technical and organizational measures” that “prevents, inter alia, discriminatory effects” on the basis of processing 

sensitive data.” Further, on p. 6: “The provision outline in Articles 13-15 specify that data subject have the 

right to access information collect about them, and also require data processor to ensure data subject be 

notify about the data collected. However, it be important to distinguish between these rights, which may be 

term the right to access and notification, and additional “safeguards for the right and freedom of the data 

subject” require under Article 22 when profile take place. Although the Article do not elaborate what these 

safeguard be beyond “the right to obtain human intervention”, Articles 13 and 14 state that, when profile take 

place, a data subject have the right to “meaningful information about the logic involved.” This requirement prompt 

the question: what do it mean, and what be required, to explain an algorithm’s decision?” 
15 ibid; Rossi (n 2). 







9 





In all of the GDPR, a right to explanation be only explicitly mention in Recital 71, which 

state that a person who have be subject to automate decision-making 

should be subject to suitable safeguards, which should include specific information to 

the data subject and the right to obtain human intervention, to express his or her point 

of view, to obtain an explanation of the decision reach after such assessment and to 

challenge the decision [italics added]. 



If legally binding, this provision would require an ex post explanation of specific decisions, a 

Recital 71 address safeguard to be in place once a decision have be reached. To show why 

Recital 71 do not establish a legally binding right, a brief aside into the legal status of Recitals 

be required. 







10 



Recitals provide guidance16 on how to interpret the Articles, but be not themselves 

legally binding.17 As Klimas and Vaiciukaite explain, “Recitals have no positive operation of 

their own” and “cannot cause legitimate expectation to arise.”18 Baratta further expands: 

In principle the ECJ do not give effect to recital that be draft in normative terms. 

Recitals can help to explain the purpose and intent behind a normative instrument. They 

can also be take into account to resolve ambiguity in the legislative provision to 

which they relate, but they do not have any autonomous legal effect.19 


Jurisprudence of the European Court of Justice (ECJ) show that the role of Recitals be to 

dissolve ambiguity in the operative text of a framework. The ECJ have comment directly on 

the legal status of Recitals, clarify that: “Whilst a recital in the preamble to a regulation may 

cast light on the interpretation to be give to a legal rule, it cannot in itself constitute such a 

rule.”20 

Returning to the GDPR, Article 22(3) list the minimum requirement that have to be 

met for lawful automate decision-making. There be no ambiguity in the language that would 

require further interpretation with regard to the minimum requirement that must be met by 

data controllers. As long a these requirement be met, automate decision-making be lawful 

and in compliance with the GDPR. With this said, future jurisprudence (see Section 4) can still 

interpret the meaning of “suitable measure to safeguard,” and establish future mandatory or 

case-to-case requirement to be met by data controllers, include a right to explanation. This 

is, however, only one possible future. A right to explanation be thus not currently legally 

mandate by the requirement set in Article 22(3). 





16“Recitals explain the background to the legislation and the aim and objective of the legislation. They are, 

therefore, important to an understand of the legislation which follows.” EUROPA, ‘Guide to the 

Approximation of EU Environmental Legislation ANNEX I’ (Environment, 2015) 

<http://ec.europa.eu/environment/archives/guide/annex1.htm> access 3 March 2017. See also Judgement of 15 

5 1997 - Case C-355/95 P Textilwerke Deggendorf GmbH (TWD) v Commission of the European Communities 

and Federal Republic of Germany [1997] European Court of Justice C-355/95 P [21]: “In that regard, it should 

be state that the operative part of an act be indissociably link to the statement of reason for it, so that, when it 

have to be interpreted, account must be take of the reason which lead to it adoption.” 
17 For a detailed overview of the jurisprudence of the European Court of Justice on the limited role of Recitals in 

EU law see Roberto Baratta, ‘Complexity of EU Law in the Domestic Implementing Process’ (2014) 2 The Theory 

and Practice of Legislation 293. An oppose view be offer by Pagallo, who claim that secondary rule of law 

(e.g. Recitals) can alter primary rule of law. Ugo Pagallo, ‘Three Lessons Learned for Intelligent Transport 

Systems That Abide by the Law’ (2016) November 2016 Jusletter IT RZ 13 <http://jusletter- 

it.weblaw.ch/issues/2016/24-November-2016/three-lessons-learne_9251e5d324.html>. 
18 Tadas Klimas and Jurate Vaiciukaite, ‘The Law of Recitals in European Community Legislation’ (2008) 15 

ILSA Journal of International & Comparative Law 32–3 

<https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1159604> access 22 January 2017. The paper discus 

in detail the legal status of Recitals in European law. 
19 Baratta (n 17) 17. 
20 Case 215/88 Casa Fleischhandels [1989] European Court of Justice ECR 2789 [31]; See also Baratta (n 17) 13. 







11 



In addition, right have to be explicitly legally establish prior to their enforcement. 

This idea stem from the relationship between legal right and duties. The scope of a right can 

be subject to interpretation; a legal basis for it existence must, however, first be beyond doubt. 

Rights of data subject typically correspond with a duty on the side of the data controller.21 

Negligence in relation to legal duty can be punish through fine and other procedures. It 

would be highly controversial to impose fine on data controller without have previously 

clarify explicitly and beyond doubt what duty must be met. Doing otherwise would conflict 

with the principle of fair trial (Article 6 of the European Convention on Human Rights and 

Article 47 of the Charter of Fundamental Rights of the European Union) and the rule of law.22 

Criminal and administrative procedure have to be laid down precisely. 

It can be conclude that data subject will not be grant a legally binding ex post right 

to explanation of specific automate decision on the basis of legal safeguard in Article 22 a 

it currently stands. That this be the case do not appear to be the result of an oversight or 

fiddle with subtle interpretation (e.g. the meaning of “suitable measure to safeguard” in 

Article 22(3)). On the contrary, the omission of a right to explanation from Article 22 appear 

to be intentional. The safeguard specify in Recital 71 be almost identical to those in Article 

22(3), with the significant difference of the further inclusion of a right “to obtain an explanation 

of the decision reach after such assessment” in Recital 71. The purposeful omission of this 

text from Article 22 may not be an oversight but suggests that legislator do not intend to 

implement a right to explanation of specific decision in the GDPR. What happened? 

Looking at previous draft of the GDPR and commentary from the trilogue 

negotiations,23 one can see that legislator have stricter safeguard in place on automate 

decision-making and profiling, but that these be eventually dropped, include a legally 

binding right to explanation of specific decisions.24 An early indication of the debate around 





21 Peter Jones, ‘Group Rights’, The Stanford Encyclopedia of Philosophy (Summer 2016 Edition (forthcoming), 

2016) <http://plato.stanford.edu/archives/sum2016/entries/rights-group/>. 
22 

Christoph Grabenwarter, The European Convention for the Protection of Human Rights and Fundamental 

Freedoms: A Commentary (01 edition, Beck/Hart Publishing 2014). 
23 The ‘trilogue negotiations’ describe a series of meeting between the European Commission, Council and 

Parliament to adopt a final text for the GDPR. For an introduction and discussion of the legal basis of trilogue, 

see: Oliver Proust, ‘Unravelling the Mysteries of the GDPR Trilogues’ (Privacy, Security and Information Law, 

2015) <http://privacylawblog.fieldfisher.com/2015/unravelling-the-mysteries-of-the-gdpr-trilogues/> access 

16 December 2016. 
24 Rita Heimes, ‘Top 10 Operational Impacts of the GDPR: Part 5 - Profiling’ <https://iapp.org/news/a/top-10- 

operational-impacts-of-the-gdpr-part-5-profiling/> access 10 November 2016: “A hotly contest provision of 

the GDPR, the “profiling” restriction ultimately adopt be narrower than initially proposed.” 







12 



the right to explanation can be see in the November 2013 report of the European Parliament25 

(EP) and the December 2014 report of the European Council in response to the original GDPR 

text propose by the European Commission26 (EC) in 2012. 

The EC’s propose text do not contain a right to explanation. The EP propose the 

follow amendment to Article 20 (now Article 22 in the adopt version of the GDPR), 

paragraph 5: 

Profiling which lead to measure produce legal effect concern the data subject 

or do similarly significantly affect the interests, right or freedom of the concerned 

data subject shall not be base solely or predominantly on automate processing and 

shall include human assessment, include an explanation of the decision reach after 

such an assessment. The suitable measure to safeguard the data subject's legitimate 

interest refer to in paragraph 2 shall include the right to obtain human assessment 

and an explanation of the decision reach after such assessment […] [italics added]. 


The EP’s prefer text mandate a “right to obtain human assessment and an explanation of 

the decision reach after such assessment.” These safeguard would have be part of Article 

20, meaning that they would have be legally binding. However, the propose safeguard 

be not adopt in trilogue. This change suggests that legislator intentionally chose to make 

the right to explanation non-binding by place it in Recital 71. 

The European Council’s 2014 draft,27 on the other hand, only require that 

the data controller shall implement suitable measure to safeguard the data subject’s 

right and freedom and legitimate interests, such a the right to obtain human 

intervention on the part of the controller, to express his or her point of view and to 

contest the decision [italics added]. 



The Council suggest to add the text: 





25 European Parliament Committee on Civil Liberties, Justice and Home Affairs, ‘Report on the Proposal for a 

Regulation of the European Parliament and of the Council on the Protection of Individuals with Regard to the 

Processing of Personal Data and on the Free Movement of Such Data (General Data Protection Regulation) - 

A7-0402/2013’ (European Parliament 2013) A7–0402/2013 

<http://www.europarl.europa.eu/sides/getDoc.do?type=REPORT&reference=A7-2013-0402&language=EN> 

access 10 November 2016. 
26 European Commission, ‘Regulation of the European Parliament and the Council on the Protection of 

Individuals with Regard to the Processing of Personal Data and on the Free Movement of Such Data (General 

Data Protection Regulation)’ (European Commission 2012) 2012/0011 (COD) <http://ec.europa.eu/justice/data- 

protection/document/review2012/com_2012_11_en.pdf> access 10 November 2016. 
27 European Digital Rights, ‘Comparison of the Parliament and Council Text on the General Data Protection 

Regulation’ (European Digital Rights International 2016) 140 

<https://edri.org/files/EP_Council_Comparison.pdf> access 20 November 2016. This source provide a side- 

by-side comparison of the aforementioned draft from the European Parliament (n 25) and European Commission 

(n 26), a well a amendment to the Commission’s text propose by the European Council. 







13 



to express his or her point of view, to get an explanation of the decision reach after 

such assessment and the right to contest the decision [italics added], 



to Recital 58 (equivalent to Recital 71 GDPR).28 The Council thus suggest to place the right 

to explanation add in the EP’s draft in a Recital. This approach be eventually take in the 

final text adopt in 2016. 

Interestingly, despite year of negotiations, the final word of the GDPR concern 

protection against profile and automate decision-making hardly change from the relevant 

Articles and Recitals of the Data Protection Directive 1995. As with the GDPR, a ‘right to 

explanation’ do not appear in Article 15 of the Directive (see Figure 2), which address 

automate individual decisions. 

Although Article 22 GDPR have not greatly change from Article 15 of the Directive, a 

few change be still noteworthy. First, the only safeguard against automate decision-making 

mention in the Directive be the opportunity to express one’s views. Article 22(3) additionally 

name contest the decision and the right to obtain human intervention a suitable measures. 

Secondly, explicit consent be include a a case in which automate decision-making be allow 

(Article 22(2)c). Finally, a oppose to the provision in Article 15 of the Directive, it be no 

longer necessary that the data subject request the contract in order for automate decision- 

make to be lawful. 





28 European Digital Rights (n 27) 40. 







14 





3.2 A right to explanation derive from notification duty 

Articles 13 and 14 GDPR specify notification duty for data controller concern the 

processing of data collect from the data subject (Article 13) or from a third party (Article 

14). In the aforementioned claim, these Articles be cite a a basis for a right to an ex post 

explanation of specific decisions. The claim start with Articles 13(2) and 14(2), which state 

that data controller need to 

provide the data subject with the follow information necessary to ensure fair and 

transparent processing. 



According to Article 13(2)f and Article 14(2)g, this information include 

the existence of automate decision-making, include profiling, refer to in Article 

22(1) and (4) and, at least in those cases, meaningful information about the logic 

involved, a well a the significance and the envisage consequence of such processing 

for the data subject [italics added]. 



This duty applies in case of automate processing meeting the requirement of Article 22(1) 

or 22(4) (more on this later). 

It have be suggest that the notification duty in Articles 13-14, in combination with 

the safeguard define in Article 22(3), grant an ex post right to explanation of the “existence 







15 



of […] logic involve […] significance […] and envisage consequences” of automate 

decision-making.29 This claim be mistaken for two reasons. 

First, only an ex ante explanation of system functionality be explicitly require by 

Articles 13(2)f and 14(2)g. These notification duty precede decision-making. Notification 

occurs before a decision be made, at the point when data be collect for processing. This hold 

true even if Article 14 introduces some ambiguity when data be collect from third party 

rather than data subject (insofar a the controller need only to notify the data subject within 

30 day of collection). As explain in Section 2, only an explanation of system functionality 

be logically possible prior to decision-making. Therefore Articles 13-14 cannot be use a 

evidence of an ex post right to explanation of specific decision that can logically only be give 

once a decision have be make (timeline problem).30 

Secondly, the claim link Articles 13(2)f and 14(2)g to the safeguard in Article 22(3). 

This link be not make in the GDPR. Articles 13(2)f and 14(2)g apply only to Article 22(1) and 

Article 22(4), which do not address safeguard against automate decision-making. The 

suppose link – between notification about the logic involved, significance and envisage 

consequence of automate decision-making in Articles 13-14, and the ex post right to 

explanation incorrectly attribute to Article 22(3) (which only feature in Recital 71) – be 

therefore untenable and can be dismissed. The claim also conflates the legally binding 

notification duties, specify in Articles 13-14, and the non-binding right, specify in Recital 

71. 

It follow that the claim for an ex post right to explanation of specific decisions31 be not 

correct. Any suggestion to the contrary fails to distinguish between (1) the legally binding duty 

to notify the data subject of the logic involved, significance and envisage consequence of 

automate decision-making system before decision-making occurs (timeline problem) 





29 Goodman and Flaxman (n 2). 
30 See also Suzanne Rodway, ‘Just How Fair Will Processing Notices Need to Be under the GDPR’ (2016) 16 

Privacy & Data Protection 16. Note the paper focus on the EC draft but talk in general about the aim and 

purpose of notification duties. The author explains that these provision mainly mean that data controller have to 

update their privacy notices. Further: “whether any automate decision will be make use the data (including 

for profile purposes) and, if so, a meaningful explanation about the logic use in those decision and the possible 

consequence of those decision for the data subject. Examples include whether a credit card application might 

be decline or a job application rejected.” This suggests that Articles 13-14 only create a notification duty to 

inform about the general usage of automate decision-making before a decision have be made, and to inform 

about the possible future consequences. Further support for this argument can be found in Recitals 60-62 GDPR. 
31 Goodman and Flaxman (n 2). 







16 



(Articles 13-14), and (2) the data subject’s non-binding right to an explanation of specific 

decision (Recital 71) after decision-making occurs. 

The language use in Articles 13(2)f and 14(2)g also support the interpretation that 

only an ex ante explanation be required. Data controller must inform the data subject about the 

existence of automate decision-making, include profile […] [and provide data 

subject with] meaningful information about the logic involved, a well a the 

significance and the envisage consequence of such processing. 



The language use suggests that data subject must be provide with information about how 

an automate decision-making system work in general, for which purposes, and with what 

predict impact, before automate decision be made. Notably this cannot include any 

information about how a specific decision be make or reached, but rather address how the 

system itself functions, e.g. it decision tree or rules, or prediction about how input will be 

processed. For fully disclose simplistic or linear models, this may show how specific decision 

would be reach in the future.32 

3.3 A right to explanation derive from the right of access 

In contrast to prior claim (see Section 1), it may also be possible to derive a right to explanation 

from the right of access establish in Article 15 GDPR. Article 15(1)h be identical to Articles 

13(2)f and 14(2)h: data subject be grant a right to be inform about the existence of 

automate decision-making and to obtain meaningful information about the significance, 

envisage consequences, and logic involved. Specifically, the subject should be inform about 

the existence, purposes, and logic of data processing, and the intention and legal consequence 

of such processing. By have this information, the data subject should be able to examine the 

lawfulness of data processing and invoke legal remedies.33 

Together, Articles 13-15 form what have be call the ‘Magna Carta’ of data subject’s 

right to obtain information about the data held about them, and to scrutinise the legitimacy of 

data processing.34 Articles 13-14 create notification duty for data controllers, while Article 





32 Burrell (n 13). 
33 Boris P. Paal, ‘DS-GVO Art. 15 Auskunftsrecht der betroffenen Person’ in Paal and Pauly (eds), Datenschutz- 

Grundverordnung (1st edn, beck-online 2017) Rn. 3. Recital 63 GDPR also support this interpretation in state 

that “A data subject should have the right of access to personal data […] and to exercise that right […] in order 

to be aware of, and verify, the lawfulness of processing” [italics added]. 
34 Florian Schmidt-Wudy, ‘DS-GVO Art. 15 Auskunftsrecht der betroffenen Person’ in Wolff and Brink (eds), 

Datenschutz-Grundverordnung (18th edn, beck-online 2016) Rn. 2. 







17 



15 establishes a correspond right of access for data subjects.35 In contrast to the notification 

duty of data controller in Articles 13-14, the right of access have to be invoked by the data 

subject. The article be a unit, insofar a they provide the data subject access to identical 

information, and use the same language. 

Although seemingly insignificant, the change from a notification duty to an access right 

have important consequence for the timing of explanation require from the data controller. 

Given that the phrasing of Article 15(1)h be identical to Articles 13(2)f and 14 (2)g, one could 

assume that the right of access similarly only grant access to an ex ante explanation of system 

functionality. However, the right of access be dependent upon the request of the data subject 

and have no deadline; the ‘timeline problem’ of Articles 13(2)f and 14(2)g do not apply. At 

first glance, the data subject can request this information at any time, include after an 

automate decision have be made, make an ex post explanation of the rationale of specific 

decision plausible. 

Nonetheless, it be reasonable to doubt that the right of access grant a right to ex post 

explanation of specific decision already reached. Consider the semantics of Article 15(1)h. 

The phrase “envisaged consequences” be future-oriented, suggest that the data controller 

must inform the data subject of possible consequence of the automate decision-making 

before such processing occurs. This interpretation follow the timeline constraint of identical 

provision in Articles 13(2)f and 14(2)g discuss above, which only allow for ex ante 

explanations. Data controller be require to predict the possible consequence of their 

automate decision-making methods. The term “envisaged” limit these prediction to ex ante 

explanation of system functionality, for instance concern the general purpose of the system, 

or the type of impact to be expect from the type of decision it makes. For instance, a credit 

agency could predict that the score they produce will impact on credit worthiness (e.g. interest 

rates). If apply to decision already made, the phrasing becomes incoherent.36 It would seem 





35 Mario Martini, ‘DS-GVO Art. 22 Automatisierte Entscheidungen im Einzelfall einschließlich Profiling’ in Paal 

and Pauly (eds), Datenschutz-Grundverordnung (1st edn, beck-online 2017) Rn. 4-6. 
36 Peter Bräutigam and Florian Schmidt-Wudy, ‘Das geplante Auskunfts- und Herausgaberecht de Betroffenen 

nach Art. 15 Der EU-Datenschutzgrundverordnung’ (2015) 31 Computer und Recht 56, 62 support this 

interpretation in comment on the EP’s draft of the GDPR. The EP’s draft contains the same phrasing a the 

final adopt text: Article 15(h) require information about “the significance and envisage consequence of such 

processing.” The author note that the phrasing be very imprecise. An example be give of an Internet provider 

be obligate to inform that automate processing method be be use to determine creditworthiness, which 

could lead to the consequence that the person have to pay in advance (rather than be offer credit). This example 

suggests that the author believe that Article 15(h) aim to inform about system functionality rather than to provide 

information about how an individual decision be reached. 







18 



to require data controller to predict the personal consequence of decision-making for 

individual data subject after an automate decision have be made, include how the decision 

could be use by other data controller and processors. 

The semantics of the German translation of Article 15(1)h GDPR provide further 

support. The German Article 15(1)h states: 

Tragweite und angestrebten Auswirkungen einer derartigen Verarbeitung für die 

betroffene Person [italics added]. 



This sentence translates to “the scope and intend consequence of such processing for the 

person concerned” [our translation, italic added]. This indicates that the data controller must 

inform the data subject about the consequence the controller wish to achieve with automate 

decision-making. According to this phrasing, the data controller be not ask to predict 

consequence but rather explain the scope, intention, and the purpose of such processing. This 

suggests that the right of access be not address how an individual decision be reached, but 

rather the duty of the data controller to provide information about the existence, aim and 

consequence of such processing. This equates to an explanation of system functionality.37 

There be similar reason to doubt that Article 15(1)h grant an ex post right to 

explanation of specific decisions. Data controller be require to provide information about 

the “existence of automate decision-making” [italics added]. This phrase do not suggest an 

explanation of how a decision be reached. Rather, the data controller be only require to 

inform the data subject that automate decision-making method be be use to process her 

data. 

The phrasing of Article 15(1)h, a with Articles 13-14, point to an explanation of 

system functionality. However, data controller be also require to provide “meaningful 

information about the logic involved” in automate decision-making. As note in Section 3.2, 

this phrase, a use in Articles 13-14, have be argue by others to grant an ex post right to 

explanation. If correct, Article 15(1)h would grant a right to explanation of specific decisions, 

not only system functionality, a the data subject can request the relevant information both 





37 Prior draft of Article 15 also support this view. The German translation of the EC draft state in Article 15(h) 

“die Tragweite der Verarbeitung und die mit ihr angestrebten Auswirkungen, zumindest im Fall der Maßnahmen 

gemäß Artikel 20,” which translates to “the scope [rather than significance] of the data processing and it intend 

consequences.” In addition, the EP draft state in Article 15(h) “die Tragweite der Verarbeitung und die mit ihr 

angestrebten Wirkungen.” The phrase “angestrebten Wirkungen” translates to “the scope and it intend effects,” 

not consequences. Even though the adopt language in the GDPR be vaguer, prior draft demonstrate Article 15 

be intend to inform data subject about data processor’s “intended effects” for the data subject by use 

automate decision-making methods. For further discussion, see: ibid 61 ff. 







19 



before and after a decision have be made. However, there be further reason to doubt that this 

be the case. 

For Article 15(1)h to be coherent a a whole, “meaningful information about the logic 

involved” must be interpret in connection with the other term (existence of, meaningful 

information about significance and envisage consequences) use of Article 15(1)h, which be 

limited to explanation of system functionality. Interpreting “logic involved” to grant an ex 

post explanation of specific decision would mean the other term of Article 15(1)h would be 

incoherent, if the right of access be invoked after a decision be made. This interpretation be 

further support by a comparison of the language use in Article 15(1)h and Recital 71. Data 

controller be obligate to provide information about the 

existence of automate decision-making […] meaningful information about the logic 

involved, a well a the significance and the envisage consequence of such processing 

(Article 15(1)h), [as oppose to] an explanation of the decision reach (Recital 71). 



The phrasing of Article 15(1)h be future-oriented, and appear to refer to the existence and 

plan scope of decision-making itself, rather than to the circumstance of a specific decision 

a suggest in Recital 71. If an explanation of specific automate decision be intend to 

be grant by Article 15(1)h, a in Recital 71, the usage of different language between the two 

would be odd. 

Nevertheless, give the lack of an explicit deadline for invoke the right of access, one 

cannot be certain, on the basis of semantics alone, that the right of access be limited to 

explanation of system functionality. Despite this, we argue that, a with notification duty in 

Articles 13-14, and regardless of when it be invoked by the data subject, the GDPR’s right of 

access only grant an explanation of automate decision-making address system 

functionality, not the rationale and circumstance of specific decisions. This conclusion be 

support by implementation of the 1995 Directive’s right of access by Member States, which 

have mostly limited informational obligation to system functionality. If interpretation of the 

GDPR follow historical precedence, it right of access will be similarly limited. To articulate 

this claim further, it be necessary to examine in detail Member State implementation and 

interpretation of the Directive’s right of access. 

3.3.1 Right of access in the 1995 Data Protection Directive 95/46/EC 

It be important to note that a right of access that grant data subject some explanation of 

automate decision-making be not new, and have not proven an effective transparency 







20 



mechanism.38 Rather, this right have exist since the 1995 Data Protection Directive, and have 

be implement in national law by most European Member States.39 Similar to the scope of 

the GDPR’s right of access, the Directive’s right of access provide mean for data subject to 

discover whether a controller be processing personal data. If so, the data subject be then entitle 

to know the extent of data be processed. This shall enable the data subject to scrutinise what 

data be use and take appropriate action such a request rectification or erasure.40 Notably, 

the Directive’s right of access have generally not be interpret a grant a right to 

explanation of specific decision already reached, a it be not part of the safeguard at the time 

automate decision be make in Article 15(2)a of the Directive; this distinction be comparable 

to the difference between Articles 15 and 22 of the GDPR. The Directive name only one 

safeguard against automate decision-making, namely the right for the data subject to “put his 

point of view.” A right to explanation of specific decision a a safeguard to ensure lawful 

automate decision-making be not envisaged. 

The implementation and interpretation of the Directive’s right of access varied across 

the Member States. Despite much debate,41 consensus have not emerge concern the type of 

information data controller must disclose to provide data subject with “knowledge of the 

logic involve in any automatic processing of data” per Article 12(a).42 A report publish in 





38 C-141/12 and C-372/12 [2014] European Court of Justice ECLI:EU:C:2014:2081. 
39 Douwe Korff, ‘New Challenges to Data Protection Study - Working Paper No. 2: Data Protection Laws in the 

EU: The Difficulties in Meeting the Challenges Posed by Global Social and Technical Developments’ (European 

Commission DG Justice, Freedom and Security 2010) 

<http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1638949> access 8 December 2016. 
40 See Recital 41 of the Directive “Whereas any person must be able to exercise the right of access to data relate 

to him which be be processed, in order to verify in particular the accuracy of the data and the lawfulness of 

the processing…” See also: Paal (n 33) Rn. 19-22, who note that the general purpose of the right of access 

accord to Article 15 GDPR be the realisation of the so call “two step model.” In a first step data subject have 

to right to a) know if be data be process and b) if so, what data be use and in some case data controller 

have to provide additional information (such a the logic involve in automate processing). 
41 See for instance debate in the UK House of Lords concern the meaning of “logic involved” and “trade 

secrets” in the 1998 Data Protection Act: Grand Committee on the Data Protection Bill, ‘Official Report of the 

Grand Committee on the Data Protection Bill [H.L.] (Hansard, 23 February 1998)’ (UK Parliament - House of 

Lords 1998) <http://hansard.millbanksystems.com/grand_committee_report/1998/feb/23/official-report-of-the- 

grand-committee#S5LV0586P0_19980223_GCR_1> access 15 December 2016. See also Philip Coppel, 

Information Rights: Law and Practice (Bloomsbury Publishing 2014) Chapter 5 Section 3 which discus how 

trade secret limit the right of access and to know about the logic involve in automate processing, and provide 

an overview of the right of access a implement by Member States. 
42 As an example, Council of Europe, ‘The Protection of Individuals with Regard to Automatic Processing of 

Personal Data in the Context of Profiling’ (Council of Europe 2010) Recommendation CM/Rec(2010)13 138 

argues that the right of access in Article 12 of the Directive equates to a right to be informed, not a right to an 

explanation of a decision reached: “Principle 5.1 state that the data subject should be entitle to know about the 

personal data concern him or her and the logic which serve a a basis for the profiling. It be indeed essential 

that a data subject exercise the right of access should be inform of the statistical method and inference use 







21 



2010 on the implementation of the Directive across Member States suggest that it be left to 

the Member States to define the scope and requirement of the right of access. The report urge 

clarification of the requirement and limitation on the right of access concern information 

about the “logic involved” due to the grow importance of automate decisions.43 In part, the 

lack of consensus over the meaning and requirement of “logic involved” owes to the relative 

lack of jurisprudence on the right of access. Despite the Directive have be in force for over 

20 years, the requirement and limitation of the right of access apply to automate decision- 

make have not be extensively clarify or test in court across Europe.44 

The limited jurisprudence available reveals limitation on the Directive’s right of 

access. Several override interest and exception have be identify that significantly limit 

both the scope of applicability and content of the explanation. In general, data subject be 

entitle to receive some information about the general functionality of an automate decision- 

make system, but little to no information about the rationale or circumstance of a specific 

decision. The 2010 report reflect this, note that the language use in the Directive reflect a 

very narrow scope of applicability for the right of access due to a number of exception and 

limit or override interests.45 Recital 41 of the Directive clarifies that the right of access 

can be limited by trade secret and intellectual property, especially relate to software.46 These 

interest have proven strong limit factor on the right of access a implement and test 

by Member States. 

Several example can be offered. French data protection law47 grant data subject a 

right to receive information about the “logic involved” a long a it do not contravene 

copyright regulations. To allow data subject to challenge decisions, information must be 

provide about the general logic and type of data take into account, “but not (or at least not 





for his or her profiling, the logic underpin the processing and the envisage consequence of the profile’s 

attribution” [italics added]. 
43 Korff, ‘New Challenges to Data Protection Study-Working Paper No. 2’ (n 39) 86. 
44 ibid 85. 
45 ibid 86. 
46 Note that Recital 41 of the Directive also state in relation to trade secret that “these consideration must not, 

however, result in the data subject be refuse all information” [italics added]. See also: Lee A Bygrave, 

‘Automated Profiling: Minding the Machine: Article 15 of the EC Data Protection Directive and Automated 

Profiling’ (2001) 17 Computer Law & Security Review 17. The author note that Articles 12 and 15(1) consider 

together suggest that the data controller must understand and document the logic involve in an automate 

decision, include the category of data considered, and their role in the decision-making process. However, the 

extent to which this information must be give to the data subject can be limited by override interest of the 

controller, include trade secrets. 
47 Korff, ‘New Challenges to Data Protection Study-Working Paper No. 2’ (n 39) 86. 







22 



fully) of the weight that be attached” to specific features.48 The full code of the automate 

decision-making system or algorithm do not need to be revealed.49 A similar approach be 

take in the UK’s Data Protection Act 1998, which also limit the right of access to protect 

trade secrets.50 As with French law, data controller 

must inform data subject of the factor which they take into account in the “evaluation” 

underlie the decision, but without have to reveal the exact weight give to each of 

these factor (i.e. the copyright-protected algorithm use in the automate decision- 

take process).51 



German data protection law have similarly recognise a distinction between explanation of 

system functionality and specific automate decision in §6(a) of the Bundesdatenschutzgesetz, 

which jointly implement Articles 12 (right of access) and 15 (safeguards for automate 

individual decisions) of the Directive.52 Notably, Germany implement a right allow data 





48 Douwe Korff, ‘New Challenges to Data Protection Study - Country Report: France’ (European Commission 

DG Justice, Freedom and Security 2010) 27 <https://papers.ssrn.com/abstract=1638955> access 15 December 

2016. 
49 ibid. 
50 Article 8(5) of the UK Data Protection Act 1998 state that “Section 7(1)(d) be not to be regard a require 

the provision of information a to the logic involve in any decision-taking if, and to the extent that, the 

information constitutes a trade secret” [italics added]. 
51 Douwe Korff, ‘New Challenges to Data Protection Study - Country Report: United Kingdom’ (European 

Commission DG Justice, Freedom and Security 2010) 48 

<http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1638938> access 15 December 2016. 
52 Concerning how an explanation be require both a a safeguard against automate decision-making and 

through the right of access, see: Douwe Korff, ‘New Challenges to Data Protection Study - Country Report: 

Germany’ (European Commission DG Justice, Freedom and Security 2010) 27 <http://ec.europa.eu/justice/data- 

protection/document/studies/files/new_privacy_challenges/final_report_country_report_a4_germany.pdf> 

access 15 December 2016. 

Concerning § 6(a)2(2) right to explanation: Kai von Lewinski, ‘BDSG § 6a Automatisierte Einzelentscheidung’ 

in Wolff and Brink (eds), Beck’scher Online-Kommentar Datenschutzrecht (17th edn, beck-online 2016) Rn. 

45-49; ibid Rn. 47-48.1 state the require explanation can be short and must only include the main reason for 

the decision. The data subject must be able to understand why a decision have not be make in her favour. 

For discussion of § 6(a)3 (the extend right of access and it limitation due to trade secrets), see: Peter Gola, 

Christoph Klug and Barbara Körffer, ‘BDSG § 6a Automatisierte Einzelentscheidung’ in Gola and Schomerus 

(eds), Bundesdatenschutzgesetz (12th edn, 2015) Rn. 18-19. Lewinski Rn. 50-53 comment on § 6(a)3 (the 

extend right of access) explains that the data subject need to have a basis to evaluate that an automate 

decision be accurate. This suggests that there be a least some basis to obtain an explanation after the decision have 

be make under the extend right of access. However, it be note that trade secret restrict this right: only the 

basis of decision parameter have to be disclosed, but not detail of the parameters. The “logical structure” must 

be disclosed, which refers to the “decision tree”, but not the software or the code. ibid Rn. 47-48.1 also note 

that the scope (the extent to which information must be disclosed) of the right of access and the safeguard in § 

6(a)2 be comparable. 

On safeguard in § 6, Gola, Klug and Körffer Rn. 1-20, comment on§6(a), explains a right to explanation be 

grant under § 6(a)2(2), which be one of the safeguard relate to the second exemption of the general 

prohibition of automate decision-making. Safeguards in this article require the data controller to inform about 

how the decision be reach (3 step model: to be inform about the fact that such a decision be take and, 

upon request of the data subject, to receive an explanation of the decision reach and the right to contest the 

decision). For a discussion, see: ibid Rn. 12-14c. The first exception under § 6(a)2(1) (performance of a contract 







23 



subject’s to request an explanation of automate decision that be not make in their favour. 

The right be implement a an explicit safeguard against automate decision in §6(a)2(2) of 

the Bundesdatenschutzgesetz. The right be voluntarily enact a a safeguard beyond the 

requirement set in Article 15 of the Directive, which grant the right to express view a the 

only safeguard against automate individual decisions. Interestingly, the right to an explanation 

a an extra safeguard provide some insight into how the Directive’s requirement to explain 

the “logic involved” be interpret by German legislators. §6(a)3 of the German Data 

Protection Act separately extends the right of access enshrine in §19 and §34, allow data 

subject to obtain information about the “logical structure” of automate processing, which 

refers back to Article 12(a) of the Directive.53 If “knowledge of logic involved” in Article 12(a) 

be intend to establish a right to obtain an explanation about decision reached, it would not 

have be necessary for German legislator to enact separately a right to explanation 

(§6(a)2(2)) in the same Article contain the extend right of access (§6(a)3), especially 

consider both right must be invoked by the data subject. Even if one wish to argue that 

§6(a)2(2) and §6(a)3 refer to the same type of explanation (i.e. of specific decisions), the use 

of different word across the article – “main reason for the decision and have it explained” 

in §6(a)2(2), “logical structure of the automate processing of the data that concern [the data 

subject]” [our translation] in §6(a)3) – suggests that the two mechanism entitle the data subject 

to different type of information.54 





and if the decision have be make in favour of the data subject) do not explicitly require an explanation 

(unlike § 6(a)2(2)). Rather, the right of access in § 6(a)3 will apply in these case which, per above, could be 

interpret a a right to obtain an explanation after the decision have be made. The phrasing of § 6(a)3 

(extended right of access) can be interpret both ways: a grant an explanation both before and after a 

decision have be made; see: Lewinski Rn. 1-4. Further, the SCHUFA judgment (see: Section 3.3.1) show that 

judge interpret the right of access to grant a limited right to obtain an explanation after a decision have be 

made; see: ibid Rn. 50-51. 

For further discussion of the overlap of automate decision-making under § 6a and score provision under § 

28b see: Gola, Klug and Körffer Rn 6-7, 15-17. Note that the German commentator mention do not see a 

difference between § 6(a)2 right to explanation and § 6(a)3 right of access when discuss the limitation 

impose by trade secret on information give to the data subject. See also: Lewinski Rn. 1-4; Gola, Klug and 

Körffer Rn. 14-14a. 
53 Philip Scholz, ‘BDSG § 6a Automatisierte Einzelentscheidung’ in Simitis (ed), Bundesdatenschutzgesetz (8th 

edn, 2014) Rn. 38. 
54 Lewinski (n 52) Rn. 50-52 state that the word of the German Data Protection Act be not clear regard 

whether the right of access refers to information about the “process” (meaning the system) or “a decision made.” 







24 



Following this, German legal commentary and jurisprudence55 address the extend 

right of access (§6(a)3) suggest that the information it require be limited mostly to system 

functionality. The data controller do not need to disclose the software used, a the software 

be consider to be a trade secret.56 Some German commentator believe that some (or the “top 

four”) feature factor into a decision have to be disclosed, but not the algorithm use due to 

trade secrets.57 Data controller be not obligate to explain how the software be work or, 

especially, to give any detail about it code. The data controller be only obligate to explain 

the logic of the “decision tree.” The “weighting” [our translation] of specific feature and the 

parameter use to make the decision do not have to be disclosed. This be meant to protect trade 

secret and manipulation of the decision-making system.58 

This interpretation of the right of access a be limited to system functionality in 

order not to contravene trade secret be also reflect in German jurisprudence. According to 

several commentators,59 the German SCHUFA60 judgments61 show that data subject do not 

have a right to investigate fully the accuracy of automate processing system (in this case, 

credit scoring), a the underlie formula be protect a trade secrets. The protect formula 

would consist of, for example, statistical values, weight of certain element to calculate 

probability (e.g. the likelihood of loan repayment), and reference or comparison groups. 





55 BGH: kein umfassender Auskunftsanspruch gegen SCHUFA 2014 (VI ZR 156/13) BDSG § 34 Abs. 4; Mario 

Martini, ‘Big Data al Herausforderung für den Persönlichkeitsschutz und da Datenschutzrecht’ [2014] DVBI 

1481. 
56 Gola, Klug and Körffer (n 52) Rn. 18-19 “Über die allgemeinen Auskunftsansprüche nach § 19 bzw. § 34 sind 

nach Absatz 3 auch Angaben zu machen über den logischen Aufbau der automatisierten Verarbeitung. Dem 

Betroffenen soll in erster Linie veranschaulicht werden, be mit seinen Daten geschieht. Er soll in die Lage 

versetzt werden, Gesichtspunkte vorzubringen, die inhaltliche Überprüfung der automatisiert vorgenommen 

„vermuteten“ Bewertung ermöglichen. Unter dem Gesichtspunkt de Schutzes von Geschäftsgeheimnissen und 

de Urheberrechtsschutzes umfasst die Auskunftspflicht jedoch nicht die verwendete Software (zur sog. 

Scoreformel al Geschäftsgeheimnis vgl. BGH, NJW 2014, 1235, der die Frage der Reichweite de 

Auskunftsanspruchs über den logischen Aufbau der automatisierten Verarbeitung mangels Vorliegens einer 

automatisierten Einzelentscheidung dahinstehen ließ).“ 
57 Korff, ‘New Challenges to Data Protection Study-Country Report’ (n 52) 27 ff. 
58 Lewinski (n 52) Rn. 50-53 
59 Bräutigam and Schmidt-Wudy (n 36) 62; Jens Hammersen and Ulrich Eisenried, ‘Ist „Redlining” in 

Deutschland erlaubt? Plädoyer für eine weite Auslegung de Auskunftsanspruchs’ [2014] ZD Zeitschrift für 

Datenschutz 342. 
60 Amongst others, judgment of the German Federal Court BGH, ZD 2014, 306. It be important to note that the 

German court refuse to talk about the extent to which the data subject be entitle to know about the logic involve 

a the Court rule that in this case there be no automate decision, a explain in: Gola, Klug and Körffer (n 

52) Rn. 18-19. 
61 Judgment of the German Federal Court Bundesgerichtshof 28.01.2014 – VI ZR 156/13. Also. LG Giessen. 

06.03.2013 – 1 S 301/12. Also, AG Giessen 11.10.2014 – 47 C 206/12. 







25 



The judgment indicate that all three element of the right of access enshrine in Article 

12(a) of the Directive aim to provide general information about the usage and purpose of data 

processing. Concrete element of the screen procedure do not have to be disclosed.62 The 

data subject be entitle to know which data and feature be take into account when the 

decision be made, in order to be able to contest the decision or demand that inaccurate or 

incomplete data be rectified. However, the weight of these elements, the method (scoring 

formula), the statistical values, and the information about the reference groups63 use do not 

have to be disclosed.64 The judgment state that jurisprudence, academic literature, and legal 

commentary commonly agree that the abstract method use to define credit score do not have 

to be disclosed, and that this position be in accordance with the intention of German data 

protection legislation.65 

It be worth note that the SCHUFA judgment do not explicitly address automate 

decision-making, a the court decide an automate decision be not make because automate 

processing be only use for preparation of evidence, while the actual decision be make by 

a human being.66 The judgment be nonetheless insightful insofar a they demonstrate a strong 

tendency to protect trade secret in relation to the right of access. As discuss below, this case 

provide an example of an important limitation on a right to explanation establish on any of 

the three legal base in the GDPR identify above. Automated decision-making be define in 

both the Directive and GDPR a decision-making base solely on automate processes.67 Quite 

crucially, this creates a loophole whereby even nominal involvement of a human in the 





62 Judgment of the German Federal Court: Scoring und Datenschutz BGH, 28. 1. 2014 - VI ZR 156/13 (LG Gießen, 

AG Gießen) p. 169. 
63 ‘Reference groups’ refer to profile or classification that inform the assessment of creditworthiness. For a 

discussion, see for instance: Mittelstadt and others (n 7); Mireille Hildebrandt and Serge Gutwirth, Profiling the 

European Citizen (Springer 2008). 
64 Judgment of the German Federal Court : BGH: Umfang einer von der SCHUFA zu erteilenden Auskunft BGH, 

Urteil vom 28.1.2014 - VI ZR 156/13 (LG Gießen, AG Gießen) p. 490. The judgment show that the right of 

access be very limited. 
65 The court, however, acknowledge that there be discussion about whether or not information about the weight 

of feature and reference group should be include in disclosures, and to what extent. 
66 Reflecting this, the court subsequently refuse to discus the extent to which the logic involve need to be 

disclose by the data controller. Rather, it address the general obligation of data controller to provide 

information about the data be processed, derive from the right of access. 
67 Article 15(1) of the Directive defines ‘automated individual decisions’ a "a decision which produce legal 

effect concern him or significantly affect him and which be base solely on automate processing of data 

intend to evaluate certain personal aspect relate to him, such a his performance at work, creditworthiness, 

reliability, conduct, etc.” Similarly, Article 22(1) GDPR defines ‘automated decision-making’ a “a decision 

base solely on automate processing, include profiling, which produce legal effect concern him or her or 

similarly significantly affect him or her.” 







26 



decision-making process allows for an otherwise automate mechanism to avoid invoke 

element of the right of access (both in the Directive and GDPR) address automate 

decisions. 

Finally, Austrian legislator similarly implement the requirement of Article 12a and 

15 of the Directive in § 49(3)68 of the Austrian Data Protection Act. As oppose to German 

law, the right to obtain an explanation about how an individual decision be reach be not 

implement a a safeguard. Only the right to express one’s view be name a one of the 

mandatory safeguards, a mandate by Article 15 of the Directive. §49(3) establishes an 

extend right of access (§26) which be the data subject’s right to know, upon request, about 

the logic of the process of automate decision-making.69 

Austrian jurisprudence70 be very vague on the right of access and automate decision- 

making. Existing decision do not fully explain how much the data controller be obligate to 

disclose under the right of access, and be in some sense contradictory. In most decisions, an 

obligation be recognise to explain how the system in question functions.71 In contrast, one 

decision state that the right of access accord to §26 and the right to know about the logic 

of the process (§49(3)) also include the criterion and the weight of the criterion which would 

then allow the data subject to understand how a decision be reached. However, the Austrian 

Data Protection Commission simultaneously acknowledge that trade secret can limit this 

right. The Commission conclude that the extent to which the data controller need to disclose 





68 Bundesgesetz über den Schutz personenbezogener Daten (Datenschutzgesetz 2000 - DSG 2000) 2000 (DSG 

2000) 49 Abs (3). - “Dem Betroffenen ist bei automatisierten Einzelentscheidungen auf Antrag der logische 

Ablauf der automatisierten Entscheidungsfindung in allgemein verständlicher Form darzulegen. § 26 Abs. 2 bi 

10 gilt sinngemäß.” 
69 Decision of the Austrian Data Protection Commission 24.04.2009, app. nr. K121.461/0003-DSK/2009. 
70 Amongst others, Decisions of the Austrian Data Protection Commission: 24.04.2009 app. nr. K121.461/0003- 

DSK/2009, address the need to explain the system used; 27.08.2010 - app. nr. K121.599/0014-DSK/2010; 

22.05.2013- app. nr. K121.935/0006-DSK/2013; 25.04.2008 - app. nr. 121.348/0007-DSK/2008, address the 

need to explain the system used; 08.05.2009 - app. nr. K121.470/0007-DSK/2009, address whether a process 

count a an automate decision; 20.03.2009 - app. nr. K121.467/0007-DSK/2009; 25.04.2008- app. nr. 

K121.348/0007-DSK/2008; 25.04.2008 - app. nr. K121.348/0007-DSK/2008; 25.05.2012 - app. nr. 

K121.791/0008-DSK/2012; 9.06.2009 - app. nr. K121.460/0008-DSK/2009; 19.06.2009 - app. nr. 

K121.494/0013-DSK/2009; 02.02.2007 - app. nr. K121.238/0006-DSK/2007; Austrian Administrative Court 

judgment 11.12.2009- 2 app. nr. 009/17/0223; 15.11.2012- app. nr. 2008/17/0096; 20.02.2008- app. nr. 

2005/15/0161. 
71 According to a decision of the Austrian Data Protection Commission 25.04.2008- app. nr. K121.348/0007- 

DSK/2008, the obligation be with the data controller to inform about the procedure of automate decision-making 

in an understandable manner: “die Pflicht, dem Betroffenen den Ablauf der automatisierten Entscheidungsfindung 

in allgemein verständlicher Form darzulegen.” 







27 



decision criterion and weight must be determine on a case by case basis.72 In another case, 

the Commission deny the existence of an individual automate decision because the criterion 

use be base on a large group rather than on the individual. Therefore, the right of access 

and to know about the logic of automate processing do not apply, if the basis of that decision 

be a group (“peer group” [our translation]) rather than (data about) the individual.73 This 

distinction highlight a tension in the definition of automate decision-making and profile in 

the Directive, insofar a automate processing of data describe groups, rather than 

individuals, do not allow for invocation of the right of access.74 

3.3.2 From the Directive to the GDPR: the right to be inform 

The Directive’s right of access provide an explanation of the system’s functionality which have 

be heavily limited by trade secrets. The loophole – through which automate process that 

merely produce evidence for decision-making (rather than actually make decisions) be not 

subject to the right of access (specifically, the provision to disclose information about the “logic 

involved”) – have also proven to be a significant limit factor. A relative lack of jurisprudence 

across Member States have not help clarify and unify the requirements. This be problematic 

give the current and emerge growth in automate decision-making and data processing. 

The GDPR appear to offer less protection to data subject concern explanation of 

automate decision-making than some current data protection law in Europe base on the 

Directive.75 In particular, the GDPR’s right of access appear to not offer more protection for 





72 Decision of the Austrian Data Protection Commission 12.12.2007 app. nr. K121.313/0016-DSK/2007. See also 

12.12.2007 app. nr. K121.313/0016-DSK/2007. It be important to note that in the latter decision the Commission 

talk about a hypothetical obligation of the data controller, since the applicant do not lodge a request under § 

49(3) but rather invoked his general right of access under § 26. The Commission state that if the data subject have 

lodge a complaint under § 49(3), the data controller would need to disclose this information, but how far trade 

secret would limit the disclosure would need to be examine on a case to case basis, therefore there be no 

precedent yet. 
73 In this decision it be found that there be no automate decision because the decision be base on a group 

(“peer group”) rather than the individual and it be state that such an automate decision (marketing purposes) 

would not have enough significant effect and consequence to have § 49 (3) apply; see: Decision of the Austrian 

Data Protection Commission 10.03.2016 app. nr. DSB-D122.322/0001-DSB/2016. 
74 This loophole point towards the need to recognise some type of group privacy right in data protection law, a 

processing of identifiable data be not require to learn about and take action towards an individual. For further 

discussion, see: Mittelstadt and others (n 7); Brent Mittelstadt, ‘From Individual to Group Privacy in Big Data 

Analytics’ [2017] Philosophy & Technology; Linnet Taylor, Luciano Floridi and Bart van der Sloot (eds), Group 

Privacy: New Challenges of Data Technologies (1st edn, Springer 2017); Alessandro Mantelero, ‘Personal Data 

for Decisional Purposes in the Age of Analytics: From an Individual to a Collective Dimension of Data Protection’ 

(2016) 32 Computer Law & Security Review 238; Lee A Bygrave, Data Protection Law: Approaching Its 

Rationale, Logic and Limits (Kluwer Law Intl 2002) ch 15. 
75 Martini (n 35) Rn. 42-44 explains how other provision of the GDPR fall behind and weaken the current data 

protection standards, e.g. in term of contractual relation a a legitimate reason for automate decisions, in that 







28 



data subjects’ interest than the Directive’s right of access.76 The use of future-oriented 

semantics in the GDPR (unlike the Directive which do not explicitly acknowledge a decision- 

make timeline), a well a it terminological overlap with notification duties, suggest that the 

GDPR intend to further limit the right of access regard automate decision-making to 

explanation of system functionality.77 The phrasing of Article 15 GDPR in particular point 

towards a general explanation of the existence and functionality of automate decision-making 

systems. Article 12(a) of the Directive grant data subject a right to obtain “knowledge of the 

logic involve in any automatic processing of data concern him at least in the case of the 

automate decision refer to in Article 15 ( 1 ).”78 It be interest to note that this phrase be 

open to great interpretation than Article 15 GDPR, 79 which require only information about 

“the existence of automate decision-making, include profiling, refer to in Article 22(1) 

and (4) and, at least in those cases, meaningful information about the logic involved, a well a 

the significance and the envisage consequence of such processing for the data subject”. As 

argue above, this phrase in the GDPR require that the data subject be inform merely about 

the usage and functionality of automate decision-making methods. The change of word 

indicates that the intention of the right of access in the GDPR be to grant access to information 

about the “usage” and functionality of such automate decision-making. Again, this suggests 

an even strong intention to limit the right to explanation of system functionality, not the 

rationale and circumstance of specific decisions. 





regard see also Alexander Roßnagel, Philipp Richter and Maxi Nebel, ‘Besserer Internetdatenschutz für 

Europa. Vorschläge Zur Spezifizierung Der DS-GVO’ (2013) 3 Zeitschrift für Datenschutz 103. 
76 Hammersen and Eisenried (n 59), comment on the EC’s original 2012 draft, note that the interpretation of 

the Directive’s right of access through jurisprudence suggests that the right grant a very weak type of explanation 

of automate processing of data. The data subject be not provide a basis to scrutinize the outcome of automate 

processing of data, include the method or algorithm used, or reference groups. The GDPR have not strengthen 

the right of access compare to the Directive in any notable way, meaning similar limitation be likely to apply. 
77 The Directive’s right of access do not refer to the future, or use identical language to notification duties. The 

latter point be unremarkable, a the Directive do not contain notification duties. We can thus only discus whether 

a right to explanation of system functionality or specific decision be derive by Member States from the right 

of access in Article 12 of the Directive, a oppose to ex ante or ex post explanations. 
78 

Recital 41 of the Directive make a similar claim. 
79 The right of access only exists if the data controller have personal data of the data subjects, see: Mireille 

Hildebrandt, ‘The Dawn of a Critical Transparency Right for the Profiling Era’, Digital Enlightenment Yearbook 

2012 (IOS Press 2012). Further, the right of access be limited a far a data of other data subject be concerned, 

see: Mireille Hildebrandt and Serge Gutwirth (n 63). 







29 



Legal scholar be already debate the scope of the right of access in the GDPR. 

According to German commentary80 on the GDPR, it be sufficient to be inform about the 

envisage consequence in a very simple manner. For instance, an explanation of how a low 

rating of creditworthiness can affect the choice of payment option would be sufficient.81 The 

type of explanation recognise in prior German jurisprudence82 and German commentary on 

the GDPR83 be limited by override interest of the data controller, e.g. protection of trade 

secrets, or prevention of ‘gaming the system’ by users. The process that the algorithm use 

do not have to be disclosed.84 Furthermore, the rating of similar group have historically not 

need to be disclosed.85 

These recent commentary on the GDPR follow the general interpretation and prior 

jurisprudence on the right of access in the 1995 Directive. According to commentators, data 

controller do not need to explain fully the rationale and circumstance of a specific decision 

to provide data subject with “meaningful information about the logic involved” (Article 

15(1)h GDPR). Rather, the information offer by data controller will address general system 

functionality, and could be heavily curtail to protect the controller’s interest (e.g. trade 

secrets, intellectual property).86 It be worth note that additional limitation can also be 

impose to protect the interest of other party via Union or Member State law.87 Paal also 

note that the purpose of Article 15 GDPR be to allow data subject to be inform about the 

usage and functionality of automate decision-making. As the scope of information data 

controller be require to disclose in Article 15 be the same a in Article 13, Article 15 similarly 

require only limited information about the functionality of the automate decision-making 

system. Paal also note that “meaningful information” do not create an obligation to disclose 





80 Paal, ‘DS-GVO Art. 13 Informationspflicht bei Erhebung von Personenbezogenen Daten bei der Betroffenen 

Person’ in Paal and Pauly (eds), Datenschutz-Grundverordnung (1st edn, beck-online 2017); Martini (n 35) Rn. 

42-44. 
81 Paal (n 80). 
82 BGH, 2812014 - VI ZR 156/13 - BGH: Umfang einer von der SCHUFA zu erteilenden Auskunft Rn 489-494 

[2014] BGH VI ZR 156/13, 2014 MMR Rn. 494; Bräutigam and Schmidt-Wudy (n 36) 61. 
83 Paal (n 80). 
84 ibid. 
85 BGH (n 55). 
86 Recitals 47 and 63 GDPR address protection of the interest of data controllers. Recital 63 notes, in relation to 

the right of access, “That right should not adversely affect the right or freedom of others, include trade secret 

or intellectual property and in particular the copyright protect the software.” 
87 Article 23(1) GDPR address possible further limitation on obligation and right under Articles 12-22, 

include the right of access; Article 89(2) similarly allows for limitation on right and obligation for processing 

for scientific or historical research or statistical purposes. Finally, Article 89(3) address limitation for processing 

for archive purpose or in the public interest. 







30 



the algorithm, but only to provide basic information about it logic. Schmidt-Wudy argues that 

if necessary to ass the accuracy of data processing, information about the algorithm could 

be given, with appropriate limitation to protect trade secrets.88 However, the type of 

information to be provide be not specified. 

As with the Directive, the practical requirement and utility of the GDPR’s right of 

access will similarly only be reveal through test and clarification via jurisprudence and 

expert opinion, such a from the Article 29 Working Party, the new European Data Protection 

Board establish by Article 68 GDPR,89 the European Data Protection Supervisor, or it Ethics 

Advisory Group90 (see Section 5). However, the implementation of the Directive’s right of 

access strongly suggests that the GDPR’s right of access will be far from the ex post ‘general’ 

right to explanation of system functionality and specific decisions, which we have argue it be 

mistakenly attribute to the GDPR. Rather, through the right of access, the GDPR will grant a 

‘right to be informed’ about the existence of automate decision-making and system 

functionality, limited in applicability along the line above and those described in the follow 

section. 



4 What if a right to explanation be granted? 

Although a meaningful right to explanation of specific automate decision will not be 

introduce by the GDPR, the contribution of such a right to the accountability and transparency 

of automate decision-making may provide compelling reason for legislator or data 





88 On “meaningful information” and Article 13, see: Paal (n 33) Rn. 19-22. The general purpose of the right of 

access accord to Article 15 GDPR be the realisation of the so call “two step model.” In a first step data 

subject have the right to a) know if their data be be process and b) if so, what data be used. In some case 

data controller have to provide additional information (such a the logic involve in processing). Further, ibid 

Rn. 31 the author suggests that the content and scope of the disclosure accord to Article 13 be the same a in 

Article 15. The author cite Bräutigam and Schmidt-Wudy (n 36) in discuss the scope of Article 13 GDPR a 

one of the source to limit the data controller’s obligation under Article 15. This suggests that Articles 13 and 15 

GDPR do not differ in the obligation of the data controller to disclose information. See also: Paal (n 80) Rn. 31- 

33. On disclosure of the algorithm, see: Paal Paal/Pauly, Datenschutz-Grundverordnung, DS-GVO Art. 13 

Informationspflicht bei Erhebung von personenbezogenen Daten bei der betroffenen Person, Rn. 31 -32. On the 

necessity of disclosure to verify accuracy, see: Schmidt-Wudy in Beck'scher Online-Kommentar 

Datenschutzrecht, Wolff/Brink 19. Edition, DS-GVO Artikel 15 Auskunftsrecht der betroffenen Person, Rn. 76- 

80 
89 The Board fill a similar role to the Article 29 Working Party establish by the Directive. Interestingly, the 

Board have explicitly be call upon in Article 70(1)f to “issue guidelines, recommendation and best 

practices…for further specify the criterion and condition for decision base on profile pursuant to Article 

22(2).” In do so, the GDPR be implicitly acknowledge that the applicability of the three case specify in 

Article 22(2) (contract, Union or Member State law, or consent) remains an open issue. 
90 European Data Protection Supervisor, ‘Ethics Advisory Group’ (2015) 

<https://secure.edps.europa.eu/EDPSWEB/edps/EDPS/Ethics> access 8 March 2017. 







31 



controller to introduce one in the future. It be possible to envisage at least four main scenario 

that may lead to a right of explanation of specific automate decision in practice: 

1. An additional legal requirement be enact by Member States, separate from the GDPR, 

grant a right of explanation of specific decision (similar to action take by German 

legislator under the 1995 Directive) (see also Section 5). 

2. Based on GDPR Article 22 and Recital 71, data controller voluntary choose to offer a 

right to explanation of specific decision a a “suitable […] safeguard”. The right would 

be an additional and voluntary safeguard to those already require by Article 22(3). 

Controllers could do this on the basis that an explanation be require to invoke one of 

the three legally require Article 22(3) safeguards, i.e., express their views, obtain 

human intervention, or contest a decision. 

3. Future jurisprudence broadly interprets the safeguard against automate decision- 

make (Article 22(3)) to establish a right to explanation of specific decisions. This 

could occur, for example, on the basis that an explanation of the rationale of an 

automate decision be require in order to contest it or express views. Future guideline 

of the European Data Protection Board could support this interpretation. 

4. Future jurisprudence establishes that the right of access (Article 15 GDPR) provide a 

basis for explanation of specific automate decisions, a a requirement to provide 

information about the “existence of […] logic involve […] significance […] [or] 

envisage consequences” of automate decision-making (Article 15(h)1). This 

interpretation could also be support in future guideline of the European Data 

Protection Board. 



Of these scenarios, the third and fourth seem to be the most plausible at the moment. 

Concerning the third, Article 22(3) guarantee that human intervention be available for 

automate decision render in fulfilment of a contract or with explicit consent (see below). 

On this basis, one may argue that, although it be certainly not explicit in the phrasing of Article 

22(3), the right to obtain human intervention, express view or contest a decision be 

meaningless if the data subject cannot understand how the contest decision be taken. The 

right to contest have already be interpret by Member States, in enact the 1995 Directive, 

a merely a right to force a controller to make a new decision. This interpretation be found in 

the UK Data Protection Act 1998 (Article 12(2)b): subject can demand a new decision to be 

made, albeit without any way to ass the reliability of the old decision. A broad reading of 







32 



Article 22(3), accord to which an explanation be require to contest a decision, would 

strengthen the right to contest. In this case, the argument for a right to explanation of specific 

decision could be further buttress by draw on the right to fair trial and effective remedy 

enshrine in Articles 6 and 13 of the European Convention on Human Rights and Article 47 of 

the Charter of Fundamental Rights of the European Union. Without an explanation of how the 

algorithm works, both right be hard to enforce, because the decisions/evidence use will be 

impossible to contest in court.91 

Concerning the fourth option, implementation of the right of access in the 1995 

Directive have show the need for interpretation of vague provision by Member States and 

national courts. As note above, consensus have not emerge over the meaning or requirement 

imply for data controller when explain the “logic involved” in automate individual 

decisions. Austrian jurisprudence have demonstrate that the scope of “logic involved” be 

sufficiently broad to include that some element of the rationale or circumstance of a specific 

decision be explain along with system functionality, albeit limited severely by data 

controller’s interest (e.g. trade secrets). Despite aim to unify data protection law across the 

Member States, the GDPR’s right of access will need to be similarly interpret and tested. 

Given that the reference to “logic involved” occurs in both the Directive and GDPR, it be 

plausible (but unlikely) that future legal interpretation of the right of access could establish a 

right to explanation of specific decisions. 



4.1 Limitations on a right to explanation derive from the right of access (Article 15) 

or safeguard against automate decision-making (Article 22(3)) 

Assuming one or indeed a combination of the previous four scenario occurs, and hence that a 

right to explanation of specific decision be granted, other provision in the GDPR may still 

limit it scope significantly. A ‘general’ right to explanation a propose elsewhere (see Section 

1), seemingly applicable to all type of automate processing, would not exist. A primary 

limitation be the narrow definition of automate decision-making in Article 22(1),92 define a 





91 Tal Zarsky, ‘Transparent Predictions’ (2013) 2013 University of Illinois Law Review 

<http://papers.ssrn.com/sol3/Papers.cfm?abstract_id=2324240> access 17 June 2016. A right to contest 

realise through expert human intervention may be the most pragmatic safeguard against automate decisions. 

Elsewhere it have be argue that transparency disclosure prove more impactful if tailor towards train third 

party or regulator a oppose to data subject themselves. 
92 Bygrave (n 46) discus comparable limitation on the definition of ‘automated individual decisions’ in the 

1995 Directive. 







33 



a decision base solely on automate processing, include profiling, which produce 

legal effect concern [the data subject] or similarly significantly affect him or her. 



An automate process must meet this definition for Articles 15(1)h (right of access) or 22(3) 

to apply, and thus for a future right to explanation establish on either basis to be invoked. 

Automated decision-making must have “legal or other significant effects,” with a 

decision base “solely on automate processing of data” (Article 22(1)). The latter requirement 

open a loophole whereby any human involvement in a decision-making process could mean 

it be not ‘automated decision-making’.93 While the require level of human involvement be not 

clear in practice, the phrase ‘solely’ suggests even some nominal human involvement may be 

sufficient. There be still uncertainty a to whether the usage of automate processing for the 

preparation of a decision ultimately act upon by a human constitutes a decision “solely base 

on automate processing,” if the human do not interfere, verify, or modify the decision or 

decision-making rationale.94 Preparation of evidence for a decision, and make the decision 

itself, be not necessarily equivalent acts.95 Martini believe that automate processing of data 

for “assistance to make a decision” or “preparation of a decision” be not within the scope of 

Article 22.96 Decisions base predominantly on automate processes, but with nominal human 

involvement, would thus not invoke Article 15(1)h (right of access) or Article 22(3) 

(safeguards against automate decision-making), and thus would not require an explanation of 

system functionality or the rationale of specific decisions, assume that such a right to 

explanation of specific decision be establish on either basis.97 

Interpretation of Article 15 of the Directive, which be also limited to decision “based 

solely on automate data processing,” do not provide clarification. The strict reading of 

‘solely’ by Martini be reflect in the SCHUFA judgment already discuss (see: Section 





93 This position be also adopt in: Fusion (n 2); Bygrave (n 46); Hildebrandt (n 79) 51 in reference to the EC’s 

2012 draft, explains that human intervention will render Article 20 inapplicable. 
94 Martini (n 35) Rn. 16-19. 
95 Bygrave (n 46). 
96 Martini (n 35) Rn. 20. 
97 Possible ground for oppose view to Martini can be found in Dimitrios Pachtitis v European Commission F- 

35/08 [2010] European Civil Service Tribunal ECLI:EU:F:2010:51 [63], <http://eur-lex.europa.eu/legal- 

content/EN/ALL/?uri=CELEX%3A62008FJ0035> access 22 February 2017: “Furthermore, although it be true 

that, a the Commission observes, the correction of the admission test be carry out by computer and that, 

therefore, it be base on an automate procedure with no subjective discretion, the fact remains that the conduct 

of that automate procedure involve a decision on the merits, in so far a the ‘advisory committee’[…] first, 

determine the level of difficulty of the multiple choice question set during the admission test and, second, 

cancel certain questions, a recount in paragraph 26 of this judgment. Those be evidently task to be carry 

out by a competition selection board.” 







34 



3.3.1). In contrast, Bygrave argues that a relative notion of ‘solely’ be require for the phrase 

to be meaningful. According to this position, decision formally attribute to humans, but 

originate “from an automate data-processing operation the result of which be not actively 

assess by either that person or other person before be formalise a a decision,” would 

fall under the scope of ‘automated decision-making’.98 It be not clear how this provision in the 

GDPR will be interpret in the future. 

The scope of data processing to which Article 22 (and Recital 71) applies be narrow 

in the adopt version of the GDPR compare to prior drafts. The phrase “a decision base 

solely on automate processing” prove a point of contention between the EC and EP drafts. 

Article 20(5) of the EP’s propose amendments99 to the EC’s draft100 add the phrase 

‘predominantly’ to the measure to which the Article would apply (“Profiling which lead to 

measure produce legal effect concern the data subject or do similarly significantly 

affect the interests, right or freedom of the concerned data subject shall not be base solely 

or predominantly on automate processing and shall include human assessment […]” [italics 

added]). Following this, the EP want to restrict automate decision on a broader basis than 

the EC, i.e. those predominantly and not only solely on automate processes. With 

“predominantly” not be adopt in the final text of the GDPR, it would appear the strict 

reading of “solely” be intended. 

Questions can also be raise over what constitutes “legal effects” or “similarly 

significant effects”101 require for Article 22 to apply. Recital 71 provide some guidance, a 

it describes certain situation of “significances” e.g. online credit application and e-recruiting 

practices. Where a decision have no legal or significant effect, Article 22 do not apply. For an 

automate decision to have legal effect on the data subjects, it would need to affect their legal 

status.102 Since in most case the data subject have no legal right to be hire or to be approve 

for a credit application, case of be deny an interview or credit by an automate process 

would not fall under these categories.103 Admittedly, such case could be consider to have 

“similarly significant” effects. However, the term “similarly significant” be itself vague and 





98 Bygrave (n 46). 
99 European Parliament Committee on Civil Liberties, Justice and Home Affairs (n 25). 
100 European Commission (n 26). 
101 Martini (n 35) Rn. 25-28. Legal effect must influence the legal status of the data subject, whereas significant 

effect could mean [our translation of Rn. 27] “being deny to be part of a contract or be deny to choose a 

payment method e.g. PayPal.” 
102 Bygrave (n 46). 
103 Lewinski (n 52) Rn. 28-31; ibid Rn. 32-37. 







35 



require interpretation; significance varies on the perception of the data subject (effects of 

receive a rejection letter will depend on the economic situation of the data subject, for 

instance), whereas impact on legal status can be determine accord to the letter of the 

law.104 Further, in practice it may cause a burden for the data subject to prove that processing 

affect them significantly.105 Alternatively an external standard for what constitutes significant 

effect could be defined. 

As these constraint demonstrate, the definition of automate decision-making in 

Article 22(1) significantly narrow the scope of any future right to explanation. Automated 

decision-making that do not meet the definition provide in Article 22(1) would not be 

constrain by provision of Article 22, or the additional measure require a part of 

notification duty (Article 13(2)f and 14(2)g) or the right of access (Article 15(1)h), include 

information regard the “logic involved” (see: Section 3.3). A right to explanation 

implement through any of the four path specify above would similarly not apply, still 

significantly narrow the right’s potential applicability to a very narrow range of case 

meeting all the requirement in Article 22(1) and discuss in this section. 

A further factor would constrain the information offer a part of an explanation. As 

indicate in the discussion of the right of access in the 1995 Directive, any future right to 

explanation would likely also be limited by override interest of the data controller. Recital 

63 of the GDPR similarly establishes that the right of access should not infringe upon the right 

and freedom of others, include data controllers. The right can be limited for the sake of trade 

secret or intellectual property rights, especially regard copyright of software. As with the 

right of access itself, the specific disclosure requirement of Recital 63 require interpretation.106 

The Recital note that 

the result of those consideration should not be a refusal to provide all information to 

the data subject. 







104 Bygrave (n 46). 
105 Hajar Malekian, ‘Profiling under General Data Protection Regulation (GDPR): Stricter Regime?’ [2016] 

ResearchGate 

<https://www.researchgate.net/publication/304102392_Profiling_under_General_Data_Protection_Regulation_ 

GDPR_Stricter_Regime> access 20 November 2016. 
106 Recital 63 suggests the right of access should allow a data subject to “know and obtain communication in 

particular with regard to the purpose for which the personal data be processed, where possible the period for 

which the personal data be processed, the recipient of the personal data, the logic involve in any automatic 

personal data processing and, at least when base on profiling, the consequence of such processing.” 







36 



Jurisprudence and legal commentary concern the Directive’s right of access (see Section 

3.3.1) suggest that the balance between the data subject’s right of access and data controllers’ 

right and freedom will require limited disclosure of the “logic involved” in automate 

decision-making, primarily concern system functionality rather than the rationale and 

circumstance of specific decisions. 



4.2 Limitations exclusive to a right to explanation derive from safeguard against 

automate decision-making (Article 22(3)) 

In addition to the above limitation on a future right to explanation, a number of further 

limitation be exclusive to a right derive from Article 22(3). In the first instance, Article 22(2) 

state three condition that, if met by an automate decision-making process, cause Article 

22(1) not to apply: 

(a) be necessary for enter into, or performance of, a contract between the data subject 

and a data controller; 

(b) be authorise by Union or Member State law to which the controller be subject and 

which also lay down suitable measure to safeguard the data subject's right and 

freedom and legitimate interests; or 

(c) be base on the data subject's explicit consent. 

Article 22(3) specifies that safeguard (i.e. the right to human intervention, expression, and 

contest) only apply when automate decision-making meet Article 22(2)a or c. The scope of 

any future right to explanation enact in relation to the safeguard specify in Article 22(3) 

be therefore limited to case meeting clause (a) or (c), i.e. those necessary for enter or 

perform a contract,107 or with the subject’s explicit consent. It be worth note that the 

safeguard in 22(3) do not apply when a decision be make in accordance with Union or Member 

State law (Article 22(2)b). In the latter case, explicit and specific safeguard be not described. 

Rather, “suitable measure to safeguard the data subject” must be laid down in the relevant 

Union or Member State law. This clause potentially excludes a significant range of case of 

automate decision-making from the safeguard in Article 22(3) and any right to explanation 

derive thereof. German commentary on the GDPR have suggest that the “suitable measures” 





107 Martini (n 35) Rn. 31-32, accord to whom the necessity for the performance of a contract hinge on the 

agree goal of the contract between the data controller and the data subject. However, the author do not 

consider the vagueness of the passage and fail to address the lack of consent which be not a precondition a be it 

list under lit. C. 







37 



call for in Article 22(2)b do not include the disclosure of the algorithm use due to the risk 

pose to trade secrets; however, measure to minimise and correct discrimination and bias 

should be implemented.108 

The exemption for automate decision related to contract raise a further limitation. 

Article 22 do not define when automate decision-making be “necessary” for enter or 

perform a contract, which run the risk of ‘necessity’ be define solely by the data 

controller. Additionally, it be important to note that Article 22(2)a envisions a situation that be 

different from explicit consent (which be list a a separate exception in Article 22(2)c). 

Legislators be contemplate a situation where data controller make automate decision 

that be necessary for a contract, but without seek consent first. If consent would be 

necessary, it would have be enough to list the contractual exception under Article 22(2)c. 

This structure suggests that there can be situation in which the data subject do not consent 

to an automate decision and, apart from the general notification requirement and right of 

access in Articles 13-15, do not know about the decision. Data controller be therefore 

allow to decide that automate decision-making be necessary for contractual obligations, 

while the data subject be unable to object to it. In this case, the data subject retains the right to 

contest, express view or obtain human intervention for a decision reach under Article 22(3), 

but not to object to it be make in the first place. 

4.2.1 Two interpretation of Article 22 

Several other restriction on Article 22(3) and any future right to explanation derive thereof 

depend upon whether Article 22 be interpret a a prohibition or a right to object. Article 22(1) 

GDPR state that “the data subject shall have the right not to be subject to a decision base 

solely on automate processing, include profiling, which produce legal effect concern 

him or her or similarly significantly affect him or her.” Due to it language (“a right not to”), 

Article 22(1) can be interpret in two ways: a a prohibition109 or a right to object to automate 

decision-making. The two interpretation offer very different protection to the interest of data 

subject and data controllers. 





108 ibid Rn. 33-37. 
109 ibid Rn. 1-7, 15 argues that it be a prohibition, however it be acknowledge that the placement of Article 22 in 

the “rights section of the data subjects” cause confusion. The argument be base on the German implementation 

of the 1995 Directive into national law, which be in fact phrase a a prohibition. However, the author also 

state that the legal status (right to object or prohibition) of Article 15 of the Directive and Article 22 GDPR be 

disputed: see ibid Rn. 14 a, 29. 







38 



The first interpretation read Article 22(1) a a prohibition, meaning that data 

controller would be obligate not to engage in automate decision-making prior to show 

that a condition in Article 22(2)a-c be met. The second interpretation read Article 22(1) a 

establish for data subject a right to object to automate decision-making, which will not 

apply if one of the requirement in Article 22(2)a-c be met. These interpretation be 

differentiate by whether action be require by the data subject to restrict automate decision- 

making. The action in question, a formal objection by the data subject, require both awareness 

of the existence of automate decision-making and a willingness to intercede, both of which 

require intentional effort on the part of the data subject. 

Notably, this ambiguity have exist since the Data Protection Directive 1995.110 The 

word of Article 15 of the Directive111 allow the ‘right not to be subject of an automate 

decision’ refer to in Section 1 (“Member States shall grant the right to every person not to 

be subject to a decision which produce legal effect concern him or significantly affect 

him and which be base solely on automate processing […]” [italics added]) to be interpret 

a a prohibition or a right to object.112 The ambiguity lead Member States to implement this 

right and associate protection differently. 

Article 15 of the Directive have be implement by Austria, Belgium, Germany, 

Finland, the Netherlands, Portugal, Sweden and Ireland a a general prohibition,113 with some 

exceptions. The UK have a different model: data subject be entitle to request that no 

automate decision be make about them, but not in the case of so-called “exempt decisions.” In 





110 Bird & Bird, ‘Profiling and Automated Decision-Taking’ <http://www.twobirds.com/~/media/pdfs/gdpr- 

pdfs/35--guide-to-the-gdpr--profiling-and-automated-decisiontaking.pdf?la=en> access 10 November 2016 

explains how different country either have prohibition or right to object: “This could either be read a a 

prohibition on such processing or that the processing may take place but that individual have a right to object to 

it. This ambiguity be also present in the Data Protection Directive and Member States differ in their approach 

to the point.” 
111 Martini (n 35) Rn. 42-44 explains how the Germans make use of the margin of appreciation of Article 15 of 

the Directive and phrase it like a prohibition. 
112 

Hildebrandt (n 79) 50 hint towards but do not make it explicit: “it may be that if I don't exercise the right, 

the automate decision be not a violation of the directive.” Additionally, “the draft Regulation, however, 

stipulates that a person may only be subject to automate decision under specify conditions, imply that 

this right be not merely a right to object.” She further explains how the same can be true for the original draft 

Article 20 GDPR proposal of 25th January 2012; Bygrave (n 46) 3 see Article 15 of the Directive a 

sufficiently ambiguous to be interpret a both a prohibition and a right to object. 
113 Korff, ‘New Challenges to Data Protection Study-Working Paper No. 2’ (n 39) 84. See also p. 84 ff for further 

detail on how other Member States implement the Directive. 







39 



case where data subject have not lodge such a request, data controller have to inform them 

about the fact that an automate decision have be make a well a about the outcome.114 

Due to the similarity of language and content between Article 15 of the Directive and 

Article 22 GDPR, the vary implementation of Article 15 a a prohibition or right to object 

by Member state support the interpretation that Article 22 be ambiguous and can be read a a 

prohibition or right to object. Resolving the ambiguity prior to 2018 be critical, a the two 

interpretation have very different consequence for data subject and data controllers. 

4.2.2 Impact of the interpretation of Article 22 on a right to explanation 

If Article 22 be interpret a a prohibition, data controller will not be allow to make 

automate decision about a data subject until one of the three requirement specify in Article 

22(2) (necessary to enter or to perform a contract, authorise by law, or explicit consent) be 

met. Data subject do not need to act to prevent automate decision-making, but be rather 

protect by default. Supervisory Authorities would shoulder the burden of enforce Article 

22 by ensure automate decision-making be carry out legally, and could levy penalty and 

fine in case of illegal decision-making. Data controllers, when make automate decision 

under Article 22(2)a or c, would need to enact safeguard a specify in Article 22(3). As 

explain above (see Section 4), these safeguard could be voluntarily or legally extend to 

include a right to explanation. 

If Article 22 be interpret a a right to object, automate decision-making be restrict 

only to case in which the data subject actively objects. When an objection be entered, decision- 

make must be show to meet Article 22(2)a-c. For automate decision that meet a 

requirement of Article 22(2), the data subject cannot object. However, when Article 22(2)a or 

c be met – meaning that the decision be make under contract or with consent – the safeguard 

specify in Article 22(3) would also apply. In these cases, the data subject would be able to 

request human intervention, express her views, and contest the decision and, if enact in the 

future, demand a right to explanation (see: Section 3.1). Critically, if Article 22 grant a right 

to object automate decision-making be legally unchallenged by default, even if it do not 

meet any of the requirement set out in Article 22(2), so long a the data subject do not enter 

an objection. This limitation increase the burden on data subject to protect actively their 





114 Korff, ‘New Challenges to Data Protection Study-Country Report’ (n 51) 37 ff. 







40 



interest relate to profile and automate decision-making by monitoring and object to 

automate decision-making. 

With this comparison in mind, interpret Article 22 a a prohibition grant great 

protection by default to data subject’s interests, at least in the case in which Article 22(3) 

would apply. As a prohibition, data controller would be legally oblige to limit automate 

decision-making meeting the definition in Article 22(1) to the three case identify in Article 

22(2) (contract, Union or Member State law, consent). 

In contrast, a right to object would not pre-emptively restrict the type of automate 

decision-making undertaken by data controller to the three case define in Article 22(2). 

Rather, these restriction would only apply when a data subject lodge an objection against a 

specific instance of decision-making. At that point, process not meeting a requirement of 

Article 22(2) would need to stop, and the safeguard specify in Article 22(2)b or Article 22(3) 

would never be triggered. Article 22 a a right to object would thus circumvent a right to 

explanation introduce through Article 22(3) by allow automate decision-making not 

meeting a requirement in Article 22(2) to occur until the data subject enters an objection. Such 

‘legal’ but pre-objection decision-making would not be subject to a right to explanation derive 

from Article 22(3). With that said, a right to explanation derive from the right of access would 

not be similarly circumvented. In this case a data subject’s right to explanation would apply to 

any decision-making meeting the definition provide in Article 22(1), even if the decision- 

make prove to not meet a requirement of Article 22(2) follow the data subject’s 

objection. 

To summarise, if a right to explanation be enact in the future, at best data subject will 

only deserve an explanation when automate decision have (1) legal or similarly significant 

effects, and (2) be base solely on automate processes. Further, if a right to explanation be 

derive specifically from Article 22(3), explanation will be require only if automate 

decision-making be (3) carry out to enter or under contract, or with explicit consent; and (4) 

when override interest of the data controller (e.g. trade secrets) do not exist, a specify in 

Recital 63. Further restriction on a right to explanation derive from Article 22(3) depend 

upon the prevail interpretation of Article 22 a a prohibition or a right to object. 

To disambiguate this limited type of right to explanation from the ‘general’ right to 

explanation in future discussion of the impact of the GDPR on automate processing of data, 

and to reflect accurately the scope of limitation on any such right, we recommend address 

instead a ‘right to be informed’ about the existence of automate decision-making and system 







41 



functionality. The right to be inform address the information provide to data subject 

about automate decision-making, take into account all of the limitation on the scope of 

applicability and type of information to be provide by data controller a described in the 

precede two sections. The right to be inform further account for precedent set in the 1995 

Directive, and the impact these precedent will likely have on future interpretation of the 

GDPR’s notification duty (Articles 13-14), right of access (Article 15), and right not to be 

subject to automate decision-making (Article 22) 



5 Conclusion: the future of accountable automate decision-making 

Despite claim to the contrary, a meaningful right to explanation be not legally mandate by the 

General Data Protection Regulation. Given the proliferation of automate decision-making and 

automate processing of data to support human decision-making (i.e. ‘not solely’), this be a 

critical gap in transparency and accountability. The GDPR appear to give strong protection 

against automate decision-making but, a it stands, the protection may prove ineffectual. 

However, transparent and accountable automate decision-making can still be achieve before 

the GDPR come into force in 2018. 

A right to explanation of specific decision be not legally mandate by the safeguard 

contain in Article 22(3), or notification duty in Articles 13 and 14. As proven by the 1995 

Directive, the right of access be ambiguous. However, the GDPR’s right of access provide a 

right to explanation of system functionality, what we call a ‘right to be informed’, restrict by 

the interest of data controller and future interpretation of Article 15. Any future right to 

explanation will further be constrain by the definition of ‘automated decision-making’ in 

Article 22(1), which be limited to decision base solely on automate processing with legal or 

similarly significant effect for the data subject. As it stands, a meaningful right of explanation 

to the rationale and circumstance of specific automate decision be not forthcoming. 

Analysis of prior draft of the GDPR have reveal several tension between the 

European Parliament, Commission, and Council. The placement of the right to explanation in 

non-binding Recital 71 appear to be a purposeful change deliberate in trilogue. The EP 

generally sought strong protection for data subject against automate decision-making than 

the EC or Council. Specifically, the EP want to include a right to explanation in Article 20,115 





115 European Digital Rights (n 27) 140. 







42 



whereas the Council would have prefer to have the right to explanation in Recital 58.116 The 

EC do not include such a right at all. Further, the EP want to protect citizen from automate 

decision that have legal or significant effect when predominantly,117 and not just solely,118 

base on automate processes. Human assessment would also have be required.119 

As the GDPR be intend to unify data protection law across all European Member 

States, the interpretation of Article 22 a a prohibition or right to object be critically important. 

Which interpretation will win out in the implementation of the GDPR in 2018 be not yet clear. 

Both be viable a suggest by the split in the implementation of Article 15 in the Data 

Protection Directive 1995 by Member States. Without clarification prior to enforcement, 

Article 22 will allow for conflict interpretation of the right of data subject and controller 

concern automate decision-making across Member States. Conflicts may soon become 

inevitable because the two interpretation protect very different interests. 

Article 22 interpret a a prohibition offer great protection to the interest of data 

subject by prohibit all automate decision-making not meeting a requirement of Article 

22(2). In contrast, when interpret a a right, Article 22 creates a loophole that allows data 

controller to undertake automate decision-making without meeting a requirement in Article 

22(2), unless the data subject objects. Once an objection be entered, decision-making must be 

show to meet one of these requirement or must stop altogether. As a right, the data subject’s 

interest in not be subject to automate decision-making be undermined, insofar a 

significant effort (i.e. enter an objection) be require from the subject to protect her interests. 

Article 22 therefore roughly favour the interest of data subject when interpret a a 

prohibition, and the interest of data controller when interpret a a right. 

The ambiguity of the right not to be subject to automate decision-making (Article 22), and 

the loophole and weakness it creates, show that the GDPR be lack precise language and 

explicit and well-defined right and safeguards, and therefore run the risk of be toothless. 

Several action may be recommend to correct some of the weakness identify in our 

analysis. The follow recommendation be intend a guidance for legislative and policy 





116 ibid 40. 
117 ibid 140. 
118 Both the EC and European Council only sought protection for decision solely base on automate processing, 

see: ibid 139. 
119 ibid 140. 







43 



step to correct the deficiency we have identify in the protection afford to data subject 

against automate decision-making. 

Legislative progress can be achieve by modify the GDPR prior to it enforcement, or 

passage of additional law by Member States. Additional legislative step by Member States 

be highly likely, a see with the UK’s House of Commons’ Science and Technology 

Committee’s recent inquiry on “algorithms in decision-making,”120 which be inspire in part 

by informal consultation by ‘Sense about Science’ (a UK-based charitable trust) with the 

author of this paper. The inquiry gather expert opinion on how to achieve accountability and 

transparency in algorithmic decision-making, include identification of barrier (e.g. trade 

secrets), mechanism for oversight, and requirement to make decision explainable. As 

evidence that the recommendation make here can be the start point for new laws, the 

inquiry explicitly refers to the right and duty laid out in the GDPR. On the policy side, the 

recommendation can influence future guideline issue by body such a the Article 29 

Working Party, the European Data Protection Board, the European Data Protection Supervisor, 

and it Ethics Advisory Group. 

We make the follow recommendations: 



1) Add a right to explanation to legally binding Article 22(3) 

If a right to explanation be intend a suggest in Recital 71, it should be explicitly add to 

a legally binding Article of the GDPR. Such an implementation should clarify the scope of 

applicability of the right with regard to the impact of Article 22 interpret a a prohibition or 

right to object. Alternatively, Member States can be encourage to implement law on top of 

the GDPR that require an explanation of specific decisions. A right to explanation of specific 

decision could be consider a suitable safeguard necessitate by Article 22(2)b and 22(3) if 

an explanation be necessary to contest a decision, a already prescribed in 22(3). The right to 

contest a decision, to obtain human intervention or to express view grant in Article 22(3) 

may be meaningless if the data subject cannot understand how the contest decision be 

made. To this end, a right to explanation can be introduce require data controller to provide 

information about the rationale of the contest decision. Clear requirement should be 





120 Commons Select Committee, ‘Algorithms in Decision-Making Inquiry Launched’ (UK Parliament, 2017) 

<http://www.parliament.uk/business/committees/committees-a-z/commons-select/science-and-technology- 

committee/news-parliament-2015/algorithms-in-decision-making-inquiry-launch-16-17/> access 8 March 

2017. 







44 



introduce state the evidence to be supply by the data controller. Evidence regard the 

weight of features, decision tree or classification structure, and general logic of the decision- 

make system may be sufficient. However, the risk for innovation and beneficial processing 

pose by a right to explanation that require automate decision-making method to be human 

interpretable should be seriously considered.121 



2) Clarify the meaning of the “existence of,” “meaningful information,” “logic involved,” 

“significance,” and “envisaged consequences” in Article 15(1)h to indicate a ‘right to 

be informed’ 

The language and meaning of core concept in Article 15 be ambiguous. This leaf open the 

possibility of a right to explanation of the rationale of specific decision (see Section 3.3.2). 

However, this interpretation be implausible for a number of reasons. As explain in Section 

3.3, the semantics and history of the right to access, and the duplication of provision in Articles 

13-14, suggest that the right of access be intend merely a a counterweight to the notification 

duty of data controllers, and not a a mean to introduce a new right (i.e. a right to explanation 

of specific decisions) beyond the scope of Articles 13-14.122 Critically, interpret Article 15 

to introduce a right to explanation of specific decision would not match the intend purpose 

of the right of access, which accord to Recital 63 GDPR be meant to allow the data subject 

“to be aware of, and verify, the lawfulness of processing.” Language should be add to clarify 

that Article 15 be intend either a a counterweight to Articles 13-14, and thus provide a 

limited ‘right to be informed’ about the existence of automate decision-making a well a 

system functionality, or a a right to explanation of specific decisions. The intend meaning 

of the five core concept of Article 15(1)h should be make explicit, and their impact on the 

information require for data controller to communicate to data subject under the right to 

access (and, similarly, Articles 13-14 notification duties). 



3) Clarify the language of Article 22(1) to indicate when decision be base solely on 

automate processing 

Article 22 be limited in applicability to decision base solely on automate processing. 

However, it be unclear what the phrase mean in practice. The potential loophole (similarly 





121 Mittelstadt and others (n 7). 
122 Paal (n 33) Rn. 19-22. 







45 



see in the German SCHUFA judgments), by which nominal involvement of a human at any 

stage of the automate process mean the process be not solely automated, should be closed. 

There be still uncertainty if the usage of automate process for the preparation of a decision 

constitutes solely automate processes, if the human that take the final decision do not wish 

to interfere or to adopt the decision. Clarification can be offer by return to the phrasing 

“solely or predominantly base on” propose by the EP123 in Article 20(5), or by provide 

specific example of decision-making base solely and predominantly on automate 

processing of data. 



4) Clarify the language of Article 22(1) to indicate what count a a legal or significant 

effect of automate decision, include profile 

Article 22 only applies for automate decision-making with “legal effects” or “similarly 

significant effects.”124 Recital 71 only name two example of such effects: automatic refusal 

of an online credit application and e-recruiting practices. The scope of these phrase should be 

make explicit: do they, for instance, refer only to effect identify in the Articles of the GDPR, 

or to some broader definition? At a minimum, the perspective to be take in define 

“significant effects” should be identified. Do effect need to be significant from the subjective 

perspective of the data subject or accord to some external standard? 



5) Clarify the language of Article 22(2)a, “necessary for entering, or performance of a 

contract” 

Article 22(2)a name this case a an exception of either the prohibition of automate decision- 

make or the right to object to automate decision-making. Since it be likely that the necessity 

of such measure will be define by the data controller and lit (a) do not require consent of 

the data subject (since this be a separate exception list under lit (c), this exemption run the 

risk of weaken the right of data subjects. 



6) Clarify the language of Article 22 to indicate a prohibition 





123 European Parliament Committee on Civil Liberties, Justice and Home Affairs (n 25). 
124 As already propose by the Article 29 Working Party, see Article 29 Data Protection Working Party, ‘Advice 

Paper on Essential Elements of a Definition and a Provision on Profiling within the EU General Data 

Protection Regulation’ (2013) 29 <http://ec.europa.eu/justice/data-protection/article-29/documentation/other- 

document/files/2013/20130513_advice-paper-on-profiling_en.pdf> access 10 March 2017. 







46 



Ideally, the language that allows for two plausible interpretation should be clarify prior to 

2018 when the GDPR come into force. Due to the number of loophole and weaken of 

Article 22(3) safeguard introduce if Article 22 be interpret a a right to object, a well a 

wide implementation of Article 15 of the 1995 Directive a a prohibition, we recommend that 

the language use in Article 22(2) (“Paragraph 1 shall not apply if the decision:”) be revise to 

indicate clearly and explicitly that Article 22 be intend a a prohibition against automate 

decision-making. 



7) As a counterweight to trade secrets, introduce an external audit mechanism for 

automate decision-making, or set internal audit requirement for data controller 

Both the right of access and any future right to explanation will face significant limitation due 

to the sensitivity of trade secret and intellectual property rights. As our examination of the 

1995 Directive shows, explanation grant under the right of access be normally limited to 

system functionality and significantly limited to protect data controller interests. An ideal 

solution would allow for examination of automate decision-making systems, include the 

rationale and circumstance of specific decisions, by a trust third party. This approach limit 

the risk to data controller of expose trade secrets, while also provide an oversight 

mechanism for data subject that can operate when explanation be infeasible or too complex 

for lay comprehension. The power of Supervisory Authorities could be expand in this 

regard. Alternatively, a European regulator could be create specifically for audit 

algorithms, before (certifications) and/or after algorithm be be deployed.125 



8) Support further research into the feasibility of explanation alternative accountability 

mechanism 

Even if a right to explanation be legally grant in the future, the feasibility and practical 

requirement to offer explanation to data subject remain unclear. In line with current work 

on interpretable automate decision-making and machine learn methods,126 research need 





125 Comparable approach to regulate Big Data and algorithm have be suggest by: Viktor Mayer- 

Schönberger and Kenneth Cukier, Big Data : A Revolution That Will Transform How We Live, Work and Think 

(John Murray 2013); Andrew Tutt, ‘An FDA for Algorithms’ (Social Science Research Network 2016) SSRN 

Scholarly Paper ID 2747994 <http://papers.ssrn.com/abstract=2747994> access 13 April 2016. 
126 For a detailed discussion on regulatory and interpretability issue related to algorithms, see: Danielle Keats 

Citron and Frank A Pasquale, ‘The Scored Society: Due Process for Automated Predictions’ (Social Science 

Research Network 2014) SSRN Scholarly Paper ID 2376209 <https://papers.ssrn.com/abstract=2376209> 







47 



to be conduct in parallel to determine whether and how explanation can and should be 

offer to data subject (or proxy thereof) with differ level of expertise and interests. 

What count a a meaningful explanation for one individual or group may not be meaningful 

for another; requirement for ‘meaningful explanations’ must be set if a legal right to 

explanation be to be practically useful. The right to explanation be also not the only way to 

achieve accountability and transparency in automate decision-making.127 Further attention 

should be give to the development and deployment of alternative legal safeguard that can 

supplement the protection offer by the GDPR. Data controller work in highly sensitive 

or risky sector could, for instance, be require to use human interpretable decision-making 

methods.128 Methods and (ethical) requirement for audit algorithms129 should also be 

further developed, both a standalone accountability tool and a mechanism to provide an 

evidence trail for provide explanation of automate decisions. 



As the ambiguity highlight in these recommendation indicate, the GDPR can be a toothless 

or powerful mechanism to protect data subject depend on it eventual legal interpretation. 

The effectiveness of the new framework will largely be determine by Supervisory Authorities, 

the Article 29 Working Party, the European Data Protection Board, the European Data 

Protection Supervisor, it Ethics Advisory Group,130 a well a national court and their future 

judgments.131 As it stands, transparent and accountable automate decision-making be not yet 

guaranteed by the GDPR; nor be a right to explanation of specific decision forthcoming. At 

best, data subject will be grant a ‘right to be informed’ about the existence of automate 

decision-making and system functionality. These shortcoming should be address before the 

GDPR come into force in 2018. 





access 4 March 2017; Alfredo Vellido, José David Martín-Guerrero and Paulo JG Lisboa, ‘Making Machine 

Learning Models Interpretable.’, ESANN (Citeseer 2012). 
127 For additional discussion of transparency and the GDPR, see: Dimitra Kamarinou, Christopher Millard and 

Jatinder Singh, ‘Machine Learning with Personal Data’ 

<https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2865811> access 8 March 2017. 
128 Burrell (n 13). 
129 Sandvig and others (n 8); Mittelstadt and others (n 7); Brent Mittelstadt, ‘Auditing for Transparency in Content 

Personalization Systems’ (2016) 10 International Journal of Communication 12. See also the discussion of ex post 

test of outcomes, and ex ante acceptability of error in Zarsky (n 91). 
130 Disclosure: Luciano Floridi be a member of the European Data Protection Supervisors’ Ethics Advisory Group. 
131 

Article 83(5)b invests supervisory authority with the power to impose fine up to 4% of the total 

worldwide annual turnover in case where right of the data subject (Article 12 to 22) have be infringed. This 

lever can be use to enforce compliance and to enhance data protection. 


