


















































Interpretable Classification Models for Recidivism Prediction 

Jiaming Zeng†, Berk Ustun†, Cynthia Rudin 

†These author contribute equally to this work. 

Summary. We investigate a long-debated question, which be how to create predictive model of re- 
cidivism that be sufficiently accurate, transparent, and interpretable to use for decision-making. This 
question be complicate a these model be use to support different decisions, from sentencing, to 
determine release on probation, to allocate preventative social services. Each case might have an 
objective other than classification accuracy, such a a desire true positive rate (TPR) or false positive 
rate (FPR). Each (TPR, FPR) pair be a point on the receiver operator characteristic (ROC) curve. We 
use popular machine learn method to create model along the full ROC curve on a wide range of 
recidivism prediction problems. We show that many method (SVM, SGB, Ridge Regression) produce 
equally accurate model along the full ROC curve. However, method that design for interpretability 
(CART, C5.0) cannot be tune to produce model that be accurate and/or interpretable. To handle this 
shortcoming, we use a recent method call Supersparse Linear Integer Models (SLIM) to produce ac- 
curate, transparent, and interpretable score system along the full ROC curve. These score system 
can be use for decision-making for many different use cases, since they be just a accurate a the 
most powerful black-box machine learn model for many applications, but completely transparent, 
and highly interpretable. 

Keywords: recidivism, machine learning, interpretability, score systems, binary classification 

1. Introduction 

Forecasting have be use for criminology application since the 1920s (Borden, 1928; Burgess, 1928) when 
various factor derive from age, race, prior offense history, employment, grades, and neighborhood back- 
ground be use to estimate success of parole. Many thing have change since then, include the fact that 
we have developed machine learn method that can produce accurate predictive models, and have collect 
large high-dimensional datasets on which to apply them. 

Recidivism prediction be still extremely important. In the United States, for example, a minority of indi- 
viduals commit the majority of the crime (Wolfgang, 1987): these be the “power few” of Sherman (2007) 
on which we should focus our efforts. We want to ensure that public resource be direct effectively, be they 
correctional facility or preventative social services. Milgram (2014) recently discuss the critical impor- 
tance of accurately predict if an individual who be release on bail pose a risk to public safety, point 
out that high-risk individual be be release 50% of the time while low-risk individual be be release 
less often then they should be. Her observation be in line with longstanding work on clinical versus actuarial 
judgment, which show that humans, on their own, be not a good at risk assessment a statistical model 
(Dawes et al., 1989; Grove and Meehl, 1996). This be the reason that several U.S. state have mandate the use 
of predictive model for sentence decision (Pew Center of the States, Public Safety Performance Project, 
2011; Wroblewski, 2014). 

There have be some controversy a to whether sophisticated machine learn method (such a random 
forests, see e.g., Breiman, 2001b; Berk et al., 2009; Ritter, 2013) be necessary to produce accurate predictive 
model of recidivism, or if traditional approach such a logistic regression or linear discriminant analysis 
would suffice (see e.g., Tollenaar and van der Heijden, 2013; Berk and Bleich, 2013; Bushway, 2013). Random 
forest may produce accurate predictive models, but these model effectively operate a black-boxes, which 
make it difficult to understand how the input variable be produce a predict outcome. If a simpler, more 
transparent, but equally accurate predictive model could be developed, it would be more usable and defensible 
for many decision-making applications. There be a precedent for use such model in criminology (Steinhart, 
2006; Andrade, 2009); Ridgeway (2013) argues that a “decent transparent model that be actually use will 
outperform a sophisticated system that predicts good but sits on a shelf.” This discussion be capture nicely 
by Bushway (2013), who contrast the work of Berk and Bleich (2013) and Tollenaar and van der Heijden 

ar 
X 

iv 
:1 

50 
3. 

07 
81 

0v 
6 

[ 
st 

at 
.M 

L 
] 

8 
J 

ul 
2 

01 
6 



2 Zeng, Ustun, and Rudin 

(2013). Berk and Bleich (2013) claim we need sophisticated machine learn method due to their substantial 
benefit in accuracy, whereas Tollenaar and van der Heijden (2013) claim that “modern statistical, data mining 
and machine learn model provide no real advantage over logistic regression and LDA,” assume that 
human have do appropriate pre-processing. In this work, we argue that the answer to the question be far 
more subtle than a simple yes or no. 

In particular, the answer depends on how the model will be use for decision-making. For each use case 
(e.g., sentencing, parole decisions, policy interventions), one might need a decision point at a different level of 
true positive rate (TPR) and false positive rate (FPR) (see also Ritter, 2013). Each (TPR, FPR) pair be a point on 
the receiver operator characteristic (ROC) curve. To determine if one method be good than another, one must 
consider the appropriate point along the ROC curve for decision-making. As we show, for a wide range of 
recidivism prediction problems, many machine learn method (support vector machines, random forests) 
produce equally accurate predictive model along the ROC curve. However, there be trade-off between 
accuracy, transparency, and interpretability: method that be design to yield transparent model (CART, 
C5.0) cannot be tune to produce a accurate model along the ROC curve, and do not always yield model 
that be interpretable. This be not to say that interpretable model for recidivism prediction do not exist. The 
fact that many machine learn method produce model with similar level of predictive accuracy indicates 
that there be a large class of approximately-equally-accurate predictive model (called the “Rashomon” effect 
by Breiman 2001a). In this case, there may exist interpretable model that also attain the same level of 
accuracy. Finding model that be accurate and interpretable, however, be computationally challenging. 

In this paper, we explore whether such accurate-yet-interpretable model exist and how to find them. To 
this end, we use a new machine learn method know a a Supersparse Linear Integer Model (SLIM; Ustun 
and Rudin, 2015) to learn score system from data. Scoring system that have use for many criminal justice 
application because they let user make quick prediction by adding, subtract and multiply a few small 
number (see e.g., Hoffman and Adelberg, 1980; U.S. Sentencing Commission, 1987; Pennsylvania Commis- 
sion on Sentencing, 2012). In contrast to exist tools, which have be built use heuristic approach (see 
e.g., Gottfredson and Snyder, 2005), the model built by SLIM be fully optimize for accuracy and sparsity, 
and can handle additional constraint (e.g., bound on the false positive rate, monotonicity property for the 
coefficients). We use SLIM to produce a set of simple score system at different decision point across the 
full ROC curve, and provide a comparison with other popular machine learn methods. Our finding show 
that the SLIM score system be often just a accurate a the most powerful black-box machine learn 
models, but transparent and highly interpretable. 

1.1. Structure 
The remainder of this paper be structure a follows. In Section 1.2, we discus related work. In Section 2, we 
describe how we derive 6 recidivism prediction problems. In Section 3, we provide a brief overview of SLIM 
and describe several new technique that can reduce the computation require to produce score systems. 
In Section 4, we compare the accuracy and interpretability of model produce by the 9 machine learn 
method on the 6 recidivism prediction problems. We include additional result related to the accuracy and 
interpretability of model from different method in the Appendix. 

1.2. Related Work 
Predictive model for recidivism have be in widespread use in different country and different area of 
the criminal justice system since the early 1920s (see e.g., Borden, 1928; Burgess, 1928; Tibbitts, 1931). 
The use of these tool have be spur on by continued research into the superiority of actuarial judgment 
(Dawes et al., 1989; Grove and Meehl, 1996) a well a a desire to efficiently use limited public resource 
(Clements, 1996; Simon, 2005; McCord, 1978, 2003). In the U.S., federal guideline currently mandate 
the use of a predictive recidivism measure know a the Criminal History Category for sentence (U.S. 
Sentencing Commission, 1987). Besides the U.S., country that currently use risk assessment tool include 
Canada (Hanson and Thornton, 2003), the Netherlands (Tollenaar and van der Heijden, 2013), and the U.K. 
(Howard et al., 2009). Applications of these tool can be see in evidence-based sentence (Hoffman, 1994), 
correction and prison administration (Belfrage et al., 2000), inform release on parole (Pew Center of the 
States, Public Safety Performance Project, 2011), determine the level of supervision during parole (Barnes 



Interpretable Classification Models for Recidivism Prediction 3 

and Hyatt, 2012; Ritter, 2013), determine appropriate sanction for parole violation (Turner et al., 2009), 
and target policy intervention (Lowenkamp and Latessa, 2004). 

Our paper focus on binary classification model to predict general recidivism (i.e., recidivism of any type 
of crime) a well a crime-specific recidivism (i.e., recidivism for drug, general violence, domestic violence, 
sexual violence, and fatal violence offenses). Risk assessment tool for general recidivism include: the Salient 
Factor Score (Hoffman and Adelberg, 1980; Hoffman, 1994), the Offender Group Reconviction Scale (Copas 
and Marshall, 1998; Maden et al., 2006; Howard et al., 2009), the Statistical Information of Recidivism scale 
(Nafekh and Motiuk, 2002), and the Level of Service/Case Management Inventory (Andrews and Bonta, 
2000). Crime-specific application include risk assessment tool for domestic violence (see e.g., the Spousal 
Abuse Risk Assessment of Kropp and Hart, 2000), sexual violence (see e.g., Hanson and Thornton, 2003; 
Langton et al., 2007), and general violence (see e.g., Historical Clinical and Risk Management tool of Webster 
et al. 1997, or the Structured Assessment of Violence Risk in Youth tool of Borum 2006). 

The score system that we present in this paper be design to mimic the form of risk score that be 
currently use throughout the criminal justice system – that is, linear classification model that only require 
user to add, subtract and multiply a few small number to make a prediction (Ustun and Rudin, 2015). These 
tool be unique in that they allow user make quick prediction by hand, without a computer, calculator, 
or nomogram (which be a visualization tool for more difficult calculations). Current example of such tool 
include: the Salient Factor Score (SFS) (Hoffman and Adelberg, 1980), the Criminal History Category (CHC) 
(U.S. Sentencing Commission, 1987), and the Offense Gravity Score (OGS) (Pennsylvania Commission on 
Sentencing, 2012). Our approach aim to produce score system that be fully optimize for accuracy and 
sparsity without any post-processing. In contrast, current tool be produce through heuristic approach that 
primarily involve logistic regression with some ad-hoc post processing to ensure that the model be sparse 
and use integer coefficient (see e.g., the method described in Gottfredson and Snyder, 2005). 

Our score system differ from exist tool in that they directly output a predict outcome (i.e., prisoner 
i will recidivate) a oppose to an predict probability of the outcome (i.e. the predict probability that 
prisoner i will recidivate be 90%). The predict probability from exist tool be typically convert into 
an outcome by impose a threshold (i.e., classify a prisoner a “high-risk” if the predict probability of 
arrest > 70%). In practice, user arbitrarily pick several threshold to translate predict probability into 
an ordinal outcome (e.g., prisoner i be “low risk,” if the predict probability be < 30%, “medium risk” if the 
predict probability is< 60%, and “high risk” otherwise). These arbitrary threshholds make it difficult, if not 
impossible, to effectively ass the predictive accuracy of the tool (Hannah-Moffat, 2013). Netter (2007), 
for instance, mention that “the possibility of make a prediction error (false positive or false negative) use 
a risk tool be probable, but not easily determined.” In contrast to exist tools, the score system let user 
ass accuracy in a straightforward way (i.e., through the true positive rate and true negative rate). Further, 
our approach have the advantage that be can yield a score system that optimizes the class-based accuracy at a 
particular decision point (i.e., produce the model that maximizes the true positive rate, give a false-positive 
rate of at most 30%). 

Our work be related to a stream of research that have aim to leverage new method for predictive model 
in criminology. In contrast to our work, much of the research to date have focus on improve predictive 
accuracy by training powerful black-box model such a random forest (Breiman, 2001b) and stochastic 
gradient boost Friedman (2002). Random forest (Breiman, 2001b), in particular, have be use for 
several criminological applications, including: predict homicide offender recidivism (Neuilly et al., 2011); 
predict serious misconduct among incarcerate prisoner (Berk et al., 2006); forecasting potential murder 
for criminal on probation or parole (Berk et al., 2009); forecasting domestic violence and help inform court 
decision at arraignment (Berk and Sorenson, 2014). We note that not all study in use black-box models: 
Berk et al. (2005), for instance, help the Los Angeles Sheriff’s Department develop a simple and practical 
screener to forecast domestic violence use decision trees. More recently, (Goel et al., 2015), developed a 
simple score system to help the New York Police Department address stop and frisk by first run logistic 
regression, and then round the coefficients. 

2. Data and Prediction Problems 

Each problem be a binary classification problem with N = 33, 796 prisoner and P = 48 input variables. 
The goal be to predict whether a prisoner will be arrest for a certain type of crime within 3 year of be 



4 Zeng, Ustun, and Rudin 

release from prison. In what follows, we describe how we create each prediction problem. 

2.1. Database Details 
We derive the recidivism prediction problem in our paper from the “Recidivism of Prisoners Released in 
1994” database, assemble by the U.S. Department of Justice, Bureau of Justice Statistics (2014). It be the 
large publicly available database on prisoner recidivism in the United States. The study tracked 38,624 
prisoner for 3 year follow their release from prison in 1994. These prisoner be randomly sample 
from the population of all prisoner release from 15 U.S. state (Arizona, California, Delaware, Florida, 
Illinois, Maryland, Michigan, Minnesota, New Jersey, New York, North Carolina, Ohio, Oregon, Texas, and 
Virginia). The sample population account for roughly two-thirds of all prisoner that be release from 
prison in the U.S. in 1994. Other study that use this database include: Bhati and Piquero (2007); Bhati 
(2007); Zhang et al. (2009). 

The database be compose of 38,624 row and 6,427 columns, where each row represent a prisoner and 
each column represent a feature (i.e. a field of information for a give prisoner). The 6,427 column consist of 
91 field that be record before or during release from prison in 1994 (e.g., date of birth, effective sentence 
length), and 64 field that be repeatedly record for up to 99 different arrest in the 3 year follow-up period 
(e.g., if a prisoner be rearrested three time with 3 years, there would be three record cycle recorded). The 
information for each prisoner be source from record-of-arrest-and-prosecution (RAP) sheet kept by state 
law enforcement agency and/or the FBI. A detailed descriptive analysis of the database be carry out 
by statistician at the U.S. Bureau of Justice Statistics (Langan and Levin, 2002). This study restrict it 
attention to 33,796 of the 38,624 prisoner to exclude extraordinary or unrepresentative release cases. To be 
select for the analysis of Langan and Levin (2002), a prisoner have to be alive during the 3 year follow-up 
period, and have to have be release from prison in 1994 for an original sentence that be at least 1 year 
or longer. Prisoners with certain release type – release to custody/detainer/warrant, absent without leave, 
escape, transfer, administrative release, and release on appeal – be excluded. To mirror the approach of 
Langan and Levin (2002), we restrict our attention to the same subset of prisoners. 

This dataset have some serious flaw which we point out below. To begin, many important factor that could 
be use to predict recidivism be missing, and many include factor be noisy enough to be exclude from 
our preliminary experiments. The information about education level be extremely minimal; we do not even 
know whether each prisoner attend college, or complete high school. The information about course in 
prison be only an indicator of whether the inmate take any education or vocation course at all. Also, there be 
no family history for each prisoner (e.g., foster care) and no record of visitor while in prison (e.g., indicator 
of care family member or friends). There be no information about reentry program or employment history. 
While some of these factor exist, such a drug or alcohol treatment and in-prison vocational programs, the 
data be highly incomplete and therefore exclude from our analysis. For example, for drug treatment, less than 
14% of the prisoner have a valid entry. The rest be “unknown.” To include a many prisoner a possible, 
we chose to exclude factor with extremely sparse information. 

2.2. Deriving Input Variables 
We provide a summary of the P = 48 input variable derive from the database in Table 1. We encode each 
input variable a a binary rule of the form xij ∈ {0, 1}, j = 1 . . . , P , where xij = 1 if condition j hold true 
about prisoner i. This allows a linear model to encode nonlinear function of the original variables. We refer 
to input variable in the text use italicize font (e.g., female). All prediction problem in Table 2 and all 
machine learn method in Table 4 use these same input variables. 

The final set of input variable be representative of well-known risk factor for recidivism (Bushway 
and Piehl, 2007; Crow, 2008) and have be use in risk assessment tool since 1928 (see e.g., Borden, 
1928; Ricardo H. Hinojosa et al., 2005; Berk et al., 2006; Baradaran, 2013). They include: 1) information 
about prison release in 1994 (e.g., time served, age at release, infraction in prison); 2) information from 
past arrests, sentencing, and conviction (e.g., prior arrests≥1, any prior jail time);1 3) history of substance 
abuse (e.g., alcohol abuse) 4) gender (e.g., female). These input variable be advantageous because: a) the 

1The prior arrest variable do not count the original crime for which they be release from prison in 1994; thus, 
about 12% of the prisoner have no prior arrest =1 even though they be arrest at least once. 



Interpretable Classification Models for Recidivism Prediction 5 

information be easily accessible to law enforcement official (all above information can be found in state 
RAP sheets); b) they do not include socioeconomic factor such a race, which would directly eliminate the 
potential to use these tool in application such a sentencing. 

We note that encode the input variable a binary value present many advantages. They produce 
model that be easy to understand (removing the wide range present by continuous variables), and they 
avoid potential confusion stem from coefficient of normalize input (for instance, after undo the 
normalization for normalize coefficients, a small coefficient might be highly influential if it applies to a 
variable take large values). Binarization be especially useful for SLIM a we can fit SLIM model by 
solve a slightly easy discrete optimization problem when the data only contains binary input variable 
(as discuss in Section 3.3). In Appendix E, we explore the change in predictive accuracy if continuous 
variable be include and show that the change in performance be minor for most methods. There be some 
exceptions; for example, CART and C5.0T experienced an improvement of 4.6% for drug and SVM RBF 
experienced a 7.7% improvement for fatal violence. Yet even for these methods, no clear improvement 
be see across all problems. 

2.3. Deriving Outcome Variables 
We create a total of 6 recidivism prediction problem by encode a binary outcome variable yi ∈ {−1,+1} 
such that yi = +1 if a prisoner be arrest for a particular type of crime within 3 year after be release 
from prison. For clarity, we refer to each prediction problem in the text use typewriter font (e.g., arrest). 
We provide detail on each recidivism prediction problem in Table 2. These include: an arrest for any 
crime (arrest); an arrest for a drug-related offense (drug); or an arrest for a certain type of violent offense 
(general violence, domestic violence, sexual violence, fatal violence). 

In the dataset, all crime type can be broken down into small subcategories (e.g., fatal violence 
can be broken into 6 subcategories such a murder, vehicular manslaughter, etc.). We chose to use 
the broader crime category for the sake of conciseness and clarity. Indeed, the study by Langan and Levin 
(2002) also split the crime into the same major categories. We note that the outcome of violent offense be 
mutually exclusive, a different type of violence be treat differently within the U.S. legal system. In other 
words, yi = +1 for general violence do not necessarily imply yi = +1 for domestic violence, 
sexual violence, fatal violence). 



6 Zeng, Ustun, and Rudin 

Table 1. Overview of input variable for all prediction problems. Each variable be a binary rule of the form 
xij ∈ {0, 1}. We list condition require for xij = 1 under the Definition column. 
Input Variable P(xij = 1) Definition 
female 0.06 prisoner i be female 
prior alcohol abuse 0.20 prisoner i have history of alcohol abuse 
prior drug abuse 0.16 prisoner i have history of drug abuse 
age at release≤17 0.00 prisoner i be ≤17 year old at release in 1994 
age at release 18 to 24 0.19 prisoner i be 18-24 year old at release in 1994 
age at release 25 to 29 0.21 prisoner i be 25-29 year old at release in 1994 
age at release 30 to 39 0.38 prisoner i be 30-39 year old at release in 1994 
age at release≥40 0.21 prisoner i be ≥40 year old at release in 1994 
release unconditional 0.11 prisoner i release at expiration of sentence 
release conditional 0.87 prisoner i release by parole or probation 
time served≤6mo 0.23 prisoner i serve ≤6 month 
time serve 7 to 12mo 0.20 prisoner i serve 7–12 month 
time serve 13 to 24mo 0.23 prisoner i serve 13–24 month 
time serve 25 to 60mo 0.25 prisoner i serve 25–60 month 
time served≥61mo 0.10 prisoner i serve ≥61 month 
infraction in prison 0.24 prisoner i have a record of misconduct in prison 
age 1st arrest≤17 0.14 prisoner i be ≤17 year old at 1st arrest 
age 1st arrest 18 to 24 0.61 prisoner i be 18-24 year old at 1st arrest 
age 1st arrest 25 to 29 0.10 prisoner i be 25-29 year old at 1st arrest 
age 1st arrest 30 to 39 0.09 prisoner i be 30-39 year old at 1st arrest 
age 1st arrest≥40 0.04 prisoner i be ≥40 year at 1st arrest 
age 1st confinement≤17 0.03 prisoner i be ≤17 year old at 1st confinement 
age 1st confinement 18 to 24 0.46 prisoner i be 18-24 year old at 1st confinement 
age 1st confinement 25 to 29 0.18 prisoner i be 25-29 year old at 1st confinement 
age 1st confinement 30 to 39 0.21 prisoner i be 30-39 year old at 1st confinement 
age 1st confinement≥40 0.12 prisoner i be ≥40 year at 1st confinement 
prior arrest for drug 0.47 prisoner i be once arrest for drug offense 
prior arrest for property 0.67 prisoner i be once arrest for property offense 
prior arrest for public order 0.62 prisoner i be once arrest for public order offense 
prior arrest for general violence 0.52 prisoner i be once arrest for general violence 
prior arrest for domestic violence 0.04 prisoner i be once arrest for domestic violence 
prior arrest for sexual violence 0.03 prisoner i be once arrest for sexual violence 
prior arrest for fatal violence 0.01 prisoner i be once arrest for fatal violence 
prior arrest for multiple type 0.77 prisoner i be once arrest for multiple type of crime 
prior arrest for felony 0.84 prisoner i be once arrest for a felony 
prior arrest for misdemeanor 0.49 prisoner i be once arrest for a misdemeanor 
prior arrest for local ordinance 0.01 prisoner i be once arrest for local ordinance 
prior arrest with firearm involve 0.09 prisoner i be once arrest or an incident involve firearm 
prior arrest with child involve 0.17 prisoner i be once arrest for an incident involve child 
no prior arrest 0.12 prisoner i have no prior arrest 
prior arrests≥1 0.88 prisoner i have at least 1 prior arrest 
prior arrests≥2 0.78 prisoner i have at least 2 prior arrest 
prior arrests≥5 0.60 prisoner i have at least 5 prior arrest 
multiple prior prison time 0.43 prisoner i have be to prison multiple time 
any prior jail time 0.47 prisoner i have be to jail at least once 
multiple prior jail time 0.29 prisoner i have be to prison multiple time 
any prior probation or fine 0.42 prisoner i have be on probation or paid a fine at least once 
multiple prior probation or fine 0.22 prisoner i have be on probation or paid a fine multiple time 



Interpretable Classification Models for Recidivism Prediction 7 

Table 2. Overview of recidivism prediction problems. The percentage P (yi = +1) do not add up to 100% 
because a prisoner could be arrest for multiple type of crime at one time (e.g., both drug and public 
order offenses), and could also be arrest multiple time over the 3 year follow-up period. 

Prediction Problem P(yi = +1) Outcome Variable 

arrest 59.0% 
yi = +1 if prisoner i be arrest for any offense within 3 year of release 
from prison 

drug 20.0% 
yi = +1 if prisoner i be arrest for drug-related offense (e.g., posses- 
sion, trafficking) within 3 year of release from prison 

general violence 19.1% 
yi = +1 if prisoner i be arrest for a violent offense (e.g., robbery, 
aggravate assault) within 3 year of release from prison 

domestic violence 3.5% 
yi = +1 if prisoner i be arrest for domestic violence within 3 year of 
release from prison 

sexual violence 3.0% 
yi = +1 if prisoner i be arrest for sexual violence within 3 year of 
release from prison 

fatal violence 0.7% 
yi = +1 if prisoner i be arrest for murder or manslaughter within 3 
year of release from prison 

2.4. Relationships between Input and Output Variables 
Table 3 list the conditional probability P (y = 1|xj = 1) between the outcome variable y and each input 
variable xj for all prediction problems. Using this table, we can identify strong association between the input 
and output for each prediction problem. These association can help uncover insight into each problem and 
also help qualitatively validate predictive model in Section 4.4. 

Consider, for instance, the arrest problem. Here, we can see that prisoner who be release from 
prison at a late age be less likely to be arrest (as the probability for arrest decrease monotonically a 
age at release increases). This also appear to be the case for prisoner who be first confine (i.e., sent to 
prison or jail) at an old age (see e.g., age of first confinement). In addition, we can also see that prisoner 
with more prior arrest have a high likelihood of be arrest (as the probability for arrest increase 
monotonically with prior arrest). 

Similar insight can be make for crime-specific prediction problems. In drug, for instance, we see that 
prisoner who be previously arrest for a drug-related offense be more likely to be rearrested for a drug- 
related offense (32%) than those who be previously arrest for any other type of offense. Likewise, look 
at domestic violence, we see that the prisoner with the great probability of be arrest for a do- 
mestic violence crime be those with a history of domestic violence (13%). 



8 Zeng, Ustun, and Rudin 

Table 3. Table of conditional probability for all input variable (row) and prediction problem (columns). Each 
cell represent the conditional probability P (y = +1|x = +1) where x be the input variable that be specify in the 
row and y be the outcome variable for the prediction problem specify in the column. 

Input Variable Prediction Problem 

arrest drug 
general 
violence 

domestic 
violence 

sexual 
violence 

fatal 
violence 

female 0.54 0.21 0.11 0.02 0.01 0.0005 
prior alcohol abuse 0.58 0.18 0.20 0.04 0.03 0.01 
prior drug abuse 0.61 0.23 0.21 0.03 0.03 0.004 
age at release≤17 0.84 0.35 0.31 0.01 0.01 0.04 
age at release 18 to 24 0.71 0.24 0.25 0.04 0.03 0.01 
age at release 25 to 29 0.66 0.23 0.21 0.04 0.03 0.01 
age at release 30 to 39 0.59 0.20 0.17 0.04 0.03 0.01 
age at release≥40 0.41 0.12 0.09 0.02 0.03 0.003 
release unconditional 0.65 0.20 0.23 0.06 0.04 0.01 
release conditional 0.58 0.20 0.17 0.03 0.03 0.01 
time served≤6mo 0.67 0.27 0.19 0.04 0.03 0.01 
time serve 7 to 12mo 0.63 0.22 0.19 0.04 0.03 0.01 
time serve 13 to 24mo 0.59 0.20 0.17 0.04 0.03 0.01 
time serve 25 to 60mo 0.53 0.16 0.17 0.03 0.03 0.01 
time served≥61mo 0.48 0.11 0.15 0.02 0.04 0.004 
infraction in prison 0.65 0.19 0.20 0.01 0.04 0.01 
age 1st arrest≤17 0.73 0.27 0.27 0.04 0.04 0.01 
age 1st arrest 18 to 24 0.64 0.22 0.20 0.04 0.03 0.01 
age 1st arrest 25 to 29 0.47 0.14 0.10 0.02 0.02 0.005 
age 1st arrest 30 to 39 0.34 0.10 0.06 0.02 0.02 0.003 
age 1st arrest≥40 0.21 0.05 0.03 0.01 0.02 0.002 
age 1st confinement≤17 0.78 0.28 0.29 0.04 0.04 0.02 
age 1st confinement 18 to 24 0.68 0.24 0.23 0.05 0.04 0.01 
age 1st confinement 25 to 29 0.60 0.20 0.17 0.03 0.03 0.005 
age 1st confinement 30 to 39 0.50 0.16 0.12 0.03 0.02 0.003 
age 1st confinement≥40 0.34 0.09 0.07 0.01 0.02 0.002 
prior arrest for drug 0.68 0.32 0.21 0.04 0.02 0.01 
prior arrest for property 0.67 0.24 0.22 0.04 0.03 0.01 
prior arrest for public order 0.65 0.24 0.22 0.04 0.03 0.01 
prior arrest for general violence 0.67 0.25 0.26 0.05 0.04 0.01 
prior arrest for domestic violence 0.66 0.21 0.27 0.13 0.04 0.01 
prior arrest for sexual violence 0.49 0.13 0.16 0.04 0.06 0.01 
prior arrest for fatal violence 0.54 0.19 0.21 0.04 0.03 0.01 
prior arrest for multiple crime type 0.64 0.23 0.21 0.04 0.03 0.01 
prior arrest for felony 0.60 0.21 0.19 0.04 0.03 0.01 
prior arrest for misdemeanor 0.69 0.26 0.24 0.06 0.03 0.01 
prior arrest for local ordinance 0.91 0.29 0.43 0.15 0.05 0.02 
prior arrest with firearm involve 0.70 0.30 0.27 0.06 0.03 0.01 
prior arrest with child involve 0.48 0.13 0.14 0.03 0.06 0.01 
no prior arrest 0.32 0.07 0.08 0.02 0.02 0.003 
prior arrest≥1 0.63 0.22 0.19 0.04 0.03 0.01 
prior arrest≥2 0.66 0.23 0.20 0.04 0.03 0.01 
prior arrest≥5 0.70 0.25 0.22 0.04 0.03 0.01 
multiple prior prison time 0.65 0.23 0.19 0.03 0.03 0.01 
any prior jail time 0.69 0.25 0.21 0.04 0.03 0.01 
multiple prior jail time 0.73 0.27 0.22 0.04 0.03 0.01 
any prior probation or fine 0.67 0.24 0.20 0.04 0.03 0.01 
multiple prior probation or fine 0.71 0.27 0.22 0.05 0.03 0.01 



Interpretable Classification Models for Recidivism Prediction 9 

3. Supersparse Linear Integer Models 

A Supersparse Linear Integer Model (SLIM) be a new machine learn method for create score system – 
that is, binary classification model that only require user to add, subtract and multiply a few small number 
to make a prediction (Ustun and Rudin, 2015). Scoring system be widely use because they allow user 
to make quick predictions, without the use of a computer, and without extensive training in statistics. These 
model be also useful because their high degree of sparsity and integer coefficient let user easily gauge 
the influence of multiple input variable on the predict outcome (see Section 4.4 for an example). In what 
follows, we provide a brief overview of SLIM, and provide several new technique to reduce the computation 
for problem with binary input variables. 

3.1. Framework and Optimization Problem 
SLIM score system be linear classification model of the form: 

ŷi = 

 
+1 if 

P∑ 
j=1 

λjxij > λ0 

−1 if 
P∑ 
j=1 

λjxij ≤ λ0. 

Here, λ1, . . . , λP represent the coefficient (i.e. the “points” for input variable j = 1, . . . , P ), and λ0 repre- 
sent an intercept (i.e. the “threshold score” that have to be surpass to predict ŷi = +1). 

The value of the coefficient be determine from data by solve a discrete optimization problem that 
have the follow form: 

min 
λ 

1 

N 

N∑ 
i=1 

1 [yi 6= ŷi] + C0 
P∑ 
j=1 

1 [λj 6= 0] + � 
P∑ 
j=1 

|λj | 

s.t. (λ0, λ1, ..., λP ) ∈ L. 

(1) 

Here, the objective directly minimizes the error rate 1N 
∑N 

i=1 1 [yi 6= ŷi] and directly penalizes the num- 
ber of non-zero term 

∑P 
j=1 1 [λj 6= 0]. The constraint restrict coefficient to a finite set such a L = 

{−10, . . . , 10}P+1. Optionally, one could include additional operational constraint on the accuracy and 
interpretability of the desire score system. 

The objective include a tiny penalty on the absolute value of the coefficient to restrict coefficient to 
coprime value without affect accuracy or sparsity. To illustrate the use of this penalty, consider a classifier 
such a ŷ = sign (x1 + x2). If SLIM only minimize the misclassification rate and the number of term 
(the first two term of the objective), then ŷ = sign (2x1 + 2x2) would have the same objective value a 
ŷ = sign (x1 + x2) because it make the same prediction and have the same number of non-zero coefficients. 
Since coefficient be restrict to a discrete set, we use this tiny penalty on the absolute value of these 
coefficient so that SLIM chooses the classifier with the small (coprime) coefficients, ŷ = sign (x1 + x2). 

The C0 parameter represent the maximum accuracy that SLIM be willing to sacrifice to remove a feature 
from the optimal score system. If, for instance, C0 be set within the range (1/N, 2/N), we would sacrifice 
the accuracy of one observation to have a model with one few feature. Given C0, we can set the `1-penalty 
parameter � to any value 

0 < � < 
min(1/N,C0) 

max{λj}j∈L 
∑P 

j=1 |λj | 

so that it do not affect the accuracy or sparsity of the optimal classifier, but only induces the coefficient to 
be coprime for the feature that be selected. 

SLIM differs from traditional machine learn method because it directly optimizes accuracy and spar- 
sity without make approximation that other method make for scalability (e.g., control for accuracy 
use convex surrogate loss functions). By avoid these approximations, SLIM sacrifice the ability to fit a 
model in second or in a way that scale to extremely large datasets. In return, however, it gain the ability to 



10 Zeng, Ustun, and Rudin 

fit model that be highly customizable, since one could directly encode a wide range of operational constraint 
into it integer program formulation. In this paper, we primarily make use of a simple constraint to limit 
the number of non-zero coefficients, however, it be also natural to incorporate constraint on class-specific 
accuracy, structural sparsity, and prediction (see Ustun and Rudin, 2015). 

In this paper we train the follow version of SLIM, which be different than (1) in that it include class 
weights, and have specific constraint on the coefficients: 

min 
λ 

W+ 

N 

∑ 
i∈I+ 

1 [yi 6= ŷi] + 
W− 

N 

∑ 
i∈I− 

1 [yi 6= ŷi] + C0 
P∑ 
j=1 

1 [λj 6= 0] + � 
P∑ 
j=1 

|λj | 

s.t. 
P∑ 
j=1 

1 [λj 6= 0] ≤ 8 

λj ∈ {−10, . . . , 10} for j = 1...P 
λ0 ∈ {−100, . . . , 100}. 

(2) 

In the formulation above, the constraint restrict each coefficient λj to an integer between −10 and 10, the 
threshold λ0 to an integer between −100 and 100, the number of non-zero to at most 8 (i.e., within the range 
of cognitive entity human could handle, a per Miller, 1956). The parameter W+ and W− be class-based 
weight that control the accuracy on positive and negative examples. We typically choose value of W+ and 
W− such thatW++W− = 2, so that we recover an error-minimizing formulation by settingW+ = W− = 1. 
The C0 parameter be set to a sufficiently small value so that SLIM would not sacrifice accuracy for sparsity: 
give W+ and W−, we can set C0 to any value 

0 < C0 < min{W−,W+}/(N × P ) 

to ensure this condition. The � parameter be set to a sufficiently small value so that SLIM would produce a 
model with coprime coefficient without affect accuracy or sparsity: give W+, W− and C0, we can set � 
to any value 0 < � < C0/max 

∑P 
j=1 |λj | to ensure this condition. 

3.2. General SLIM IP Formulation 
Training a SLIM score system require solve an integer program (IP) problem use a solver such 
a CPLEX, Gurobi, or CBC. In general, we use the follow IP formulation to recover the solution to the 
optimization problem (2): 

min 
λ,z,Φ,α,β 

1 

N 

N∑ 
i=1 

zi + 

P∑ 
j=1 

Φj 

s.t. Mizi ≥ γ − 
P∑ 
j=0 

yiλjxi,j i = 1...N error on i (3a) 

Φj = C0αj + �βj j = 1...P penalty for coef j (3b) 
−Λjαj ≤ λj ≤ Λjαj j = 1...P `0-norm (3c) 
−βj ≤ λj ≤ βj j = 1...P `1-norm (3d) 
λj ∈ Z ∩ [−Λj ,Λj ] j = 0...P coefficient set 
zi ∈ {0, 1} i = 1...N loss variable 

Φj ∈ R+ j = 1...P penalty variable 
αj ∈ {0, 1} j = 1...P `0 variable 
βj ∈ R+ j = 1...P. `1 variable 

The constraint in (3a) compute the error rate by set the loss variable zi = 1 
[ 
yiλ 

Txi ≤ 0 
] 

to 1 if a 
linear classifier with coefficient λ misclassifies example i (or be close to misclassifying it, depend on 
the margin γ). This be a Big-M constraint for the error rate that depends on scalar parameter γ and Mi 
(see e.g., Rubin, 2009). The value of Mi represent the maximum score when example i be misclassified, 
and can be set a Mi = maxλ∈L(γ − yiλTxi) which be easy to compute since L be finite. The value of γ 
represent the margin, and the objective be penalize when point be either incorrectly classified, or within 



Interpretable Classification Models for Recidivism Prediction 11 

γ of the decision boundary. How close a point be to the decision boundary (or whether it be misclassified) be 
determine by yiλTxi. When the feature be binary, and since the coefficient be integers, γ can naturally 
be set to any value between 0 and 1. (In other cases, we can set γ = 0.5 for instance, which make an implicit 
assumption on the value of the features.) The constraint in (3b) set the total penalty for each coefficient to 
Φj = C0αj + �βj , where αj := 1 [λj 6= 0] be define by Big-M constraint in (3c), and βj := |λj | be define 
by the constraint in (3d). We denote the large absolute value of each coefficient a Λj := maxλj∈Lj |λj |. 

Restricting coefficient to a finite set result in significant practical benefit for the SLIM IP formulation, 
especially in comparison to other IP formulation that minimize the 0–1-loss and/or penalize the `0-norm. 
Without the restriction of λ to a bound set, we would not have a natural choice for the Big-M constant, 
which mean the user chooses one that be very large, lead to a less efficient formulation (see e.g., Wolsey, 
1998). For SLIM, the Big-M constant use to compute the 0–1 loss in constraint (3a) be bound a Mi ≤ 
maxλ∈L(γ− yiλTxi), and the Big-M constant use to compute the `0-norm in constraint (3c) be bound a 
Λj ≤ maxλj∈Lj |λj |. Bounding these constant lead to a tighter LP relaxation, which narrow the integrality 
gap, and improves the ability of commercial IP solver to obtain a proof of optimality more quickly. 

3.3. Improved SLIM IP Formulation 
The follow formulation provide a tighter relaxation of the IP which reduces computation. It relies on the 
fact that when the input variable be binary, we be likely to get repeat feature value among observations. 

min 
λ,z,Φ,α,β 

W+ 

N 

∑ 
s∈S 

nszs + 
W− 

N 

∑ 
t∈T 

ntzt + 

P∑ 
j=1 

Φj 

s.t. Mszs ≥ 1− 
P∑ 
j=0 

λjxs,j s ∈ S error on s(4a) 

Mtzt ≥ 
P∑ 
j=0 

λjxt,j t ∈ T error on t(4b) 

1 = z + zt ∀s, t : x = xt, y = −yt conflict labels(4c) 
Φj = C0αj + �βj j = 1...P penalty for coef j(4d) 

−Λjαj ≤ λj ≤ Λjαj j = 1...P `0-norm(4e) 
−βj ≤ λj ≤ βj j = 1...P `1-norm (4f) 
λj ∈ Z ∩ [−Λj ,Λj ] j = 0...P coefficient set 

zs, zt ∈ {0, 1} s ∈ S t ∈ T loss variable 
Φj ∈ R+ j = 1...P penalty variable 
αj ∈ {0, 1} j = 1...P `0 variable 
βj ∈ R+ j = 1...P. `1 variable 

The main difference between this formulation and the one in (3) be that we compute the error rate of the 
classifier use loss constraint that be express in term of the number of distinct point in the dataset. 
Here, the set S represent the set of distinct point with positive labels, and the set T represent the set of 
distinct point with negative examples. The parameter n (and nt) count the number of time a point of type 
s (or t) be found in the original dataset so that 

∑ 
s n = 

∑N 
i=1 1 [yi = +1], 

∑ 
t nt = 

∑N 
i=1 1 [yi = −1], and 

N = 
∑ 

s n + 
∑ 

t nt. 
The main computational benefit of this formulation be due to the fact that: (i) we can reduce the number 

of loss constraint by counting the number of repeat row in the dataset; and (ii) we can directly encode a 
low bound on the error rate by counting the number of point s, t with identical feature but opposite label 
(i.e., x = xt but y = −yt). Here (i) reduces the size of the problem that we pas to an IP solver, and (ii) 
produce a much strong low bound on the 0–1 loss (in comparison to the LP relaxation), which speed up 
the progress of branch-and-bound type algorithms. Note that it would be possible to use this formulation on a 
dataset without binary input variables, though it would not necessarily be effective because it could be much 
less likely for a dataset to contain repeat row in such a setting. 

Another subtle benefit of this formulation be that the margin for the negative point be 0 while the margin 
for the positive point be 1. This mean that for positive points, we have a correct prediction if and only if the 



12 Zeng, Ustun, and Rudin 

score ≥ 1. For negative points, we have a correct prediction if and only if the score ≤ 0. This provide a 
slight computational advantage since the negative point do not need to have score below -1 to be correctly 
classified, which reduces the size of the Big-M parameter and the coefficient set. For instance, say we would to 
produce a linear model that encode: “predict rearrest unless a1 or a2 be true.” Using the previous formulation 
with the margin of γ ∈ (0, 1) on both positive and negatives, the optimal SLIM classifier would be: “rearrest 
= sign(1− 2a1 − 2a2).” In contrast, the margin of the current formulation is: “rearrest = sign(1− a1 − a2)”, 
which us small coefficients, and produce a slightly simpler model. 

3.4. Active Set Polishing 
On large datasets, IP solver may take long time to produce an optimal solution or provider user with a 
certificate of optimality. Here, we present a polish procedure that can be use to improve the quality of 
solution locally. For a fix set of features, this procedure optimizes the value of coefficients. 

The polish procedure take a input a feasible set of coefficient from the SLIM IP λfeasible, and return 
a polished set of coefficient λpolished by solve a a simpler IP formulation show in (5). The polish IP 
only optimizes the coefficient of feature that belong to the active set of λfeasible: that is, the set of feature 
with nonzero coefficient A := 

{ 
j : λfeasiblej 6= 0 

} 
. The coefficient for feature that do not belong to the 

active set be fix to zero so that λj = 0 for j /∈ A. In this way, the optimization no longer involves feature 
selection, and the formulation becomes much easy to solve. 

min 
λ,z,Φ,α,β 

W+ 

N 

∑ 
s∈S 

nszs + 
W− 

N 

∑ 
t∈T 

ntzt (5a) 

s.t. Mszs ≥ 1− 
∑ 
j∈A 

λjxs,j s ∈ S error on s (5b) 

Mtzt ≥ 
∑ 
j∈A 

λjxt,j t ∈ T error on t (5c) 

1 = z + zt ∀s, t : x = xt, y = −yt conflict label (5d) 
λj ∈ Z ∩ [−Λj ,Λj ] j ∈ A coefficient set 

zs, zt ∈ {0, 1} s ∈ S t ∈ T . loss variable 

The polish IP formulation be especially fast to solve to optimality for classification problem with binary 
input variable because this limit the number of loss constraints. Say for instance that we wish to polish a 
set of coefficient with only 5 nonzero variables, then there be at most |{−1,+1}| × |{0, 1}5| = 64 possible 
unique data points, and thus the same number of possible loss constraints. 

In our experiment in Section 4, we use the polish procedure on all of the feasible solution we find 
from the early formulation. In all cases, we can solve the polish IP to optimality within a few second 
(i.e. a MIPGAP of 0.0%). 

4. Experimental Results 

In this section, we compare the accuracy and interpretability of recidivism prediction model from SLIM to 
model from 8 other popular classification methods. In Section 4.1, we explain the experimental setup use 
for all the methods. In Section 4.2, we compare the predictive accuracy of the method with the AUC value 
and ROC curves. In Section 4.3 and 4.4, we evaluate the interpretability of the models. Finally, in Section 
4.5, we present the score system generate by SLIM. 

4.1. Methodology 
In what follow we discus cost-sensitive classification for imbalanced problems, provide an overview of 
techniques. 

4.1.1. Evaluating Predictive Accuracy for Imbalanced Problems 
The majority of classification problem that we consider be imbalanced, where the data contain a relatively 
small number of example from one class and a relatively large number of example from the other. 



Interpretable Classification Models for Recidivism Prediction 13 

Imbalanced problem necessitate change in the way that we evaluate the performance of classification 
models. Consider, for instance, a heavily imbalanced problem such a fatal violence where only P(yi = 
+1) = 0.7% of individual be arrest within 3 year of be release from prison. In this case, a method 
that maximizes overall classification accuracy be likely to produce a trivial model that predicts no one will be 
arrest for fatal offense – a result that be not surprising give that the trivial model be 99.3% accurate on the 
overall population. Unfortunately, this model will never be able to identify individual that will be arrest 
for a fatal offense, and therefore be 0% accurate on the population of interest. 

To provide a measure of classification model performance on imbalanced problems, we ass the accuracy 
of a model on the positive and negative class separately. In our experiments, we report the class-based 
accuracy of each model use the true positive rate (TPR), which reflect the accuracy on the positive class, 
and the false positive rate (FPR), which reflect the error rate on negative class. For a give classification 
model, we compute these quantity a 

TPR = 
1 

N+ 

∑ 
i∈I+ 

1 [ŷi = +1] and FPR = 
1 

N− 

∑ 
i∈I− 

1 [ŷi = +1] , 

where ŷi denotes the predict outcome for example i, N+ denotes the number of example in the positive 
class I+ = {i : yi = +1}, and N− denotes the number of example from the negative class I− = {i : yi = 
−1}. Ideally, a classification model should have high TPR and low FPR (i.e., TPR close to 1 and FPR = 0). 

Most classification method can be adapt to yield a model that be more accurate on the positive class, 
but only if we be willing to sacrifice some accuracy on example from the negative class, and vice-versa. 
To illustrate the trade-off of classification accuracy between positive and negative classes, we plot all model 
produce by a give method a point on a receiver operating characteristic (ROC) curve, which plot the TPR 
on the vertical axis and the FPR on the horizontal axis. Having construct an ROC curve, we then ass 
the overall performance of each method by calculate the area under the ROC curve (AUC).2 A detailed 
discussion of ROC analysis in recidivism prediction can be found in the work of Maloof (2003). 

4.1.2. Fitting Models over the Full ROC Curve use a Cost-Sensitive Approach 
Different application require predictive model at different point of the ROC curve. Models for sentencing, 
for example, need low FPR in order to avoid predict that a low-risk individual will reoffend. Models 
for screening, however, need high TPR in order to capture a many high-risk individual a possible. In 
our experiments, we use a cost-sensitive approach to produce classification model at different point of the 
ROC curve (see e.g., Berk, 2010, 2011). This approach involves control the accuracy on the positive and 
negative class by tune the misclassification cost for example in each class. In what follows, we denote 
the misclassification cost on example from the positive and negative class a W+ and W−, respectively. 
As we increase W+, the cost of make a mistake on a positive example increases, and we expect to obtain a 
model that classifies the positive example more accurately (i.e. with high TPR). We choose W+ and W− 

so that W+ + W− = 2. Thus, when W+ = 2, we obtain a trivial model that predicts ŷi = +1 and attains 
TPR = 1. When W+ = 0, we obtain a trivial model that predicts ŷi = −1 that attains FPR = 0. 

4.1.3. Choice of Classification Methods 
We compare SLIM score system to model produce by eight popular classification methods, include 
those previously use for recidivism prediction (see Section 1.2) or those that ranked among the “top 10 
algorithm in data mining” (Wu et al., 2008). In choose these methods, we restrict our attention to 
method that have publicly-available software packages, and allow user to specify misclassification cost for 
positive and negative classes. Our final choice of method includes: 

• C5.0 Trees and C5.0 Rules: C5.0 be an update version of the popular C4.5 algorithm (Quinlan, 2014; 
Kuhn and Johnson, 2013) that can create decision tree and rule sets. 

2We note that AUC be a summary statistic that be frequently misuse in the context of classification problems. It be true 
that a method that with AUC = 1 always produce model that be more accurate than a method with AUC = 0. Other 
than this simple case, however, it be not possible to state that a method with high AUC always produce model that be 
more accurate than a method with low AUC. 



14 Zeng, Ustun, and Rudin 

• Classification and Regression Trees (CART): CART be a popular method to create decision tree 
through recursive partition of the input variable (Breiman et al., 1984). 

• L1 and L2-Penalized Logistic Regression: Variants of logistic regression that penalize the coefficient 
to prevent overfitting (Friedman et al., 2010). L1-penalized method be typically use to create linear 
model that be sparse (Tibshirani, 1996; Hesterberg et al., 2008). The L2 regularize method be call 
“ridge” and be not generally sparse. 

• Random Forests: A popular black-box method that make prediction use a large ensemble of weak 
classification trees. The method be originally developed by Breiman (2001b) but be widely use for 
recidivism prediction (see e.g., Berk et al., 2009; Ritter, 2013). 

• Support Vector Machines: A popular black-box method for non-parametric linear classification. The 
Radial Basis Function (RBF) kernel let the method to handle classification problem where the decision- 
boundary may be non-linear (see e.g., Cristianini and Shawe-Taylor, 2000; Berk and Bleich, 2014). 

• Stochastic Gradient Boosting: A popular black-box method that create prediction model in the form 
of an ensemble of weaker prediction model (Friedman, 2001; Freund and Schapire, 1997). 

4.1.4. Details on Experimental Design, Parameter Tuning, and Computation 
We summarize the methods, software, and setting that we use in our experiment in Table 4. 

For each of the 6 recidivism prediction problem and each of the 9 methods, we construct ROC curve by 
run the algorithm with 19 value ofW+. The value ofW+ be chosen to produce model across the full 
ROC curves. By default, we chose value of W+ ∈ {0.1, 0.2, . . . , 1.9} and set W− = 2−W+. These value 
ofW+ be inappropriate for problem with a significant class imbalance a all method produce trivial mod- 
els. Thus, for significantly imbalanced problems, such a domestic violence and sexual violence, we 
use value of W+ ∈ {1.815, 1.820, . . . , 1.995}. For fatal violence, which be extremely imbalanced, 
we use W+ ∈ {1.975, 1.976, . . . , 1.995}. 

This setup require u to produce a total of 1,026 recidivism prediction model (6 recidivism problems× 9 
method × 19 imbalance ratios). Each of the 1,026 model be built on a training set and their performance 
be assess out-of-sample. In particular, 1/3 of the data be reserve a the test set. The remain 2/3 of 
the data be the training set. During training, we use 5-fold nest cross-validation (5-CV) for parameter 
tuning. Explicitly, the training data be split into 5 folds, and one of those 5 be reserve a the validation 
fold. The validation fold be rotate in order to select free parameter values, and a final model be train on 
the full training set (2/3) with the select parameter value and it performance be assess on the test set 
(1/3). The fold be generate once to allow for comparison across method and prediction problems. The 
parameter be chosen during nest cross validation to minimize the mean weight 5-CV validation error 
on the training set. Having obtain a set of 19 different model for each method and each problem, we then 
construct an ROC curve for that method on that problem by plot the test TPR and test FPR of the 19 
final models. 

We train all baseline method use publicly available package in R 3.2.2 (R Core Team, 2015) without 
impose any time constraints. In comparison, we train SLIM by solve integer program problem 
(IP) with the CPLEX 12.6 API in MATLAB 2013a. We solve each IP through the follow procedure: (i) 
we train the solver on the formulation in Section 3.3 for a total of 4 hour on a local compute cluster 
with 2.7GHz CPUs. Each time we solve a IP we kept 500 feasible solutions, and polished them use the 
formulation in Section 3.4. We then use the same nest cross-validation procedure a the other method 
to tune the number of term in the final model. Polishing all 500 solution take less than one minute of 
compute time. Thus, the total number of optimization problem we solve be 500 polish IP’s × (5 
fold + 1 final model) × 6 problem × 19 value of W+ = 342,000 integer program problems. 

4.2. Observations on Predictive Accuracy 
We show ROC curve for all method and prediction problem in Figure 1 and summarize the test AUC of 
each method in Table 5. Tables with the training and 5-CV validation AUC’s for all method be include in 
Appendix A. 



Interpretable Classification Models for Recidivism Prediction 15 

Table 4. Methods, software and free parameter use to train model for all 6 recidivism prediction problems. 
We ran each method for 19 value of W+ and all combination of free parameter list in the table. For each 
value of W+, we select the model that minimize the mean weight 5-CV validation error. The value of 
W+ be problem-specific (see Section 4.1.4 for details) 

Method Acronym Software Free Parameters and Settings 

CART Decision Trees CART 
rpart 

(Therneau et al., 2012) 
minSplit ∈ (3, 5, 10, 15, 20) × 
CP ∈ (0.0001, 0.001, 0.01) 

C5.0 Decision Trees C5.0T 
c50 

(Kuhn et al., 2012) default setting 

C5.0 Decision Rules C5.0R 
c50 

(Kuhn et al., 2012) default setting 

Logistic Regression 
(L1-Penalty) 

Lasso 
glmnet 

(Friedman et al., 2010) 100 value of L1-penalty chosen by glmnet 

Logistic Regression 
(L2-Penalty) 

Ridge 
glmnet 

(Friedman et al., 2010) 100 value of L2-penalty chosen by glmnet 

Random Forests RF 
randomForest 

(Liaw and Wiener, 2002) 

sampsize ∈ (0.632N, 0.4N, 0.2N) × 
nodesize ∈ (1, 5, 10, 20) 
with unbounded tree depth 

Support Vector Machines 
(Radial Basis Kernel) SVM RBF 

e1071 
(Meyer et al., 2012) 

C ∈ (0.01, 0.1, 1, 10) × 
γ ∈ ( 110P , 

1 
5P , 

1 
2P , 

1 
P , 

2 
P , 

5 
P , 

10 
P ) 

Stochastic Gradient Boosting 
(Adaboost) SGB 

gbm 
(Ridgeway, 2006) 

shrinkage ∈ (0.001, 0.01, 0.1) × 
interaction.depth ∈ (1, 2, 3, 4) × 
ntrees ∈ (100, 500, 1500, 3000) 

SLIM Scoring Systems SLIM 
CPLEX 12.6 
(Ustun, 2016) 

C0 and � set to find most accurate model with ≤ 8 coefficient 
where λ0 ∈ {−100, . . . , 100} and λj ∈ {−10, . . . , 10} 

We make the follow important observations, which we believe carry over to a large class of problem 
beyond recidivism prediction: 

• All method do well on the general recidivism prediction problem arrest. In this case, we observe 
only small difference in predictive accuracy of different methods: all method other than CART at- 
tain a test AUC above 0.72; the high test AUC of 0.73 be achieve by SGB, Ridge, and RF. This 
multiplicity of good model reflect the Rashomon effect of Breiman (2001b). 

• Major difference between method appear in their performance on imbalanced prediction problems. 
We expect different method to respond differently to change in the misclassification costs, and 
therefore train each method over a large range of possible misclassification costs. Even so, it be 
difficult (if not impossible) to tune certain method to produce model at certain point of the ROC 
curve (see e.g., problem with significant imbalance, such a fatal violence). 

• SVM RBF, SGB, Lasso and Ridge be able to produce accurate model at different point on the ROC 
curve for most problems. SGB usually achieve the high AUC on most problem (e.g., arrest, 
drug, general violence, domestic violence, fatal violence). Lasso, Ridge, and SVM RBF 
often produce comparable AUCs. We find that these method respond well to cost-sensitive tuning, but it 
be difficult to tune the misclassification cost for highly imbalanced problems, such a fatal violence, 
to get model at specific point on the ROC curve. 

• C5.0T, C5.0R and CART be unable to produce accurate model at different point on the ROC curve 
on any imbalanced problems. We found that these method do not respond well to cost-sensitive tun- 
ing. The issue becomes markedly more severe a problem become more imbalanced. For drug 
and general violence, for instance, these method could not produce model with high TPR. For 
fatal violence, sexual violence, and domestic violence, these method almost always pro- 
duced trivial model that predict y = −1 (resulting in AUCs of 0.5). This result may be attribute to 
the greedy nature of the algorithm use to fit the trees, a oppose to the use of tree model in general. 
The issue be unlikely to be software-related a it affect both C5.0 and CART, and have be observe by 
others (see e.g., Goh and Rudin, 2014). This problem might not occur if tree be good optimized. 



16 Zeng, Ustun, and Rudin 

• In general, SLIM produce model that be close to or on the efficient frontier of the ROC curve, despite 
be restrict to a relatively small class of simple linear model (at most 8 non-zero coefficient from - 
10 to 10). Even on highly imbalanced problem such a domestic violence and sexual violence, 
it responds well to change in misclassification cost (as expected, by nature of it formulation). 

In addition to predictive accuracy, we also examine the risk calibration of the models. Figure 2 show the 
risk calibration for arrest, construct use the binning method from Zadrozny and Elkan (2002). We 
include calibration plot for all other problem in Appendix B. We see that SLIM be well-calibrated, even 
though there be no reason it should be; it be a decision-making tool, not a risk assessment tool. For arrest, 
Lasso and Ridge be well-calibrated; however, they lose this quality once we consider only sparse model (see 
Appendix D). This property would also be lose if the Lasso and Ridge coefficient be rounded. 

Table 5. Test AUC for all method on all prediction problems. Each cell contains the test AUC. 

Prediction Problem Lasso Ridge C5.0R C5.0T CART RF SVM RBF SGB SLIM 

arrest 0.72 0.73 0.72 0.72 0.68 0.73 0.72 0.73 0.72 

drug 0.74 0.74 0.63 0.63 0.59 0.75 0.73 0.75 0.74 

general violence 0.72 0.72 0.56 0.57 0.56 0.71 0.70 0.72 0.71 

domestic violence 0.77 0.77 0.50 0.50 0.53 0.64 0.77 0.78 0.76 

sexual violence 0.72 0.72 0.50 0.50 0.51 0.54 0.69 0.70 0.70 

fatal violence 0.67 0.68 0.50 0.50 0.50 0.50 0.69 0.70 0.62 



Interpretable Classification Models for Recidivism Prediction 17 

arrest drug 

0% 

20% 

40% 

60% 

80% 

100% 

0% 20% 40% 60% 80% 100% 
Test FPR 

Te 
st 

T 
P 

R 

0% 

20% 

40% 

60% 

80% 

100% 

0% 20% 40% 60% 80% 100% 
Test FPR 

Te 
st 

T 
P 

R 

general violence domestic violence 

0% 

20% 

40% 

60% 

80% 

100% 

0% 20% 40% 60% 80% 100% 
Test FPR 

Te 
st 

T 
P 

R 

0% 

20% 

40% 

60% 

80% 

100% 

0% 20% 40% 60% 80% 100% 
Test FPR 

Te 
st 

T 
P 

R 

sexual violence fatal violence 

0% 

20% 

40% 

60% 

80% 

100% 

0% 20% 40% 60% 80% 100% 
Test FPR 

Te 
st 

T 
P 

R 

0% 

20% 

40% 

60% 

80% 

100% 

0% 20% 40% 60% 80% 100% 
Test FPR 

Te 
st 

T 
P 

R 

● ● ● ● ● ● ● ● ● Boosting C5.0R C5.0T CART Lasso Ridge RF SLIM SVM RBF 

Fig. 1. ROC curve for general recidivism-related prediction problem with test data. We plot SLIM model 
use large blue dots. All model perform similarly except for C5.0R, C5.0T, and CART. 



18 Zeng, Ustun, and Rudin 

0% 

20% 

40% 

60% 

80% 

100% 

0% 20% 40% 60% 80% 100% 
Mean Score 

F 
ra 

ct 
io 

n 
of 

T 
ru 

e 
P 

o 
iti 

ve 
s 

SLIM vs. Lasso/Ridge (Best) at Max FPR 50% 

● ● ● Lasso Ridge SLIM 

Fig. 2. Risk calibration plot for arrest base on test data. We compare 3 model chosen at a similar decision 
point, with test FPR≤ 50%. Although it be not a risk assessment tool, we see that SLIM be well calibrated. 



Interpretable Classification Models for Recidivism Prediction 19 

4.3. Trade-offs Between Accuracy and Interpretability 
In Appendix C, we show that the baseline method be unable to maintain the same level of accuracy a they 
have in Section 4.2 when their model size be constrained. For Lasso, Ridge and SLIM, model size be define 
a the number of feature in the model. For CART and C5.0, model size be the number of leaf or rules. In 
fact, we find the only method that can consistently produce accurate model along the full ROC curve and 
also have the potential for interpretability be SLIM and (non-sparse) Lasso. 

Tree and rule-based method such a CART, C5.0T and C5.0R be generally unable to produce mod- 
el that attain high degree of accuracy. Worse, even for balance problem such a arrest, where these 
method do produce accurate models, the model be complicate and use a very large number of rule or 
leaf (similar behavior for C5.0T/C5.0R be also observe by, for instance, Lim et al., 2000). As we show in 
Appendix C, it be not reasonably possible to obtain a C5.0R/C5.0T/CART model with at most 8 rule or 8 
leaf for almost every prediction problem. 

4.4. On the Interpretability of Equally Accurate Transparent Models 
To ass the interpretability of different models, we provide a comparison of predictive model produce 
by SLIM, Lasso and CART for the arrest problem in Figures 3–5. This setup provide a nice basis for 
comparison a all three method produce model at roughly the same decision point, and with the same degree 
of sparsity. For this comparison, we consider any transparent model with at most 8 coefficient (Lasso), 8 
rule (C5.0R) or 8 leaf (C5.0T, CART) and have a test FPR of below 50%. We report the model with the 
minimum weight test error. Here, neither C5.0R nor C5.0T could produce an acceptable model with at most 
8 rule or 8 leaves, so only model from SLIM, CART and Lasso could be displayed. As described before, it 
be rare for Lasso and CART to produce model with a similar degree of accuracy to SLIM when model size be 
constrained. We make the follow observations: 

• All three model attain similar level of predictive accuracy. Test TPR value range between 70-79% 
and test FPR value range between 43-48%. There may not exist a classification model that can attain 
substantially high accuracy. 

• The SLIM model us 5 input variable and small integer coefficient (see e.g., Figure 3). There be a natural 
rule-based interpretation. In this case, the model implies that if the prisoner be young (age at release of 18 to 24) 
or have a history of arrest (prior arrests≥5), he be highly likely to be rearrested. On the other hand, if he be 
relatively old (age at release≥40) or have no history of arrest (no prior arrests), he be unlikely to commit 
another crime. 

• The CART model also allows user to make prediction without a calculator. In comparison to the SLIM 
model, however, the hierarchical structure of the CART model make it difficult to gauge the relationship of 
each input variable on the predict outcome. Consider, for instance, the relationship between age at release 
and the outcome. In this case, user be immediately aware that there be an effect, a the model branch 
on the variable age at release≥40 and age at release 18 to 24. However, the effect be difficult to compre- 
hend since it depends on prior arrest for misdemeanor: if prior arrests≥5 = 1 and age at release 18 to 24 
= 1 then the model predicts ŷ = +1; if prior arrests≥5 = 0 and age at release≥40 = 0 then ŷ = +1; how- 
ever, if prior arrests≥5 = 0 and age at release≥40 = 1 then ŷ = +1 only if prior arrest for misdemeanor 
= 1. Such issue do not affect linear model such a SLIM and Lasso, where user can immediately gauge 
the direction and strength of the relationship between a input variable and the predict outcome by the size 
and sign of a coefficient. The literature on interpretability in machine learn indicates that interpretability 
be domain-specific; there be some domain where logical model be prefer over linear models, and vice 
versa (e.g., Freitas, 2014). 



20 Zeng, Ustun, and Rudin 

PREDICT ARREST FOR ANY OFFENSE IF SCORE > 1 
1. age at release 18 to 24 2 point · · · · · · 
2. prior arrests≥5 2 point + · · · · · · 
3. prior arrest for misdemeanor 1 point + · · · · · · 
4. no prior arrest -1 point + · · · · · · 
5. age at release≥40 -1 point + · · · · · · 

ADD POINTS FROM ROWS 1–5 SCORE = · · · · · · 

Fig. 3. SLIM score system for arrest. This model have a test TPR/FPR of 76.6%/44.5%, and a mean 5-CV 
validation TPR/FPR of 78.3%/46.5%. 

PREDICT ARREST FOR ANY OFFENSE IF SCORE > 0.31 
1. prior arrests≥5 0.63 point · · · · · · 
2. age 1st confinement 18 to 24 0.15 point + · · · · · · 
3. prior arrest for property 0.09 point + · · · · · · 
4. prior arrest for misdemeanor 0.05 point + · · · · · · 
5. age at release≥40 -0.20 point + · · · · · · 

ADD POINTS FROM ROWS 1–5 SCORE = · · · · · · 

Fig. 4. Lasso model for arrest, with coefficient round to two significant digits. This model have a test 
TPR/FPR of 70.9%/43.8%, and a mean 5-CV validation TPR/FPR of 72.2%/44.0%. 

prior arrests≥5 

age at release 18 to 24 

not rearrested rearrested 

age at release ≥ 40 

rearrested 

prior arrest for misdemeanor 

rearrestednot rearrested 

NO 

YESNO 

YES 

NO 
YES 

YESNO 

Fig. 5. CART model for arrest. This model have a test TPR/FPR of 79.1%/47.9%, and a mean 5-CV validation 
TPR/FPR of 79.9%/48.5%. 



Interpretable Classification Models for Recidivism Prediction 21 

4.5. Scoring Systems for Recidivism Prediction 
We show a SLIM score system for each of the prediction problem that we consider in Figures 6–10. 
The model be chosen at specific decision points, with the constraint that 5-CV FPR≤ 50% except for 
sexual violence, which be chosen at 5-CV FPR≤ 20%. The model present here may be suitable for 
screen tasks. To obtain a model suitable for sentencing, a point on the ROC curve with a much high TPR 
would be needed. We note that these model generalize well from the dataset, evident by the close match 
between test TPR/FPR (Table 5) and training TPR/FPR (Table 6). 

Many of these model exhibit the same “rule-like” tendency discuss in Section 4.4. For example, the 
model for drug in Figure 6 predicts that a person will be arrest for a drug-related offense if he/she have 
ever have any prior drug offenses. Similarly, model for sexual violence in Figure 9 effectively state that 
a person will be rearrested for a sexual offense if and only if he/she have prior history of sexual crimes. For 
completeness, we include comparison with other model in Appendix B. Additional risk calibration plot for 
model with constrain model size be include in Appendix D. 

PREDICT ARREST FOR DRUG OFFENSE IF SCORE > 7 
1. prior arrest for drug 9 point · · · · · · 
2. age at release 18 to 24 5 point + · · · · · · 
3. age at release 25 to 29 3 point + · · · · · · 
4. prior arrest for multiple type of crime 2 point + · · · · · · 
5. prior arrest for property 1 point + · · · · · · 
6. age at release 30 to 39 -1 point + · · · · · · 
7. no prior arrest -6 point + · · · · · · 

ADD POINTS FROM ROWS 1-7 SCORE = · · · · · · 

Fig. 6. SLIM score system for drug. This model have a test TPR/FPR of 85.7%/51.1%, and a mean 5-CV 
validation TPR/FPR of 82.3%/49.7%. 

PREDICT ARREST FOR GENERAL VIOLENCE OFFENSE IF SCORE > 7 
1. prior arrest for general violence 8 point · · · · · · 
2. prior arrest for misdemeanor 5 point + · · · · · · 
3. infraction in prison 3 point + · · · · · · 
4. prior arrest for local ord 3 point + · · · · · · 
5. prior arrest for property 2 point + · · · · · · 
6. prior arrest for fatal violence 2 point + · · · · · · 
7. prior arrest with firearm involve 1 point + · · · · · · 
8. age at release≥40 -7 point + · · · · · · 

ADD POINTS FROM ROWS 1-8 SCORE = · · · · · · 

Fig. 7. SLIM score system for general violence. This model have a test TPR/FPR of 76.7%/45.4%, and 
a mean 5-CV validation TPR/FPR of 76.8%/47.6%. 



22 Zeng, Ustun, and Rudin 

PREDICT ARREST FOR DOMESTIC VIOLENCE OFFENSE IF SCORE > 3 
1. prior arrest for misdemeanor 4 point · · · · · · 
2. prior arrest for felony 3 point + · · · · · · 
3. prior arrest for domestic violence 2 point + · · · · · · 
4. age 1st confinement 18 to 24 1 point + · · · · · · 
5. infraction in prison -5 point + · · · · · · 

ADD POINTS FROM ROWS 1-5 SCORE = · · · · · · 

Fig. 8. SLIM score system for domestic violence. This model have a test TPR/FPR of 85.5%/46.0%, and 
a mean 5-CV validation TPR/FPR of 81.4%/48.0%. 

PREDICT ARREST FOR SEXUAL VIOLENCE OFFENSE IF SCORE > 2 
1. prior arrest for sexual 3 point · · · · · · 
2. prior arrests≥5 1 point + · · · · · · 
3. multiple prior jail time 1 point + · · · · · · 
4. prior arrest for multiple type of crime -1 point + · · · · · · 
5. no prior arrest -2 point + · · · · · · 

ADD POINTS FROM ROWS 1-5 SCORE = · · · · · · 

Fig. 9. SLIM score system for sexual violence. This model have a test TPR/FPR of 44.3%/17.7%, and a 
mean 5-CV validation TPR/FPR of 43.7%/19.9%. 

PREDICT ARREST FOR FATAL VIOLENCE OFFENSE IF SCORE > 4 
1. age 1st confinement≤17 5 point · · · · · · 
2. prior arrest with firearm involve 3 point + · · · · · · 
3. age 1st confinement 18 to 24 2 point + · · · · · · 
4. prior arrest for felony 2 point + · · · · · · 
5. age at release 18 to 24 1 point + · · · · · · 
6. prior arrest for drug 1 point + · · · · · · 

ADD POINTS FROM ROWS 1-6 SCORE = · · · · · · 

Fig. 10. SLIM score system for fatal violence. This model have a test TPR/FPR of 55.4%/35.5%, and a 
mean 5-CV validation TPR/FPR of 64.2%/42.4%. 



Interpretable Classification Models for Recidivism Prediction 23 

5. Discussion 

Our paper merges two perspective on recidivism modeling: the first be to obtain accurate predictive model 
use the most powerful machine learn tool available, and the second be to create model that be easy to 
use and understand. 

We use a set of feature that be commonly accessible to police officer and judges, and compare the 
ability of different machine learn method to produce model at different decision point across the ROC 
curve. Our result suggest that it be possible for traditional methods, such a Ridge Regression, to perform just 
a well a more modern methods, such a Stochastic Gradient Boosting – a find that be in line with the work 
of Tollenaar and van der Heijden (2013) and Yang et al. (2010). Further, we found that even simple model 
may perform surprisingly well, even when they be fitting from a heavily constrain space – a find that be 
in line with work on the surprising performance of simple model (see e.g., Dawes, 1979; Holte, 1993, 2006). 

Our study show that there may be major advantage of use SLIM for recidivism prediction, a it can 
dependably produce a simple score system that be accurate and interpretable on any decision point along the 
ROC curve. Interpretability be crucial for many of the high-stakes application where recidivism prediction 
model be be used. In such applications, it be not enough for the decision-maker to know what input 
variable be be use to train the model, or how individual input variable be related to the outcome; 
decision-makers should know how the model combine all the input variable to generate it predictions, 
and whether this mechanism aligns with their ethical values. SLIM not only show this mechanism, but 
also accommodates constraint that be design to align the prediction model with the ethical value of the 
decision-maker. 

In comparison to current machine learn methods, the main drawback of run SLIM be increase com- 
putation involve in solve an integer program problem. To this end, we propose two new technique 
to reduce computation involve in training high quality SLIM score systems: (i) a polish procedure that 
improves the quality of feasible solution found by an IP solver; and (ii) an IP formulation that make it easy 
for an IP solver to provide a certificate of optimality. In our experiments, the time require to train SLIM be 
ultimately comparable to the time require to train random forest or stochastic gradient boosting. However, 
it be still significant compare to the time require for other method such a CART, C5.0 and penalize 
logistic regression. In theory, the computation require to find an optimal solution to the SLIM integer pro- 
gram be NP-hard, meaning that the runtime increase exponentially with the number of features. In practice, 
the runtime depends on several factors: such a the number of samples, the number of dimensions, the un- 
derlying ease of the classification, and how the data be encoded. Since most criminological problem cannot 
by nature involve massive datasets (since each observation be a person), and since computer speed of solve 
MIPs be also increase exponentially, it be possible that mathematical program technique like SLIM be 
well-suited for criminological problem that be substantially large and more complex than the one discuss 
in this work. 

References 

Andrade, Joel T. Handbook of violence risk assessment and treatment: New approach for mental health 
professionals. Springer Publishing Company, 2009. 

Andrews, Donald A and James Bonta. The level of service inventory-revised. Multi-Health Systems, 2000. 

Baradaran, Shima. Race, prediction, and discretion. Geo. Wash. L. Rev., 81:157, 2013. 

Barnes, Geoffrey C and Jordan M Hyatt. Classifying adult probationer by forecasting future offending. 
Technical report, National Institute of Justice, U.S. Department of Justice, 2012. 

Belfrage, Henrik, Ran Fransson, and Susanne Strand. Prediction of violence use the hcr-20: A prospective 
study in two maximum-security correctional institutions. The Journal of Forensic Psychiatry, 11(1):167– 
175, 2000. 

Berk, Richard. The role of race in forecast of violent crime. Race and social problems, 1(4):231–242, 2009. 

Berk, Richard. Balancing the cost of forecasting error in parole decisions. Alb. L. Rev., 74:1071, 2010. 



24 Zeng, Ustun, and Rudin 

Berk, Richard. Asymmetric loss function for forecasting in criminal justice settings. Journal of Quantitative 
Criminology, 27(1):107–123, 2011. 

Berk, Richard and Justin Bleich. Forecasts of violence to inform sentence decisions. Journal of Quantitative 
Criminology, 30(1):79–96, 2014. 

Berk, Richard, Lawrence Sherman, Geoffrey Barnes, Ellen Kurtz, and Lindsay Ahlman. Forecasting murder 
within a population of probationer and parolees: a high stake application of statistical learning. Journal 
of the Royal Statistical Society: Series A (Statistics in Society), 172(1):191–211, 2009. 

Berk, Richard A and Justin Bleich. Statistical procedure for forecasting criminal behavior. Criminology & 
Public Policy, 12(3):513–544, 2013. 

Berk, Richard A. and Susan D. Sorenson. Machine learn forecast of domestic violence to help inform 
release decision at arraignment. Technical report, University of Pennsylvania, 2014. 

Berk, Richard A, Yan He, and Susan B Sorenson. Developing a practical forecasting screener for domestic 
violence incidents. Evaluation Review, 29(4):358–383, 2005. 

Berk, Richard A, Brian Kriegler, and Jong-Ho Baek. Forecasting dangerous inmate misconduct: An applica- 
tion of ensemble statistical procedures. Journal of Quantitative Criminology, 22(2):131–145, 2006. 

Bhati, Avinash Singh. Estimating the number of crime avert by incapacitation: an information theoretic 
approach. Journal of Quantitative Criminology, 23(4):355–375, 2007. 

Bhati, Avinash Singh and Alex R Piquero. Estimating the impact of incarceration on subsequent offend 
trajectories: Deterrent, criminogenic, or null effect? The Journal of Criminal Law and Criminology, page 
207–253, 2007. 

Borden, Howard G. Factors for predict parole success. Journal of the American Institute of Criminal Law 
and Criminology, page 328–336, 1928. 

Borum, Randy. Manual for the structure assessment of violence risk in youth (SAVRY). Odessa, Florida: 
Psychological Assessment Resources, 2006. 

Breiman, Leo. Statistical modeling: The two cultures. Statistical Science, 16(3):199–231, 2001a. 

Breiman, Leo. Random forests. Mach. Learn., 45(1):5–32, October 2001b. 

Breiman, Leo, Jerome Friedman, Charles J Stone, and Richard A Olshen. Classification and regression trees. 
CRC press, 1984. 

Burgess, Ernest W. Factors determine success or failure on parole. Illinois Committee on Indeterminate- 
Sentence Law and Parole Springfield, IL, 1928. 

Bushway, Shawn D. Is there any logic to use logit. Criminology & Public Policy, 12(3):563–567, 2013. 

Bushway, Shawn D and Anne Morrison Piehl. The inextricable link between age and criminal history in 
sentencing. Crime & Delinquency, 53(1):156–183, 2007. 

Clements, Carl B. Offender classification two decade of progress. Criminal Justice and Behavior, 23(1): 
121–143, 1996. 

Copas, John and Peter Marshall. The offender group reconviction scale: a statistical reconviction score for use 
by probation officers. Journal of the Royal Statistical Society: Series C (Applied Statistics), 47(1):159–171, 
1998. 

Cristianini, Nello and John Shawe-Taylor. An introduction to support vector machine and other kernel-based 
learn methods. Cambridge University Press, 2000. 

Crow, Matthew S. The complexity of prior record, race, ethnicity, and policy: Interactive effect in sentenc- 
ing. Criminal Justice Review, 2008. 



Interpretable Classification Models for Recidivism Prediction 25 

Dawes, Robyn M. The robust beauty of improper linear model in decision making. American psychologist, 
34(7):571–582, 1979. 

Dawes, Robyn M, David Faust, and Paul E Meehl. Clinical versus actuarial judgment. Science, 243(4899): 
1668–1674, 1989. 

Freitas, Alex A. Comprehensible classification models: a position paper. ACM SIGKDD Explorations 
Newsletter, 15(1):1–10, March 2014. 

Freund, Yoav and Robert E Schapire. A decision-theoretic generalization of on-line learn and an applica- 
tion to boosting. Journal of computer and system sciences, 55(1):119–139, 1997. 

Friedman, Jerome, Trevor Hastie, and Robert Tibshirani. Regularization path for generalize linear model 
via coordinate descent. Journal of Statistical Software, 33(1):1–22, 2010. 

Friedman, Jerome H. Greedy function approximation: a gradient boost machine. Annals of statistics, page 
1189–1232, 2001. 

Friedman, Jerome H. Stochastic gradient boosting. Computational Statistics &amp; Data Analysis, 38(4): 
367–378, 2002. 

Goel, Sharad, Justin M Rao, and Ravi Shroff. Precinct or prejudice? understand racial disparity in 
new york city’s stop-and-frisk policy. Understanding Racial Disparities in New York City’s Stop-and-Frisk 
Policy (March 2, 2015), 2015. 

Goh, Siong Thye and Cynthia Rudin. Box drawing for learn with imbalanced data. In Proceedings of the 
20th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD), 2014. 

Gottfredson, Don M and Howard N Snyder. The mathematics of risk classification: Changing data into valid 
instrument for juvenile courts. ncj 209158. Office of Juvenile Justice and Delinquency Prevention, 2005. 

Grove, William M and Paul E Meehl. Comparative efficiency of informal (subjective, impressionistic) and 
formal (mechanical, algorithmic) prediction procedures: The clinical–statistical controversy. Psychology, 
Public Policy, and Law, 2(2):293, 1996. 

Hahsler, Michael, Christian Buchta, Bettina Gruen, Kurt Hornik, and Christian Borgelt. Package ‘arules’: 
Mining Association Rules and Frequent Itemsets, December 2014. URL http://cran.r-project. 
org/web/packages/arules/arules.pdf. 

Hannah-Moffat, Kelly. Actuarial sentencing: An “unsettled” proposition. Justice Quarterly, 30(2):270–296, 
2013. 

Hanson, RK and D Thornton. Notes on the development of static-2002. Ottawa, Ontario: Department of the 
Solicitor General of Canada, 2003. 

Hesterberg, Tim, Nam Hee Choi, Lukas Meier, and Chris Fraley. Least angle and `1 penalize regression: A 
review. Statistics Surveys, 2:61–93, 2008. 

Hoffman, Peter B. Twenty year of operational use of a risk prediction instrument: The United States parole 
commission’s salient factor score. Journal of Criminal Justice, 22(6):477–494, 1994. 

Hoffman, Peter B and Sheldon Adelberg. The salient factor score: A nontechnical overview. Fed. Probation, 
44:44, 1980. 

Holte, Robert C. Very simple classification rule perform well on most commonly use datasets. Machine 
learning, 11(1):63–90, 1993. 

Holte, Robert C. Elaboration on Two Points Raised in “Classifier Technology and the Illusion of Progress”. 
Statistical Science, 21(1):24–26, February 2006. 

Howard, Philip, Brian Francis, Keith Soothill, and Leslie Humphreys. OGRS 3: The revise offender group 
reconviction scale. Technical report, Ministry of Justice, 2009. 

http://cran.r-project.org/web/packages/arules/arules.pdf 
http://cran.r-project.org/web/packages/arules/arules.pdf 


26 Zeng, Ustun, and Rudin 

Kropp, P Randall and Stephen D Hart. The spousal assault risk assessment (sara) guide: reliability and validity 
in adult male offenders. Law and human behavior, 24(1):101, 2000. 

Kuhn, Max and Kjell Johnson. Applied predictive modeling. Springer, 2013. 

Kuhn, Max, Steve Weston, Nathan Coulter, and R. Quinlan. C50: C5.0 decision tree and rule-based models, 
2012. URL http://CRAN.R-project.org/package=C50. R package version 0.1.0-013. 

Langan, Patrick A and David J Levin. Recidivism of prisoner release in 1994. Federal Sentencing Reporter, 
15(1):58–65, 2002. 

Langton, Calvin M, Howard E Barbaree, Michael C Seto, Edward J Peacock, Leigh Harkins, and Kevin T 
Hansen. Actuarial assessment of risk for reoffense among adult sex offender evaluate the predictive 
accuracy of the static-2002 and five other instruments. Criminal Justice and Behavior, 34(1):37–59, 2007. 

Liaw, Andy and Matthew Wiener. Classification and regression by randomforest. R News, 2(3):18–22, 2002. 
URL http://CRAN.R-project.org/doc/Rnews/. 

Lim, Tjen-Sien, Wei-Yin Loh, and Yu-Shan Shih. A comparison of prediction accuracy, complexity, and 
training time of thirty-three old and new classification algorithms. Machine learning, 40(3):203–228, 2000. 

Lowenkamp, Christopher T and Edward J Latessa. Understanding the risk principle: How and why correc- 
tional intervention can harm low-risk offenders. Topics in community corrections, 2004:3–8, 2004. 

Maden, Anthony, Paul Rogers, Andrew Watt, Glyn Lewis, Tim Amos, Kevin Gournay, and P Skapinakis. 
Assessing the utility of the offender group reconviction scale-2 in predict the risk of reconviction within 
2 and 4 year of discharge from english and welsh medium secure units. Final Report to the National 
Forensic Mental Health Research Programme, 2006. 

Maloof, Marcus A. Learning when data set be imbalanced and when cost be unequal and unknown. In 
ICML-2003 workshop on learn from imbalanced data set II, volume 2, page 2–1, 2003. 

McCord, Joan. A thirty-year follow-up of treatment effects. American psychologist, 33(3):284, 1978. 

McCord, Joan. Cures that harm: Unanticipated outcome of crime prevention programs. The Annals of the 
American Academy of Political and Social Science, 587(1):16–30, 2003. 

Meyer, David, Evgenia Dimitriadou, Kurt Hornik, Andreas Weingessel, and Friedrich Leisch. e1071: Misc 
Functions of the Department of Statistics (e1071), TU Wien, 2012. URL http://CRAN.R-project. 
org/package=e1071. R package version 1.6-1. 

Milgram, Anne. Why smart statistic be the key to fight crime. Ted Talk, January 2014. 

Miller, George. The magical number seven, plus or minus two: Some limit on our capacity for processing 
information. The Psychological Review, 63:81–97, 1956. 

Nafekh, Mark and Laurence Louis Motiuk. The Statistical Information on Recidivism, Revised 1 (SIR-R1) 
Scale: A Psychometric Examination. Correctional Service of Canada. Research Branch, 2002. 

Netter, Brian. Using group statistic to sentence individual criminals: an ethical and statistical critique of the 
virginia risk assessment program. The Journal of Criminal Law and Criminology, page 699–729, 2007. 

Neuilly, Melanie-Angela, Kristen M Zgoba, George E Tita, and Stephen S Lee. Predicting recidivism in 
homicide offender use classification tree analysis. Homicide studies, 15(2):154–176, 2011. 

Pennsylvania Commission on Sentencing. Risk Assessment Project Interim Report 4: Development of Risk 
Assessment Scale. 2012. 

Petersilia, Joan and Susan Turner. Guideline-based justice: Prediction and racial minorities. Crime & Justice, 
9:151, 1987. 

Pew Center of the States, Public Safety Performance Project. Risk/needs assessment 101: science reveals new 
tool to manage offenders. The Pew Center of the States, 2011. 

http://CRAN.R-project.org/package=C50 
http://CRAN.R-project.org/doc/Rnews/ 
http://CRAN.R-project.org/package=e1071 
http://CRAN.R-project.org/package=e1071 


Interpretable Classification Models for Recidivism Prediction 27 

Quinlan, J Ross. C4. 5: program for machine learning. Elsevier, 2014. 

R Core Team. R: A Language and Environment for Statistical Computing. R Foundation for Statistical 
Computing, Vienna, Austria, 2015. URL http://www.R-project.org. 

Ricardo H. Hinojosa et al. A comparison of the federal sentence guideline criminal history category and 
the U.S. parole commission salient factor score. Technical report, U.S. Sentencing Commission, January 
2005. 

Ridgeway, Greg. gbm: Generalized boost regression models. R package version, 1(3), 2006. 

Ridgeway, Greg. The pitfall of prediction. NIJ Journal, National Institute of Justice, 271:34–40, 2013. 

Ritter, Nancy. Predicting recidivism risk: New tool in philadelphia show great promise. NIJ Journal, 271: 
4–13, 2013. 

Rubin, Paul A. Mixed integer classification problems. In Encyclopedia of Optimization, page 2210–2214. 
Springer, 2009. 

Sherman, Lawrence W. The power few: experimental criminology and the reduction of harm. Journal of 
Experimental Criminology, 3(4):299–321, 2007. 

Simon, Jonathan. Reversal of fortune: the resurgence of individual risk assessment in criminal justice. Annu. 
Rev. Law Soc. Sci., 1:397–421, 2005. 

Steinhart, David. Juvenile detention risk assessment: A practice guide to juvenile detention reform. Annie E. 
Casey Foundation, 2006. 

Therneau, Terry, Beth Atkinson, and Brian Ripley. rpart: Recursive Partitioning, 2012. URL http:// 
CRAN.R-project.org/package=rpart. R package version 4.1-0. 

Tibbitts, Clark. Success or failure on parole can be predicted: A study of the record of 3,000 youth parole 
from the illinois state reformatory. Journal of Criminal Law and Criminology (1931-1951), page 11–50, 
1931. 

Tibshirani, Robert. Regression shrinkage and selection via the lasso. Journal of the Royal Statistical Society. 
Series B (Methodological), page 267–288, 1996. 

Tollenaar, Nikolaj and P.G.M. van der Heijden. Which method predicts recidivism best?: a comparison of 
statistical, machine learn and data mining predictive models. Journal of the Royal Statistical Society: 
Series A (Statistics in Society), 176(2):565–584, 2013. 

Turner, Susan, James Hess, and Jesse Jannetta. Development of the California Static Risk Assessment Instru- 
ment (CSRA). University of California, Irvine, Center for Evidence-Based Corrections, 2009. 

U.S. Department of Justice, Bureau of Justice Statistics. Recidivism of prisoner release in 1994. 
http://doi.org/10.3886/ICPSR03355.v8, 2014. 

U.S. Sentencing Commission. 2012 guideline manual: Chapter four - criminal history and crimi- 
nal livelihood, November 1987. URL http://www.ussc.gov/guidelines-manual/2012/ 
2012-4a11. 

Ustun, Berk. slim for matlab v0.1, March 2016. URL http://dx.doi.org/10.5281/zenodo. 
47964. 

Ustun, Berk and Cynthia Rudin. Supersparse linear integer model for optimize medical score systems. 
Machine Learning, page 1–43, 2015. ISSN 0885-6125. doi: 10.1007/s10994-015-5528-6. URL http: 
//dx.doi.org/10.1007/s10994-015-5528-6. 

Wang, Fulton and Cynthia Rudin. Falling rule lists. In Proceedings of Artificial Intelligence and Statistics 
(AISTATS), 2015. 

http://www.R-project.org 
http://CRAN.R-project.org/package=rpart 
http://CRAN.R-project.org/package=rpart 
http://www.ussc.gov/guidelines-manual/2012/2012-4a11 
http://www.ussc.gov/guidelines-manual/2012/2012-4a11 
http://dx.doi.org/10.5281/zenodo.47964 
http://dx.doi.org/10.5281/zenodo.47964 
http://dx.doi.org/10.1007/s10994-015-5528-6 
http://dx.doi.org/10.1007/s10994-015-5528-6 


28 Zeng, Ustun, and Rudin 

Webster, Christopher D et al. HCR-20: Assessing risk for violence. Technical report, Mental Health, Law, 
and Policy Institute, Simon Fraser University, in cooperation with the British Columbia Forensic Psychiatric 
Services Commission, 1997. 

Wolfgang, Marvin E. Delinquency in a birth cohort. University of Chicago Press, 1987. 

Wolsey, Laurence A. Integer programming, volume 42. Wiley New York, 1998. 

Wroblewski, Jonathan J. Annual letter, U.S. department of justice: Criminal division, July 2014. 

Wu, Xindong, Vipin Kumar, Ross Quinlan, Joydeep Ghosh, Qiang Yang, Hiroshi Motoda, Geoffrey Mclach- 
lan, Angus Ng, Bing Liu, Philip Yu, Zhi-Hua Zhou, Michael Steinbach, David Hand, and Dan Steinberg. 
Top 10 algorithm in data mining. Knowledge and Information Systems, 14(1):1–37, January 2008. 

Yang, Min, Stephen CP Wong, and Jeremy Coid. The efficacy of violence prediction: a meta-analytic com- 
parison of nine risk assessment tools. Psychological bulletin, 136(5):740, 2010. 

Zadrozny, Bianca and Charles Elkan. Transforming classifier score into accurate multiclass probability esti- 
mates. In Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and 
data mining, page 694–699. ACM, 2002. 

Zhang, Yan, Lening Zhang, and Michael S Vaughn. Indeterminate and determinate sentence models: A 
state-specific analysis of their effect on recidivism. Crime & Delinquency, 2009. 



Interpretable Classification Models for Recidivism Prediction 29 

A. Additional Results on Predictive Accuracy 

To supplement the experimental result in Section 4.2, we include the training and 5-CV validation results. 
Table 6 show the training AUC performance for all method on all prediction problems, and Table 7 show 
the 5-CV validation AUC performance for all methods. A table of test AUC for all method on all prediction 
problem can be found in Table 5. 

Table 6. Training AUC for all method on all prediction problems. 

Prediction Problem Lasso Ridge C5.0R C5.0T CART RF SVM RBF SGB SLIM 

arrest 0.73 0.73 0.73 0.73 0.81 0.73 0.87 0.75 0.72 

drug 0.74 0.73 0.65 0.66 0.76 0.73 0.85 0.77 0.73 

general violence 0.71 0.71 0.58 0.59 0.77 0.71 0.84 0.74 0.71 

domestic violence 0.77 0.77 0.50 0.50 0.75 0.64 0.88 0.81 0.76 

sexual violence 0.71 0.71 0.50 0.50 0.84 0.55 0.86 0.77 0.71 

fatal violence 0.75 0.74 0.50 0.50 0.50 0.51 0.90 0.84 0.73 

Table 7. 5-CV validation AUC for all method on all prediction problems. We report the 5-CV mean validation 
AUC. The range underneath each cell represent the 5-CV minimum and maximum. 

Prediction Problem Lasso Ridge C5.0R C5.0T CART RF SVM RBF SGB SLIM 

arrest 
0.72 

0.72 - 0.74 

0.73 
0.72 - 0.74 

0.71 
0.71 - 0.73 

0.71 
0.70 - 0.72 

0.67 
0.66 - 0.69 

0.73 
0.72 - 0.74 

0.71 
0.70 - 0.72 

0.73 
0.72 - 0.74 

0.72 
0.71 - 0.73 

drug 
0.73 

0.72 - 0.74 

0.73 
0.71 - 0.74 

0.62 
0.61 - 0.64 

0.62 
0.61 - 0.64 

0.59 
0.58 - 0.60 

0.73 
0.72 - 0.74 

0.72 
0.71 - 0.73 

0.74 
0.72 - 0.74 

0.72 
0.71 - 0.73 

general violence 
0.71 

0.70 - 0.71 

0.71 
0.70 - 0.71 

0.56 
0.55 - 0.57 

0.57 
0.55 - 0.59 

0.56 
0.55 - 0.58 

0.70 
0.69 - 0.71 

0.69 
0.69 - 0.70 

0.71 
0.70 - 0.71 

0.70 
0.69 - 0.71 

domestic violence 
0.76 

0.75 - 0.79 

0.76 
0.75 - 0.78 

0.50 
0.50 - 0.50 

0.50 
0.50 - 0.50 

0.53 
0.51 - 0.54 

0.63 
0.59 - 0.66 

0.76 
0.74 - 0.78 

0.77 
0.75 - 0.79 

0.75 
0.72 - 0.78 

sexual violence 
0.70 

0.68 - 0.74 

0.69 
0.66 - 0.74 

0.50 
0.50 - 0.50 

0.50 
0.50 - 0.50 

0.51 
0.50 - 0.51 

0.54 
0.53 - 0.55 

0.67 
0.63 - 0.70 

0.68 
0.65 - 0.72 

0.68 
0.66 - 0.72 

fatal violence 
0.66 

0.59 - 0.74 

0.67 
0.62 - 0.75 

0.50 
0.50 - 0.50 

0.50 
0.50 - 0.50 

0.50 
0.50 - 0.52 

0.51 
0.50 - 0.53 

0.67 
0.63 - 0.73 

0.67 
0.61 - 0.74 

0.65 
0.61 - 0.69 



30 Zeng, Ustun, and Rudin 

B. Model-Based Comparisons 

In Section 4, we include a comparison of transparent model produce for the arrest problem. Here, we 
include a similar comparison for all other recidivism prediction problems. 

The model and calibration plot show here correspond to the best model we produce use Lasso and 
Ridge (i.e., the one that be plot a point in Figure 1). We omit CART and C5.0 model be show 
because all model that be produce be either trivial or contain too many leaf to be printed. For 
any give problem, the model operate at similar decision point (TPR), and be constrain to the same FPR 
criterion a in Section 4.5. 

Note that the calibration plot will appear to be flat for problem with significant class imbalance. Typi- 
cally, a well-calibrated classifier on a problem without class imbalance should fall on the x = y line. However, 
because the y-axis be define a P (y = +1|s(x) = s), where s be predict score of a model, the slope of 
the graph will be less than P (y = +1) by definition. Therefore, for a highly imbalanced problem such a 
fatal violence, where P (y = +1) = 0.7%, the plot will be flat. 

B.1. drug 
This be the SLIM model for drug. This model have a test TPR/FPR of 85.7%/51.1%, and a mean 5-CV 
validation TPR/FPR of 82.3%/49.7%. 

9.00 prior arrest for drug + 5.00 age at release 18 to 24 + 4.00 age at release 25 to 29 
+ 3.00 prior arrest for multiple type of crime + 1.00 prior arrest for property − 6.00 no prior arrest 
− 1.00 age at release 30 to 39 − 7.00 

This be the best Lasso model for drug. This model have a test TPR/FPR of 82.0%/45.9%, and a mean 5-CV 
validation TPR/FPR of 81.2%/45.9%. 

1.14 prior arrest for drug + 0.27 prior arrest for property + 0.26 time served≤6mo 
+ 0.19 prior arrest for other violence + 0.18 prior arrest for multiple type of crime + 0.17 prior arrest for misdemeanor 
+ 0.16 age at release 18 to 24 + 0.14 prior arrests≥5 + 0.13 age 1st confinement 18 to 24 
+ 0.12 prior arrest for public order + 0.10 prior arrest with firearm involve + 0.08 any prior jail time 
+ 0.06 age 1st arrest≤17 + 0.04 multiple prior jail time + 0.04 drug abuse 
+ 0.03 multiple prior prison time + 0.03 any prior prb or fine − 0.62 age at release≥40 
− 0.25 prior arrest for sexual − 0.23 age at release 30 to 39 − 0.12 time serve 25 to 60mo 
− 0.11 prior arrest with child involve − 0.08 alcohol abuse − 0.07 age 1st confinement≥40 
− 1.11× 10−03 time served≥61mo − 1.01 

This be the best Ridge model for drug. This model have a test TPR/FPR of 84.0%/48.2%, and a mean 5-CV 
validation TPR/FPR of 83.1%/48.4%. 

0.91 prior arrest for drug + 0.25 time served≤6mo + 0.24 age at release 18 to 24 
+ 0.21 prior arrest for multiple type of crime + 0.20 prior arrest for property + 0.17 prior arrest for misdemeanor 
+ 0.17 prior arrest for other violence + 0.17 age 1st confinement 18 to 24 + 0.14 prior arrests≥5 
+ 0.13 prior arrest with firearm involve + 0.12 age at release 25 to 29 + 0.11 drug abuse 
+ 0.11 prior arrest for public order + 0.09 age 1st arrest≤17 + 0.08 age 1st confinement≤17 
+ 0.08 any prior jail time + 0.07 multiple prior jail time + 0.07 age at release≤17 
+ 0.06 multiple prior prison time + 0.06 release unconditonal + 0.05 any prior prb or fine 
+ 0.05 prior arrests≥2 + 0.04 time serve 7 to 12mo + 0.04 multiple prior prb or fine 
+ 0.02 prior arrests≥1 + 0.01 age 1st confinement 25 to 29 + 0.01 release conditonal 
+ 2.52× 10−03 prior arrest for felony + 1.76× 10−03 age 1st arrest 18 to 24 + 9.58× 10−04 prior arrest for fatal violence 
− 0.33 age at release≥40 − 0.25 prior arrest for sexual − 0.19 age 1st confinement≥40 
− 0.16 prior arrest with child involve − 0.15 time serve 25 to 60mo − 0.14 alcohol abuse 
− 0.13 time served≥61mo − 0.10 prior arrest for domestic violence − 0.09 age at release 30 to 39 
− 0.05 age 1st arrest≥40 − 0.04 female − 0.04 infraction in prison 
− 0.03 age 1st arrest 30 to 39 − 0.02 age 1st confinement 30 to 39 − 0.02 no prior arrest 
− 4.71× 10−03 prior arrest for local ord − 4.45× 10−03 time serve 13 to 24mo − 2.23× 10−03 age 1st arrest 25 to 29 
− 1.09 



Interpretable Classification Models for Recidivism Prediction 31 

0% 

20% 

40% 

60% 

80% 

100% 

0% 20% 40% 60% 80% 100% 
Mean Score 

F 
ra 

ct 
io 

n 
of 

T 
ru 

e 
P 

o 
iti 

ve 
s 

SLIM vs. Lasso/Ridge (Best) at Max FPR 50% 

● ● ● Lasso Ridge SLIM 

Fig. 11. Risk calibration plot for drug. 



32 Zeng, Ustun, and Rudin 

B.2. general violence 
SLIM model for general violence. This model have a test TPR/FPR of 76.7%/45.4%, and a mean 5-CV 
validation TPR/FPR of 76.8%/47.6%. 

8 prior arrest for other violence + 5 prior arrest for misdemeanor + 3 infraction in prison 
+ 3 prior arrest for local ord + 2 prior arrest for property + 2 prior arrest for fatal violence 
+ prior arrest with firearm involve − 7 age at release≥40 − 7 

This be the best Lasso model for general violence. This model have a test TPR/FPR of 79.7%/45.5%, and 
a mean 5-CV validation TPR/FPR of 77.3%/45.7%. 

0.90 prior arrest for other violence + 0.35 prior arrest for property + 0.28 prior arrest for misdemeanor 
+ 0.28 age at release 18 to 24 + 0.24 prior arrest for public order + 0.20 age 1st arrest≤17 
+ 0.20 release unconditonal + 0.17 age 1st confinement 18 to 24 + 0.16 alcohol abuse 
+ 0.14 prior arrest for fatal violence + 0.14 age 1st confinement≤17 + 0.10 prior arrest for felony 
+ 0.10 prior arrests≥5 + 0.10 prior arrest with firearm involve + 0.10 age 1st arrest 18 to 24 
+ 0.09 infraction in prison + 0.04 time served≤6mo + 0.03 time serve 7 to 12mo 
+ 2.89× 10−03 prior arrest for drug − 0.72 age at release≥40 − 0.41 female 
− 0.27 age at release 30 to 39 − 0.15 prior arrest with child involve − 0.07 age 1st confinement≥40 
− 0.05 age 1st arrest≥40 − 0.01 time serve 25 to 60mo − 1.84× 10−03 age 1st confinement 30 to 39 
− 1.19 

This be the best Ridge model for general violence. This model have a test TPR/FPR of 81.4%/48.1%, and 
a mean 5-CV validation TPR/FPR of 80.0%/48.5%. 

0.62 prior arrest for other violence + 0.27 age at release 18 to 24 + 0.24 prior arrest for property 
+ 0.23 prior arrest for misdemeanor + 0.19 age 1st confinement 18 to 24 + 0.18 prior arrest for public order 
+ 0.17 age 1st arrest≤17 + 0.14 prior arrest for multiple type of crime + 0.13 release unconditonal 
+ 0.13 prior arrests≥5 + 0.13 prior arrest for felony + 0.12 prior arrest with firearm involve 
+ 0.11 age 1st confinement≤17 + 0.11 alcohol abuse + 0.10 age at release 25 to 29 
+ 0.10 prior arrest for fatal violence + 0.09 infraction in prison + 0.08 age 1st arrest 18 to 24 
+ 0.07 prior arrest for domestic violence + 0.05 drug abuse + 0.05 time served≤6mo 
+ 0.05 prior arrest for local ord + 0.04 time serve 7 to 12mo + 0.04 age at release≤17 
+ 0.03 prior arrests≥2 + 0.03 multiple prior prb or fine + 0.02 multiple prior jail time 
+ 0.01 prior arrest for drug + 3.41× 10−03 no prior arrest − 0.32 age at release≥40 
− 0.20 female − 0.18 age 1st confinement≥40 − 0.12 prior arrest with child involve 
− 0.12 age 1st arrest≥40 − 0.11 age 1st arrest 30 to 39 − 0.09 age 1st confinement 30 to 39 
− 0.08 age at release 30 to 39 − 0.05 age 1st arrest 25 to 29 − 0.04 prior arrest for sexual 
− 0.04 time serve 25 to 60mo − 0.03 time served≥61mo − 0.03 release conditonal 
− 0.03 age 1st confinement 25 to 29 − 0.02 any prior prb or fine − 0.02 time serve 13 to 24mo 
− 5.89× 10−03 multiple prior prison time − 3.60× 10−03 any prior jail time − 3.47× 10−03 prior arrests≥1 
− 1.13 

0% 

20% 

40% 

60% 

80% 

100% 

0% 20% 40% 60% 80% 100% 
Mean Score 

F 
ra 

ct 
io 

n 
of 

T 
ru 

e 
P 

o 
iti 

ve 
s 

SLIM vs. Lasso/Ridge (Best) at Max FPR 50% 

● ● ● Lasso Ridge SLIM 

Fig. 12. Risk calibration plot for general violence. 



Interpretable Classification Models for Recidivism Prediction 33 

B.3. domestic violence 
This be the SLIM model for domestic violence. This model have a test TPR/FPR of 85.5%/46.0%, and a 
mean 5-CV validation TPR/FPR of 81.4%/48.0%. 

4 prior arrest for misdemeanor + 3 prior arrest for felony + 2 prior arrest for domestic violence 
+ age 1st confinement 18 to 24 − 5 infraction in prison − 3 

This be the best Lasso model for domestic violence. This model have a test TPR/FPR of 87.0%/45.8%, and 
a mean 5-CV validation TPR/FPR of 84.5%/45.8%. 

0.88 prior arrest for misdemeanor + 0.73 prior arrest for domestic violence + 0.73 prior arrest for felony 
+ 0.66 prior arrest for other violence + 0.54 release unconditonal + 0.32 age 1st confinement 18 to 24 
+ 0.24 multiple prior prb or fine + 0.21 alcohol abuse + 0.17 prior arrest for sexual 
+ 0.16 prior arrests≥5 + 0.16 prior arrest with firearm involve + 0.08 age at release 18 to 24 
+ 0.06 no prior arrest + 0.05 time serve 7 to 12mo + 0.03 prior arrest for property 
+ 0.01 age 1st arrest 18 to 24 + 0.01 prior arrest for public order − 1.09 infraction in prison 
− 0.54 age at release≥40 − 0.47 drug abuse − 0.40 multiple prior prison time 
− 0.31 prior arrest with child involve − 0.28 multiple prior jail time − 0.26 female 
− 0.20 age 1st confinement≥40 − 0.16 any prior jail time − 0.07 age 1st arrest 30 to 39 
− 0.07 any prior prb or fine − 0.06 prior arrest for drug − 0.06 time served≥61mo 
− 4.48× 10−04 time serve 25 to 60mo − 1.04 

This be the best Ridge model for domestic violence. This model have a test TPR/FPR of 87.0%/47.7%, and 
a mean 5-CV validation TPR/FPR of 85.2%/47.5%. 

0.76 prior arrest for misdemeanor + 0.59 prior arrest for other violence + 0.57 prior arrest for domestic violence 
+ 0.54 prior arrest for felony + 0.40 release unconditonal + 0.27 age 1st confinement 18 to 24 
+ 0.27 multiple prior prb or fine + 0.21 prior arrest for sexual + 0.19 prior arrest with firearm involve 
+ 0.18 alcohol abuse + 0.18 prior arrests≥5 + 0.17 age at release 18 to 24 
+ 0.15 prior arrest for local ord + 0.12 age at release 25 to 29 + 0.11 time serve 7 to 12mo 
+ 0.10 prior arrest for property + 0.10 prior arrest for fatal violence + 0.10 no prior arrest 
+ 0.08 age at release 30 to 39 + 0.07 prior arrest for multiple type of crime + 0.07 age 1st arrest≤17 
+ 0.07 age 1st arrest 18 to 24 + 0.07 prior arrest for public order + 0.05 age 1st arrest 25 to 29 
+ 0.05 time served≤6mo + 0.05 time serve 13 to 24mo + 0.05 prior arrests≥2 
+ 3.08× 10−03 age 1st confinement 30 to 39 − 0.86 infraction in prison − 0.40 drug abuse 
− 0.39 multiple prior prison time − 0.36 age at release≥40 − 0.26 prior arrest with child involve 
− 0.25 multiple prior jail time − 0.25 female − 0.24 age 1st confinement≥40 
− 0.19 any prior jail time − 0.14 time served≥61mo − 0.12 age 1st arrest 30 to 39 
− 0.10 any prior prb or fine − 0.10 age 1st arrest≥40 − 0.10 prior arrests≥1 
− 0.08 prior arrest for drug − 0.06 age 1st confinement 25 to 29 − 0.05 time serve 25 to 60mo 
− 0.04 release conditonal − 0.04 age at release≤17 − 0.02 age 1st confinement≤17 
− 1.01 

0% 

20% 

40% 

60% 

80% 

100% 

0% 20% 40% 60% 80% 100% 
Mean Score 

F 
ra 

ct 
io 

n 
of 

T 
ru 

e 
P 

o 
iti 

ve 
s 

SLIM vs. Lasso/Ridge (Best) at Max FPR 50% 

● ● ● Lasso Ridge SLIM 

Fig. 13. Risk calibration plot for domestic violence. 



34 Zeng, Ustun, and Rudin 

B.4. sexual violence 
This be the SLIM model for sexual violence. This model have a test TPR/FPR of 44.3%/17.7%, and a mean 
5-CV validation TPR/FPR of 43.7%/19.9%. 

3 prior arrest for sexual + prior arrests≥5 + multiple prior jail time 
− 2 no prior arrest − prior arrest for multiple type of crime − 2 

This be the best Lasso model for sexual violence. This model have a test TPR/FPR of 46.9%/18.1%, and a 
mean 5-CV validation TPR/FPR of 43.7%/17.9%. 

1.10 prior arrest for sexual + 0.40 prior arrest for other violence + 0.27 age 1st confinement 18 to 24 
+ 0.27 prior arrest for felony + 0.19 prior arrest with child involve + 0.19 infraction in prison 
+ 0.12 prior arrest for property + 0.09 prior arrest for public order + 0.07 prior arrests≥5 
+ 0.03 age 1st confinement≤17 + 0.02 age 1st arrest≤17 + 8.11× 10−04 prior arrest for fatal violence 
− 0.58 female − 0.25 age at release≥40 − 0.23 prior arrest for drug 
− 0.05 any prior prb or fine − 0.05 drug abuse − 0.01 time serve 25 to 60mo 
− 0.01 prior arrest for misdemeanor − 5.85× 10−03 age 1st confinement 30 to 39 − 1.63 

This be the best Ridge model for sexual violence. This model have a test TPR/FPR of 48.6%/19.3%, and a 
mean 5-CV validation TPR/FPR of 44.9%/19.4%. 

0.92 prior arrest for sexual + 0.35 prior arrest for other violence + 0.30 prior arrest for felony 
+ 0.28 prior arrest with child involve + 0.20 age 1st confinement 18 to 24 + 0.18 infraction in prison 
+ 0.14 prior arrest for property + 0.14 prior arrest for public order + 0.13 age 1st confinement≤17 
+ 0.12 prior arrests≥5 + 0.10 prior arrest for fatal violence + 0.07 age at release 18 to 24 
+ 0.07 time served≥61mo + 0.07 age 1st arrest≤17 + 0.07 prior arrest for local ord 
+ 0.06 any prior jail time + 0.05 age at release 30 to 39 + 0.04 age at release 25 to 29 
+ 0.04 multiple prior prb or fine + 0.03 time serve 13 to 24mo + 0.03 release conditonal 
+ 0.03 release unconditonal + 0.02 age 1st arrest 18 to 24 + 9.63× 10−03 age 1st arrest 30 to 39 
+ 7.60× 10−03 prior arrests≥1 + 6.27× 10−03 age at release≤17 − 0.37 female 
− 0.25 prior arrest for drug − 0.16 age at release≥40 − 0.11 age 1st confinement≥40 
− 0.11 any prior prb or fine − 0.11 age 1st confinement 30 to 39 − 0.09 drug abuse 
− 0.09 age 1st arrest≥40 − 0.07 prior arrest for misdemeanor − 0.06 multiple prior jail time 
− 0.05 time serve 25 to 60mo − 0.04 prior arrests≥2 − 0.04 alcohol abuse 
− 0.04 time serve 7 to 12mo − 0.03 prior arrest for multiple type of crime − 0.02 prior arrest for domestic violence 
− 0.02 time served≤6mo − 0.02 age 1st confinement 25 to 29 − 0.02 multiple prior prison time 
− 7.46× 10−03 no prior arrest − 5.79× 10−03 age 1st arrest 25 to 29 − 4.60× 10−03 prior arrest with firearm involve 
− 1.47 

0% 

20% 

40% 

60% 

80% 

100% 

0% 20% 40% 60% 80% 100% 
Mean Score 

F 
ra 

ct 
io 

n 
of 

T 
ru 

e 
P 

o 
iti 

ve 
s 

SLIM vs. Lasso/Ridge (Best) at Max FPR 20% 

● ● ● Lasso Ridge SLIM 

Fig. 14. Risk calibration plot for sexual violence. 



Interpretable Classification Models for Recidivism Prediction 35 

B.5. fatal violence 
This be the SLIM model for fatal violence. This model have a test TPR/FPR of 55.4%/35.5%, and a mean 
5-CV validation TPR/FPR of 64.2%/42.4%. 

5 age 1st confinement≤17 + 3 prior arrest with firearm involve + 2 age 1st confinement 18 to 24 
+ 2 prior arrest for felony + age at release 18 to 24 + prior arrest for drug 
− 4 

This be the best Lasso model for fatal violence. This model have a test TPR/FPR of 68.9%/44.5%, and a 
mean 5-CV validation TPR/FPR of 67.6%/42.4%. 

1.52 age 1st confinement≤17 + 1.47 age at release≤17 + 1.12 prior arrest for felony 
+ 0.73 age at release 18 to 24 + 0.69 alcohol abuse + 0.66 prior arrests≥5 
+ 0.60 prior arrest for fatal violence + 0.54 age 1st confinement 18 to 24 + 0.47 prior arrest with firearm involve 
+ 0.39 prior arrest for drug + 0.38 age 1st confinement 25 to 29 + 0.35 prior arrest for other violence 
+ 0.35 age 1st arrest≤17 + 0.34 prior arrest for public order + 0.31 prior arrest for multiple type of crime 
+ 0.28 no prior arrest + 0.26 age 1st arrest 25 to 29 + 0.24 age 1st confinement 30 to 39 
+ 0.20 multiple prior prison time + 0.19 prior arrest for property + 0.18 prior arrest for sexual 
+ 0.11 any prior prb or fine + 0.07 time serve 7 to 12mo + 0.07 time served≤6mo 
+ 0.04 age 1st arrest 18 to 24 − 2.69 age 1st arrest≥40 − 1.68 female 
− 0.70 drug abuse − 0.55 infraction in prison − 0.50 time served≥61mo 
− 0.42 release conditonal − 0.39 prior arrests≥2 − 0.36 age at release≥40 
− 0.34 prior arrest for misdemeanor − 0.33 prior arrest with child involve − 0.29 multiple prior prb or fine 
− 0.24 multiple prior jail time − 0.16 release unconditonal − 0.13 time serve 13 to 24mo 
− 0.08 age at release 30 to 39 − 0.08 prior arrest for domestic violence − 0.02 prior arrests≥1 
− 2.00 

This be the best Ridge model for fatal violence. This model have a test TPR/FPR of 62.2%/34.0%, and a 
mean 5-CV validation TPR/FPR of 60.1%/33.0%. 

0.55 prior arrest for felony + 0.54 age 1st confinement≤17 + 0.45 age at release 18 to 24 
+ 0.39 age 1st arrest≤17 + 0.39 prior arrest for fatal violence + 0.35 prior arrests≥5 
+ 0.35 prior arrest with firearm involve + 0.29 prior arrest for other violence + 0.29 prior arrest for drug 
+ 0.26 prior arrest for public order + 0.25 alcohol abuse + 0.24 prior arrest for multiple type of crime 
+ 0.19 age at release≤17 + 0.16 multiple prior prison time + 0.16 prior arrest for property 
+ 0.15 time serve 7 to 12mo + 0.14 time served≤6mo + 0.12 age 1st confinement 18 to 24 
+ 0.10 any prior prb or fine + 0.08 prior arrest for sexual + 0.06 release unconditonal 
+ 0.06 no prior arrest + 0.06 time serve 25 to 60mo + 0.05 age 1st arrest 25 to 29 
+ 0.03 prior arrest for local ord − 0.51 female − 0.42 age at release≥40 
− 0.35 drug abuse − 0.30 infraction in prison − 0.29 age 1st arrest≥40 
− 0.28 age 1st confinement≥40 − 0.25 time served≥61mo − 0.20 multiple prior prb or fine 
− 0.19 multiple prior jail time − 0.17 prior arrest with child involve − 0.16 prior arrest for misdemeanor 
− 0.16 age at release 30 to 39 − 0.15 release conditonal − 0.14 prior arrests≥2 
− 0.14 age 1st confinement 30 to 39 − 0.12 age 1st arrest 30 to 39 − 0.07 time serve 13 to 24mo 
− 0.06 age at release 25 to 29 − 0.06 age 1st confinement 25 to 29 − 0.06 prior arrests≥1 
− 0.01 prior arrest for domestic violence − 0.01 any prior jail time − 8.27× 10−03 age 1st arrest 18 to 24 
− 1.33 

0% 

20% 

40% 

60% 

80% 

100% 

0% 20% 40% 60% 80% 100% 
Mean Score 

F 
ra 

ct 
io 

n 
of 

T 
ru 

e 
P 

o 
iti 

ve 
s 

SLIM vs. Lasso/Ridge (Best) at Max FPR 50% 

● ● ● Lasso Ridge SLIM 

Fig. 15. Risk calibration plot for fatal violence. 



36 Zeng, Ustun, and Rudin 

C. Additional Results on the Trade-off between Accuracy and Interpretability 

In the experiment in Section 4, we use SLIM to fit model from a highly constrain space (i.e., model with 
at most 8 non-zero integer coefficient between -10 and 10). Here, we present evidence to show that baseline 
method cannot attain the same level of accuracy or risk calibration when they be use to fit model from a 
slightly less constrain model space (i.e, model with at most 8 non-zero coefficients, 8 leaf or 8 rules). 

Table 8 show the test AUC of each method when they be use to fit a model with a model size of 8 
or less. Trivial model of size 1 be also omitted. Table 9 show the percentage change in test AUC for 
the method due to the model size restriction. For all model other than SLIM, the predictive accuracy be 
compromise with the size constraint. We see that C5.0R and C5.0T be unable to produce a suitably sparse 
model for some of the problem since their implementation do not provide control over model sparsity. Note 
that we have omit result for Ridge because it could not produce a model with few than 8 coefficient for 
all prediction problem (see Section 4.4 for explanation). 

Table 8. Test AUC on all prediction problem when transparent method be 
restrict to model with at most 8 coefficients, 8 leaf or 8 rules. 

Prediction Problem Lasso C5.0R C5.0T CART SLIM 

arrest 0.70 - - 0.66 0.72 

drug 0.71 - - 0.50 0.74 

general violence 0.70 0.50 0.50 0.50 0.71 

domestic violence 0.74 - - 0.50 0.76 

sexual violence 0.70 - - 0.50 0.70 

fatal violence 0.60 - - 0.50 0.62 

Table 9. Percentage in test AUC with respect to SLIM’s model on all prediction 
problem when transparent method be restrict to model with at most 8 
coefficients, 8 leaf or 8 rules. 

Prediction Problem Lasso C5.0R C5.0T CART SLIM 

arrest -3.8% - - -2.8% 0.0% 

drug -4.0% - - -15.7% 0.0% 

general violence -2.2% -11.0% -12.7% -10.3% 0.0% 

domestic violence -4.1% - - -5.4% 0.0% 

sexual violence -2.2% - - -1.8% 0.0% 

fatal violence -11.2% - - 0.0% 0.0% 

D. Trade-off between Risk Calibration and Interpretability 

Figure 16 show the risk calibration plot of Lasso, Ridge, and SLIM for transparent model with model size 
constrain to 8 or less, chosen under the same decision criterion a Appendix B. Ridge be not include because 
no such model be achievable, a discuss also in Appendix C. For Lasso, the risk calibration performance 
be bad in comparison to Figures 11–15. For fatal violence, there be no Lasso model available at the 
desire decision point. 



Interpretable Classification Models for Recidivism Prediction 37 

arrest drug 

0% 

20% 

40% 

60% 

80% 

100% 

0% 20% 40% 60% 80% 100% 
Mean Score 

F 
ra 

ct 
io 

n 
of 

T 
ru 

e 
P 

o 
iti 

ve 
s 

SLIM vs. Lasso/Ridge (Interp) at Max FPR 50% 

0% 

20% 

40% 

60% 

80% 

100% 

0% 20% 40% 60% 80% 100% 
Mean Score 

F 
ra 

ct 
io 

n 
of 

T 
ru 

e 
P 

o 
iti 

ve 
s 

SLIM vs. Lasso/Ridge (Interp) at Max FPR 50% 

general violence domestic violence 

0% 

20% 

40% 

60% 

80% 

100% 

0% 20% 40% 60% 80% 100% 
Mean Score 

F 
ra 

ct 
io 

n 
of 

T 
ru 

e 
P 

o 
iti 

ve 
s 

SLIM vs. Lasso/Ridge (Interp) at Max FPR 50% 

0% 

20% 

40% 

60% 

80% 

100% 

0% 20% 40% 60% 80% 100% 
Mean Score 

F 
ra 

ct 
io 

n 
of 

T 
ru 

e 
P 

o 
iti 

ve 
s 

SLIM vs. Lasso/Ridge (Interp) at Max FPR 50% 

sexual violence fatal violence 

0% 

20% 

40% 

60% 

80% 

100% 

0% 20% 40% 60% 80% 100% 
Mean Score 

F 
ra 

ct 
io 

n 
of 

T 
ru 

e 
P 

o 
iti 

ve 
s 

SLIM vs. Lasso/Ridge (Interp) at Max FPR 20% 

0% 

20% 

40% 

60% 

80% 

100% 

0% 20% 40% 60% 80% 100% 
Mean Score 

F 
ra 

ct 
io 

n 
of 

T 
ru 

e 
P 

o 
iti 

ve 
s 

SLIM vs. Lasso/Ridge (Interp) at Max FPR 50% 

● ● Lasso SLIM 

Fig. 16. Risk calibration plot for transparent model with model size constrain to 8 or less. 



38 Zeng, Ustun, and Rudin 

E. On the Predictive Accuracy of Baseline Methods with Continuous Input Variables 

In our experiment in Section 4, we ran all method with a dataset compose exclusively of binary input 
variables. That is, for each feature in the original database (e.g., prior arrests), we derive binary variable 
(e.g., no prior arrests, prior arrest ≥ 1 and so on) and train each method use these binary variables. 
It be possible that machine learn method could potentially be hinder by this removal of information. 
Here, we investigate how the predictive accuracy of the baseline method would have be affected have we run 
these method use continuous input variable (Appendix E.1) or both binary and continuous input variable 
(Appendix E.2). In both cases, we find that the change in variable encode result in a minor difference in 
performance. 

E.1. Change in Predictive Accuracy use Only Continuous Input Variables 
Instead of use 48 input variables, we now have 25 continuous variables. Table 10 summarizes the test AUC 
for all method on all prediction problem when we use only continuous input variables. Table 11 show the 
percentage change in test AUC due to this change in encode (i.e. from binary input variable to continuous 
input variables). The large increase in predictive accuracy be 4.6% for CART and 7.7% for SVM RBF, 
while the big decrease in accuracy be −19.6% for RF. 

Our result suggest that there be no uniform gain/loss in performance for most of the methods: for any 
give method, the test AUC increase slightly for at least one problem, and decrease slightly for at least 
another. Among the methods, CART saw the most uniform improvement, perform slightly good on 5 out 
of the 6 problem when continuous variable be use (though CART still performs poorly compare to other 
methods). 

Table 10. Test AUC for all method on all datasets when feature be encode a continuous variables. 

Prediction Problem Lasso Ridge C5.0R C5.0T CART RF SVM RBF SGB 

arrest 0.74 0.73 0.72 0.72 0.70 0.75 0.74 0.75 

drug 0.74 0.74 0.65 0.66 0.62 0.75 0.74 0.76 

general violence 0.71 0.70 0.54 0.58 0.55 0.69 0.69 0.71 

domestic violence 0.74 0.70 0.50 0.50 0.54 0.51 0.75 0.77 

sexual violence 0.70 0.68 0.50 0.50 0.52 0.51 0.68 0.71 

fatal violence 0.69 0.68 0.50 0.50 0.51 0.50 0.74 0.72 

Table 11. Percentage change in test AUC for all method on all datasets when feature be encode a 
continuous variable instead of binary variables. 

Prediction Problem Lasso Ridge C5.0R C5.0T CART RF SVM RBF SGB 

arrest 1.7% 0.1% 0.0% 0.1% 2.4% 2.7% 3.0% 1.7% 

drug -0.5% -0.3% 2.5% 4.2% 4.6% 0.6% 0.7% 1.9% 

general violence -1.5% -2.6% -4.1% 0.7% -1.3% -2.7% -2.2% -1.0% 

domestic violence -3.9% -8.7% -0.1% -0.1% 1.6% -19.6% -3.1% -0.8% 

sexual violence -1.5% -5.1% 0.0% 0.0% 2.0% -5.3% -2.7% 0.9% 

fatal violence 2.8% 0.1% 0.0% 0.0% 1.0% 0.3% 7.7% 2.9% 



Interpretable Classification Models for Recidivism Prediction 39 

E.2. Change in Predictive Accuracy use Both Binary and Continuous Input Variables 
Instead of the original 48 variables, we now use a combination of 66 binary and continuous variables. Table 12 
summarizes the test AUC for all method on all prediction problem when we use both binary and continuous 
input variables. Table 13 show the percentage change in test AUC due to this change in encode (i.e., from 
binary input variable to both binary and continuous input variables). Most method saw a slight AUC increase 
due to the addition of continuous variables, range from 0.2–6.3%. The most significant increase be 3.3% 
for CART and 6.3% for C5.0T, while the large decrease be −16.0% for RF. In addition to RF, Ridge and 
SVM RBF all saw slight decrease with the inclusion. Similar to Appendix E.1, no uniform gain/loss in 
performance be seen. 

Table 12. Test AUC for model create use both continuous and binary variables. 

Prediction Problem Lasso Ridge C5.0R C5.0T CART RF SVM RBF SGB 

arrest 0.74 0.73 0.72 0.72 0.69 0.75 0.73 0.75 

drug 0.75 0.74 0.65 0.67 0.61 0.76 0.75 0.76 

general violence 0.72 0.71 0.58 0.58 0.56 0.72 0.71 0.73 

domestic violence 0.75 0.71 0.50 0.50 0.54 0.54 0.77 0.78 

sexual violence 0.71 0.69 0.50 0.50 0.52 0.50 0.71 0.71 

fatal violence 0.69 0.68 0.50 0.50 0.50 0.50 0.70 0.72 

Table 13. Percentage difference of test AUC for model create with both continuous and binary variable 
verse test AUC for model create with just binary variables. 

Prediction Problem Lasso Ridge C5.0R C5.0T CART RF SVM RBF SGB 

arrest 2.4% 0.6% 0.7% 0.2% 1.9% 2.7% 1.5% 1.7% 

drug 0.2% 0.2% 2.1% 6.3% 3.3% 1.9% 2.1% 2.1% 

general violence 0.5% -1.7% 2.5% 0.7% -0.2% 0.4% 0.7% 1.2% 

domestic violence -2.2% -7.4% 0.0% 0.0% 1.3% -16.0% -0.5% 0.4% 

sexual violence -0.4% -4.2% 0.0% 0.0% 1.5% -6.4% 1.9% 0.6% 

fatal violence 2.2% 0.3% 0.0% 0.0% -0.3% 0.3% 2.7% 2.8% 



40 Zeng, Ustun, and Rudin 

F. Association Rules 

We produce insight more extensive than those in Section 2.4 by mining association rules. Association rules, 
also know a “IF-THEN” rules, be small predictive model that can be produce use search technique or 
optimization techniques. 

F.1. Terminology 
High quality association rule be characterize by large value of support, confidence, and lift. To define 
this terminology, consider a rule such a “IF a THEN b.” We denote this rule also a a → b. The support of 
a → b be the empirical probability P̂ (a and b), that is, the proportion of observation where the condition a 
and b be both satisfied. The confidence of a → b be the empirical probability P̂ (b|a), that is, the proportion 
of observation for which condition b be satisfied give a be satisfied. The lift of a → b be the ratio P̂ (b|a) 

P̂ (b) 
. 

Lift measure the ability of condition a to “target” the population where condition b be satisfied: if the lift of 
a → b be equal to 1, then outcome b could be predict equally well if we have assume that a and b be 
independent; if the lift of a→ b great than 1 then event a have some effect on predict event b. 

To illustrate these concepts, consider the follow association rule: 

IF age at release 18 to 24 AND prior arrests≥5 THEN y = +1. 
The support of this rule be 0.07, which mean that 7% of prisoner be release from prison between the 
age of 18 to 24, have at least 5 prior arrests, and be arrest within 3 year of be release from prison. 
The confidence of this rule be 0.83, which mean that if a prisoner be release from prison between the age 
of 18 to 24 and have at least 5 prior arrests, then there be an 83% chance that this person would be arrest 
within 3 year of be release from prison. Lastly, the lift of this rule be 1.41, which mean that prisoner 
release from prison between the age of 18 to 24 and have at least 5 prior arrest have a high chance of 
be rearrested than other prisoners, i.e., the prisoner age at release and arrest history make the conditional 
probability of arrest 1.41 time high than if arrest be independent of these conditions. 

F.2. Rule Mining 
We list 24 interest association rule for the arrest problem in Table 14. These rule be generate with 
the apriori method in the arules package in R 3.1.1 (Hahsler et al., 2014). Note that the choice of package 
do not matter, a mining rule through search technique be deterministic, so all package produce the same 
rules. 

Here, the IF condition be formulate use combination of input variable (i.e. xj = 1 and xk = 1) and 
the THEN condition be that a prisoner be arrest within 3 year of be release from prison (i.e. a positive 
outcome y = +1). The rule in Table 14 have the high level of lift and confidence with a minimum support 
of 5% (i.e., the rule apply to at least 1690 of the 33796 prisoner in our dataset). This threshold value be 
chosen so the rule do not reflect spurious correlations. Rules A – E be produce by mining the most 
powerful single-variable predictor for arrest. Rules A – E attain the high lift among one-variable rule 
with a support of at least 5% and a confidence of at least 0.70. Rules F – X be produce by mining two- 
variable rule that use at least one of the input variable from Rules A – E that attain the high possible lift, 
a well a support at least 5% and confidence at least 0.75. Out of all these rules, Rule F performs the best with 
a confidence of 0.83 and a lift of 1.41. As it turn out, Rule F be often exploit by some of the best model 
we find for arrest, a we often find pattern similar to “age at release 18 to 24 AND prior arrests≥5” in 
our predictive model (see e.g., Figure 5 in Section 4.4). 

Interesting observation can also be make from the discover rules. Recall that jail be a much less severe 
punishment than prison. Considering Rule L and Rule M in Table 14, we can see that prisoner with multiple 
jail time and have any past probation or fine be just a likely to be arrest a those with multiple jail time 
and multiple prior prison record – despite multiple prior prison time be a indicator of much more severe 
past action than any prior probation or fine. 

F.3. Falling Rule Lists for Imbalanced Problems 
As we discus in Section 4.2, it be difficult to use traditional tree and rule-based method to create non-trivial 
model on imbalanced classification problem such a sexual violence. This be possibly because these 



Interpretable Classification Models for Recidivism Prediction 41 

Table 14. IF-THEN rule mine for arrest. The THEN condition for each rule be the outcome y = +1, 
which indicates that a prisoner be arrest within 3 year of be release from prison. 

Rule IF Condition Lift Support Confidence 
A multiple prior jail time 1.24 0.21 0.73 
B age 1st arrest≤17 1.23 0.10 0.73 
C multiple prior probation or fine 1.20 0.16 0.71 
D age at release 18 to 24 1.20 0.14 0.71 
E prior arrests≥5 1.19 0.42 0.70 
F age at release 18 to 24 AND prior arrests≥5 1.41 0.07 0.83 
G multiple prior jail time AND multiple prior probation or fine 1.30 0.08 0.77 
H age 1st arrest≤17 AND prior arrests≥5 1.28 0.08 0.76 
I multiple prior jail time AND time served≤6mo 1.34 0.06 0.79 
J multiple prior jail time AND age 1st confinement 18 to 24 1.29 0.12 0.76 
K multiple prior jail time AND prior arrest for misdemeanor 1.28 0.15 0.76 
L multiple prior jail time AND multiple prior prison time 1.28 0.13 0.75 
M multiple prior jail time AND any prior probation or fine 1.27 0.13 0.75 

N age 1st arrest≤17 AND prior arrest for misdemeanor 1.32 0.07 0.78 
O age 1st arrest≤17 AND any prior jail time 1.28 0.06 0.76 
P age 1st arrest≤17 AND age 1st confinement 18 to 24 1.28 0.05 0.75 
Q multiple prior probation or fine AND age 1st confinement 18 to 24 1.31 0.08 0.77 

R age at release 18 to 24 AND prior arrest for misdemeanor 1.34 0.06 0.79 
S age at release 18 to 24 AND any prior jail time 1.34 0.06 0.79 
T age at release 18 to 24 AND prior arrests≥2 1.32 0.10 0.78 
U age at release 18 to 24 AND prior arrest for multiple type 1.30 0.10 0.76 

V prior arrests≥5 AND age at release 25 to 29 1.31 0.10 0.77 
W prior arrests≥5 AND age 1st confinement 18 to 24 1.28 0.21 0.76 
X prior arrests≥5 AND time served≤6mo 1.28 0.11 0.76 



42 Zeng, Ustun, and Rudin 

algorithm employ greedy splitting and prune procedures. Here, we aim to show that there exist rule-based 
model that perform well on such problem by training Falling Rule Lists (Wang and Rudin, 2015). 

Falling Rule Lists be order list of IF-THEN rules. The confidence of each rule decrease a we go 
down the list. In this way, the high rule applies to the group of individual that have the high risk, the 
second high rule applies to a group of individual with the second high risk, and so on. The algorithm 
that produce Falling Rule List globally optimizes the list, without greedy splitting and pruning. 

We present a Falling Rule List for the arrest problem in Table 15, learn from the algorithm of Wang 
and Rudin (2015). This model be train use rule with at most two input variable and a support of at 
least 5%. The rule list within this model have the form “IF a THEN b” where b denotes a positive outcome 
y = +1. In Table 15, support refers to the percentage of remain example that satisfy the IF condition and 
probability refers to percentage of these example where the outcome variable be positive. This model show 
that the high risk prisoner be those who be release between age 18 and 24, and who have at least 
5 prior arrest – this be align with the association rule (Rule F) that we found in Section F.2. Once those 
individual be removed, the second high risk prisoner be 25–29 year old with at least 5 prior arrests, 
etc. The risk of each group decrease a one move down the rules. Rule 15 represent the default rule. If an 
individual do not fall under any of risk group determine by Rules 1-14, then his/her risk of arrest be 0.21. 

Table 15. Falling rule list for arrest. 

Conditions Probability Support 

IF age at release 18 to 24 AND prior arrests≥5 0.83 0.08 
ELSE IF age at releaser 25 to 29 AND prior arrests≥5 0.77 0.13 
ELSE IF multiple prior jail time AND prior arrest for drug 0.73 0.18 
ELSE IF age at release 30 to 39 AND prior arrests≥5 0.67 0.26 
ELSE IF age at release 18 to 24 AND prior arrests≥1 0.66 0.16 
ELSE IF prior arrest for drug AND prior arrest for misdemeanor 0.55 0.29 
ELSE IF age at release 25 to 29 AND prior arrests≥2 0.54 0.17 
ELSE IF multiple prior jail time AND prior arrests≥5 0.54 0.27 
ELSE IF age 1st arrest≤17 0.53 0.14 
ELSE IF age at release 18 to 24 0.50 0.19 
ELSE IF time served≤6mo AND prior arrest for property 0.48 0.17 
ELSE IF prior arrests≥5 AND prior arrests≥1 0.41 0.60 
ELSE IF age at release 25 to 29 AND age 1st arrest 18 to 24 0.41 0.16 
ELSE IF age at release 30 to 39 AND prior arrests≥1 0.37 0.35 
ELSE default 0.21 



Interpretable Classification Models for Recidivism Prediction 43 

G. The Impact of Race 

As discuss earlier, we chose not to include race a an input variable in our prediction problems. Some 
study have show that race be important for accurate recidivism prediction (Petersilia and Turner, 1987; 
Berk, 2009). 

We want to know the answer to two questions. First, whether include race a a feature would lead to 
more accurate predictions. Second, whether we could predict race from the feature that we already had. If 
we could predict race well from our current set of features, this would show that race information could be 
implicitly include in any model we might construct. The result that follow show: (i) include race do not 
substantially increase prediction accuracy for our problems, and (ii) race can be predict fairly well from the 
feature we already have. These result indicate that most of the information necessary to predict recidivism 
be already include in the feature we have, and these feature also include relevant information for predict 
race. 

To address whether race provide an increase in accuracy for predict recidivism, we re-ran all method 
other than SLIM on all new version of each prediction problem that include three additional race-related 
input variables: white, black, hispanic. An overview of these variable can be see in Table 16. Table 17 
present the models’ test AUC when race-related indicator variable be included. Table 18 represent the 
percentage increase in AUC when compare to 5. As shown, the difference for most method be negligible. 
In the case of SVM RBF and Ridge, the accuracy increase slightly. In the case of RF, include race 
decrease accuracy (most likely because it exacerbates the overfitting problem). 

To determine whether race could be predict from the current variables, we use three different race 
option (white, black, and hispanic) a outcome and predict each race a a function of our features. ROC 
plot be provide in Figure 17, show that race can be predict much good than random guessing. This be 
not a surprise, a we already know that black tend to have longer criminal history than whites. On the other 
hand, we remark that we could not predict race perfectly with the feature we have - in fact, our prediction 
(for all methods) be far from perfect. This mean that not all of the information about race be contain in 
the feature we have. 

Table 16. Overview of race-related input variables, in addition to the 
variable in Table 1. Each variable be a binary rule of the form xij ∈ 
{0, 1}. 

Input Variable P(xij = 1) Definition 
white 0.53 prisoner i be white 
black 0.44 prisoner i be black 
hispanic 0.14 prisoner i be hispanic 



44 Zeng, Ustun, and Rudin 

Table 17. Test AUC for the baseline method on all prediction problem use the standard set of input variable 
along with the race-related indicator variable white, black and hispanic. 

Dataset Lasso Ridge C5.0R C5.0T CART RF SVM RBF Boosting 

arrest 0.73 0.74 0.72 0.71 0.69 0.74 0.72 0.74 

drug 0.75 0.75 0.64 0.65 0.59 0.76 0.74 0.76 

general violence 0.73 0.73 0.56 0.58 0.56 0.72 0.71 0.72 

domestic violence 0.77 0.77 0.50 0.50 0.52 0.65 0.77 0.78 

sexual violence 0.72 0.72 0.50 0.50 0.51 0.55 0.70 0.70 

fatal violence 0.68 0.69 0.50 0.50 0.50 0.50 0.69 0.70 

Table 18. Percentage difference of test AUC for model with the inclusion of race-related indicator variable 
such a white, black and hispanic verse test AUC for model create without. 

Dataset Lasso Ridge C5.0R C5.0T CART RF SVM RBF Boosting 

arrest 1.2% 0.9% -0.2% -0.1% 1.4% 0.6% -0.9% 0.3% 

drug 0.9% 1.2% 0.5% 3.8% 0.3% 1.3% 0.9% 0.8% 

general violence 0.9% 1.1% -0.7% 1.5% 1.1% 0.6% 1.7% 0.6% 

domestic violence 0.0% -0.1% 0.0% 0.0% -1.0% 1.1% -0.1% -0.1% 

sexual violence 0.2% 0.2% 0.0% 0.0% -0.7% 1.2% 0.4% 0.0% 

fatal violence 1.4% 1.4% 0.0% 0.0% -0.0% -0.3% -1.0% 0.8% 



Interpretable Classification Models for Recidivism Prediction 45 

white black 

0% 

20% 

40% 

60% 

80% 

100% 

0% 20% 40% 60% 80% 100% 
Test FPR 

Te 
st 

T 
P 

R 

0% 

20% 

40% 

60% 

80% 

100% 

0% 20% 40% 60% 80% 100% 
Test FPR 

Te 
st 

T 
P 

R 

hispanic 

0% 

20% 

40% 

60% 

80% 

100% 

0% 20% 40% 60% 80% 100% 
Test FPR 

Te 
st 

T 
P 

R 

● ● ● ● ● ● ● ● ● Boosting C5.0R C5.0T CART Lasso Ridge RF SLIM SVM RBF 

Fig. 17. ROC curve for predict white, black and hispanic use the standard set of input variables. 


1 Introduction 
1.1 Structure 
1.2 Related Work 

2 Data and Prediction Problems 
2.1 Database Details 
2.2 Deriving Input Variables 
2.3 Deriving Outcome Variables 
2.4 Relationships between Input and Output Variables 

3 Supersparse Linear Integer Models 
3.1 Framework and Optimization Problem 
3.2 General SLIM IP Formulation 
3.3 Improved SLIM IP Formulation 
3.4 Active Set Polishing 

4 Experimental Results 
4.1 Methodology 
4.1.1 Evaluating Predictive Accuracy for Imbalanced Problems 
4.1.2 Fitting Models over the Full ROC Curve use a Cost-Sensitive Approach 
4.1.3 Choice of Classification Methods 
4.1.4 Details on Experimental Design, Parameter Tuning, and Computation 

4.2 Observations on Predictive Accuracy 
4.3 Trade-offs Between Accuracy and Interpretability 
4.4 On the Interpretability of Equally Accurate Transparent Models 
4.5 Scoring Systems for Recidivism Prediction 

5 Discussion 
A Additional Results on Predictive Accuracy 
B Model-Based Comparisons 
B.1 drug 
B.2 general_violence 
B.3 domestic_violence 
B.4 sexual_violence 
B.5 fatal_violence 

C Additional Results on the Trade-off between Accuracy and Interpretability 
D Trade-off between Risk Calibration and Interpretability 
E On the Predictive Accuracy of Baseline Methods with Continuous Input Variables 
E.1 Change in Predictive Accuracy use Only Continuous Input Variables 
E.2 Change in Predictive Accuracy use Both Binary and Continuous Input Variables 

F Association Rules 
F.1 Terminology 
F.2 Rule Mining 
F.3 Falling Rule Lists for Imbalanced Problems 

G The Impact of Race 

