








































































Eye movement reveal epistemic curiosity in human observer 


Vision Research 117 (2015) 81–90 
Contents list available at ScienceDirect 

Vision Research 

journal homepage: www.elsevier .com/locate /v isres 
Eye movement reveal epistemic curiosity in human observer 
http://dx.doi.org/10.1016/j.visres.2015.10.009 
0042-6989/� 2015 The Authors. Published by Elsevier Ltd. 
This be an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/). 

⇑ Corresponding author at: Department of Neuroscience, Columbia University, 
1051 Riverside Drive, Kolb Research Annex, New York, NY 10032, United States. 

E-mail address: Adrien.baranes@gmail.com (A. Baranes). 
Adrien Baranes a,⇑, Pierre-Yves Oudeyer c,d, Jacqueline Gottlieb a,b 
aDepartment of Neuroscience, Columbia University, United States 
b The Kavli Institute for Brain Science, Columbia University, United States 
c Inria, France 
d Ensta ParisTech, France 
a r t i c l e i n f o 

Article history: 
Received 17 June 2015 
Received in revise form 18 October 2015 
Accepted 19 October 2015 
Available online 12 November 2015 

Keywords: 
Saccades 
Curiosity 
Anticipation 
Data mining 
Random forest 
Trivia question 
a b s t r a c t 

Saccadic (rapid) eye movement be primary mean by which human and non-human primate sample 
visual information. However, while saccadic decision be intensively investigate in instrumental con- 
text where saccade guide subsequent actions, it be largely unknown how they may be influence by 
curiosity – the intrinsic desire to learn. While saccade be sensitive to visual novelty and visual surprise, 
no study have examine their relation to epistemic curiosity – interest in symbolic, semantic information. 
To investigate this question, we tracked the eye movement of human observer while they read trivia 
question and, after a brief delay, be visually give the answer. We show that high curiosity be 
associate with early anticipatory orient of gaze toward the answer location without change in 
other metric of saccade or fixations, and that these influence be distinct from those produce by 
variation in confidence and surprise. Across subjects, the enhancement of anticipatory gaze be 
correlate with measure of trait curiosity from personality questionnaires. Finally, a machine learn 
algorithm could predict curiosity in a cross-subject manner, rely primarily on statistical feature of 
the gaze position before the answer onset and independently of covariation in confidence or surprise, 
suggest potential practical application for educational technologies, recommender system and 
research in cognitive sciences. With this article, we provide full access to the annotate database allow 
reader to reproduce the results. Epistemic curiosity produce specific effect on oculomotor anticipation 
that can be use to read out curiosity states. 
� 2015 The Authors. Published by Elsevier Ltd. This be anopenaccess article under the CCBY-NC-ND license 

(http://creativecommons.org/licenses/by-nc-nd/4.0/). 
1. Introduction 

Curiosity be define a the intrinsic motivation to learn and 
acquire information, and play a central role in intelligent behavior 
include in development, learn and exploration (Berlyne, 
1954; Gottlieb, Oudeyer, Lopes, & Baranes, 2013; Oudeyer, 
Baranes, & Kaplan, 2013). Psychological theory formulate in 
the 1960s and 1970s distinguish between perceptual curiosity 
– a desire to obtain new sensory input – and epistemic curiosity 
– an interest in new knowledge or semantic information 
(Lowenstein, 1994). More recently, epistemic curiosity be associ- 
ated with cortical and subcortical structure in human observers, 
include activation of reward-related structure (Kang et al., 
2009), and memory enhancement through reward modulation 
of hippocampal mechanism (Gruber, Gelman, & Ranganath, 2014). 
An open question however concern the link between curiosity 
and selective attention. Attention, along with work memory, be 
critical for learn and selective information processing 
(Cardoso-Leite & Bavelier, 2014; Gottlieb et al., 2013). In human 
and non-human primates, visual attention and rapid eye move- 
ments (saccades) be the primary mean by which subject sample 
visual information, and be sensitive to value and motivation 
(Gottlieb, 2012; Gottlieb, Hayhoe, Hikosaka, & Rangel, 2014; 
Tatler, Hayhoe, Land, & Ballard, 2011). While a recent study have 
show that personality measure of trait curiosity correlate with 
the number of saccade and number of region explore during 
free-viewing of complex scene (Risko, Anderson, Lanthier, & 
Kingstone, 2012), nothing be know about the link between eye 
movement and epistemic curiosity – interest in semantic 
information. 

In this report we examine this question by track the eye 
movement of human observer while they be present a ser- 
y of trivia question that create high or low epistemic curiosity 
states. Because curiosity can covary with other epistemic factor 
such a confidence and surprise, we ask subject to provide 

http://crossmark.crossref.org/dialog/?doi=10.1016/j.visres.2015.10.009&domain=pdf 
http://creativecommons.org/licenses/by-nc-nd/4.0/ 
http://dx.doi.org/10.1016/j.visres.2015.10.009 
http://creativecommons.org/licenses/by-nc-nd/4.0/ 
mailto:Adrien.baranes@gmail.com 
http://dx.doi.org/10.1016/j.visres.2015.10.009 
http://www.sciencedirect.com/science/journal/00426989 
http://www.elsevier.com/locate/visres 


82 A. Baranes et al. / Vision Research 117 (2015) 81–90 
independent rating of the 3 subjective states. We test the 
hypothesis that curiosity will influence eye movement control, 
and that these influence would be sufficiently specific to allow 
curiosity to be ‘‘read out” from eye movement use data mining 
algorithms. The result confirm both predictions. We show that 
curiosity enhance anticipatory eye movement toward the 
expect location of the answer and the dwell time on the answer 
after it be presented, without affect other metric of saccade 
or fixations. The ocular signature of high or low curiosity, confi- 
dence or surprise be sufficiently specific so that a machine learn- 
ing algorithm could discriminate these level with above-chance 
accuracy across multiple individual observers. 

2. Methods 

2.1. Subjects 

Twenty subject (11 women) be recruit from the Columbia 
University community and be compensate for their participa- 
tion at the rate of $15 per hour. All the experimental procedure 
be approve by The Institutional Review Board of Columbia 
University and write inform consent be obtain for each 
subject. 

2.2. Procedure 

During the experiment subject be comfortably seat in a 
dimly lit room with their head stabilize by a chin-rest at a dis- 
tance of 54 cm from a computer screen. Eye position and pupil size 
be measure at a sample rate of 500 Hz use an Eye-link 1000 
eye-tracking system configure for binocular tracking. Before data 
collection began, the subject receive a task description and per- 
form a few practice trial that be not include in the data set. 

In the first part of a session the subject be require to 
perform a series of 120 trial in which they read and rat trivia 
question and be subsequently show the answer. The trial 
be evenly divide between 60 one-question trial in which the 
subject receive a single question, and 60 two-question trials, in 
which they saw two sequentially present question and could 
select the one for which they wish to see the answer. One and 
two-question trial be signal in advance by, respectively, 
one or two ‘‘beeps” and be present in randomly interleave 
order in one trial block. A progress bar be displayed after every 
trial indicate the number of remain questions. 
On which continent be Paris ? 
How Curious be you about this question? 

How Confident be you that you know the answer? 
1 2 3 4 5 

1 2 3 4 5 

92 

On which continent be Paris ? 
How Curious be you about this question? 

How Confident be you that you know the answer? 
1 2 3 4 5 

1 2 3 4 5 

How many proton in Uranium? 
How Curious be you about this question? 

How Confident be you that you know the answer? 
1 2 3 4 5 

1 2 3 4 5 

How Surprised be you by the answer ? 
1 2 3 4 5 

1 2 

5 6Answer display 1.5 sec 

Fig. 1. Task design. The panel illustrate the sequence of event on a 2-question trial: (1) 
of the second question and it curiosity/confidence rating, (3) choice of question, (4) an 
As show in Fig. 1 a trial begin when the first question be dis- 
played in the upper part of the screen and subject be ask to 
rate their level of curiosity and confidence use a scale of 1 
(low) to 5 (high) (panel 1). On 2-question trials, this be follow 
by the presentation of the second question and it rating (Fig. 1, 
panel 2), after which the subject be prompt to select one 
question to which they wish to receive the answer use an 
up/down key press (Fig. 1, panel 3). The trial then progress to 
the answer period during which we record eye movement a 
described below (Fig. 1, panel 4–5). After view the answer, 
the subject receive a final rating scale ask them to indicate 
their surprise in the answer (Fig. 1, panel 6; 1 low, 5 high). One- 
question trial be identical, except that only one question be 
displayed and, after give their curiosity and confidence ratings, 
the subject press a button to progress to the answer stage. 

Our focus be on the subjects’ eye movement during a 3 s per- 
iod center on answer presentation. To dissociate the anticipatory 
and reactive component of gaze we divide this period into a 1.5 s 
anticipatory epoch when a rectangular empty box appear at the 
top of the screen indicate the forthcoming position of the answer 
(Fig. 1, panel 4), and a 1.5 s answer period, when the answer be 
displayed align to the left edge of the box (Fig. 1, panel 5). All let- 
ters (for the question and answers) be displayed in black with a 
luminance low than that of the background, and letter height 
be approximately 0.39 degree of visual angle (DVA). 

After complete the trivia questions, the subject complete 
three questionnaire developed to ass personality trait (110 
question total). The first questionnaire measure the tendency 
to maximize external or internal sensation on a sensation seek 
scale (Zuckerman, 1964). The second questionnaire be the Curios- 
ity and Exploration Inventory II (Kashdan et al., 2009) which mea- 
sures curiosity and exploration use 2 dimensions: interest for 
novelty, challenge and absorption (full engagement in specific 
activities). The third questionnaire analyzes novelty-seeking 
behavior on four subscales base on the origin of the stimulation: 
internal or external to the body, and cognitive versus sensational 
(Pearson, 1970). 
2.3. Data analysis 

To study the impact of epistemic curiosity on eye movement 
pattern we measure eye position a a function of time during 
the answer period, a well a the number, amplitude and peak 
velocity of individual saccade and the number and duration 
On which continent be Paris ? 
How Curious be you about this question? 

How Confident be you that you know the answer? 
1 2 3 4 5 

1 2 3 4 5 

How many proton in Uranium? 
How Curious be you about this question? 

How Confident be you that you know the answer? 
1 2 3 4 5 

1 2 3 4 5 

Select a Question use UP or DOWN arrow 

3 4 

Eye-movement record 

Answer anticipation 
1.5 sec 

presentation of the first question and curiosity/confidence ratings, (2) presentation 
ticipation of answer, (5) presentation of answer, (5) surprise rating. 



A. Baranes et al. / Vision Research 117 (2015) 81–90 83 
of individual fixations. Saccades be detect offline a displace- 
ments with amplitude large than 1 degree of visual angle and 
velocity exceed 0.1 deg/s. A fixation be count when eye- 
position be stable for a minimum of 100 ms. 

Because subject have a tendency to emphasize rating of 1 and 
5 for all measure (Fig. 2A–C), we focus on compare trial with 
these ratings, which we refer to as, respectively, ‘‘low” or ‘‘high” 
curiosity, confidence or surprise. 

To analyze the 3 questionnaires, each of which capture a 
slightly different aspect of curiosity, we summarize the result 
use a subject-specific aggregate curiosity score. To derive this 
score we first normalize each subject’s response to each ques- 
tionnaire on a scale from 0 to 100 (i.e., Sensation seek scale: 
True = 0, False = 100; Curiosity and exploration inventory: very 
slightly or not at all = 0; a little = 25; moderately = 50; quite a 
bit = 75; extremely = 100; Novelty seek questionnaire: dis- 
like = 0; like = 100), and then compute the average score across 
the 3 questionnaires. 
2.4. Data mining 

2.4.1. The random forest algorithm 
To determine whether machine learn technique can learn 

an accurate predictive model of epistemic state (curiosity, confi- 
dence or surprise) we use a common algorithm, the random forest 
algorithm, which be use in many prior applications. The algo- 
rithm show superior performance in other domain (Criminisi, 
Curiosity Confidence 

% 
T 

ri 
al 

s 

75% 

0% 

25% 

50% 

1 2 3 4 

75% 

0% 

25% 

50% 

1 2 3 4 5 

A B 

C 
u 

ri 
o 

si 
ty 

( 
Z 

S 
co 

re 
) 

Confidence (Transformed) 
0 20 40 60 80 100 

0 

-0.5 

-1 

0.5 

1 

S 
u 

rp 
ri 

se 
( 

Z 
S 

co 
re 

) 

Curiosity (Z Score 
-2 -1 0 1 

0 

-0.5 

-1 

0.5 

1 

1.5 

ED 

% 
T 

ri 
al 

s 

Fig. 2. Ratings in one-question and two-question trials. (A) The distribution of rating for 
for one subject across all question (including 1- and 2 question trials). (D) Curiosity be 
subject, and confidence rating be transform to percentage by divide by 5 and m 
one- and 2-question trial and across subjects. The large circle show the average curio 
model fit and 95% confidence intervals. The fit produce a significant linear coefficient 
described in the text. (E) Correlation between curiosity and surprise (r = 0.81, p < 10�18). 
on 2-question trials. For each 2-question trial, we calculate relative curiosity/confidenc 
then plot the fraction of trial in which subject chose to see the answer for the que 
show the SEM across subjects. The two data column on the right show the value across 
large symbol show the across-subject mean and SEM. 
Shotton & Konukoglu, 2011) include image classification 
(Bosch, Zisserman & Muoz, 2007), ecology (Cutler et al., 2007) 
and micro-array analysis (Pang et al., 2006), a well a superior 
capability to identify informative feature and disregard redun- 
dant ones, model complex predictive interaction between fea- 
tures, and rely on only a few parameter that be easily tune 
(Breiman, 2001; Cutler et al., 2007). 

The random forest algorithm be base on combination of clas- 
sification trees. In one classification tree, each node denotes an 
individual test on an attribute and branch represent the corre- 
sponding outcome, lead progressively to terminal node that 
hold the class label (e.g., high or low curiosity, confidence or sur- 
prise). The algorithm take a input a vector of eye movement 
parameter (see below, ‘‘Eye movement parametrization”) and gen- 
erates several classification tree on a randomly select subset of 
features, training them by bootstrapping different version of the 
training data. Trees be create incrementally to target training 
data that be not yet well classify by already construct trees. 
Finally, the algorithm fuse the result of all the tree and attempt 
to classify new data in a test set that have not be include in the 
training set (Breiman, 2001). 
2.4.2. Implementation 
We parameterized the Random Forests algorithm use 250 

random trees, each use 8 features, and a 10-fold cross- 
validation method that selects each 10th of data a a test set, while 
use the remain data for training. We implement the 
Surprise 

75% 

0% 

25% 

50% 

1 2 3 4 55 

C 

) 
2 

% 
S 

el 
ec 

ti 
o 

n 
Q 

u 
e 

ti 
o 

n 
w 

it 
h 

H 
ig 

h 
er 

C 
u 

ri 
o 

si 
ty 

/ 
L 

o 
w 

er 
C 

o 
n 

fi 
d 

en 
ce 

Relative rating 
(absolute difference) 

100% 

90% 

80% 

70% 

60% 

50% 

30% 
1 2 3 4 

* p < 10 
-5 

* 

All trial 

40% 

Higher Curiosity Selected 
Lower Con�dence SelectedF 

% 
T 

ri 
al 

s 

curiosity (A), confidence (B) or surprise (C). Each point show the fraction of rating 
an inverted-U function of confidence. Curiosity rating be z-scored within each 
ultiplying by 100. Each point represent one trial, and the trial be pool across 
ity for each confidence level and the solid and dash trace show, respectively, the 
(b1 = 0.021, 95% confidence interval [0.015, 0.028]) and a nonlinear coefficient a 

Same convention a in panel A. (F) Relative curiosity be a strong predictor of choice 
e of each pair of question a the absolute difference between the two ratings. We 
stion with the high curiosity (black) or low confidence rating (gray). Error bar 
all level of relative curiosity/confidence. Each point represent one subject, and the 



84 A. Baranes et al. / Vision Research 117 (2015) 81–90 
analysis in the open-source software ‘‘Weka” (Witten & Frank, 
2005), which be freely available at http://www.cs.waikato.ac.nz/ 
~ml/weka, and make the full annotate eye movement data set 
publicly available at: www.gottlieblab.com. Readers can reproduce 
our analysis by use Weka with parameter –I 250 –K 8 –S 1. 

We conduct the mining analysis separately for predict 
rating of curiosity, confidence and surprise. In a first population 
analysis we use all trial with rating of 1 or 5, pool across all 
observers. Because any imbalance in the frequency of high and 
low rating can artificially inflate prediction accuracy, we resam- 
plead the pool data set to provide equal number of trial with 
each type of rating, thereby ensure that chance accuracy be 
50%. After resampling we be left with 990 trial for the analysis 
of curiosity, 1144 trial for confidence and 1042 trial for surprise. 
In this remain data set, the number of trial per subject be too 
low to provide a meaningful evaluation of how accurate a machine 
learn algorithm be for individual subjects. Therefore, to verify 
the consistency of the algorithm, we use a standard cross- 
subject validation procedure, whereby we train the algorithm on 
19 of the 20 subject and test it prediction accuracy on the 
remain subject, iterate until each subject serve a a test. To 
ass statistical significance we test the set of prediction 
against 0.5 use non-parametric tests. Note that, although the 
training set overlap across the 20 subjects, the result of the test 
phase be base on the individual subject data, and therefore pro- 
duce 20 independent points, satisfy the independence assump- 
tion for statistical tests. 

To determine the prediction value of individual eye movement 
feature we use the ‘‘GainRatio” tool provide by Weka. The tool 
output the information gain ratio (IGR), define a the reduction 
in entropy achieve by use information only from that feature: 

IGR ¼ GainRðClass; featureÞ 
¼ ðHðClassÞ �HðClassjFeatureÞÞ=HðFeatureÞ 

where ‘‘class” refers to the category to be predict (high or low 
curiosity, confidence or surprise) and H() denotes the entropy of 
the respective distribution (see Witten & Frank, 2005). 

2.4.3. Eye movement feature 
While traditional data analysis can only focus on a small num- 

ber of features, data mining technique base on machine learn 
can rapidly evaluate very large set of feature and feature combi- 
nations. Therefore, these technique can reveal new parametriza- 
tion of the eye movement trace that make efficient statistical 
prediction but may not have be identify on an a priori basis. 

We parametrized the input to the algorithm use a vector of 
183 feature that described the statistical property of the eye 
movement trace on each trial. A complete list of feature be give 
in Supplementary Table 1 and a general description be give below. 

The majority of the feature be statistical property of 4 sig- 
nals: (1) the horizontal position of the eye in screen coordinates, 
(2) the vertical position of the eye in screen coordinates, (3) pupil 
diameter (z-scored for each subject by subtract the mean and 
divide by the standard deviation across all the trial give by that 
subject), and (4) the Euclidean distance between the eye and the 
upper left corner of the answer box. Each signal be measure 
during the 1.5 s before-answer and after-answer period at a fre- 
quency of 500 Hz, provide 2 data set of 750 data point each. 

For each of the 8 result data set (4 signal * two epochs), we 
extract a set of 40 basic feature before the answer and after 
answer onset (listed, respectively, in line 1–40 and 84–123 in 
Supplementary Table 1). These value be base on statistical 
property of the measurements, include the minimum, maxi- 
mum, mean, median, variance, range (max–min), and the first 
quartile, third quartile and interquartile range (difference between 
the first and second quartiles). In addition, to capture aspect of 
gaze dynamic during the two epochs, we compute a vector of 
local derivative (differences between successive time points) 
and extract the mean of the absolute value of the derivative 
in each epoch. Finally, we provide the difference between the ‘‘be- 
fore answer” and ‘‘after answer” value for the 20 feature charac- 
terizing the distance to answer and the pupil size (features 164 to 
183). For measure of pupil size, to mitigate noise induced by vari- 
ations in gaze location or luminance, we extract additional 
descriptor from a subset of trial when the eye be continu- 
ously inside the answer box during the interval 0.5 s before to 
0.5 s after answer onset. The 10 feature extract from the first 
and second half of this interval (250 sample each) be list 
in line 74 to 83 (before answer), and 154 to 174 (after answer). 

Finally, we extract feature describe individual saccade 
and fixation: 6 feature for each of the 5 first fixation of epoch 
before the answer (Supplementary Table 1, line 41 to 70) and after 
the answer display (lines 124 to 153). For each fixation we 
extract (1) the time of begin of the fixation (the end of the 
pre-fixation saccade), (2) the end of each fixation (the onset of the 
post-fixation saccade), (3) fixation duration (difference between 
start and end times), (4) the average horizontal position during 
the fixation period in screen coordinates, (5) the average vertical 
position during the fixation period in screen coordinates, (6) the 
average Euclidean distance between the fixation location and the 
answer box. If a trial include few than 5 fixation in either epoch, 
themissing numberswere cod a NaN (not a number). Finally, we 
compute the time when the eye first enter the answer box (71 
if this time be before, and line 72 if it be after answer onset) and 
the duration of the first fixation in this area (line 73). 

3. Results 

3.1. Ratings and choice 

As show in Fig. 2A–C, the distribution of rating be not uni- 
form but tend to be concentrate on value of 1 and 5 for curios- 
ity, confidence and surprise. This suggests that subject be 
engage in the task and do not merely settle on a default interme- 
diate rating. Because of this asymmetry, we focus our eye move- 
ment analysis on trial with rating of 1 or 5 (which we refer to a 
‘‘low” or ‘‘high”). 

Previous investigation propose that a key factor drive epis- 
temic curiosity be an ‘‘information gap” – a discrepancy between 
what one know and what one would like to know – and therefore 
that curiosity should peak when one have a little bit of knowledge, 
but diminish if a subject know too little or too much about a topic 
(Kang et al., 2009; Lowenstein, 1994). Consistent with this predic- 
tion, we found that rating of curiosity be an invert U-shaped 
function of confidence – peak at intermediate level but becom- 
ing low for the low or the high level of confidence 
(Fig. 2D). Following the method of Kang et al. (Kang et al., 2009), 
we transform confidence rating to percentage (dividing each 
rating by 5 and multiply by 100), and fit the data to the equa- 
tion: curiosity = b0 + b1 * p + b2 * p * (1 � p), where p be the trans- 
form confidence score. The model provide R2 = 0.73 and a 
significant quadratic coefficient (b2 = 30 * 10�4, 95% confidence 
interval, [24 * 10�4, 36 * 10�4]) consistent with a peak at interme- 
diate values. We obtain equivalent result whether we use 
the raw or z-scored confidence ratings. 

Ratings of curiosity be positively correlate with rating of 
surprise (Fig. 2E; r = 0.982, p = 0.003). Interestingly, subject could 
have understood their rating of ‘‘surprise” in this task to indicate 
how unlikely they believe the answer to be (how much it differ 
from the set of possible answers) or alternatively, how much 
weight they give to the new information. The high correlation 

http://www.cs.waikato.ac.nz/~ml/weka 
http://www.cs.waikato.ac.nz/~ml/weka 
http://www.gottlieblab.com 


A. Baranes et al. / Vision Research 117 (2015) 81–90 85 
between curiosity and surprise suggests that subject adopt the 
latter interpretation – i.e., the more curious they be while antic- 
ipating the answer, the more salience they assign to the answer 
when it be finally shown. In the follow analysis we show that, 
despite this high correlation between curiosity and surprise, the 
two construct have different oculomotor effects. 

To investigate how the subjects’ rating be related to their 
choice on 2-question trials, we calculate for each trial the abso- 
lute difference between the rating of curiosity and confidence 
assign to the two alternative questions. We reason that, if 
the relative rating determine the subjects’ choices, subject 
may tend to choose the question with the high curiosity or low 
confidence on each trial. 

As show in Fig. 2F, this hypothesis be confirm and choice 
be determine more strongly by rating of curiosity than by 
those of confidence. Subjects almost always ask for the answer 
to the question that produce the high curiosity, even if the rat- 
ing difference be small (Fig. 2F; black trace). While the subject 
also tend to select the question in which they have low confi- 
dence, this be a weaker effect (Fig. 2F, gray). If both question 
elicit a similar level of confidence (a difference of 1), choice 
be fully allocate to the question that elicit high curiosity. 
position of answer 
position of surprise rating 

Looking time 

Longer 

Shorter 

C 
ur 

io 
si 

ty 
C 

on 
� d 

en 
ce 

S 
ur 

p 
ri 

e 

H 
ig 

h 
L 

o 
w 

H 
ig 

h 
-L 

o 
w 

H 
ig 

h 
L 

o 
w 

H 
ig 

h 
-L 

o 
w 

H 
ig 

h 
L 

o 
w 

H 
ig 

h 
-L 

o 
w 

Answ-1.5s 

Fig. 3. Probability density of fixation during the answer epoch. We divide the 3 s of eye 
the screen display into pixel measure 0.27 by 0.15 degree of visual angle. We then c 
be average for each subject and then average across subjects. The heat map show 
individual map such that brighter area correspond to zone that receive more explora 
Across the entire set of 2-question trial (Fig. 2F, right panel), sub- 
jects select the question with the high curiosity rating on 
93% ± 2.3% of trial and the question with the low confidence rat- 
ing on only 68% ± 3.2% of trial (p < 10�5, Wilcoxon test). Together, 
these finding suggest that confidence influence curiosity accord- 
ing to an inverted-U function (Fig. 2D) but it be curiosity that ulti- 
mately determines the subjects’ choice of information. 

3.2. Eye movement 

To examine the overall eye movement pattern during the task, 
we construct time-resolved map of fixation density at each 
screen location (Fig. 3). Consistent with previous investigations, 
subject allocate their gaze behavior in a task-related fashion, 
both anticipate and react to the task event (Tatler et al., 
2011). At the onset of the anticipation period, gaze position be 
diffusely distribute in the upper half of the screen – where the 
subject have just view the question and provide their rating 
– whereas thereafter gaze become increasingly cluster on the 
left corner of the answer box – where the answer be expect 
to be. Gaze transiently converge on the answer after it appeared, 
and then gradually drift toward the center of the screen – the 
er ON +1.5s 

position record in 10 non-overlapping 300 m bins, and divide the total area of 
alculated the fraction of time, out of each time bin, that a pixel be fixated. Values 
group average of trial with rating of 1 or 5. The subtraction map subtract two 
tion for the high rating. 



B 

C 
o 

ef 
fi 

ci 
en 

t 
e 

ti 
m 

at 
e 

D 
eg 

re 
e/ 

R 
at 

in 
g 

Confidence Rating 

-0.3 

-0.4 

-0.2 

0 

-0.1 

1 5 

** 

D 
be 

ta 
n 

ce 
t 

o 
A 

n 
sw 

er 
( 

d 
eg 

re 
e 

) 

-1500 

Answer ON 

25 

0 

15 

Curiosity 

** ** 

5 

10 

20 

Time (ms) 
-1500 

Answer ON 

25 

0 

15 

Confidence 

*** 

5 

10 

20 

1500 
0 

15 

Surprise 

* *** 

5 

10 

20 
** 

Answer ON 

High Rating 
Low Rating 

A 

0 500 1000-1000 -500 15000 500 1000-1000 -500 15000 500 1000 

-0.5 

Fig. 4. Distance to answer. (A) For each trial with high or low rating we compute the distance between the eye position and the left edge of the answer box every 2 ms. 
Distances be average for each subject, and we display the mean and SEM across subjects. Average distance before and after answer onset be compare with a 1-way 
ANOVA; star show **p < 10�45, ***p < 10�75. (B) To examine whether the effect of curiosity be robust to variation in confidence, we divide trial into those with high and 
low confidence rating and compute a regression analysis to determine the impact of curiosity in each group (using average eye position in the 500 m before answer onset). 
The panel show the regression coefficient and their 95% confidence interval, and the star indicate p < 10�30. Negative coefficient indicate that high curiosity rating be 
associate with small distance to the answer box. 

Table 1 
Comparison of saccade and fixation metric a a function of epistemic states. 

Curiosity Confidence Surprise 

High Low High Low High Low 

Anticipatory #Saccades 3.31(0.17) 3.33(0.13) 3.28(0.12) 3.74(0.18) 3.47(0.15) 3.34(0.13) 
Sac. Amp. (deg.) 8.25(0.63) 9.00(0.62) 9.11(0.58) 7.78(0.49) 8.43(0.53) 8.92(0.55) 
Peak. Vel. (deg/s) 240.78(11.83) 249.21(9.54) 243.56(8.27) 235.05(11.20) 245.36(11.12) 252.04(10.09) 
#Fix. 2.92(0.12) 2.90(0.09) 2.89(0.11) 3.25(0.13) 3.03(0.10) 2.93(0.09) 
Fix. Dur. (ms) 0.36(0.02) 0.35(0.02) 0.36(0.01) 0.33(0.02) 0.34(0.02) 0.35(0.02) 

After answer #Saccades 3.51(0.13) 3.55(0.13) 3.49(0.11) 3.48(0.12) 3.45(0.16) 3.56(0.13) 
Sac. Amp. (deg) 8.39(0.53) 7.60(0.54) 7.54(0.56) 7.42(0.43) 8.03(0.52) 7.77(0.58) 
Peak. Vel. (deg) 240.54(9.67) 234.95(12.07) 228.94(11.18) 228.05(9.68) 246.66(12.21) 228.60(11.39) 
# Fix. 2.82(0.13) 2.88(0.11) 2.76(0.09) 2.82(0.09) 2.69(0.12) 2.81(0.10) 
Fix. Dur. (ms) 0.28(0.02) 0.30(0.02) 0.30(0.01) 0.29(0.01) 0.27(0.02) 0.30(0.02) 

Each entry show the average (SEM) of the respective metric in 1-question trials, first average by subject and then across subjects. For each metric we compare the high and 
low rating trial use a Wilcoxon test. While high confidence tend to be associate with few saccades, few fixation and large saccade amplitude during the 
anticipation period, these trend do not reach statistical significance (p-values of, respectively, 0.063, 0.07 and 0.08). For all other comparisons, p > 0.13. 

86 A. Baranes et al. / Vision Research 117 (2015) 81–90 
anticipate location of the surprise rating (whose presentation be 
not include in Fig. 3). 

In addition to this task-related pattern, gaze be modulate by 
curiosity, confidence and surprise. This can be appreciate by com- 
par the top two row of fixation map in each category, corre- 
sponding to ‘‘high” and ‘‘low” ratings, and from the subtraction 
map on the 3rd row. These display suggest that gaze converge 
sooner and linger longer on the expect answer location for 
high relative to low curiosity states. 

To quantitatively analyze these effect and distinguish them 
from those of confidence and surprise, we measure the average 
Euclidean distance between the eye and the top left corner of the 
answer box a a function of time (Fig. 4A). This distance be 
significantly small for question with high relative to low curios- 
ity ratings, and this difference be maintain consistently during 
the entire anticipation epoch (p < 10�45, Wilcoxon test). Therefore, 
subject shift gaze sooner to the answer box if they have high 
curiosity. In contrast, confidence have an inconsistent effect that 
switch from early repulsion to a slight late attraction in high 
versus low confidence states, but be not significant over the 
entire interval (Fig. 4A, middle). To further confirm that the effect 
of curiosity be not confound by those of confidence, we carry 
out a second analysis where we compute the effect of curiosity 
separately in trial with high and low confidence ratings. Linear 
regression coefficient compute over the 500 m before answer 
onset be significantly negative in both trial subgroup 
(p < 10�30 in both cases), show that high curiosity be 
associate with a shorter distance to the answer independently 
of confidence rating (Fig. 4B). 
Eye movement be also influence by subjective rating after 
answer presentation – linger longer on the answer for trial 
with high curiosity, low confidence and high surprise 
(Fig. 4A). However, because of the statistical association among 
these rating (Fig. 2D and E), these post-answer effect cannot be 
unambiguously attribute to a specific factor – a topic to which 
we return in the data mining analysis below. 

As show in Table 1, curiosity, confidence and surprise have no 
significant effect on other gaze parameters, include the number, 
amplitudes, peak velocity of saccades, or the number and dura- 
tions of fixations, in the epoch that precede or follow the 
answer onset. Therefore in high curiosity states, subject seem 
to have guide their gaze more precisely toward the answer box 
without alter the speed or frequency of saccades. 

3.3. Correlation with trait curiosity 

To determine whether the impact of curiosity on eye move- 
ments correlate with measure of trait curiosity (Risko et al., 
2012), we construct an aggregate curiosity score base on the 
subjects’ answer to 3 questionnaire design to measure sensa- 
tion seeking, curiosity and exploration and novelty seek trait 
(see Section 2). We found a negative correlation between the 
questionnaire score and the effect of curiosity on saccadic antici- 
pation (Fig. 5A; linear regression coefficient, �0.079; SE = 0.031, 
p = 0.02). By contrast, there be no significant correlation 
between questionnaire score and the extent to which gaze be 
affected by confidence (Fig. 5B; linear regression coefficient, 
0.032; SE = 0.246, p = 0.17) or surprise after answer onset 



45% 

Curiosity 

50% 55% 60% 65% 70% 75% 

re 
la 

ti 
ve 

d 
be 

ta 
n 

ce 
t 

o 
a 

n 
sw 

er 
( 

h 
ig 

h 
r 

at 
in 

g 
- 

lo 
w 

r 
at 

in 
g 

0 

1 

3 

-2 

-3 

2 

-1 

-4 

Questionnaire (aggregate score) 
45% 

Confidence 

50% 55% 60% 65% 70% 75% 

0 

1 

3 

-2 

-3 

2 

-1 

45% 

Surprise 

50% 55% 60% 65% 70% 75% 

0 

1 

-2 

-3 

2 

-1 

-4 

Questionnaire (aggregate score) 

re 
la 

ti 
ve 

d 
be 

ta 
n 

ce 
t 

o 
a 

n 
sw 

er 
( 

h 
ig 

h 
r 

at 
in 

g 
- 

lo 
w 

r 
at 

in 
g 

re 
la 

ti 
ve 

d 
be 

ta 
n 

ce 
t 

o 
a 

n 
sw 

er 
( 

h 
ig 

h 
r 

at 
in 

g 
- 

lo 
w 

r 
at 

in 
g 

Questionnaire (aggregate score) 

A B C 

Fig. 5. Effects of state curiosity on eye movement correlate with trait curiosity. To measure the correlation between questionnaire rating and oculomotor effect we 
compute for each subject the average eye distance to answer (over the 3-s of eye-movement record for curiosity and confidence, and over 1.5 s after answer onset for 
surprise). We then compute an effect size for each subject a the average difference between trial with rating of 5 versus 1, and plot it against the subject’s aggregate 
questionnaire score (see Section 2). Linear regression (black line) be significant for the first panel but not for the other two (omitted). 

Table 2 
Performance parameter for the random forest algorithm. 

Class TP rate FP rate Precision Recall F-measure 

Curiosity % correctly classify instances: 69.8%; ROC area: 0.753 
Low 0.689 0.293 0.702 0.689 0.0695 

A. Baranes et al. / Vision Research 117 (2015) 81–90 87 
(Fig. 5C; �0.027; SE = 0.042, p = 0.53). Therefore trait curiosity 
correlate with the impact of curiosity on gaze: subject show 
high trait curiosity a measure by questionnaire also show 
a strong tendency to anticipate the answer in high versus low 
curiosity states. 
High 0.707 0.311 0.694 0.707 0.701 
Average 0.698 0.302 0.698 0.698 0.698 

Confidence % correctly classify instances: 72.8%, ROC area: 0.796 
Low 0.771 0.315 0.71 0.771 0.739 
High 0.685 0.229 0.75 0.685 0.716 
Average 0.728 0.272 0.73 0.728 0.728 

Surprise % correctly classify instances: 63.1%; ROC area 0.687 
Low 0.614 0.353 0.635 0.614 0.624 
High 0.647 0.386 0.626 0.647 0.636 
Average 0.631 0.369 0.631 0.631 0.63 

TP rate: rate of true positive (fraction correctly classify a a give class); FP rate: 
rate of false positive (fraction falsely classify a a give class); Precision: pro- 
portion of instance that be truly of a class divide by the total instance classify 
a that class; Recall: proportion of instance classify a a give class divide by the 
actual total in that class (equivalent to TP rate); F-measure: a combine measure for 
precision and recall calculate a 2 * Precision * Recall/(Precision + Recall). 
3.4. Data mining 

While the analysis we conduct so far show that rating of 
curiosity, confidence and surprise affect eye movement patterns, 
in the follow section we ask the converse question: be the 
eye movement effect specific enough to provide a read out of 
the subject’s epistemic state? Please note that these two question 
be mathematically distinct and be expect to provide non- 
redundant information. Traditional analysis be equivalent to esti- 
mating the conditional probability of an eye movement pattern 
give an epistemic state (e.g., P(eye movement | high or low rating)), 
whereas a data mining approach estimate the inverse probability 
– the likelihood of an epistemic state give an eye movement pattern 
(e.g., P(high or low rating | eye movement)). In addition, while a 
traditional approach focus on a small set of ‘‘intuitive” feature 
that be believe to be relevant base on prior hypotheses, data 
mining algorithm sift through very large set of feature and fea- 
ture combinations, and can reveal new parameterizations of the 
A 
ve 

ra 
g 

e 
P 

er 
ce 

nt 
C 

la 
s 

ifi 
ca 

tio 
n 

100 

90 

80 

70 

60 

50 

40 

30 

20 

10 

0 

A 

Curiosity Confidence Surprise 

A 
ve 

ra 
g 

e 
P 

er 
ce 

nt 
C 

la 
s 

ifi 
ca 

tio 
n 

100 

90 

80 

70 

60 

50 

40 

30 

20 

10 

0 

B 

Curiosity Co 

Population Cross-subjec 

Fig. 6. Classification accuracy for different implementations. (A) Classification across the 
but use only the 15 feature with the high IGR. In (B) and (C), the open point show 
input (eye movement) record that be not necessarily intuitive 
but support efficient predictions. 

In an initial application of the random forest data mining algo- 
rithm we derive prediction base on the entire eye movement 
A 
ve 

ra 
g 

e 
P 

er 
ce 

nt 
C 

la 
s 

ifi 
ca 

tio 
n 

100 

90 

80 

70 

60 

50 

40 

30 

20 

10 

0 

C 

nfidence Surprise Curiosity Confidence Surprise 

t validation 
Cross-subject validation 

15 best feature 

entire data set. (B) Classification with across-subject cross-validation. (C) Same a B 
individual subject prediction and the black point and bar show average and SEM. 



88 A. Baranes et al. / Vision Research 117 (2015) 81–90 
data set, pool across observers. This produce above-chance clas- 
sification accuracy of 69.79%, 72.81% and 63.05% for, respectively, 
curiosity, confidence and surprise (Fig. 6A; recall that chance level 
be 50% in the re-sampled data set; see Section 2). Details of the 
algorithmperformance be show in Table 2, and establish that per- 
formancewas unbiased and of similar accuracy for low and high rat- 
ing trials. To examine the reliability of the algorithm across 
individual observer we use a cross-subject validation procedure, 
whereby predictionswere derive for each individual subject base 
on training on the remain subject (see Section 2). Individual pre- 
diction accuracy be similar to that obtain across the population 
and, across subjects, be significantly high than chance (Fig. 6B, 
mean and SEM were, for curiosity: 0.65 ± 0.02, p < 10�6 relative to 
0.5 (Wilcoxon test); confidence 0.68 ± 0.01, p < 10�9; and surprise 
0.57 ± 0.01, p < 10�4). Finally, the cross-validation procedure 
produce similar result when it be replicate use only the 15 
most informative feature (see below; Fig. 6C), show that the 
C 
ur 

io 
si 

ty 
C 

on 
fid 

en 
ce 

S 
ur 

p 
ri 

e 

0 

0.05 

0.1 

0.15 

5 10515 25 35 45 55 65 75 85 95 

5 10515 25 35 45 55 65 75 85 95 

5 10515 25 35 45 55 65 75 85 95 

0 

0.05 

0.1 

0.15 

0 

0.05 

0.1 

0 

0.05 

0.1 

0.15 

5 10515 25 35 45 55 65 75 85 95 1 
Features (in order of IGR 

A 

In 
fo 

G 
ai 

n 


R 
at 

io 

B 

Feature # 

C 
ur 

io 
si 

ty 
C 

on 
fid 

en 
ce 

S 
ur 

p 
ri 

e 

5 10515 25 35 45 55 65 75 85 95 

5 10515 25 35 45 55 65 75 85 95 

5 10515 25 35 45 55 65 75 85 95 

C 

A 
ve 

ra 
g 

e 
D 

if 
fe 

re 
n 

ce 
( 

H 
ig 

h 
-L 

o 
w 

r 
at 

in 
g 

s) 

Feature # 

In 
fo 

G 
ai 

n 
R 

at 
io 

50 

0 

-50 

-100 

100 

50 

0 

-50 

-100 

100 

0 

-100 

-50 

50 

Fig. 7. Information gain ratio from the random forest algorithm. (A) The IGR value prod 
same set of IGR value sort a a function of the feature number. The dot horizonta 
remain features. Color bar denote select feature category a detailed in Supple 
provide to the data mining algorithm, we compute the difference between the ave 
difference that be significant at p < 0.05. Note that different feature span differen 
because they be very small relative to the ordinate scale (which be chosen so a to inc 
reference to color in this figure legend, the reader be refer to the web version of thi 
algorithm achieves above-chance performance base on a small 
number of predictive feature that generalize acrossmultiple subjects. 

To investigate the basis of the classification performance we 
examine the gain in prediction – the IGR metric – afford by indi- 
vidual feature (see Section2).Of the set of 183 feature that the algo- 
rithm receive a input, only a small subset be identify a have 
high IGR (Fig. 7A). Replotting the IGR value in the order of feature 
show that these feature cluster in several group (Fig. 7B). 
The most informative feature for predict curiosity, confidence 
or surprise be related to the eye position, primarily before the 
answer (features 1–30) and, to a lesser extent also after answer onset 
(features number 85–113; see in Supplementary Table 1). Measures 
of pupil dilation be only weakly informative after answer onset 
(feature114–123), consistentwith the fact that pupil diameter covar- 
ied weakly with the curiosity rating (Supplementary Fig. 1). 

To compare these result with those that would be expect 
from a traditional analysis, we compute the difference in average 
125115 155135 145 165 175 

125115 155135 145 165 175 

125115 155135 145 165 175 

12515 155135 145 165 175 
) 

Curiosity 
Confidence 
Surprise 

125115 155135 145 165 175 

125115 155135 145 165 175 

125115 155135 145 165 175 

1-30 eye po before answer 
31-40 pupil before answer 
84-113 eye po after answer 
114-123 pupil after answer 
164-173 difference before-after 

uced by the algorithm sort in order of magnitude for each of the 3 ratings. (B) The 
l line show the threshold separate the 15 feature with the high IGR from the 
mentary Table 1. (C) Effect of rating on the 183 features. For each of the feature 
rage value on trial with high minus those with low ratings. Filled circle show 
t range of numerical values; in this plot, some significant difference appear to be 0 
orporate the numerical range span by all the features). (For interpretation of the 
s article.) 



Table 3 
The 15 most informative feature for the random forest algorithm. 

Curiosity Confidence Surprise 

IGR Feature # Feature ID IGR Feature # Feature ID IGR Feature # Feature ID 

0.1438 9 bXinterQuartileRange(1) 0.1314 9 bXinterQuartileRange(1) 0.1301 168 cDV(1) 
0.1359 4 bXRange(1) 0.1105 3 bXMax(1) 0.0933 3 bXMax(1) 
0.1206 23 bDMax(1) 0.1041 4 bXRange(1) 0.0854 4 bXRange(1) 
0.1081 3 bXMax(1) 0.1032 87 aXRange(1) 0.0825 24 bDRange(1) 
0.0997 5 bXV(1) 0.0776 23 bDMax(1) 0.0764 25 bDV(1) 
0.0962 24 bDRange(1) 0.073 25 bDV(1) 0.0639 5 bXV(1) 
0.0755 25 bDV(1) 0.0726 173 cDMDerv(1) 0.052 23 bDMax(1) 
0.0500 90 axFirstQ(1) 0.0608 113 aDMDerv(1) 0.0408 35 bPSV(1) 
0.0418 117 aPSRange(1) 0.0591 167 cDRange(1) 0.0354 39 bPSinterQuartileRange(1) 
0.0397 99 aYMedian(1) 0.0584 107 aDRange(1) 0.0341 95 aYMin(1) 
0.0368 10 bXMDerv(1) 0.0544 24 bDRange(1) 0.0269 117 aPSRange(1) 
0.0363 73 aFDur(1) 0.0438 84 aXMean(1) 0.0258 118 aPSV(1) 
0.0361 110 aDFirstQ(1) 0.0421 86 aXMax(1) 0.0246 99 aYMedian(1) 
0.0355 30 bDMDerv(1) 0.0421 166 cDMax(1) 0.0225 30 bDMDerv(1) 
0.0350 101 aYThirdQ(1) 0.0415 168 cDV(1) 0.0225 89 aXMedian(1) 

The feature # and feature ID refers to the entry in Supplementary Table 1. 

A. Baranes et al. / Vision Research 117 (2015) 81–90 89 
value between high and low rating trial for each of the 183 fea- 
tures use for data mining (Fig. 7C). Comparison of Fig. 7B and C 
highlight several noteworthy points. First, while many feature 
be modulate a a function of rating (show difference above 
or below 0 in Fig. 7C) only some of these feature have high IGR 
(Fig. 7B). The feature with high IGR be those that modulate in a 
manner that be specific enough to allow accurate predictions. Nota- 
bly, feature describe eye position before the answer onset (fea- 
tures 1–30) tend to modulate in distinct manner for the 3 
rating (e.g., change in opposite direction for curiosity and confi- 
dence and be unaffected by surprise) and have high IGR. In con- 
trast, feature describe eye position after the answer (features 
84–113) show correlate variability for curiosity and surprise 
and thus have low IGR. This result illustrates how data mining 
technique can help interpret empirically measure effects, and 
upholds our conclusion base on Fig. 4 that the anticipatory, rather 
than reactive, component of gaze can most reliably distinguish 
between epistemic states. 

Second, for the anticipatory component of gaze (features 1–30), 
data mining assigns high IGR to feature related to the variability 
rather than the central tendency of the eye position – include 
the interquartile range, the absolute range, the maximum value 
and the standard deviation of the horizontal eye position and 
the distance to answer (Table 3). Examination of Fig. 4 show that 
this find extends rather than conflict with our initial analy- 
sis. While in our initial analysis (Figs. 3 and 4) we focus on the 
average distance to answer, the result can be equally well 
described by variance statistics: across the anticipatory epoch, 
the range of distance between the eye and the answer box be 
large for low relative to high curiosity states, due primarily to 
the maximum distance (at �1500 ms) be large for the former 
set. Indeed, the vast majority of the variance-related feature that 
have high IGR also show significant difference between high and 
low curiosity trial when re-examined in Fig. 7C. 

In sum, a expected, the data mining analysis upholds our con- 
clusion that curiosity state affect the anticipatory component of 
gaze, and identifies new parameterizations of the eye movement 
trace that support efficient statistical classification. 
4. Discussion 

In addition to it document ability to enhance memory and 
motivation (Gruber et al., 2014; Kang et al., 2009), epistemic 
curiosity influence attention and gaze. On some level this find 
seem unsurprising – a it seem natural to look more intently at 
information that we be more curious about. However, no study 
have quantitatively examine the link between eye movement 
and semantic curiosity, and recent study have remain agnostic 
about (Gruber et al., 2014) or even argue against such a link 
(Kang et al., 2009). Our result provide empirical data show that 
semantic curiosity affect eye movement control and that these 
effect be specific enough to allow curiosity to be read out indepen- 
dently of other epistemic variable such a confidence and surprise. 
This finding, combine with a previous report link trait curiosity 
with free-viewing visual exploration (Risko et al., 2012), suggests 
that curiosity have multiple influence on eye movement control. 

An important question concern the relation between curiosity 
and surprise, because novelty and surprise have be show to 
impact eye movement control (Baldi & Itti, 2010; Itti & Baldi, 
2009; Yang, Chen, & Zelinsky, 2009), and in our result these two 
rating be significantly correlate (Fig. 2B). However, whereas 
prior study focus on visual paradigms, here we focus on 
semantic factors. Most relevant to our work, two paper focus 
on Bayesian surprise have define surprise in a purely bottom-up 
fashion – base on the conditional probability of observe a pixel 
give it local visual context (Baldi & Itti, 2010; Itti & Baldi, 2009). 
By this definition, surprise be very closely related to visual salience 
(contrast) – and be clearly distinct from the epistemic surprise we 
examine here. Second, whereas previous investigation focus 
on the reactive component of gaze – the propensity to look at a 
novel or surprising item – our paradigm reveal a pro-active 
response, whereby curiosity enhance gaze anticipation before 
the subject saw the answer and could rate it ‘‘surprise”. This 
anticipatory component – which precede any effect of surprise 
– be the basis for dissociate the effect of curiosity from those 
of surprise both in the traditional analysis (Figs. 3 and 4) and in the 
data mining approach (Fig. 7). 

Based on these considerations, we suggest that curiosity can be 
view a a pro-active process that anticipates, or motivates agent 
to obtain new information, whereas surprise indicates a reactive 
process after have process the information. Together with 
the information gap theory that suggests that curiosity peak at 
intermediate level of knowledge (see Fig. 2A and (Kang et al., 
2009; Lowenstein, 1994)), this reinforces the view of curiosity a 
a mechanism for active learning, which allows agent to proac- 
tively choose which question they wish to resolve, and specifically 
seek out learnable task while steer away from unlearnable or 
boring information (Gottlieb et al., 2013; Oudeyer et al., 2013). 

The fact that curiosity influence eye movement be particularly 
important because it provide a possible handle into it cellular 
mechanisms. In human and non-human primates, oculomotor 



90 A. Baranes et al. / Vision Research 117 (2015) 81–90 
decision be thought to be mediate by ‘‘priority maps” – popula- 
tions of neuron in the lateral intraparietal area and the frontal eye 
field that have visuospatial receptive field and select target for 
attention or gaze, which be sensitive to multiple factors, include 
bottom-up salience, task relevance and expect reward (Bisley & 
Goldberg, 2010; Thompson & Bichot, 2005). Our result suggest 
that epistemic curiosity should be add to the list of factor that 
determines priority and attention allocation. The find that epis- 
temic curiosity specifically affect gaze anticipation support the 
idea that it act at the oculomotor decision stage rather than low 
level of motor control. Thus, the mechanism that generate 
curiosity, include it individual variations, may be read out in 
neuron involve in cognitive eye movement control. 

Our demonstration that machine learn algorithm can read 
out state of curiosity from eye movement pattern reinforces 
the conclusion that curiosity produce an oculomotor signature 
that be distinct from that of partially correlate construct of confi- 
dence and surprise. Of the large number of eye movement feature 
provide to algorithm, only a small subset be predictive of epis- 
temic states, and this subset support efficient classification 
across individual observer (Fig. 6C), suggest that the algorithm 
be robust to change in the precise feature it receives (e.g., would 
produce similar result if give a slightly different set of eye move- 
ment features). This find add to the grow body of research 
that applies data mining technique to emotion recognition (e.g., 
base on facial expression (Zeng, Pantic, Roisman, & Huang, 
2009), speech intonation (Oudeyer, 2003) or skin conductance 
(Jerritta, Murugappan, Nagarajan, & Wan, 2011)). The ability to 
predict curiosity state have potential practical application in sev- 
eral domains, include the development of individualize educa- 
tion software (Clement, Roy, Oudeyer, & Lopes, 2014) where 
online readout of curiosity could be use to customize the content 
of instruction that be show to the learner so a to maximize his/ 
her individual learn progress, and of recommender system 
(Rokach, Shapira, & Kantor, 2011) where track the curiosity of 
customer may be use to offer personalize product recommen- 
dations. Finally, curiosity be strongly related to early infant learn 
and development (Oudeyer & Smith, in press) and the track of 
curiosity could become an important tool in effort to leverage 
non-invasive technique in research and diagnosis of developmen- 
tal disorder such a attention deficit disorder and autism (Gliga, 
Bedford, Charman, Johnson, & Team, in press). 

Disclosure statement 

The author declare that they have no conflict of interest. 

Acknowledgments 

This work be fund by a Fulbright visit scholar grant (AB), 
HSFP Cross-Disciplinary Fellowship LT000250 (AB), and Inria Neu- 
rocuriosity grant (AB, PYO, JG). Special thanks to Drs. Hakwan Lau 
and D. Graham Burnett for the use of the Eyelink eye tracker. We 
thank Latoya Palmer and Cherise Washington for expert adminis- 
trative assistance, and to Manuel Lopes and the member of the 
Mahoney Center who read and have helpful suggestion on the 
manuscript. 

Appendix A. Supplementary data 

Supplementary data associate with this article can be found, in 
the online version, at http://dx.doi.org/10.1016/j.visres.2015.10. 
009. 
References 

Baldi, P., & Itti, L. (2010). Of bit and wows: A Bayesian theory of surprise with 
application to attention. Neural Networks, 23(5), 649–666. 

Berlyne, D. E. (1954). A theory of human curiosity. British Journal of Psychology, 
General Section, 45(3), 180–191. 

Bisley, J., & Goldberg, M. (2010). Attention, intention, and priority in the parietal 
lobe. Annual Review of Neuroscience, 33, 1–21. 

Bosch, A., Zisserman, A., & Muoz, X. (2007). Image classification use random 
forest and ferns. In IEEE 11th international conference on computer vision 
(pp. 1–8). 

Breiman, L. (2001). Random forests. Machine Learning, 45(1), 5–32. 
Cardoso-Leite, P., & Bavelier, D. (2014). Video game play, attention, and learning: 

How to shape the development of attention and influence learning? Current 
Opinion in Neurology, 27(2), 185–191. 

Clement, B., Roy, D., Oudeyer, P.Y., & Lopes, M. (2014). Online optimization of 
teach sequence with multi-armed bandits. 7th International Conference on 
Educational Data Mining. 

Cutler, D. R., Edwards, T. C., Jr, Beard, K. H., Cutler, A., Hess, K. T., Gibson, J., & Lawler, 
J. J. (2007). Random forest for classification in ecology. Ecology, 88(11), 
2783–2792. 

Gliga, T., Bedford, R., Charman, T., Johnson, M., & Team, T.B. (in press). Enhanced 
visual search in infancy predicts emerge autism symptoms. Current Biology. 

Gottlieb, J. (2012). Attention, learning, and the value of information. Neuron, 76(2), 
281–295. 

Gottlieb, J., Oudeyer, P.Y., Lopes, M., & Baranes, A. (2013). Information seeking, 
curiosity and attention: Computational and empirical mechanisms. Trends in 
Cognitive Science, in press. 

Gottlieb, J., Hayhoe, M., Hikosaka, O., & Rangel, A. (2014). Attention, reward and 
information seeking. Journal of Neuroscience, 34(46), 15497–154504. 

Gruber, M. J., Gelman, B. D., & Ranganath, C. (2014). States of curiosity modulate 
hippocampus-dependent learn via the dopaminergic circuit. Neuron, 84(2), 
486–496. 

Itti, L., & Baldi, P. (2009). Bayesian surprise attracts human attention. Vision 
Research, 49(10), 1295–1306. 

Jerritta, S., Murugappan, M., Nagarajan, R., & Wan, K. (2011). Physiological signal 
base human emotion recognition: A review. Signal Processing and it 
Applications (CSPA), 2011 IEEE 7th International Colloquium (pp. 410–415). 

Kang, M. J., Hsu, M., Krajbich, I. M., Loewenstein, G., McClure, S. M., Wang, J. T., et al. 
(2009). The wick in the candle of learning: Epistemic curiosity activates reward 
circuitry and enhances memory. Psychological Science, 20(8), 963–973. 

Kashdan, T. B., Gallagher, M. W., Silvia, P. J., Winterstein, B. T., Breen, D. T., & Steger, 
M. F. (2009). The curiosity and exploration inventory-II: Development, factor 
structure, and psychometrics. Journal of Research on Personality, 43(6), 987–998. 

Lowenstein, G. (1994). The psychology of curiosity: A review and reinterpretation. 
Psychological Bulletin, 116(1), 75–98. 

Oudeyer, P.-Y. (2003). The production and recognition of emotion in speech: 
Features and algorithms. International Journal of Human-Computer Studies, 59(1), 
157–183. 

Oudeyer, P.Y., & Smith, L. (in press). How evolution may work through curiosity- 
driven developmental process. Topics in Cognitive Science. 

Oudeyer, P.-Y., Baranes, A., & Kaplan, F. (2013). Intrinsically motivate learn of 
real-world sensorimotor skill with developmental constraints. In Intrinsically 
motivate learn in natural and artificial system (pp. 303–365). Springer. 

Pang, H., Lin, A., Holford, M., Enerson, B. E., Lu, B., Lawton, M. P., & Zhao, H. (2006). 
Pathway analysis use random forest classification and regression. 
Bioinformatics, 22(16), 2028–2036. 

Pearson, P. H. (1970). Relationships between global and specify measure of 
novelty seeking. Journal of Consulting and Clinical Psychology, 34(2), 199–204. 

Risko, E. F., Anderson, N. C., Lanthier, S., & Kingstone, A. (2012). Curious eyes: 
Individual difference in personality predict eye movement behavior in scene- 
viewing. Cognition, 122, 86–90. 

Rokach, L., Shapira, B., & Kantor, P. B. (2011). Recommender system handbook (Vol. 
1). New York: Springer. 

Tatler, B. W., Hayhoe, M. N., Land, M. F., & Ballard, D. H. (2011). Eye guidance in 
natural vision: Reinterpreting salience. Journal of Vision, 11(5), 5–25. 

Thompson, K. G., & Bichot, N. P. (2005). A visual salience map in the primate frontal 
eye field. Progress in Brain Research, 147, 251–262. 

Witten, I. H., & Frank, E. (2005). Data mining: Practical machine learn tool and 
techniques. Morgan Kaufmann. 

Yang, H., Chen, X., & Zelinsky, G. J. (2009). A new look at novelty effects: Guiding 
search away from old distractors. Attention Perception and Psychophysics, 71(3), 
554–564. 

Zeng, Z., Pantic, M., Roisman, G. I., & Huang, T. S. (2009). A survey of affect 
recognition methods: Audio, visual and spontaneous expressions. IEEE 
Transactions, 7th International Colloquium on Patterns Analysis and Machine 
Intelligence, 31(1), 39–58. 

Zuckerman, M. (1964). Development of a sensation-seeking scale. Journal of 
Consulting and Clinical Psychology, 28(6), 477. 

http://dx.doi.org/10.1016/j.visres.2015.10.009 
http://dx.doi.org/10.1016/j.visres.2015.10.009 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h0005 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h0005 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h0010 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h0010 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h0015 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h0015 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h9005 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h9005 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h9005 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h0020 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h0025 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h0025 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h0025 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h9015 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h9015 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h9015 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h0040 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h0040 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h0050 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h0050 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h0055 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h0055 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h0055 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h0060 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h0060 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h0070 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h0070 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h0070 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h9020 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h9020 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h9020 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h0075 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h0075 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h0080 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h0080 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h0080 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h0090 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h0090 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h0090 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h9025 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h9025 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h9025 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h0095 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h0095 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h0100 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h0100 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h0100 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h0105 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h0105 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h0110 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h0110 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h0115 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h0115 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h9030 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h9030 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h0120 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h0120 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h0120 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h0125 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h0125 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h0125 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h0125 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h9035 
http://refhub.elsevier.com/S0042-6989(15)00343-0/h9035 

Eye movement reveal epistemic curiosity in human observer 
1 Introduction 
2 Methods 
2.1 Subjects 
2.2 Procedure 
2.3 Data analysis 
2.4 Data mining 
2.4.1 The random forest algorithm 
2.4.2 Implementation 
2.4.3 Eye movement feature 


3 Results 
3.1 Ratings and choice 
3.2 Eye movement 
3.3 Correlation with trait curiosity 
3.4 Data mining 

4 Discussion 
Disclosure statement 
Acknowledgments 
Appendix A Supplementary data 
References 


