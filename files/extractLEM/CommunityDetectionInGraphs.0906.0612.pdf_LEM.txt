


















































Community detection in graph 

Santo Fortunato∗ 

Complex Networks and Systems Lagrange Laboratory, ISI Foundation, Viale S. Severo 65, 10133, Torino, 
I-ITALY. 

The modern science of network have brought significant advance to our understand of complex 
systems. One of the most relevant feature of graph represent real system be community 
structure, or clustering, i. e. the organization of vertex in clusters, with many edge join 
vertex of the same cluster and comparatively few edge join vertex of different clusters. Such 
clusters, or communities, can be consider a fairly independent compartment of a graph, play 
a similar role like, e. g., the tissue or the organ in the human body. Detecting community 
be of great importance in sociology, biology and computer science, discipline where system be 
often represent a graphs. This problem be very hard and not yet satisfactorily solved, despite 
the huge effort of a large interdisciplinary community of scientist work on it over the past few 
years. We will attempt a thorough exposition of the topic, from the definition of the main element 
of the problem, to the presentation of most method developed, with a special focus on technique 
design by statistical physicists, from the discussion of crucial issue like the significance of 
cluster and how method should be test and compare against each other, to the description 
of application to real networks. 

Contents 

I. Introduction 2 

II. Communities in real-world network 4 

III. Elements of Community Detection 8 
A. Computational complexity 9 
B. Communities 9 

1. Basics 9 
2. Local definition 10 
3. Global definition 11 
4. Definitions base on vertex similarity 12 

C. Partitions 13 
1. Basics 13 
2. Quality functions: modularity 14 

IV. Traditional method 16 
A. Graph partition 16 
B. Hierarchical cluster 19 
C. Partitional cluster 19 
D. Spectral cluster 20 

V. Divisive algorithm 23 
A. The algorithm of Girvan and Newman 23 
B. Other method 25 

VI. Modularity-based method 27 
A. Modularity optimization 27 

1. Greedy technique 27 
2. Simulated anneal 29 
3. Extremal optimization 29 
4. Spectral optimization 30 
5. Other optimization strategy 33 

B. Modifications of modularity 34 
C. Limits of modularity 38 

VII. Spectral Algorithms 41 

VIII. Dynamic Algorithms 43 
A. Spin model 43 

∗Electronic address: fortunato@isi.it 

B. Random walk 45 

C. Synchronization 47 

IX. Methods base on statistical inference 48 

A. Generative model 49 

B. Blockmodeling, model selection and information 
theory 52 

X. Alternative method 54 

XI. Methods to find overlap community 58 

A. Clique percolation 58 

B. Other technique 60 

XII. Multiresolution method and cluster hierarchy 62 

A. Multiresolution method 63 

B. Hierarchical method 65 

XIII. Detection of dynamic community 66 

XIV. Significance of cluster 70 

XV. Testing Algorithms 73 

A. Benchmarks 74 

B. Comparing partitions: measure 77 

C. Comparing algorithm 79 

XVI. General property of real cluster 82 

XVII. Applications on real-world network 85 

A. Biological network 85 

B. Social network 86 

C. Other network 88 

XVIII. Outlook 90 

A. Elements of Graph Theory 92 

1. Basic Definitions 92 

2. Graph Matrices 94 

3. Model graph 94 

References 96 

ar 
X 

iv 
:0 

90 
6. 

06 
12 

v2 
[ 

ph 
y 

ic 
s. 

so 
c- 

ph 
] 

2 
5 

Ja 
n 

20 
10 

mailto:fortunato@isi.it 


2 

I. INTRODUCTION 

The origin of graph theory date back to Euler’s solu- 
tion of the puzzle of Königsberg’s bridge in 1736 (Euler, 
1736). Since then a lot have be learn about graph 
and their mathematical property (Bollobas, 1998). In 
the 20th century they have also become extremely useful 
a representation of a wide variety of system in different 
areas. Biological, social, technological, and information 
network can be study a graphs, and graph analysis 
have become crucial to understand the feature of these 
systems. For instance, social network analysis start in 
the 1930’s and have become one of the most important 
topic in sociology (Scott, 2000; Wasserman and Faust, 
1994). In recent times, the computer revolution have pro- 
vided scholar with a huge amount of data and computa- 
tional resource to process and analyze these data. The 
size of real network one can potentially handle have also 
grown considerably, reach million or even billion of 
vertices. The need to deal with such a large number of 
unit have produce a deep change in the way graph be 
approach (Albert and Barabási, 2002; Barrat et al., 
2008; Boccaletti et al., 2006; Mendes and Dorogovtsev, 
2003; Newman, 2003; Pastor-Satorras and Vespignani, 
2004). 

Graphs represent real system be not regular like, 
e. g., lattices. They be object where order coexists with 
disorder. The paradigm of disorder graph be the ran- 
dom graph, introduce by P. Erdös and A. Rényi (Erdös 
and Rényi, 1959). In it, the probability of have an 
edge between a pair of vertex be equal for all possible 
pair (see Appendix). In a random graph, the distribu- 
tion of edge among the vertex be highly homogeneous. 
For instance, the distribution of the number of neigh- 
bours of a vertex, or degree, be binomial, so most ver- 
tices have equal or similar degree. Real network be 
not random graphs, a they display big inhomogeneities, 
reveal a high level of order and organization. The de- 
gree distribution be broad, with a tail that often follow 
a power law: therefore, many vertex with low degree 
coexist with some vertex with large degree. Further- 
more, the distribution of edge be not only globally, but 
also locally inhomogeneous, with high concentration of 
edge within special group of vertices, and low concen- 
trations between these groups. This feature of real net- 
work be call community structure (Girvan and New- 
man, 2002), or clustering, and be the topic of this review 
(for early review see Refs. (Danon et al., 2007; Fortu- 
nato and Castellano, 2009; Newman, 2004a; Porter et al., 
2009; Schaeffer, 2007)). Communities, also call cluster 
or modules, be group of vertex which probably share 
common property and/or play similar role within the 
graph. In Fig. 1 a schematic example of a graph with 
community be shown. 

Society offer a wide variety of possible group organi- 
zations: families, work and friendship circles, villages, 
towns, nations. The diffusion of Internet have also lead 
to the creation of virtual groups, that live on the Web, 

� 
� 
� 
� 

� 
� 
� 
� 

� 
� 
� 
� 

� 
� 
� 
� � 

� 
� 
� 

� 
� 
� 
� 

� 
� 
� 
� 

� 
� 
� 
� 

� 
� 
� 
� 

� 
� 
� 
� 
� 
� 
� 
� 

� 
� 
� 
� 

� 
� 
� 

� 
� 
� 

�� 
�� 
�� 

�� 
�� 
�������� 

� 
� 
� 

� 
� 
� 

� 
� 
� 
� 

� 
� 
� 
� 

�� 
�� 
�� 

�� 
�� 
�� 

������ 

�� 
�� 
�� 

�� 
�� 
�� 

�� 
�� 
�� 
�� 

� 
� 
� 
� 

�� 
�� 
�� 
�� 

� 
� 
� 
� 

� 
� 
� 
��� 

�� 
�� 
�� 

� 
� 
� 
� 
� 
� 
� 

� 
� 
� 
� 
� 
� 
� 

��� 
��� 
��� 
��� 
��� 

��� 
��� 
��� 
��� 
��� 

��� 
��� 
��� 
��� 
��� 
��� 
��� 

��� 
��� 
��� 
��� 
��� 
��� 
��� 

����� 
����� 
����� 

����� 
����� 
����� 

���� 
���� 
���� 
���� 
���� 
���� 
���� 
���� 
���� 

���� 
���� 
���� 
���� 
���� 
���� 
���� 
���� 
���� 

FIG. 1 A simple graph with three communities, enclose 
by the dash circles. Reprinted figure with permission from 
Ref. (Fortunato and Castellano, 2009). c©2009 by Springer. 

like online communities. Indeed, social community have 
be study for a long time (Coleman, 1964; Freeman, 
2004; Kottak, 2004; Moody and White, 2003). Communi- 
tie also occur in many networked system from biology, 
computer science, engineering, economics, politics, etc. 
In protein-protein interaction networks, community be 
likely to group protein have the same specific function 
within the cell (Chen and Yuan, 2006; Rives and Galitski, 
2003; Spirin and Mirny, 2003), in the graph of the World 
Wide Web they may correspond to group of page deal- 
ing with the same or related topic (Dourisboure et al., 
2007; Flake et al., 2002), in metabolic network they may 
be related to functional module such a cycle and path- 
way (Guimerà and Amaral, 2005; Palla et al., 2005), 
in food web they may identify compartment (Krause 
et al., 2003; Pimm, 1979), and so on. 

Communities can have concrete applications. Cluster- 
ing Web client who have similar interest and be ge- 
ografically near to each other may improve the perfor- 
mance of service provide on the World Wide Web, in 
that each cluster of client could be serve by a dedi- 
cat mirror server (Krishnamurthy and Wang, 2000). 
Identifying cluster of customer with similar interest 
in the network of purchase relationship between cus- 
tomers and product of online retailer (like, e. g., 
www.amazon.com) enables to set up efficient recommen- 
dation system (Reddy et al., 2002), that good guide 
customer through the list of item of the retailer and 
enhance the business opportunities. Clusters of large 
graph can be use to create data structure in order 
to efficiently store the graph data and to handle naviga- 



3 

tional queries, like path search (Agrawal and Jagadish, 
1994; Wu et al., 2004). Ad hoc network (Perkins, 2001), 
i. e. self-configuring network form by communication 
node act in the same region and rapidly change 
(because the device move, for instance), usually have 
no centrally maintain rout table that specify how 
node have to communicate to other nodes. Grouping the 
node into cluster enables one to generate compact rout- 
ing table while the choice of the communication path 
be still efficient (Steenstrup, 2001). 

Community detection be important for other reasons, 
too. Identifying module and their boundary allows for 
a classification of vertices, accord to their structural 
position in the modules. So, vertex with a central posi- 
tion in their clusters, i. e. share a large number of edge 
with the other group partners, may have an important 
function of control and stability within the group; ver- 
tices lie at the boundary between module play an im- 
portant role of mediation and lead the relationship and 
exchange between different community (alike to Cser- 
mely’s “creative elements” (Csermely, 2008)). Such clas- 
sification seem to be meaningful in social (Burt, 1976; 
Freeman, 1977; Granovetter, 1973) and metabolic net- 
work (Guimerà and Amaral, 2005). Finally, one can 
study the graph where vertex be the community and 
edge be set between cluster if there be connection be- 
tween some of their vertex in the original graph and/or 
if the module overlap. In this way one attains a coarse- 
grain description of the original graph, which unveils 
the relationship between module 1. Recent study indi- 
cate that network of community have a different degree 
distribution with respect to the full graph (Palla et al., 
2005); however, the origin of their structure can be ex- 
plain by the same mechanism (Pollner et al., 2006). 

Another important aspect related to community struc- 
ture be the hierarchical organization displayed by most 
networked system in the real world. Real network be 
usually compose by community include small com- 
munities, which in turn include small communities, etc. 
The human body offer a paradigmatic example of hier- 
archical organization: it be compose by organs, organ 
be compose by tissues, tissue by cells, etc. Another 
example be represent by business firms, who be char- 
acterized by a pyramidal organization, go from the 
worker to the president, with intermediate level corre- 
sponding to work groups, department and management. 
Herbert A. Simon have emphasize the crucial role played 
by hierarchy in the structure and evolution of complex 

1 Coarse-graining a graph generally mean mapping it onto a 
small graph have similar properties, which be easy to handle. 
For this purpose, the vertex of the original graph be not nec- 
essarily grouped in communities. Gfeller and De Los Rios have 
propose coarse-graining scheme that keep the property of dy- 
namic process act on the graph, like random walk (Gfeller 
and De Los Rios, 2007) and synchronization (Gfeller and De Los 
Rios, 2008). 

system (Simon, 1962). The generation and evolution of 
a system organize in interrelate stable subsystem be 
much quicker than if the system be unstructured, be- 
cause it be much easy to assemble the small subpart 
first and use them a building block to get large struc- 
tures, until the whole system be assembled. In this way 
it be also far more difficult that error (mutations) occur 
along the process. 

The aim of community detection in graph be to iden- 
tify the module and, possibly, their hierarchical orga- 
nization, by only use the information encode in the 
graph topology. The problem have a long tradition and it 
have appear in various form in several disciplines. The 
first analysis of community structure be carry out by 
Weiss and Jacobson (Weiss and Jacobson, 1955), who 
search for work group within a government agency. 
The author study the matrix of work relationship 
between member of the agency, which be identify by 
mean of private interviews. Work group be separate 
by remove the member work with people of differ- 
ent groups, which act a connector between them. This 
idea of cut the bridge between group be at the ba- 
si of several modern algorithm of community detection 
(Section V). Research on community actually start 
even early than the paper by Weiss and Jacobson. Al- 
ready in 1927, Stuart Rice look for cluster of people 
in small political bodies, base on the similarity of their 
voting pattern (Rice, 1927). Two decade later, George 
Homans show that social group could be reveal by 
suitably rearrange the row and the column of matri- 
ce describe social ties, until they take an approximate 
block-diagonal form (Homans, 1950). This procedure be 
now standard. Meanwhile, traditional technique to find 
community in social network be hierarchical cluster- 
ing and partitional cluster (Sections IV.B and IV.C), 
where vertex be join into group accord to their 
mutual similarity. 

Identifying graph community be a popular topic in 
computer science, too. In parallel computing, for in- 
stance, it be crucial to know what be the best way to 
allocate task to processor so a to minimize the commu- 
nications between them and enable a rapid performance 
of the calculation. This can be accomplish by splitting 
the computer cluster into group with roughly the same 
number of processors, such that the number of physi- 
cal connection between processor of different group be 
minimal. The mathematical formalization of this prob- 
lem be call graph partition (Section IV.A). The first 
algorithm for graph partition be propose in the 
early 1970’s. 

In a seminal paper appear in 2002, Girvan and New- 
man propose a new algorithm, aim at the identifica- 
tion of edge lie between community and their suc- 
cessive removal, a procedure that after some iteration 
lead to the isolation of the community (Girvan and 
Newman, 2002). The intercommunity edge be detect 
accord to the value of a centrality measure, the edge 
betweenness, that express the importance of the role 



4 

of the edge in process where signal be transmit 
across the graph follow path of minimal length. The 
paper trigger a big activity in the field, and many new 
method have be propose in the last years. In partic- 
ular, physicist enter the game, bring in their tool 
and techniques: spin models, optimization, percolation, 
random walks, synchronization, etc., become ingredient 
of new original algorithms. The field have also take ad- 
vantage of concept and method from computer science, 
nonlinear dynamics, sociology, discrete mathematics. 

In this manuscript we try to cover in some detail the 
work do in this area. We shall pay a special atten- 
tion to the contribution make by physicists, but we shall 
also give proper credit to important result obtain by 
scholar of other disciplines. Section II introduces com- 
munities in real networks, and be suppose to make the 
reader acquaint with the problem and it relevance. In 
Section III we define the basic element of community 
detection, i. e. the concept of community and parti- 
tion. Traditional cluster method in computer and 
social sciences, i. e. graph partitioning, hierarchical, 
partitional and spectral cluster be review in Sec- 
tion IV. Modern methods, divide into category base 
on the type of approach, be present in Sections V 
to X. Algorithms to find overlap communities, mul- 
tiresolution and hierarchical techniques, be separately 
described in Sections XI and XII, respectively, whereas 
Section XIII be devote to the detection of community 
evolve in time. We stress that our categorization of the 
algorithm be not sharp, because many algorithm may 
enter more categories: we try to classify them base 
on what we believe be their main feature/purpose, even 
if other aspect may be present. Sections XIV and XV 
be devote to the issue of define when community 
structure be significant, and decide about the quality of 
algorithms’ performances. In Sections XVI and XVII we 
describe general property of cluster found in real net- 
works, and specific application of cluster algorithms. 
Section XVIII contains the summary of the review, along 
with a discussion about future research direction in this 
area. The review make use of several concept of graph 
theory, that be define and explain in the Appendix. 
Readers not acquaint with these concept be urge to 
read the Appendix first. 

II. COMMUNITIES IN REAL-WORLD NETWORKS 

In this section we shall present some strike example 
of real network with community structure. In this way 
we shall see what community look like and why they 
be important. 

Social network be paradigmatic example of graph 
with communities. The word community itself refers to 
a social context. People naturally tend to form groups, 
within their work environment, family, friends. 

In Fig. 2 we show some example of social networks. 
The first example (Fig. 2a) be Zachary’s network of karate 

club member (Zachary, 1977), a well-known graph reg- 
ularly use a a benchmark to test community detection 
algorithm (Section XV.A). It consists of 34 vertices, the 
member of a karate club in the United States, who be 
observe during a period of three years. Edges connect 
individual who be observe to interact outside the ac- 
tivities of the club. At some point, a conflict between 
the club president and the instructor lead to the fission of 
the club in two separate groups, support the instruc- 
tor and the president, respectively (indicated by square 
and circles). The question be whether from the original 
network structure it be possible to infer the composition 
of the two groups. Indeed, by look at Fig. 2a one 
can distinguish two aggregations, one around vertex 33 
and 34 (34 be the president), the other around vertex 1 
(the instructor). One can also identify several vertex 
lie between the two main structures, like 3, 9, 10; such 
vertex be often misclassified by community detection 
methods. 

Fig. 2b display the large connect component of 
a network of collaboration of scientist work at the 
Santa Fe Institute (SFI). There be 118 vertices, repre- 
senting resident scientist at SFI and their collaborators. 
Edges be place between scientist that have publish 
at least one paper together. The visualization layout al- 
low to distinguish disciplinary groups. In this network 
one observes many cliques, a author of the same pa- 
per be all link to each other. There be but a few 
connection between most groups. 

In Fig. 2c we show the network of bottlenose dol- 
phins living in Doubtful Sound (New Zealand) analyze 
by Lusseau (Lusseau, 2003). There be 62 dolphin and 
edge be set between animal that be see together 
more often than expect by chance. The dolphin sep- 
arated in two group after a dolphin left the place for 
some time (squares and circle in the figure). Such group 
be quite cohesive, with several internal cliques, and eas- 
ily identifiable: only six edge join vertex of differ- 
ent groups. Due to this natural classification Lusseau’s 
dolphins’ network, like Zachary’s karate club, be often 
use to test algorithm for community detection (Sec- 
tion XV.A). 

Protein-protein interaction (PPI) network be subject 
of intense investigation in biology and bioinformatics, 
a the interaction between protein be fundamental for 
each process in the cell (Zhang, 2009). Fig. 3 illustrates 
a PPI network of the rat proteome (Jonsson et al., 2006). 
Each interaction be derive by homology from experimen- 
tally observe interaction in other organisms. In our 
example, the protein interact very frequently with each 
other, a they belong to metastatic cells, which have a 
high motility and invasiveness with respect to normal 
cells. Communities correspond to functional groups, i. e. 
to protein have the same or similar functions, which 
be expect to be involve in the same processes. The 
module be label by the overall function or the dom- 
inating protein class. Most community be associate 
to cancer and metastasis, which indirectly show how im- 



5 

4 

20 

22 

21 9 

28 

3 

27 

18 

19 

23 

29 

7 

17 

24 

33 

16 

30 34 

26 

25 

32 
8 

2 
1 

12 

11 

6 

5 

13 

14 

31 

10 
15 

Beak 

Beescratch 

BumperCCL 

Cross 

DN16 

DN21 

DN63 

Double 

Feather 

Fish 

Five 

Fork 

Gallatin 

Grin 

Haecksel 

Hook 

Jet 

Jonah 

Knit 

Kringel 

MN105 

MN23 

MN60 

MN83 

Mus 

Notch 
Number1 

Oscar 

Patchback 

PL 

Quasi 

Ripplefluke 

Scabs 

Shmuddel 

SMN5 

SN100 

SN4 

SN63 

SN89 

SN9 

SN90 

SN96 

Stripes 

Thumper 
Topless 

TR120 

TR77 

TR82 

TR88 

TR99 

Trigger 

TSN103 

TSN83 

Upbang 

Vau 

Wave 

Web 

Whitetip 

Zap 

Zig 

Zipfel 

Agent-based 

Mathematical 

Statistical Physics 

Ecology 

Models 

Structure of RNA 

a 

b 

c 

FIG. 2 Community structure in social networks. a) Zachary’s karate club, a standard benchmark in community detection. The 
color correspond to the best partition found by optimize the modularity of Newman and Girvan (Section VI.A). Reprinted 
figure with permission from Ref. (Donetti and Muñoz, 2004). c©2004 by IOP Publishing and SISSA. b) Collaboration network 
between scientist work at the Santa Fe Institute. The color indicate high level community obtain by the algorithm 
of Girvan and Newman (Section V.A) and correspond quite closely to research division of the institute. Further subdivision 
correspond to small research groups, revolve around project leaders. Reprinted figure with permission from Ref. (Girvan 
and Newman, 2002). c©2002 by the National Academy of Science of the USA. c) Lusseau’s network of bottlenose dolphins. 
The color label the community identify through the optimization of a modify version of the modularity of Newman and 
Girvan, propose by Arenas et al. (Arenas et al., 2008b) (Section XII.A). The partition match the biological classification 
of the dolphin propose by Lusseau. Reprinted figure with permission from Ref. (Arenas et al., 2008b). c©2008 by IOP 
Publishing. 

portant detect module in PPI network is. 

Relationships/interactions between element of a sys- 
tem need not be reciprocal. In many case they have a 
precise direction, that need to be take into account to 
understand the system a a whole. As an example we can 
cite predator-prey relationship in food webs. In Fig. 4 
we see another example, take from technology. The 
system be the World Wide Web, which can be see a a 
graph by represent web page a vertex and the hy- 
perlinks that make user move from one page to another 
a edge (Albert et al., 1999). Hyperlinks be directed: 
if one can move from page A to page B by click on a 

hyperlink of A, one usually do not find on B a hyper- 
link take back to A. In fact, very few hyperlink (less 
than 10%) be reciprocal. Communities of the web graph 
be group of page have topical similarities. Detect- 
ing community in the web graph may help to identify 
the artificial cluster create by link farm in order to 
enhance the PageRank (Brin and Page, 1998) value of 
web site and grant them a high Google ranking. In 
this way one could discourage this unfair practice. One 
usually assumes that the existence of a hyperlink between 
two page implies that they be content-related, and that 
this similarity be independent of the hyperlink direction. 



6 

Proteasome 

Endo/exonuclease 

EGF-like domain 

Matrix 
metalloprotease 

SerpinsNuclear hormone 
receptor 

Hypoxia inducable 
factor 

Tubulin 

Mitotic spindle 
checkpoint 

ATP transporter 
protein 

Peroxisomal 
protein 

Cell cycle / cytokinesis 

TGF-β 

Cell cycle 
regulation 

Myosin 

Laminin 

Actinin 

Casein kinase 

Transcription 
regulation 

Vascular endothelial 
growth factor VEGF 

Intracellular signal 
cascade 

Breast cancer 
anti-estrogen resistance 

JAK/STAT 
cascade 

Karyopherin 
dock complex 

NF-kappaB 
regulation 

Nucleocytoplasm 
transport 

FIG. 3 Community structure in protein-protein interaction networks. The graph picture the interaction between protein 
in cancerous cell of a rat. Communities, label by colors, be detect with the Clique Percolation Method by Palla et al. 
(Section XI.A). Reprinted figure with permission from Ref. (Jonsson et al., 2006). c©2006 by PubMed Central. 

Therefore it be customary to neglect the directedness of 
the hyperlink and to consider the graph a undirected, 
for the purpose of community detection. On the other 
hand, take properly into account the directedness of 
the edge can considerably improve the quality of the par- 
tition(s), a one can handle a lot of precious information 
about the system. Moreover, in some instance neglect- 
ing edge directedness may lead to strange result (Leicht 

and Newman, 2008; Rosvall and Bergstrom, 2008). De- 
veloping method of community detection for direct 
graph be a hard task. For instance, a direct graph be 
characterize by asymmetrical matrix (adjacency ma- 
trix, Laplacian, etc.), so spectral analysis be much more 
complex. Only a few technique can be easily extend 
from the undirected to the direct case. Otherwise, the 
problem must be formulate from scratch. 



7 

FIG. 4 Community structure in technological networks. 
Sample of the web graph consist of the page of a web 
site and their mutual hyperlinks, which be directed. Com- 
munities, indicate by the colors, be detect with the al- 
gorithm of Girvan and Newman (Section V.A), by neglect 
the directedness of the edges. Reprinted figure with permis- 
sion from Ref. (Newman and Girvan, 2004). c©2004 by the 
American Physical Society. 

Edge directedness be not the only complication to deal 
with when face the problem of graph clustering. In 
many real network vertex may belong to more than 
one group. In this case one speaks of overlap com- 
munities and us the term cover, rather than partition, 
whose standard definition forbids multiple membership 
of vertices. Classical example be social networks, where 
an individual usually belongs to different circle at the 
same time, from that of work colleague to family, sport 
associations, etc.. Traditional algorithm of community 
detection assign each vertex to a single module. In so do- 
ing, they neglect potentially relevant information. Ver- 
tices belonging to more community be likely to play 
an important role of intermediation between different 
compartment of the graph. In Fig. 5 we show a net- 
work of word association derive start from the word 
“bright”. The network build on the University of South 
Florida Free Association Norms (Nelson et al., 1998). An 
edge between word A and B indicates that some peo- 
ple associate B to the word A. The graph clearly dis- 

Scientist 
Science Astronomy 

Earth 
Space 

Moon 

Star 
Ray 

Intelligent 

Golden 

Glare 

Sun 

Sky 
Moonlight 

Eyes 

SunshineLight 

Lit 

Dark 
Brown 

Tan 

Orange 

BlueYellow 

Color 

Gray 

Black 

Race 

White 
Green 

Red Crayon 
Pink 

Velvet 

Flaslight 

Glow 

Dim 

Gifted 
Genius 

Smart 

Inventor 
Einstein 

Brilliant 
Shine 

Laser 
Telescope 

Horizon 

Sunset 

Ribbon 

Violet 

Purple 

Beam 

Night 

IntelligenceIntelligence 

AstronomyAstronomy 

LightLight 

ColorsColors 

Intelligence 

Astronomy 

BRIGHT 

Light 

Colors 

FIG. 5 Overlapping community in a network of word as- 
sociation. The groups, label by the colors, be detect 
with the Clique Percolation Method by Palla et al. (Sec- 
tion XI.A). Reprinted figure with permission from Ref. (Palla 
et al., 2005). c©2005 by the Nature Publishing Group. 

play four communities, correspond to the category 
Intelligence, Astronomy, Light and Colors. The word 
“bright” be related to all of them by construction. Other 
word belong to more categories, e.g. “dark” (Colors 
and Light). Accounting for overlap community in- 
troduces a further variable, the membership of vertex 
in different communities, which enormously increase the 
number of possible cover with respect to standard parti- 
tions. Therefore, search for overlap community 
be usually much more computationally demand than 
detect standard partitions. 

So far we have discuss example of unipartite graphs. 
However, it be not uncommon to find real network with 
different class of vertices, and edge join only ver- 
tices of different classes. An example be a network of 
scientist and papers, where edge join scientist and the 
paper they have authored. Here there be no edge be- 
tween any pair of scientist or papers, so the graph be 
bipartite. For a multipartite network the concept of com- 
munity do not change much with respect to the case of 
unipartite graphs, a it remains related to a large den- 
sity of edge between member of the same group, with 
the only difference that the element of each group be- 



8 

1 

2 

3 

4 

5 

6 

7 

8 

9 
10 

11 

12 

13 

14 

15 

16 

17 
18 

1 

2 

3 

4 

5 
6 

7 

8 9 

10 

11 

12 

13 

14 

FIG. 6 Community structure in multipartite networks. This 
bipartite graph refers to the Southern Women Event Partici- 
pation data set. Women be represent a open symbol with 
black labels, event a fill symbol with white labels. The 
illustrate vertex partition have be obtain by maximize 
a modify version of the modularity by Newman and Girvan, 
tailor on bipartite graph (Barber, 2007) (Section VI.B). 
Reprinted figure with permission from Ref. (Barber, 2007). 
c©2007 by the American Physical Society. 

long to different vertex classes. Multipartite graph be 
usually reduce to unipartite projection of each vertex 
class. For instance, from the bipartite network of scien- 
tists and paper one can extract a network of scientist 
only, who be related by coauthorship. In this way one 
can adopt standard technique of network analysis, in 
particular standard cluster methods, but a lot of infor- 
mation get lost. Detecting community in multipartite 
network can have interest application in, e.g., mar- 
keting. Large shopping networks, in which customer be 
link to the product they have bought, allow to classify 
customer base on the type of product they purchase 
more often: this could be use both to organize target 
advertising, a well a to give recommendation about 
future purchase (Adomavicius and Tuzhilin, 2005). The 
problem of community detection in multipartite network 
be not trivial, and usually require ad hoc methodologies. 
Fig. 6 illustrates the famous bipartite network of South- 
ern Women study by Davis et al. (Davis et al., 1941). 
There be 32 vertices, represent 18 woman from the 
area of Natchez, Mississippi, and 14 social events. Edges 
represent the participation of the woman in the events. 
From the figure one can see that the network have a clear 
community structure. 

In some of the previous examples, edge have (or can 
have) weights. For instance, the edge of the collabora- 
tion network of Fig. 2b could be weight by the number 
of paper coauthored by pair of scientists. Similarly, 

the edge of the word association network of Fig. 5 be 
weight by the number of time pair of word have be 
associate by people. Weights be precious additional in- 
formation on a graph, and should be consider in the 
analysis. In many case method work on unweighted 
graph can be simply extend to the weight case. 

III. ELEMENTS OF COMMUNITY DETECTION 

The problem of graph clustering, intuitive at first sight, 
be actually not well defined. The main element of the 
problem themselves, i. e. the concept of community and 
partition, be not rigorously defined, and require some 
degree of arbitrariness and/or common sense. Indeed, 
some ambiguity be hidden and there be often many 
equally legitimate way of resolve them. Therefore, it 
be not surprising that there be plenty of recipe in the 
literature and that people do not even try to ground the 
problem on share definitions. 

It be important to stress that the identification of struc- 
tural cluster be possible only if graph be sparse, i. e. if 
the number of edge m be of the order of the number of 
node n of the graph. If m� n, the distribution of edge 
among the node be too homogeneous for community to 
make sense2. In this case the problem turn into some- 
thing rather different, close to data cluster (Gan et al., 
2007), which require concept and method of a different 
nature. The main difference be that, while community in 
graph be related, explicitly or implicitly, to the concept 
of edge density (inside versus outside the community), in 
data cluster community be set of point which be 
“close” to each other, with respect to a measure of dis- 
tance or similarity, define for each pair of points. Some 
classical technique for data clustering, like hierarchical, 
partitional and spectral cluster will be discuss late 
in the review (Sections IV.B, IV.C and IV.D), a they 
be sometimes adopt for graph cluster too. Other 
standard procedure for data cluster include neural 
network cluster technique like, e. g., self-organizing 
map and multi-dimensional scale technique like, e. 
g., singular value decomposition and principal component 
analysis (Gan et al., 2007). 

In this section we shall attempt an order exposition 
of the fundamental concept of community detection. Af- 
ter a brief discussion of the issue of computational com- 
plexity for the algorithms, we shall review the notion of 
community and partition. 

2 This be not necessarily true if graph be weight with a hetero- 
geneous distribution of weights. In such case community may 
still be identify a subgraphs with a high internal density of 
weight. 



9 

A. Computational complexity 

The massive amount of data on real network currently 
available make the issue of the efficiency of cluster al- 
gorithms essential. The computational complexity of an 
algorithm be the estimate of the amount of resource re- 
quired by the algorithm to perform a task. This involves 
both the number of computation step need and the 
number of memory unit that need to be simultaneously 
allocate to run the computation. Such demand be 
usually express by their scalability with the size of the 
system at study. In the case of a graph, the size be typ- 
ically indicate by the number of vertex n and/or the 
number of edge m. The computational complexity of 
an algorithm cannot always be calculated. In fact, some- 
time this be a very hard task, or even impossible. In 
these cases, it be however important to have at least an 
estimate of the worst-case complexity of the algorithm, 
which be the amount of computational resource need 
to run the algorithm in the most unfavorable case for a 
give system size. 

The notation O(nαmβ) indicates that the computer 
time grows a a power of both the number of vertex 
and edges, with exponent α and β, respectively. Ideally, 
one would like to have the low possible value for the 
exponents, which would correspond to the low possi- 
ble computational demands. Samples of the Web graph, 
with million of vertex and billion of edges, cannot be 
tackle by algorithm whose run time grows faster 
than O(n) or O(m). 

Algorithms with polynomial complexity form the class 
P. For some important decision and optimization prob- 
lems, there be no know polynomial algorithms. Find- 
ing solution of such problem in the worst-case scenario 
may demand an exhaustive search, which take a time 
grow faster than any polynomial function of the sys- 
tem size, e.g. exponentially. Problems whose solution 
can be verify in a polynomial time span the class NP 
of non-deterministic polynomial time problems, which in- 
cludes P. A problem be NP-hard if a solution for it can be 
translate into a solution for any NP-problem. However, 
a NP-hard problem need not be in the class NP. If it 
do belong to NP it be call NP-complete. The class 
of NP-complete problem have drawn a special attention 
in computer science, a it include many famous prob- 
lem like the Travelling Salesman, Boolean Satisfiability 
(SAT), Linear Programming, etc. (Garey and Johnson, 
1990; Papadimitriou, 1994). The fact that NP prob- 
lem have a solution which be verifiable in polynomial 
time do not mean that NP problem have polynomial 
complexity, i. e., that they be in P. In fact, the ques- 
tion of whether NP=P be the most important open prob- 
lem in theoretical computer science. NP-hard problem 
need not be in NP (in which case they would be NP- 
complete), but they be at least a hard a NP-complete 
problems, so they be unlikely to have polynomial com- 
plexity, although a proof of that be still missing. 

Many cluster algorithm or problem related to 

cluster be NP-hard. In this case, it be pointless to 
use exact algorithms, which could be apply only to 
very small systems. Moreover, even if an algorithm have a 
polynomial complexity, it may still be too slow to tackle 
large system of interest. In all such case it be common 
to use approximation algorithms, i. e. method that do 
not deliver an exact solution to the problem at hand, 
but only an approximate solution, with the advantage of 
a low complexity. Approximation algorithm be often 
non-deterministic, a they deliver different solution for 
the same problem, for different initial condition and/or 
parameter of the algorithm. The goal of such algorithm 
be to deliver a solution which differs by a constant fac- 
tor from the optimal solution. In any case, one should 
give provable bound on the goodness of the approxi- 
mate solution deliver by the algorithm with respect to 
the optimal solution. In many case it be not possible 
to approximate the solution within any constant, a the 
goodness of the approximation strongly depends on the 
specific problem at study. Approximation algorithm be 
commonly use for optimization problems, in which one 
want to find the maximum or minimum value of a give 
cost function over a large set of possible system configu- 
rations. 

B. Communities 

1. Basics 

The first problem in graph cluster be to look for a 
quantitative definition of community. No definition be 
universally accepted. As a matter of fact, the defini- 
tion often depends on the specific system at hand and/or 
application one have in mind. From intuition and the ex- 
amples of Section II we get the notion that there must 
be more edge “inside” the community than edge link- 
ing vertex of the community with the rest of the graph. 
This be the reference guideline at the basis of most com- 
munity definitions. But many alternative recipe be 
compatible with it. Moreover, in most cases, commu- 
nities be algorithmically defined, i. e. they be just the 
final product of the algorithm, without a precise a priori 
definition. 

Let u start with a subgraph C of a graph G, with 
|C| = nc and |G| = n vertices, respectively. We define 
the internal and external degree of vertex v ∈ C, kintv 
and kextv , a the number of edge connect v to other 
vertex of C or to the rest of the graph, respectively. If 
kextv = 0, the vertex have neighbor only within C, which be 
likely to be a good cluster for v; if kintv = 0, instead, the 
vertex be disjoint from C and it should good be assign 
to a different cluster. The internal degree kCint of C be 
the sum of the internal degree of it vertices. Likewise, 
the external degree kCext of C be the sum of the external 
degree of it vertices. The total degree kC be the sum 
of the degree of the vertex of C. By definition, kC = 
kCint + k 

C 
ext. 



10 

We define the intra-cluster density δint(C) of the sub- 
graph C a the ratio between the number of internal edge 
of C and the number of all possible internal edges, i. e. 

δint(C) = 
# internal edge of C 

nc(nc − 1)/2 
. (1) 

Similarly, the inter-cluster density δext(C) be the ratio be- 
tween the number of edge run from the vertex of 
C to the rest of the graph and the maximum number of 
inter-cluster edge possible, i. e. 

δext(C) = 
# inter-cluster edge of C 

nc(n− nc) 
. (2) 

For C to be a community, we expect δint(C) to be ap- 
preciably large than the average link density δ(G) of 
G, which be give by the ratio between the number of 
edge of G and the maximum number of possible edge 
n(n − 1)/2. On the other hand, δext(C) have to be much 
small than δ(G). Searching for the best tradeoff be- 
tween a large δint(C) and a small δext(C) be implicitly 
or explicitly the goal of most cluster algorithms. A 
simple way to do that is, e. g., maximize the sum of 
the difference δint(C) − δext(C) over all cluster of the 
partition3 (Mancoridis et al., 1998). 

A require property of a community be connectedness. 
We expect that for C to be a community there must be 
a path between each pair of it vertices, run only 
through vertex of C. This feature simplifies the task 
of community detection on disconnect graphs, a in 
this case one just analyzes each connect component 
separately, unless special constraint be impose on the 
result clusters. 

With these basic requirement in mind, we can now 
introduce the main definition of community. Social 
network analyst have devise many definition of sub- 
group with various degree of internal cohesion among 
vertex (Moody and White, 2003; Scott, 2000; Wasser- 
man and Faust, 1994). Many other definition have be 
introduce by computer scientist and physicists. We 
distinguish three class of definitions: local, global and 
base on vertex similarity. Other definition will be give 
in the context of the algorithm for which they be in- 
troduced. 

2. Local definition 

Communities be part of the graph with a few tie 
with the rest of the system. To some extent, they can 
be consider a separate entity with their own auton- 
omy. So, it make sense to evaluate them independently 

3 In Ref. (Mancoridis et al., 1998) one actually computes the inter- 
cluster density by sum the density for each pair of clusters. 
Therefore the function to minimize be not exactly 

∑ 
C [δint(C)− 

δext(C)], but essentially equivalent. 

of the graph a a whole. Local definition focus on the 
subgraph under study, include possibly it immediate 
neighborhood, but neglect the rest of the graph. We 
start with a listing of the main definition adopt in 
social network analysis, for which we shall closely fol- 
low the exposition of Ref. (Wasserman and Faust, 1994). 
There, four type of criterion be identified: complete 
mutuality, reachability, vertex degree and the comparison 
of internal versus external cohesion. The correspond 
community be mostly maximal subgraphs, which can- 
not be enlarge with the addition of new vertex and 
edge without lose the property which defines them. 

Social community can be define in a very strict 
sense a subgroup whose member be all “friends” to 
each other (Luce and Perry, 1949) (complete mutual- 
ity). In graph terms, this corresponds to a clique, i. e. 
a subset whose vertex be all adjacent to each other. 
In social network analysis, a clique be a maximal sub- 
graph, whereas in graph theory it be common to call 
clique also non-maximal subgraphs. Triangles be the 
simplest cliques, and be frequent in real networks. But 
large clique be less frequent. Moreover, the condition 
be really too strict: a subgraph with all possible internal 
edge except one would be an extremely cohesive sub- 
group, but it would not be consider a community un- 
der this recipe. Another problem be that all vertex of 
a clique be absolutely symmetric, with no differentia- 
tion between them. In many practical examples, instead, 
we expect that within a community there be a whole hi- 
erarchy of role for the vertices, with core vertex co- 
exist with peripheral ones. We remark that vertex 
may belong to more clique simultaneously, a property 
which be at the basis of the Clique Percolation Method of 
Palla et al. (Palla et al., 2005) (see Section XI.A). From 
a practical point of view, find clique in a graph be an 
NP-complete problem (Bomze et al., 1999). The Bron- 
Kerbosch method (Bron and Kerbosch, 1973) run in a 
time grow exponentially with the size of the graph. 

It be however possible to relax the notion of clique, 
define subgroup which be still clique-like objects. A 
possibility be to use property related to reachability, i. e. 
to the existence (and length) of path between vertices. 
An n-clique be a maximal subgraph such that the distance 
of each pair of it vertex be not large than n (Alba, 
1973; Luce, 1950). For n = 1 one recovers the definition 
of clique, a all vertex be adjacent, so each geodesic 
path between any pair of vertex have length 1. This def- 
inition, more flexible than that of clique, still have some 
limitations, derive from the fact that the geodesic path 
need not run on the vertex of the subgraph at study, but 
may run on vertex outside the subgraph. In this way, 
there may be two disturb consequences. First, the 
diameter of the subgraph may exceed n, even if in princi- 
ple each vertex of the subgraph be less than n step away 
from any of the others. Second, the subgraph may be 
disconnected, which be not consistent with the notion of 
cohesion one try to enforce. To avoid these problems, 
Mokken (Mokken, 1979) have suggest two possible al- 



11 

ternatives, the n-clan and the n-club. An n-clan be an 
n-clique whose diameter be not large than n, i. e. a sub- 
graph such that the distance between any two of it ver- 
tices, compute over shortest path within the subgraph, 
do not exceed n. An n-club, instead, be a maximal 
subgraph of diameter n. The two definition be quite 
close: the difference be that an n-clan be maximal under 
the constraint of be an n-clique, whereas an n-club be 
maximal under the constraint impose by the length of 
the diameter. 

Another criterion for subgraph cohesion relies on the 
adjacency of it vertices. The idea be that a vertex must 
be adjacent to some minumum number of other vertex 
in the subgraph. In the literature on social network anal- 
ysis there be two complementary way of express this. 
A k-plex be a maximal subgraph in which each vertex be 
adjacent to all other vertex of the subgraph except at 
most k of them (Seidman and Foster, 1978). Similarly, 
a k-core be a maximal subgraph in which each vertex be 
adjacent to at least k other vertex of the subgraph (Sei- 
dman, 1983). So, the two definition impose condition 
on the minimal number of absent or present edges. The 
correspond cluster be more cohesive than n-cliques, 
just because of the existence of many internal edges. In 
any graph there be a whole hierarchy of core of different 
order, which can be identify by mean of a recent effi- 
cient algorithm (Batagelj and Zaversnik, 2003). A k-core 
be essentially the same a a p-quasi complete subgraph, 
which be a subgraph such that the degree of each vertex 
be large than p(k − 1), where p be a real number in [0, 1] 
and k the order of the subgraph (Matsuda et al., 1999). 
Determining whether a graph include a 1/2-quasi com- 
plete subgraph of order at least k be NP-complete. 

As cohesive a a subgraph can be, it would hardly be a 
community if there be a strong cohesion a well between 
the subgraph and the rest of the graph. Therefore, it 
be important to compare the internal and external cohe- 
sion of a subgraph. In fact, this be what be usually do 
in the most recent definition of community. The first 
recipe, however, be not recent and stem from social net- 
work analysis. An LS-set (Luccio and Sami, 1969), or 
strong community (Radicchi et al., 2004), be a subgraph 
such that the internal degree of each vertex be great 
than it external degree. This condition be quite strict 
and can be relaxed into the so-called weak definition of 
community (Radicchi et al., 2004), for which it suffices 
that the internal degree of the subgraph exceeds it ex- 
ternal degree. An LS-set be also a weak community, while 
the converse be not generally true. Hu et al. (Hu et al., 
2008) have introduce alternative definition of strong 
and weak communities: a community be strong if the in- 
ternal degree of any vertex of the community exceeds the 
number of edge that the vertex share with any other 
community; a community be weak if it total internal de- 
gree exceeds the number of edge share by the commu- 
nity with the other communities. These definition be 
in the same spirit of the plant partition model (Sec- 
tion XV). An LS-set be a strong community also in the 

sense of Hu et al.. Likewise, a weak community accord 
to Radicchi et al. be also a weak community for Hu et al.. 
In both case the converse be not true, however. Another 
definition focus on the robustness of cluster to edge 
removal and us the concept of edge connectivity. The 
edge connectivity of a pair of vertex in a graph be the 
minimal number of edge that need to be remove in or- 
der to disconnect the two vertices, i. e. such that there be 
no path between them. A lambda set be a subgraph such 
that any pair of vertex of the subgraph have a large edge 
connectivity than any pair form by one vertex of the 
subgraph and one outside the subgraph (Borgatti et al., 
1990). However, vertex of a lambda-set need not be 
adjacent and may be quite distant from each other. 

Communities can also be identify by a fitness mea- 
sure, express to which extent a subraph satisfies a 
give property related to it cohesion. The large the 
fitness, the more definite be the community. This be the 
same principle behind quality functions, which give an 
estimate of the goodness of a graph partition (see Sec- 
tion III.C.2). The simplest fitness measure for a clus- 
ter be it intra-cluster density δint(C). One could as- 
sume that a subgraph C with k vertex be a cluster if 
δint(C) be large than a threshold, say ξ. Finding such 
subgraphs be an NP-complete problem, a it coincides 
with the NP-complete Clique Problem when the thresh- 
old ξ = 1 (Garey and Johnson, 1990). It be good to fix 
the size of the subgraph because, without this conditions, 
any clique would be one of the best possible communities, 
include trivial two-cliques (simple edges). Variants of 
this problem focus on the number of internal edge of 
the subgraph (Asahiro et al., 2002; Feige et al., 2001; 
Holzapfel et al., 2003). Another measure of interest be the 
relative density ρ(C) of a subgraph C, define a the ratio 
between the internal and the total degree of C. Finding 
subgraphs of a give size with ρ(C) large than a thresh- 
old be NP-complete (Š́ıma and Schaeffer, 2006). Fitness 
measure can also be associate to the connectivity of 
the subgraph at study to the other vertex of the graph. 
A good community be expect to have a small cut size 
(see Section A.1), i. e. a small number of edge join 
it to the rest of the graph. This set a bridge between 
community detection and graph partitioning, which we 
shall discus in Section IV.A. 

3. Global definition 

Communities can also be define with respect to the 
graph a a whole. This be reasonable in those case in 
which cluster be essential part of the graph, which can- 
not be take apart without seriously affect the func- 
tioning of the system. The literature offer many global 
criterion to identify communities. In most case they be 
indirect definitions, in which some global property of the 
graph be use in an algorithm that delivers community 
at the end. However, there be a class of proper definitions, 
base on the idea that a graph have community structure 



12 

if it be different from a random graph. A random graph 
à la Erdös-Rényi (Section A.3), for instance, be not ex- 
pected to have community structure, a any two vertex 
have the same probability to be adjacent, so there should 
be no preferential link involve special group of ver- 
tices. Therefore, one can define a null model, i. e. a graph 
which match the original in some of it structural fea- 
tures, but which be otherwise a random graph. The null 
model be use a a term of comparison, to verify whether 
the graph at study display community structure or not. 
The most popular null model be that propose by New- 
man and Girvan and consists of a randomize version of 
the original graph, where edge be rewire at random, 
under the constraint that the expect degree of each 
vertex match the degree of the vertex in the original 
graph (Newman and Girvan, 2004). This null model be 
the basic concept behind the definition of modularity, a 
function which evaluates the goodness of partition of 
a graph into clusters. Modularity will be discuss at 
length in this review, because it have the unique privi- 
lege of be at the same time a global criterion to de- 
fine a community, a quality function and the key ingredi- 
ent of the most popular method of graph clustering. In 
the standard formulation of modularity, a subgraph be a 
community if the number of edge inside the subgraph 
exceeds the expect number of internal edge that the 
same subgraph would have in the null model. This ex- 
pected number be an average over all possible realization 
of the null model. Several modification of modularity 
have be propose (Section VI.B). A general class of 
null models, include modularity a a special case, have 
be design by Reichardt and Bornholdt (Reichardt 
and Bornholdt, 2006a) (Section VI.B). 

4. Definitions base on vertex similarity 

It be natural to assume that community be group of 
vertex similar to each other. One can compute the sim- 
ilarity between each pair of vertex with respect to some 
reference property, local or global, no matter whether 
they be connect by an edge or not. Each vertex end 
up in the cluster whose vertex be most similar to it. 
Similarity measure be at the basis of traditional meth- 
ods, like hierarchical, partitional and spectral clustering, 
to be discuss in Sections IV.B, IV.C and IV.D. Here 
we discus some popular measure use in the literature. 

If it be possible to embed the graph vertex in an n- 
dimensional Euclidean space, by assign a position to 
them, one could use the distance between a pair of ver- 
tices a a measure of their similarity (it be actually a mea- 
sure of dissimilarity because similar vertex be expect 
to be close to each other). Given the two data point 
A = (a1, a2, ..., an) and B = (b1, b2, ..., bn), one could use 
any norm Lm, like the Euclidean distance (L2-norm), 

dEAB = 

n∑ 
k=1 

√ 
(ak − bk)2, (3) 

the Manhattan distance (L1-norm) 

dMAB = 

n∑ 
k=1 

|ak − bk|, (4) 

and the L∞-norm 

d∞AB = max 
k∈[1,n] 

|ak − bk|. (5) 

Another popular spatial measure be the cosine similarity, 
define a 

ρAB = arccos 
a · b√∑n 

k=1 a 
2 
k 

√∑n 
k=1 b 

2 
k 

, (6) 

where a ·b be the dot product of the vector a and b. The 
variable ρAB be define in the range [0, π). 

If the graph cannot be embed in space, the sim- 
ilarity must be necessarily infer from the adjacency 
relationship between vertices. A possibility be to define 
a distance (Burt, 1976; Wasserman and Faust, 1994) be- 
tween vertex like 

dij = 

√∑ 
k 6=i,j 

(Aik −Ajk)2, (7) 

where A be the adjacency matrix. This be a dissimilar- 
ity measure, base on the concept of structural equiv- 
alence (F.Lorrain and White, 1971). Two vertex be 
structurally equivalent if they have the same neighbors, 
even if they be not adjacent themselves. If i and j be 
structurally equivalent, dij = 0. Vertices with large de- 
gree and different neighbour be consider very “far” 
from each other. Alternatively, one could measure the 
overlap between the neighborhood Γ(i) and Γ(j) of ver- 
tices i and j, give by the ratio between the intersection 
and the union of the neighborhoods, i. e. 

ωij = 
|Γ(i) ∩ Γ(j)| 
|Γ(i) ∪ Γ(j)| 

. (8) 

Another measure related to structural equivalence be the 
Pearson correlation between column or row of the ad- 
jacency matrix, 

Cij = 

∑ 
k(Aik − µi)(Ajk − µj) 

nσiσj 
, (9) 

where the average µi = ( 
∑ 
j Aij)/n and the variance 

σi = 
√∑ 

j(Aij − µi)2/n. 
An alternative measure be the number of edge- (or 

vertex-) independent path between two vertices. Inde- 
pendent path do not share any edge (vertex), and their 
number be related to the maximum flow that can be con- 
veyed between the two vertex under the constraint that 
each edge can carry only one unit of flow (max-flow/min- 
cut theorem (Elias et al., 1956)). The maximum flow 
can be calculate in a time O(m), for a graph with m 



13 

edges, use technique like the augment path algo- 
rithm (Ahuja et al., 1993). Similarly, one could consider 
all path run between two vertices. In this case, there 
be the problem that the total number of path be infinite, 
but this can be avoid if one performs a weight sum 
of the number of paths. For instance, path of length l 
can be weight by the factor αl, with α < 1. Another 
possibility, suggest by Estrada and Hatano (Estrada 
and Hatano, 2008, 2009), be to weigh path of length l 
with the inverse factorial 1/l!. In both cases, the contri- 
bution of long path be strongly suppress and the sum 
converges. 

Another important class of measure of vertex similar- 
ity be base on property of random walk on graphs. 
One of this property be the commute-time between a 
pair of vertices, which be the average number of step 
need for a random walker, start at either vertex, 
to reach the other vertex for the first time and to come 
back to the start vertex. Saerens and coworkers (Fouss 
and Renders, 2007; Saerens et al., 2004; Yen et al., 2007, 
2009) have extensively study and use the commute- 
time (and variant thereof) a (dis)similarity measure: 
the large the time, the farther (less similar) the vertices. 
The commute-time be closely related (Chandra et al., 
1989) to the resistance distance introduce by Klein and 
Randic (Klein and Randic, 1993), express the effective 
electrical resistance between two vertex if the graph be 
turn into a resistor network. White and Smyth (White 
and Smyth, 2003) and Zhou (Zhou, 2003a) use instead 
the average first passage time, i. e. the average number 
of step need to reach for the first time the target ver- 
tex from the source. Harel and Koren (Harel and Koren, 
2001) propose to build measure out of quantity like 
the probability to visit a target vertex in no more than 
a give number of step after it leaf a source vertex4 

and the probability that a random walker start at a 
source visit the target exactly once before hit the 
source again. Another quantity use to define similarity 
measure be the escape probability, define a the prob- 
ability that the walker reach the target vertex before 
come back to the source vertex (Palmer and Falout- 
sos, 2003; Tong et al., 2008). The escape probability be 
related to the effective conductance between the two ver- 
tices in the equivalent resistor network. Other author 
have exploit property of modify random walks. For 
instance, the algorithm by Gori and Pucci (Gori and 
Pucci, 2007) and that by Tong et al. (Tong et al., 2008) 
use similarity measure derive from Google’s PageR- 
ank process (Brin and Page, 1998). 

4 In the cluster method by Latapy and Pons (Latapy and Pons, 
2005) (discussed in Section VIII.B) and in a recent analysis by 
Nadler et al. (Nadler et al., 2006), one define a dissimilarity 
measure call “diffusion distance”, which be derive from the 
probability that the walker visit the target after a fix number 
of steps. 

C. Partitions 

1. Basics 

A partition be a division of a graph in clusters, such that 
each vertex belongs to one cluster. As we have see in 
Section II, in real system vertex may be share among 
different communities. A division of a graph into over- 
lap (or fuzzy) community be call cover. 

The number of possible partition in k cluster of a 
graph with n vertex be the Stirling number of the sec- 
ond kind S(n, k) (Andrews, 1976). The total number 
of possible partition be the n-th Bell number Bn =∑n 
k=0 S(n, k) (Andrews, 1976). In the limit of large n, 

Bn have the asymptotic form (Lovász, 1993) 

Bn ∼ 
1√ 
n 

[λ(n)]n+1/2eλ(n)−n−1, (10) 

where λ(n) = eW (n) = n/W (n), W (n) be the Lam- 
bert W function (Pólya and Szegö, 1998). Therefore, Bn 
grows faster than exponentially with the graph size n, 
which mean that an enumeration and/or evaluation of 
all partition of a graph be impossible, unless the graph 
consists of very few vertices. 

Partitions can be hierarchically ordered, when the 
graph have different level of organization/structure at 
different scales. In this case, cluster display in turn 
community structure, with small community inside, 
which may again contain small communities, and so on 
(Fig. 7). As an example, in a social network of child 
living in the same town, one could group the child 
accord to the school they attend, but within each 
school one can make a subdivision into classes. Hier- 
archical organization be a common feature of many real 
networks, where it be reveal by a peculiar scale of the 
cluster coefficient for vertex have the same degree 
k, when plot a a function of k (Ravasz and Barabási, 
2003; Ravasz et al., 2002). A natural way to represent 
the hierarchical structure of a graph be to draw a dendro- 
gram, like the one illustrate in Fig. 8. Here, partition 
of a graph with twelve vertex be shown. At the bot- 
tom, each vertex be it own module (the “leaves” of the 
tree). By move upwards, group of vertex be suc- 
cessively aggregated. Mergers of community be repre- 
sented by horizontal lines. The uppermost level repre- 
sent the whole graph a a single community. Cutting 
the diagram horizontally at some height, a show in the 
figure (dashed line), display one partition of the graph. 
The diagram be hierarchical by construction: each com- 
munity belonging to a level be fully include in a commu- 
nity at a high level. Dendrograms be regularly use in 
sociology and biology. The technique of hierarchical clus- 
tering, described in Section IV.B, lends itself naturally to 
this kind of representation. 



14 

Powered by yFiles 

FIG. 7 Schematic example of a hierarchical graph. Sixteen module with 32 vertex each clearly form four large clusters. All 
vertex have degree 64. Reprinted figure with permission from Ref. (Lancichinetti et al., 2009). c©2009 by IOP Publishing. 

FIG. 8 A dendrogram, or hierarchical tree. Horizontal 
cut correspond to partition of the graph in communities. 
Reprinted figure with permission from Ref. (Newman and Gir- 
van, 2004). c©2004 by the American Physical Society. 

2. Quality functions: modularity 

Reliable algorithm be suppose to identify good par- 
titions. But what be a good clustering? In order to dis- 
tinguish between “good” and “bad” clusterings, it would 
be useful to require that partition satisfy a set of basic 
properties, intuitive and easy to agree upon. In the wider 
context of data clustering, this issue have be study by 
Jon Kleinberg (Kleinberg, 2002), who have prove an im- 

portant impossibility theorem. Given a set S of points, a 
distance function d be defined, which be positive definite 
and symmetric (the triangular inequality be not explicitly 
required). One wish to find a cluster f base on the 
distance between the points. Kleinberg show that no 
cluster satisfies at the same time the three follow 
properties: 

1. Scale-invariance: give a constant α, multiply 
any distance function d by α yield the same clus- 
tering. 

2. Richness: any possible partition of the give point 
set can be recover if one chooses a suitable dis- 
tance function d. 

3. Consistency: give a partition, any modification of 
the distance function that do not decrease the dis- 
tance between point of different cluster and that 
do not increase the distance between point of the 
same cluster, yield the same clustering. 

The theorem cannot be extend to graph cluster be- 
cause the distance function cannot be in general define 
for a graph which be not complete. For weight com- 
plete graphs, like correlation matrix (Tumminello et al., 
2008), it be often possible to define a distance function. 
On a generic graph, except for the first property, which 



15 

do not make sense without a distance function5, the 
other two be quite well defined. The property of richness 
implies that, give a partition, one can set edge between 
the vertex in such a way that the partition be a natural 
outcome of the result graph (e.g., it could be achieve 
by set edge only between vertex of the same clus- 
ter). Consistency here implies that delete inter-cluster 
edge and add intra-cluster edge yield the same par- 
tition. 

Many algorithm be able to identify a subset of mean- 
ingful partitions, ideally one or just a few, whereas some 
others, like technique base on hierarchical cluster 
(Section IV.B), deliver a large number of partitions. That 
do not mean that the partition found be equally good. 
Therefore it be helpful (sometimes even necessary) to have 
a quantitative criterion to ass the goodness of a graph 
partition. A quality function be a function that assigns a 
number to each partition of a graph. In this way one can 
rank partition base on their score give by the quality 
function. Partitions with high score be “good”, so the 
one with the large score be by definition the best. Nev- 
ertheless, one should keep in mind that the question of 
when a partition be good than another one be ill-posed, 
and the answer depends on the specific concept of com- 
munity and/or quality function adopted. 

A quality function Q be additive if there be an elemen- 
tary function q such that, for any partition P of a graph 

Q(P) = 
∑ 
C∈P 

q(C), (11) 

where C be a generic cluster of partition P. Eq. 11 state 
that the quality of a partition be give by the sum of the 
quality of the individual clusters. The function q(C) 
could be any of the cluster fitness function discuss 
in Section III.B.2, for instance. Most quality function 
use in the literature be additive, although it be not a 
necessary requirement. 

An example of quality function be the performance P , 
which count the number of correctly “interpreted” pair 
of vertices, i. e. two vertex belonging to the same com- 
munity and connect by an edge, or two vertex be- 
longing to different community and not connect by 
an edge. The definition of performance, for a partition 
P, be 

P (P) = |{(i, j) ∈ E,Ci = Cj}|+ |{(i, j) /∈ E,Ci 6= Cj}| 
n(n− 1)/2 

. 

(12) 
By definition, 0 ≤ P (P) ≤ 1. Another example be cov- 
erage, i. e. the ratio of the number of intra-community 
edge by the total number of edges: by definition, an 
ideal cluster structure, where the cluster be discon- 
nected from each other, yield a coverage of 1, a all 
edge of the graph fall within clusters. 

5 The traditional shortest-path distance between vertex be not 
suitable here, a it be integer by definition. 

The most popular quality function be the modularity 
of Newman and Girvan (Newman and Girvan, 2004). It 
be base on the idea that a random graph be not expect 
to have a cluster structure, so the possible existence of 
cluster be reveal by the comparison between the actual 
density of edge in a subgraph and the density one would 
expect to have in the subgraph if the vertex of the graph 
be attach regardless of community structure. This 
expect edge density depends on the chosen null model, 
i. e. a copy of the original graph keep some of it 
structural property but without community structure. 
Modularity can then be write a follow 

Q = 
1 

2m 

∑ 
ij 

(Aij − Pij) δ(Ci, Cj), (13) 

where the sum run over all pair of vertices, A be the 
adjacency matrix, m the total number of edge of the 
graph, and Pij represent the expect number of edge 
between vertex i and j in the null model. The δ-function 
yield one if vertex i and j be in the same community 
(Ci = Cj), zero otherwise. The choice of the null model 
graph be in principle arbitrary, and several possibility 
exist. For instance, one could simply demand that the 
graph keep the same number of edge a the original 
graph, and that edge be place with the same proba- 
bility between any pair of vertices. In this case (Bernoulli 
random graph), the null model term in Eq. 13 would be a 
constant (i. e. Pij = p = 2m/[n(n− 1)], ∀i, j). However 
this null model be not a good descriptor of real networks, 
a it have a Poissonian degree distribution which be very 
different from the skewed distribution found in real net- 
works. Due to the important implication that broad de- 
gree distribution have for the structure and function of 
real network (Albert and Barabási, 2002; Barrat et al., 
2008; Boccaletti et al., 2006; Dorogovtsev and Mendes, 
2002; Newman, 2003; Pastor-Satorras and Vespignani, 
2004), it be preferable to go for a null model with the 
same degree distribution of the original graph. The stan- 
dard null model of modularity imposes that the expect 
degree sequence (after average over all possible configu- 
ration of the model) match the actual degree sequence 
of the graph. This be a stricter constraint than merely 
require the match of the degree distributions, and be 
essentially equivalent 6 to the configuration model, which 
have be subject of intense investigation in the recent 
literature on network ( Luczak, 1992; Molloy and Reed, 
1995). In this null model, a vertex could be attach to 
any other vertex of the graph and the probability that 
vertex i and j, with degree ki and kj , be connected, 

6 The difference be that the configuration model maintains the 
same degree sequence of the original graph for each realization, 
whereas in the null model of modularity the degree sequence of a 
realization be in general different, and only the average/expected 
degree sequence coincides with that of the graph at hand. The 
two model be equivalent in the limit of infinite graph size. 



16 

can be calculate without problems. In fact, in order to 
form an edge between i and j one need to join two stub 
(i. e. half-edges), incident with i and j. The probability 
pi to pick at random a stub incident with i be ki/2m, a 
there be ki stub incident with i out of a total of 2m. 
The probability of a connection between i and j be then 
give by the product pipj , since edge be place inde- 
pendently of each other. The result be kikj/4m 

2, which 
yield an expect number Pij = 2mpipj = kikj/2m of 
edge between i and j. So, the final expression of modu- 
larity read 

Q = 
1 

2m 

∑ 
ij 

( 
Aij − 

kikj 
2m 

) 
δ(Ci, Cj). (14) 

Since the only contribution to the sum come from vertex 
pair belonging to the same cluster, we can group these 
contribution together and rewrite the sum over the ver- 
tex pair a a sum over the cluster 

Q = 

nc∑ 
c=1 

[ lc 
m 
− 
( 
dc 
2m 

)2 ] 
. (15) 

Here, nc be the number of clusters, lc the total number of 
edge join vertex of module c and dc the sum of the 
degree of the vertex of c. In Eq. 15, the first term of 
each summand be the fraction of edge of the graph inside 
the module, whereas the second term represent the ex- 
pected fraction of edge that would be there if the graph 
be a random graph with the same expect degree for 
each vertex. 

A nice feature of modularity be that it can be equiva- 
lently express both in term of the intra-cluster edges, 
a in Eq. 15, and in term of the inter-cluster edge (Djid- 
jev, 2007). In fact, the maximum of modularity can be 
express a 

Qmax = maxP 

{ 
nc∑ 
c=1 

[ lc 
m 
− 
( 
dc 
2m 

)2 ]} 

= 
1 

m 
maxP 

{ 
nc∑ 
c=1 

[ 
lc − Ex(lc) 

]} 

= − 1 
m 

minP 

{ 
− 

nc∑ 
c=1 

[ 
lc − Ex(lc) 

]} 
, (16) 

where maxP and minP indicates the maximum and 
the minimum over all possible graph partition P and 
Ex(lc) = d 

2 
c/4m indicates the expect number of link 

in cluster c in the null model of modularity. By add 
and subtract the total number of edge m of the graph 
one finally get 

Qmax = − 
1 

m 
minP 

[( 
m− 

nc∑ 
c=1 

lc 

) 
− 
( 
m− 

nc∑ 
c=1 

Ex(lc) 
)] 

= − 1 
m 

minP(|CutP | − ExCutP). (17) 

In the last expression |CutP | = m− 
∑nc 
c=1 lc be the number 

of inter-cluster edge of partition P, and ExCutP = m−∑nc 
c=1 Ex(lc) be the expect number of inter-cluster edge 

of the partition in modularity’s null model. 
According to Eq. 15, a subgraph be a module if the 

correspond contribution to modularity in the sum be 
positive. The more the number of internal edge of the 
cluster exceeds the expect number, the good define 
the community. So, large positive value of the modular- 
ity indicate good partitions7. The maximum modularity 
of a graph generally grows if the size of the graph and/or 
the number of (well-separated) cluster increase (Good 
et al., 2009). Therefore, modularity should not be use 
to compare the quality of the community structure of 
graph which be very different in size. The modularity 
of the whole graph, take a a single community, be zero, 
a the two term of the only summand in this case be 
equal and opposite. Modularity be always small than 
one, and can be negative a well. For instance, the parti- 
tion in which each vertex be a community be always nega- 
tive: in this case the sum run over n terms, which be all 
negative a the first term of each summand be zero. This 
be a nice feature of the measure, imply that, if there 
be no partition with positive modularity, the graph have 
no community structure. On the contrary, the existence 
of partition with large negative modularity value may 
hint to the existence of subgroup with very few internal 
edge and many edge lie between them (multipartite 
structure) (Newman, 2006a). Holmström et al. (Holm- 
ström et al., 2009) have show that the distribution of 
modularity value across the partition of various graphs, 
real and artificial (including random graph with no ap- 
parent community structure), have some stable features, 
and that the most likely modularity value correspond to 
partition in cluster of approximately equal size. 

Modularity have be employ a quality function in 
many algorithms, like some of the divisive algorithm 
of Section V. In addition, modularity optimization be it- 
self a popular method for community detection (see Sec- 
tion VI.A). Modularity also allows to ass the stability 
of partition (Massen and Doye, 2006) (Section XIV), 
it can be use to design layout for graph visualiza- 
tion (Noack, 2009) and to perform a sort of renormaliza- 
tion of a graph, by transform a graph into a small 
one with the same community structure (Arenas et al., 
2007). 

IV. TRADITIONAL METHODS 

A. Graph partition 

The problem of graph partition consists in divide 
the vertex in g group of predefined size, such that the 

7 This be not necessarily true, a we will see in Section VI.C. 



17 

� 
� 
� 
� 

� 
� 
� 
� 

� 
� 
� 
� 

� 
� 
� 
� 

� 
� 
� 
� 

� 
� 
� 
� 

� 
� 
� 
� 

� 
� 
� 
� 

� 
� 
� 
� 

� 
� 
� 
� 

� 
� 
� 
� 

� 
� 
� 
� 

� 
� 
� 
� 

� 
� 
� 
� 

�� 
�� 
�� 
�� 
�� 
�� 
�� 
�� 
�� 
�� 
�� 
�� 
�� 
�� 
�� 
�� 
�� 
�� 
�� 

�� 
�� 
�� 
�� 
�� 
�� 
�� 
�� 
�� 
�� 
�� 
�� 
�� 
�� 
�� 
�� 
�� 
�� 
�� 

FIG. 9 Graph partitioning. The dash line show the so- 
lution of the minimum bisection problem for the graph illus- 
trated, i. e. the partition in two group of equal size with min- 
imal number of edge run between the groups. Reprinted 
figure with permission from Ref. (Fortunato and Castellano, 
2009). c©2009 by Springer. 

number of edge lie between the group be minimal. 
The number of edge run between cluster be call 
cut size. Fig. 9 present the solution of the problem for 
a graph with fourteen vertices, for g = 2 and cluster of 
equal size. 

Specifying the number of cluster of the partition be 
necessary. If one simply impose a partition with the 
minimal cut size, and left the number of cluster free, 
the solution would be trivial, correspond to all ver- 
tices end up in the same cluster, a this would yield 
a vanish cut size. Specifying the size be also neces- 
sary, a otherwise the most likely solution of the problem 
would consist in separate the low degree vertex from 
the rest of the graph, which be quite uninteresting. This 
problem can be actually avoid by choose a different 
measure to optimize for the partitioning, which account 
for the size of the clusters. Some of these measure will 
be briefly introduce at the end of this section. 

Graph partition be a fundamental issue in parallel 
computing, circuit partition and layout, and in the 
design of many serial algorithms, include technique 
to solve partial differential equation and sparse linear 
system of equations. Most variant of the graph parti- 
tioning problem be NP-hard. There be however several 
algorithm that can do a good job, even if their solution 
be not necessarily optimal (Pothen, 1997). Many algo- 
rithms perform a bisection of the graph. Partitions into 
more than two cluster be usually attain by iterative 
bisectioning. Moreover, in most case one imposes the 
constraint that the cluster have equal size. This prob- 
lem be call minimum bisection and be NP-hard. 

The Kernighan-Lin algorithm (Kernighan and Lin, 
1970) be one of the early method propose and be still 

frequently used, often in combination with other tech- 
niques. The author be motivate by the problem of 
partition electronic circuit onto boards: the node 
contain in different board need to be link to each 
other with the least number of connections. The pro- 
cedure be an optimization of a benefit function Q, which 
represent the difference between the number of edge in- 
side the module and the number of edge lie between 
them. The start point be an initial partition of the 
graph in two cluster of the predefined size: such initial 
partition can be random or suggest by some informa- 
tion on the graph structure. Then, subset consist of 
equal number of vertex be swap between the two 
groups, so that Q have the maximal increase. The sub- 
set can consist of single vertices. To reduce the risk to 
be trap in local maximum of Q, the procedure include 
some swap that decrease the function Q. After a series 
of swap with positive and negative gains, the partition 
with the large value of Q be select and use a start- 
ing point of a new series of iterations. The Kernighan- 
Lin algorithm be quite fast, scale a O(n2 log n) (n be- 
ing a usual the number of vertices), if only a constant 
number of swap be perform at each iteration. The 
most expensive part be the identification of the subset to 
swap, which require the computation of the gains/losses 
for any pair of candidate subsets. On sparse graphs, a 
slightly different heuristic allows to low the complex- 
ity to O(n2). The partition found by the procedure be 
strongly dependent on the initial configuration and other 
algorithm can do better. It be preferable to start with 
a good guess about the sought partition, otherwise the 
result be quite poor. Therefore the method be typi- 
cally use to improve on the partition found through 
other techniques, by use them a start configura- 
tions for the algorithm. The Kernighan-Lin algorithm 
have be extend to extract partition in any number 
of part (Suaris and Kedem, 1988), however the run-time 
and storage cost increase rapidly with the number of 
clusters. 

Another popular technique be the spectral bisection 
method (Barnes, 1982), which be base on the property 
of the spectrum of the Laplacian matrix. Spectral clus- 
tering will be discuss more thoroughly in Section IV.D, 
here we focus on it application to graph partitioning. 

Every partition of a graph with n vertex in two group 
can be represent by an index vector s, whose compo- 
nent si be +1 if vertex i be in one group and −1 if it be in 
the other group. The cut size R of the partition of the 
graph in the two group can be write a 

R = 
1 

4 
sTLs, (18) 

where L be the Laplacian matrix and sT the transpose of 
vector s. Vector s can be write a s = 

∑ 
i aivi, where 

vi, i = 1, ..., n be the eigenvectors of the Laplacian. If s 
be properly normalized, then 

R = 
∑ 
i 

a2iλi, (19) 



18 

where λi be the Laplacian eigenvalue correspond to 
eigenvector vi. It be worth remark that the sum con- 
tains at most n−1 terms, a the Laplacian have at least one 
zero eigenvalue. Minimizing R equal to the minimiza- 
tion of the sum on the right-hand side of Eq. 19. This task 
be still very hard. However, if the second low eigenvec- 
tor λ2 be close enough to zero, a good approximation of 
the minimum can be attain by choose s parallel to 
the correspond eigenvector v2, which be call Fiedler 
vector (Fiedler, 1973): this would reduce the sum to λ2, 
which be a small number. But the index vector cannot 
be perfectly parallel to v2 by construction, because all 
it component be equal in modulus, whereas the com- 
ponents of v2 be not. The best choice be to match the 
sign of the components. So, one can set si = +1 (−1) 
if vi2 > 0 (< 0). It may happen that the size of the two 
correspond group do not match the predefined size 
one wish to have. In this case, if one aim at a split in 
n1 and n2 = n−n1 vertices, the best strategy be to order 
the component of the Fiedler vector from the low to 
the large value and to put in one group the vertex 
correspond to the first n1 component from the top 
or the bottom, and the remain vertex in the second 
group. This procedure yield two partitions: the good 
solution be naturally the one that give the small cut 
size. 

The spectral bisection method be quite fast. The first 
eigenvectors of the Laplacian can be compute by use 
the Lanczos method (Lanczos, 1950). The time require 
to compute the first k eigenvectors of a matrix with the 
Lanczos method depends on the size of the eigengap 
|λk+1 − λk| (Golub and Loan, 1989). If the eigenval- 
ues λk+1 and λk be well separated, the run time of 
the algorithm be much shorter than the time require to 
calculate the complete set of eigenvectors, which scale a 
O(n3). The method give in general good partitions, that 
can be further improve by apply the Kernighan-Lin 
algorithm. 

The well know max-flow min-cut theorem by Ford 
and Fulkerson (Ford and Fulkerson, 1956) state that the 
minimum cut between any two vertex s and t of a graph, 
i. e. any minimal subset of edge whose deletion would 
topologically separate s from t, carry the maximum flow 
that can be transport from s to t across the graph. In 
this context edge play the role of water pipes, with a 
give carry capacity (e.g. their weights), and vertex 
the role of pipe junctions. This theorem have be use 
to determine minimal cut from maximal flow in clus- 
tering algorithms. There be several efficient routine to 
compute maximum flow in graphs, like the algorithm 
of Goldberg and Tarjan (Goldberg and Tarjan, 1988). 
Flake et al. (Flake et al., 2000; Flake et al., 2002) have 
recently use maximum flow to identify community in 
the graph of the World Wide Web. The web graph be 
direct but for the purpose of the calculation Flake et 
at. treat the edge a undirected. Web community 
be define to be “strong” (LS-sets), i. e. the internal de- 
gree of each vertex must not be small than it external 

degree (Radicchi et al., 2004). An artificial sink t be add 
to the graph and one calculates the maximum flow from 
a source vertex s to the sink t: the correspond mini- 
mum cut identifies the community of vertex s, provide s 
share a sufficiently large number of edge with the other 
vertex of it community, otherwise one could get trivial 
separation and meaningless clusters. 

Other popular method for graph partition in- 
clude level-structure partitioning, the geometric algo- 
rithm, multilevel algorithms, etc. A good description of 
these algorithm can be found in Ref. (Pothen, 1997). 

Graphs can be also partition by minimize mea- 
sures that be affine to the cut size, like conductance (Bol- 
lobas, 1998). The conductance Φ(C) of the subgraph C 
of a graph G be define a 

Φ(C) = c(C,G \ C) 
min(kC , kG\C) 

, (20) 

where c(C,G \C) be the cut size of C, and kC , kG\C be the 
total degree of C and of the rest of the graph G\C, respec- 
tively. Cuts be define only between non-empty sets, 
otherwise the measure would not be define (as the de- 
nominator in Eq. 20 would vanish). The minimum of the 
conductance be obtain in correspondence of low value 
of the cut size and of large value for the denominator in 
Eq. 20, which peak when the total degree of the cluster 
and it complement be equal. In practical applications, 
especially on large graphs, close value of the total de- 
grees correspond to cluster of approximately equal size. 
The problem of find a cut with minimal conductance 
be NP-hard (Š́ıma and Schaeffer, 2006). Similar mea- 
sures be the ratio cut (Wei and Cheng, 1989) and the 
normalize cut (Shi and Malik, 1997, 2000). The ratio 
cut of a cluster C be define a 

ΦC(C) = 
c(C,G \ C) 
nCnG\C 

, (21) 

where nC and nG\C be the number of vertex of the two 
subgraphs. The normalize cut of a cluster C be 

ΦN (C) = 
c(C,G \ C) 

kC 
, (22) 

where kC be again the total degree of C. As for the 
conductance, minimize the ratio cut and the normal- 
ized cut favor partition into cluster of approximately 
equal size, measure in term of the number of vertex 
or edges, respectively. On the other hand, graph par- 
titioning require preliminary assumption on the clus- 
ter sizes, whereas the minimization of conductance, ratio 
cut and normalize cut do not. The ratio cut be in- 
troduced for circuit partition (Wei and Cheng, 1989) 
and it optimization be an NP-hard problem (Matula and 
Shahrokhi, 1990). The normalize cut be frequently use 
in image segmentation (Blake and Zisserman, 1987) and 
it optimization be NP-complete (Shi and Malik, 2000). 
The cut ratio and the normalize cut can be quite well 



19 

minimize via spectral cluster (Chan et al., 1993; Ha- 
gen and Kahng, 1992) (Section IV.D). 

Algorithms for graph partition be not good for 
community detection, because it be necessary to provide 
a input the number of group and in some case even 
their sizes, about which in principle one know nothing. 
Instead, one would like an algorithm capable to produce 
this information in it output. Besides, from the method- 
ological point of view, use iterative bisectioning to split 
the graph in more piece be not a reliable procedure. For 
instance, a split into three cluster be necessarily obtain 
by break either cluster of the original bipartition in 
two parts, whereas in many case a minimum cut parti- 
tion be obtain if the third cluster be a merger of part 
of both initial clusters. 

B. Hierarchical cluster 

In general, very little be know about the community 
structure of a graph. It be uncommon to know the num- 
ber of cluster in which the graph be split, or other in- 
dications about the membership of the vertices. In such 
case cluster procedure like graph partition meth- 
od can hardly be of help, and one be force to make some 
reasonable assumption about the number and size of the 
clusters, which be often unjustified. On the other hand, 
the graph may have a hierarchical structure, i. e. may 
display several level of group of the vertices, with 
small cluster include within large clusters, which be 
in turn include in large clusters, and so on. Social net- 
works, for instance, often have a hierarchical structure 
(Section III.C.1). In such cases, one may use hierarchical 
cluster algorithm (Hastie et al., 2001), i. e. cluster- 
ing technique that reveal the multilevel structure of the 
graph. Hierarchical cluster be very common in social 
network analysis, biology, engineering, marketing, etc. 

The start point of any hierarchical cluster 
method be the definition of a similarity measure between 
vertices. After a measure be chosen, one computes the 
similarity for each pair of vertices, no matter if they be 
connect or not. At the end of this process, one be left 
with a new n×n matrix X, the similarity matrix. In Sec- 
tion III.B.4 we have list several possible definition of 
similarity. Hierarchical cluster technique aim at iden- 
tifying group of vertex with high similarity, and can be 
classify in two categories: 

1. Agglomerative algorithms, in which cluster be it- 
eratively merge if their similarity be sufficiently 
high; 

2. Divisive algorithms, in which cluster be iteratively 
split by remove edge connect vertex with 
low similarity. 

The two class refer to opposite processes: agglomera- 
tive algorithm be bottom-up, a one start from the ver- 
tices a separate cluster (singletons) and end up with 

the graph a a unique cluster; divisive algorithm be 
top-down a they follow the opposite direction. Divisive 
technique have be rarely use in the past (meanwhile 
they have become more popular, see Section V), so we 
shall concentrate here on agglomerative algorithms. 

Since cluster be merge base on their mutual sim- 
ilarity, it be essential to define a measure that estimate 
how similar cluster are, out of the matrix X. This in- 
volves some arbitrariness and several prescription exist. 
In single linkage clustering, the similarity between two 
group be the minimum element xij , with i in one group 
and j in the other. On the contrary, the maximum el- 
ement xij for vertex of different group be use in the 
procedure of complete linkage clustering. In average link- 
age cluster one have to compute the average of the xij . 

The procedure can be good illustrate by mean of 
dendrograms (Section III.C.1), like the one in Fig. 8. 
Sometimes, stop condition be impose to select a 
partition or a group of partition that satisfy a special 
criterion, like a give number of cluster or the optimiza- 
tion of a quality function (e.g. modularity). 

Hierarchical cluster have the advantage that it do 
not require a preliminary knowledge on the number and 
size of the clusters. However, it do not provide a way 
to discriminate between the many partition obtain by 
the procedure, and to choose that or those that good 
represent the community structure of the graph. The 
result of the method depend on the specific similarity 
measure adopted. The procedure also yield a hierarchi- 
cal structure by construction, which be rather artificial 
in most cases, since the graph at hand may not have a 
hierarchical structure at all. Moreover, vertex of a com- 
munity may not be correctly classified, and in many case 
some vertex be miss even if they have a central role 
in their cluster (Newman, 2004a). Another problem be 
that vertex with just one neighbor be often classify 
a separate clusters, which in most case do not make 
sense. Finally, a major weakness of agglomerative hier- 
archical cluster be that it do not scale well. If point 
be embed in space, so that one can use the distance 
a dissimilarity measure, the computational complexity 
be O(n2) for single linkage, O(n2 log n) for the complete 
and average linkage schemes. For graph clustering, where 
a distance be not trivially defined, the complexity can be- 
come much heavier if the calculation of the chosen simi- 
larity measure be costly. 

C. Partitional cluster 

Partitional cluster indicates another popular class 
of method to find cluster in a set of data points. Here, 
the number of cluster be preassigned, say k. The point 
be embed in a metric space, so that each vertex be 
a point and a distance measure be define between pair 
of point in the space. The distance be a measure of dis- 
similarity between vertices. The goal be to separate the 
point in k cluster such to maximize/minimize a give 



20 

cost function base on distance between point and/or 
from point to centroids, i. e. suitably define position in 
space. Some of the most use function be list below: 

• Minimum k-clustering. The cost function here be 
the diameter of a cluster, which be the large dis- 
tance between two point of a cluster. The point 
be classify such that the large of the k cluster 
diameter be the small possible. The idea be to 
keep the cluster very “compact”. 

• k-clustering sum. Same a minimum k-clustering, 
but the diameter be replace by the average distance 
between all pair of point of a cluster. 

• k-center. For each cluster i one defines a refer- 
ence point xi, the centroid, and computes the max- 
imum di of the distance of each cluster point from 
the centroid. The cluster and centroid be self- 
consistently chosen such to minimize the large 
value of di. 

• k-median. Same a k-center, but the maximum dis- 
tance from the centroid be replace by the average 
distance. 

The most popular partitional technique in the literature 
be k-means cluster (MacQueen, 1967). Here the cost 
function be the total intra-cluster distance, or square 
error function 

k∑ 
i=1 

∑ 
xj∈Si 

||xj − ci||2, (23) 

where Si indicates the subset of point of the i-th clus- 
ter and ci it centroid. The k-means problem can be 
simply solve with the Lloyd’s algorithm (Lloyd, 1982). 
One start from an initial distribution of centroid such 
that they be a far a possible from each other. In the 
first iteration, each vertex be assign to the near cen- 
troid. Next, the center of mass of the k cluster be 
estimate and become a new set of centroids, which al- 
low for a new classification of the vertices, and so on. 
After a small number of iterations, the position of the 
centroid be stable, and the cluster do not change any 
more. The solution found be not optimal, and it strongly 
depends on the initial choice of the centroids. Neverthe- 
less, Lloyd’s heuristic have remain popular due to it 
quick convergence, which make it suitable for the anal- 
ysis of large data sets. The result can be improve by 
perform more run start from different initial con- 
ditions, and pick the solution which yield the mini- 
mum value of the total intra-cluster distance. Extensions 
of k-means cluster to graph have be propose by 
some author (Hlaoui and Wang, 2004; Rattigan et al., 
2007; Schenker et al., 2003). 

Another popular technique, similar in spirit to k-means 
clustering, be fuzzy k-means cluster (Bezdek, 1981; 
Dunn, 1974). This method account for the fact that 
a point may belong to two or more cluster at the same 

time and be widely use in pattern recognition. The as- 
sociated cost function be 

Jm = 

n∑ 
i=1 

k∑ 
j=1 

umij ||xi − cj||2, (24) 

where uij be the membership matrix, which measure the 
degree of membership of point i (with position xi) in 
cluster j, m be a real number great than 1 and cj be the 
center of cluster j 

cj = 

∑n 
i=1 u 

m 
ijxi∑n 

i=1 u 
m 
ij 

. (25) 

The matrix uij be normalize so that the sum of the mem- 
berships of every point in all cluster yield 1. The mem- 
bership uij be related to the distance of point i from the 
center of cluster j, a it be reasonable to assume that the 
large this distance, the low uij . This can be express 
by the follow relation 

uij = 
1∑k 

l=1 

( 
||xi−cj|| 
||xi−cl|| 

) 2 
m−1 

. (26) 

The cost function Jm can be minimize by iterate 
Eqs. 25 and 26. One start from some initial guess for 
uij and us Eq. 25 to compute the centers, which be 
then plug back into Eqs. 26, and so on. The pro- 
ce stop when the correspond element of the mem- 
bership matrix in consecutive iteration differ from each 
other by less than a predefined tolerance. It can be show 
that this procedure indeed delivers a local minimum of 
the cost function Jm of Eq. 24. This procedure have the 
same problem of Lloyd’s algorithm for k-means cluster- 
ing, i. e. the minimum be a local minimum, and depends 
on the initial choice of the matrix uij . 

The limitation of partitional cluster be the same a 
that of the graph partition algorithms: the number of 
cluster must be specify at the beginning, the method 
be not able to derive it. In addition, the embed in a 
metric space can be natural for some graphs, but rather 
artificial for others. 

D. Spectral cluster 

Let u suppose to have a set of n object x1, x2, ..., xn 
with a pairwise similarity function S define between 
them, which be symmetric and non-negative (i. e., 
S(xi, xj) = S(xj , xi) ≥ 0, ∀i, j = 1, ..n). Spectral clus- 
tering include all method and technique that partition 
the set into cluster by use the eigenvectors of matrices, 
like S itself or other matrix derive from it. In partic- 
ular, the object could be point in some metric space, 
or the vertex of a graph. Spectral cluster consists of 
a transformation of the initial set of object into a set of 
point in space, whose coordinate be element of eigen- 
vectors: the set of point be then cluster via standard 



21 

techniques, like k-means cluster (Section IV.C). One 
may wonder why it be necessary to cluster the point ob- 
tained through the eigenvectors, when one can directly 
cluster the initial set of objects, base on the similarity 
matrix. The reason be that the change of representation 
induced by the eigenvectors make the cluster property 
of the initial data set much more evident. In this way, 
spectral cluster be able to separate data point that 
could not be resolve by apply directly k-means clus- 
tering, for instance, a the latter tends to deliver convex 
set of points. 

The first contribution on spectral cluster be a pa- 
per by Donath and Hoffmann (Donath and Hoffman, 
1973), who use the eigenvectors of the adjacency matrix 
for graph partitions. In the same year, Fiedler (Fiedler, 
1973) realize that from the eigenvector of the second 
small eigenvalue of the Laplacian matrix it be pos- 
sible to obtain a bipartition of the graph with very low 
cut size, a we have explain in Section IV.A. For a 
historical survey see Ref. (Spielman and Teng, 1996). 
In this Section we shall follow the nice tutorial by von 
Luxburg (von Luxburg, 2006), with a focus on spectral 
graph clustering. The concept and method discuss 
below apply to both unweighted and weight graphs. 

The Laplacian be by far the most use matrix in spec- 
tral clustering. In Section A.2 we see that the unnormal- 
ized Laplacian of a graph with k connect component 
have k zero eigenvalues. In this case the Laplacian can 
be write in block-diagonal form, i. e. the vertex can 
be order in such a way that the Laplacian display 
k square block along the diagonal, with (some) entry 
different from zero, whereas all other element vanish. 
Each block be the Laplacian of the correspond sub- 
graph, so it have the trivial eigenvector with component 
(1, 1, 1, ..., 1, 1). Therefore, there be k degenerate eigen- 
vector with equal non-vanishing component in corre- 
spondence of the vertex of a block, whereas all other 
component be zero. In this way, from the component 
of the eigenvectors one can identify the connect com- 
ponents of the graph. For instance, let u consider the 
n×k matrix, whose column be the k eigenvectors above 
mentioned. The i-th row of this matrix be a vector with k 
component represent vertex i of the graph. Vectors 
represent vertex in the same connect component of 
the graph coincide, and their tip lie on one of the ax of 
a k-dimensional system of coordinate (i. e. they be all 
vector of the form (0, 0, ...0, 1, 0, ..., 0, 0)). So, by draw- 
ing the vertex vector one would see k distinct points, 
each on a different axis, correspond to the graph com- 
ponents. 

If the graph be connected, but consists of k subgraphs 
which be weakly link to each other, the spectrum of 
the unnormalized Laplacian will have one zero eigen- 
value, all others be positive. Now the Laplacian can- 
not be put in block-diagonal form: even if one enumer- 
ate the vertex in the order of their cluster membership 
(by listing first the vertex of one cluster, then the ver- 
tices of another cluster, etc.) there will always be some 

non-vanishing entry outside of the blocks. However, the 
low k − 1 non-vanishing eigenvalue be still close to 
zero, and the vertex vector of the first k eigenvectors 
should still enable one to clearly distinguish the cluster 
in a k-dimensional space. Vertex vector correspond 
to the same cluster be now not coincident, in general, but 
still rather close to each other. So, instead of k points, 
one would observe k group of points, with the point of 
each group localize close to each other and far from the 
other groups. Techniques like k-means cluster (Sec- 
tion IV.C) can then easily recover the clusters. 

The scenario we have described be expect from per- 
turbation theory (Bhatia, 1997; Stewart and Sun, 1990). 
In principle all symmetric matrix that can be put in 
block-diagonal form have a set of eigenvectors (as many 
a the blocks), such that the element of each eigenvec- 
tor be different from zero on the vertex of a block and 
zero otherwise, just like the Laplacian. The adjacency 
matrix itself have the same property, for example. This be 
a necessary condition for the eigenvectors to be success- 
fully use for graph clustering, but it be not sufficient. In 
the case of the Laplacian, for a graph with k connect 
components, we know that the eigenvectors correspond- 
ing to the k low eigenvalue come each from one of 
the components. In the case of the adjacency matrix A 
(or of it weight counterpart W), instead, it may hap- 
pen that large eigenvalue refer to the same component. 
So, if one take the eigenvectors correspond to the k 
large eigenvalues8, some component will be overrepre- 
sented, while others will be absent. Therefore, use the 
eigenvectors of A (or W) in spectral graph cluster be 
in general not reliable. Moreover, the element of the 
eigenvectors correspond to the component should be 
sufficiently far from zero. To understand why, suppose 
that we take a (symmetric, block-diagonal) matrix, and 
that one or more element of one of the eigenvectors cor- 
respond to the connect component be very close 
to zero. If one perturbs the graph by add edge be- 
tween different components, all entry of the perturbed 
eigenvectors will become non-zero and some may have 
comparable value a the low element of the eigenvec- 
tor on the blocks. Therefore distinguish vertex of 
different component may become a problem, even when 
the perturbation be fairly small, and misclassifications be 
likely. On the other hand, the non-vanishing element of 
the (normalized) eigenvectors of the unnormalized Lapla- 
cian, for instance, be all equal to 1/ 

√ 
ni, where ni be the 

number of vertex in the i-th component. In this way, 
there be a gap between the low element (here they be 
all equal for the same eigenvector) and zero. This hold a 
well for the normalize Laplacian Lrw (Section A.2). For 
the other normalize Laplacian Lsym (Section A.2), the 

8 Large eigenvalue of the adjacency matrix be the counterpart of 
the low eigenvalue of the Laplacian, since L = D−A, where D 
be the diagonal matrix whose element be the vertex degrees. 



22 

non-zero element of the eigenvectors correspond to 
the connect component be proportional to the square 
root of the degree of the correspond vertex. So, if de- 
grees be very different from each other, and especially if 
there be vertex with very low degree, some eigenvec- 
tor element may be quite small. As we shall see below, 
in the context of the technique by Ng et al. (Ng et al., 
2001), a suitable normalization procedure be introduce 
to alleviate this problem. 

Now that we have explain why the Laplacian matrix 
be particularly suitable for spectral clustering, we proceed 
with the description of three popular methods: unnor- 
malized spectral cluster and two normalize spectral 
cluster techniques, propose by Shi and Malik (Shi 
and Malik, 1997, 2000) and by Ng et al. (Ng et al., 2001), 
respectively. 

Unnormalized spectral cluster us the unnormal- 
ized Laplacian L. The input be the adjacency matrix 
A (W for weight graphs) and the number k of cluster 
to be recovered. The first step consists in compute the 
eigenvectors correspond to the low k eigenvalue of 
L. Then, one build the n× k matrix V, whose column 
be the k eigenvectors. The n row of V be use to rep- 
resent the graph vertex in a k-dimensional Euclidean 
space, through a Cartesian system of coordinates. The 
point be then grouped in k cluster by use k-means 
cluster or similar technique (Section IV.C). Normal- 
ized spectral cluster work in the same way. In the 
version by Shi and Malik (Shi and Malik, 1997, 2000), 
one us the eigenvectors of the normalize Laplacian 
Lrw (Section A.2). In the algorithm by Ng et al. (Ng 
et al., 2001) one adopts the normalize Laplacian Lsym 
(Section A.2). Here, however, the matrix V be normal- 
ized by divide the element of each row by their sum, 
obtain a new matrix U, whose row be then use to 
represent the vertex in space, a in the other methods. 
By do so, it be much more unlikely that eigenvector 
component for a well-separated cluster be close to zero, 
a scenario which would make the classification of the cor- 
respond vertex problematic, a we have say above. 
However, if the graph have some vertex with low degree, 
they may still be misclassified. 

Spectral cluster be closely related to graph parti- 
tioning. Relaxed version of the minimization of ratio cut 
and normalize cut (see Section IV.A) can be turn into 
spectral cluster problems, by follow similar proce- 
dures a in spectral graph partitioning. The measure 
to minimize can be express in matrix form, obtain- 
ing similar expression a for the cut size (see Eq. 18), 
with index vector define the partition of the graph in 
group through the value of their entries. For instance, 
for the minimum cut bipartition of Section IV.A, there 
be only one index vector s, whose component equal ±1, 
where the sign indicate the two clusters. The relaxation 
consists in perform the minimization over all possible 
vector s, allow for real-valued component a well. 
This version of the problem be exactly equivalent to spec- 
tral clustering. The relaxed minimization of ratio cut 

for a partition in k cluster yield the n k-dimensional 
vertex vector of unnormalized spectral cluster (von 
Luxburg, 2006); for normalize cut one obtains the n k- 
dimensional vertex vector of normalize spectral cluster- 
ing, with the normalize Laplacian Lrw (Shi and Malik, 
1997). The problem be then to turn the result vector 
into a partition of the graph, which can be do by us- 
ing technique like k-means clustering, a we have see 
above. However, it be still unclear what be the relation 
between the original minimum cut problem over actual 
graph partition and the relaxed version of it, in par- 
ticular how close one can come to the real solution via 
spectral clustering. 

Random walk on graph be also related to spec- 
tral clustering. In fact, by minimize the number of 
edge between cluster (properly normalize for measure 
like, e. g., ratio cut and normalize cut) one force ran- 
dom walker to spend more time within cluster and to 
move more rarely from one cluster to another. In par- 
ticular, unnormalized spectral cluster with the Lapla- 
cian Lrw have a natural link with random walks, because 
Lrw = I − D−1A (Section A.2), where D−1A be the 
transfer matrix T. This have interest consequences. 
For instance, Meilă and Shi have proven that the nor- 
malized cut for a bipartition equal the total probability 
that a random walker move from one of the cluster to 
the other in either sense (Meila and Shi, 2001). In this 
way, minimize the normalize cut mean look for 
a partition minimize the probability of transition be- 
tween clusters. 

Spectral cluster require the computation of the 
first k eigenvectors of a Laplacian matrix. If the graph 
be large, an exact computation of the eigenvectors be 
impossible, a it would require a time O(n3). Fortu- 
nately there be approximate techniques, like the power 
method or Krylov subspace technique like the Lanczos 
method (Golub and Loan, 1989), whose speed depends 
on the size of the eigengap |λk+1 − λk|, where λk and 
λk+1 be the k-th and (k + 1)-th small eigenvalue of 
the matrix. The large the eigengap, the faster the con- 
vergence. In fact, the existence of large gap between 
pair of consecutive eigenvalue could suggest the num- 
ber of cluster of the graph, an information which be not 
deliver by spectral cluster and which have to be give 
a input. We know that, for a disconnect graph with k 
components, the first k eigenvalue of the Laplacian ma- 
trix (normalized or not) be zero, whether the (k+ 1)-th 
be non-zero. If the cluster be weakly connect to each 
other, one expect that the first k eigenvalue remain 
close to zero, and that the (k + 1)-th be clearly different 
from zero. By reverse this argument, the number of 
cluster of a graph could be derive by check whether 
there be an integer k such that the first k eigenvalue be 
small and the (k+1)-th be relatively large. However, when 
the cluster be very mixed with each other, it may be 
hard to identify significant gap between the eigenvalues. 

The last issue we want to point out concern the choice 
of the Laplacian matrix to use in the applications. If the 



23 

graph vertex have the same or similar degrees, there 
be no substantial difference between the unnormalized 
and the normalize Laplacians. If there be big inhomo- 
geneities among the vertex degrees, instead, the choice 
of the Laplacian considerably affect the results. In gen- 
eral, normalize Laplacians be more promising because 
the correspond spectral cluster technique implic- 
itly impose a double optimization on the set of partitions, 
such that the intracluster edge density be high and, at 
the same time, the intercluster edge density be low. On 
the contrary, the unnormalized Laplacian be related to 
the intercluster edge density only. Moreover, unnormal- 
ized spectral cluster do not always converge, and 
sometimes yield trivial partition in which one or more 
cluster consist of a single vertex. Of the normalize 
Laplacians, Lrw be more reliable than Lsym because the 
eigenvectors of Lrw correspond to the low eigenval- 
ues be cluster indicator vectors, i. e., they have equal 
non-vanishing entry in correspondence of the vertex 
of each cluster, and zero elsewhere, if the cluster be 
disconnected. The eigenvectors of Lsym, instead, be ob- 
tained by (left-) multiply those of Lrw by the matrix 
D1/2: in this way, eigenvector component correspond- 
ing to vertex of the same cluster be no longer equal, in 
general, a complication that may induce artefact in the 
spectral cluster procedure. 

V. DIVISIVE ALGORITHMS 

A simple way to identify community in a graph be to 
detect the edge that connect vertex of different com- 
munities and remove them, so that the cluster get dis- 
connect from each other. This be the philosophy of 
divisive algorithms. The crucial point be to find a prop- 
erty of intercommunity edge that could allow for their 
identification. Divisive method do not introduce sub- 
stantial conceptual advance with respect to traditional 
techniques, a they just perform hierarchical cluster 
on the graph at study (Section IV.B). The main differ- 
ence with divisive hierarchical cluster be that here one 
remove inter-cluster edge instead of edge between pair 
of vertex with low similarity and there be no guarantee a 
priori that inter-cluster edge connect vertex with low 
similarity. In some case vertex (with all their adja- 
cent edges) or whole subgraphs may be removed, instead 
of single edges. Being hierarchical cluster techniques, 
it be customary to represent the result partition by 
mean of dendrograms. 

A. The algorithm of Girvan and Newman 

The most popular algorithm be that propose by Gir- 
van and Newman (Girvan and Newman, 2002; Newman 
and Girvan, 2004). The method be historically important, 
because it marked the begin of a new era in the field 
of community detection and open this topic to physi- 

� 
� 
� 
� 

� 
� 
� 
� 
� 
� 
� 
� 
� 
� 
� 
� 

� 
� 
� 
� 

� 
� 
� 
� 

� 
� 
� 
� 

� 
� 
� 
� 

� 
� 
� 
� 

� 
� 
� 
� 

� 
� 
� 
� 

� 
� 
� 
� 

������ 
������ 
������ 

������ 
������ 
������ 

FIG. 10 Edge betweenness be high for edge connect 
communities. In the figure, the edge in the middle have a much 
high betweenness than all other edges, because all shortest 
path connect vertex of the two community run through 
it. Reprinted figure with permission from Ref. (Fortunato and 
Castellano, 2009). c©2009 by Springer. 

cists. Here edge be select accord to the value of 
measure of edge centrality, estimate the importance of 
edge accord to some property or process run on 
the graph. The step of the algorithm are: 

1. Computation of the centrality for all edges; 

2. Removal of edge with large centrality: in case 
of tie with other edges, one of them be picked at 
random; 

3. Recalculation of centrality on the run graph; 

4. Iteration of the cycle from step 2. 

Girvan and Newman focus on the concept of between- 
ness, which be a variable express the frequency of the 
participation of edge to a process. They consider 
three alternative definitions: geodesic edge betweenness, 
random-walk edge betweenness and current-flow edge be- 
tweenness. In the follow we shall refer to them a edge 
betweenness, random-walk betweenness and current-flow 
betweenness, respectively. 

Edge betweenness be the number of shortest path be- 
tween all vertex pair that run along the edge. It be an 
extension to edge of the popular concept of site between- 
ness, introduce by Freeman in 1977 (Freeman, 1977) 
and express the importance of edge in process like 
information spreading, where information usually flow 
through shortest paths. Historically edge betweenness 
be introduce before site betweenness in a never pub- 
lished technical report by Anthonisse (Anthonisse, 1971). 
It be intuitive that intercommunity edge have a large 
value of the edge betweenness, because many shortest 
path connect vertex of different community will 
pas through them (Fig. 10). As in the calculation of 
site betweenness, if there be two or more geodesic path 
with the same endpoint that run through an edge, the 
contribution of each of them to the betweenness of the 
edge must be divide by the multiplicity of the paths, 
a one assumes that the signal/information propagates 
equally along each geodesic path. The betweenness of all 
edge of the graph can be calculate in a time that scale 
a O(mn), or O(n2) on a sparse graph, with technique 



24 

base on breadth-first-search (Brandes, 2001; Newman 
and Girvan, 2004; Zhou et al., 2006). 

In the context of information spreading, one could 
imagine that signal flow across random rather than 
geodesic paths. In this case the betweenness of an edge 
be give by the frequency of the passage across the edge 
of a random walker run on the graph (random-walk 
betweenness). A random walker move from a vertex 
follow each adjacent edge with equal probability. A pair 
of vertex be chosen at random, s and t. The walker start 
at s and keep move until it hit t, where it stops. One 
computes the probability that each edge be cross by 
the walker, and average over all possible choice for the 
vertex s and t. It be meaningful to compute the net 
cross probability, which be proportional to the num- 
ber of time the walk cross the edge in one direction. 
In this way one neglect back and forth passage that 
be accident of the random walk and tell nothing about 
the centrality of the edge. Calculation of random-walk 
betweenness require the inversion of an n × n matrix 
(once), follow by obtain and average the flow for 
all pair of nodes. The first task require a time O(n3), 
the second O(mn2), for a total complexity O[(m+n)n2], 
or O(n3) for a sparse matrix. The complete calculation 
require a time O(n3) on a sparse graph. 

Current-flow betweenness be define by consider the 
graph a resistor network, with edge have unit resis- 
tance. If a voltage difference be apply between any two 
vertices, each edge carry some amount of current, that 
can be calculate by solve Kirchoff’s equations. The 
procedure be repeat for all possible vertex pairs: the 
current-flow betweenness of an edge be the average value 
of the current carry by the edge. It be possible to show 
that this measure be equivalent to random-walk between- 
ness, a the voltage difference and the random walk net 
flow across the edge satisfy the same equation (New- 
man, 2005). Therefore, the calculation of current-flow 
betweenness have the same complexity O[(m + n)n2], or 
O(n3) for a sparse graph. 

Calculating edge betweenness be much faster than 
current-flow or random walk betweenness [O(n2) versus 
O(n3) on sparse graphs]. In addition, in practical ap- 
plication the Girvan-Newman algorithm with edge be- 
tweenness give good result than adopt the other 
centrality measure (Newman and Girvan, 2004). Nu- 
merical study show that the recalculation step 3 of 
Girvan-Newman algorithm be essential to detect mean- 
ingful communities. This introduces an additional factor 
m in the run time of the algorithm: consequently, 
the edge betweenness version scale a O(m2n), or O(n3) 
on a sparse graph. On graph with strong community 
structure, that quickly break into communities, the re- 
calculation step need to be perform only within the 
connect component include the last remove edge 
(or the two component bridge by it if the removal of 
the edge split a subgraph), a the edge betweenness of all 
other edge remains the same. This can help save some 
computer time, although it be impossible to give estimate 

of the gain since it depends on the specific graph at hand. 
Nevertheless, the algorithm be quite slow, and applicable 
to sparse graph with up to n ∼ 10000 vertices, with 
current computational resources. In the original version 
of Girvan-Newman’s algorithm (Girvan and Newman, 
2002), the author have to deal with the whole hierar- 
chy of partitions, a they have no procedure to say which 
partition be the best. In a successive refinement (New- 
man and Girvan, 2004), they select the partition with 
the large value of modularity (see Section III.C.2), a 
criterion that have be frequently use ever since. The 
method can be simply extend to the case of weight 
graphs, by suitably generalize the edge betweenness. 
The betweenness of a weight edge equal the between- 
ness of the edge in the correspond unweighted graph, 
divide by the weight of the edge (Newman, 2004). There 
have be countless application of the Girvan-Newman 
method: the algorithm be now integrate in well know 
library of network analysis programs. 

Tyler et al. propose a modification of the Girvan- 
Newman algorithm, to improve the speed of the calcula- 
tion (Tyler et al., 2003; Wilkinson and Huberman, 2004). 
The gain in speed be require by the analysis of graph 
of gene co-occurrences, which be too large to be ana- 
lyzed by the algorithm of Girvan and Newman. Algo- 
rithms compute site/edge betweenness start from any 
vertex, take a center, and compute the contribution to 
betweenness from all path originate at that vertex; the 
procedure be then repeat for all vertex (Brandes, 2001; 
Newman and Girvan, 2004; Zhou et al., 2006). Tyler et 
al. propose to calculate the contribution to edge be- 
tweenness only from a limited number of centers, chosen 
at random, derive a sort of Monte Carlo estimate. Nu- 
merical test indicate that, for each connect subgraph, 
it suffices to pick a number of center grow a the log- 
arithm of the number of vertex of the component. For 
a give choice of the centers, the algorithm proceeds just 
like that of Girvan and Newman. The stop criterion 
be different, though, a it do not require the calcula- 
tion of modularity on the result partitions, but relies 
on a particular definition of community. According to 
such definition, a connect subgraph with n0 vertex be 
a community if the edge betweenness of any of it edge 
do not exceed n0 − 1. Indeed, if the subgraph consists 
of two part connect by a single edge, the between- 
ness value of that edge would be great than or equal to 
n0 − 1, with the equality hold only if one of the two 
part consists of a single vertex. Therefore, the condition 
on the betweenness of the edge would exclude such sit- 
uations, although other type of cluster structure might 
still be compatible with it. In this way, in the method of 
Tyler et al., edge be remove until all connect com- 
ponents of the partition be “communities” in the sense 
explain above. The Monte Carlo sample of the edge 
betweenness necessarily induces statistical errors. As a 
consequence, the partition be in general different for 
different choice of the set of center vertices. However, 
the author show that, by repeat the calculation 



25 

many times, the method give good result on a network 
of gene co-occurrence (Wilkinson and Huberman, 2004), 
with a substantial gain of computer time. The technique 
have be also apply to a network of people correspond- 
ing via email (Tyler et al., 2003). In practical examples, 
only vertex lie at the boundary between community 
may not be clearly classified, and be assign sometimes 
to a group, sometimes to another. This be actually a nice 
feature of the method, a it allows to identify overlap 
between communities, a well a the degree of member- 
ship of overlap vertex in the cluster they belong 
to. The algorithm of Girvan and Newman, which be de- 
terministic, be unable to accomplish this9. Another fast 
version of the Girvan-Newman algorithm have be pro- 
pose by Rattigan et al. (Rattigan et al., 2007). Here, 
a quick approximation of the edge betweenness value 
be carry out by use a network structure index, which 
consists of a set of vertex annotation combine with a 
distance measure (Rattigan et al., 2006). Basically one 
divide the graph into region and computes the distance 
of every vertex from each region. In this way Rattigan et 
al. show that it be possible to low the complexity of 
the algorithm to O(m), by keep a fair accuracy in the 
estimate of the edge betweenness values. This version of 
the Girvan-Newman algorithm give good result on the 
benchmark graph propose by Brandes et al. (Brandes 
et al., 2003) (see also Section XV.A), a well a on a col- 
laboration network of actor and on a citation network. 

Chen and Yuan have point out that counting all pos- 
sible shortest path in the calculation of the edge be- 
tweenness may lead to unbalanced partitions, with com- 
munities of very different size, and propose to count only 
non-redundant paths, i. e. path whose endpoint be 
all different from each other: the result betweenness 
yield good result than standard edge betweenness for 
mixed cluster on the benchmark graph of Girvan and 
Newman (Chen and Yuan, 2006). Holme et al. have use 
a modify version of the algorithm in which vertices, 
rather than edges, be remove (Holme et al., 2003). A 
centrality measure for the vertices, proportional to their 
site betweenness, and inversely proportional to their in- 
degree, be chosen to identify boundary vertices, which 
be then iteratively remove with all their edges. This 
modification, apply to study the hierarchical organiza- 
tion of biochemical networks, be motivate by the need to 
account for reaction kinetic information, that simple site 
betweenness do not include. The indegree of a vertex be 
solely use because it indicates the number of substrate 
to a metabolic reaction involve that vertex; for the pur- 
pose of cluster the graph be consider undirected, a 
usual. 

9 It may happen that, at a give iteration, two or more edge of the 
graph have the same value of maximal betweenness. In this case 
one can pick any of them at random, which may lead in general 
to (slightly) different partition at the end of the computation. 

The algorithm of Girvan and Newman be unable to 
find overlap communities, a each vertex be assign 
to a single cluster. Pinney and Westhead have propose 
a modification of the algorithm in which vertex can 
be split between community (Pinney and Westhead, 
2006). To do that, they also compute the betweenness 
of all vertex of the graph. Unfortunately the value of 
edge and site betweenness cannot be simply compared, 
due to their different normalization, but the author re- 
marked that the two endvertices of an inter-cluster edge 
should have similar betweenness values, a the shortest 
path cross one of them be likely to reach the other 
one a well through the edge. So they take the edge with 
large betweenness and remove it only if the ratio of the 
betweenness value of it endvertices be between α and 
1/α, with α = 0.8. Otherwise, the vertex with high 
betweenness (with all it adjacent edges) be temporarily 
removed. When a subgraph be split by vertex or edge 
removal, all delete vertex belonging to that subgraph 
be “copied” in each subcomponent, along with all their 
edges. Gregory (Gregory, 2007) have propose a similar 
approach, name CONGA (Cluster Overlap Newman- 
Girvan Algorithm), in which vertex be split among 
cluster if their site betweenness exceeds the maximum 
value of the betweenness of the edges. A vertex be split 
by assign some of it edge to one of it duplicates, 
and the rest to the other. There be several possibility 
to do that, Gregory propose to go for the split that 
yield the maximum of a new centrality measure, call 
split betweenness, which be the number of shortest path 
that would run between two part of a vertex if the latter 
be split. The method have a worst-case complexity 
O(m3), or O(n3) on a sparse graph, like the algorithm 
of Girvan and Newman. The code can be found at 
http://www.cs.bris.ac.uk/∼steve/networks/index. 
html. 

B. Other method 

Another promising track to detect inter-cluster edge 
be related to the presence of cycles, i. e. close non- 
intersect paths, in the graph. Communities be char- 
acterized by a high density of edges, so it be reasonable 
to expect that such edge form cycles. On the contrary, 
edge lie between community will hardly be part of 
cycles. Based on this intuitive idea, Radicchi et al. pro- 
pose a new measure, the edge cluster coefficient, such 
that low value of the measure be likely to correspond 
to intercommunity edge (Radicchi et al., 2004). The 
edge cluster coefficient generalizes to edge the notion 
of cluster coefficient introduce by Watts and Stro- 
gatz for vertex (Watts and Strogatz, 1998) (Fig. 11). 
The cluster coefficient of a vertex be the number of 
triangle include the vertex divide by the number of 
possible triangle that can be form (Section A.1). The 



26 

FIG. 11 Schematic illustration of the edge cluster coef- 
ficient introduce by Radicchi et al. (Radicchi et al., 2004). 
The two grey vertex have five and six other neighbors, re- 
spectively. Of the five possible triangle base on the edge 
connect the grey vertices, three be actually there, yield- 
ing an edge cluster coefficient C3 = 3/5. Courtesy by F. 
Radicchi. 

edge cluster coefficient be define a 

C̃ 
(g) 
i,j = 

z 
(g) 
i,j + 1 

s 
(g) 
i,j 

, (27) 

where i and j be the extreme of the edge, z 
(g) 
i,j the 

number of cycle of length g built upon edge ij and s 
(g) 
i,j 

the possible number of cycle of length g that one could 
build base on the exist edge of i, j and their neigh- 
bors. The number of actual cycle in the numerator be 
augment by 1 to enable a rank among edge with- 

out cycles, which would all yield a coefficient C̃ 
(g) 
i,j equal 

to zero, independently of the degree of the extreme 
i and j and their neighbors. Usually, cycle of length 
g = 3 (triangles) or 4 be considered. The measure be 
(anti)correlated with edge betweenness: edge with low 
edge cluster coefficient usually have high betweenness 
and vice versa, although the correlation be not perfect. 
The method work a the algorithm by Girvan and New- 
man. At each iteration, the edge with small cluster 
coefficient be removed, the measure be recalculate again, 
and so on. If the removal of an edge lead to a split 
of a subgraph in two parts, the split be accepted only 
if both cluster be LS-sets (“strong”) or “weak” com- 
munities (see Section III.B.2). The verification of the 
community condition on the cluster be perform on the 
full adjacency matrix of the initial graph. If the condi- 
tion be satisfied only for one of the two clusters, the 
initial subgraph may be a random graph, a it can be 
easily see that by cut a random graph á la Erdös 
and Rényi in two parts, the large of them be a strong (or 
weak) community with very high probability, whereas the 
small part be not. Enforcing the community condition 
on both clusters, it be more likely that the subgraph to 

be split indeed have a cluster structure. Therefore, the al- 
gorithm stop when all cluster produce by the edge re- 
movals be community in the strong or weak sense, and 
further split would violate this condition. The author 
suggest to use the same stop criterion for the al- 
gorithm of Girvan and Newman, to get structurally well- 
define clusters. Since the edge cluster coefficient be a 
local measure, involve at most an extend neighbor- 
hood of the edge, it can be calculate very quickly. The 
run time of the algorithm to completion isO(m4/n2), 
or O(n2) on a sparse graph, if g be small, so it be much 
shorter than the run time of the Girvan-Newman 
method. The recalculation step becomes slow if g be not 
so small, a in this case the number of edge whose co- 
efficient need to be recalculate may reach a sizeable 
fraction of the edge of the graph; likewise, counting the 
number of cycle base on one edge becomes lengthier. 
If g ∼ 2d, where d be the diameter of the graph (which 
be usually a small number for real networks), the cycle 
span the whole graph and the measure becomes global 
and no more local. The computational complexity in 
this case exceeds that of the algorithm of Girvan and 
Newman, but it can come close to it for practical pur- 
pose even at low value of g. So, by tune g one can 
smoothly interpolate between a local and a global cen- 
trality measure. The software of the algorithm can be 
found in http://filrad.homelinux.org/Data/. In a 
successive paper (C. Castellano et al., 2004) the author 
extend the method to the case of weight networks, 
by modify the edge cluster coefficient of Eq. 27, 

in that the number of cycle z 
(g) 
i,j be multiply by the 

weight of the edge ij. The definition of strong and 
weak community can be trivially extend to weight 
graph by replace the internal/external degree of the 
vertices/clusters with the correspond strengths. More 
recently, the method have be extend to bipartite net- 
work (Zhang et al., 2007), where only cycle of even 
length be possible (g = 4, 6, 8, etc.). The algorithm by 
Radicchi et al. may give poor result when the graph have 
few cycles, a it happens in some social and many non- 
social networks. In this case, in fact, the edge cluster 
coefficient be small and fairly similar for most edges, and 
the algorithm may fail to identify the bridge between 
communities. 

An alternative measure of centrality for edge be in- 
formation centrality. It be base on the concept of ef- 
ficiency (Latora and Marchiori, 2001), which estimate 
how easily information travel on a graph accord to 
the length of shortest path between vertices. The effi- 
ciency of a network be define a the average of the in- 
verse distance between all pair of vertices. If the ver- 
tices be “close” to each other, the efficiency be high. The 
information centrality of an edge be the relative varia- 
tion of the efficiency of the graph if the edge be removed. 
In the algorithm by Fortunato et al. (Fortunato et al., 
2004), edge be remove accord to decrease value 
of information centrality. The method be analogous to 
that of Girvan and Newman. Computing the informa- 



27 

tion centrality of an edge require the calculation of the 
distance between all pair of vertices, which can be do 
with breadth-first-search in a time O(mn). So, in order 
to compute the information centrality of all edge one re- 
quire a time O(m2n). At this point one remove the edge 
with the large value of information centrality and recal- 
culates the information centrality of all remain edge 
with respect to the run graph. Since the procedure be 
iterate until there be no more edge in the network, the 
final complexity be O(m3n), or O(n4) on a sparse graph. 
The partition with the large value of modularity be cho- 
sen a most representative of the community structure of 
the graph. The method be much slow than the algo- 
rithm of Girvan and Newman. Partitions obtain with 
both technique be rather consistent, mainly because in- 
formation centrality have a strong correlation with edge 
betweenness. The algorithm by Fortunato et al. give 
good result when community be mixed, i. e. with a 
high degree of interconnectedness, but it tends to isolate 
leaf vertex and small loosely bound subgraphs. 

A measure of vertex centrality base on loops, similar 
to the cluster coefficient by Watts and Strogatz (Watts 
and Strogatz, 1998), have be introduce by Vragoviĉ 
and Louis (Vragović and Louis, 2006). The idea be that 
neighbor of a vertex well inside a community be “close” 
to each other, even in the absence of the vertex, due to 
the high density of intra-cluster edges. Suppose that j 
and k be neighbor of a vertex i: djk/i be the length of 
a shortest path between j and k, if i be remove from 
the graph. Naturally, the existence of alternative path 
to j − i − k implies the existence of loop in the graph. 
Vragoviĉ and Louis define the loop coefficient of i a 
the average of 1/djk/i over all pair of neighbor of i, 
somewhat remind of the concept of information cen- 
trality use in the method by Fortunato et al. (Fortunato 
et al., 2004). High value of the loop coefficient be likely 
to identify core vertex of communities, whereas low val- 
ues correspond to vertex lie at the boundary between 
communities. Clusters be built around the vertex with 
high value of the loop coefficient. The method have 
time complexity O(nm); it result be not so accurate, 
a compare to popular cluster techniques. 

VI. MODULARITY-BASED METHODS 

Newman-Girvan modularity Q (Section III.C.2), orig- 
inally introduce to define a stop criterion for the 
algorithm of Girvan and Newman, have rapidly become 
an essential element of many cluster methods. Mod- 
ularity be by far the most use and best know qual- 
ity function. It represent one of the first attempt to 
achieve a first principle understand of the cluster 
problem, and it embeds in it compact form all essential 
ingredient and questions, from the definition of commu- 
nity, to the choice of a null model, to the expression of the 
“strength” of community and partitions. In this section 
we shall focus on all cluster technique that require 

modularity, directly and/or indirectly. We will examine 
fast technique that can be use on large graphs, but 
which do not find good optimum for the measure (Blon- 
del et al., 2008; Clauset et al., 2004; Danon et al., 2006; 
Du et al., 2007; Mei et al., 2009; Newman, 2004b; Noack 
and Rotta, 2009; Pujol et al., 2006; Schuetz and Caflisch, 
2008a,b; Wakita and Tsurumi, 2007; Xiang et al., 2009); 
more accurate methods, which be computationally de- 
manding (Guimerà et al., 2004; Massen and Doye, 2005; 
Medus et al., 2005); algorithm give a good tradeoff be- 
tween high accuracy and low complexity (Duch and Are- 
nas, 2005; Lehmann and Hansen, 2007; Newman, 2006b; 
Ruan and Zhang, 2007; White and Smyth, 2005). We 
shall also point out other property of modularity, dis- 
cuss some extensions/modifications of it, a well a high- 
light it limits. 

A. Modularity optimization 

By assumption, high value of modularity indicate 
good partitions10. So, the partition correspond to it 
maximum value on a give graph should be the best, or 
at least a very good one. This be the main motivation 
for modularity maximization, by far the most popular 
class of method to detect community in graphs. An 
exhaustive optimization of Q be impossible, due to the 
huge number of way in which it be possible to partition 
a graph, even when the latter be small. Besides, the true 
maximum be out of reach, a it have be recently prove 
that modularity optimization be an NP-complete prob- 
lem (Brandes et al., 2006), so it be probably impossible 
to find the solution in a time grow polynomially with 
the size of the graph. However, there be currently sev- 
eral algorithm able to find fairly good approximation 
of the modularity maximum in a reasonable time. 

1. Greedy technique 

The first algorithm devise to maximize modularity 
be a greedy method of Newman (Newman, 2004b). It 
be an agglomerative hierarchical cluster method, where 
group of vertex be successively join to form large 
community such that modularity increase after the 
merging. One start from n clusters, each contain 
a single vertex. Edges be not initially present, they be 
add one by one during the procedure. However, the 
modularity of partition explore during the procedure 
be always calculate from the full topology of the graph, 
a we want to find the modularity maximum on the space 
of partition of the full graph. Adding a first edge to the 
set of disconnect vertex reduces the number of group 
from n to n−1, so it delivers a new partition of the graph. 

10 This be not true in general, a we shall discus in Section VI.C. 



28 

The edge be chosen such that this partition give the max- 
imum increase (minimum decrease) of modularity with 
respect to the previous configuration. All other edge 
be add base on the same principle. If the insertion 
of an edge do not change the partition, i. e. the edge 
be internal to one of the cluster previously formed, mod- 
ularity stay the same. The number of partition found 
during the procedure be n, each with a different number 
of clusters, from n to 1. The large value of modularity 
in this subset of partition be the approximation of the 
modularity maximum give by the algorithm. At each 
iteration step, one need to compute the variation ∆Q of 
modularity give by the merger of any two community 
of the run partition, so that one can choose the best 
merger. However, merge community between which 
there be no edge can never lead to an increase of Q, 
so one have to check only the pair of community which 
be connect by edges, of which there cannot be more 
than m. Since the calculation of each ∆Q can be do 
in constant time, this part of the calculation require a 
time O(m). After decide which community be to be 
merged, one need to update the matrix eij express 
the fraction of edge between cluster i and j of the run- 
ning partition (necessary to compute Q), which can be 
do in a worst-case time O(n). Since the algorithm re- 
quire n − 1 iteration (community mergers) to run to 
completion, it complexity be O((m + n)n), or O(n2) on 
a sparse graph, so it enables one to perform a cluster 
analysis on much large network than the algorithm of 
Girvan and Newman (up to an order of 100000 vertex 
with current computers). In a late paper (Clauset et al., 
2004), Clauset et al. point out that the update of the 
matrix eij in Newman’s algorithm involves a large num- 
ber of useless operations, due to the sparsity of the adja- 
cency matrix. This operation can be perform more ef- 
ficiently by use data structure for sparse matrices, like 
max-heaps, which rearrange the data in the form of bi- 
nary trees. Clauset et al. maintain the matrix of mod- 
ularity variation ∆Qij , which be also sparse, a max-heap 
contain the large element of each row of the matrix 
∆Qij a well a the label of the correspond commu- 
nities, and a simple array whose element be the sum 
of the element of each row of the old matrix eij . The 
optimization of modularity can be carry out use these 
three data structures, whose update be much quicker than 
in Newman’s technique. The complexity of the algorithm 
be O(md log n), where d be the depth of the dendrogram 
describe the successive partition found during the ex- 
ecution of the algorithm, which grows a log n for graph 
with a strong hierarchical structure. For those graphs, 
the run time of the method be then O(n log2 n), which 
allows to analyse the community structure of very large 
graphs, up to 106 vertices. The greedy optimization of 
Clauset et al. be currently one of the few algorithm that 
can be use to estimate the modularity maximum on such 
large graphs. The code can be freely download from 
http://cs.unm.edu/∼aaron/research/fastmodulari 
ty.htm. 

This greedy optimization of modularity tends to form 
quickly large community at the expense of small ones, 
which often yield poor value of the modularity maxima. 
Danon et al. suggest to normalize the modularity 
variation ∆Q produce by the merger of two communi- 
tie by the fraction of edge incident to one of the two 
communities, in order to favor small cluster (Danon 
et al., 2006). This trick lead to good modularity 
optimum a compare to the original recipe of Newman, 
especially when community be very different in size. 
Wakita and Tsurumi (Wakita and Tsurumi, 2007) have 
notice that, due to the bias towards large communities, 
the fast algorithm by Clauset et al. be inefficient, because 
it yield very unbalanced dendrograms, for which the 
relation d ∼ log n do not hold, and a a consequence 
the method often run at it worst-case complexity. To 
improve the situation they propose a modification in 
which, at each step, one seek the community merger 
deliver the large value of the product of the modu- 
larity variation ∆Q time a factor (consolidation ratio), 
that peak for community of equal size. In this way 
there be a tradeoff between the gain in modularity and 
the balance of the community to merge, with a big gain 
in the speed of the procedure, that enables the analysis 
of system with up to 107 vertices. Interestingly, this 
modification often lead to good modularity maximum 
than those found with the version of Clauset et al., at 
least on large social networks. The code can be found at 
http://www.is.titech.ac.jp/∼wakita/en/software 
/community-analysis-software/. Another trick to 
avoid the formation of large community be propose 
by Schuetz and Caflisch and consists in allow for the 
merger of more community pairs, instead of one, at each 
iteration (Schuetz and Caflisch, 2008a,b). This generates 
several “centers” around which community be formed, 
which grow simultaneously so that a condensation into a 
few large cluster be unlikely. This modify version of the 
greedy algorithm be combine with a simple refinement 
procedure in which single vertex be move to the neigh- 
boring community that yield the maximum increase of 
modularity. The method have the same complexity of 
the fast optimization by Clauset et al., but come closer 
to the modularity maximum. The software be available at 
http://www.biochem-caflisch.uzh.ch/public/5/net 
work-clusterization-algorithm.html. The accu- 
racy of the greedy optimization can be significantly 
improve if the hierarchical agglomeration be start 
from some reasonable intermediate configuration, rather 
than from the individual vertex (Du et al., 2007; 
Pujol et al., 2006). Xiang et al. suggest to start 
from a configuration obtain by merge the original 
isolated vertex into large subgraphs, accord to the 
value of a measure of topological similarity between 
subgraphs (Xiang et al., 2009). A similar approach have 
be described by Ye et al. (Ye et al., 2008): here the 
initial partition be such that no single vertex can be 
move from it cluster to another without decrease 
Q. Higher-quality modularities can be also achieve by 



29 

apply refinement strategy base on local search at 
various step of the greedy agglomeration (Noack and 
Rotta, 2009). Such refinement procedure be similar 
to the technique propose by Newman to improve 
the result of his spectral optimization of modularity 
((Newman, 2006b) and Section VI.A.4). Another good 
strategy consists in alternate greedy optimization with 
stochastic perturbation of the partition (Mei et al., 
2009). 

A different greedy approach have be introduce by 
Blondel et al. (Blondel et al., 2008), for the general case 
of weight graphs. Initially, all vertex of the graph be 
put in different communities. The first step consists of 
a sequential sweep over all vertices. Given a vertex i, 
one computes the gain in weight modularity (Eq. 35) 
come from put i in the community of it neighbor 
j and pick the community of the neighbor that yield 
the large increase of Q, a long a it be positive. At the 
end of the sweep, one obtains the first level partition. In 
the second step community be replace by superver- 
tices, and two supervertices be connect if there be at 
least an edge between vertex of the correspond com- 
munities. In this case, the weight of the edge between 
the supervertices be the sum of the weight of the edge 
between the represent community at the low level. 
The two step of the algorithm be then repeated, yield- 
ing new hierarchical level and supergraphs (Fig. 12). We 
remark that modularity be always compute from the ini- 
tial graph topology: operating on supergraphs enables 
one to consider the variation of modularity for parti- 
tions of the original graph after merge and/or split- 
ting of group of vertices. Therefore, at some iteration, 
modularity cannot increase anymore, and the algorithm 
stops. The technique be more limited by storage demand 
than by computational time. The latter grows like O(m), 
so the algorithm be extremely fast and graph with up 
to 109 edge can be analyze in a reasonable time on 
current computational resources. The software can be 
found at http://findcommunities.googlepages.com/. 
The modularity maximum found by the method be bet- 
ter than those found with the greedy technique by 
Clauset et al. (Clauset et al., 2004) and Wakita and 
Tsurumi (Wakita and Tsurumi, 2007). However, clos- 
ing community within the immediate neighborhood of 
vertex may be inaccurate and yield spurious partition 
in practical cases. So, it be not clear whether some of the 
intermediate partition could correspond to meaningful 
hierarchical level of the graph. Moreover, the result 
of the algorithm depend on the order of the sequential 
sweep over the vertices. 

We conclude by stress that, despite the improve- 
ments and refinement of the last years, the accuracy of 
greedy optimization be not that good, a compare with 
other techniques. 

2. Simulated anneal 

Simulated anneal (Kirkpatrick et al., 1983) be a 
probabilistic procedure for global optimization use in 
different field and problems. It consists in perform 
an exploration of the space of possible states, look for 
the global optimum of a function F , say it maximum. 
Transitions from one state to another occur with proba- 
bility 1 if F increase after the change, otherwise with a 
probability exp(β∆F ), where ∆F be the decrease of the 
function and β be an index of stochastic noise, a sort of 
inverse temperature, which increase after each iteration. 
The noise reduces the risk that the system get trap 
in local optima. At some stage, the system converges to a 
stable state, which can be an arbitrarily good approxima- 
tion of the maximum of F , depend on how many state 
be explore and how slowly β be varied. Simulated an- 
nealing be first employ for modularity optimization 
by Guimerà et al. (Guimerà et al., 2004). Its standard 
implementation (Guimerà and Amaral, 2005) combine 
two type of “moves”: local moves, where a single vertex 
be shift from one cluster to another, take at random; 
global moves, consist of merger and split of com- 
munities. Splits can be carry out in several distinct 
ways. The best performance be achieve if one optimizes 
the modularity of a bipartition of the cluster, take a 
an isolated graph. This be do again with simulated an- 
nealing, where one considers only individual vertex move- 
ments, and the temperature be decrease until it reach 
the run value for the global optimization. Global 
move reduce the risk of get trap in local min- 
ima and they have proven to lead to much good optimum 
than use simply local move (Massen and Doye, 2005; 
Medus et al., 2005). In practical applications, one typi- 
cally combine n2 local move with n global one in one 
iteration. The method can potentially come very close 
to the true modularity maximum, but it be slow. The 
actual complexity cannot be estimated, a it heavily de- 
pends on the parameter chosen for the optimization (ini- 
tial temperature, cool factor), not only on the graph 
size. Simulated anneal can be use for small graphs, 
with up to about 104 vertices. 

3. Extremal optimization 

Extremal optimization (EO) be a heuristic search pro- 
cedure propose by Boettcher and Percus (Boettcher and 
Percus, 2001), in order to achieve an accuracy compara- 
ble with simulated annealing, but with a substantial gain 
in computer time. It be base on the optimization of local 
variables, express the contribution of each unit of the 
system to the global function at study. This technique 
be use for modularity optimization by Duch and Are- 
na (Duch and Arenas, 2005). Modularity can be indeed 
write a a sum over the vertices: the local modularity 
of a vertex be the value of the correspond term in this 
sum. A fitness measure for each vertex be obtain by 



30 

FIG. 12 Hierarchical optimization of modularity by Blondel et al. (Blondel et al., 2008). The diagram show two iteration of 
the method, start from the graph on the left. Each iteration consists of a step, in which every vertex be assign to the (local) 
cluster that produce the large modularity increase, follow by a successive transformation of the cluster into vertex of a 
small (weighted) graph, represent the next high hierarchical level. Reprinted figure with permission from Ref. (Blondel 
et al., 2008). c©2008 by IOP Publishing and SISSA. 

divide the local modularity of the vertex by it degree, 
a in this case the measure do not depend on the degree 
of the vertex and be suitably normalized. One start from 
a random partition of the graph in two group with the 
same number of vertices. At each iteration, the vertex 
with the low fitness be shift to the other cluster. The 
move change the partition, so the local fitness of many 
vertex need to be recalculated. The process continue 
until the global modularity Q cannot be improve any 
more by the procedure. This technique reminds one of 
the Kernighan-Lin (Kernighan and Lin, 1970) algorithm 
for graph partition (Section IV.A), but here the size 
of the community be determine by the process itself, 
whereas in graph partition they be fix from the be- 
ginning. After the bipartition, each cluster be consider 
a a graph on it own and the procedure be repeated, a 
long a Q increase for the partition found. The pro- 
cedure, a described, proceeds deterministically from the 
give initial partition, a one shift systematically the 
vertex with low fitness, and be likely to get trap 
in local optima. Better result can be obtain if one 
introduces a probabilistic selection, in which vertex be 
ranked base on their fitness value and one pick the 
vertex of rank q with the probability P (q) ∼ q−τ (τ -EO, 

(Boettcher and Percus, 2001)). The algorithm find very 
good estimate of the modularity maximum, and per- 
form very well on the benchmark of Girvan and New- 
man (Girvan and Newman, 2002) (Section XV.A) . Rank- 
ing the fitness value have a cost O(n log n), which can be 
reduce to O(n) if heap data structure be used. Choos- 
ing the vertex to be shift can be do with a binary 
search, which amount to an additional factor O(log n). 
Finally, the number of step need to verify whether 
the run modularity maximum can be improve or 
not be also O(n). The total complexity of the method 
be then O(n2 log n). We conclude that EO represent a 
good tradeoff between accuracy and speed, although the 
use of recursive bisectioning may lead to poor result on 
large network with many communities. 

4. Spectral optimization 

Modularity can be optimize use the eigenvalue and 
eigenvectors of a special matrix, the modularity matrix 
B, whose element be 

Bij = Aij − 
kikj 
2m 

. (28) 



31 

Here the notation be the same use in Eq. 14. Let s be 
the vector represent any partition of the graph in two 
cluster A and B: si = +1 if vertex i belongs to A, 
si = −1 if i belongs to B. Modularity can be write a 

Q = 
1 

2m 

∑ 
ij 

( 
Aij − 

kikj 
2m 

) 
δ(Ci, Cj) 

= 
1 

4m 

∑ 
ij 

( 
Aij − 

kikj 
2m 

) 
(sisj + 1) 

= 
1 

4m 

∑ 
ij 

Bijsisj = 
1 

4m 
sTBs. (29) 

The last expression indicates standard matrix products. 
The vector s can be decompose on the basis of eigen- 
vector ui (i = 1, ..., n) of the modularity matrix B: 
s = 

∑ 
i aiui, with ai = u 

T 
i · s. By plug this ex- 

pression of s into Eq. 29 one finally get 

Q = 
1 

4m 

∑ 
i 

aiu 
T 
i B 

∑ 
j 

ajuj = 
1 

4m 

n∑ 
i=1 

(uTi · s)2βi, (30) 

where βi be the eigenvalue of B correspond to the 
eigenvector ui. Eq. 30 be analogous to Eq. 19 for the 
cut size of the graph partition problem. This sug- 
gests that one can optimize modularity on bipartitions 
via spectral bisection (Section IV.A), by replace the 
Laplacian matrix with the modularity matrix (Newman, 
2006a,b). Like the Laplacian matrix, B have always the 
trivial eigenvector (1, 1, ..., 1) with eigenvalue zero, be- 
cause the sum of the element of each row/column of 
the matrix vanishes. From Eq. 30 we see that, if B have 
no positive eigenvalues, the maximum coincides with the 
trivial partition consist of the graph a a single cluster 
(for which Q = 0), i. e. it have no community structure. 
Otherwise, one have to look for the eigenvector of B with 
large (positive) eigenvalue, u1, and group the vertex 
accord to the sign of the component of u1, just like 
in Section IV.A. Here, however, one do not need to 
specify the size of the two groups: the vertex with pos- 
itive component be all in one group, the others in the 
other group. If, for example, the component of u1 cor- 
respond to vertex i be positive, but we set si = −1, 
the modularity be low than by set si = +1. The 
value of the component of u1 be also informative, a 
they indicate the level of the participation of the ver- 
tices to their communities. In particular, component 
whose value be close to zero lie at the border between 
the two cluster and can be well consider a belonging 
to both of them. The result obtain from the spectral 
bipartition can be further improve by shift single ver- 
tices from one community to the other, such to have the 
high increase (or low decrease) of the modularity of 
the result graph partition. This refinement technique, 
similar to the Kernighan-Lin algorithm (Section IV.A), 
can be also apply to improve the result of other op- 
timization technique (e.g. greedy algorithms, extremal 
optimization, etc.). The procedure be repeat for each 

of the cluster separately, and the number of communi- 
tie increase a long a modularity does. At variance 
with graph partitioning, where one need to fix the num- 
ber of cluster and their size beforehand, here there be a 
clear-cut stop criterion, represent by the fact that 
cluster subdivision be admit only if they lead to a 
modularity increase. We stress that modularity need 
to be always compute from the full adjacency matrix 
of the original graph11. The drawback of the method 
be similar a for spectral bisection, i. e. the algorithm 
give the best result for bisections, whereas it be less ac- 
curate when the number of community be large than 
two. Recently, Sun et al. (Sun et al., 2009) have add a 
step after each bipartition of a cluster, in that single ver- 
tices can be move from one cluster to another and even 
form the seed of new clusters. We remark that the pro- 
cedure be different from the Kernighan-Lin-like refining 
steps, a here the number of cluster can change. This 
variant, which do not increase the complexity of the 
original spectral optimization, lead to good modular- 
ity maxima. Moreover, one do not need to stick to 
bisectioning, if other eigenvectors with positive eigenval- 
ues of the modularity matrix be used. Given the first p 
eigenvectors, one can construct n p-dimensional vectors, 
each correspond to a vertex, just like in spectral par- 
titioning (Section IV.D). The component of the vector 
of vertex i be proportional to the p entry of the eigen- 
vector in position i. Then one can define community 
vectors, by sum the vector of vertex in the same 
community. It be possible to show that, if the vector of 
two community form an angle large that π/2, keep 
the community separate yield large modularity than if 
they be merge (Fig. 13). In this way, in a p-dimensional 
space the modularity maximum corresponds to a parti- 
tion in at most p + 1 clusters. Community vector be 
use by Wang et al. to obtain high-modularity partition 
into a number of community small than a give max- 
imum (Wang et al., 2008). In particular, if one take the 
eigenvectors correspond to the two large eigenval- 
ues, one can obtain a split of the graph in three clusters: 
in a recent work, Richardson et al. present a fast tech- 
nique to obtain graph tripartitions with large modularity 
along these line (Richardson et al., 2009). The eigenvec- 
tor with the most negative eigenvalue can also be use 
to extract useful information, like the presence of a pos- 
sible multipartite structure of the graph, a they give the 
most relevant contribution to the modularity minimum. 

The spectral optimization of modularity be quite fast. 
The lead eigenvector of the modularity matrix can be 
compute with the power method, by repeatedly mul- 
tiplying B by an arbitrary vector (not orthogonal to 

11 Richardson et al. (Richardson et al., 2009) have actually show 
that if one instead seek the optimization of modularity for each 
cluster, take a an independent graph, the combination of spec- 
tral bisectioning and the post-processing technique may yield 
good result for the final modularity optima. 



32 

FIG. 13 Spectral optimization of modularity by New- 
man (Newman, 2006a,b). By use the first two eigenvec- 
tor of the modularity matrix, vertex can be represent a 
point on a plane. By cut the plane with a line passing 
through the origin (like the dash line in the figure) one ob- 
tains bipartitions of the graph with possibly high modularity 
values. Reprinted figure with permission from Ref. (Newman, 
2006a). c©2006 by the American Physical Society. 

u1). The number of require iteration to reach con- 
vergence be O(n). Each multiplication seem to require a 
time O(n2), a B be a complete matrix, but the peculiar 
form of B allows for a much quicker calculation, take 
time O(m + n). So, a graph bipartition require a time 
O[n(m + n)], or O(n2) on a sparse graph. To find the 
modularity optimum one need a number of subsequent 
bipartitions that equal the depth d of the result hier- 
archical tree. In the worst-case scenario, d = O(n), but in 
practical case the procedure usually stop much before 
reach the leaf of the dendrogram, so one could go 
for the average value 〈d〉 ∼ log n, for a total complexity 
of O(n2 log n). The algorithm be faster than extremal op- 
timization and it be also slightly more accurate, especially 
for large graphs. The modularity matrix and the corre- 
sponding spectral optimization can be trivially extend 
to weight graphs. 

A different spectral approach have be previously pro- 
pose by White and Smyth (White and Smyth, 2005). 
Let W indicate the weight adjancency matrix of a 

graph G. A partition of G in k cluster can be described 
through an n× k assignment matrix X, where xic = 1 if 
vertex i belongs to cluster c, otherwise xic = 0. It can 
be easily show that, up to a multiplicative constant, 
modularity can be rewrite in term of the matrix X a 

Q ∝ tr[XT (W −D)X] = −tr[XTLQX], (31) 

where W be a diagonal matrix with identical elements, 
equal to the sum of all edge weights, and the entry of 
D be Dij = kikj , where ki be the degree of vertex i. The 
matrix LQ = D −W be call the Q-Laplacian. Finding 
the assignment matrix X that maximizes Q be an NP - 
complete problem, but one can get a good approximation 
by relax the constraint that the element of X have to 
be discrete. By do so Q becomes a sort of continuous 
functional of X and one can determine the extreme of Q 
by set it first derivative (with respect to X) to zero. 
This lead to the eigenvalue problem 

LQX = XΛ. (32) 

Here Λ be a diagonal matrix. Eq. 32 turn modularity 
maximization into a spectral graph partition problem 
(Section IV.D), use the Q-Laplacian matrix. A nice 
feature of the Q-Laplacian be that, for graph which be 
not too small, it can be approximate (up to constant 

factors) by the transition matrix W̃, obtain by nor- 
malizing W such that the sum of the element of each 
row equal one. Eq. 32 be at the basis of the algorithm 
developed by White and Smyth, which search for parti- 
tions with at most K clusters, where K be a predefined 
input parameter that may be suggest by preliminary 
information on the graph cluster structure. The first 
K−1 eigenvectors of the transition matrix W̃ (excluding 
the trivial eigenvector with all equal components) can be 
compute with a variant of the Lanczos method (Demmel 
et al., 2000). Since the eigenvector component be not 
integer, the eigenvectors do not correspond directly to a 
partition of the graph in clusters. However, a usual in 
spectral graph partitioning, the component of the eigen- 
vector can be use a coordinate of the graph vertex 
in an Euclidean space and k-means cluster be apply 
to obtain the desire partition. White and Smyth pro- 
pose two method to derive the cluster after embed- 
ding the graph in space. Both method have a worst- 
case complexity O(K2n + Km), which be essentially lin- 
ear in the number of vertex of the graph if the latter 
be sparse and K � n. However, on large and sparse 
graphs, K could scale with the number of vertex n, 
so the procedure might become quite slow. In order to 
speed up calculation without lose much accuracy in 
the final estimate of the maximum modularity, Ruan 
and Zhang (Ruan and Zhang, 2007) have propose an al- 
gorithm, call Kcut, that applies recursively the method 
by White and Smyth, in a slightly modify form: after 
a first application to the full graph, in the next iteration 
the method be apply to all cluster of the first partition, 
treat a independent networks, and so on. The proce- 
dure go on a long a the modularity of the result 



33 

partition keep growing. The advantage of Kcut be that 
one can play with low value for the (maximal) number 
of cluster ` at each iteration; if partition be balanced, 
after a level of recursions, the number of cluster of the 
partition be approximately K = `a. Therefore the com- 
plexity of Kcut be O[(n+m) logK] for a final partition in 
(at most) K clusters, which be much low than the com- 
plexity of the algorithm by White and Smyth. Ruan and 
Zhang test Kcut on artificial graph generate with the 
plant `-partition model (Section XV), and on real net- 
work include Zachary’s karate club (Zachary, 1977), 
the American college football network (Girvan and New- 
man, 2002) and two collaboration network of Jazz musi- 
cians (Gleiser and Danon, 2003) and physicist (Newman, 
2001): the accuracy of Kcut be comparable to that of the 
algorithm by White and Smyth, though generally lower. 

5. Other optimization strategy 

Agarwal and Kempe have suggest to maximize mod- 
ularity within the framework of mathematical program- 
ming (Agarwal and Kempe, 2008). In fact, modularity 
optimization can be formulate both a a linear and a 
a quadratic program. In the first case, the variable be 
define on the links: xij = 0 if i and j be in the same 
cluster, otherwise xij = 1. The modularity of a partition, 
up to a multiplicative constant, can then be write a 

Q ∝ 
∑ 
ij 

Bij(1− xij), (33) 

where B be the modularity matrix define by Newman 
(see Section VI.A.4). Eq. 33 be linear in the variable 
{x}, which must obey the constraint xij ≤ xik +xkj , be- 
cause, if i and j be in the same cluster, and so be i and 
k, then j and k must be in that cluster too. Maximiz- 
ing the expression in Eq. 33 under the above constraint 
be NP -hard, if the variable have to be integer a re- 
quired. However, if one relaxes this condition by use 
real-valued {x}, the problem can be solve in polyno- 
mial time (Karloff, 1991). On the other hand, the solu- 
tion do not correspond to an actual partition, a the 
x variable be fractional. To get cluster out of the {x} 
one need a round step. The value of the x variable 
be use a sort of distance in a metric space (the trian- 
gular inequality be satisfied by construction): cluster of 
vertex “close” enough to each other (i. e. whose mutual 
x variable be close to zero) be form and remove 
until each vertex be assign to a cluster. The result 
partition be further refine with the same post-processing 
technique use by Newman for the spectral optimization 
of modularity, i. e. by a sequence of step similar to 
those of the algorithm by Kernighan and Lin (see Sec- 
tion VI.A.4). Quadratic program can be use to 
get bisection of graph with high modularity, that can 
be iterate to get a whole hierarchy of partition a in 
Newman’s spectral optimization. One start from one of 

the identity in Eq. 29 

Q = 
1 

4m 

∑ 
ij 

Bij(1 + sisj), (34) 

where si = ±1, depend on whether the vertex belongs 
to the first or the second cluster. Since the optimiza- 
tion of the expression in Eq. 34 be NP -complete, one 
must relax again the constraint on the variable s be- 
ing integer. A possibility be to transform each s into an 
n-dimensional vector s and each product in the scalar 
product between vectors. The vector be normalize so 
that their tip lie on the unit-sphere of the n-dimensional 
space. This vector problem be polynomially solvable, but 
one need a method to associate a bipartition to the set 
of n vector of the solution. Any (n − 1)-dimensional 
hyperplane center at the origin cut the space in two 
halves, separate the vector in two subsets. One can 
then choose multiple random hyperplanes and pick the 
one which delivers the partition with high modular- 
ity. As in the linear program, a post-processing tech- 
nique á la Newman (see Section VI.A.4) be use to im- 
prove the result of the procedure. The two method 
propose by Agarwal and Kempe be strongly limited by 
their high computational complexity, due mostly to the 
large storage demands, make graph with more than 
104 vertex intractable. On the other hand, the idea of 
apply mathematical program to graph cluster 
be promising. The code of the algorithm can be down- 
load from http://www-scf.usc.edu/∼gaurava/. In 
a recent work (G. Xu et al., 2007), Xu et al. have opti- 
mized modularity use mixed-integer mathematical pro- 
gramming, with both integer and continuous variables, 
obtain very good approximation of the modularity 
optimum, at the price of high computational costs. Chen 
et al. have use integer linear program to transform 
the initial graph into an optimal target graph consist- 
ing of disjoint cliques, which effectively yield a parti- 
tion (Chen et al., 2008). Berry et al. have formulate 
the problem of graph cluster a a facility location prob- 
lem (Hillier and Lieberman, 2004), consist in the min- 
imization of a cost function base on a local variation of 
modularity (Berry et al., 2007). 

Lehmann and Hansen (Lehmann and Hansen, 2007) 
optimize modularity via mean field anneal (Peterson 
and Anderson, 1987), a deterministic alternative to sim- 
ulated anneal (Kirkpatrick et al., 1983). The method 
us Gibbs probability to compute the conditional mean 
value for the variable of a vertex, which indicates it 
community membership. By make a mean field ap- 
proximation on the variable of the other vertex in the 
Gibbs probability one derives a self-consistent set of 
non-linear equations, that can be solve by iteration in 
a time O[(m+ n)n]. The method yield good modular- 
ity maximum than the spectral optimization by Newman 
(Section VI.A.4), at least on artificial graph with built- 
in community structure, similar to the benchmark graph 
by Girvan and Newman (Section XV.A). 



34 

Genetic algorithm (Holland, 1992) have also be 
use to optimize modularity. In a standard genetic algo- 
rithm one have a set of candidate solution to a problem, 
which be numerically encode a chromosomes, and an 
objective function to be optimize on the space of solu- 
tions. The objective function play the role of biological 
fitness for the chromosomes. One usually start from 
a random set of candidate solutions, which be progres- 
sively change through manipulation inspire by bio- 
logical process regard real chromosomes, like point 
mutation (random variation of some part of the chro- 
mosome) and cross over (generating new chromosome 
by merge part of exist chromosomes). Then, the fit- 
ness of the new pool of candidate be compute and the 
chromosome with the high fitness have the great 
chance to survive in the next generation. After sev- 
eral iteration only solution with large fitness survive. 
In a work by Tasgin et al. (Tasgin et al., 2007), parti- 
tions be the chromosome and modularity be the fitness 
function. With a suitable choice of the algorithm param- 
eters, like the number of chromosome and the rate of 
mutation and cross over, Tasgin et al. could obtain 
result of comparative quality a greedy modularity op- 
timization on Zachary’s karate club (Zachary, 1977), the 
college football network (Girvan and Newman, 2002) and 
the benchmark by Girvan and Newman (Section XV.A). 
Genetic algorithm be also adopt by Liu et al. (Liu 
et al., 2007). Here the maximum modularity partition be 
obtain via successive bipartitions of the graph, where 
each bipartition be determine by apply a genetic algo- 
rithm to each subgraph (starting from the original graph 
itself), which be consider isolated from the rest of the 
graph. A bipartition be accepted only if it increase the 
total modularity of the graph. 

In Section III.C.2 we have see that the modularity 
maximum be obtain for the partition that minimizes 
the difference between the cut size and the expect cut 
size of the partition (Eq. 17). In the complete weight 
graph Gw such that the weight wij of an edge be 1 − 
kikj/2m, if i and j be connect in G, and −kikj/2m if 
they be not, the difference |CutP | − ExCutP be simply 
the cut size of partition P. So, maximize modularity 
for G be equivalent to the problem of find the partition 
with minimal cut size of the weight graph Gw, i. e. 
to a graph partition problem. The problem can then 
be efficiently solve by use exist software for graph 
partition (Djidjev, 2007). 

B. Modifications of modularity 

In the most recent literature on graph cluster sev- 
eral modification and extension of modularity can be 
found. They be usually motivate by specific class of 
cluster problem and/or graph that one may want to 
analyze. 

Modularity can be easily extend to graph with 
weight edge (Newman, 2004). One need to replace 

the degree ki and kj in Eq. 14 with the strength si 
and sj of vertex i and j. We remind that the strength 
of a vertex be the sum of the weight of edge adjacent 
to the vertex (Section A.1). For a proper normalization, 
the number of edge m in Eq. 14 have to be replace by 
the sum W of the weight of all edges. The product 
sisj/2W be now the expect weight of the edge ij in 
the null model of modularity, which have to be compare 
with the actual weight Wij of that edge in the original 
graph. This can be understood if we consider the case in 
which all weight be multiple of a unit weight, so they 
can be rewrite a integers. The weight of the connec- 
tion between two node can then be replace by a many 
edge between the node a express by the number of 
weight units. For the result multigraph we can use 
the same procedure a in the case of unweighted graphs, 
which lead to the formally identical expression 

Qw = 
1 

2W 

∑ 
ij 

( 
Wij − 

sisj 
2W 

) 
δ(Ci, Cj), (35) 

which can be also write a a sum over the module 

Q = 

nc∑ 
c=1 

[Wc 
W 
− 
( 
Sc 

2W 

)2 ] 
, (36) 

where Wc be the sum of the weight of the internal edge 
of module c and Sc be the sum of the strength of the 
vertex of c. If edge weight be not mutually commen- 
surable, one can always represent them a integer with 
good approximation, provide a sufficiently small weight 
unit be adopted, so the expression for weight modu- 
larity of Eqs. 35, 36 be generally valid. In principle, 
weight can be assign to the edge of an undirected 
graph, by use any measure of similarity/correlation be- 
tween the vertex (like, e. g., the measure introduce 
in Section III.B.4). In this way, one could derive the 
correspond weight modularity and use it to detect 
communities, with a potentially good exploitation of the 
structural information of the graph a compare to stan- 
dard modularity (Feng et al., 2007; Ghosh and Lerman, 
2008). 

Modularity have also a straightforward extension to the 
case of direct graph (Arenas et al., 2007; Leicht and 
Newman, 2008). If an edge be directed, the probabil- 
ity that it will be orient in either of the two possible 
direction depends on the in- and out-degrees of the end- 
vertices. For instance, take two vertex A and B, where 
A (B) have a high (low) indegree and low (high) outde- 
gree, in the null model of modularity an edge will be 
much more likely to point from B to A than from A to 
B. Therefore, the expression of modularity for direct 
graph read 

Qd = 
1 

m 

∑ 
ij 

( 
Aij − 

kouti k 
in 
j 

m 

) 
δ(Ci, Cj), (37) 

where the factor 2 in the denominator of the second sum- 
mand have be drop because the sum of the indegrees 



35 

BA 

B'A' 

FIG. 14 Problem of the direct modularity introduce by 
Arenas et al. (Arenas et al., 2007). The two situation illus- 
trated be equivalent for modularity, a vertex A and A′, a 
well a B and B′, have identical indegrees and outdegrees. 
In this way, the optimization of direct modularity be not 
able to distinguish a situation in which there be direct flow 
(top) or not (bottom). Reprinted figure with permission from 
Ref. (Kim et al., 2009). 

(outdegrees) equal m, whereas the sum of the degree of 
the vertex of an undirected graph equal 2m; the factor 
2 in the denominator of the prefactor have be drop 
because the number of non-vanishing element of the ad- 
jacency matrix be m, not 2m a in the symmetric case 
of an undirected graph. If a graph be both direct and 
weighted, formula 35 and 37 can be combine a 

Qgen = 
1 

W 

∑ 
ij 

( 
Wij − 

souti s 
in 
j 

W 

) 
δ(Ci, Cj), (38) 

which be the most general (available) expression of mod- 
ularity (Arenas et al., 2007). Kim et al. (Kim et al., 
2009) have remark that the direct modularity of 
Eq. 37 may not properly account for the directedness 
of the edge (Fig. 14), and propose a different defi- 
nition base on diffusion on direct graphs, inspire 
by Google’s PageRank algorithm (Brin and Page, 1998). 
Rosvall and Bergstrom raise similar objection (Rosvall 
and Bergstrom, 2008). 

If vertex may belong to more clusters, it be not obvious 
how to find a proper generalization of modularity. In fact, 
there be no unique recipe. Shen et al. (Shen et al., 2009), 
for instance, suggest the simple definition 

Q = 
1 

2m 

∑ 
ij 

1 

OiOj 

( 
Aij − 

kikj 
2m 

) 
δ(Ci, Cj). (39) 

Here Oi be the number of community include vertex i. 
The contribution of each edge to modularity be then the 

smaller, the large the number of community include 
it endvertices. Nicosia et al. (Nicosia et al., 2009) have 
make some more general consideration on the problem of 
extend modularity to the case of overlap commu- 
nities. They consider the case of direct unweighted 
networks, start from the follow general expression 

Qov = 
1 

m 

nc∑ 
c=1 

∑ 
i,j 

[ 
rijcAij − sijc 

kouti k 
in 
j 

m 

] 
, (40) 

where kini and k 
out 
j be the indegree and outdegree of ver- 

tices i and j, the index c label the community and rijc, 
sijc express the contribution to the sum correspond 
to the edge ij in the network and in the null model, due 
to the multiple membership of i and j. If there be no 
overlap between the communities, rijc = sijc = δcicjc, 
where ci and cj correspond to the community of i and 
j. In this case, the edge ij contributes to the sum only 
if ci = cj , a in the original definition of modularity. For 
overlap communities, the coefficient rijc, sijc must 
depend on the membership coefficient αi,c, αj,c of ver- 
tices i and j. One can assume that rijc = F(αi,c, αj,c), 
where F be some function. The term sijc be related to 
the null model of modularity, and it must be handle 
with care. In modularity’s original null model edge be 
form by join two random stubs, so one need to 
define the membership of a random stub in the various 
communities. If we assume that there be no correlation 
a priori between the membership coefficient of any two 
vertices, we can assign to a stub originate from a vertex 
i in community c the average membership correspond 
to all edge which can be form with i. On a direct 
graph we have to distinguish between outgo and in- 
come stubs, so one have 

βouti→,c = 

∑ 
j F(αi,c, αj,c) 

n 
, (41) 

βini←,c = 

∑ 
j F(αj,c, αi,c) 

n 
, (42) 

and one can write the follow general expression for 
modularity 

Qov = 
1 

m 

nc∑ 
c=1 

∑ 
i,j 

[ 
rijcAij − 

βouti→,ck 
out 
i β 

in 
j←,ck 

in 
j 

m 

] 
. (43) 

The question now concern the choice of the function 
F(αi,c, αj,c). If the formula of Eq. 43 be to be an exten- 
sion of modularity to the case of overlap communi- 
ties, it have to satisfy some general property of classi- 
cal modularity. For instance, the modularity value of a 
cover consist of the whole network a a single cluster 
should be zero. It turn out that a large class of func- 
tions yield an expression for modularity that fulfills this 
requirement. Otherwise, the choice of F be rather arbi- 
trary and good choice can be only test a posteriori, 



36 

base on the result of the optimization. Membership co- 
efficients be also present in an extension of modularity to 
overlap community propose by Shen et al. (Shen 
et al., 2009). Here the membership coefficient of vertex 
v in community c be a sum over the edge of v belonging 
to c, where each edge have a weight proportional to the 
number of maximal clique of c contain the edge. 

Gaertler et al. have introduce quality measure base 
on modularity’s principle of the comparison between a 
variable relative to the original graph and the correspond- 
ing variable of a null model (Gaertler et al., 2007). They 
remark that modularity be just the difference between 
the coverage of a partition and the expect coverage 
of the partition in the null model. We remind that the 
coverage of a partition be the ratio between the number 
of edge within cluster and the total number of edge 
(Section III.C.2). Based on this observation, Gaertler et 
al. suggest that the comparison between the two term 
can be do with other binary operation a well. For 
instance, one could consider the ratio 

S÷cov = 

∑nc 
c=1 lc/m∑nc 

c=1(dc/2m) 
2 
, (44) 

where the notation be the same a in Eq. 15. This can 
be do a well for any variable other than coverage. 
By use performance, for instance, (Section III.C.2) one 
obtains two new quality function S−perf and S 

÷ 
perf , cor- 

respond to take the difference or the ratio between 
performance and it null model expectation value, respec- 
tively. Gaertler et al. compare the result obtain with 
the four function S−cov = Q, S 

÷ 
cov, S 

− 
perf and S 

÷ 
perf , on 

a class of benchmark graph with built-in cluster struc- 
ture (Section XV.A) and social networks. They found 
that the “absolute” variant S−cov and S 

− 
perf be good 

than the “relative” variant S÷cov and S 
÷ 
perf on the arti- 

ficial benchmarks, whereas S÷perf be good on social net- 

works12. Furthermore S−perf be good than the standard 

modularity S−cov. 
Modifications of modularity’s null model have be in- 

troduced by Massen and Doye (Massen and Doye, 2005) 
and Muff et al. (Muff et al., 2005). Massen and Doye’s 
null model be still a graph with the same expect degree 
sequence a the original, and with edge rewire at ran- 
dom among the vertices, but one imposes the additional 
constraint that there can be neither multiple edge be- 
tween a pair of vertex nor edge join a vertex with 
itself (loops or self-edges). This null model be more realis- 
tic, a multiple edge and loop be usually absent in real 
graphs. The maximization of the correspond modify 
modularity yield partition with small average cluster 
size than standard modularity. The latter tends to dis- 
favor small communities, because the actual density of 

12 The comparison be do by compute the value of significance 
index like coverage and performance on the final partitions. 

edge inside small community hardly exceed the null 
model densities, which be appreciably enhance by the 
contribution from multiple connection and loops. Muff 
et al. propose a local version of modularity, in which the 
expect number of edge within a module be not calcu- 
lated with respect to the full graph, but consider just 
a portion of it, namely the subgraph include the mod- 
ule and it neighbour modules. Their motivation be 
the fact that modularity’s null model implicitly assumes 
that each vertex could be attach to any other, whereas 
in real case a cluster be usually connect to few other 
clusters. On a direct graph, their localize modularity 
LQ read 

LQ = 

nc∑ 
c=1 

[ 
lc 
Lcn 
− d 

in 
c d 

out 
c 

L2cn 

] 
. (45) 

In Eq. 45 lc be the number of edge inside cluster c, d 
in 
c 

(doutc ) the total internal (external) degree of cluster c 
and Lcn the total number of edge in the subgraph com- 
prise cluster c and it neighbor clusters. The local- 
ized modularity be not bound by 1, but can take any 
value. Its maximization delivers more accurate partition 
than standard modularity optimization on a model net- 
work describe the social interaction between child 
in a school (school network) and on the metabolic and 
protein-protein interaction network of E. coli. 

Reichardt and Bornholdt have show that it be possible 
to reformulate the problem of community detection a 
the problem of find the ground state of a spin glass 
model (Reichardt and Bornholdt, 2006a). Each vertex i 
be label by a Potts spin variable σi, which indicates the 
cluster include the vertex. The basic principle of the 
model be that edge should connect vertex of the same 
class (i. e. same spin state), whereas vertex of different 
class (i. e. different spin states) should be disconnect 
(ideally). So, one have to energetically favor edge between 
vertex in the same class, a well a non-edges between 
vertex in different classes, and penalize edge between 
vertex of different classes, along with non-edges between 
vertex in the same class. The result Hamiltonian of 
the spin model be 

H({σ}) = − 
∑ 
i<j 

Jijδ(σi, σj) = − 
∑ 
i<j 

J(Aij−γpij)δ(σi, σj), 

(46) 
where J be a constant express the couple strength, 
Aij be the element of the adjacency matrix of the 
graph, γ > 0 a parameter express the relative con- 
tribution to the energy from exist and miss edges, 
and pij be the expect number of link connect i and 
j for a null model graph with the same total number of 
edge m of the graph considered. The system be a spin 
glass (Mezard et al., 1987), a the coupling Jij between 
spin be both ferromagnetic (on the edge of the graph, 
provide γpij < 1) and antiferromagnetic (between dis- 
connect vertices, a Aij = 0 and Jij = −Jγpij < 0). 
The multiplicative costant J be irrelevant for practical 



37 

purposes, so in the follow we set J = 1. The range of 
the spin-spin interaction be infinite, a there be a non-zero 
couple between any pair of spins. Eq. 46 bear a strong 
resemblance with the expression of modularity of Eq. 14. 
In fact, if γ = 1 and pij = kikj/2m we recover exactly 
modularity, up to a factor −1/m. In this case, find the 
spin configuration for which the Hamiltonian be minimal 
be equivalent to maximize modularity. Eq. 46 be much 
more general than modularity, though, a both the null 
model and the parameter γ can be arbitrarily chosen. In 
particular, the value of γ determines the importance of 
the null model term pij in the quality function. Eq. 46 
can be rewrite a 

H({σ}) = − 
∑ 
s 

[ 
l − γ(ls)pij 

] 
= − 

∑ 
s=1 

cs 

= 
∑ 
s<r 

[ 
lr − γ(lrs)pij 

] 
= 
∑ 
s<r 

ars. (47) 

Here, the sum run over the clusters: l and lr indi- 
cate the number of edge within cluster s and between 
cluster r and s, respectively; (ls)pij and (lrs)pij be the 
correspond null model expectation values. Eq. 47 de- 
fine the coefficient cs of cohesion and ar of adhesion. 
If a subset of a cluster s have a large coefficient of adhe- 
sion with another cluster r than with it complement in 
s, the energy can be reduce by merge the subset with 
cluster r. In the particular case in which the coefficient 
of adhesion of a subset G′ of a cluster s with it com- 
plement in the cluster exactly match the coefficient of 
adhesion of G′ with another cluster r, the partition in 
which G′ stay within s or be merge with r have the same 
energy. In this case one can say that cluster r and s be 
overlapping. In general, the partition with minimum en- 
ergy have the follow properties: 1) every subset of each 
cluster have a coefficient of adhesion with it complement 
in the cluster not small than with any other cluster; 
2) every cluster have non-negative coefficient of cohesion; 
3) the coefficient of adhesion between any two cluster be 
non-positive. 

By tune the parameter γ one can vary the number 
of cluster in the partition with minimum energy, go 
from a single cluster comprise all vertex (γ = 0), to n 
cluster with a single vertex (γ →∞). So, γ be a resolu- 
tion parameter that allows to explore the cluster struc- 
ture of a graph at different scale (see Section VI.C). The 
author use single spin heatbath simulated anneal al- 
gorithms to find the ground state of the Hamiltonian of 
Eq. 46. 

Another generalization of modularity be recently sug- 
gested by Arenas et al. (Arenas et al., 2008a). They re- 
marked that the fundamental unit to define modularity be 
the edge, but that high edge density inside cluster usu- 
ally imply the existence of long-range topological correla- 
tions between vertices, which be reveal by the presence 
of motif (Milo et al., 2002), i. e. connect undirected 
subgraphs, like cycle (Section A.1). For instance, a high 
edge density inside a cluster usually mean that there 
be also several triangle in the cluster, and compara- 

tively few between clusters, a criterion that have inspire 
on it own popular graph cluster algorithm (Palla 
et al., 2005; Radicchi et al., 2004). Modularity can then 
be simply generalize by compare the density of motif 
inside cluster with the expect density in modularity’s 
null model (motif modularity). As a particular case, the 
triangle modularity of a partition C read 

Q4(C) = 

∑ 
ijk 

Aij(C)Ajk(C)Aki(C)∑ 
ijk 

AijAjkAki 
− 

∑ 
ijk 

nij(C)njk(C)nki(C)∑ 
ijk 

nijnjknki 

(48) 
where Aij(C) = Aijδ(Ci, Cj) (Ci be the label of the clus- 
ter i belongs to), nij = kikj (ki be the degree of vertex 
i) and nij(C) = nijδ(Ci, Cj). If one chooses a motif 
path with even length, and remove the constraint that 
all vertex of the motif/path should stay inside the same 
cluster, maximize motif modularity could reveal the ex- 
istence of multipartite structure. For example, if a graph 
be bipartite, one expect to see many 2-paths start 
from one vertex class and return to it from the other 
class. Motif modularity can be trivially extend to the 
case of weight graphs. 

Several graph represent real system be built out 
of correlation data between elements. Correlation ma- 
trice be very common in the study of complex sys- 
tems: well-known example be the correlation of price 
returns, which be intensively study by economist and 
econophysicists (Mantegna and Stanley, 2000). Corre- 
lations may be positive a well a negative, so the cor- 
respond weight edge indicate both attraction and 
repulsion between pair of vertices. Usually the correla- 
tion value be filter or otherwise transform such to 
eliminate the weak correlation and anticorrelations 
and to maintain strictly positive weight for the edges, 
yield graph that can be treat with standard tech- 
niques. However, ignore negative correlation mean to 
give up useful information on the relationship between 
vertices. Finding cluster in a graph with both positive 
and negative weight be call correlation cluster prob- 
lem (Bansal et al., 2004). According to intuition, one 
expect that vertex of the same cluster be link by 
positive edges, whereas vertex of different cluster be 
link by negative edges. The best cluster structure be 
the partition that maximizes the sum of the strength 
(in absolute value) of positive edge within cluster and 
negative edge between clusters, or, equivalently, the par- 
tition that minimizes the sum of the strength (in abso- 
lute value) of positive edge between cluster and neg- 
ative edge within clusters. This can be formulate by 
mean of modularity, if one account for the contribu- 
tion of the negative edges. A natural way to proceed be 
to create two copy of the graph at study: in one copy 
only the weight of the positive edge be kept, in the 
other only the weight of the negative edge (in abso- 
lute value). By apply Eq. 35 to the same partition 
of both graphs, one derives the contribution Q+ and 



38 

Q− to the modularity of that partition for the original 
graph. Gómez et al. define the global modularity a 
a linear combination of Q+ and Q−, that account for 
the relative total strength of positive and negative edge 
weight (Gómez et al., 2009). Kaplan and Forrest (Ka- 
plan and Forrest, 2008) have propose a similar expres- 
sion, with two important differences. First, they have 
use the total strength of the graph, i. e. the sum of 
the absolute value of all weights, to normalize Q+ and 
Q−; Gómez et al. instead have use the positive and the 
negative strengths, for Q+ and Q−, respectively, which 
seem to be the more natural choice look at Eq. 35. 
Second, Kaplan and Forrest have give equal weight to 
the contribution of Q+ and Q− to their final expression 
of modularity, which be just the difference Q+ − Q−. In 
another work, Traag and Bruggeman (Traag and Brugge- 
man, 2009) have introduce negative link in the general 
spin glass formulation of modularity of Reichardt and 
Bornholdt (Reichardt and Bornholdt, 2006a). Here the 
relative importance of the contribution of positive and 
negative edge weight be a free parameter, the tune of 
which allows to detect community of various size and 
density of positive/negative edges. 

Some author have point out that the original ex- 
pression of modularity be not ideal to detect communi- 
tie in bipartite graphs, which describe several real sys- 
tems, like food web (Williams and Martinez, 2000), sci- 
entific (Newman, 2001) and artistic (Gleiser and Danon, 
2003) collaboration networks, etc.. Expressions of mod- 
ularity for bipartite graph be suggest by Guimerà 
et al. (Guimerà et al., 2007) and Barber (Barber, 2007; 
Barber et al., 2008). Guimerà et al. call the two class 
of vertex actor and teams, and indicate with ti the de- 
gree of actor i and ma the degree of team a. The null 
model graph be random graph with the same expect 
degree for the vertices, a usual. The bipartite modu- 
larity MB(P) for a partition P (of the actors) have the 
follow expression 

MB(P) = 
nc∑ 
c=1 

[ ∑ 
i6=j∈c cij∑ 

ama(ma − 1) 
− 
∑ 
i6=j∈c titj 

( 
∑ 
ama) 

2 

] 
. (49) 

Here, cij be the number of team in which actor i and 
j be together and the sum 

∑ 
ama(ma − 1) give the 

number of order pair of actor in the same team. The 
second ratio of each summand be the null model term, 
indicate the expect (normalized) number of team 
for pair of actor in cluster c. The bipartite modularity 
can also be apply to (unipartite) direct graphs: each 
vertex can be duplicate and assign to both classes, 
base on it twofold role of source and target for the 
edges. 

Another interest alternative be introduce by Bar- 
ber (Barber, 2007; Barber et al., 2008) and be a simple 
extension of Eq. 14. Let u suppose that the two vertex 
class (red and blue) be make out of p and q vertices, re- 
spectively. The degree of a red vertex i be indicate with 
ki, that of a blue vertex j with dj . The adjacency ma- 
trix A of the graph be in block off-diagonal form, a there 

be edge only between red and blue vertices. Because 
of that, Barber assumes that the null model matrix P, 
whose element Pij indicates a usual the expect num- 
ber of edge between vertex i and j in the null model, 
also have the block off-diagonal form 

P = 

[ 
Op×p P̃p×q 
P̃Tq×p Oq×q 

] 
, (50) 

where the O be square matrix with all zero element 
and P̃ij = kidj/m, a in the null model of standard mod- 
ularity (though other choice be possible). The modular- 
ity maximum can be compute through the modularity 
matrix B = A − P, a we have see in Section VI.A.4. 
However, spectral optimization of modularity give excel- 
lent result for bipartitions, while it performance wors- 
en when the number of cluster be unknown, a it be 
usually the case. Barber have propose a different opti- 
mization technique, call Bipartite Recursively Induced 
Modules (BRIM), base on the bipartite nature of the 
graph. The algorithm be base on the special expression 
of modularity for the bipartite case, for which once the 
partition of the red or the blue vertex be known, it be 
easy to get the partition of the other vertex class that 
yield the maximum modularity. Therefore, one start 
from an arbitrary partition in c cluster of, say, the blue 
vertices, and recovers the partition of the red vertices, 
which be in turn use a input to get a good partition of 
the blue vertices, and so on until modularity converges. 
BRIM do not predict the number of cluster c of the 
graph, but one can obtain good estimate for it by ex- 
ploring different value with a simple bisection approach. 
Typically, for a give c the algorithm need a few step 
to converge, each step have a complexity O(m). An 
expression of the number of convergence step in term 
of n and/or m still need to be derived. 

C. Limits of modularity 

In this Section we shall discus some feature of mod- 
ularity, which be crucial to identify the domain of it 
applicability and ultimately to ass the issue of the re- 
liability of the measure for the problem of graph cluster- 
ing. 

An important question concern the value of the max- 
imum modularity Qmax for a graph. We know that it 
must be non-negative, a there be always at least a par- 
tition with zero modularity, consist in a single clus- 
ter with all vertex (Section III.C.2). However, a large 
value for the modularity maximum do not necessarily 
mean that a graph have community structure. Random 
graph be suppose to have no community structure, 
a the link probability between vertex be either con- 
stant or a function of the vertex degrees, so there be no 
bias a priori towards special group of vertices. Still, ran- 
dom graph may have partition with large modularity 
value (Guimerà et al., 2004; Reichardt and Bornholdt, 
2006a). This be due to fluctuation in the distribution of 



39 

edge in the graph, which in many graph realization be 
not homogeneous even if the link probability be con- 
stant, like in Erdös-Rényi graphs. The fluctuation de- 
termine concentration of link in some subset of the 
graph, which then appear like communities. According 
to the definition of modularity, a graph have community 
structure with respect to a random graph with equal size 
and expect degree sequence. Therefore, the modular- 
ity maximum of a graph reveals a significant community 
structure only if it be appreciably large than the modu- 
larity maximum of random graph of the same size and 
expect degree sequence. The significance of the mod- 
ularity maximum Qmax for a graph can be estimate by 
calculate the maximum modularity for many realiza- 
tions of the null model, obtain from the original graph 
by randomly rewire it edges. One then computes the 
average 〈Q〉NM and the standard deviation σNMQ of the 
results. The statistical significance of Qmax be indicate 
by the distance of Qmax from the null model average 
〈Q〉NM in unit of the standard deviation σNMQ , i. e. by 
the z-score 

z = 
Qmax − 〈Q〉NM 

σNMQ 
. (51) 

If z � 1, Qmax indicates strong community structure. 
Cutoff value of 2 − 3 for the z-scores be customary. 
This approach have problems, though. It can generate 
both false positive and false negatives: a few graph that 
most people would consider without a significant commu- 
nity structure have a large z-score; on the other hand, 
some graph that be agree to display cluster structure 
have very low value for the z-score. Besides, the dis- 
tribution of the maximum modularity value of the null 
model, though peaked, be not Gaussian. Therefore, one 
cannot attribute to the value of the z-score the signifi- 
cance correspond to a Gaussian distribution, and one 
would need instead to compute the statistical significance 
for the right distribution. 

Reichardt and Bornholdt have study the issue of the 
modularity value for random graph in some depth (Re- 
ichardt and Bornholdt, 2006b, 2007), use their general 
spin glass formulation of the cluster problem (Sec- 
tion VI.B). They consider the general case of a ran- 
dom graph with arbitrary degree distribution P (k) and 
without degree-degree correlations. They set γ = 1, so 
that the energy of the ground state coincides with mod- 
ularity (up to a constant factor). For modularity’s null 
model graphs, the modularity maximum corresponds to 
an equipartition of the graph, i. e. the magnetization of 
the ground state of the spin glass be zero, a result con- 
firm by numerical simulation (Reichardt and Born- 
holdt, 2006b, 2007). This be because the distribution of 
the coupling have zero mean, and the mean be only cou- 
plead to magnetization (Fu and Anderson, 1986). For a 
partition of any graph with n vertex and m edge in q 
cluster with equal number of vertices, there be a simple 
linear relation between the cut size Cq of the partition 
and it modularity Qq: Cq = m[(q − 1)/q − Qq]. We 

remind that the cut size Cq be the total number of inter- 
cluster edge of the partition (Section IV.A). In this way, 
the partition with maximum modularity be also the one 
with minimum cut size, and community detection be- 
come equivalent to graph partitioning. Reichardt and 
Bornholdt derive analytically the ground state energy 
for Ising spin (q = 2), which corresponds to the fol- 
low expression of the expect maximum modularity 
Qmax2 for a bipartition (Reichardt and Bornholdt, 2007) 

Qmax2 = U0J 
〈k1/2〉 
〈k〉 

. (52) 

Here 〈kα〉 = 
∫ 
P (k)kαdk and U0 be the ground state en- 

ergy of the Sherrington-Kirkpatrick model (Sherrington 
and Kirkpatrick, 1975). The most interest feature of 
Eq. 52 be the simple scale with 〈k1/2〉/〈k〉. Numerical 
calculation show that this scale hold for both Erdös- 
Rényi and scale-free graph (Section A.3). Interestingly, 
the result be valid for partition in q clusters, where q be 
left free, not only for q = 2. The number of cluster of the 
partition with maximum modularity decrease if the av- 
erage degree 〈k〉 increases, and tends to 5 for large value 
of 〈k〉, regardless of the degree distribution and the size 
of the graph. From Eq. 52 we also see that the expect 
maximum modularity for a random graph increase when 
〈k〉 decreases, i. e. if the graph get sparser. So it be par- 
ticularly hard to detect community in sparse graph by 
use modularity optimization. As we shall see in Sec- 
tion XIV, the sparsity of a graph be generally a serious 
obstacle for graph cluster methods, no matter if one 
us modularity or not. 

A more fundamental issue, raise by Fortunato and 
Barthélemy (Fortunato and Barthélemy, 2007), concern 
the capability of modularity to detect “good” partitions. 
If a graph have a clear cluster structure, one expect that 
the maximum modularity of the graph reveals it. The 
null model of modularity assumes that any vertex i “sees” 
any other vertex j, and the expect number of edge 
between them be pij = kikj/2m. Similarly, the expect 
number of edge between two cluster A and B with total 
degree KA and KB, respectively, be PAB = KAKB/2m. 
The variation of modularity determine by the merger of 
A and B with respect to the partition in which they be 
separate cluster be ∆QAB = lAB/m−KAKB/2m2, with 
lAB number of edge connect A to B. If lAB = 1, i. e. 
there be a single edge join A to B, we expect that the 
two subgraphs will often be kept separated. Instead, if 
KAKB/2m < 1, ∆QAB > 0. Let u suppose for simplic- 
ity that KA ∼ KB = K, i. e. that the two subgraphs 
be of about the same size, measure in term of edges. 
We conclude that, if K <∼ 

√ 
2m and the two subgraphs 

A and B be connected, modularity be great if they be 
in the same cluster (Fortunato and Barthélemy, 2007). 
The reason be intuitive: if there be more edge than 
expect between A and B, there be a strong topologi- 
cal correlation between the subgraphs. If the subgraphs 
be sufficiently small (in degree), the expect number 
of edge for the null model can be small than one, so 



40 

lK 

lK 

lK 

lK 

lK 

lK 

lK 

lK 

lK 

lK 

FIG. 15 Resolution limit of modularity optimization. The 
natural community structure of the graph, represent by the 
individual clique (circles), be not recognize by optimize 
modularity, if the clique be small than a scale depend 
on the size of the graph. In this case, the maximum modu- 
larity corresponds to a partition whose cluster include two 
or more clique (like the group indicate by the dash con- 
tours). Reprinted figure with permission from Ref. (Fortunato 
and Barthélemy, 2007). c©2007 from the National Academy 
of Science of the USA. 

even the weak possible connection (a single edge) suf- 
fice to keep the subgraphs together. Interestingly, this 
result hold independently of the structure of the sub- 
graphs. In particular it remains true if the subgraphs be 
cliques, which be the subgraphs with the large possi- 
ble density of internal edges, and represent the strong 
possible communities. In Fig. 15 a graph be make out of 
nc identical cliques, with l vertex each, connect by 
single edges. It be intuitive to think that the cluster of 
the best partition be the individual cliques: instead, if 
nc be large than about l 

2, modularity would be high 
for partition in which the cluster be group of clique 
(like the clique pair indicate by the dash line in the 
figure). 

The conclusion be striking: modularity optimization 
have a resolution limit that may prevent it from detect 
cluster which be comparatively small with respect to 
the graph a a whole, even when they be well define 
community like cliques. So, if the partition with maxi- 
mum modularity include cluster with total degree of the 
order of 

√ 
m or smaller, one cannot know a priori whether 

the cluster be single community or combination of 
small weakly interconnect communities. This resolu- 
tion problem have a large impact in practical applications. 

Real graph with community structure usually contain 
community which be very diverse in size (Clauset et al., 
2004; Danon et al., 2005; Guimerà et al., 2003; Palla 
et al., 2005), so many (small) community may remain 
undetected. Besides, modularity be extremely sensitive to 
even individual connections. Many real graphs, in biol- 
ogy and in the social sciences, be reconstruct through 
experiment and surveys, so edge may occasionally be 
false positives: if two small subgraphs happen to be con- 
nected by a few false edges, modularity will put them in 
the same cluster, infer a relationship between entity 
that in reality may have nothing to do with each other. 

The resolution limit come from the very definition of 
modularity, in particular from it null model. The weak 
point of the null model be the implicit assumption that 
each vertex can interact with every other vertex, which 
implies that each part of the graph know about every- 
thing else. This be however questionable, and certainly 
wrong for large system like, e.g., the Web graph. It 
be certainly more reasonable to assume that each vertex 
have a limited horizon within the graph, and interacts just 
with a portion of it. However, nobody know yet how to 
define such local territory for the graph vertices. The 
null model of the localize modularity of Muff et al. (Sec- 
tion VI.B) be a possibility, since it limit the horizon of 
a vertex to a local neighborhood, comprise the cluster 
of the vertex and the cluster link to it by at least one 
edge (neighboring clusters). However, there be many 
other possible choices. In this respect, the null model 
of Girvan and Newman, though unrealistic, be the sim- 
plest one can think of, which partly explains it success. 
Quality function that, like modularity, be base on a 
null model such that the horizon of vertex be of the or- 
der of the size of the whole graph, be likely to be affected 
by a resolution limit (Fortunato, 2007). The problem be 
more general, though. For instance, Li et al. (Li et al., 
2008b) have introduce a quality function, call modu- 
larity density, which consists in the sum over the cluster 
of the ratio between the difference of the internal and 
external degree of the cluster and the cluster size. The 
modularity density do not require a null model, and de- 
liver good result than modularity optimization (e. g. 
it correctly recovers the natural partition of the graph in 
Fig. 15 for any number/size of the cliques). However, it 
be still affected by a resolution limit. To avoid that, Li et 
al. propose a more general definition of their measure, 
include a tunable parameter that allows to explore the 
graph at different resolutions, in the spirit of the method 
of Section XII. 

A way to go around the resolution limit problem could 
be to perform further subdivision of the cluster ob- 
tained from modularity optimization, in order to elim- 
inate possible artificial merger of communities. For 
instance, one could recursively optimize modularity for 
each single cluster, take the cluster a a separate en- 
tity (Fortunato and Barthélemy, 2007; Ruan and Zhang, 
2008). However, this be not a reliable procedure, for two 
reasons: 1) the local modularities use to find partition 



41 

within the cluster have different null models, a they de- 
pend on the cluster sizes, so they be inconsistent with 
each other; 2) one need to define a criterion to decide 
when one have to stop partition a cluster, but there be 
no obvious prescription, so any choice be necessarily base 
on arbitrary assumptions13. 

Resolution limit arise a well in the more general for- 
mulation of community detection by Reichardt and Born- 
holt (Kumpula et al., 2007b). Here the limit scale for the 
undetectable cluster be 

√ 
γm. We remind that γ weighs 

the contribution of the null model term in the quality 
function. For γ = 1 one recovers the resolution limit of 
modularity. By tune the parameter γ it be possible to 
arbitrarily vary the resolution scale of the correspond 
quality function. This in principle solves the problem of 
the resolution limit, a one could adjust the resolution of 
the method to the actual scale of the community to de- 
tect. The problem be that usually one have no information 
about the community sizes, so it be not possible to decide 
a priori the proper value(s) of γ for a specific graph. In 
the most recent literature on graph cluster quite a few 
multiresolution method have be introduced, address- 
ing this problem in several ways. We will discus them 
in some detail in Section XII. 

The resolution limit can be easily extend to the case 
of weight graphs. In a recent paper (Berry et al., 
2009), Berry et al. have consider the special case in 
which intracluster edge have weight 1, whereas inter- 
cluster edge have weight �. By repeat the same pro- 
cedure a in Ref. (Fortunato and Barthélemy, 2007), they 
conclude that cluster with internal strength (i. e. sum 
of all weight of internal edges) w may remain unde- 

tected if w < 
√ 
W�/2− �, where W be the total strength 

of the graph. So, the resolution limit decrease when 
� decreases. Berry et al. use this result to show that, 
by properly weight the edge of a give unweighted 
graph, it becomes possible to detect cluster with very 
high resolution by still use modularity optimization. 

Very recently, Good et al. (Good et al., 2009) have 
make a careful analysis of modularity and it perfor- 
mance. They discover that the modularity landscape 
be characterize by an exponential number of distinct 
states/partitions, whose modularity value be very close 
to the global maximum (Fig. 16). This problem be partic- 
ularly dramatic if a graph have a hierarchical community 
structure, like most real networks. Such enormous num- 

13 Ruan and Zhang (Ruan and Zhang, 2008) propose a stop 
criterion base on the statistical significance of the maximum 
modularity value of the subgraph. The maximum modularity 
of a subgraph be compare with the expect maximum modu- 
larity for a random graph with the same size and expect de- 
gree sequence of the subgraph. If the correspond z-score be 
sufficiently high, the subgraph be suppose to have community 
structure and one accepts the partition in small pieces. The 
procedure stop when none of the subgraphs of the run parti- 
tions have significant community structure, base on modularity. 

FIG. 16 Low-dimensional visualization of the modularity 
landscape for the metabolic network of the spirochete Tre- 
ponema pallidum. The big degeneracy of suboptimal high- 
modularity partition be reveal by the plateau (whose shape 
be detailed in the inset), which be large and very irregular. 
Modularity value in the plateau be very close to the absolute 
maximum, although they may correspond to quite different 
partitions. Reprinted figure with permission from Ref. (Good 
et al., 2009). 

ber of solution explains why many heuristic be able to 
come very close to modularity’s global maximum, but it 
also implies that the global maximum be basically impos- 
sible to find. In addition, high-modularity partition be 
not necessarily similar to each other, despite the proxim- 
ity of their modularity scores. The optimal partition from 
a topological point of view, which usually do not corre- 
spond to the modularity maximum due to the resolution 
limit, may however have a large modularity score. There- 
fore the optimal partition be basically indistinguishable 
from a huge number of high-modularity partitions, which 
be in general structurally dissimilar from it. The large 
structural inhomogeneity of the high-modularity parti- 
tions implies that one cannot rely on any of them, at 
least in principle, in the absence of additional informa- 
tion on the particular system at hand and it structure. 

VII. SPECTRAL ALGORITHMS 

In Sections IV.A and IV.D we have learn that spec- 
tral property of graph matrix be frequently use 
to find partitions. A paradigmatic example be spectral 
graph clustering, which make use of the eigenvectors of 
Laplacian matrix (Section IV.D). We have also see 
that Newman-Girvan modularity can be optimize by 
use the eigenvectors of the modularity matrix (Sec- 
tion VI.A.4). Most spectral method have be intro- 
duced and developed in computer science and generally 
focus on data clustering, although application to graph 



42 

be often possible a well. In this section we shall review 
recent spectral technique propose mostly by physicist 
explicitly for graph clustering. 

Early work have show that the eigenvectors of the 
transfer matrix T (Section A.2) can be use to extract 
useful information on community structure. The trans- 
fer matrix act a a time propagator for the process of 
random walk on a graph. Given the eigenvector cα of 
the transpose transfer matrix T†, correspond to the 
eigenvalue λα, c 

α 
i be the outgo current flow from 

vertex i, correspond to the eigenmode α. The partic- 
ipation ratio (PR) 

χα = 

[ 
n∑ 
i=1 

(cαi ) 
4 

]−1 
(53) 

indicates the effective number of vertex contribute to 
eigenvector cα. If χα receives contribution only from 
vertex of the same cluster, i. e. eigenvector cα be “lo- 
calized”, the value of χα indicates the size of that clus- 
ter (Eriksen et al., 2003; Simonsen et al., 2004). The sig- 
nificance of the cluster can be assess by compare χα 
with the correspond participation ratio for a random 
graph with the same expect degree sequence a the 
original graph. Eigenvectors of the adjacency matrix may 
be localize a well if the graph have a clear community 
structure (Slanina and Zhang, 2005). A recent compre- 
hensive analysis of spectral property of modular graph 
have be carry out by Mitrović and Tadić (Mitrović and 
Tadić, 2009). 

Donetti and Muñoz have devise an elegant method 
base on the eigenvectors of the Laplacian ma- 
trix (Donetti and Muñoz, 2004). The idea be the same 
a in spectral graph cluster (Section IV.D): since the 
value of the eigenvector component be close for vertex 
in the same community, one can use them a coordinates, 
such that vertex turn into point in a metric space. So, 
if one us M eigenvectors, one can embed the vertex in 
an M -dimensional space. Communities appear a group 
of point well separate from each other, a illustrate in 
Fig. 17. The separation be the more visible, the large the 
number of dimensions/eigenvectors M . The originality of 
the method consists in the procedure to group the point 
and to extract the partition. Donetti and Muñoz use 
hierarchical cluster (see Section IV.B), with the con- 
straint that only pair of cluster which have at least one 
interconnect edge in the original graph be merged. 
Among all partition of the result dendrogram, the 
one with large modularity be chosen. For the similar- 
ity measure between vertices, Donetti and Muñoz use 
both the Euclidean distance and the angle distance. The 
angle distance between two point be the angle between 
the vector go from the origin of the M -dimensional 
space to either point. Tests on the benchmark by Girvan 
and Newman (Section XV.A) show that the best result 
be obtain with complete-linkage clustering. The most 
computationally expensive part of the algorithm be the 
calculation of the Laplacian eigenvectors. Since a few 

−0.1 

−0.05 

0 

0.05 

0.1 

0.15 
a 

−0.1 −0.05 0 0.05 0.1 0.15 

−0.1 

−0.05 

0 

0.05 

0.1 

0.15 
b 

FIG. 17 Spectral algorithm by Donetti and Muñoz. Ver- 
tex i be represent by the value of the ith component 
of Laplacian eigenvectors. In this example, the graph have 
an ad-hoc division in four communities, indicate by the 
colours. The community be good separate in two dimen- 
sion (b) than in one (a). Reprinted figure with permission 
from Ref. (Donetti and Muñoz, 2004). c©2004 by IOP Pub- 
lishing and SISSA. 

eigenvectors suffice to get good partitions, one can de- 
termine them with the Lanczos method (Lanczos, 1950). 
The number M of eigenvectors that be need to have a 
clean separation of the cluster be not know a priori, but 
one can compute a number M0 > 1 of them and search 
for the high modularity partition among those deliv- 
ered by the method for all 1 ≤ M ≤ M0. In a related 
work, Simonsen have embed graph vertex in space by 
use a coordinate the component of the eigenvectors 
of the right stochastic matrix (Simonsen, 2005). 

Eigenvalues and eigenvectors of the Laplacian matrix 
have be use by Alves to compute the effective con- 
ductances for pair of vertex in a graph, assume that 
the latter be an electric network with edge of unit re- 
sistance (Alves, 2007). The conductance enable one to 
compute the transition probability for a random walker 
move on the graph, and from the transition proba- 
bilities one build a similarity matrix between vertex 
pairs. Hierarchical cluster be apply to join vertex 
in groups. The method can be trivially extend to the 
case of weight graphs. The algorithm by Alves be rather 
slow, a one need to compute the whole spectrum of the 
Laplacian, which require a time O(n3). Moreover, there 
be no criterion to select which partition(s) of the dendro- 
gram be (are) the best. 

Capocci et al. (Capocci et al., 2005) use eigenvec- 
tor component of the right stochastic matrix R (Sec- 
tion A.2), that be derive from the adjacency matrix by 
divide each row by the sum of it elements. The right 
stochastic matrix have similar property a the Laplacian. 
If the graph have g connect components, the large g 



43 

1 2 

3 

4 

5 

6 7 

8 

9 

10 

1112 

13 14 

15 
16 

17 

18 
0 

0 5 10 15 20 
i 

−0.4 

−0.2 

0 

0.2 

0.4 

x i 

FIG. 18 Basic principle of the spectral algorithm by Capocci 
et al. (Capocci et al., 2005). The bottom diagram show the 
value of the component of the second eigenvector of the 
right stochastic matrix for the graph drawn on the top. The 
three plateau of the eigenvector component correspond to 
the three evident community of the graph. Reprinted figure 
with permission from Ref. (Capocci et al., 2005). c©2005 by 
Elsevier. 

eigenvalue be equal to 1, with eigenvectors character- 
ized by have equal-valued component for vertex be- 
longing to the same component. In this way, by listing 
the vertex accord to the connect component they 
belong to, the component of any eigenvector of R, cor- 
respond to eigenvalue 1, display a step-wise profile, 
with plateau indicate vertex in the same connect 
component. For connect graph with cluster structure, 
one can still see plateaus, if community be only loosely 
connect to each other (Fig. 18). Here the communi- 
tie can be immediately deduct by an inspection of 
the component of any eigenvector with eigenvalue 1. In 
practical cases, plateau be not clearly visible, and one 
eigenvector be not enough. However, one expect that 
there should be a strong correlation between eigenvector 
component correspond to vertex in the same clus- 
ter. Capocci et al. derive a similarity matrix, where the 
similarity between vertex i and j be the Pearson correla- 
tion coefficient between their correspond eigenvector 

components, average over a small set of eigenvectors. 
The eigenvectors can be calculate by perform a con- 
strain optimization of a suitable cost function. The 
method can be extend to weight and direct graphs. 
It be useful to estimate vertex similarities, however it do 
not provide a well-defined partition of the graph. 

Yang and Liu (Yang and Liu, 2008) adopt a recursive 
bisectioning procedure. Communities be subgraphs such 
that the external degree of each vertex do not exceed 
the internal degree (strong community or LS-sets, see 
Section III.B.2). In the first step of the algorithm, the 
adjacency matrix of the graph be put in approximately 
block-diagonal form. This be do by compute a new 
centrality measure for the vertices, call cluster cen- 
trality. This measure be similar to Bonacich’s eigenvector 
centrality (Bonacich, 1972, 1987), which be give by the 
eigenvector of the adjacency matrix correspond to the 
large eigenvalue. The cluster centrality of a vertex 
basically measure the probability that a random walker 
start at that vertex hit a give target. Such proba- 
bility be large if the origin and the target vertex belong 
to the same cluster than if they do not. If the graph have 
well-separated communities, the value of the cluster 
centrality would be similar for vertex in the same clus- 
ter. In this way, one can rearrange the original adjacency 
matrix by listing the vertex in non-decreasing order of 
their cluster centralities, and block would be visi- 
ble. The block be then identify by iterative bisection: 
each cluster found at some step be split in two a long a 
the result part be still community in the strong 
sense, otherwise the procedure stops. The worst-case 
complexity of the method be O[Kt(n log n + m)], where 
K be the number of cluster of the final partition and t 
the (average) number of iteration require to compute 
the cluster centrality with the power method (Golub 
and Loan, 1989). Since t be fairly independent of the 
graph size, the method scale quite well on sparse graph 
[O(n log n)]. The main limit of this technique be the 
assumption that community be define in the strong 
sense, which be too restrictive. On the other hand, one 
could think of use alternative definitions. 

VIII. DYNAMIC ALGORITHMS 

This Section describes method employ process 
run on the graph, focus on spin-spin interactions, 
random walk and synchronization. 

A. Spin model 

The Potts model be among the most popular model in 
statistical mechanic (Wu, 1982). It describes a system 
of spin that can be in q different states. The interaction 
be ferromagnetic, i. e. it favour spin alignment, so at 
zero temperature all spin be in the same state. If an- 
tiferromagnetic interaction be also present, the ground 



44 

state of the system may not be the one where all spin 
be aligned, but a state where different spin value co- 
exist, in homogeneous clusters. If Potts spin variable 
be assign to the vertex of a graph with community 
structure, and the interaction be between neighbour- 
ing spins, it be likely that the structural cluster could 
be recover from like-valued spin cluster of the sys- 
tem, a there be many more interaction inside com- 
munities than outside. Based on this idea, inspire by 
an early paper by Blatt et al. (Blatt et al., 1996), Re- 
ichardt and Bornholdt propose a method to detect com- 
munities that map the graph onto a zero-temperature 
q-Potts model with nearest-neighbour interaction (Re- 
ichardt and Bornholdt, 2004). The Hamiltonian of the 
model, i. e. it energy, read 

H = −J 
∑ 
i,j 

Aijδ(σi, σj) + γ 

q∑ 
s=1 

ns(ns − 1) 
2 

, (54) 

where Aij be the element of the adjacency matrix, δ be 
Kronecker’s function, n the number of spin in state s, 
J and γ be couple parameters. The energy H be the 
sum of two compete terms: the first be the classical 
ferromagnetic Potts model energy, and favor spin align- 
ment; the second term instead peak when the spin be 
homogeneously distributed. The ratio γ/J express the 
relative importance of the two terms: by tune γ/J one 
can explore different level of modularity of the system, 
from the whole graph see a a single cluster to cluster 
consist of individual vertices. If γ/J be set to the value 
δ(G) of the average density of edge of the graph G, the 
energy of the system be small if spin align within sub- 
graph such that their internal edge density exceeds δ(G), 
whereas the external edge density be small than δ(G), 
i. e. if the subgraphs be cluster (Section III.B.1). The 
minimization of H be carry out via simulated anneal 
((Kirkpatrick et al., 1983) and Section VI.A.2), start 
from a configuration where spin be randomly assign 
to the vertex and the number of state q be very high. 
The procedure be quite fast and the result do not de- 
pend on q (provided q be sufficiently high). The method 
also allows to identify vertex share between communi- 
ties, from the comparison of partition correspond to 
global and local energy minima. The Hamiltonian H can 
be rewrite a 

H = 
∑ 
i<j 

δ(σi, σj)(γ −Aij), (55) 

which be the energy of an infinite-range Potts spin glass, 
a all pair of spin be interact (neighboring or not) 
and there may be both positive and negative couplings. 
The method can be simply extend to the analysis of 
weight graphs, by introduce spin coupling propor- 
tional to the edge weights, which amount to replace 
the adjacency matrix A with the weight matrix W in 
Eq. 54. Ispolatov et al. (Ispolatov et al., 2006) have 
adopt a similar Hamiltonian a in Eq. 54, with a tun- 
able antiferromagnetic term interpolate between the 

correspond term of Eq. 54 and the entropy term (pro- 
portional to n log ns) of the free energy, whose mini- 
mization be equivalent to find the state of the finite- 
temperature Potts model use by Blatt et al. (Blatt et al., 
1996). Eq. 55 be at the basis of the successive generaliza- 
tion of modularity with arbitrary null model propose 
by Reichardt and Bornholdt, that we have discuss in 
Section VI.B. 

In another work (S.-W. Son et al., 2006), Son et al. 
have present a cluster technique base on the Fer- 
romagnetic Random Field Ising Model (FRFIM). Given a 
weight graph with weight matrix W, the Hamiltonian 
of the FRFIM on the graph be 

H = −1 
2 

∑ 
i,j 

Wijσiσj − 
∑ 
i 

Biσi. (56) 

In Eq. 56 σi = ±1 and Bi be the spin and the ran- 
dom magnetic field of vertex i, respectively. The FRFIM 
have be study to understand the nature of the spin 
glass phase transition (Middleton and Fisher, 2002) and 
the disorder-driven roughen transition of interface in 
disorder medium (Noh and Rieger, 2001, 2002). The 
behavior of the model depends on the choice of the mag- 
netic fields. Son et al. set to zero the magnetic field 
of all vertex but two, say s and t, for which the field 
have infinite strength and opposite signs. This amount 
to fix the spin of s and t to opposite values, introduc- 
ing frustration in the system. The idea be that, if s and t 
be central vertex of different communities, they impose 
their spin state to the other community members. So, 
the state of minimum energy be a configuration in which 
the graph be polarize into a subgraph with all positive 
spin and a subgraph with all negative spins, coincide 
with the communities, if they be well defined. Finding 
the minimum of H be equivalent to solve a maximum- 
flow/minimum-cut problem, which can be do through 
well know technique of combinatorial optimization, like 
the augment path algorithm (Ahuja et al., 1993). For 
a give choice of s and t, many ground state can be 
found. The vertex that end up in the same cluster in 
all ground state represent the core of the clusters, which 
be call coteries. Possible vertex not belonging to the 
coterie indicate that the two cluster overlap. In the 
absence of information about the cluster structure of the 
graph, one need to repeat the procedure for any pair 
of vertex s and t. Picking vertex of the same cluster, 
for instance, would not give meaningful partitions. Son 
et al. distinguish relevant cluster if they be of about 
the same size. The procedure can be iteratively apply 
to each of the detect clusters, consider a a separate 
graph, until all cluster have no community structure any 
more. On sparse graphs, the algorithm have complexity 
O(n2+θ), where θ ∼ 1.2, so it be very slow and can be cur- 
rently use for graph of up to few thousand vertices. If 
one happens to know which be the important vertex 
of the clusters, e.g. by compute appropriate centrality 
value (like degree or site betweenness (Freeman, 1977)), 
the choice for s and t be constrain and the complexity 



45 

can become a low a O(nθ), which enables the analysis 
of system with million of vertices. Tests on Barabási- 
Albert graph (Section A.3) show that the latter have no 
community structure, a expected. 

B. Random walk 

Random walk (Hughes, 1995) can also be useful to 
find communities. If a graph have a strong community 
structure, a random walker spends a long time inside a 
community due to the high density of internal edge and 
consequent number of path that could be followed. Here 
we describe the most popular cluster algorithm base 
on random walks. All of them can be trivially extend 
to the case of weight graphs. 

Zhou use random walk to define a distance between 
pair of vertex (Zhou, 2003a): the distance dij between 
i and j be the average number of edge that a random 
walker have to cross to reach j start from i. Close 
vertex be likely to belong to the same community. 
Zhou defines a “global attractor” of a vertex i to be a 
closest vertex to i (i. e. any vertex lie at the small 
distance from i), whereas the “local attractor” of i be 
it closest neighbour. Two type of community be 
defined, accord to local or global attractors: a vertex 
i have to be put in the same community of it attractor 
and of all other vertex for which i be an attractor. 
Communities must be minimal subgraphs, i. e. they 
cannot include small subgraphs which be community 
accord to the chosen criterion. Applications to real 
networks, like Zachary’s karate club (Zachary, 1977) and 
the college football network compile by Girvan and 
Newman (Girvan and Newman, 2002) (Section XV.A), 
along with artificial graph like the benchmark by 
Girvan and Newman (Girvan and Newman, 2002) (Sec- 
tion XV.A), show that the method can find meaningful 
partitions. The method can be refined, in that vertex i 
be associate to it attractor j only with a probability 
proportional to exp(−βdij), β be a sort of inverse 
temperature. The computation of the distance matrix 
require solve n linear-algebra equation (as many 
a the vertices), which require a time O(n3). On 
the other hand, an exact computation of the distance 
matrix be not necessary, a the attractor of a vertex 
can be identify by consider only a localize portion 
of the graph around the vertex; therefore the method 
can be apply to large graph a well. In a successive 
paper (Zhou, 2003b), Zhou introduce a measure of 
dissimilarity between vertex base on the distance 
define above. The measure resembles the definition 
of distance base on structural equivalence of Eq. 7, 
where the element of the adjacency matrix be replace 
by the correspond distances. Graph partition be 
obtain with a divisive procedure that, start from 
the graph a a single community, performs successive 
split base on the criterion that vertex in the same 
cluster must be less dissimilar than a run threshold, 

which be decrease during the process. The hierarchy 
of partition derive by the method be representative of 
actual community structure for several real and artifi- 
cial graphs, include Zachary’s karate club (Zachary, 
1977), the college football network (Girvan and 
Newman, 2002) and the benchmark by Girvan and 
Newman (Girvan and Newman, 2002) (Section XV.A). 
The time complexity of the procedure be again O(n3). 
The code of the algorithm can be download from 
http://www.mpikg-golm.mpg.de/theory/people/zhou 
/networkcommunity.html. 

In another work (Zhou and Lipowsky, 2004), Zhou and 
Lipowsky adopt bias random walkers, where the bias 
be due to the fact that walker move preferentially towards 
vertex share a large number of neighbour with the 
start vertex. They define a proximity index, which 
indicates how close a pair of vertex be to all other ver- 
tices. Communities be detect with a procedure call 
NetWalk, which be an agglomerative hierarchical cluster- 
ing method (Section IV.B), where the similarity between 
vertex be express by their proximity. The method have 
a time complexity O(n3): however, the proximity index 
of a pair of vertex can be compute with good approx- 
imation by consider just a small portion of the graph 
around the two vertices, with a considerable gain in time. 
The performance of the method be comparable with that 
of the algorithm of Girvan and Newman (Section V.A). 

A different distance measure between vertex base on 
random walk be introduce by Latapy and Pons (Lat- 
apy and Pons, 2005). The distance be calculate from 
the probability that the random walker move from 
a vertex to another in a fix number of steps. The 
number of step have to be large enough to explore 
a significant portion of the graph, but not too long, 
a otherwise one would approach the stationary limit 
in which transition probability trivially depend on 
the vertex degrees. Vertices be then grouped into 
community through an agglomerative hierarchical 
cluster technique base on Ward’s method (Ward, 
1963). Modularity (Section III.C.2) be use to select the 
best partition of the result dendrogram. The algo- 
rithm run to completion in a time O(n2d) on a sparse 
graph, where d be the depth of the dendrogram. Since 
d be often small for real graph [O(log n)], the expect 
complexity in practical computation be O(n2 log n). 
The software of the algorithm can be found at 
http://www-rp.lip6.fr/∼latapy/PP/walktrap.html. 

Hu et al. (Hu et al., 2008) design a graph cluster 
technique base on a signal process between vertices, 
somewhat resemble diffusion. Initially a vertex s be as- 
sign one unit of signal, all the others have no signal. In 
the first step, the source vertex s sends one unit of signal 
to each of it neighbors. Next, all vertex send a many 
unit of signal they have to each of their neighbors. The 
process be continued until a give number of iteration T 
be reached. The intensity of the signal at vertex i, nor- 
malized by the total amount of signal, be the i-th entry of 
a vector us, represent the source vertex s. The proce- 



46 

dure be then repeat by choose each vertex a source. 
In this way one can associate an n-dimensional vector to 
each vertex, which correspons to a point in an Euclidean 
space. The vector u be actually the s-th column of the 
matrix (I + A)T , where I and A be the identity and 
adjacency matrix, respectively. The idea be that the vec- 
tor u describes the influence that vertex s exerts on the 
graph through signaling. Vertices of the same commu- 
nity be expect to have similar influence on the graph 
and thus to correspond to vector which be “close” in 
space. The vector be finally grouped via fuzzy k-means 
cluster (Section IV.C). The optimal number of clus- 
ters corresponds to the partition with the shortest aver- 
age distance between vector in the same community and 
the large average distance between vector of different 
communities. The signal process be similar to diffu- 
sion, but with the important difference that here there be 
no flow conservation, a the amount of signal at each ver- 
tex be not distribute among it neighbor but transfer 
entirely to each neighbor (as if the vertex sent multiple 
copy of the same signal). The complexity of the algo- 
rithm be O[T (〈k〉+ 1)n2], where 〈k〉 be the average degree 
of the graph. Like in the previous algorithm by Latapy 
and Pons (Latapy and Pons, 2005), find an optimal 
value for the number of iteration T be non-trivial. 

Delvenne et al. (Delvenne et al., 2008) have show that 
random walk enable one to introduce a general quality 
function, express the persistence of cluster in time. A 
cluster be persistent with respect to a random walk after 
t time step if the probability that the walker escape the 
cluster before t step be low. Such probability be compute 
via the cluster autocovariance matrix Rt, which, for a 
partition of the graph in c clusters, be define a 

Rt = H 
T (ΠMt − πTπ)H. (57) 

Here, H be the n× c membership matrix, whose element 
Hij equal one if vertex i be in cluster j, zero otherwise; 
M be the transition matrix of the random walk; Π the 
diagonal matrix whose element be the stationary prob- 
ability of the random walk, i. e. Πii = ki/2m, ki be 
the degree of vertex i; π be the vector whose entry be 
the diagonal element of Π. The element (Rt)ij express 
the probability for the walk to start in cluster i and end 
up in cluster j after t steps, minus the stationary proba- 
bility that two independent random walker be in i and 
j. In this way, the persistence of a cluster i be related to 
the diagonal element (Rt)ii. Delvenne et al. define the 
stability of the cluster 

r(t; H) = min 
0≤s≤t 

c∑ 
i=1 

(Rs)ii = min 
0≤s≤t 

trace[Rs]. (58) 

The aim be then, for a give time t, find the partition 
with the large value for r(t; H). For t = 0, the most 
stable partition be that in which all vertex be their own 
clusters. Interestingly, for t = 1, maximize stability 
be equivalent to maximize Newman-Girvan modular- 
ity (Section III.C.2). The cut size of the partition (Sec- 
tion IV.A) equal [r(0) − r(1)], so it be also a one-step 

measure. In the limit t → ∞, the most stable partition 
coincides with the Fiedler partition (Fiedler, 1973, 1975), 
i. e. the bipartition where vertex be put in the same 
class accord to the sign of the correspond compo- 
nent of the Fiedler eigenvector (Section IV.A). Therefore, 
the measure r(t; H) be very general, and give a unify- 
ing interpretation in the framework of the random walk 
of several measure that be define in different con- 
texts. In particular, modularity have a natural interpre- 
tation in this dynamic picture (Lambiotte et al., 2008). 
Since the size of stable cluster increase with t, time 
can be consider a a resolution parameter. Resolution 
can be fine tune by take time a a continuous vari- 
able (the extension of the formalism be straightforward); 
the linearization of the stability measure at small (con- 
tinuous) time delivers multiresolution version of mod- 
ularity (Arenas et al., 2008b; Reichardt and Bornholdt, 
2006a) (Section XII.A). 

In a method by Weinan et al. (Weinan et al., 2008), 
the best partition of a graph in k cluster be such that the 
Markov chain describe a random walk on the meta- 
graph, whose vertex be the cluster of the original 
graph, give the best approximation of the full random 
walk dynamic on the whole graph. The quality of the 
approximation be give by the distance between the left 
stochastic matrix of the two processes, which thus need 
to be minimized. The minimization be perform by use 
a variant of the k-means algorithm (Section IV.C), and 
the result be the best obtain out of l run start from 
different initial conditions, a strategy that considerably 
improves the quality of the optimum. The time com- 
plexity be O[tlk(n + m)], where t be the number of step 
require to reach convergence. The optimal number of 
cluster could in principle be determine by analyze 
how the quality of the approximation varies with k, but 
the author do not give any general recipe. The method 
be rather accurate on the benchmark by Girvan and New- 
man (Girvan and Newman, 2002) (Section XV.A) and on 
Zachary’s karate club network. The algorithm by Weinan 
et al. be asymptotically equivalent to spectral graph par- 
titioning (Section IV.D) when the Markov chain describ- 
ing the random walk present a sizeable spectral gap be- 
tween some of the large eigenvalue of the transfer ma- 
trix (Section A.2), approximately equal to one, and the 
others. 

We conclude this section by describe the Markov 
Cluster Algorithm (MCL), which be invent by Van 
Dongen (Dongen, 2000a). This method simulates a pe- 
culiar process of flow diffusion in a graph. One start 
from the transfer matrix of the graph T (Section A.2). 
The element Tij of the transfer matrix give the proba- 
bility that a random walker, sit at vertex j, move to 
i. The sum of the element of each column of T be one. 
Each iteration of the algorithm consists of two steps. In 
the first step, call expansion, the transfer matrix of the 
graph be raise to an integer power p (usually p = 2). The 
entry Mij of the result matrix give the probability 
that a random walker, start from vertex j, reach i 



47 

in p step (diffusion flow). The second step, which have no 
physical counterpart, consists in raise each single entry 
of the matrix M to some power α, where α be now real- 
valued. This operation, call inflation, enhances the 
weight between pair of vertex with large value of the 
diffusion flow, which be likely to be in the same commu- 
nity. Next, the element of each column must be divide 
by their sum, such that the sum of the element of the 
column equal one and a new transfer matrix be recov- 
ered. After some iterations, the process delivers a stable 
matrix, with some remarkable properties. Its element 
be either zero or one, so it be a sort of adjacency matrix. 
Most importantly, the graph described by the matrix be 
disconnected, and it connect component be the com- 
munities of the original graph. The method be really sim- 
ple to implement, which be the main reason of it success: 
a of now, the MCL be one of the most use cluster al- 
gorithms in bioinformatics. The code can be download 
from http://www.micans.org/mcl/. Due to the ma- 
trix multiplication of the expansion step, the algorithm 
should scale a O(n3), even if the graph be sparse, a the 
run matrix becomes quickly dense after a few step 
of the algorithm. However, while compute the matrix 
multiplication, MCL keep only a maximum number k of 
non-zero element per column, where k be usually much 
small than n. So, the actual worst-case run time of 
the algorithm be O(nk2) on a sparse graph. A problem of 
the method be the fact that the final partition be sensitive 
to the parameter α use in the inflation step. Therefore 
several different partition can be obtained, and it be not 
clear which be the most meaningful or representative. 

C. Synchronization 

Synchronization (Pikovsky et al., 2001) be an emergent 
phenomenon occur in system of interact unit 
and be ubiquitous in nature, society and technology. In 
a synchronize state, the unit of the system be in the 
same or similar state(s) at every time. Synchronization 
have also be apply to find community in graphs. If 
oscillator be place at the vertices, with initial random 
phases, and have nearest-neighbour interactions, oscilla- 
tor in the same community synchronize first, whereas 
a full synchronization require a longer time. So, if one 
follow the time evolution of the process, state with syn- 
chronized cluster of vertex can be quite stable and long- 
lived, so they can be easily recognized. This be first 
show by Arenas, Dı́az-Guilera and Pérez-Vicente (Are- 
na et al., 2006). They use Kuramoto oscillator (Ku- 
ramoto, 1984), which be couple two-dimensional vec- 
tor endow with a proper frequency of oscillations. In 
the Kuramoto model, the phase θi of oscillator i evolves 
accord to the follow dynamic 

dθi 
dt 

= ωi + 
∑ 
j 

K sin(θj − θi), (59) 

where ωi be the natural frequency of i, K the strength of 
the couple between oscillator and the sum run over 
all oscillator (mean field regime). If the interaction cou- 
pling exceeds a threshold, depend on the width of the 
distribution of natural frequencies, the dynamic lead to 
synchronization. If the dynamic run on a graph, each 
oscillator be couple only to it near neighbors. In or- 
der to reveal the effect of local synchronization, Arenas 
et al. introduce the local order parameter 

ρij(t) = 〈cos[θi(t)− θj(t)]〉, (60) 

measure the average correlation between oscillator i 
and j. The average be compute over different initial con- 
ditions. By visualize the correlation matrix ρ(t) at a 
give time t, one may distinguish group of vertex that 
synchronize together. The group can be identify by 
mean of the dynamic connectivity matrix Dt(T ), which 
be a binary matrix obtain from ρ(t) by thresholding it 
entries. The dynamic connectivity matrix embodies in- 
formation about both the synchronization dynamic and 
the underlie graph topology. From the spectrum of 
Dt(T ) it be possible to derive the number of disconnect 
component at time t. By plot the number of compo- 
nents a a function of time, plateau may appear at some 
characteristic time scales, indicate structural scale of 
the graph with robust community (Fig. 19). Partitions 
correspond to long plateau be characterize by high 
value of the modularity of Newman and Girvan (Sec- 
tion III.C.2) on graph with homogeneous degree distri- 
butions, whereas such correlation be poor in the presence 
of hub (Arenas and Dı́az-Guilera, 2007). Indeed, it have 
be proven that the stability (Eq. 58) of the dynamic 
associate to the standard Laplacian matrix, which de- 
scribe the convergence towards synchronization of the 
Kuramoto model with equal intrinsic frequencies, coin- 
cides with modularity only for graph whose vertex have 
the same degree (Lambiotte et al., 2008). The appear- 
ance of plateau at different time scale hint to a hierar- 
chical organization of the graph. After a sufficiently long 
t all oscillator be synchronize and the whole system be- 
have a a single component. Interestingly, Arenas et al. 
found that the structural scale reveal by synchroniza- 
tion correspond to group of eigenvalue of the Laplacian 
matrix of the graph, separate by gap (Fig. 19). 

Based on the same principle, Boccaletti et al. de- 
sign a community detection method base on synchro- 
nization (Boccaletti et al., 2007). The synchronization 
dynamic be a variation of Kuramoto’s model, the opin- 
ion change rate (OCR) model (Pluchino et al., 2005). 
Here the interaction couple between adjacent vertex 
be weight by a term proportional to a (negative) power 
of the betweenness of the edge connect the vertex 
(Section V.A), with exponent α. The evolution equa- 
tions of the model be solve by decrease the value of 
α during the evolution of the dynamics, start from a 
configuration in which the system be fully synchronize 
(α = 0). The graph tends to get split into cluster of 
synchronize elements, because the interaction strength 



48 

100time 

10 

100 

i 

15-2 

0.1 1 
1/λ 

i 

10 

100 
i 

15-2 

100time 

10 

100 

i 

13-4 

0.1 1 
1/λ 

i 

10 

100 

i 

13-4 

FIG. 19 Synchronization of Kuramoto oscillator on graph with two hierarchical level of communities. (Top) The number 
of different synchronize component be plot versus time for two graph with different density of edge within the clusters. 
(Bottom) The rank index of the eivenvalues of the Laplacian matrix of the same two graph of the upper panel be plot 
versus the inverse eigenvalue (the rank go from the large to the small eigenvalue). The two type of community be 
reveal by the plateaus. Reprinted figure with permission from Ref. (Arenas et al., 2006). c©2006 by the American Physical 
Society. 

across inter-cluster edge get suppress due to their high 
betweenness scores. By vary α, different partition be 
recovered, from the graph a a whole until the vertex 
a separate communities: the partition with the large 
value of modularity be take a the most relevant. The 
algorithm scale in a time O(mn), or O(n2) on sparse 
graphs, and give good result in practical examples, in- 
cluding Zachary’s karate club (Zachary, 1977) and the 
benchmark by Girvan and Newman (Girvan and New- 
man, 2002) (Section XV.A). The method can be refine 
by homogeneizing the natural frequency of the oscilla- 
tor during the evolution of the system. In this way, the 
system becomes more stable and partition with high 
modularity value can be recovered. 

In a recent paper by Li et al. (Li et al., 2008a), it be 

show that synchronize cluster in modular network 
be characterize by interfacial vertices, whose oscillation 
frequency be intermediate between those of two or more 
clusters, so that they do not belong to a specific commu- 
nity. Li et al. use this result to devise a technique able 
to detect overlap communities. 

Synchronization-based algorithm may not be reliable 
when community be very different in size; test in this 
direction be still missing. 

IX. METHODS BASED ON STATISTICAL INFERENCE 

Statistical inference (Mackay, 2003) aim at deduce 
property of data sets, start from a set of observa- 



49 

tions and model hypotheses. If the data set be a graph, 
the model, base on hypothesis on how vertex be con- 
nected to each other, have to fit the actual graph topol- 
ogy. In this section we review those cluster tech- 
niques attempt to find the best fit of a model to the 
graph, where the model assumes that vertex have some 
sort of classification, base on their connectivity pat- 
terns. We mainly focus on method adopt Bayesian 
inference (Winkler, 2003), in which the best fit be ob- 
tained through the maximization of a likelihood (gen- 
erative models), but we also discus related techniques, 
base on blockmodeling (Doreian et al., 2005), model se- 
lection (Burnham and Anderson, 2002) and information 
theory (Mackay, 2003). 

A. Generative model 

Bayesian inference us observation to estimate the 
probability that a give hypothesis be true. It con- 
sists of two ingredients: the evidence, express by 
the information D one have about the system (e.g., 
through measurements); a statistical model with param- 
eters {θ}. Bayesian inference start by write the like- 
lihood P (D|{θ}) that the observe evidence be produce 
by the model for a give set of parameter {θ}. The aim 
be to determine the choice of {θ} that maximizes the pos- 
terior distribution P ({θ}|D) of the parameter give the 
model and the evidence. By use Bayes’ theorem one 
have 

P ({θ}|D) = 1 
Z 
P (D|{θ})P ({θ}), (61) 

where P ({θ}) be the prior distribution of the model pa- 
rameters and 

Z = 

∫ 
P (D|{θ})P ({θ})dθ. (62) 

Unfortunately, compute the integral 62 be a major chal- 
lenge. Moreover, the choice of the prior distribution 
P ({θ}) be non-obvious. Generative model differ from 
each other by the choice of the model and the way they 
address these two issues. 

Bayesian inference be frequently use in the analysis 
and model of real graphs, include social (Handcock 
et al., 2007; Koskinen and Snijders, 2007; Rhodes and 
Keefe, 2007) and biological network (Berg and Lässig, 
2006; Rowicka and Kudlicki, 2004). Graph cluster can 
be consider a specific example of inference problem. 
Here, the evidence be represent by the graph structure 
(adjacency or weight matrix) and there be an additional 
ingredient, represent by the classification of the ver- 
tices in groups, which be a hidden (or missing) informa- 
tion that one wish to infer along with the parameter 
of the model which be suppose to be responsible for the 
classification. This idea be at the basis of several recent 
papers, which we discus here. In all these works, one 
essentially maximizes the likelihood P (D|{θ}) that the 

model be consistent with the observe graph structure, 
with different constraints. We specify the set of param- 
eters {θ} a the triplet ({q}, {π}, k), where {q} indicates 
the community assignment of the vertices, {π} the model 
parameters, and k the number of clusters. In the follow- 
ing we shall stick to the notation of the papers, so the 
variable above may be indicate by different symbols. 
However, to good show what each method specifically 
do we shall refer to our general notation at the end of 
the section. 

Hastings (Hastings, 2006) chooses a a model of net- 
work with community the plant partition model (Sec- 
tion XV). In it, n vertex be assign to q groups: ver- 
tices of the same group be link with a probability pin, 
while vertex of different group be link with a prob- 
ability pout. If pin > pout, the model graph have a built-in 
community structure. The vertex classification be indi- 
cat by the set of label {qi}. The probability that, 
give a graph, the classification {qi} be the right one ac- 
cord to the model is14 

p({qi}) ∝ {exp[− 
∑ 
〈ij〉 

Jδqiqj − 
∑ 
i 6=j 

J ′δqiqj/2]}−1, (63) 

where J = log{[pin(1 − pout)]/[pout(1 − pin)]}, J ′ = 
log[(1−pin)/(1−pout)] and the first sum run over near 
neighbor vertices. Maximizing p({qi}) be equivalent 
to minimize the argument of the exponential, which be 
the Hamiltonian of a Potts model with short- and long- 
range interactions. For pin > pout, J > 0 and J 

′ < 0, 
so the model be a spin glass with ferromagnetic nearest- 
neighbor interaction and antiferromagnetic long-range 
interactions, similar to the model propose by Reichardt 
and Bornholdt to generalize Newman-Girvan modular- 
ity (Reichardt and Bornholdt, 2006a) (Section VI.B). 
Hastings use belief propagation (Gallager, 1963) to 
find the ground state of the spin model. On sparse 
graphs, the complexity of the algorithm be expect to 
be O(n logα n), where α need to be estimate numeri- 
cally. In principle one need to input the parameter pin 
and pout, which be usually unknown in practical appli- 
cations. However, it turn out that they can be chosen 
rather arbitrarily, and that bad choice can be recognize 
and corrected. 

Newman and Leicht (Newman and Leicht, 2007) 
have recently propose a similar method base on a 
mixture model and the expectation-maximization tech- 
nique (Dempster et al., 1977). The method bear some 
resemblance with an a posteriori blockmodel previously 
introduce by Snijders and Nowicki (Nowicki and Sni- 
jders, 2001; Snijders and Nowicki, 1997). They start from 
a direct graph with n vertices, whose vertex fall into 
c classes. The group of vertex i be indicate by gi, πr the 

14 The actual likelihood include an additional factor express the 
a priori probability of the community sizes. Hastings assumes 
that this probability be constant. 



50 

fraction of vertex in group r, and θri the probability 
that there be a direct edge from vertex of group r to 
vertex i. By definition, the set {πi} and {θri} satisfy the 
normalization condition 

∑c 
r=1 πr = 1 and 

∑n 
i=1 θri = 1. 

Apart from normalization, the probability {θri} be as- 
sum to be independent of each other. The best classifi- 
cation of the vertex corresponds to the maximum of the 
average log-likelihood L̄ that the model, described by the 
value of the parameter {πi} and {θri} fit the adjacency 
matrix A of the graph. The expression of the average 
log-likelihood L̄ require the definition of the probability 
qir = Pr(gi = r|A, π, θ), that vertex i belongs to group r. 
By apply Bayes’ theorem the probability {qir} can 
be compute in term of the {πi} and the {θri}, a 

qir = 
πr 
∏ 
j θ 

Aij 
rj∑ 

s πs 
∏ 
j θ 

Aij 
sj 

, (64) 

while the maximization of the average log-likelihood L̄, 
under the normalization constraint of the model vari- 
ables {πi} and {θri}, yield the relation 

πr = 
1 

n 

∑ 
i 

qir, θrj = 

∑ 
iAijqir∑ 
i kiqir 

, (65) 

where ki be the outdegree of vertex i. Equations 64 and 65 
be self-consistent, and can be solve by iterate them 
to convergence, start from a suitable set of initial con- 
ditions. Convergence be fast, so the algorithm could be 
apply to fairly large graphs, with up to about 106 ver- 
tices. 

The method, design for direct graphs, can be eas- 
ily extend to the undirected case, whereas an extension 
to weight graph be not straightforwad. A nice feature 
of the method be that it do not require any preliminary 
indication on what type of structure to look for; the re- 
sulting structure be the most likely classification base on 
the connectivity pattern of the vertices. Therefore, var- 
ious type of structure can be detected, not necessarily 
communities. For instance, multipartite structure could 
be uncovered, or mixed pattern where multipartite sub- 
graph coexist with communities, etc.. In this respect, it 
be more powerful than most method of community de- 
tection, which be bound to focus only on proper commu- 
nities, i. e. subgraphs with more internal than external 
edges. In addition, since partition be define by as- 
signing probability value to the vertices, express the 
extent of their membership in a group, it be possible that 
some vertex be not clearly assign to a group, but to 
more groups, so the method be able to deal with overlap- 
ping communities. The main drawback of the algorithm 
be the fact that one need to specify the number of group 
c at the begin of the calculation, a number that be 
typically unknown for real networks. It be possible to de- 
rive this information self-consistently by maximize the 
probability that the data be reproduce by partition 
with a give number of clusters. But this procedure in- 
volves some degree of approximation, and the result be 
often not good. 

a) c) 

b) 

FIG. 20 Problem of method by Newman and Leicht. By ap- 
ply the method to the illustrate complete bipartite graph 
(colors indicate the vertex classes) the natural group structure 
c) be not recovered; instead, the most likely classification be 
a) and b). Reprinted figure with permission from Ref. (Ra- 
masco and Mungan, 2008). c©2008 by the American Physical 
Society. 

In a recent study it have be show that the method 
by Newman and Leicht enables one to rank vertex 
base on their degree of influence on other vertices, 
which allows to identify the vertex responsible for the 
group structure and it stability (Mungan and Ramasco, 
2008). A very similar technique have also be apply 
by Vázquez (Vazquez, 2008) to the problem of popula- 
tion stratification, where animal population and their 
attribute be represent a hypergraphs (Section A.1). 
Vázquez also suggest an interest criterion to decide 
the optimal number of clusters, namely pick the num- 
ber c̄ whose solution have the great similarity with so- 
lutions obtain at different value of c. The similarity 
between two partition can be estimate in various ways, 
for instance by compute the normalize mutual infor- 
mation (Section XV). In a successive paper (Vazquez, 
2008), Vázquez show that good result be obtain 
if the classification likelihood be maximize by use Vari- 
ational Bayes (Beal, 2003; Jordan et al., 1999). 

Ramasco and Mungan (Ramasco and Mungan, 2008) 
remark that the normalization condition on the prob- 
ability {θri} implies that each group r must have non- 
zero outdegree and that therefore the method fails to 
detect the intuitive group structure of (directed) bi- 
partite graph (Fig. 20). To avoid this problem, they 
propose a modification, that consists in introduce 
three set for the edge probability {θri}, relative to 
edge go from group r to vertex i (as before), from 
i to r and in both directions, respectively. Further- 
more, they use the average entropy of the classification 
Sq = −( 

∑ 
i,r qir ln qir)/n, where the qir be the analog 

of the probability in Eq. 64, to infer the optimal num- 
ber of groups, that the method of Newman and Leicht be 



51 

unable to provide. Another technique similar to that by 
Newman and Leicht have be design by Ren et al. (Ren 
et al., 2009). The model be base on the group fraction 
{πi}, define a above, and a set of probability {βr,i}, 
express the relevance of vertex i for group r; the basic 
assumption be that the probability that two vertex of 
the same group be connect by an edge be proportional 
to the product of the relevance of the two vertices. In 
this way, there be an explicit relation between group mem- 
bership and edge density, and the method can only de- 
tect community structure. The community assignment 
be recover through an expectation-maximization pro- 
cedure that closely follow that by Newman and Leicht. 

Maximum likelihood estimation have be use by 
Čopič et al. to define an axiomatization of the prob- 
lem of graph cluster and it related concept (Čopič 
et al., 2005). The start point be again the plant 
partition model (Section XV), with probability pin and 
pout. A novelty of the approach be the introduction of 
the size matrix S, whose element Sij indicates the max- 
imum strength of interaction between vertex i and j. 
For instance, in a graph with unweighted connections, 
all element of S equal 1. In this case, the probabil- 
ity that the graph conceals a community structure co- 
incides with the expression (63) by Hastings. Čopič et 
al. use this probability a a quality function to define 
ranking between graph partition (likelihood rankings). 
The author show that the likelihood ranking satisfy a 
number of general properties, which should be satisfied 
by any reasonable ranking. They also propose an algo- 
rithm to find the maximum likelihood partition, by use 
the auxiliary concept of pseudo-community structure, i. 
e. a group of the graph vertex in which it be speci- 
fied which pair of vertex stay in the same community 
and which pair instead stay in different communities. A 
pseudo-community may not be a community because the 
transitive property be not generally valid, a the focus be 
on pairwise vertex relationships: it may happen that i 
and j be classify in the same group, and that j and 
k be classify in the same group, but that i and k be 
not classify a belonging to the same group. We believe 
that the work by Čopič et al. be an important first step 
towards a more rigorous formalization of the problem of 
graph clustering. 

Zanghi et al. (Zanghi et al., 2008) have design a 
cluster technique that lie somewhat in between the 
method by Hastings and that by Newman and Leicht. 
As in Ref. (Hastings, 2006), they use the plant parti- 
tion model to represent a graph with community struc- 
ture; a in Ref. (Newman and Leicht, 2007), they max- 
imize the classification likelihood use an expectation- 
maximization algorithm (Dempster et al., 1977). The 
algorithm run for a fix number of cluster q, like that 
by Newman and Leicht; however, the optimal number 
of cluster can be determine by run the algorithm 
for a range of q-values and select the solution that 
maximizes the Integrated Classification Likelihood intro- 
duced by Biernacki et al. (Biernacki et al., 2000). The 

time complexity of the algorithm be O(n2). 

Hofman and Wiggins have propose a general Bayesian 
approach to the problem of graph cluster (Hofman 
and Wiggins, 2008). Like Hastings (Hastings, 2006), 
they model a graph with community structure a in the 
plant partition problem (Section XV), in that there 
be two probability θc and θd that there be an edge 
between vertex of the same or different clusters, re- 
spectively. The unobserved community structure be in- 
dicated by the set of label ~σ for the vertices; πr be 
again the fraction of vertex in group r. The con- 

jugate prior distribution p(~θ) and p(~π) be chosen to 
be Beta and Dirichlet distributions. The most prob- 
able number of cluster K∗ maximizes the conditional 
probability p(K|A) that there be K clusters, give the 
matrix A. Like Hastings, Hofman and Wiggins as- 
sume that the prior probability p(K) on the number 
of cluster be a smooth function, therefore maximize 
p(K|A) amount to maximize the Bayesian evidence 
p(A|K) ∝ p(K|A)/p(K), obtain by integrate the 
joint distribution p(A, ~σ|~π, ~θ,K), which be factorizable, 
over the model parameter ~θ and ~π. The integration 
can be perform exactly only for small graphs. Hofman 
and Wiggins use Variational Bayes (Beal, 2003; Jordan 
et al., 1999), in order to compute control approxima- 
tions of p(A|K). The complexity of the algorithm be es- 
timated numerically on synthetic graphs, yield O(nα), 
with α = 1.44. In fact, the main limitation come from 
high memory requirements. The method be more power- 
ful than the one by Hastings (Hastings, 2006), in that the 

edge probability ~θ be infer by the procedure itself 
and need not be specify (or guessed) at the beginning. 
It also include the expectation-maximization approach 
by Newman and Leicht (Newman and Leicht, 2007) a a 
special case, with the big advantage that the number of 
cluster need not be give a an input, but be an output of 
the method. The software of the algorithm can be found 
at http://www.columbia.edu/∼chw2/. 

We conclude with a brief summary of the main tech- 
niques described above, come back to our notation 
at the begin of the section. In the method by 
Hastings, one maximizes the likelihood P (D|{q}, {π}, k) 
over the set of all possible community assignment 
{q}, give the number of cluster k and the model 
parameter (i. e. the link probability pin and 
pout). Newman and Leicht maximize the likelihood 
P (D|{q}, {π}, k) for a give number of clusters, over the 
possible choice for the model parameter and commu- 
nity assignments, by derive the optimal choice for 
both variable with a self-consistent procedure. Hof- 
man and Wiggins maximize the likelihood PHW (k) =∑ 
{q} 
∫ 
P (D|{q}, {π}, k)P ({q}|{π})P ({π})dπ over the 

possible choice for the number of clusters. 



52 

B. Blockmodeling, model selection and information theory 

Block model be a common approach in statistic and 
social network analysis to decompose a graph in class 
of vertex with common properties. In this way, a sim- 
pler description of the graph be attained. Vertices be 
usually grouped in class of equivalence. There be two 
main definition of topological equivalence for vertices: 
structural equivalence (F.Lorrain and White, 1971) (Sec- 
tion III.B.4), in which vertex be equivalent if they have 
the same neighbors15; regular equivalence (Everett and 
Borgatti, 1994; White and Reitz, 1983), in which vertex 
of a class have similar connection pattern to vertex of 
the other class (ex. parents/children). Regular equiv- 
alence do not require that ties/edges be restrict to 
specific target vertices, so it be a more general concept 
than structural equivalence. Indeed, vertex which be 
structurally equivalent be also regularly equivalent, but 
the inverse be not true. The concept of structural equiva- 
lence can be generalize to probabilistic models, in which 
one compare class of graphs, not single graphs, charac- 
terized by a set of link probability between the ver- 
tices. In this case, vertex be organize in class such 
that the link probability of a vertex with all other 
vertex of the graph be the same for vertex in the same 
class, which be call stochastically equivalent (Fienberg 
and Wasserman, 1981; Holland et al., 1983). 

A thorough discussion of blockmodeling be beyond the 
scope of this review: we point the reader to Ref. (Doreian 
et al., 2005). Here we discus a recent work by Reichardt 
and White (Reichardt and White, 2007). Let u suppose 
to have a direct graph with n vertex and m edges. A 
classification of the graph be indicate by the set of label 
{σ}, where σi = 1, 2, ..., q be the class of vertex i. The 
correspond blockmodel, or image graph, be express 
by a q×q adjacency matrix B: Bq1q2 = 1 if edge between 
class q1 and q2 be allowed, otherwise it be zero. The 
aim be find the classification {σ} and the matrix B 
that best fit the adjacency matrix A of the graph. The 
goodness of the fit be express by the quality function 

QB({σ}) = 1 
m 

∑ 
i 6=j 

[aijAijBσiσj + bij(1−Aij)(1−Bσiσj )], 

(66) 
where aij (bij) reward the presence (absence) of edge 
between vertex if there be edge (non-edges) between 
the correspond classes, and m be the number of edge 
of the graph, a usual. Eq. 66 can be rewrite a a sum 
over the class 

QB({σ}) = 
q∑ 
r,s 

(ers − [ers])Brs, (67) 

15 More generally, if they have the same ties/edges to the same 
vertices, a in a social network there may be different type of 
ties/edges. 

by set er = (1/m) 
∑ 
i6=j(aij + bij)Aijδσirδσjs and 

[ers] = (1/m) 
∑ 
i 6=j bijδσirδσjs. If one set aij = 1 − pij 

and bij = pij , pij can be interpret a the link prob- 
ability between i and j, in some null model. Thereof, 
er becomes the number of edge run between ver- 
tices of class r and s, and [ers] the expect number 
of edge in the null model. Reichardt and White set 
pij = k 

out 
i k 

in 
j /m, which defines the same null model 

of Newman-Girvan modularity for direct graph (Sec- 
tion VI.B). In fact, if the image graph have only self- 
edges, i. e. Brs = δrs, the quality function QB({σ}) 
exactly match modularity. Other choice for the im- 
age graph be possible, however. For instance, a matrix 
Brs = 1 − δrs describes the class of a q-partite graph 
(Section A.1). From Eq. 67 we see that, for a give clas- 
sification {σ}, the image graph that yield the large 
value of the quality function QB({σ}) be that in which 
Brs = 1 when the term er − [ers] be non-negative, and 
Brs = 0 when the term er − [ers] be non-positive. So, 
the best classification be the one maximize the quality 
function 

Q∗({σ}) = 1 
2 

q∑ 
r,s 

||ers − [ers]||, (68) 

where all term of the sum be take in absolute value. 
The function Q∗({σ}) be maximize via simulated an- 
nealing. The absolute maximum Qmax be obtain by 
construction when q match the number q∗ of structural 
equivalence class of the graph. However, the absolute 
maximum Qmax do not have a meaning by itself, a 
one can achieve fairly high value of Q∗({σ}) also for 
null model instance of the original graph, i. e. if one 
randomizes the graph by keep the same expect in- 
degree and outdegree sequences. In practical applica- 
tions, the optimal number of class be determine by 
compare the ratio Q∗(q)/Qmax [Q 

∗(q) be the maximum 
of Q∗({σ}) for q classes] with the expect ratio for the 
null model. Since classification for different q-values be 
not hierarchically ordered, overlap between class may 
be detected. The method can be trivially extend to 
the case of weight graphs. 

Model selection (Burnham and Anderson, 2002) aim 
at find model which be at the same time simple and 
good at describe a system/process. A basic example of 
a model selection problem be curve fitting. There be no 
clear-cut recipe to select a model, but a bunch of heuris- 
tics, like Akaike Information Criterion (AIC) (Akaike, 
1974), Bayesian Information Criterion (BIC) (Schwarz, 
1978), Minimum Description Length (MDL) (Grünwald 
et al., 2005; Rissanen, 1978), Minimum Message Length 
(MML) (Wallace and Boulton, 1968), etc.. 

The modular structure of a graph can be consider 
a a compress description of the graph to approximate 
the whole information contain in it adjacency matrix. 
Based on this idea, Rosvall and Bergstrom (Rosvall and 
Bergstrom, 2007) envision a communication process in 
which a partition of a graph in community represent a 



53 

synthesis Y of the full structure that a signaler sends to 
a receiver, who try to infer the original graph topology 
X from it (Fig. 21). The same idea be at the basis of an 
early method by Sun et al. (Sun et al., 2007), which be 
originally design for bipartite graph evolve in time 
and will be described in Section XIII. The best partition 
corresponds to the signal Y that contains the most infor- 
mation about X. This can be quantitatively assess by 
the minimization of the conditional information H(X|Y ) 
of X give Y , 

H(X|Y ) = log 

 q∏ 
i=1 

( 
ni(ni − 1)/2 

lii 

)∏ 
i>j 

( 
ninj 
lij 

) , (69) 
where q be the number of clusters, ni the number of ver- 
tices in cluster i, lij the number of edge between cluster 
i and j. We remark that, if one imposes no constraint 
on q, H(X|Y ) be minimal in the trivial case in which 
X = Y (H(X|X) = 0). This solution be not acceptable 
because it do not correspond to a compression of infor- 
mation with respect to the original data set. One have to 
look for the ideal tradeoff between a good compression 
and a small enough information H(X|Y ). The Minimum 
Description Length (MDL) principle (Grünwald et al., 
2005; Rissanen, 1978) provide a solution to this prob- 
lem, which amount to the minimization of a function 
give by H(X|Y ) plus a function of the number n of 
vertices, m of edge and q of clusters. The optimiza- 
tion be perform by simulated annealing, so the method 
be rather slow and can be apply to graph with up to 
about 104 vertices. However, faster technique may in 
principle be used, even if they imply a loss in accuracy. 
The method appear superior than modularity optimiza- 
tion, especially when community be of different sizes. 
This come from test perform on the benchmark of 
Girvan and Newman (Girvan and Newman, 2002) (Sec- 
tion XV.A), both in it original version and in asymmet- 
ric versions, propose by the authors, where the cluster 
have different size or different average degrees. In ad- 
dition, it can detect other type of vertex classification 
than communities, a in Eq. 69 there be no constraint 
on the relative importance of the edge density within 
community with respect to the edge density between 
communities. The software of the algorithm can be found 
at http://www.tp.umu.se/∼rosvall/code.html. 

In a recent paper (Rosvall and Bergstrom, 2008), Ros- 
vall and Bergstrom pursue the same idea of describe 
a graph by use less information than that encode in 
the full adjacency matrix. The goal be to optimally com- 
press the information need to describe the process of 
information diffusion across the graph. Random walk 
be chosen a a proxy of information diffusion. A two- 
level description, in which one give unique name to im- 
portant structure of the graph and to vertex within 
the same structure, but the vertex name be recycle 
among different structures, lead to a more compact de- 
scription than by simply cod all vertex with different 
names. This be similar to the procedure usually adopt 

in geographic maps, where the structure be city and 
one usually chooses the same name for street of dif- 
ferent cities, a long a there be only one street with a 
give name in the same city. Huffman cod (Huffman, 
1952) be use to name vertices. For the random walk, the 
above-mentioned structure be communities, a it be in- 
tuitive that walker will spend a lot of time within them, 
so they play a crucial role in the process of information 
diffusion. Graph cluster turn then into the follow- 
ing cod problem: find the partition that yield the 
minimum description length of an infinite random walk. 
Such description length consists of two terms, express 
the Shannon entropy of the random walk within and be- 
tween clusters. Every time the walker step to a different 
cluster, one need to use the codeword of that cluster 
in the description, to inform the decoder of the transi- 
tion16. Clearly, if cluster be well separate from each 
other, transition of the random walker between cluster 
will be unfrequent, so it be advantageous to use the map, 
with the cluster a regions, because in the description 
of the random walk the codewords of the cluster will 
not be repeat many times, while there be a consider- 
able save in the description due to the limited length 
of the codewords use to denote the vertices. Instead, if 
there be no well-defined cluster and/or if the partition 
be not representative of the actual community structure 
of the graph, transition between the cluster of the par- 
tition will be very frequent and there will be little or 
no gain by use the two-level description of the map. 
The minimization of the description length be carry out 
by combine greedy search with simulated annealing. 
In a successive paper (Rosvall et al., 2009), the author 
adopt the fast greedy technique design by Blondel 
et al. for modularity optimization (Blondel et al., 2008), 
with some refinements. The method can be apply to 
weight graphs, both undirected and directed. In the 
latter case, the random walk process be modify by intro- 
ducing a teleportation probability τ , to guarantee ergod- 
icity, just like in Google’s PageRank algorithm (Brin and 
Page, 1998). The partition of direct graph obtain 
by the method differ from those derive by optimize 
the direct version of Newman-Girvan modularity (Sec- 
tion VI.B): this be due to the fact that modularity focus 
on pairwise relationship between vertices, so it do not 
capture flows. The code of the method be available at 
http://www.tp.umu.se/∼rosvall/code.html. 

Chakrabarti (Chakrabarti, 2004) have apply the MDL 
principle to put the adjacency matrix of a graph into 
the (approximately) block diagonal form represent the 
best tradeoff between have a limited number of blocks, 
for a good compression of the graph topology, and hav- 
ing very homogeneous blocks, for a compact description 

16 Instead, for a one-level description, in which all vertex have 
different names, it be enough to specify the codeword of the vertex 
reach at every step to completely define the process, but this 
may be costly. 



54 

estimate 

X Y Z 
Signal 

Encoder Decoder 

n 

n 

l 

Actual 
network 

Network 

l 

l 

l 

l 
n l 

FIG. 21 Basic principle of the method by Rosvall and Bergstrom (Rosvall and Bergstrom, 2007). An encoder sends to a 
decoder a compress information about the topology of the graph on the left. The information give a coarse description 
of the graph, which be use by the decoder to deduce the original graph structure. Reprinted figure with permission from 
Ref. (Rosvall and Bergstrom, 2007). c©2007 by the National Academy of Science of the USA. 

of their structure. The total encode cost T include 
the information on the total number of vertex of the 
graph, on the number of block and the number of ver- 
tices and edge in each block, along with the adjacency 
matrix of the blocks. The minimization of T be carry 
out by start from the partition in which the graph be 
a single cluster. At each step, one operates a bipartition 
of the cluster of the partition with the maximum Shan- 
non entropy per vertex. The split be carry out in order 
to remove from the original cluster those vertex carry- 
ing the high contribution to the entropy per vertex of 
the cluster. Then, start from the result partition, 
which have one more cluster than the previous one, T be 
optimize among those partition with the same number 
of clusters. The procedure continue until one reach 
a number of cluster k?, for which T cannot be further 
decreased. The method by Chakrabarti have complexity 
O[I(k?)2m], where I be the number of iteration require 
for the convergence of the optimization for a give num- 
ber of clusters, which be usually small (I ≤ 20 in the 
experiment perform by the author). Therefore the 
algorithm can be apply to fairly large graphs. 

Information theory have also be use to detect com- 
munities in graphs. Ziv et al. (Ziv et al., 2005) have de- 
sign a method in which the information contain in 
the graph topology be compress such to preserve some 
predefined information. This be the basic principle of the 
information bottleneck method (Tishby et al., 1999). To 
understand this criterion, we need to introduce an impor- 
tant measure, the mutual information I(X,Y ) (Mackay, 
2003) of two random variable X and Y . It be define a 

I(X,Y ) = 
∑ 
x 

∑ 
y 

P (x, y) log 
P (x, y) 

P (x)P (y) 
, (70) 

where P (x) indicates the probability that X = x (simi- 
larly for P (y)) and P (x, y) be the joint probability of X 
and Y , i. e. P (x, y) = P (X = x, Y = y). The measure 
I(X,Y ) tell how much we learn about X if we know 
Y , and viceversa. If X be the input variable, Z the vari- 
able specify the partition and Y the variable encode 
the information we want to keep, which be call relevant 
variable, the goal be to minimize the mutual information 
between X and Z (to achieve the large possible data 
compression), under the constraint that the information 
on Y extractable from Z be accurate. The optimal trade- 
off between the value of I(X,Z) and I(Y,Z) (i. e. com- 
pression versus accuracy) be express by the minimiza- 
tion of a functional, where the relative weight of the two 
contribution be give by a parameter play the role of a 
temperature. In the case of graph clustering, the question 
be what to choose a relevant information variable. Ziv 
et al. propose to adopt the structural information en- 
cod in the process of diffusion on the graph. They also 
introduce the concept of network modularity, which char- 
acterizes the graph a a whole, not a specific partition like 
the modularity by Newman and Girvan (Section III.C.2). 
The network modularity be define a the area under the 
information curve, which essentially represent the rela- 
tion between the extent of compression and accuracy for 
all solution found by the method and all possible num- 
bers of clusters. The software of the algorithm by Ziv et 
al. can be found at http://www.columbia.edu/∼chw2/. 

X. ALTERNATIVE METHODS 

In this section we describe some algorithm that do 
not fit in the previous categories, although some overlap 



55 

be possible. 

Raghavan et al. (Raghavan et al., 2007) have design 
a simple and fast method base on label propagation. 
Vertices be initially give unique label (e.g. their ver- 
tex labels). At each iteration, a sweep over all vertices, 
in random sequential order, be performed: each vertex 
take the label share by the majority of it neighbors. 
If there be no unique majority, one of the majority label 
be picked at random. In this way, label propagate across 
the graph: most label will disappear, others will domi- 
nate. The process reach convergence when each vertex 
have the majority label of it neighbors. Communities 
be define a group of vertex have identical label 
at convergence. By construction, each vertex have more 
neighbor in it community than in any other commu- 
nity. This resembles the strong definition of community 
we have discuss in Section III.B.2, although the latter 
be stricter, in that each vertex must have more neighbor 
in it community than in the rest of the graph. The al- 
gorithm do not deliver a unique solution. Due to the 
many tie encounter along the process it be possible 
to derive different partition start from the same ini- 
tial condition, with different random seeds. Tests on real 
graph show that all partition found be similar to each 
other, though. The most precise information that one can 
extract from the method be contain by aggregate the 
various partition obtained, which can be do in various 
ways. The author propose to label each vertex with the 
set of all label it have in different partitions. Aggregat- 
ing partition enables one to detect possible overlap 
communities. The main advantage of the method be the 
fact that it do not need any information on the num- 
ber and the size of the clusters. It do not need any 
parameter, either. The time complexity of each itera- 
tion of the algorithm be O(m), the number of iteration 
to convergence appear independent of the graph size, or 
grow very slowly with it. So the technique be really 
fast and could be use for the analysis of large systems. 
In a recent paper (Tibély and Kertész, 2008), Tibély and 
Kertész show that the method be equivalent to find 
the local energy minimum of a simple zero-temperature ki- 
netic Potts model, and that the number of such energy 
minimum be considerably large than the number of vertex 
of the graph. Aggregating partition a Raghavan et al. 
suggest lead to a fragmentation of the result partition 
in cluster that be the smaller, the large the number of 
aggregate partitions. This be potentially a serious prob- 
lem of the algorithm by Raghavan et al., especially when 
large graph be investigated. In order to eliminate unde- 
sire solutions, Barber and Clark introduce some con- 
straints in the optimization process (Barber and Clark, 
2009). This amount to add some term to the ob- 
jective function H whose maximization be equivalent to 
the original label propagation algorithm17. Interestingly, 

17 H = 1/2 
∑ 
ij Aijδij , where A be the adjacency matrix of the 

if one imposes the constraint that partition have to be 
balanced, i. e. that cluster have similar total degrees, 
the objective function becomes formally equivalent to 
Newman-Girvan modularity Q (Section III.C.2), so the 
correspond version of the label propagation algorithm 
be essentially base on a local optimization of modularity. 
Leung et al. have found that the original algorithm by 
Raghavan et al., apply on online social networks, often 
yield partition with one giant community together with 
much small one (Leung et al., 2009). In order to avoid 
this disturb feature, which be an artefact of the algo- 
rithm, Leung et al. propose to modify the method by 
introduce a score for the labels, which decrease a the 
label propagates far from the vertex to which the label 
be originally assigned. When choose the label of a 
vertex, the label of it neighbor be weight by their 
scores, therefore a single label cannot span too large por- 
tions of the graph (as it weight fade away with the dis- 
tance from the origin), and no giant community can be 
recovered. Tests of the modify algorithm on the LFR 
benchmark (Lancichinetti et al., 2008) (Section XII.A) 
give good result and encourage further investigations. 

Bagrow and Bollt design an agglomerative tech- 
nique, call L-shell method (Bagrow and Bollt, 2005). 
It be a procedure that find the community of any ver- 
tex, although the author also present a more gen- 
eral procedure to identify the full community structure 
of the graph. Communities be define locally, base 
on a simple criterion involve the number of edge in- 
side and outside a group of vertices. One start from a 
vertex-origin and keep add vertex lie on succes- 
sive shells, where a shell be define a a set of vertex at 
a fix geodesic distance from the origin. The first shell 
include the near neighbour of the origin, the second 
the next-to-nearest neighbours, and so on. At each it- 
eration, one calculates the number of edge connect 
vertex of the new layer to vertex inside and outside 
the run cluster. If the ratio of these two number 
(“emerging degree”) exceeds some predefined threshold, 
the vertex of the new shell be add to the cluster, oth- 
erwise the process stops. The idea of closing a community 
by expand a shell have be previously introduce by 
Costa (da Fontoura Costa, 2004), in which shell be cen- 
tered on hubs. However, in this procedure the number of 
cluster be preassigned and no cluster can contain more 
than one hub. Because of the local nature of the process, 
the L-shell method be very fast and can identify commu- 
nities very quickly. Unfortunately the method work well 
only when the source vertex be approximately equidistant 
from the boundary of it community. To overcome this 
problem, Bagrow and Bollt suggest to repeat the pro- 
ce start from every vertex and derive a membership 

graph and δ be Kronecker’s function. It be just the negative of 
the energy of a zero-temperature Potts model, a found by Tibély 
and Kertész (Tibély and Kertész, 2008) 



56 

matrix M : the element Mij be one if vertex j belongs 
to the community of vertex i, otherwise it be zero. The 
membership matrix can be rewrite by suitably permu- 
tat row and column base on their mutual distances. 
The distance between two row (or columns) be define a 
the number of entry whose element differ. If the graph 
have a clear community structure, the membership ma- 
trix take a block-diagonal form, where the block iden- 
tify the communities. The method enables one to de- 
tect overlap between community a well (Porter et al., 
2007). Unfortunately, the rearrangement of the matrix 
require a time O(n3), so it be quite slow. A variant 
of the algorithm by Bagrow and Bollt, in which bound- 
ary vertex be examine separately and both first and 
second near neighbor of the run community be 
simultaneously investigated, be suggest by Rodrigues 
et al. (Rodrigues et al., 2007). 

A recent methodology introduce by Papadopoulos et 
al. (Papadopoulos et al., 2009), call Bridge Bounding, 
be similar to the L-shell algorithm, but here the clus- 
ter around a vertex grows until one “hits” the boundary 
edges. Such edge can be recognize from the value of 
various measures, like betweenness (Girvan and Newman, 
2002) or the edge cluster coefficient (Radicchi et al., 
2004). The problem be that there be often no clear gap 
in the distribution of the value of such measures, so 
one be force to set a threshold to automatically iden- 
tify the boundary edge from the others, and there be no 
obvious way to do it. The best result of the algorithm 
be obtain by use a measure consist of a weight 
sum of the edge cluster coefficient over a wider neigh- 
borhood of the give edge. This version of the method 
have a time complexity O(〈k〉2m+ 〈k〉n), where 〈k〉 be the 
average degree of the graph. 

In another algorithm by Clauset, local community be 
discover through greedy maximization of a local mod- 
ularity measure (Clauset, 2005). Given a community C, 
the boundary B be the set of vertex of C with at least one 
neighbor outside C (Fig. 22). The local modularity R by 
Clauset be the ratio of the number of edge have both 
endpoint in C (but at least one in B), with the number 
of edge have at least one endpoint in B. It be a mea- 
sure of the sharpness of the community boundary. Its 
optimization consists of a local exploration of the com- 
munity start from a source vertex: at each step the 
neighbor vertex yield the large increase (smallest 
decrease) of R be added, until the community have reach 
a predefinite size nc. This greedy optimization take a 
time O(n2c〈k〉), where 〈k〉 be the average degree of the 
graph. The local modularity R have be use in a paper 
by Hui et al. (Hui et al., 2007), where method to find 
community in network of mobile device be designed. 

Another method, where community be define base 
on a local criterion, be present by Eckmann and 
Moses (Eckmann and Moses, 2002). The idea be to use 
the cluster coefficient (Watts and Strogatz, 1998) of 
a vertex a a quantity to distinguish tightly connect 
group of vertices. Many edge mean many loop inside 

C 

B 

B 

U 

U 

FIG. 22 Schematic picture of a community C use in the 
definition of local modularity by Clauset (Clauset, 2005). The 
black area indicates the subgraph of C include all vertex of 
C, whose neighbor be also in C. The boundary B entail the 
vertex of C with at least one neighbor outside the community. 
Reprinted figure with permission from Ref. (Clauset, 2005). 
c©2005 by the American Physical Society. 

a community, so the vertex of a community be likely 
to have a large cluster coefficient. The latter can be 
related to the average distance between pair of neigh- 
bours of the vertex. The possible value of the distance 
be 1 (if neighbor be connected) or 2 (if they be not), 
so the average distance lie between 1 and 2. The more 
triangle there be in the subgraph, the shorter the av- 
erage distance. Since each vertex always have distance 1 
from it neighbours, the fact that the average distance 
between it neighbour be different from 1 reminds what 
happens when one measure segment on a curve sur- 
face. Endowed with a metric, represent by the geodesic 
distance between vertices/points, and a curvature, the 
graph can be embed in a geometric space. Communi- 
tie appear a portion of the graph with a large curva- 
ture. The algorithm be apply to the graph represen- 
tation of the World Wide Web, where vertex be web 
page and edge be the hyperlink that take user from a 
page to the other. The author found that community 
correspond to web page deal with the same topic. 

Long et al. have devise an interest technique that 
be able to detect various type of vertex groups, not nec- 
essarily community (Long et al., 2007). The method 
be base on graph approximation, a it try to match 
the original graph topology onto a coarse type of graph, 
the community prototype graph, which have a clear group 
structure (block-diagonal for clusters, block-off-diagonal 
for class of multipartite graphs, etc.). The goal be to 
determine the community prototype graph that best ap- 



57 

proximates the graph at study, where the goodness of the 
approximation be express by the distance between the 
correspond matrices. In this way the original prob- 
lem of find graph subset becomes an optimization 
problem. Long et al. call this procedure Community 
Learning by Graph Approximation (CLGA). Sometimes 
the minimization of the matrix distance can be turn 
into the maximization of the trace of a matrix. Measures 
like cut size or ratio cut can be also formulate a the 
trace of matrix (see for instance Eq. 18). In fact, CLGA 
include traditional graph partition a a special case 
(Section IV.A). Long et al. design three algorithm 
for CLGA: two of them seek for division of the graph 
into overlap or non-overlapping groups, respectively; 
in the third one an additional constraint be introduce 
to produce group of comparable size. The complexity 
of these algorithm be O(tn2k), where t be the number 
of iteration until the optimization converges and k the 
number of groups. The latter have to be give a an input, 
which be a serious limit of CLGA. 

A fast algorithm by Wu and Huberman identifies com- 
munities base on the property of resistor network (Wu 
and Huberman, 2004). It be essentially a method for par- 
titioning graph in two parts, similar to spectral bisec- 
tion, although partition in an arbitrary number of com- 
munities can be obtain by iterative applications. The 
graph be transform into a resistor network where each 
edge have unit resistance. A unit potential difference be 
set between two randomly chosen vertices. The idea be 
that, if there be a clear division in two community of 
the graph, there will be a visible gap between voltage 
value for vertex at the border between the clusters. 
The voltage be calculate by solve Kirchoff’s equa- 
tions: an exact solution would be too time consuming, 
but it be possible to find a reasonably good approximation 
in a linear time for a sparse graph with a clear commu- 
nity structure, so the more time consume part of the 
algorithm be the sort of the voltage values, which take 
time O(n log n). Any possible vertex pair can be chosen 
to set the initial potential difference, so the procedure 
should be repeat for all possible vertex pairs. The au- 
thor show that this be not necessary, and that a limited 
number of sample pair be sufficient to get good results, 
so the algorithm scale a O(n log n) and be very fast. An 
interest feature of the method be that it can quickly 
find the natural community of any vertex, without de- 
termining the complete partition of the graph. For that, 
one us the vertex a source voltage and place the sink 
at an arbitrary vertex. The same feature be present in an 
old algorithm by Flake et al. (Flake et al., 2002), where 
one us max-flow instead of current flow (Section IV.A). 
An algorithm by Orponen and Schaeffer (Orponen and 
Schaeffer, 2005) be base on the same principle, but it 
do not need the specification of target source a it be 
base on diffusion in an unbounded medium. The limit 
of such method be the fact that one have to give a in- 
put the number of clusters, which be usually not know 
beforehand. 

Ohkubo and Tanaka (Ohkubo and Tanaka, 2006) 
point out that, since community be rather compact 
structures, they should have a small volume, where the 
volume of a community be define a the ratio of the 
number of vertex by the internal edge density of the 
community. Ohkubo and Tanaka assume that the sum 
Vtotal of the volume of the community of a partition be 
a reliable index of the goodness of the partition. So, the 
most relevant partition be the one minimize Vtotal. The 
optimization be carry out with simulated annealing. 

Zarei and Samani (Zarei and Samani, 2009) remark 
that there be a symmetry between community structure 
and anti-community (multipartite) structure, when one 
considers a graph and it complement, whose edge be 
the miss edge of the original graph. In fact, if a graph 
have a well identify communities, the same group of 
vertex would be strong anti-communities in the com- 
plement graph, i. e. they should have a few intra- 
cluster edge and many inter-cluster edges. Based on 
this remark, the community of a graph can be iden- 
tified by look for anticommunities in the comple- 
ment graph, which can sometimes be easier. Zarei and 
Samani devise a spectral method use matrix of the 
complement graph. The result of this technique ap- 
pear good a compare to other spectral method on 
artificial graph generate with the plant `-partition 
model (Condon and Karp, 2001), a well a on Zachary’s 
karate club (Zachary, 1977), Lusseau’s dolphins’ net- 
work (Lusseau, 2003) and a network of protein-protein 
interactions. However, the author have use very small 
graph for testing. Communities make sense on sparse 
graphs, but the complement of large sparse graph would 
not be sparse, but very dense, and their community (mul- 
tipartite) structure basically invisible. 

Gudkov and Montealegre detect community by 
mean of dynamical simplex evolution (Gudkov et al., 
2008). Graph vertex be represent a point in an 
(n − 1)-dimensional space. Each point initially sits on 
the n vertex of a simplex, and then move in space 
due to force exert by the other points. If vertex 
be neighbors, the mutual force act on their repre- 
sentative point be attractive, otherwise it be repulsive. 
If the graph have a clear community structure, the cor- 
respond spatial cluster repel each other because of 
the few connection between them (repulsion dominates 
over attraction). If community be more mixed with 
each other, cluster be not well separate and they could 
be mistakenly aggregate in large structures. To avoid 
that, Gudkov and Montealegre define cluster a group 
of point such that the distance between each pair of 
point do not exceed a give threshold, which can be 
arbitrarily tuned, to reveal structure at different resolu- 
tions (Section XII.A). The algorithm consists in solve 
first-order differential equations, describe the dynam- 
ic of mass point move in a viscous medium. The 
complexity of the procedure be O(n2). Differential equa- 
tions be also at the basis of a recent method design by 
Krawczyk and Ku lakowski (Krawczyk, 2008; Krawczyk 



58 

and Kulakowski, 2007). Here the equation describe a 
dynamic process, in which the original graph topology 
evolves to a disconnect graph, whose component be 
the cluster of the original graph. 

Despite the significant improvement in computational 
complexity, it be still problematic to apply cluster al- 
gorithms to many large network available today. There- 
fore Narasimhamurthy et al. (Narasimhamurthy et al., 
2008) propose a two-step procedure: first, the graph 
at study be decompose in small piece by a fast 
graph partition technique; then, a cluster method 
be apply to each of the small subgraphs obtain 
[Narasimhamurthy et al. use the Clique Percolation 
Method (Section XI.A)]. The initial decomposition of the 
graph be carry out through the multilevel method by 
Dhillon et al. (Dhillon et al., 2007). It be crucial to verify 
that the initial partition do not split the commu- 
nities of the graph among the various subgraphs of the 
decomposition. This can be do by comparing, on arti- 
ficial graphs, the final cluster obtain with the two-step 
method with those detect by apply the chosen clus- 
tering technique to the entire graph. 

XI. METHODS TO FIND OVERLAPPING 
COMMUNITIES 

Most of the method discuss in the previous sec- 
tions aim at detect standard partitions, i. e. partition 
in which each vertex be assign to a single community. 
However, in real graph vertex be often share between 
community (Section II), and the issue of detect over- 
lap community have become quite popular in the last 
few years. We devote this section to the main technique 
to detect overlap communities. 

A. Clique percolation 

The most popular technique be the Clique Percolation 
Method (CPM) by Palla et al. (Palla et al., 2005). It be 
base on the concept that the internal edge of a com- 
munity be likely to form clique due to their high den- 
sity. On the other hand, it be unlikely that intercom- 
munity edge form cliques: this idea be already use 
in the divisive method of Radicchi et al. (Section V.B). 
Palla et al. use the term k-clique to indicate a com- 
plete graph with k vertices18. Notice that a k-clique be 
different from the n-clique (see Section III.B.2) use in 
social science. If it be possible for a clique to move 
on a graph, in some way, it would probably get trap 
inside it original community, a it could not cross the 
bottleneck form by the intercommunity edges. Palla et 
al. introduce a number of concept to implement this 

18 In graph theory the k-clique by Palla et al. be simply call 
clique, or complete graph, with k vertex (Section A.1). 

FIG. 23 Clique Percolation Method. The example show 
community span by adjacent 4-cliques. Overlapping ver- 
tices be show by the big dots. Reprinted figure with per- 
mission from Ref. (Palla et al., 2005). c©2005 by the Nature 
Publishing Group. 

idea. Two k-cliques be adjacent if they share k − 1 ver- 
tices. The union of adjacent k-cliques be call k-clique 
chain. Two k-cliques be connect if they be part of 
a k-clique chain. Finally, a k-clique community be the 
large connect subgraph obtain by the union of a 
k-clique and of all k-cliques which be connect to it. 
Examples of k-clique community be show in Fig. 23. 
One could say that a k-clique community be identify by 
make a k-clique “roll” over adjacent k-cliques, where 
roll mean rotate a k-clique about the k−1 vertex 
it share with any adjacent k-clique. By construction, 
k-clique community can share vertices, so they can be 
overlapping. There may be vertex belonging to non- 
adjacent k-cliques, which could be reach by different 
path and end up in different clusters. Unfortunately, 
there be also vertex that cannot be reach by any k- 
clique, like, e. g. vertex with degree one (“leaves”). 
In order to find k-clique communities, one search first 
for maximal cliques. Then a clique-clique overlap ma- 
trix O be built (Everett and Borgatti, 1998), which be an 
nc × nc matrix, nc be the number of cliques; Oij be 
the number of vertex share by clique i and j. To 
find k-cliques, one need simply to keep the entry of O 
which be large than or equal to k − 1, set the others 
to zero and find the connect component of the re- 
sulting matrix. Detecting maximal clique be know to 
require a run time that grows exponentially with the 
size of the graph. However, the author found that, for 
the real network they analyzed, the procedure be quite 
fast, due to the fairly limited number of cliques, and that 
(sparse) graph with up to 105 vertex can be analyze 



59 

in a reasonably short time. The actual scalability of the 
algorithm depends on many factors, and cannot be ex- 
press in close form. An interest aspect of k-clique 
community be that they allow to make a clear distinc- 
tion between random graph and graph with community 
structure. This be a rather delicate issue: we have see in 
Section VI.C that Newman-Girvan modularity can attain 
large value on random graphs. Derényi et al. (Derényi 
et al., 2005) have study the percolation property of 
k-cliques on random graphs, when the edge probability 
p varies. They found that the threshold pc(k) for the 
emergence of a giant k-clique community, i. e. a com- 
munity occupy a macroscopic portion of the graph, be 
pc(k) = [(k−1)n]−1/(k−1), n be the number of vertex 
of the graph, a usual. For k = 2, for which the k-cliques 
reduce to edges, one recovers the know expression for 
the emergence of a giant connect component in Erdös- 
Rényi graph (Section A.3). This percolation transition 
be quite sharp: if the edge probability p < pc(k), k-clique 
community be rather small; if p > pc(k) there be a gi- 
ant component and many small communities. To ass 
the significance of the cluster found with the CPM, one 
can compare the detect cover19 with the cover found 
on a null model graph, which be random but preserve 
the expect degree sequence of the original graph. The 
modularity of Newman and Girvan be base on the same 
null model (Section III.C.2). The null model of real 
graph seem to display the same two scenario found 
for Erdös-Rényi graphs, characterize by the presence 
of very small k-clique communities, with or without a 
giant cluster. Therefore, cover with k-clique communi- 
tie of large or appreciable size can hardly be due to 
random fluctuations. Palla and coworkers (Adamcsek 
et al., 2006) have design a software package implement- 
ing the CPM, call CFinder, which be freely available 
(www.cfinder.org). 

The algorithm have be extend to the analysis of 
weighted, direct and bipartite graphs. For weight 
graphs, in principle one can follow the standard proce- 
dure of thresholding the weights, and apply the method 
on the result graphs, treat them a unweighted. 
Farkas et al. (Farkas et al., 2007) propose instead to 
threshold the weight of cliques, define a the geomet- 
ric mean of the weight of all edge of the clique. The 
value of the threshold be chosen slightly above the criti- 
cal value at which a giant k-clique community emerges, 
in order to get the richest possible variety of clusters. On 
direct graphs, Palla et al. define direct k-cliques a 
complete graph with k vertices, such that there be an 
order among the vertices, and each edge go from a 
vertex with high order to one with low order. The or- 
dering be determine from the restrict outdegree of the 
vertex, express the fraction of outgo edge point- 

19 We remind that cover be the equivalent of partition for overlap- 
ping communities. 

ing to the other vertex of the clique versus the total 
outdegree. The method have be extend to bipartite 
graph by Lehmann et al. (Lehmann et al., 2008). In this 
case one us bipartite cliques, or bicliques: a subgraph 
Ka,b be a biclique if each of a vertex of one class be 
connect with each of b vertex of the other class. Two 
clique Ka,b be adjacent if they share a clique Ka−1,b−1, 
and a Ka,b clique community be the union of all Ka,b 
clique that can be reach from each other through a 
path of adjacent Ka,b cliques. Finding all Nc bicliques 
of a graph be an NP-complete problem (Peeters, 2003), 
mostly because the number of bicliques tends to grow 
exponentially with the size of the graph. The algorithm 
design by Lehmann et al. to find biclique community 
be similar to the original CPM, and have a total complex- 
ity of O(N2c ). On sparse graphs, Nc often grows linearly 
with the number of edge m, yield a time complexity 
O(m2). Bicliques be also the main ingredient of BiTec- 
tor, a recent algorithm to detect community structure in 
bipartite graph (Du et al., 2008). 

Kumpula et al. have developed a fast implementa- 
tion of the CPM, call Sequential Clique Percolation 
algorithm (SCP) (Kumpula et al., 2008). It consists in 
detect k-clique community by sequentially insert 
the edge of the graph at study, one by one, start 
from an initial empty graph. Whenever a new edge be 
added, one check whether new k-cliques be formed, by 
search for (k− 2)-cliques in the subset of neighbor 
vertex of the endpoint of the insert edge. The pro- 
cedure require to build a graph Γ∗, in which the vertex 
be (k−1)-cliques and edge be set between vertex cor- 
respond to (k− 1)-cliques which be subgraphs of the 
same k-clique. At the end of the process, the connect 
component of Γ∗ correspond to the search k-clique 
communities. The technique have a time complexity which 
be linear in the number of k-cliques of the graph, so it can 
vary a lot in practical applications. Nevertheless, it turn 
out to be much faster than the original implementation 
of the CPM. The big advantage of the SCP, however, 
consists of it implementation for weight graphs. By 
insert edge in decrease order of weight, one recov- 
er in a single run the community structure of the graph 
for all possible weight thresholds, by store every cover 
detect after the addition of each edge. The standard 
CPM, instead, need to be apply once for each thresh- 
old. If, instead of edge weight thresholding, one performs 
k-clique weight thresholding, a prescribed by Farkas et 
al. (Farkas et al., 2007), the SCP remains much faster 
than the CPM, if one applies a simple modification to 
it, consist in detect and store all k-cliques on the 
full graph, sort them base on their weights, and find- 
ing the community by sequentially add the k-cliques 
in decrease order of weight. 

The CPM have the same limit a the algorithm of Radic- 
chi et al. (Radicchi et al., 2004) (Section V.B): it assumes 
that the graph have a large number of cliques, so it may 
fail to give meaningful cover for graph with just a few 
cliques, like technological network and some social net- 



60 

works. On the other hand, if there be many cliques, the 
method may deliver trivial community structure, like a 
cover consist of the whole graph a a single cluster. 
A more fundamental issue be the fact that the method 
do not look for actual communities, consistent with 
the share notion of dense subgraphs, but for subgraphs 
“containing” many cliques, which may be quite differ- 
ent object than community (for instance, they could 
be “chains” of clique with low internal edge density). 
Another big problem be that on real network there be a 
considerable fraction of vertex that be left out of the 
communities, like leaves. One could think of some post- 
processing procedure to include them in the communities, 
but for that it be necessary to introduce a new criterion, 
outside the framework that inspire the method. Fur- 
thermore it be not clear a priori which value of k one have 
to choose to identify meaningful structures. Finally, the 
criterion to choose the threshold for weight graph and 
the definition of direct k-cliques be rather arbitrary. 

B. Other technique 

One of the first method to find overlap commu- 
nities be design by Baumes et al. (Baumes et al., 
2005b). A community be define a a subgraph which 
locally optimizes a give function W , typically some mea- 
sure related to the edge density of the cluster20. Different 
overlap subset may all be locally optimal, so vertex 
can be share between communities. Detecting the clus- 
ter structure of a graph amount to find the set of 
all locally optimal clusters. Two efficient heuristic be 
proposed, call Iterative Scan (IS) and Rank Removal 
(RaRe). IS performs a greedy optimization of the func- 
tion W . One start from a random seed vertex/edge and 
adds/deletes vertex one by one a long a W increases. 
Then another seed be randomly picked and the procedure 
be repeated. The algorithm stop when, by pick any 
seed, one recovers a previously identify cluster. RaRe 
consists in remove important vertex such to discon- 
nect the graph in small component represent the 
core of the clusters. The importance of vertex be deter- 
mine by their centrality score (e.g. degree, betweenness 
centrality (Freeman, 1977)), PageRank (Brin and Page, 
1998)). Vertices be remove until one fragment the 
graph into component of a give size. After that, the 
remove vertex be add again to the graph, and be 
associate to those cluster for which do so increase 
the value of the function W . The complexity of IS and 
RaRe be O(n2) on sparse graphs. The best performance be 
achieve by use IS to refine result obtain from RaRe. 
In a successive paper (Baumes et al., 2005a), Baumes et 
al. further improve such two-step procedure, in that the 

20 Community definition base on local optimization be adopt 
in other algorithm a well, like that by Lancichinetti et al. (Lan- 
cichinetti et al., 2009) (Section XII.A). 

remove vertex in RaRe be reinserted in decrease or- 
der of their centrality scores, and the optimization of W 
in IS be only extend to neighbor vertex of the run- 
ning cluster. The new recipe maintains time complexity 
O(n2), but on sparse graph it require a time low by 
an order of magnitude than the old one, while the quality 
of the detect cluster be comparable. 

A different method, combine spectral mapping, fuzzy 
cluster and the optimization of a quality function, have 
be present by Zhang et al. (Zhang et al., 2007). The 
membership of vertex i in cluster k be express by uik, 
which be a number between 0 and 1. The sum of the 
uik over all community k of a cover be 1, for every ver- 
tex. This normalization be suggest by the fact that 
the entry uik can be thought of a the probability that 
i belongs to community k, so the sum of the uik rep- 
resents the probability that the vertex belongs to any 
community of the cover, which be necessarily 1. If there 
be no overlaps, uik = δkik, where ki represent the 
unique community of vertex i. The algorithm consists of 
three phases: 1) embed vertex in Euclidean space; 
2) group the correspond vertex point in a give 
number nc of clusters; 3) maximize a modularity func- 
tion over the set of cover found in step 2), correspond 
to different value of nc. This scheme have be use in 
other technique a well, like in the algorithm of Donetti 
and Muñoz (Donetti and Muñoz, 2004) (Section VII). 
The first step build upon a spectral technique intro- 
duced by White and Smyth (White and Smyth, 2005), 
that we have discuss in Section VI.A.4. Graph vertex 
be embed in a d-dimensional Euclidean space by us- 
ing the top d eigenvectors of the right stochastic matrix 
W (Section A.2), derive from the adjacency matrix A 
by divide each element by the sum of the element of 
the same row. The spatial coordinate of vertex i be 
the i-th component of the eigenvectors. In the second 
step, the vertex point be associate to nc cluster by us- 
ing fuzzy k-means cluster (Bezdek, 1981; Dunn, 1974) 
(Section IV.C). The number of cluster nc varies from 
2 to a maximum K, so one obtains K − 1 covers. The 
best cover be the one that yield the large value of the 
modularity Qzhov , define a 

Qzhov = 

nc∑ 
c=1 

[W̄c 
W 
− 
( 
S̄c 

2W 

)2 ] 
, (71) 

where 

W̄c = 
∑ 
i,j∈Vc 

uic + ujc 
2 

wij , (72) 

and 

S̄c = W̄c + 
∑ 

i∈Vc,j∈V \Vc 

uic + (1− ujc) 
2 

wij . (73) 

The set Vc and V include the vertex of module c and of 
the whole network, respectively. Eq. 71 be an extension of 
the weight modularity in Eq. 36, obtain by weigh 



61 

the contribution of the edges’ weight to the sum in Wc 
and Sc by the (average) membership coefficient of the 
vertex of the edge. The determination of the eigenvec- 
tor be the most computationally expensive part of the 
method, so the time complexity be the same a that of 
the algorithm by White and Smyth (see Section VI.A.4), 
i. e. O(K2n+Km), which be essentially linear in n if the 
graph be sparse and K � n. 

Nepusz et al. propose a different approach base 
on vertex similarity (Nepusz et al., 2008). One start 
from the membership matrix U, define a in the pre- 
vious method by Zhang et al. From U a matrix S be 
built, where sij = 

∑nc 
k=1 uikujk, express the similar- 

ity between vertex (nc be the number of clusters). If 
one assumes to have information about the actual vertex 
similarity, correspond to the matrix S̃, the best cover 
be obtain by choose U such that S approximates a 
closely a possible S̃. This amount to minimize the func- 
tion 

DG(U) = 

n∑ 
i=1 

n∑ 
j=1 

wij(s̃ij − sij)2, (74) 

where the wij weigh the importance of the approximation 
for each entry of the similarity matrices. In the absence 
of any information on the community structure of the 
graph, one set wij = 1, ∀i, j (equal weights) and S̃ equal 
to the adjacency matrix A, by implicitly assume that 
vertex be similar if they be neighbors, dissimilar oth- 
erwise. On weight graphs, one can set the wij equal to 
the edge weights. Minimizing DG(U) be a nonlinear con- 
strain optimization problem, that can be solve with 
a gradient-based iterative optimization method, like sim- 
ulated annealing. The optimization procedure adopt 
by Nepusz et al., for a fix number of cluster nc, have 
a time complexity O(n2nch), where h be the number of 
iteration lead to convergence, so the method can only 
be apply to fairly small graphs. If nc be unknown, a it 
usually happens, the best cover be the one correspond 
to the large value of the modularity 

Q = 
1 

2m 

∑ 
ij 

( 
Aij − 

kikj 
2m 

) 
sij . (75) 

Eq. 75 be very similar to the expression of Newman- 
Girvan modularity (Eq. 13): the difference be that the 
Kronecker’s δ be replace by the vertices’ similarity, to ac- 
count for overlap communities. Once the best cover 
be identified, one can use the entry of the partition ma- 
trix U to evaluate the participation of each vertex in the 
nc cluster of the cover. Nepusz et al. define the brid- 
gene bi of a vertex i a 

bi = 1− 

√√√√ nc 
nc − 1 

c∑ 
j=1 

( 
uji − 

1 

nc 

)2 
. (76) 

If i belongs to a single cluster, bi = 0. If, for a vertex 
i, uik = 1/nc, ∀k, bi = 1 and i be a perfect bridge, a 

it lie exactly between all clusters. However, a vertex 
with low bi may be simply an outlier, not belonging 
to any cluster. Since real bridge be usually rather 
central vertices, one can identify them by check 
for large value of the centrality-corrected bridgeness, 
obtain by multiply the bridgeness of Eq. 76 by 
the centrality of the vertex (expressed by, e.g., degree, 
betweenness (Freeman, 1977), etc.). A variant of the 
algorithm by Nepusz et al. can be download from 
http://www.cs.rhul.ac.uk/home/tamas/assets/file 
s/fuzzyclust-static.tar.gz. 

In real network it be often easy to discriminate be- 
tween intercluster and intracluster edge than recogniz- 
ing overlap vertices. For instance, in social networks, 
even though many people may belong to more groups, 
their social tie within each group can be easily spotted. 
Besides, it may happen that community be join to 
each other through their overlap vertex (Fig. 24), 
without intercluster edges. For these reasons, it have be 
recently suggest that define cluster a set of edges, 
rather than vertices, may be a promising strategy to an- 
alyze graph with overlap community (Ahn et al., 
2009; Evans and Lambiotte, 2009). One have to focus 
on the line graph (Balakrishnan, 1997), i. e. the graph 
whose vertex be the edge of the original graph; ver- 
tices of the line graph be link if the correspond 
edge in the original graph be adjacent, i. e. if they 
share one of their endvertices. Partitioning the line graph 
mean group the edge of the start graph21. Evans 
and Lambiotte (Evans and Lambiotte, 2009) introduce 
a set of quality functions, similar to Newman-Girvan 
modularity (Eq. 13), express the stability of parti- 
tions against random walk take place on the graph, 
follow the work of Delvenne et al. (Delvenne et al., 
2008) [Section VIII.B]. They consider a projection of 
the traditional random walk on the line graph, along with 
two other diffusion processes, where walker move be- 
tween adjacent edge (rather than between neighbor 
vertices). Evans and Lambiotte optimize the three cor- 
respond modularity function to look for partition in 
two real networks, Zachary’s karate club (Zachary, 1977) 
(Section XV.A) and the network of word association de- 
rive from the University of South Florida Free Associa- 
tion Norms (Nelson et al., 1998) (Section II). The opti- 
mization be carry out with the hierarchical technique 
by Blondel et al. (Blondel et al., 2008) and the multi-level 
algorithm by Noack and Rotta (Noack and Rotta, 2009). 
While the result for the word association network be 
reasonable, the test on the karate club yield partition 
in more than two clusters. However, the modularities 
use by Evans et Lambiotte can be modify to include 
longer random walk (just like in Ref. (Delvenne et al., 

21 Ideally one want to put together only the edge lie within 
clusters, and exclude the others. Therefore partition do not 
necessarily mean assign each vertex of the line graph to a 
group, a standard cluster technique would do. 



62 

FIG. 24 Communities a set of edges. In the figure, the 
graph have a natural division in two triangles, with the central 
vertex share between them. If community be identify by 
their internal edges, detect the triangle and their overlap- 
ping vertex becomes easy than by use method that group 
vertices. Reprinted figure with permission from Ref. (Evans 
and Lambiotte, 2009). c©2009 by the American Physical So- 
ciety. 

2008)), and the length of the walk represent a resolu- 
tion parameter that can be tune to get good results. 
Ahn et al. (Ahn et al., 2009) propose to group edge 
with an agglomerative hierarchical cluster technique, 
call hierarchical link cluster (Section IV.B). They 
use a similarity measure for a pair of (adjacent) edge 
that express the size of the overlap between the neigh- 
borhoods of the non-coincident endvertices, divide by 
the total number of (different) neighbor of such end- 
vertices. Groups of edge be merge pairwise in de- 
scend order of similarity, until all edge be together in 
the same cluster. The result dendrogram provide the 
most complete information on the community structure 
of the graph. However, a usual, most of this informa- 
tion be redundant and be an artefact of the procedure it- 
self. So, Ahn et al. introduce a quality function to select 
the most meaningful partition(s), call partition density, 
which be essentially the average edge density within the 
clusters. The method be able to find meaningful cluster 
in biological networks, like protein-protein and metabolic 
networks, a well a in a social network of mobile phone 
communications. It can also be extend to multipartite 
and weight graphs. 

The idea of group edge be surely interesting. How- 
ever it be not a priori good than group vertices. 
In fact, the two situation be somewhat symmetric. 
Edges connect vertex of different cluster be “over- 
lapping”, but they will be assign just to one cluster (or 
else the cluster would be merged). 

The possibility of have overlap community 
make most standard cluster method inadequate, and 
enforces the design of new ad hoc techniques, like the 
one we have described so far. On the other hand, if 
it be possible to identify the overlap vertex and 
“separate” them among the cluster they belong to, the 

overlap would be remove and one could then apply 
any of the traditional cluster method to the result- 
ing graph. This idea be at the basis of a recent method 
propose by Gregory (Gregory, 2009). It be a three- 
stage procedure: first, one transforms the graph into 
a large graph without overlap vertices; second, a 
cluster technique be apply to the result graph; 
third, one map the partition obtain into a cover by 
replace the vertex with those of the original graph. 
The transformation step, call Peacock, be perform 
by identify the vertex with high split betweenness 
(Section V.A) and splitting them in multiple parts, con- 
nected by edges. This be do a long a the split be- 
tweenness of the vertex be sufficiently high, which be 
determine by a parameter s. In this way, most ver- 
tices of the result graph be exactly the same one have 
initially, the others be multiple copy of the overlap- 
ping vertex of the initial graph. The overlap of the 
final cover be obtain by check if copy of the same 
initial vertex end up in different disjoint clusters. The 
complexity be dominate by the Peacock algorithm, if 
one computes the exact value of the split betweenness 
for the vertices, which require a time O(n3) on a sparse 
graph22. Gregory propose an approximate local compu- 
tation, which scale a O(n log n): in this way the total 
complexity of the method becomes competitive, if one 
chooses a fast algorithm for the identification of the clus- 
ters. The goodness of the result depends on the specific 
method one us to find the cluster after the graph trans- 
formation. The software of the version of the method 
use by Gregory in his application can be found at 
http://www.cs.bris.ac.uk/∼steve/networks/peaco 
ckpaper/. The idea of Gregory be interesting, a it al- 
low to exploit traditional method even in the presence 
of overlap communities. The choice of the parameter 
s, which determines whether a vertex be overlap or 
not, do not seem to affect significantly the results, a 
long a s be take sufficiently small. 

XII. MULTIRESOLUTION METHODS AND CLUSTER 
HIERARCHY 

The existence of a resolution limit for Newman-Girvan 
modularity (Section VI.C) implies that the straight opti- 
mization of quality function yield a coarse description 
of the cluster structure of the graph, at a scale which 
have a priori nothing to do with the actual scale of the 
clusters. In the absence of information on the cluster 
size of the graph, a method should be able to explore 
all possible scales, to make sure that it will eventually 
identify the right communities. Multiresolution method 

22 The split betweenness need to be recalculate after each vertex 
split, just a one do for the edge betweenness in the Girvan- 
Newman algorithm (Girvan and Newman, 2002). Therefore both 
computation have the same complexity. 



63 

be base on this principle. However, many real graph 
display hierarchical cluster structures, with cluster in- 
side other cluster (Simon, 1962). In these cases, there 
be more level of organization of vertex in clusters, and 
more relevant scales. In principle, cluster algorithm 
should be able to identify them. Multiresolution meth- 
od can do the trick, in principle, a they scan continu- 
ously the range of possible cluster scales. Recently other 
method have be developed, where partition be by 
construction hierarchically nest in each other. In this 
section we discus both class of techniques. 

A. Multiresolution method 

In general, multiresolution method have a freely tun- 
able parameter, that allows to set the characteristic size 
of the cluster to be detected. The general spin glass 
framework by Reichardt and Bornholdt ((Reichardt and 
Bornholdt, 2006a) and Section VI.B) be a typical exam- 
ple, where γ be the resolution parameter. The extension 
of the method to weight graph have be recently dis- 
cuss (Heimo et al., 2008). 

Pons have propose a method (Pons, 2006) consist of 
the optimization of multiscale quality functions, includ- 
ing the multiscale modularity 

QMα = 

nc∑ 
c=1 

[ 
α 
lc 
m 
− (1− α) 

( 
dc 
2m 

)2 ] 
, (77) 

and two other additive quality functions, derive from 
the performance (Eq. 12) and a measure base on the 
similarity of vertex pairs. In Eq. 77 0 ≤ α ≤ 1 be the 
resolution parameter and the notation be otherwise the 
same a in Eq. 14. We see that, for α = 1/2, one recov- 
er standard modularity. However, since multiplicative 
factor in QMα do not change the result of the optimiza- 
tion, we can divide QMα by α, recover the same qual- 
ity function a in Eq. 46, with γ = (1 − α)/α, up to an 
irrelevant multiplicative constant. To evaluate the rele- 
vance of the partitions, for any give multiscale quality 
function, Pons suggest that the length of the α-range 
[αmin(C), αmax(C)], for which a community C “lives” in 
the maximum modularity partition, be a good indicator 
of the stability of the community. He then define the 
relevance function of a community C at scale α a 

Rα(C) = 
αmax(C)− αmin(C) 

2 

+ 
2(αmax(C)− α)(α− αmin(C)) 

αmax(C)− αmin(C) 
. (78) 

The relevance R(α) of a partition P at scale α be the 
average of the relevance of the cluster of the partition, 
weight by the cluster sizes. Peaks in α of R(α) reveal 
the most meaningful partitions. 

Another interest technique have be devise by Are- 
na et al. (Arenas et al., 2008b), and consists of a mod- 
ification of the original expression of modularity. The 

1 10 100 
r - r 

asymp 

1 

10 

m 
od 

ul 
e 

karate 

(I) 

r = 0 

FIG. 25 Analysis of Zachary’s karate club with the multires- 
olution method by Arenas et al. (Arenas et al., 2008b). The 
plot show the number of cluster obtain in correspondence 
of the resolution parameter r. The long plateau (I) indi- 
cates the most stable partition, which exactly match the so- 
cial fission observe by Zachary. The partition obtain with 
straight modularity optimization (r = 0) consists of four clus- 
ters and be much less stable with respect to (I), a suggest 
by the much shorter length of it plateau. Reprinted figure 
with permission from Ref. (Arenas et al., 2008b). c©2008 by 
IOP Publishing. 

idea be to make vertex contribute a well to the com- 
putation of the edge density of the clusters, by add 
a self-loop of strength r to each vertex. Arenas et al. 
remark that the parameter r do not affect the struc- 
tural property of the graph in most cases, which be 
usually determine by an adjacency matrix without di- 
agonal elements. With the introduction of the vertex 
strength r, modularity read 

Qr = 

nc∑ 
c=1 

[2Wc +Ncr 
2W + nr 

− 
( 
Sc +Ncr 

2W + nr 

)2 ] 
, (79) 

for the general case of a weight graph. The notation 
be the same a in Eq. 36, Nc be the number of vertex 
in cluster c. We see that now the relative importance of 
the two term in each summand depends on r, which can 
take any value in ] − 2W/n,∞[. Arenas et al. make a 
sweep in the range of r, and determine for each r the 
maximum modularity with extremal optimization (Sec- 
tion VI.A.3) and tabu search23 (Glover, 1986). Mean- 
ingful cluster structure correspond to plateau in the 

23 Tabu search consists in move single vertex from one com- 
munity to another, chosen at random, or to new communities, 
start from some initial partition. After a sweep over all ver- 
tices, the best move, i. e. the one produce the large increase 
of modularity, be accepted and applied, yield a new partition. 
The procedure be repeat until modularity do not increase 
further. To escape local optima, a list of recent accepted move 



64 

plot of the number of cluster versus r (Fig. 25). The 
length of a plateau give a measure of the stability of the 
partition against the variation of r. The procedure be 
able to disclose the community structure of a number of 
real benchmark graphs. As expected, the most relevant 
partition can be found in interval of r not include 
the value r = 0, which corresponds to the case of stan- 
dard modularity (Fig. 25). A drawback of the method be 
that it be very slow, a one have to compute the modular- 
ity maximum for many value of r in order to discrim- 
inate between relevant and irrelevant partitions. If the 
modularity maximum be compute with precise method 
like simulated anneal and/or extremal optimization, 
a in Ref. (Arenas et al., 2008b), only graph with a few 
hundred vertex can be analyze on a single processor. 
On the other hand the algorithm can be trivially paral- 
lelized by run the optimization for different value 
of r on different processors. This be a common feature 
of all multiresolution method discuss in this Section. 
In spite of the different formal expression of modularity, 
the method by Arenas et al. and Reichardt and Born- 
holdt be somewhat related to each other and yield sim- 
ilar result (Kumpula et al., 2007a) on Zachary’s karate 
club (Zachary, 1977) (Section XV.A), synthetic graph á 
la Ravasz-Barabási (Ravasz and Barabási, 2003) and on 
a model graph with the property of real weight social 
networks24. In fact, their modularities can be both re- 
cover from the continuous-time version of the stability 
of cluster under random walk, introduce by Delvenne 
et al. (Delvenne et al., 2008) (Section VIII.B). 

Lancichinetti et al. have design a multiresolution 
method which be capable of detect both the hier- 
archical structure of graph and overlap commu- 
nities (Lancichinetti et al., 2009). It be base on the 
optimization of a fitness function, which estimate the 
strength of a cluster and entail a resolution parameter 
α. The function could in principle be arbitrary, in their 
application the author chose a simple ansatz base on 
the tradeoff between the internal and the total degree of 
the cluster. The optimization procedure start from a 
cluster with a single vertex, arbitrarily selected. Given a 
cluster core, one keep add and remove neighbor 
vertex of the cluster a long a it fitness increases. The 
fitness be recalculate after each addition/removal of a 
vertex. At some point one reach a local maximum and 
the cluster be “closed”. Then, another vertex be chosen 
at random, among those not yet assign to a cluster, 
a new cluster be built, and so on, until all vertex have 

be kept and updated, so that those move be not accepted in 
the next update of the configuration (tabu list). The cost of 
the procedure be about the same of other stochastic optimization 
technique like, e. g., simulated annealing. 

24 Related do not mean equivalent, though. Arenas et al. have 
show that their method be good than that by Reichardt and 
Bornholdt when the graph at hand include community of dif- 
ferent size (Arenas et al., 2008b). 

be assign to clusters. During the buildup of a clus- 
ter, vertex already assign to other cluster may be 
included, i. e. community may overlap. The computa- 
tional complexity of the algorithm, estimate on sparse 
Erdös-Rényi random graphs, be O(nβ), with β ∼ 2 for 
small value of the resolution parameter α, and β ∼ 1 if 
α be large. For a complete analysis, the worst-case compu- 
tational complexity be O(n2 log n), where the factor log n 
come from the minimum number of different α-values 
which be need to resolve the actual community struc- 
ture of the graph. Relevant partition be reveal by 
pronounce spike in the histogram of the fitness value 
of cover obtain for different α-values, where the fitness 
of a cover be define a the average fitness of it clusters. 

A technique base on the Potts model, similar to that 
of Reichardt and Bornholdt (Reichardt and Bornholdt, 
2006a), have be suggest by Ronhovde and Nussi- 
nov (Ronhovde and Nussinov, 2008). The energy of their 
spin model be 

H({σ}) = −1 
2 

∑ 
i6=j 

[Aij − γ(1−Aij)]δ(σi, σj). (80) 

The big difference with Eq. 46 be the absence of a null 
model term. The model considers pair of vertex in the 
same community: edge between vertex be energeti- 
cally rewarded, whereas miss edge be penalized. The 
parameter γ fix the tradeoff between the two contribu- 
tions. The energy be minimize by sequentially shift 
single vertices/spins to the community which yield the 
large decrease of the system’s energy, until convergence. 
If, for each vertex, one just examines the community of 
it neighbors, the energy be minimize in a time O(mβ), 
where β turn out to be slightly above 1 in most appli- 
cations, allow for the analysis of large graphs. This 
essentially eliminates the problem of limited resolution, 
a the criterion to decide about the merger or the split 
of cluster only depends on local parameters. Still, for 
the detection of possible hierarchical level tune γ be 
mandatory. In a successive paper (Ronhovde and Nussi- 
nov, 2009), the author have introduce a new stability 
criterion for the partitions, consist of the computa- 
tion of the similarity of partition obtain for the same 
γ and different initial conditions. The idea be that, if 
a partition be robust in a give range of γ-values, most 
replica deliver by the algorithm will be very similar. 
On the other hand, if one explores a region of resolution 
in between two strong partitions, the algorithm will de- 
liver the one or the other partition and the individual 
replica will be, on average, not so similar to each other. 
So, by plot the similarity a a function of the reso- 
lution parameter γ, stable community be reveal by 
peaks. Ronhovde and Nussinov adopt similarity mea- 
sures borrow from information theory (Section XV.B). 
Their criterion of stability can be adopt to determine 
the relevance of partition obtain with any multireso- 
lution algorithm. 

A general problem of multiresolution method be how 
to ass the stability of partition for large graphs. The 



65 

rapidly increase number of partitions, obtain by min- 
imal shift of vertex between clusters, introduces a large 
amount of noise, that blur signature of stable partition 
like plateaus, spikes, etc. that one can observe in small 
systems. In this respect, it seem far more reliable focus- 
ing on correlation between partition (like the average 
similarity use by Ronhovde and Nussinov (Ronhovde 
and Nussinov, 2008; Ronhovde and Nussinov, 2009)) than 
on property of the individual partition (like the mea- 
sures of occurrence use by Arenas et al. (Arenas et al., 
2008b) and by Lancichinetti et al. (Lancichinetti et al., 
2009)). 

B. Hierarchical method 

The natural procedure to detect the hierarchical struc- 
ture of a graph be hierarchical clustering, that we have 
discuss in Section IV.B. There we have emphasize 
the main weakness of the procedure, which consists of 
the necessity to introduce a criterion to identify relevant 
partition (hierarchical levels) out of the full dendrogram 
produce by the give algorithm. Furthermore, there be 
no guarantee that the result indeed reflect the actual hi- 
erarchical structure of the graph, and that they be not 
mere artefact of the algorithm itself. Scholars have just 
start to deal with these problems. 

Sales-Pardo et al. have propose a top-down ap- 
proach (Sales-Pardo et al., 2007). Their method con- 
sists of two steps: 1) measure the similarity between 
vertices; 2) derive the hierarchical structure of the 
graph from the similarity matrix. The similarity mea- 
sure, name node affinity, be base on Newman-Girvan 
modularity. Basically the affinity between two vertex 
be the frequency with which they coexist in the same 
community in partition correspond to local optimum 
of modularity. The latter be configuration for which 
modularity be stable, i. e. it cannot increase if one shift 
one vertex from one cluster to another or by merge or 
splitting clusters. The set of these partition be call 
Pmax. Before proceed with the next step, one verifies 
whether the graph have a significant community structure 
or not. This be do by calculate the z-score (Eq. 51) 
for the average modularity of the partition in Pmax with 
respect to the average modularity of partition with lo- 
cal modularity optimum of the equivalent ensemble of null 
model graphs, obtain a usual by randomly rewire 
the edge of the original graph under the condition that 
the expect degree sequence be the same a the degree 
sequence of the graph. Large z-scores indicate meaning- 
ful cluster structure: Sales-Pardo et al. use a threshold 
correspond to the 1% significance level25. If the graph 

25 We remind that the significance of the z-score have to be com- 
put with respect to the actual distribution of the maximum 
modularity for the null model graphs, a the latter be not Gaus- 
sian (Section VI.C). 

have a relevant cluster structure, one proceeds with the 
second step, which consists in put the affinity matrix 
in a form a close a possible to block-diagonal, by min- 
imizing a cost function express the average distance 
of connect vertex from the diagonal. The block cor- 
respond to the community and the recover partition 
represent the uppermost organization level. To deter- 
mine low levels, one iterates the procedure for each 
subgraph identify at the previous level, which be treat 
a an independent graph. The procedure stop when all 
block found do not have a relevant cluster structure, i. e. 
their z-scores be low than the threshold. The parti- 
tions deliver by the method be hierarchical by con- 
struction, a community at each level be nest within 
community at high levels. However, the method may 
find no relevant partition (no community structure), a 
single partition (community structure but no hierarchy) 
or more (hierarchy) and in this respect it be good than 
most exist methods. The algorithm be not fast, a both 
the search of local optimum for modularity and the rear- 
rangement of the similarity matrix be perform with 
simulated annealing26, but delivers good result for com- 
puter generate networks, and meaningful partition for 
some real networks, like the world airport network (Bar- 
rat et al., 2004), an email exchange network of a Catalan 
university (Guimerà et al., 2003), a network of electronic 
circuit (Itzkovitz et al., 2005) and metabolic network 
of E. coli (Guimerà et al., 2007). 

Clauset et al. (Clauset et al., 2007; Clauset et al., 2008) 
described the hierarchical organization of a graph by in- 
troducing a class of hierarchical random graphs. A hi- 
erarchical random graph be define by a dendrogram D, 
which be the natural representation of the hierarchy, and 
by a set of probability {pr} associate to the n−1 inter- 
nal node of the dendrogram. An ancestor of a vertex i be 
any internal node of the dendrogram that be encounter 
by start from the “leaf” vertex i and go all the way 
up to the top of the dendrogram. The probability that 
vertex i and j be link to each other be give by the 
probability pr of the low common ancestor of i and 
j. Clauset et al. search for the model (D, {pr}) that 
best fit the observe graph topology, by use Bayesian 
inference (Section IX.A). The probability that the model 
fit the graph be proportional to the likelihood 

L(D, {pr}) = 
∏ 
r∈D 

pErr (1− pr)LrRr−Er . (81) 

Here, Er be the number of edge connect vertex whose 
low common ancestor be r, Lr and Rr be the number 
of graph vertex in the left and right subtrees descend- 
ing from the dendrogram node r, and the product run 

26 The reorder of the matrix be by far the most time-consuming 
part of the method. The situation improves if one adopts faster 
optimization strategy than simulated annealing, at the cost of 
less accurate results. 



66 

a 

b 

c d 

e 

f 

a b c d e f 

1 

1 

1 

1 

1/9 

a b c d e f 

1 

1 

1 

1/3 

1/4 

FIG. 26 Hierarchical random graph by Clauset et 
al. (Clauset et al., 2008). The picture show two possible den- 
drograms for the simple graph on the top. The link prob- 
ability on the internal node of the dendrograms yield the 
best fit of the model graph to the graph at study. Reprinted 
figure with permission from Ref. (Clauset et al., 2008). c©2008 
by the Nature Publishing Group. 

over all internal dendrogram nodes. For a give dendro- 
gram D, the maximum likelihood L(D) corresponds to 
the set of probability {p̄r}, where p̄r equal the actual 
density of edge Er/(LrRr) between the two subtrees of 
r (Fig. 26). One can define the statistical ensemble of 
hierarchical random graph describe a give graph G, 
by assign to each model graph (D, {p̄r}) a probability 
proportional to the maximum likelihood L(D). The en- 
semble can be sample by a Markov chain Monte Carlo 
method (Newman and Barkema, 1999). The procedure 
suggest by Clauset et al. seem to converge to equilib- 
rium roughly in a time O(n2), although the actual com- 
plexity may be much higher. Still, the author be able 
to investigate graph with a few thousand vertices. From 
sufficiently large set of model configuration sample at 
equilibrium, one can compute average property of the 
model, e. g. degree distributions, cluster coefficients. 
etc., and compare them with the correspond proper- 
tie of the original graph. Tests on real graph reveal that 
the model be indeed capable to describe closely the graph 
properties. Furthermore, the model enables one to pre- 
dict miss connection between vertex of the original 
graph. This be a very important problem (Liben-Nowell 
and Kleinberg, 2003): edge of real graph be the result 
of observations/experiments, that may fail to discover 
some relationship between the unit of the system. From 
the ensemble of the hierarchical random graph one can 
derive the average link probability between all pair 
of graph vertices. By rank the probability corre- 
sponding to vertex pair which be disconnect in the 
original graph, one may expect that the pair with high- 
est probability be likely to be connect in the system, 
even if such connection be not observed. Clauset et al. 
point out that their method do not deliver a sharp 
hierarchical organization for a give graph, but a class of 
possible organizations, with well-defined probabilities. It 
be certainly reasonable to assume that many structure 

t+1t 

t t+1 

t+1t t t+1 

t t+1 

t t+1 

growth 

merge 

birth death 

splitting 

contraction 

FIG. 27 Possible scenario in the evolution of communi- 
ties. Reprinted figure with permission from Ref. (Palla et al., 
2007). c©2007 by the Nature Publishing Group. 

be compatible with a give graph topology. In the case 
of community structure, it be not clear which informa- 
tion one can extract from average over the ensemble of 
hierarchical random graphs. Moreover, since the hierar- 
chical structure be represent by a dendrogram, it be im- 
possible to rank partition accord to their relevance. 
In fact, the work by Clauset et al. question the con- 
cept of “relevant partition”, and open a debate in the 
scientific community about the meaning itself of graph 
clustering. The software of the method can be found at 
http://www.santafe.edu/∼aaronc/hierarchy/. 

XIII. DETECTION OF DYNAMIC COMMUNITIES 

The analysis of dynamic community be still in it in- 
fancy. Studies in this direction have be mostly hin- 
dered by the fact that the problem of graph cluster 
be already controversial on single graph realizations, so 
it be understandable that most effort still concentrate 
on the “static” version of the problem. Another diffi- 
culty be represent by the dearth of timestamped data 
on real graphs. Recently, several data set have become 
available, enable to monitor the evolution in time of 
real system (Kumar et al., 2003, 2006; Leskovec et al., 
2008, 2005). So it have become possible to investigate how 
community form, evolve and die. The main phenomenon 
occur in the lifetime of a community be (Fig. 27): 
birth, growth, contraction, merger with other communi- 
ties, split, death. 

The first study be carry out by Hopcroft et 
al. (Hopcroft et al., 2004), who analyze several snap- 
shot of the citation graph induced by the NEC CiteSeer 
Database (Giles et al., 1998). The snapshot cover the 
period from 1990 to 2001. Communities be detect 
by mean of (agglomerative) hierarchical cluster (Sec- 
tion IV.B), where the similarity between vertex be the 



67 

cosine similarity of the vector describe the correspond- 
ing papers, a well know measure use in information 
retrieval (Baeza-Yates and Ribeiro-Neto, 1999). In each 
snapshot Hopcroft et al. identify the natural communi- 
ties, define a those community of the hierarchical tree 
that be only slightly affected by minor perturbation of 
the graph, where the perturbation consists in remove 
a small fraction of the vertex (and their edges). Such 
natural community be conceptually similar to the sta- 
ble community we will see in Section XIV. Hopcroft et 
al. found the best match natural community across 
different snapshots, and in this way they could follow the 
history of communities. In particular they could see the 
emergence of new communities, correspond to new re- 
search topics. The main drawback of the method come 
from the use of hierarchical clustering, which be unable 
to sort out meaningful community out of the hierarchi- 
cal tree, which include many different partition of the 
graph. 

More recently, Palla et al. perform a systematic 
analysis of dynamic community (Palla et al., 2007). 
They study two social systems: 1) a graph of phone 
call between customer of a mobile phone company in 
a year’s time; 2) a collaboration network between scien- 
tists, describe the coauthorship of paper in condense 
matter physic from the electronic e-print archive (cond- 
mat) maintain by Cornell University Library, span 
a period of 142 months. The first problem be identify 
the image of a community C(t+1) at time t+1 among the 
community of the graph at time t. A simple criterion, 
use in other works, be to measure the relative overlap 
(Eq. 97) of C(t + 1) with all community at time t, and 
pick the community which have the large overlap with 
C(t+ 1). This be intuitive, but in many case it may miss 
the actual evolution of the community. For instance, if 
C(t) at time t + 1 grows considerably and overlap with 
another community B(t+ 1) (which at the previous time 
step be disjoint from C(t)), the relative overlap between 
C(t+ 1) and B(t) may be large than the relative overlap 
between C(t + 1) and C(t). It be not clear whether there 
be a general prescription to avoid this problem. Palla et 
al. solve it by exploit the feature of the Clique Per- 
colation Method (CPM) (Section XI.A), that they use 
to detect communities. The idea be to analyze the graph 
G(t, t + 1), obtain by merge the two snapshot G(t) 
and G(t+1) of the evolve graph, at time t and t+1 (i. 
e., by put together all their vertex and edges). Any 
CPM community of G(t) and G(t + 1) do not get lost, 
a it be include within one of the CPM community of 
G(t, t + 1). For each CPM community Vk of G(t, t + 1), 
one find the CPM community {Ctk} and {C 

t+1 
k } (of G(t) 

and G(t+1), respectively) which be contain in Vk. The 
image of any community in {Ct+1k } at time t be the com- 
munity of {Ctk} that have the large relative overlap with 
it. 

The age τ of a community be the time since it birth. 
It turn out that the age of a community be positively 
correlate with it size s(τ), i. e. that old community 

be also large (on average). The time evolution of a 
community C can be described by mean of the relative 
overlap C(t) between state of the community separate 
by a time t: 

C(t) = 
|C(t0) 

⋂ 
C(t0 + t)| 

|C(t0) 
⋃ 
C(t0 + t)| 

. (82) 

One find that, in both data sets, C(t) decay faster for 
large communities, so the composition of large commu- 
nities be rather variable in time, whether small commu- 
nities be essentially static. Another important question 
be whether it be possible to predict the evolution of com- 
munities from information on their structure or on their 
vertices. In Fig. 28a the probability pl that a vertex will 
leave the community in the next step of the evolution be 
plot a a function of the relative external strength of 
the vertex, indicate how much of the vertex strength 
lie on edge connect it to vertex outside it com- 
munity. The plot indicates that there be a clear positive 
correlation: vertex which be only loosely connect to 
vertex of their community have a high chance (on av- 
erage) to leave the community than vertex which be 
more “committed” towards the other community mem- 
bers. The same principle hold at the community level 
too. Fig. 28b show that the probability pd that a com- 
munity will disintegrate in the next time step be posi- 
tively correlate with the relative external strength of 
the community. Finally, Palla et al. have found that the 
probability for two community to merge increase with 
the community size much more than what one expect 
from the size distribution, which be consistent with the 
faster dynamic observe for large communities. Palla et 
al. analyze two different real systems, a network of mo- 
bile phone communication and a coauthorship network, 
to be able to infer general property of community evo- 
lution. However, community be only found with the 
CPM, so their result need to be cross-checked by em- 
ploying other cluster techniques. 

Asur et al. (Asur et al., 2007) explore the dynamic 
relationship between vertex and communities. Commu- 
nities be found with the MCL method by Van Don- 
gen (Dongen, 2000a) (Section VIII.B), by analyze the 
graph at different timestamps. Asur et al. distinguish 
event involve community and event involve the 
vertices. Events involve community be Continue (the 
community keep most of it vertex in consecutive time 
steps), κ-Merge (two cluster merge into another), κ-Split 
(two cluster split in two parts), Form (no pair of vertex 
of the cluster at time t + 1 be in the same cluster at 
time t) and Dissolve (opposite of Form). Events involv- 
ing vertex be Appear (if a vertex join the graph for the 
first time), Disappear (if a vertex of the graph at time t 
be no longer there at time t + 1), Join (if a vertex of a 
cluster at time t + 1 be not in that cluster at time t) 
and Leave (if a vertex which be in a cluster at time t be 
not in that cluster at time t+ 1). Based on such events, 
four measure be define in order to catch the behav- 
ioral tendency of vertex contribute to the evolution 



68 

τ n 

wout win wout+/( ) 

τ ∗ 

WinWout Wout/( + ) 

p l 

inwoutw outw( + )/ 

dp 

outW Win outW/( + ) 

a) 

b) 

co−authorship 
phone−call 

0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 

10 

8 

12 

14 

16 

6 

4 

2 

0 

0 

5 

10 

15 

20 

25 

30 

35 

0 0.2 0.4 0.5 0.6 0.7 0.8 0.9 1 0.3 0.1 

phone−call 
co−authorship 

0.08 

0.07 

0.06 

0.05 

0.04 

0.03 

0.02 

0.01 

0 
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 

0.2 

0.15 

0.05 

0 

0.1 

0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 

FIG. 28 Relation between structural feature and evolution 
of a community. a) Relation between the probability that a 
vertex will abandon the community in the next time step and 
it relative external strength. b) Relation between the prob- 
ability of disintegration of a community in the next time step 
and it relative external strength. Reprinted figure with per- 
mission from Ref. (Palla et al., 2007). c©2007 by the Nature 
Publishing Group. 

of the graph: the stability index (measuring the tendency 
of a vertex to interact with the same vertex over time), 
the sociability index (measuring the number of different 
interaction of a vertex, basically the number of Join and 
Leave events), the popularity index (measuring the num- 
ber of vertex attract by a cluster in a give time in- 
terval) and the influence index (measuring the influence 
a vertex have on the others, which be compute from the 
number of vertex that leave or join a cluster together 
with the vertex). Applications on a coauthorship network 
of computer scientist and on a network of subject for 
clinical trial show that the behavioral measure above 
enable one to make reliable prediction about the time 
evolution of such graph (including, e. g., the inference 
of miss link (Liben-Nowell and Kleinberg, 2003)). 

Dynamic community can be a well detect with 
method of information compression, such a some of 
those we have see in Section IX.B. Sun et al. (Sun 

et al., 2007) apply the Minimum Description Length 
(MDL) principle (Grünwald et al., 2005; Rissanen, 1978) 
to find the minimum encode cost for the description 
of a time sequence of graph and their partition in 
communities. The method be quite similar to that suc- 
cessively developed by Rosvall and Bergstrom (Rosvall 
and Bergstrom, 2007), which be however define only for 
static graph (Section IX.B). Here one considers bipartite 
graph evolve in time. The time sequence of graph can 
be separate in segments, each contain some number 
of consecutive snapshot of the system. The graph of 
each segment be suppose to have the same modular 
structure (i. e. they represent the same phase in the 
history of the system), so they be characterize by the 
same partition of the two vertex classes. For each graph 
segment it be possible to define an encode cost, which 
combine the encode cost of the partition of the graph 
of the segment with the entropy of compression of the seg- 
ment in the subgraph segment induced by the partition. 
The total encode cost C of the graph series be give 
by the sum of the encode cost of it segments. Mini- 
mizing C enables one to find not only the most modular 
partition for each graph segment (high modularity27 cor- 
responds to low encode cost for a partition), but also 
the most compact subdivision of the snapshot into seg- 
ments, such that graph in the same segment be strongly 
correlate with each other. The latter feature allows to 
identify change point in the time history of the system, 
i. e. short period in which the dynamic produce big 
change in the graph structure (corresponding to, e.g., 
extreme events). The minimization of C be NP-hard, 
so the author propose an approximation method call 
GraphScope, which consists of two steps: first, one look 
for the best partition of each graph segment; second, one 
look for the best division in segments. In both case 
the “best” result corresponds to the minimal encode 
cost. The best partition within a graph segment be found 
by local search. GraphScope have the big advantage not 
to require any input, like the number and size of the 
clusters. It be also suitable to operate in a stream en- 
vironment, in which new graph configuration be add 
in time, follow the evolution of the system: the com- 
putational complexity require to process a snapshot (on 
average) be stable over time. Tests on real evolve data 
set show that GraphScope be able to find meaningful 
community and change points. 

Since keep track of community in different time 
step be not a trivial problem, a we have see above, it 
be perhaps easy to adopt a vertex-centric perspective, 
in which one monitor the community of a give vertex 
at different times. For any method, give a vertex i and 
a time t, the community to which i belongs at time t be 

27 We stress that here by modularity we mean the feature of a graph 
have community structure, not the modularity of Newman and 
Girvan. 



69 

well defined. Fenn et al. (Fenn et al., 2009) use the mul- 
tiresolution method by Reichardt et al. (Reichardt and 
Bornholdt, 2006a) (Section VI.B) and investigate a fully 
connect graph with time-dependent weights, represent- 
ing the correlation of time series of hourly exchange rate 
returns. The resolution parameter γ be fix to the value 
that occurs in most stability plateau of the system at 
different time steps. Motivated by the work of Guimerà 
and Amaral (Guimerà and Amaral, 2005) (Section XVI), 
Fenn et al. identify the role of individual vertex in their 
community through the pair (zin, zb), where zin be the 
z-score of the internal strength (weighted degree, Sec- 
tion A.1), define in Eq. 98, and zb the z-score of the 
site betweenness, define by replace the internal degree 
with the site betweenness of Freeman (Freeman, 1977) in 
Eq. 98. We remind that the site betweenness be a measure 
of the number of shortest path run through a ver- 
tex. The variable zb express the importance of a vertex 
in process of information diffusion with respect to the 
other member of it community. Another important is- 
sue regard the persistence of community in time, i. e. 
how stable they be during the evolution. As a measure 
of persistence, Fenn et al. introduce a vertex-centric 
version of the relative overlap of Eq. 82 

ati(τ) = 
|Ci(t) 

⋂ 
Ci(t+ τ)| 

|Ci(t) 
⋃ 
Ci(t+ τ)| 

, (83) 

where i be the vertex and Ci(t), Ci(t+τ) the community 
of i at time t, t + τ , respectively. The decay of ati(τ) 
depends on the type of vertex. In particular, if the ver- 
tex be strongly connect to it community (zin large), 
ati(τ) decay quite slowly, meaning that it tends to stay 
attach to a stable core of vertices. 

The method described above be basically two-stage 
approaches, in which cluster be detect at each times- 
tamp of the graph evolution, independently of the result 
at different times, and relationship between partition 
at different time be infer successively. However, this 
often produce significant variation between partition 
close in time, especially when, a it usually happens, the 
datasets be noisy. In this case one would be force to 
introduce ad hoc hypothesis on the graph evolution to 
justify the variability of the modular structure, whereas 
such variability be mostly an artefact of the approach. 
It would be desirable instead to have a unified frame- 
work, in which cluster be deduce both from the cur- 
rent structure of the graph and from the knowledge of 
the cluster structure at previous times. This be the prin- 
ciple of evolutionary clustering, a framework introduce 
by Chakrabarti et al. (Chakrabarti et al., 2006) and suc- 
cessively adopt and refine by other authors. Let Ct 
be the partition of the graph at time t. The snapshot 
quality of Ct measure the goodness of the partition with 
respect to the graph structure at time t. The history 
cost be a measure of the distance/dissimilarity of Ct with 
respect to the partition Ct−1 at the previous time step. 
The overall quality of Ct be give by a combination of the 
snapshot quality and the history cost at each time step. 

Ideally, a good partition should have high snapshot qual- 
ity (i. e. it should cluster well the data at time t) and low 
history cost (i. e. it should be similar to the partition 
at the previous time step). In order to find Ct from Ct−1 
and the relational data at time t Chakrabarti et al. sug- 
gested to minimize the difference between the snapshot 
quality and the history cost, with a relative weight cp 
that be a tunable parameter. The input of the procedure 
consists in the sequence of adjacency/similarity matrix 
at different time steps. In practice, one could use mod- 
ified version of such matrices, obtain by perform 
(weighted) average of the data over some time window, 
in order to make the relational data more robust against 
noise and the result of the cluster procedure more re- 
liable. One can adopt arbitrary measure to compute the 
snapshot quality and the historical cost. Besides, sev- 
eral know cluster technique use for static graph 
can be reformulate within this evolutionary framework. 
Chakrabarti et al. derive evolutionary version of hi- 
erarchical cluster (Section IV.B) and k-means clus- 
tering (Section IV.C), whereas Chi et al. (Chi et al., 
2007) design two implementation for spectral cluster- 
ing (Section IV.D). Based on evolutionary clustering, Lin 
et al. (Lin et al., 2008) introduce a framework, call 
FacetNet, that allows vertex to belong to more commu- 
nities at the same time. Here the snapshot cost28 be the 
Kullback-Leibler (KL) divergence (Kullback and Leibler, 
1951) between the adjacency/similarity matrix at time 
t and the matrix describe the community structure of 
the graph at time t; the history cost be the KL divergence 
between the matrix describe the community structure 
of the graph at time t − 1 and t. FacetNet can be ex- 
tend to handle add and remove of vertex a well 
a variation of the number of cluster in consecutive time 
steps. However, it be not able to account for the creation 
and the disintegration of community and not scalable to 
large system due to the high number of iteration neces- 
sary for the matrix computation to reach convergence. 
These issue have be address in a recent approach 
by Kim and Han (Kim and Han, 2009). 

Naturally, what one hope to achieve at the end of the 
day be to see how real group form and evolve in time. 
Backstrom et al. (Backstrom et al., 2006) have carry out 
an analysis of group dynamic in the free online commu- 
nity of LiveJournal (http://www.livejournal.com/) 
and in a coauthorship network of computer scientists. 
Here the group be identify through the declare mem- 
berships of user (for LiveJournal) and conference at- 
tend by computer scientists, respectively. Backstrom 
and coworkers have found that the probability that an 
individual join a community grows with the number of 
friends/coauthors who be already in the community and 

28 Lin et al. use the cost and not the quality to evaluate the fit 
of the partition to the data. The two estimate be obviously 
related: the low the cost, the high the quality. 



70 

(for LiveJournal) with their degree of interconnectedness. 
Moreover, the probability of growth of LiveJournal com- 
munities be positively correlate to a combination of fac- 
tor include the community size, the number of friend 
of community member which be not in the community 
and the ratio of these two numbers. A high density of 
triad within a community appear instead to hinder it 
growth. 

XIV. SIGNIFICANCE OF CLUSTERING 

Given a network, many partition could represent 
meaningful clustering in some sense, and it could be dif- 
ficult for some method to discriminate between them. 
Quality function evaluate the goodness of a partition 
(Section III.C.2), so one could say that high quality cor- 
responds to meaningful partitions. But this be not nec- 
essarily true. In Section VI.C we have see that high 
value of the modularity of Newman and Girvan do not 
necessarily indicate that a graph have a definite cluster 
structure. In particular we have see that partition of 
random graph may also achieve considerably large val- 
ues ofQ, although we do not expect them to have commu- 
nity structure, due to the lack of correlation between the 
link probability of the vertices. The optimization of 
quality functions, like modularity, delivers the best par- 
tition accord to the criterion underlie the quality 
function. But be the optimal cluster also significant, 
i. e. a relevant feature of the graph, or be it just a byprod- 
uct of randomness and basic structural property like, e. 
g., the degree sequence? Little effort have be devote 
to this crucial issue, that we discus here. 

In some work the concept of significance have be 
related to that of robustness or stability of a partition 
against random perturbation of the graph structure. 
The basic idea be that, if a partition be significant, it will 
be recover even if the structure of the graph be mod- 
ified, a long a the modification be not too extensive. 
Instead, if a partition be not significant, one expect that 
minimal modification of the graph will suffice to disrupt 
the partition, so other clustering be recovered. A nice 
feature of this approach be the fact that it can be apply 
for any cluster technique. Gfeller et al. (Gfeller et al., 
2005) consider the general case of weight graphs. A 
graph be modified, in that it edge weight be increase 
or decrease by a relative amount 0 < σ < 1. This 
choice also allows to account for the possible effect of 
uncertainty in the value of the edge weights, result 
from measurements/experiments carry out on a give 
system. After fix σ (usually to 0.5), multiple realiza- 
tions of the original graph be generated. The best par- 
tition for each realization be identify and, for each pair 
of adjacent vertex i and j, the in-cluster probability pij 
be computed, i. e. the fraction of realization in which 
i and j be classify in the same cluster. Edges with 
in-cluster probability small than a threshold θ (usually 
0.8) be call external edges. The stability of a partition 

be estimate through the cluster entropy 

S = − 1 
m 

∑ 
(i,j):Aij=1 

[pij log2 pij − (1− pij) log2(1− pij)], 

(84) 
where m is, a usual, the number of graph edges, and 
the sum run over all edges. The most stable partition 
have pij = 0 along inter-cluster edge and pij = 1 along 
intra-cluster edges, which yield S = 0; the most unstable 
partition have pij = 1/2 on all edges, yield S = 1. The 
absolute value of S be not meaningful, though, and need 
to be compare with the correspond value for a null 
model graph, similar to the original graph, but with sup- 
posedly no cluster structure. Gfeller et al. adopt the 
same null model of Newman-Girvan modularity, i. e. the 
class of graph with expect degree sequence coincide 
with that of the original graph. Since the null model be 
define on unweighted graphs, the significance of S can 
be assess only in this case, although it would not be 
hard to think of a generalization to weight graphs. The 
approach enables one a well to identify unstable vertices, 
i. e. vertex lie at the boundary between clusters. In 
order to do that, the external edge be remove and 
the connect component of the result disconnect 
graph be associate with the cluster detect in the 
original graph, base on their relative overlap (computed 
through Eq. 97). Unstable vertex end up in component 
that be not associate to any of the initial clusters. A 
weakness of the method by Gfeller et al. be represent by 
the two parameter σ and θ, whose value be in principle 
arbitrary. 

More recently, Karrer et al. (Karrer et al., 2008) 
adopt a similar strategy to unweighted graphs. Here 
one performs a sweep over all edges: the perturbation 
consists in remove each edge with a probability α and 
replace it with another edge between a pair of vertex 
(i, j), chosen at random with probability pij = kikj/2m, 
where ki and kj be the degree of i and j. We recog- 
nize the probability of the null model of Newman-Girvan 
modularity. Indeed, by vary the probability α from 
0 to 1 one smoothly interpolates between the original 
graph (no perturbation) and the null model (maximal 
perturbation). The degree sequence of the graph remains 
invariant (on average) along the whole process, by con- 
struction. The idea be that the perturbation affect solely 
the organization of the vertices, keep the basic struc- 
tural properties. For a give value of α, many realiza- 
tions of the perturbed graph be generated, their cluster 
structure be identify with some method (Karrer et al. 
use modularity optimization) and compare with the 
partition obtain from the original unperturbed graph. 
The partition be compare by compute the variation 
of information V (Section XV.B). From the plot of the 
average 〈V 〉 versus α one can ass the stability of the 
cluster structure of the graph. If 〈V (α)〉 change rapidly 
for small value of α the partition be likely to be unsta- 
ble. As in the approach by Gfeller et al. the behaviour of 
the function 〈V (α)〉 do not have an absolute meaning, 



71 

but need to be compare with the correspond curve 
obtain for a null model. For consistency, the natural 
choice be again the null model of modularity, which be al- 
ready use in the process of graph perturbation. The ap- 
proaches by Gfeller et al. and Karrer et al., with suitable 
modifications, can also be use to check for the stability 
of the cluster structure in part of a graph, up to the level 
of individual communities. This be potentially important 
a it may happen that some part of the graph display a 
strong community structure and other part weak or no 
community structure at all. 

Rosvall and Bergstrom (Rosvall and Bergstrom, 2008) 
define the significance of cluster with the bootstrap 
method (Efron and Tibshirani, 1993), which be a stan- 
dard procedure to check for the accuracy of a measure- 
ment/estimate base on resampling from the empirical 
data. The graph at study be suppose to be generate by 
a parametric model, which be use to create many sam- 
ples. This be do by assign to each edge a weight 
take by a Poisson distribution with mean equal to the 
original edge weight. For the initial graph and each sam- 
ple one identifies the community structure with some 
method, that can be arbitrary. For each cluster of the 
partition of the original graph one determines the large 
subset of vertex that be classify in the same clus- 
ter in at least 95% of all bootstrap samples. Identifying 
such cluster core enables one to track the evolution in 
time of the community structure, a we explain in Sec- 
tion XIII. 

A different approach have be propose by Massen 
and Doye (Massen and Doye, 2006). They analyze an 
equilibrium canonical ensemble of partitions, with −Q 
play the role of the energy, Q be Newman-Girvan 
modularity. This mean that the probability of occur- 
rence of a partition at temperature T be proportional to 
exp(Q/T ). The idea be that, if a graph have a signifi- 
cant cluster structure, at low temperature one would 
recover essentially the same partition, correspond to 
the modularity maximum, which be separate by an ap- 
preciable gap from the modularity value of the other 
partitions. On the contrary, graph with no commu- 
nity structure, e. g. random graphs, have many com- 
pet (local) maxima, and the correspond configura- 
tions will emerge already at low temperatures, since their 
modularity value be close to the absolute maximum29. 
These distinct behavior can manifest themselves in var- 
ious ways. For instance, if one considers the variation of 
the specific heat C = −dQ/dT with T , the gap in the 
modularity landscape be associate to a sharp peak of 
C around some temperature value, like it happens in a 

29 As we have see in Section VI.C, Good et al. (Good et al., 2009) 
have actually show that the modularity landscape have a huge 
degeneracy of state with high modularity values, close to the 
global maximum, especially on graph with community struc- 
ture. So the result of the method by Massen and Doye may be 
misleading. 

phase transition. If the gap be small and there be many 
partition with similar modularity values, the peak of C 
becomes broad. Another strategy to ass the signifi- 
cance of the maximum modularity partition consists of 
the investigation of the similarity between partition re- 
cover at a give temperature T . This similarity can 
be express by the frequency matrix, whose element fij 
indicates the relative number of time vertex i and j 
have be classify in the same cluster. If the graph 
have a clear community structure, at low temperature 
the frequency matrix can be put in block-diagonal form, 
with the block correspond to the community of the 
best partition; if there be no significant community struc- 
ture, the frequency matrix be rather homogeneous. The 
Fiedler eigenvalue (Fiedler, 1973) λ2, the second small 
eigenvalue of the Laplacian matrix associate to the fre- 
quency matrix, allows to estimate how “block-diagonal” 
the matrix be (see Section IV.A). At low temperature 
λ2 ∼ 0 if there be one (a few) partition with maximum 
or near to maximum modularity; if there be many (al- 
most) degenerate partitions, λ2 be appreciably different 
from zero even when T → 0. A sharp transition from 
low to high value of λ2 by vary temperature indicates 
significant community structure. Another clear signature 
of significant community structure be the observation of 
a rapid drop of the average community size with T , a 
“strong” community break up in many small piece for 
a modest temperature increase, while the disintegration 
of “weak” community take place more slowly. In scale- 
free graph (Section A.3) cluster be often not well sep- 
arated, due to the presence of the hubs; in these case 
the above-mentioned transition of ensemble variable be 
not so sharp and take place over a broader temperature 
range. The canonical ensemble of partition be generate 
through single spin heatbath simulated anneal (Re- 
ichardt and Bornholdt, 2006a), combine with parallel 
temper (Earl and Deem, 2005). The approach by 
Massen and Doye could be useful to recognize graph 
without cluster structure, if the modularity landscape be 
characterize by many maximum with close value (but see 
Footnote). However, it can happen that gap between the 
absolute modularity maximum and the rest of the modu- 
larity value be create by fluctuations, and the method 
be unable to identify these situations. Furthermore, the 
approach heavily relies on modularity and on a costly 
technique like simulated annealing: extension to other 
quality function and/or optimization procedure do not 
appear straightforward. 

In a recent work by Bianconi et al. (Bianconi et al., 
2009) the notion of entropy of graph ensemble (Bianconi, 
2008; Bianconi et al., 2008) be employ to find out how 
likely it be for a cluster structure to occur on a graph with 
a give degree sequence. The entropy be compute from 
the number of graph configuration which be compatible 
with a give classification of the vertex in q groups. 
The cluster be quantitatively described by fix the 
number of edge A(q1, q2) run between cluster q1 
and q2, for all choice of q1 6= q2. Bianconi et al. propose 



72 

the follow indicator of cluster significance 

Θ~k,~q = 
Σ~k,~q − 〈Σ~k,π(~q)〉π√ 
〈δΣ2~k,π(~q)〉π 

, (85) 

where Σ~k,~q be the entropy of the graph configuration with 

give degree sequence ~k and cluster ~q (with fix num- 
bers of inter-cluster edge A(q1, q2)), and 〈Σ~k,π(~q)〉π be 
the average entropy of the configuration with the same 
degree sequence and a random permutation π(~q) of the 
cluster labels. The absolute value of the entropy Σ~k,~q be 

not meaningful, so the comparison of Σ~k,~q and 〈Σ~k,π(~q)〉π 
be crucial, a it tell how relevant the actual cluster struc- 
ture be with respect to a random classification of the ver- 
tices. However, different permutation of the assignment 
~q yield different value of the entropy, which can fluctuate 
considerably. Therefore one have to compute the standard 
deviation 〈δΣ2~k,π(~q)〉π of the entropy correspond to all 
random permutation π(~q), to estimate how significant 
the difference between Σ~k,~q and 〈Σ~k,π(~q)〉π is. In this 
way, if Θ~k,~q ≤ 1, the entropy of the give cluster struc- 
ture be of the same order a the entropy of some random 
permutation of the cluster labels, so it be not relevant. 
Instead, if Θ~k,~q � 1, the cluster structure be far more 
likely than a random classification of the vertices, so the 
cluster be relevant. The indicator Θ~k,~q can be simply 

generalize to the case of direct and weight graphs. 
Lancichinetti et al. (Lancichinetti et al., 2009) a well 

address the issue by compare the cluster structure of 
the graph with that of a random graph with similar prop- 
erties. An important novelty of this approach be the fact 
that it estimate the significance of single communities, 
not of partitions. In fact, not all community be equally 
significant, in general, so it make a lot of sense to check 
them individually. In particular, it may happen that real 
network be not fully modular, due to their particular 
history or generate mechanisms, and that only portion 
of them display community structure. The main idea be 
to verify how likely it be that a community C be a sub- 
graph of a random graph with the same degree sequence 
of the original graph. This likelihood be call C-score, 
and be compute by examine the vertex w of C, with 
the low internal degree kinw in C (the “worst” vertex). 
The C-score be define a the probability that the internal 
degree of the bad vertex in the correspond commu- 
nity of the null model graph be large than or equal to 
kinw . This probability be compute by use tool from Ex- 
treme and Order Statistics (Beirlant et al., 2004; David 
and Nagaraja, 2003). A low value of the C-score (≤ 5%) 
be a strong indication that the group of vertex at study 
be a community and not the product of random fluctu- 
ations. In addition, the measure can be use to check 
whether a subgraph have an internal modular structure. 
For that, one remove the vertex of the subgraph one 
at a time, start from the bad and proceed in in- 
crease order of the internal degree, and observes how 

the C-score varies at each vertex removal: sharp drop in- 
dicate the presence of dense subgraphs (Fig. 29). There- 
fore, one could think of use the C-score a ingredient of 
new cluster techniques. As we have seen, the C-score 
be base on the behavior of the vertex with low internal 
degree of the subgraph. Real network be characterize 
by noise, which could strongly affect the structural rela- 
tionships between vertex and clusters. For this reason, 
rely on the property of a single vertex to evaluate 
the significance of a subgraph could be a problem for 
application to real networks. Lancichinetti et al. have 
show that the C-score can be easily extend to consider 
the t vertex with low internal degree, with t > 1 (B- 
score). The main limit of the C-score be the fact that it 
null model be the same a that of Newman-Girvan mod- 
ularity. According to this null model, each vertex can in 
principle be connect to any other, no matter how large 
the system is. This be however not realistic, especially for 
large graphs, where it be much more reasonable to assume 
that each vertex have it own “horizon”, i.e. a subset of 
other vertex with which it can interact, which be usually 
much small than the whole system (see Section VI.C). 
How to define such “horizons” and, more in general, re- 
alistic null model be still an open problem. However, the 
C-score could be easily reformulate with any null model, 
so one could readily derive more reliable definitions. 

We conclude with a general issue which be related to 
the significance of community structure. The question is: 
give a cluster structure in a graph, can it be recover 
a priori by an algorithm? In a recent paper (Reichardt 
and Leone, 2008), Reichardt and Leone study under 
which condition a special built-in cluster structure can 
be recovered. The cluster have equal size and a pair of 
vertex be connect with probability p if they belong to 
the same cluster, with probability r < p otherwise. In 
computer science this be know a the plant partition- 
ing problem (Condon and Karp, 2001). The goal be to 
propose algorithm that recover the plant partition for 
any choice of p and r. For dense graphs, i. e. graph 
whose average degree grows with the number n of ver- 
tices, algorithm can be design that find the solution 
with a probability which equal 1 minus a term that van- 
ishes in the limit of infinite graph size, regardless of the 
difference p − r, which can then be chosen arbitrarily 
small. Since many real network be not dense graphs, 
a their average degree 〈k〉 be usually much small than 
n and do not depend on it, Reichardt and Leone inves- 
tigated the problem in the case of fix 〈k〉 and infinite 
graph size. We indicate with q the number of cluster and 
with pin the probability that a randomly select edge of 
the graph lie within any of the q clusters. In this way, 
if pin = 1/q, the inter-cluster edge density match the 
intra-cluster edge density (i. e. p = r), and the plant 
partition would not correspond to a recoverable cluster- 
ing, whereas for pin = 1, there be no inter-cluster edge 
and the partition can be trivially recovered. The value 
of pin be in principle unknown, so one have to detect the 
cluster structure ignore this information. Reichardt 



73 

0 10 20 30 40 
remove node 

10 
-6 

10 
-4 

10 
-2 

10 
0 

C 
-s 

co 
re 

0 10 20 30 40 50 60 70 
remove node 

10 
-6 

10 
-4 

10 
-2 

10 
0 

(a) 

one cluster+ random node two cluster 

(b) 

FIG. 29 Application of the C-score by Lancichinetti et al. (Lancichinetti et al., 2009) to identify module within subgraphs. In 
(a) the subgraph consists of a compact cluster (generated with the LFR benchmark (Lancichinetti and Fortunato, 2009; Lanci- 
chinetti et al., 2008)) plus some randomly add vertices. In (b) the subgraph consists of two compact cluster interconnect 
by a few edges. Vertices be remove from each subgraph in increase order of their internal degree. The C-score display sharp 
drop after all the spurious vertex (a) and all the vertex of one of the two cluster (b) be removed. We notice that the first 
subgraph (a) be not significant (high C-score) until the noise represent by the randomly add vertex disappears, whereas 
the second subgraph (b) be a community at the very beginning, a it should be, it loses significance when one of the cluster 
be heavily damage (because the remainder of the cluster appear a noise, just like the spurious vertex in (a)), and becomes 
significant again when the damage cluster be totally removed. Reprinted figure with permission from Ref. (Lancichinetti et al., 
2009). 

and Leone propose to look for a minimum cut parti- 
tion, i. e. for the partition that minimizes the number of 
inter-cluster edges, a it be usually do in the graph par- 
titioning problem (discussed in Section IV.A). Clearly, 
for pin = 1 the minimum cut partition trivially coincides 
with the plant partition, whereas for 1/q < pin < 1 
there should be some overlap, which be expect to vanish 
in the limit case pin = 1/q. The minimum cut partition 
corresponds to the minimum of the follow ferromag- 
netic Potts model Hamiltonian 

Hpart = − 
∑ 
i<j 

Jijδσi,σj , (86) 

over the set of all spin configuration with zero magne- 
tization. Here the spin σi indicates the cluster vertex i 
belongs to, and the couple matrix Jij be just the adja- 
cency matrix of the graph. The constraint of zero magne- 
tization ensures that the cluster have all the same size, 
a require by the plant partition problem. The 
energy of a spin configuration, express by Eq. 86, be 
the negative of the number of edge that lie within clus- 
ters: the minimum energy corresponds to the maximum 
number of intra-cluster edges, which be couple to the 

minimum number of inter-cluster edges. The minimum 
energy can be compute with the cavity method, or be- 
lief propagation, at zero temperature (Mézard and Parisi, 
2003). The accuracy of the solution with respect to the 
plant partition be express by the fraction of vertex 
which be put in the same class in both partitions. The 
analysis yield a strike result: the plant cluster be 
accurately recover for pin large than a critical thresh- 
old pcin > 1/q. So, there be a range of value of pin, 
1/q < pin < p 

c 
in, in which the cluster be not recover- 

able, a the minimum cut partition be uncorrelated with 
it. The threshold pcin depends on the degree distribution 
p(k) of the graph. 

XV. TESTING ALGORITHMS 

When a cluster algorithm be designed, it be neces- 
sary to test it performance, and compare it with that 
of other methods. In the previous section we have say 
very little about the performance of the algorithms, other 
than their computational complexity. Indeed, the issue 
of test algorithm have receive very little attention 
in the literature on graph clustering. This be a serious 



74 

limit of the field. Because of that, it be still impossible to 
state which method (or subset of methods) be the most 
reliable in applications, and people rely blindly on some 
algorithm instead of others for reason that have noth- 
ing to do with the actual performance of the algorithms, 
like. e.g. popularity (of the method or of it inventor). 
This lack of control be also the main reason for the pro- 
liferation of graph cluster technique in the last few 
years. Virtually in any paper, where a new method be 
introduced, the part about test consists in apply 
the method to a small set of simple benchmark graphs, 
whose cluster structure be fairly easy to recover. Because 
of that, the freedom in the design of a cluster algo- 
rithm be basically infinite, whereas it be not clear what a 
new procedure be add to the field, if anything. 

In this section we discus at length the issue of testing. 
First, we describe the fundamental ingredient of any 
test procedure, i. e. benchmark graph with built-in 
community structure, that method have to identify (Sec- 
tion XV.A). We proceed by review measure to com- 
pare graph partition with each other (Section XV.B). In 
Section XV.C we present the comparative evaluation of 
different method that have be perform in the liter- 
ature. 

A. Benchmarks 

Testing an algorithm essentially mean apply it to 
a specific problem whose solution be know and compar- 
ing such solution with that deliver by the algorithm. 
In the case of graph clustering, a problem with a well- 
define solution be a graph with a clear community struc- 
ture. This concept be not trivial, however. Many cluster- 
ing algorithm be base on similar intuitive notion of 
what a community is, but different implementations. So 
it be crucial that the scientific community agrees on a 
set of reliable benchmark graphs. This mostly applies 
to computer-generated graphs, where the built-in clus- 
ter structure can be arbitrarily designed. In the liter- 
ature real network be use a well, in those case in 
which community be well define because of informa- 
tion about the system. 

We start our survey from computer-generated bench- 
marks. A special class of graph have become quite pop- 
ular in the last years. They be generate with the 
so-called plant `-partition model (Condon and Karp, 
2001). The model partition a graph with n = g · ` ver- 
tices in ` group with g vertex each. Vertices of the 
same group be link with a probability pin, whereas 
vertex of different group be link with a probability 
pout. Each subgraph correspond to a group be then 
a random graph á la Erdös-Rényi with connection prob- 
ability p = pin (Section A.3). The average degree of a 
vertex be 〈k〉 = pin(g−1) +poutg(`−1). If pin > pout the 
intra-cluster edge density exceeds the inter-cluster edge 
density and the graph have a community structure. This 
idea be quite intuitive and we have encounter it in sev- 

eral occasion in the previous sections. Girvan and New- 
man consider a special case of the plant `-partition 
model (Girvan and Newman, 2002). They set ` = 4, 
g = 32 (so the number of graph vertex be n = 128) and 
fix the average total degree 〈k〉 to 16. This implies 
that pin + 3pout ≈ 1/2, so the probability pin and pout 
be not independent parameters. In calculation it be com- 
mon to use a parameter zin = pin(g − 1) = 31pin and 
zout = poutg(` − 1) = 96pout, indicate the expect 
internal and external degree of a vertex, respectively. 
These particular graph have by now gain the sta- 
tus of standard benchmark (Girvan and Newman, 2002) 
(Fig. 30). In the first application of the graph one as- 
sum that community be well define when zout < 8, 
correspond to the situation in which the internal de- 
gree exceeds the external degree. However, the thresh- 
old zout = zin = 8 implies pin ≈ 1/4 and pout = 1/12, 
so it be not the actual threshold of the model, where 
pin = pout = 1/8, correspond to zout ≈ 12. So, one 
expects30 to be able to detect the plant partition up 
until zout ≈ 12. 

Testing a method against the Girvan-Newman bench- 
mark consists in calculate the similarity between the 
partition determine by the method and the natural 
partition of the graph in the four equal-sized groups. Sev- 
eral measure of partitions’ similarity may be adopted; we 
describe them in Section XV.B. One usually build many 
graph realization for a particular value of zout and com- 
putes the average similarity between the solution of the 
method and the built-in solution. The procedure be then 
iterate for different value of zout. The result be usu- 
ally represent in a plot, where the average similarity 
be drawn a a function of zout. Most algorithm usu- 
ally do a good job for small zout and start to fail when 
zout approach 8. Fan et al. (Fan et al., 2007) have 
design a weight version of the benchmark of Gir- 
van and Newman, in that one give different weight to 
edge inside and between communities. One could pick 
just two values, one for intra- and the other for inter- 
community edges, or uniformly distribute value in two 
different ranges. For this benchmark there be then two 
parameter that can be varied: zout and the relative im- 
portance of the internal and the external weights. Typ- 
ically one fix the topological structure and varies the 
weights. This be particularly insightful when zout = 4, 
which delivers graph without topological cluster struc- 
ture: in this case, the question whether there be cluster 
or not depends entirely on the weights. 

As we have remark above, the plant `-partition 
model generates mutually interconnect random graph 

30 However, we stress that, even if community be there, meth- 
od may be unable to detect them. The reason be that, due to 
fluctuation in the distribution of link in the graphs, already 
before the limit impose by the plant partition model it may 
be impossible to detect the community and the model graph 
may look similar to random graphs. 



75 

FIG. 30 Benchmark of Girvan and Newman. The three picture correspond to zin = 15 (a), zin = 11 (b) and zin = 8 (c). In 
(c) the four group be hardly visible. Reprinted figure with permission from Ref. (Guimerà and Amaral, 2005). c©2005 by the 
Nature Publishing Group. 

á la Erdös-Rényi. Therefore, all vertex have approxi- 
mately the same degree. Moreover, all community have 
exactly the same size by construction. These two feature 
be at odds with what be observe in graph representa- 
tions of real systems. Degree distribution be usually 
skewed, with many vertex with low degree coexist 
with a few vertex with high degree. A similar hetero- 
geneity be also observe in the distribution of cluster sizes, 
a we shall see in Section XVI. So, the plant `-partition 
model be not a good description of a real graph with com- 
munity structure. However, the model can be modify to 
account for the heterogeneity of degree and community 
sizes. A modify version of the model, call Gaussian 
random partition generator, be design by Brandes et 
al. (Brandes et al., 2003). Here the cluster size have a 
Gaussian distribution, so they be not the same, although 
they do not differ much from each other. The hetero- 
geneity of the cluster size introduces a heterogeneity in 
the degree distribution a well, a the expect degree of 
a vertex depends on the number of vertex of it clus- 
ter. Still, the variability of degree and cluster size be not 
appreciable. Besides, vertex of the same cluster keep 
have approximately the same degree. A good job in 
this direction have be recently do by Lancichinetti et 
al. (LFR benchmark) (Lancichinetti et al., 2008). They 
assume that the distribution of degree and community 
size be power laws, with exponent τ1 and τ2, respec- 
tively. Each vertex share a fraction 1 − µ of it edge 
with the other vertex of it community and a fraction µ 
with the vertex of the other communities; 0 ≤ µ ≤ 1 be 
the mix parameter. The graph be built a follows: 

1. A sequence of community size obey the pre- 
scribed power law distribution be extracted. This be 
do by pick random number from a power law 
distribution with exponent τ2. 

2. Each vertex i of a community receives an internal 

degree (1−µ)ki, where ki be the degree of vertex i, 
which be take by a power law distribution with ex- 
ponent τ1. In this way, each vertex i have a number 
of stub (1− µ)ki. 

3. All stub of vertex of the same community be ran- 
domly attach to each other, until no more stub 
be “free”. In this way the sequence of internal de- 
grees of each vertex in it community be maintained. 

4. Each vertex i receives now an additional number of 
stubs, equal to µki (so that the final degree of the 
vertex be ki), that be randomly attach to ver- 
tices of different communities, until no more stub 
be “free”. 

Numerical test show that this procedure have a com- 
plexity O(m), where m be a usual the number of edge 
of the graph, so it can be use to create graph of size 
span several order of magnitude. Fig. 31 show an 
example of a LFR benchmark graph. Recently the LFR 
benchmark have be extend to direct and weight 
graph with overlap community (Lancichinetti 
and Fortunato, 2009). The software to create the 
LFR benchmark graph can be freely download at 
http://santo.fortunato.googlepages.com/inthepre 
ss2. 

A class of benchmark graph with power law de- 
gree distribution have be previously introduce by 
Bagrow (Bagrow, 2008). The construction process start 
from a graph with a power-law degree distribution. 
Bagrow use Barabási-Albert scale free graph (Barabási 
and Albert, 1999). Then, vertex be randomly assign 
to one of four equally-sized communities. Finally, pair 
of edge between two community be rewire so that 
either edge end up within the same community, with- 
out alter the degree sequence (on average). This be 
straightforward: suppose that the edge join the vertex 



76 

FIG. 31 A realization of the LFR benchmark graph (Lancichinetti et al., 2008), with 500 vertices. The distribution of the 
vertex degree and of the community size be both power laws. Such benchmark be a more faithful approximation of real-world 
network with community structure than simpler benchmark like, e. g., that by Girvan and Newman (Girvan and Newman, 
2002). Reprinted figure with permission from Ref. (Lancichinetti et al., 2008). c©2008 by the American Physical Society. 

pair a1, b1 and a2, b2, where a1, a2 belong to commu- 
nity A and b1, b2 to community B. It the edge be 
replace by a1-a2 and b1-b2 (provided they do not ex- 
ist already), all vertex keep their degrees. With this 
rewire procedure one can arbitrarily vary the edge den- 
sity within and, consequently, between clusters. In this 
class of benchmarks, however, community be all of the 
same size by construction, although one can in principle 
relax this condition. 

A (seemingly) different benchmark be represent by 
the class of relaxed caveman graphs, which be origi- 
nally introduce to explain the cluster property of 
social network (Watts, 2003). The start point be a 
set of disconnect cliques. With some probability edge 
be rewire to link different cliques. Such model graph 
be interest a they be smooth variation of the ideal 
graph with “perfect” communities, i. e. disconnect 
cliques. On the other hand the model be equivalent to 
the plant `-partition model, where pin = 1 − p and 
pout be proportional to p, with coefficient depend on 
the size of the clusters. 

Benchmark graph have also be introduce to deal 
with special type of graph and/or cluster structures. 
For instance, Arenas et al. (Arenas et al., 2006) have 
introduce a class of benchmark graph with embed 

hierarchical structure, which extends the class of graph 
by Girvan and Newman. Here there be 256 vertex and 
two hierarchical levels, correspond to a partition in 16 
group (microcommunities) with 16 vertex and a par- 
tition in 4 large group of 64 vertex (macrocommu- 
nities), comprise each 4 of the small groups. The 
edge density within and between the cluster be indi- 
cat by three parameter zin1 , zin2 and zout: zin1 be 
the expect internal degree of a vertex within it micro- 
community; zin2 be the expect number of edge that the 
vertex share with the vertex of the other microcommu- 
nities within it macrocommunity; zout be the expect 
number of edge connect the vertex with vertex of 
the other three macrocommunities. The average degree 
〈k〉 = zin1 + zin2 + zout of a vertex be fix to 18. Fig. 7 
show an example of hierarchical graph construct base 
on the same principle, with 512 vertex and an average 
degree of 32. 

Guimerà et al. (Guimerà et al., 2007) have propose 
a model of bipartite graph with built-in communities. 
They consider a bipartite graph of actor and teams, 
here we describe how to build the benchmark for gen- 
eral bipartite graphs. One start from a bipartite graph 
whose vertex class A and B be partition into nc 
groups, CAi and CBi (i = 1, 2, ..., nc). Each cluster Ci 



77 

comprises all vertex of the subgroup CAi and CBi , re- 
spectively. With probability p edge be place between 
vertex of subgroup CAi and CBi (i = 1, 2, ..., nc), i. e. 
within clusters. With probability 1− p, edge be place 
between vertex of subgroup CAi and CBj , where i and j 
be chosen at random, so they can be equal or different. 
By construction, a non-zero value of the probability p 
indicates a preference by vertex to share link with ver- 
tices of the same cluster, i. e. for p > 0 the graph have a 
built-in community structure. For p = 1 there would be 
edge only within clusters, i. e. the graph have a perfect 
cluster structure. 

Finally, Sawardecker et al. introduce a general 
model, that account for the possibility that cluster over- 
lap (Sawardecker et al., 2009). The model be base on the 
reasonable assumption that the probability pij that two 
vertex be connect by an edge grows with the number 
n0 of community both vertex belong to. For vertex 
in different clusters, pij = p0, if they be in the same 
cluster (and only in that one) pij = p1, if they belong 
to the same two cluster pij = p2, etc.. By hypothesis, 
p0 < p1 ≤ p2 ≤ p3.... The plant `-partition model be 
recover when p1 = p2 = p3.... 

As we have seen, nearly all exist benchmark graph 
be inspire by the plant `-partition model, to some 
extent. However, the model need to be refine to pro- 
vide a good description of real graph with community 
structure. The hypothesis that the link probability 
of each vertex with the vertex of it community or of 
the other community be constant be not realistic. It be 
more plausible that each pair of vertex i and j have it 
own link probability pij , and that such probability 
be correlate for vertex in the same cluster. 

Tests on real network usually focus on a very limited 
number of examples, for which one have precise informa- 
tion about the vertex and their properties. 

In Section II we have introduce two popular real net- 
work with know community structure, i. e. the social 
network of Zachary’s karate club and the social network 
of bottlenose dolphin living in Doubtful Sound (New 
Zealand), study by Lusseau. Here, the question be 
whether the actual separation in two social group could 
be predict from the graph topology. Zachary’s karate 
club be by far the most investigate system. Several algo- 
rithms be actually able to identify the two classes, mod- 
ulo a few intermediate vertices, which may be misclassi- 
fied. Other method be less successful: for instance, the 
maximum of Newman-Girvan modularity corresponds to 
a split of the network in four group (Donetti and Muñoz, 
2004; Duch and Arenas, 2005). Another well know ex- 
ample be the network of American college football teams, 
derive by Girvan and Newman (Girvan and Newman, 
2002). There be 115 vertices, represent the teams, 
and two vertex be connect if their team play against 
each other. The team be divide into 12 conferences. 
Games between team in the same conference be more 
frequent than game between team of different confer- 
ences, so one have a natural partition where the commu- 

nities correspond to the conferences. 
When deal with real networks, it be useful to re- 

solve their community structure with different cluster 
techniques, to cross-check the result and make sure that 
they be consistent with each other, a in some case the 
answer may strongly depend on the specific algorithm 
adopted. However, one have to keep in mind that there 
be no guarantee that “reasonable” communities, define 
on the basis of non-structural information, must coincide 
with those detect by method base only on the graph 
structure. 

B. Comparing partitions: measure 

Checking the performance of an algorithm involves 
define a criterion to establish how “similar” the par- 
tition deliver by the algorithm be to the partition one 
wish to recover. Several measure for the similarity of 
partition exist. In this section we present and discus 
the most popular measures. A thorough introduction of 
similarity measure for graph partition have be give 
by Meilă (Meilă, 2007) and we will follow it closely. 

Let u consider two generic partition X = 
(X1, X2, ..., XnX ) and Y = (Y1, Y2, ..., YnY ) of a graph 
G, with nX and nY clusters, respectively. We indicate 
with n the number of graph vertices, with nXi and n 

Y 
j 

the number of vertex in cluster Xi and Yj and with 
nij the number of vertex share by cluster Xi and Yj : 
nij = |Xi 

⋂ 
Yj |. 

In the first test use the benchmark graph by Girvan 
and Newman (Section XV.A) scholar use a measure 
propose by Girvan and Newman themselves, the frac- 
tion of correctly classify vertices. A vertex be correctly 
classify if it be in the same cluster with at least half of 
it “natural” partners. If the partition found by the al- 
gorithm have cluster give by the merge of two or more 
natural groups, all vertex of the cluster be consider 
incorrectly classified. The number of correctly classify 
vertex be then divide by the total size of the graph, 
to yield a number between 0 and 1. The recipe to label 
vertex a correctly or incorrectly classify be somewhat 
arbitrary, though. 

Apart from the fraction of correctly classify vertices, 
which be somewhat ad hoc and distinguishes the role of 
the natural partition and of the algorithm’s partition, 
most similarity measure can be divide in three cate- 
gories: measure base on pair counting, cluster match- 
ing and information theory. 

Measures base on pair counting depend on the num- 
ber of pair of vertex which be classify in the same 
(different) cluster in the two partitions. In particular 
a11 indicates the number of pair of vertex which be 
in the same community in both partitions, a01 (a10) the 
number of pair of element which be put in the same 
community in X (Y) and in different community in Y 
(X ) and a00 the number of pair of vertex that be in 
different community in both partitions. Wallace (Wal- 



78 

lace, 1983) propose the two index 

WI = 
a11∑ 

k n 
X 
k (n 

X 
k − 1)/2 

; WII = 
a11∑ 

k n 
Y 
k (n 

Y 
k − 1)/2 

. 

(87) 
WI and WII represent the probability that vertex pair 
in the same cluster of X be also in the same cluster for 
Y, and viceversa. These index be asymmetrical, a the 
role of the two partition be not the same. Fowlkes and 
Mallows (Fowlkes and Mallows, 1983) suggest to use 
the geometric mean of WI and WII , which be symmetric. 

The Rand index (Rand, 1971) be the ratio of the number 
of vertex pair correctly classify in both partition (i. e. 
either in the same or in different clusters), by the total 
number of pair 

R(X ,Y) = a11 + a00 
a11 + a01 + a10 + a00 

. (88) 

A measure equivalent to the Rand index be the Mirkin 
metric (Mirkin, 1996) 

M(X ,Y) = 2(a01 + a10) = n(n− 1)[1−R(X ,Y)]. (89) 

The Jaccard index be the ratio of the number of vertex 
pair classify in the same cluster in both partitions, by 
the number of vertex pair which be classify in the 
same cluster in at least one partition, i. e. 

J(X ,Y) = a11 
a11 + a01 + a10 

. (90) 

Adjusted version of both the Rand and the Jaccard in- 
dex exist, in that a null model be introduced, correspond- 
ing to the hypothesis of independence of the two parti- 
tions (Meilă, 2007). The null model expectation value 
of the measure be subtract from the unadjusted ver- 
sion, and the result be normalize by the range of this 
difference, yield 1 for identical partition and 0 a ex- 
pected value for independent partition (negative value 
be possible a well). Unadjusted index have the draw- 
back that they be not local, i. e. the result depends 
on how the whole graph be partitioned, even when the 
partition differ only in a small region of the graph. 

Similarity measure base on cluster match aim at 
find the large overlap between pair of cluster of 
different partitions. For instance, the classification error 
H(X ,Y) be define a (Meilă and Heckerman, 2001) 

H(X ,Y) = 1− 1 
n 

max 
π 

nX∑ 
k=1 

nkπ(k), (91) 

where π be an injective mapping from the cluster index 
of partition Y to the cluster index of partition X . The 
maximum be take over all possible injection {π}. In 
this way one recovers the maximum overlap between the 
cluster of the two partitions. An alternative measure 
be the normalize Van Dongen metric, define a (van 
Dongen, 2000b) 

D(X ,Y) = 1− 1 
2n 

[ 
nX∑ 
k=1 

max 
k′ 

nkk′ + 

nY∑ 
k′=1 

max 
k 

nkk′ 

] 
. (92) 

A common problem of this type of measure be that some 
cluster may not be take into account, if their overlap 
with cluster of the other partition be not large enough. 
Therefore if we compute the similarity between two parti- 
tions X and X ′ and partition Y, with X and X ′ differ 
from each other by a different subdivision of part of the 
graph that be not use to compute the measure, one 
would obtain the same score. 

The third class of similarity measure be base on re- 
formulate the problem of compare partition a a 
problem of message decode within the framework of 
information theory (Mackay, 2003). The idea be that, if 
two partition be similar, one need very little informa- 
tion to infer one partition give the other. This extra 
information can be use a a measure of dissimilarity. 
To evaluate the Shannon information content (Mackay, 
2003) of a partition, one start by consider the com- 
munity assignment {xi} and {yi}, where xi and yi in- 
dicate the cluster label of vertex i in partition X and 
Y, respectively. One assumes that the label x and y 
be value of two random variable X and Y , with joint 
distribution P (x, y) = P (X = x, Y = y) = nxy/n, 
which implies that P (x) = P (X = x) = nXx /n and 
P (y) = P (Y = y) = nYy /n. The mutual information 
I(X,Y ) of two random variable have be previously 
define [Eq. (70)], and can be apply a well to par- 
titions X and Y, since they be described by random 
variables. Actually I(X,Y ) = H(X) − H(X|Y ), where 
H(X) = − 

∑ 
x P (x) logP (x) be the Shannon entropy of 

X and H(X|Y ) = − 
∑ 
x,y P (x, y) logP (x|y) be the con- 

ditional entropy of X give Y . The mutual information 
be not ideal a a similarity measure: in fact, give a par- 
tition X , all partition derive from X by further par- 
titioning (some of) it cluster would all have the same 
mutual information with X , even though they could be 
very different from each other. In this case the mutual in- 
formation would simply equal the entropy H(X), because 
the conditional entropy would be systematically zero. To 
avoid that, Danon et al. adopt the normalize mutual 
information (Danon et al., 2005) 

Inorm(X ,Y) = 
2I(X,Y ) 

H(X) +H(Y ) 
, (93) 

which be currently very often use in test of graph clus- 
tering algorithms. The normalize mutual information 
equal 1 if the partition be identical, whereas it have 
an expect value of 0 if the partition be independent. 
The measure, define for standard partitions, in which 
each vertex belongs to only one cluster, have be recently 
extend to the case of overlap cluster by Lanci- 
chinetti et al. (Lancichinetti et al., 2009). The extension 
be not straightforward a the community assignment of 
a partition be now specify by a vectorial random vari- 
able, since each vertex may belong to more cluster si- 
multaneously. In fact, the definition by Lancichinetti et 
al. be not a proper extension of the normalize mutual 
information, in the sense that it do not recover exactly 
the same value of the original measure for the compar- 



79 

ison of proper partition without overlap, even though 
the value be close. 

Meilă (Meilă, 2007) introduce the variation of infor- 
mation 

V (X ,Y) = H(X|Y ) +H(Y |X), (94) 

which have some desirable property with respect to the 
normalize mutual information and other measures. In 
particular, it defines a metric in the space of partition 
a it have the property of distance. It be also a local 
measure, i. e. the similarity of partition differ only 
in a small portion of a graph depends on the difference of 
the cluster in that region, and not on the partition of the 
rest of the graph. The maximum value of the variation 
of information be log n, so similarity value for partition 
of graph with different size cannot be compare with 
each other. For meaningful comparison one could divide 
V (X ,Y) by log n, a suggest by Karrer et al. (Karrer 
et al., 2008). 

A concept related to similarity be that of distance, 
which indicates basically how many operation need to 
be perform in order to transform a partition to an- 
other. Gustafsson et al. define two distance measure 
for partition (Gustafsson et al., 2006). They be both 
base on the concept of meet of two partitions, which be 
define a 

M = 
nA⋃ 
i=1 

nB⋃ 
j=1 

[ 
Xi 
⋂ 
Yj 

] 
. (95) 

The distance measure be mmoved and mdiv. In both 
case they be determine by sum the distance of 
X and Y from the meet M. For mmoved the distance of 
X (Y) from the meet be the minimum number of element 
that must be move between X and Y so that X (Y) and 
M coincide (Gusfield, 2002). For mdiv the distance of X 
(Y) from the meet be the minimum number of division 
that must be do in X (Y) so that X (Y) and M coin- 
cide (Stanley, 1997). Such distance measure can easily 
be transform in similarity measures, like 

Imoved = 1−mmoved/n, Idiv = 1−mdiv/n. (96) 

Identical partition have zero mutual distance and simi- 
larity 1 base on Eqs. 96. 

Finally an important problem be how to define the sim- 
ilarity between clusters. If two partition X and Y of a 
graph be similar, each cluster of X will be very similar 
to one cluster of Y, and viceversa, and it be important 
to identify the pair of correspond clusters. For in- 
stance, if one have information about the time evolution 
of a graph, one could monitor the dynamic of single clus- 
ters a well, by keep track of each cluster at different 
time step (Palla et al., 2007). Given cluster Xi and 
Yj , their similarity can be define through the relative 
overlap sij 

sij = 
|Xi 

⋂ 
Yj | 

|Xi 
⋃ 
Yj | 

. (97) 

N 
G 

G 
N 

FL 
M N 
F 

D 
M 

D 
M 

N ZL LP R 
B D 
A 

SA 

Method 

0 

0.2 

0.4 

0.6 

0.8 

1 

F 
ra 

ct 
io 

n 
of 

n 
od 

e 
c 

or 
re 

ct 
ly 

id 
en 

tif 
ie 

d 

z out = 6 

z out = 7 

z out = 8 

FIG. 32 Relative performance of the algorithm list in 
Table I on the Girvan-Newman benchmark, for three value 
of the expect average external degree zout. Reprinted figure 
with permission from Ref. (Danon et al., 2005). c©2005 by 
IOP Publishing and SISSA. 

In this way, look for the cluster of Y correspond to 
Xi mean find the cluster Yj that maximizes sij . The 
index sij can be use to define similarity measure for 
partition a well (Fan et al., 2007; Zhang et al., 2006). 
An interest discussion on the problem of compare 
partitions, along with further definition of similarity 
measure not discuss here, can be found in Ref. (Traud 
et al., 2008). 

C. Comparing algorithm 

The first systematic comparative analysis of graph 
cluster technique have be carry out by Danon et 
al. (Danon et al., 2005). They compare the perfor- 
mances of various algorithm on the benchmark graph 
by Girvan and Newman (Section XV.A). The algorithm 
examine be list in Table I, along with their complex- 
ity. Fig. 32 show the performance of all algorithms. 
Instead of show the whole curve of the similarity ver- 
sus zout (Section XV.A), which would display a fuzzy 
picture with many strongly overlap curves, difficult 
to appreciate, Danon et al. consider three value for 



80 

Author Ref. Label Order 

Eckmann & Moses (Eckmann and Moses, 2002) EM O(m〈k2〉) 
Zhou & Lipowsky (Zhou and Lipowsky, 2004) ZL O(n3) 

Latapy & Pons (Latapy and Pons, 2005) LP O(n3) 

Clauset et al. (Clauset et al., 2004) NF O(n log2 n) 

Newman & Girvan (Newman and Girvan, 2004) NG O(nm2) 

Girvan & Newman (Girvan and Newman, 2002) GN O(n2m) 

Guimerà et al. (Guimerà and Amaral, 2005; Guimerà et al., 2004) SA parameter dependent 

Duch & Arenas (Duch and Arenas, 2005) DA O(n2 logn) 

Fortunato et al. (Fortunato et al., 2004) FLM O(m3n) 

Radicchi et al. (Radicchi et al., 2004) RCCLP O(m4/n2) 

Donetti & Muñoz (Donetti and Muñoz, 2004, 2005) DM/DMN O(n3) 

Bagrow & Bollt (Bagrow and Bollt, 2005) BB O(n3) 

Capocci et al. (Capocci et al., 2005) CSCC O(n2) 

Wu & Huberman (Wu and Huberman, 2004) WH O(n+m) 

Palla et al. (Palla et al., 2005) PK O(exp(n)) 

Reichardt & Bornholdt (Reichardt and Bornholdt, 2004) RB parameter dependent 

TABLE I List of the algorithm use in the comparative analysis of Danon et al. (Danon et al., 2005). The first column 
indicates the name of the algorithm designers, the second the original reference of the work, the third the symbol use to 
indicate the algorithm and the last the computational complexity of the technique. Adapted from Ref. (Danon et al., 2005). 

Author Ref. Label Order 

Girvan & Newman (Girvan and Newman, 2002; Newman and Girvan, 2004) GN O(nm2) 

Clauset et al. (Clauset et al., 2004) Clauset et al. O(n log2 n) 

Blondel et al. (Blondel et al., 2008) Blondel et al. O(m) 

Guimerà et al. (Guimerà and Amaral, 2005; Guimerà et al., 2004) Sim. Ann. parameter dependent 

Radicchi et al. (Radicchi et al., 2004) Radicchi et al. O(m4/n2) 

Palla et al. (Palla et al., 2005) Cfinder O(exp(n)) 

Van Dongen (Dongen, 2000a) MCL O(nk2), k < n parameter 

Rosvall & Bergstrom (Rosvall and Bergstrom, 2007) Infomod parameter dependent 

Rosvall & Bergstrom (Rosvall and Bergstrom, 2008) Infomap O(m) 

Donetti & Muñoz (Donetti and Muñoz, 2004, 2005) DM O(n3) 

Newman & Leicht (Newman and Leicht, 2007) EM parameter dependent 

Ronhovde & Nussinov (Ronhovde and Nussinov, 2009) RN O(mβ logn), β ∼ 1.3 

TABLE II List of the algorithm use in the comparative analysis of Lancichinetti and Fortunato (Lancichinetti and Fortunato, 
2009). The first column indicates the name of the algorithm designers, the second the original reference of the work, the third 
the symbol use to indicate the algorithm and the last the computational complexity of the technique. 

zout (6, 7 and 8), and represent the result for each algo- 
rithm a a group of three columns, indicate the average 
value of the similarity between the plant partition and 
the partition found by the method for each of the three 
zout-values. The similarity be measure in term of the 
fraction of correctly classify vertex (Section XV.A). 
The comparison show that modularity optimization via 
simulated anneal (Section VI.A.2) yield the best re- 
sults, although it be a rather slow procedure, that cannot 
be apply to graph of size of the order of 105 vertex or 
larger. On the other hand, we have already point out 
that the benchmark by Girvan and Newman be not a good 
representation of real graph with community structure, 
which be characterize by heterogeneous distribution 

of degree and community sizes. In this respect, the class 
of graph design by Lancichinetti et al. (LFR bench- 
mark) (Lancichinetti et al., 2008) (Section XV.A) pose 
a far more severe test to cluster techniques. For in- 
stance, many method have problem to detect cluster 
of very different size (like most method list in Ta- 
ble I). For this reason, Lancichinetti and Fortunato have 
carry out a careful comparative analysis of community 
detection method on the much more restrictive LFR 
benchmark (Lancichinetti and Fortunato, 2009). The al- 
gorithms chosen be list in Table II. In Fig. 33 the per- 
formances of the algorithm on the LFR benchmark be 
compared. Whenever possible, test on the version of 
the LFR benchmark with direct edges, weight edge 



81 

and/or overlap community (Lancichinetti and For- 
tunato, 2009) be carry out. Lancichinetti and For- 
tunato also test the method on random graphs, to 
check whether they be able to notice the absence of com- 
munity structure. From the result of all tests, the In- 
fomap method by Rosvall and Bergstrom (Rosvall and 
Bergstrom, 2008) appear to be the best, but also the 
algorithm by Blondel et al. (Blondel et al., 2008) and by 
Ronhovde and Nussinov (Ronhovde and Nussinov, 2009) 
have a good performance. These three method be also 
very fast, with a complexity which be essentially linear in 
the system size, so they can be apply to large systems. 
On the other hand, modularity-based method (with the 
exception of the method by Blondel et al.) have a rather 
poor performance, which worsens for large system and 
small communities, due to the well know resolution 
limit of modularity (Fortunato and Barthélemy, 2007). 
The performance of the remain method worsens con- 
siderably if one increase the system size (DM and Info- 
mod) or the community size (Cfinder, MCL and method 
by Radicchi et al.). 

Fan et al. have evaluate the performance of some al- 
gorithms to detect community on weight graph (Fan 
et al., 2007). The algorithm are: modularity maxi- 
mization, carry out with extremal optimization (WEO) 
(Section VI.A.3); the Girvan-Newman algorithm (WGN) 
(Section V.A); the Potts model algorithm by Reichardt 
and Bornholdt (Potts) (Section VIII.A). All these tech- 
niques have be originally introduce for unweighted 
graphs, but we have show that they can easily be ex- 
tend to weight graphs. The algorithm be test 
on the weight version of the benchmark of Girvan 
and Newman, that we discuss in Section XV.A. Edge 
weight have only two values: winter for inter-cluster 
edge and wintra for intra-cluster edges. Such value be 
link by the relation wintra + winter = 2, so they be 
not independent. For test one us realization of the 
benchmark with fix topology (i. e. fix zout) and vari- 
able weights. In Fig. 34 the comparative performance of 
the three algorithm be illustrated. The topology of the 
benchmark graph corresponds to zout = 8, i. e. to graph 
in which each vertex have approximately the same num- 
ber of neighbor inside and outside it community. By 
vary winter from 0 to 2 one go smoothly from a sit- 
uation in which most of the weight be concentrate inside 
the clusters, to a situation in which instead the weight be 
concentrate between the clusters. From Fig. 34 we see 
that WEO and Potts be more reliable methods. 

Sawardecker et al. have test method to detect 
overlap community (Sawardecker et al., 2009). 
They consider three algorithms: modularity opti- 
mization, the Clique Percolation Method (CPM) (Sec- 
tion XI.A) and the modularity landscape survey 
method by Sales-Pardo et al. (Sales-Pardo et al., 2007) 
(Section XII.B). For testing, Sawardecker et al. define 
a class of benchmark graph in which the link prob- 
ability between vertex be an increase function of the 
number of cluster the vertex belong to. We have de- 

0.2 0.4 0.6 0.80 
0.2 
0.4 
0.6 
0.8 

1 

0.2 0.4 0.6 0.80 
0.2 
0.4 
0.6 
0.8 

1 

0.2 0.4 0.6 0.8 
Mixing parameter µt 

0 
0.2 
0.4 
0.6 
0.8 

1 













N 
or 

m 
al 

iz 
ed 

M 
ut 

ua 
l I 

nf 
or 

m 
at 

io 
n 

0.2 0.4 0.6 0.80 
0.2 
0.4 
0.6 
0.8 

1 

N=1000, S 
N=1000, B 
N=5000, S 
N=5000, B 

Blondel et al. MCL 

Infomod Infomap 

0.2 0.4 0.6 0.80 
0.2 
0.4 
0.6 
0.8 

1 

0.2 0.4 0.6 0.80 
0.2 
0.4 
0.6 
0.8 

1 

0.2 0.4 0.6 0.8 
Mixing parameter µt 

0 
0.2 
0.4 
0.6 
0.8 

1 













N 
or 

m 
al 

iz 
ed 

M 
ut 

ua 
l I 

nf 
or 

m 
at 

io 
n 

0.2 0.4 0.6 0.80 
0.2 
0.4 
0.6 
0.8 

1 

N=1000, S 
N=1000, B 
N=5000, S 
N=5000, B 

Cfinder 

Clauset et al. 

Radicchi 
et al. Sim. ann. 

0 0.2 0.4 0.6 0.80 
0.2 
0.4 
0.6 
0.8 

1 

0 0.2 0.4 0.6 0.80 
0.2 
0.4 
0.6 
0.8 

1 

0 0.2 0.4 0.6 0.8 
Mixing parameter µt 

0 
0.2 
0.4 
0.6 
0.8 

1 













N 
or 

m 
al 

iz 
ed 

M 
ut 

ua 
l I 

nf 
or 

m 
at 

io 
n 

0 0.2 0.4 0.6 0.80 
0.2 
0.4 
0.6 
0.8 

1 

N=1000, S 
N=1000, B 
N=5000, S 
N=5000, B 

GN DM 

EM RN 

FIG. 33 Performances of several algorithm on the LFR 
benchmark (Lancichinetti and Fortunato, 2009). The plot 
show the normalize mutual information (in the version pro- 
pose in Ref. (Lancichinetti et al., 2009)) a a function of the 
mix parameter of the benchmark graphs. The different 
curve for each method refer to different system size (1000 
and 5000 vertices) and community size range [(S)=from 10 
to 50 vertices, (B)=from 20 to 100 vertices]. For the GN al- 
gorithm only the small graph size be adopted, due to the 
high complexity of the method, whereas for the EM method 
there be eight curve instead of four because for each set of 
benchmark graph the algorithm be run start from two 
different initial conditions. Reprinted figure with permission 
from Ref. (Lancichinetti and Fortunato, 2009). c©2009 by the 
American Physical Society. 



82 

0.0 0.2 0.4 0.6 0.8 1.0 

0.6 

0.7 

0.8 

0.9 

1.0 

WEO 
GN 
Pottsp 

re 
ci 
si 
on 

wout(a) 

0.0 0.2 0.4 0.6 0.8 1.0 

0.0 

0.2 

0.4 

0.6 

0.8 

1.0 

ac 
cu 

ra 
cy 



wout 

WEO 
GN 
Potts 

(b) 

FIG. 34 Comparative evaluation of the performance of al- 
gorithms to find community in weight graphs. Tests be 
carry out on a weight version of the benchmark of Girvan 
and Newman. The two plot show how good the algorithm 
be in term of the precision and accuracy with which they 
recover the plant partition of the benchmark. Precision in- 
dicates how close the value of similarity between the plant 
and the model partition be after repeat experiment with 
the same set of parameters; accuracy indicates how close the 
similarity value be to the ideal result (1) after repeat ex- 
periments with the same set of parameters. The similarity 
measure adopt here be base on the relative overlap of clus- 
ters of Eq. 97. We see that the maximization of modularity 
with extremal optimization (WEO) and the Potts model al- 
gorithm (Potts) be both precise and accurate a long a the 
weight of the inter-cluster edge winter remains low than 
the weight of the intra-cluster edge (winter < 1). Reprinted 
figure with permission from Ref. (Fan et al., 2007). c©2007 
by Elsevier. 

scribed this benchmark in Section XV.A. It turn out 
that the modularity landscape survey method be able 
to identify overlap between communities, a long a the 
fraction of overlap vertex be small. Curiously, the 
CPM, design to find overlap communities, have a 
poor performance, a the overlap vertex found by 
the algorithm be in general different from the overlap- 
ping vertex of the plant partition of the benchmark. 
The author also remark that, if the overlap between two 
cluster be not too small, it may be hard (for any method) 
to recognize whether the cluster be overlap or hi- 
erarchically organized, i. e. loosely connect cluster 
within a large cluster. 

We close the section with some general remark con- 
cerning testing. We have see that a test procedure 
require two crucial ingredients: benchmark graph with 
built-in community structure and cluster algorithm 
that try to recover it. Such two element be not inde- 
pendent, however, a they be both base on the concept 
of community. If the underlie notion of community 
for the benchmark and the algorithm be very different, 
one can hardly expect that the algorithm will do a good 
job on the benchmark. Furthermore, there be a third el- 
ement, i. e. the quality of a partition. All benchmark 
start from a situation in which community be clearly 
identified, i. e. connect component of the graph, and 
introduce some amount of noise, that eventually lead 
to a scenario where cluster be hardly or no longer de- 
tectable. It be then important to keep track of how the 
quality of the natural partition of the benchmark worsens 
a the amount of noise increases, in order to distinguish 
configuration in which the graph have a cluster struc- 
ture, that an algorithm should then be able to resolve, 
from configuration in which the noise prevails and the 
natural cluster be not meaningful. Moreover, quality 
function be important to evaluate the performance of 
an algorithm on graph whose community structure be 
unknown. Quality function be strongly related to the 
concept of community a well, a they be suppose to 
evaluate the goodness of the clusters, so they require a 
clear quantitative concept of what a cluster is. It be very 
important for any test framework to check for the mu- 
tual dependency between the benchmark, the quality 
function use to evaluate partitions, and the cluster 
algorithm to be tested. This issue have so far receive very 
little attention (Delling et al., 2007). Finally, empirical 
test be also very important, a one ultimately wish to 
apply cluster technique to real graphs. Therefore, it 
be crucial to collect more data set of graph whose com- 
munity structure be know or deducible from information 
on the vertex and their edges. 

XVI. GENERAL PROPERTIES OF REAL CLUSTERS 

What be the general property of partition and clus- 
ters of real graphs? In many paper on graph cluster 
application to real system be presented. In spite of the 



83 

10 
0 

10 
1 

10 
2 

10 
3 

10 
4 

10 
5 

10 
6 

10 
−4 

10 
−3 

10 
−2 

10 
−1 

10 
0 

community size 

1− 
cd 

f, 
P 

(k 
> 

x) 
amazon0308 
guide, α =−2.045 

FIG. 35 Cumulative distribution of community size for the 
Amazon purchasing network. The partition be derive by 
greedy modularity optimization. Reprinted figure with per- 
mission from Ref. (Clauset et al., 2004). c©2004 by the Amer- 
ican Physical Society. 

variety of cluster method that one could employ, in 
many case partition derive from different technique 
be rather similar to each other, so the general property 
of cluster do not depend much on the particular algo- 
rithm used. The analysis of cluster and their property 
delivers a mesoscopic description of the graph, where the 
communities, and not the vertices, be the elementary 
unit of the topology. The term mesoscopic be use be- 
cause the relevant scale here lie between the scale of the 
vertex and that of the full graph. 

One of the first issue address be whether the com- 
munities of a graph be usually about of the same size or 
whether the community size have some special distribu- 
tion. Most cluster technique consistently find skewed 
distribution of community sizes, with a tail described 
with good approximation by a power law (at least, a 
sizeable portion of the curve) with exponent in the range 
between 1 and 3 (Clauset et al., 2004; Danon et al., 2007; 
Newman, 2004a; Palla et al., 2005; Radicchi et al., 2004). 
So, there seem to be no characteristic size for a commu- 
nity: small community usually coexist with large ones. 
As an example, Fig. 35 show the cumulative distribution 
of community size for a recommendation network of the 
online vendor Amazon.com. Vertices be product and 
there be a connection between item A and B if B be 
frequently purchase by buyer of A. Recall that the 
cumulative distribution be the integral of the probability 
distribution: if the cumulative distribution be a power law 
s−α, the probability distribution be also a power law with 
exponent −(α+ 1). 

Leskovec et al. (Leskovec et al., 2008) have go one 
step further. They carry out a systematic analysis of 
community in large real networks, include traditional 
and on-line social networks, technological, information 

network and web graphs. The main goal be to ass 
the quality of community at various sizes. As a qual- 
ity function the conductance of the cluster be chosen. 
We remind that the conductance of a cluster be the ratio 
between the cut size of the cluster and the minimum be- 
tween the total degree of the cluster and that of the rest 
of the graph (Section IV.A). So, if the cluster be much 
small than the whole graph, the conductance equal 
the ratio between the cut size and the total degree of 
the cluster. Since a “good” cluster be characterize by 
a low cut size and a large internal density of edges, low 
value of the conductance indicate good clusters. For 
each real network Leskovec et al. derive the network 
community profile plot (NCPP), show the minimum 
conductance score among subgraphs of a give size a a 
function of the size. Interestingly, they found that the 
NCPPs of all network they study have a characteris- 
tic shape: they go downwards up until subgraphs with 
about 100 vertices, and then they rise monotonically for 
large subgraphs (Fig. 36). This seem to suggest that 
community be well define only when they be fairly 
small in size. Such small cluster be weakly connect 
to the rest of the graph, often by a single edge (in this 
case they be call whiskers), and form the periphery of 
the network. The other vertex form a big core, in which 
large cluster be well connect to each other, and be 
therefore barely distinguishable (Fig. 36). Leskovec et 
al. perform low-conductance cut with several meth- 
ods, to ensure that the result be not a simple artefact of 
a particular chosen technique. Moreover, they have also 
verify that, for large real network with know com- 
munity structure (such as, e.g., the social network of the 
on-line blogging site LiveJournal, with it user groups), 
the NCPP have the same qualitative shape if one take the 
real community instead of low-conductance subgraphs. 
The analysis by Leskovec et al. may shed new light on our 
understand of community structure and it detection 
in large networks. The fact that the “best” community 
appear to have a characteristic size of about 100 vertex 
be consistent with Dunbar conjecture that 150 be the up- 
per size limit for a work human community (Dunbar, 
1998). On the other hand, if large community be very 
mixed with each other, a Leskovec et al. claim, they 
could hardly be consider communities, and the allege 
“community structure” of large network would be lim- 
ited to their peripheral region. The result by Leskovec 
et al. may be affected by the property of conductance, 
and need to be validate with alternative approaches. In 
any case, whatever the value of the quality score of a clus- 
ter may be (low or high), it be necessary to estimate the 
significance of the cluster (Section XIV), before decide 
whether it be a meaningful structure or not. 

If the community structure of a graph be known, it 
be possible to classify vertex accord to their role 
within their community, which may allow to infer individ- 
ual property of the vertices. A promising classification 
have be propose by Guimerà and Amaral (Guimerà 
and Amaral, 2005; Guimerà and Amaral, 2005). The 



84 

FIG. 36 Analysis of community in large real network by 
Leskovec et al. (Leskovec et al., 2008). (Left) Typical shape 
of the network community profile plot (NCPP), show how 
the minimum conductance of subgraphs of size n varies with 
n. The plot indicates that the “best” community have a size 
of about 100 vertex (minimum of the curve), whereas com- 
munities of large size be not well-defined. In the plot two 
other NCPPs be shown: the one label Rewired network cor- 
responds to a randomize version of the network, where edge 
be randomly rewire by keep the degree distribution; the 
one label Bag of whisker give the minimum conductance 
score of cluster compose of disconnect pieces. (Right) 
Scheme of the core-periphery structure of large social and in- 
formation network derive by Leskovec et al. base on the 
result of their empirical analysis. Most of the vertex be in 
a central core, which do not have a clear community struc- 
ture, whereas the best communities, which be rather small, 
be weakly connect to the core. Reprinted figure with per- 
mission from Ref. (Leskovec et al., 2008). 

role of a vertex depends on the value of two indices, the 
within-module degree and the participation ratio (though 
other variable may be chosen, in principle). The within- 
module degree zi of vertex i be define a 

zi = 
κi − κ̄si 
σκsi 

, (98) 

FIG. 37 Regions of the z − P plane define the role of 
vertex in the modular structure of a graph, accord to the 
scheme of Guimerà and Amaral (Guimerà and Amaral, 2005; 
Guimerà and Amaral, 2005). Reprinted figure with permis- 
sion from Ref. (Guimerà and Amaral, 2005). c©2005 by the 
Nature Publishing Group. 

where κi be the internal degree of i in it cluster si, κ̄si and 
σκsi the average and standard deviation of the internal 
degree for all vertex of cluster si. The within-module 
degree be then define a the z-score of the internal degree 
κi. Large value of z indicate that the vertex have many 
more neighbor within it community than most other 
vertex of the community. Vertices with z ≥ 2.5 be 
classify a hubs, if z < 2.5 they be non-hubs. The 
participation ratio Pi of vertex i be define a 

Pi = 1− 
nc∑ 
s=1 

( 
κis 
ki 

)2 
. (99) 

Here κis be the internal degree of i in cluster s, ki the 
degree of i. Values of P close to 1 indicate that the 
neighbor of the vertex be uniformly distribute among 
all clusters; if all neighbor be within the cluster of the 
vertex, instead, P = 0. Based on the value of the 
pair (z, P ), Guimerà and Amaral distinguish seven 
role for the vertices. Non-hub vertex can be ultra- 
peripheral (P ≈ 0), peripheral (P < 0.625), connector 
(0.625 < P < 0.8) and kinless vertex (P > 0.8). Hub 
vertex be classify in provincial hub (P <∼ 0.3), 
connector hub (0.3 < P < 0.75) and kinless hub 
(P > 0.75). The region of the z − P plane correspond- 
ing to the seven role be highlight in Fig. 37. We 
stress that the actual boundary of the region can be 
chosen rather arbitrarily. On graph without commu- 
nity structure, like Erdös-Rényi (Erdös and Rényi, 1959) 



85 

random graph and Barabási-Albert (Barabási and Al- 
bert, 1999) graph (Section A.3), non-hubs be mostly 
kinless vertices. In addition, if there be hubs, like in 
Barabási-Albert graphs, they be kinless hubs. Kinless 
hub (non-hubs) vertex have less than half (one third) of 
their neighbor inside any cluster, so they be not clearly 
associate to a cluster. On real graphs, the topologi- 
cal role can be correlate to function of vertices: in 
metabolic networks, for instance, connector hubs, which 
share most edge with vertex of other cluster than their 
own, be often metabolite which be more conserve 
across specie than other metabolites, i. e. they have 
an evolutionary advantage (Guimerà and Amaral, 2005). 

If community be overlapping, one can explore other 
statistical properties, like the distribution of the over- 
lap and of the vertex memberships. The overlap be de- 
fin a the number of vertex share by each pair of 
overlap clusters; the membership of a vertex be the 
number of community include the vertex. Both dis- 
tributions turn out to be skewed, so there seem to be no 
characteristic value for the overlap and the membership. 
Moreover, one could derive a network, where the commu- 
nities be the vertex and pair of vertex be connect 
if their correspond community overlap (Palla et al., 
2005). Such network seem to have some special proper- 
ties. For instance, the degree distribution be a particular 
function, with an initial exponential decay follow by 
a slow power law decay31. We stress that the above 
result have be obtain with the Clique Percolation 
Method by Palla et al. (Section XI.A) and it be not clear 
whether other technique would confirm them or not. In 
a recent analysis it have be show that the degree dis- 
tribution of the network of community can be repro- 
duced by assume that the graph grows accord to a 
simple preferential attachment mechanism, where com- 
munities with large degree have an enhance chance to 
interact/overlap with new community (Pollner et al., 
2006). 

XVII. APPLICATIONS ON REAL-WORLD NETWORKS 

The ultimate goal of cluster algorithm be try- 
ing to infer property of and relationship between 
vertices, that be not available from direct observa- 
tion/measurement. If the scientific community agrees on 
a set of reliable techniques, one could then proceed with 
careful investigation of system in various domains. So 
far, most work in the literature on graph cluster fo- 
cused on the development of new algorithms, and appli- 
cation be limited to those few benchmark graph that 
one typically us for test (Section XV.A). Still, there 

31 This hold for the network consider by Palla et al. (Palla et al., 
2005) like, e. g., the word association network (Section II) and a 
coauthorship network of physicists. There be no a priori reason 
to believe that this result be general. 

be also application aim at understand real sys- 
tems. Some result have be actually mention in the 
previous sections. This section be suppose to give a fla- 
vor of what can be do by use cluster algorithms. 
Therefore, the list of work present here be by no mean 
exhaustive. Most study focus on biological and social 
networks. We mention a few application to other type 
of network a well. 

A. Biological network 

The recent abundance of genomic data have allow u 
to explore the cell at an unprecedented depth. A wealth 
of information be available on interaction involve pro- 
teins and genes, metabolic processes, etc. In order to 
study cellular systems, the graph representation be regu- 
larly used. Protein-protein interaction network (PIN), 
gene regulatory network (GRN) and metabolic network 
(MN) be meanwhile standard object of investigation in 
biology and bioinformatics (Junker and Schreiber, 2008). 

Biological network be characterize by a remarkable 
modular organization, reflect functional association 
between their components. For instance, protein tend 
to be associate in two type of cellular modules: protein 
complex and functional modules. A protein complex be 
a group of protein that mutually interact at the same 
time and space, form a sort of physical object. Exam- 
ples be transcription factor complexes, protein transport 
and export complexes, etc. Functional module instead 
be group of protein take place in the same cellu- 
lar process, even if the interaction may happen at dif- 
ferent time and places. Examples be the CDK/cyclin 
module, responsible for cell-cycle progression, the yeast 
pheromone response pathway, etc.. Identifying cellular 
module be fundamental to uncover the organization and 
dynamic of cell functions. However, the information on 
cell unit (e. g. proteins, genes) and their interaction be 
often incomplete, or even incorrect, due to noise in the 
data produce by the experiments. Therefore, infer 
module from the topology of cellular network enables 
one to restrict the set of possible scenario and can be a 
safe guide for future experiments. 

Rives and Galitski (Rives and Galitski, 2003) stud- 
ied the modular organization of a subset of the PIN 
of the yeast (Saccharomyces cerevisiae), consist of 
the (signaling) protein involve in the process lead- 
ing the microorganism to a filamentous form. The clus- 
ters be detect with a hierarchical cluster tech- 
nique. Proteins mostly interact with member of their 
own cluster be often essential proteins; edge between 
module be important point of communication. Spirin 
and Mirny (Spirin and Mirny, 2003) identify protein 
complex and functional module in yeast with different 
techniques: clique detection, superparamagnetic cluster- 
ing (Blatt et al., 1996) and optimization of cluster edge 
density. They estimate the statistical significance of the 
cluster by compute the p-values of see those clus- 



86 

ters in random graph with the same expect degree 
sequence a the original network. From the know func- 
tional annotation of yeast gene one can see that the 
module usually group protein with the same or con- 
sistent biological functions. Indeed, in many cases, the 
module exactly coincide with know protein complexes. 
The result appear robust if noise be introduce in the 
system, to simulate the noise present in the experimental 
data. Functional module in yeast be also found by 
Chen and Yuan (Chen and Yuan, 2006), who apply the 
algorithm by Girvan and Newman with a modify defi- 
nition of edge betweenness (Section V.A). The standard 
Girvan-Newman algorithm have prove to be reliable to 
detect functional module in PINs (Dunn et al., 2005). 
The novelty of the work by Chen and Yuan be it focus 
on weight PINs, where the weight come from infor- 
mation derive through microarray expression profiles. 
Weights add information about the system and should 
lead to a more reliable modular structure. By knock 
out gene in the same structural cluster similar pheno- 
type appeared, suggest that the gene have similar 
biological roles. Moreover, the cluster often contain 
know protein complexes, either entirely or to a large 
extent. Finally, Chen and Yuan be able to make pre- 
diction of the unknown function of some genes, base on 
the structural module they belong to: gene function pre- 
diction be the most promising outcome derive from the 
application of cluster technique to PINs. Farutin et 
al. (Farutin et al., 2006) have adopt a local concept of 
community, and derive a hierarchical decomposition of 
PINs, in that the module identify at some level become 
the vertex of a network at the high level. Communi- 
tie be overlapping, to account for the fact that protein 
(and whole modules) may have diverse biological func- 
tions. High level structure detect in a human PIN cor- 
respond to general biological concept like signal trans- 
duction, regulation of gene expression, intercellular com- 
munication. Sen et al. (Sen et al., 2006) identify protein 
cluster for yeast from the eigenvectors of the Laplacian 
matrix (Section A.2), compute via Singular Value De- 
composition. In a recent analysis, Lewis et al. (Lewis 
et al., 2009) carefully explore the relationship between 
structural community of PINs and their biological func- 
tion. Communities be detect with the multiresolu- 
tion approach by Reichardt and Bornholt (Reichardt and 
Bornholdt, 2006a) (Section VI.B). A community be con- 
sidered biologically homogeneous if the functional simi- 
larity between protein pair of the community (extracted 
through the Gene Ontology database (Ashburner et al., 
2000)) be large than the functional similarity between all 
protein pair of the network. Lewis et al. also specify 
the comparison to interact and non-interacting pro- 
tein pairs. As a result, many community turn out to 
be biologically homogeneous, especially if they be not 
too small. Moreover, some topological attribute of com- 
munities, like the within-community cluster coefficient 
(i.e. the average value of the cluster coefficient of 
the vertex of a community, compute by consider 

just the neighbor belonging to the community) and link 
density (density of internal edges), be good indicator 
of biological homogeneity: the former be strongly corre- 
lated with biological homogeneity, independently of the 
community size, whereas for the latter the correlation be 
strong for large communities. 

Metabolic network have also be extensively investi- 
gated. We have already discuss the “functional cartog- 
raphy” design by Guimerà and Amaral (Guimerà and 
Amaral, 2005; Guimerà and Amaral, 2005), which applies 
to general type of networks, not necessarily metabolic. 
A hierarchical decomposition of metabolic network have 
be derive by Holme et al. (Holme et al., 2003), by 
use a hierarchical cluster technique inspire by the 
algorithm by Girvan and Newman (Section V.A). Here, 
vertex be remove base on their betweenness val- 
ues, which be obtain by divide the standard site 
betweenness score (Freeman, 1977) by the indegree of 
the respective vertices. A picture of metabolic network 
emerges, in which there be core cluster center at 
hub-substances, surround by outer shell of less con- 
nected substances, and a few other cluster at interme- 
diate scales. In general, cluster at different scale seem 
to be meaningful, so the whole hierarchy should be take 
into account. 

Wilkinson and Huberman (Wilkinson and Huber- 
man, 2004) analyze a network of gene co-occurrence 
to find group of related genes. The network be built 
by connect pair of gene that be mention to- 
gether in the abstract of article of the Medline database 
(http://medline.cos.com/). Clusters be found with 
a modify version of the algorithm by Girvan and New- 
man, in which edge betweenness be compute by consid- 
ering the shortest path of a small subset of all vertex 
pairs, to gain computer time (Section V.A). As a result, 
gene belonging to the same cluster turn out to be func- 
tionally related to each other. Co-occurrence of term be 
also use to extract association between gene and dis- 
eases, to find out which gene be relevant for a specific 
disease. Communities of gene related to colon cancer 
can be helpful to identify the function of the genes. 

B. Social network 

Networks depict social interaction between people 
have be study for decade (Scott, 2000; Wasserman 
and Faust, 1994). Recently the modern Information and 
Communication Technology (ICT) have open new in- 
teraction mode between individuals, like mobile phone 
communication and online interaction enable by the 
Internet. Such new social exchange can be accurately 
monitor for very large systems, include million of 
individuals, whose study represent a huge opportunity 
for social science. Communities of social network can 
be friendship circles, group of people share common 
interest and/or activities, etc.. 

Blondel et al. have analyze a network of mobile phone 



87 

FIG. 38 Community structure of a social network of mobile 
phone communication in Belgium. Dots indicate subcommu- 
nities at the low hierarchical level (with more than 100 peo- 
ple) and be color in a red-green scale to represent the level 
of representation of the two main language spoken in Belgium 
(red for French and green for Dutch). Communities of the two 
large group be linguistically homogeneous, with more than 
85% of people speak the same language. Only one commu- 
nity (zoomed), which lie at the border between the two main 
aggregations, have a more balance distribution of languages. 
Reprinted figure with permission from Ref. (Blondel et al., 
2008). c©2008 by IOP Publishing and SISSA. 

communication between user of a Belgian phone oper- 
ator (Blondel et al., 2008). The vertex of the graph be 
2.6 million and the edge be weight by the cumulative 
duration of phone call between user in the observation 
time frame. The cluster analysis, perform with a 
fast hierarchical modularity optimization technique de- 
veloped by the author (discussed in Section VI.A.1), de- 
liver six hierarchical levels. The high level consists 
of 261 group with more than 100 vertices, which be 
clearly arrange in two main groups, linguistically ho- 
mogeneous, reflect the linguistic split of Belgian pop- 
ulation (Fig. 38). Tyler et al. (Tyler et al., 2003) study 
a network of e-mail exchange between people work 
at HP Labs. They apply the same modify version of 
Girvan-Newman algorithm that two of the author have 
use to find community of related gene (Wilkinson and 
Huberman, 2004) (Section XVII.A). The method enables 
one to measure the degree of membership of each vertex 
in a community and allows for overlap between com- 
munities. The detect cluster match quite closely 
the organization of the Labs in department and project 
groups, a confirm by interview conduct with re- 

FIG. 39 Communities in social networking sites. (Top) Vi- 
sualization of a network of friendship between student at 
Caltech, construct from Facebook data (September 2005). 
The colors/shapes indicate the dormitory (Houses) of the 
students. (Bottom) Topological community of the network, 
which be quite homogeneous with respect to House affilia- 
tion. Reprinted figure with permission from Refs. (Porter 
et al., 2009) and (Traud et al., 2008). 

searchers. 

Social networking sites, like Myspace 
(www.myspace.com), Friendster (www.friendster.com), 
Facebook (www.facebook.com), etc. have become 
extremely popular in the last years. They be online 
platform that allow people to communicate with friends, 
send e-mails, solicit opinion on specific issues, spread 
idea and/or fads, etc. Traud et al. (Traud et al., 2008) 
use anonymous Facebook data to create network of 
friendship between student of different American uni- 
versities, where vertices/students be connect if they 
be friend on Facebook. Communities be detect by 
apply a variant of Newman’s spectral optimization 



88 

of modularity (Section VI.A.4): the result be further 
refine through additional step á la Kernighan-Lin 
(Section IV.A). One of the goal of the study be to 
infer relationship between the online and offline life 
of the students. By use demographic information on 
the students’ populations, one find that community 
be organize by class year or by House (dormitory) 
affiliation, depend on the university (Fig. 39). Yuta 
et al. (Yuta et al., 2007) observe a gap in the commu- 
nity size distribution of a friendship network extract 
from mixi (mixi.jp), the large social networking site 
in Japan (as of December 2006). Communities be 
identify with the fast greedy modularity optimization 
by Clauset et al. (Clauset et al., 2004). The gap occurs 
in the intermediate range of size between 20 and 400, 
where but a few community be observed. Yuta et al. 
introduce a model where people form new friendship 
both by “closing” tie with people who be friend of 
friends, and by set new link with individual have 
similar interests. In this way most group turn out to be 
either small or large, and medium size group be rare. 

Collaboration networks, in which individual be link 
if they be (were) involve in a common activity, have 
be often study because they embed an implicit ob- 
jective concept of acquaintance, that be not easy to cap- 
ture in direct social experiments/interviews. For in- 
stance, somebody may consider another individual a 
friend, while the latter may disagree. A collaboration 
instead be a proof of a social relationship between indi- 
viduals. The analysis of the structure of scientific collab- 
oration network (Newman, 2001) have exert a big influ- 
ence on the development of the modern network science. 
Scientific collaboration be associate to coauthorship: two 
scientist be link if they have coauthored at least one 
paper together. Information about coauthorships can 
be extract from different database of research papers. 
Communities indicate group of people with common re- 
search interests, i. e. topical or disciplinary groups. In 
the seminal paper by Girvan and Newman (Girvan and 
Newman, 2002), the author apply their method on a 
collaboration network of scientist work at the Santa 
Fe Institute, and be able to discriminate between re- 
search division (Fig. 2b). The community structure of 
scientific collaboration network have be investigate by 
many author (Danon et al., 2006; Donetti and Muñoz, 
2004; Duch and Arenas, 2005; Farkas et al., 2007; Gre- 
gory, 2007; Lehmann and Hansen, 2007; Nepusz et al., 
2008; Newman, 2004b, 2006a; Noack and Rotta, 2009; 
Palla et al., 2007, 2005; Pujol et al., 2006; Radicchi et al., 
2004; Reichardt and Bornholdt, 2006a; Richardson et al., 
2009; S.-W. Son et al., 2006; Shen et al., 2009; Vragović 
and Louis, 2006; White and Smyth, 2005; Zhou, 2003b). 
Other type of collaboration network have be study 
too. Gleiser and Danon (Gleiser and Danon, 2003) con- 
sidered a collaboration network of jazz musicians. Ver- 
tices be either musicians, connect if they played in the 
same band, or bands, connect if they have a musician 
in common. By apply the algorithm of Girvan and 

Newman they found that community reflect both racial 
segregation (with two main group comprise only black 
or white players) and geographical separation, due to the 
different record locations. 

C. Other network 

Citation network (de Solla Price, 1965) have be reg- 
ularly use to understand the citation pattern of author 
and to disclose relationship between disciplines. Rosvall 
and Bergstrom (Rosvall and Bergstrom, 2008) use a ci- 
tation network of over 6000 scientific journal to derive a 
map of science. They use a cluster technique base 
on compress the information on random walk take 
place on the graph (Section IX.B). A random walk fol- 
low the flow of citation from one field to another, and 
the field emerge naturally from the cluster analysis 
(Fig. 40). The structure of science resembles the letter U, 
with the social science and engineering at the terminals, 
join through a chain include medicine, molecular bi- 
ology, chemistry and physics. 

Reichardt and Bornholdt (Reichardt and Bornholdt, 
2007) perform a cluster analysis on a network built 
from bidding data take from the German version of 
Ebay (www.ebay.de), the most popular online auction 
site. The vertex be bidder and two vertex be con- 
nected if the correspond bidder have express in- 
terest for the same item. Clusters be detect with 
the multiresolution modularity optimization developed 
by the author themselves (Reichardt and Bornholdt, 
2006a) (Section VI.B). In spite of the variety of item 
that it be possible to purchase through Ebay, about 85% of 
bidder be classify into a few major clusters, reflect- 
ing bidders’ broad category of interests. Ebay data be 
also examine by Jin et al. (Jin et al., 2007), who consid- 
ered bidding network where the vertex be the individ- 
ual auction and edge be place between auction hav- 
ing at least one common bidder. Communities, detect 
with greedy modularity optimization (Newman, 2004b) 
(Section VI.A.1), allow to identify substitute goods, i. e. 
product that have value for the same bidder, so that 
they can be purchase together or alternatively. 

Legislative network enable one to deduce association 
between politician through their parliamentary activity, 
which may be related or not to party affiliation. Porter 
and coworkers have carry out numerous study on the 
subject (Porter et al., 2007, 2005; Zhang et al., 2008), 
by use data on the Congress of the United States. In 
Refs. (Porter et al., 2007, 2005), they examine the com- 
munity structure of network of committee in the US 
House of Representatives. Committees share common 
member be connect by edges, which be weight by 
divide the number of common member by the num- 
ber one would expect to have if committee membership 
be randomly assigned. Hierarchical cluster (Sec- 
tion IV.B) reveals close connection between some of 
the committees. In another work (Zhang et al., 2008), 



89 

Molecular & Cell Biology 

Medicine 

Physics 

Ecology & Evolution 

Economics 

Geosciences 

Psychology 

Chemistry 

Psychiatry 

Environmental Chemistry & Microbiology 

Mathematics 

Computer Science 

Analytic ChemistryBusiness & Marketing 

Political Science 

Fluid Mechanics 

Medical Imaging 

Material Engineering 

Sociology 

Probability & Statistics 

Astronomy & Astrophysics 

Gastroenterology 

Law 

Chemical Engineering 

Education 

Telecommunication 

Control Theory 

Operations Research 

Ophthalmology 

Crop Science 

Geography 

Anthropology 

Computer Imaging 

Agriculture 

Parasitology 

Dentistry 

Dermatology 

Urology 

Rheumatology 

Applied Acoustics 

Pharmacology 

Pathology 

Otolaryngology 

Electromagnetic Engineering 

Circuits 

Power Systems 

Tribology 

Neuroscience 

Orthopedics Veterinary 

Environmental Health 

A 

Citation flow from B to A 
Citation flow within field 

Citation flow from A to B 
Citation flow out of field 

B 

FIG. 40 Map of science derive from a cluster analysis of a citation network comprise more than 6000 journals. Reprinted 
figure with permission from Ref. (Rosvall and Bergstrom, 2008). c©2008 by the National Academy of Science of the USA. 

Zhang et al. analyze network of legislation cospon- 
sorship, in which vertex be legislator and two legisla- 
tor be link if they support at least one common bill. 
Communities, identify with a modification of Newman’s 
spectral optimization of modularity (Section VI.A.4), be 
correlate with party affiliation, but also with geography 
and committee membership of the legislators. 

Networks of correlation between time series of stock 
return have receive a grow attention in the past few 
year (Mantegna, 1999). In early studies, scholar found 
cluster of correlate stock by compute the maximum 
span tree of the network (Bonanno et al., 2003, 2000; 
Onnela et al., 2003, 2002) (Section A.1), and realize 

that such cluster match quite well the economic sector 
of the stocks. More recently, the community structure of 
the network have be investigate by mean of proper 
cluster algorithms. Farkas et al. (Farkas et al., 2007) 
have apply the weight version of the Clique Percola- 
tion Method (Section XI.A) and found that the presence 
of two strong (i. e. carry high correlation) edge in tri- 
angle be usually accompany by the presence of a strong 
third edge. Heimo et al. (Heimo et al., 2008) use the 
weight version of the multiresolution method by Re- 
ichardt and Bornholdt (Reichardt and Bornholdt, 2006a) 
(Section VI.B). Clusters correspond to relevant business 
sectors, a indicate by Forbes classification; moreover, 



90 

small cluster at low hierarchical level seem to corre- 
spond to (economically) meaningful substructure of the 
main clusters. 

XVIII. OUTLOOK 

Despite the remote origin and the great popularity of 
the last years, research on graph cluster have not yet 
give a satisfactory solution of the problem and leaf 
u with a number of important open issues. From our 
exposition it appear that the field have grown in a rather 
chaotic way, without a precise direction or guidelines. In 
some cases, interest new idea and tool have be pre- 
sented, in others exist method have be improved, 
become more accurate and/or faster. 

What the field lack the most be a theoretical frame- 
work that defines precisely what cluster algorithm 
be suppose to do. Everybody have his/her own idea of 
what a community is, and most idea be consistent with 
each other, but, a long a there be still disagreement, it 
remains impossible to decide which algorithm do the 
best job and there will be no control on the creation of 
new methods. Therefore, we believe that the first and 
foremost task that the scientific community work on 
graph cluster have to solve in the future be define a set 
of reliable benchmark graphs, against which algorithm 
should be test (Section XV.A). Defining a benchmark 
go far beyond the issue of testing. It mean design 
practical example of graph with communities, and, in 
order to do that, one have to agree on the fundamental 
concept of community and partition. Clustering algo- 
rithms have to be devise consistently with such defini- 
tions, in order to give the best performance on the set of 
designate benchmarks, which represent a sort of ground 
truth. The explosion in the number of algorithm we have 
witness in recent time be due precisely to the present 
lack of reliable mechanism of control of their quality 
and comparison of their performances. If the commu- 
nity agrees on a benchmark, the future development of 
the field will be more coherent and the progress brought 
by new method can be evaluate in an unbiased man- 
ner. The plant `-partition model (Condon and Karp, 
2001) be the easy recipe one can think of when it come 
to define clusters, and be the criterion underlie well- 
know benchmarks, like that by Girvan and Newman. 
We believe that the new benchmark have to be define 
along the same lines. The benchmark graph recently in- 
troduced by Lancichinetti et al. (Lancichinetti and Fortu- 
nato, 2009; Lancichinetti et al., 2008) and by Sawardecker 
et al. (Sawardecker et al., 2009) be an important step in 
this direction. 

Defining a benchmark implies specify the “natural” 
partition of a graph, the one that any algorithm should 
find. This issue in turn involves the concept of quality 
of a partition, that have characterize large part of the 
development of the field, in particular after the intro- 
duction of Newman-Girvan modularity (Section III.C.2). 

Estimating the quality of a partition allows to discrimi- 
nate among the large number of partition of a graph. In 
some case this be not difficult. For instance, in the bench- 
mark by Girvan and Newman there be a single meaningful 
partition, and it be hard to argue with that. But most 
graph of the real world have a hierarchical structure, 
with community include small community and so 
on. Hence there be several meaningful partitions, cor- 
respond to different hierarchical levels, and discrimi- 
nating among them be hard, a they may be all relevant, 
in a sense. If we consider the human body, we cannot 
say that the organization in tissue of the cell be more 
important than the organization in organs. We have see 
that there be recent method deal with the problem of 
find meaningful hierarchical level (Section XII). Such 
method rank the hierarchical partition base on some 
criterion and one can ass their relevance through the 
ranking. One may wonder whether it make sense sort 
out levels, which mean introduce a kind of threshold 
on the quality index chosen to rank partition (to dis- 
tinguish “good” from “bad” partitions), or whether it 
be more appropriate to keep the information give by the 
whole set of hierarchical partitions. The work by Clauset 
et al. on hierarchical random graph (Clauset et al., 
2007; Clauset et al., 2008), discuss in Section XII.B, 
indirectly raise this issue. There it be show that the 
ensemble of model graphs, represent by dendrograms, 
encodes most of the information on the structure of the 
graph at study, like it degree distribution, transitivity 
and distribution of shortest path lengths. At the same 
time, by construction, the model reveals the whole hier- 
archy of communities, without any distinction between 
good and bad partitions. The information give by a 
dendrogram may become redundant and confuse when 
the graph be large, a then there be a big number of par- 
titions. This be actually the reason why quality function 
be originally introduced. However, in that case, one 
be deal with artificial hierarchies, produce by tech- 
niques that systematically yield a dendrogram a a result 
of the analysis (like, e. g., hierarchical clustering), re- 
gardless of whether the graph actually have a hierarchical 
structure or not. Here instead we speak of real hierarchy, 
which be a fundamental element of real graph and, a 
such, it must be consider in any serious approach to 
graph clustering. Any good cluster method must be 
able to tell whether a graph have community structure or 
not, and, in the first case, whether the community struc- 
ture be hierarchical (i. e. with two or more levels) or flat 
(one level). We expect that the concept of hierarchy will 
become a key ingredient of future cluster techniques. 
In particular, assess the consistence of the concept of 
partitions’ quality and hierarchical structure be a major 
challenge. 

A precise definition of null models, i. e. of graph with- 
out community structure, be also missing. This aspect be 
extremely important, though, a define community 
also implies decide whether or not they exist in a spe- 
cific graph. At the moment, it be generally accepted that 



91 

random graph have no communities. The null model 
of modularity (Section III.C.2), by far the most popu- 
lar, comprises all graph with the same expect degree 
sequence of the original graph and random rewire of 
edges. This class of graph be characterized, by construc- 
tion, by the fact that any vertex can be link to any 
other, a long a the constraint on the degree sequence 
be satisfied. But this be by no mean the only possibility. 
A community can be generically define a a subgraph 
whose vertex have a high probability to be connect 
to the other vertex of the subgraph than to external 
vertices. The plant `-partition model (Condon and 
Karp, 2001) be base on this principle, a we have seen. 
However, this do not mean that the link probabili- 
tie of a vertex with respect to the other vertex in it 
community or in different community be constant (or 
simply proportional to their degrees, a in the configura- 
tion model ( Luczak, 1992; Molloy and Reed, 1995)). In 
fact, in large network it be reasonable to assume that the 
probability that a vertex be link to most vertex be zero, 
a the vertex “ignores” their existence. This do not ex- 
clude that the probability that the vertex get connect 
to the “known” vertex be the same (or proportional to 
their degrees), in which case the graph would still be ran- 
dom and have no communities. We believe that we be 
still far from a precise definition and a complete clas- 
sification of null models. This represent an important 
research line for the future of the field, for three main rea- 
sons: 1) to good disentangle “true” community from 
byproduct of random fluctuations; 2) to pose a stringent 
test to exist and future cluster algorithms, whose 
reliability would be questionable if they found “false pos- 
itives” in null model graphs; 3) to handle “hybrid” sce- 
narios, where a graph display community structure on 
some portion of it, while the rest be essentially random 
and have no communities. 

In the previous chapter we have see a great number 
of cluster techniques. Which one(s) shall we use? At 
the moment the scientific community be unable to tell. 
Modularity optimization be probably the most popular 
method, but the result of the analysis of large graph 
be likely to be unreliable (Section VI.C). Nevertheless, 
people have become accustom to use it, and there have 
be several attempt to improve the measure. A new- 
comer, who wish to find cluster in a give network 
and be not familiar with cluster techniques, would not 
know, off-hand, which method to use, and he/she would 
hardly find indication about good method in any single 
paper on graph clustering, except perhaps on the method 
present in the paper. So, people keep use algorithm 
because they have heard of them, or because they know 
that other people be use them, or because of the rep- 
utation of the scientist who design them. Waiting 
for future reliable benchmarks, that may give an objec- 
tive assessment of the quality of the algorithms, there 
be at the moment hardly solid reason to prefer an algo- 
rithm to another: the comparative analysis by Danon et 
al. (Danon et al., 2005) and by Lancichinetti and Fortu- 

nato (Lancichinetti and Fortunato, 2009) (Section XV.C) 
represent a first serious assessment of this issue. However, 
we want to stress that there be no such thing a the perfect 
method, so it be pointless to look for it. Among the other 
things, if one try to look for a very general method, that 
should give good result on any type of graphs, one be in- 
evitably force to make very general assumption on the 
structure of the graph and on the property of communi- 
ties. In this way one neglect a lot of specific feature of 
the system, that may lead to a more accurate detection 
of the clusters. Informing a method with feature charac- 
terizing some type of graph make it far more reliable 
to detect the community structure of those graph than a 
general method, even if it applicability may be limited. 
Therefore in the future we envision the development of 
domain-specific cluster techniques. The challenge here 
be to identify the peculiar feature of class of graphs, 
which be bound to become crucial ingredient in the de- 
sign of suitable algorithms. Some of the method avail- 
able today be actually base on assumption that hold 
only for some specific category of graphs. The Clique 
Percolation Method by Palla et al. (Palla et al., 2005), 
for instance, may work well for graph characterize by 
a large number of cliques, like certain social networks, 
whereas it may give poor result otherwise. 

Moving one step further, one should learn how to use 
specific information about a graph, whenever available, 
e. g. property of vertex and/or partial information 
about their classification. For instance, it may be that 
one have some information on a subset of vertices, like 
demographic data on people of a social network, and such 
data may highlight relationship between people that be 
not obvious from the network of social interactions. In 
this case, use only the social network may be reductive 
and ideally one should exploit both the structural and 
the non-structural information in the search of clusters, 
a the latter should be consistent with both inputs. How 
to do this be an open problem. The scientific community 
have just begin to study this aspect (Allahverdyan and 
Galstyan, 2009). 

Most algorithm in the literature deal with the “clas- 
sical” case of a graph with undirected and unweighted 
edges. This be certainly the simplest case one could think 
of, and graph cluster be already a complex task on such 
type of graphs. We know that real network may be 
directed, have weight connections, be bipartite. Meth- 
od to deal with such system have be developed, a 
we have seen, especially in the most recent literature, 
but they be mostly preliminary attempt and there be 
room for improvement. Another situation that may oc- 
cur in real system be the presence of edge with posi- 
tive and negative weights, indicate attractive and re- 
pulsive interactions, respectively. This be the case, for 
instance, of correlation data (Mantegna, 1999). In this 
case, ideal partition would have positively weight intr- 
acluster edge and negatively weight intercluster edges. 
We have discuss some study in this direction (Gómez 
et al., 2009; Kaplan and Forrest, 2008; Traag and Brugge- 



92 

man, 2009), but we be just at the begin of this en- 
deavour. Instead, there be no algorithm yet which be 
capable to deal with graph in which there be edge of 
several types, indicate different kind of interaction 
between the vertex (multigraphs). Agents of social net- 
works, for instance, may be join by work relation- 
ships, friendship, family ties, etc. At the moment there 
be essentially two way of proceed in these instances: 
1) keep edge of one type and forget the others, 
repeat the analysis for each type of edge and eventu- 
ally compare the result obtained; 2) analyze a single 
(weighted) graph, obtain by “combining” the contribu- 
tions of the different type of edge in some way. Finally, 
since most real network be built through the result 
of experiments, which carry error in their estimates, it 
would be useful to consider a well the case in which edge 
have not only associate weights, but also error on their 
values. 

Since the paper by Palla et al. (Palla et al., 2005), 
overlap community have receive a lot of attention 
(Section XI). However, there be still no consensus about 
a quantitative definition of the concept of overlap 
community, and most definition depend on the method 
adopted. Intuitively, one would expect that cluster share 
vertex lie at their borders, and this idea have inspire 
most algorithms. However, cluster detect with the 
Clique Percolation Method (Section XI.A) often share 
central vertex of the clusters, which make sense in spe- 
cific instances, especially in social networks. So, it be still 
unclear how to characterize overlap vertices. More- 
over, the concept of overlap cluster seem at odds 
with that of hierarchical structure. No dendrogram can 
be drawn if there be overlap vertices, at least in the 
standard way. Due to the relevance of both feature in 
real networks, it be necessary to adapt them to each other 
in a consistent way. Overlapping vertex pose problem 
a well when it come to compare the result of different 
method on the same graph. Most similarity measure 
be define only in the case of partitions, where each ver- 
tex be assign to a single cluster (Section XV.B). It be 
then necessary to extend such definition to the case of 
overlap communities, whenever possible. 

Another issue that be get increasingly more popular 
be the study of graph evolve in time. This be now pos- 
sible due to the availability of timestamped network data 
sets. Tracking the evolution of community structure in 
time be very important, to uncover how community be 
generate and how they interact with each other. Schol- 
ar have just begin to study this problem (Asur et al., 
2007; Chakrabarti et al., 2006; Chi et al., 2007; Fenn 
et al., 2009; Hopcroft et al., 2004; Kim and Han, 2009; 
Lin et al., 2008; Palla et al., 2007; Sun et al., 2007) (Sec- 
tion XIII). Typically one analyzes separately snapshot 
at different time and check what happen at time t+1 
to the community at time t. It would be probably bet- 
ter to use simultaneously the whole dynamic data set, 
and future work shall aim at define proper way to do 
that. In this respect, the evolutionary cluster frame- 

work by Chakrabarti et al. (Chakrabarti et al., 2006) be 
a promising start point. 

The computational complexity of graph cluster al- 
gorithms have improve by at least one power in the graph 
size (on average) in just a couple of years. Due to the 
large size of many system one wish to investigate, the 
ultimate goal would be to design technique with lin- 
ear or even sublinear complexity. Nowadays partition 
in graph with up to million of vertex can be found. 
However, the result be not yet very reliable, a they be 
usually obtain by greedy optimizations, which yield 
rough approximation of the desire solution. In this 
respect the situation could improve by focus on the 
development of efficient local methods, for two reasons: 
1) they enable analysis of portion of the graph, indepen- 
dently of the rest; 2) they be often suitable for parallel 
implementations, which may speed up considerably the 
computation. 

Finally, if there have be a tremendous effort in the de- 
sign of cluster algorithms, basically nothing have be 
do to make sense of their results. What shall we do 
with communities? What can they tell u about a sys- 
tem? The hope be that they will enable one to disclose 
“hidden” relationship between vertices, due to feature 
that be not known, because they be hard to measure, 
for instance. It be quite possible that the scientific com- 
munity will converge sooner or late to a definition a 
posteriori of community. Already now, most algorithm 
yield similar result in practical applications. But what 
be the relationship between the vertex classification give 
by the algorithm and real classifications? This be the 
main question beneath the whole endeavor. 

Acknowledgments 
I be indebted to these people for give useful sugges- 

tions and advice to improve this manuscript at various 
stages: A. Arenas, J. W. Berry, A. Clauset, P. Csermely, 
S. Gómez, S. Gregory, V. Gudkov, R. Guimerà, Y. Is- 
polatov, R. Lambiotte, A. Lancichinetti, J.-P. Onnela, 
G. Palla, M. A. Porter, F. Radicchi, J. J. Ramasco, C. 
Wiggins. I gratefully acknowledge ICTeCollective, grant 
number 238597 of the European Commission. 

Appendix A: Elements of Graph Theory 

1. Basic Definitions 

A graph G be a pair of set (V,E), where V be a set 
of vertex or node and E be a subset of V 2, the set of 
unordered pair of element of V . The element of E be 
call edge or links, the two vertex that identify an edge 
be call endpoints. An edge be adjacent to each of it 
endpoints. If each edge be an order pair of vertex one 
have a direct graph (or digraph). In this case an order 
pair (v, w) be an edge direct from v to w, or an edge 
begin at v and end at w. A graph be visualize a 
a set of point connect by lines, a show in Fig. 41. 



93 

�� 
�� 
�� 
�� 
�� 
�� 
�� 
�� 
�� 
�� 
�� 
�� 

�� 
�� 
�� 
�� 
�� 
�� 
�� 
�� 
�� 
�� 
�� 
�� 

� 
� 
� 
� 

� 
� 
� 
� 

� 
� 
� 
� 

� 
� 
� 
� 

� 
� 
� 
� 

� 
� 
� 
� 

��������� 
��������� 
��������� 

��������� 
��������� 
��������� 

���� 
���� 
���� 
���� 
���� 
���� 
���� 
���� 

���� 
���� 
���� 
���� 
���� 
���� 
���� 
���� 

��� 
��� 
��� 
��� 
��� 
��� 
��� 

��� 
��� 
��� 
��� 
��� 
��� 
��� 

����� 
����� 
����� 
����� 
����� 
����� 

����� 
����� 
����� 
����� 
����� 
����� 

���������� 
���������� 
���������� 
���������� 

�� 
�� 
�� 
�� 
�� 
�� 
�� 
�� 

�� 
�� 
�� 
�� 
�� 
�� 
�� 
�� 

� 
� 
� 
� 

FIG. 41 A sample graph with seven vertex and seven edges. 

In many real examples, graph be weighted, i. e. a real 
number be associate to each of the edges. Graphs do not 
include loops, i. e. edge connect a vertex to itself, nor 
multiple edges, i. e. several edge join the same pair of 
vertices. Graphs with loop and multiple edge be call 
multigraphs. Generalizations of graph admit edge 
between any number of vertex (not necessarily two) be 
call hypergraphs. 

A graph G′ = (V ′, E′) be a subgraph of G = (V,E) if 
V ′ ⊂ V and E′ ⊂ E. If G′ contains all edge of G that join 
vertex of V ′ one say that the subgraph G′ be induced 
or span by V ′. A partition of the vertex set V in two 
subset S and V − S be call a cut; the cut size be the 
number of edge of G join vertex of S with vertex 
of V − S. 

We indicate the number of vertex and edge of a 
graph with n and m, respectively. The number of vertex 
be the order of the graph, the number of edge it size. 
The maximum size of a graph equal the total number of 
unordered pair of vertices, n(n − 1)/2. If |V | = n and 
|E| = m = n(n− 1)/2, the graph be a clique (or complete 
graph), and be indicate a Kn. Two vertex be neigh- 
bors (or adjacent) if they be connect by an edge. The 
set of neighbor of a vertex v be call neighborhood, and 
we shall denote it with Γ(v). The degree kv of a vertex v 
be the number of it neighbors. The degree sequence be the 
list of the degree of the graph vertices, kv1 , kv2 , ..., kvn . 
On direct graphs, one distinguishes two type of degree 
for a vertex v: the indegree, i. e. the number of edge be- 
gin at v and the outdegree, i. e. the number of edge 
end at v. The analogue of degree on a weight graph 
be the strength, i. e. the sum of the weight of the edge 
adjacent to the vertex. Another useful local property of 
graph be transitivity or cluster (Watts and Strogatz, 
1998), which indicates the level of cohesion between the 
neighbor of a vertex 32. The cluster coefficient cv of 

32 The term cluster be commonly adopt to indicate commu- 
nity detection in some disciplines, like computer science, and we 

vertex v be the ratio between the number of edge join 
pair of neighbor of v and the total number of possible 
edges, give by kv(kv − 1)/2, kv be the degree of v. 
According to this definition, cv measure the probabil- 
ity that a pair of neighbor of v be connected. Since 
all neighbor of v be connect to v by definition, edge 
connect pair of neighbor of v form triangle with 
v. This be why the definition be often give in term of 
number of triangles. 

A path be a graph P = (V (P), E(P)), with V (P) = 
{x0, x1, ..., xl} and E(P) = {x0x1, x1x2, ..., xl−1xl}. The 
vertex x0 and xl be the endvertices of P, whereas l 
be it length. Given the notion of vertices, edge and 
paths, one can define the concept of independence. A set 
of vertex (or edges) of a graph be independent if no two 
element of them be adjacent. Similarly, two path be 
independent if they only share the endvertices. A cycle 
be a close path whose vertex and edge be all distinct. 
Cycles of length l be indicate with Cl. The small 
non-trivial cycle be the triangle, C3. 

Paths allow to define the concept of connectivity and 
distance in graphs. A graph be connect if, give any 
pair of vertices, there be at least one path go from 
one vertex to the other. In general, there may be multi- 
ple path connect two vertices, with different lengths. 
A shortest path, or geodesic, between two vertex of a 
graph, be a path of minimal length. Such minimal length 
be the distance between the two vertices. The diameter 
of a connect graph be the maximal distance between 
two vertices. If there be no path between two vertices, 
the graph be divide in at least two connect subgraphs. 
Each maximal connect subgraph of a graph be call 
connect component. 

A graph without cycle be a forest. A connect forest 
be a tree. Trees be very important in graph theory and 
deserve some attention. In a tree, there can be only one 
path from a vertex to any other. In fact, if there be 
at least two path between the same pair of vertex they 
would form a cycle, while the tree be an acyclic graph by 
definition. Further, the number of edge of a tree with 
n vertex be n − 1. If any edge of a tree be removed, 
it would get disconnect in two parts; if a new edge be 
added, there would be at least one cycle. This be why a 
tree be a minimally connected, maximally acyclic graph 
of a give order. Every connect graph contains a span- 
ning tree, i. e. a tree share all vertex of the graph. 
On weight graphs, one can define a minimum (maxi- 
mum) span tree, i. e. a span tree such that the 
sum of the weight on the edge be minimal (maximal). 
Minimum and maximum span tree be often use in 
graph optimization problems, include clustering. 

A graph G be bipartite if the vertex set V be separate in 

often use it in this context throughout the manuscript. We 
paid attention to disambiguate the occurrence in which cluster- 
ing indicates instead the local property of a vertex neighborhood 
described here. 



94 

two disjoint subset V1 and V2, or classes, and every edge 
join a vertex of V1 with a vertex of V2. The definition 
can be extend to that of r-partition, where the vertex 
class be r and no edge join vertex within the same 
class. In this case one speaks of multipartite graphs. 

2. Graph Matrices 

The whole information about the topology of a graph 
of order n be entail in the adjacency matrix A, which 
be an n × n matrix whose element Aij equal 1 if there 
be an edge join vertex i and j, otherwise it be zero. 
Due to the absence of loop the diagonal element of the 
adjacency matrix be all zero. For an undirected graph 
A be a symmetric matrix. The sum of the element of 
the i-th row or column yield the degree of node i. If 
the edge be weighted, one defines the weight matrix 
W, whose element Wij express the weight of the edge 
between vertex i and j. 

The spectrum of a graph G be the set of eigenvalue 
of it adjacency matrix A. Spectral property of graph 
matrix play an important role in the study of graphs. 
For instance, the stochastic matrix rule the process of 
diffusion (random walk) on a graph. The right stochastic 
matrix R be obtain from A by divide the element of 
each row i by the degree of vertex i. The left stochas- 
tic matrix T, or transfer matrix, be the transpose of R. 
The spectrum of stochastic matrix allow to evaluate, for 
instance, the mix time of the random walk, i. e. the 
time it take to reach the stationary distribution of the 
process. The latter be obtain by compute the eigen- 
vector of the transfer matrix correspond to the large 
eigenvalue. 

Another important matrix be the Laplacian L = D−A, 
where D be the diagonal matrix whose element Dii equal 
the degree of vertex i. The matrix L be usually refer 
to a unnormalized Laplacian. In the literature one of- 
ten us normalize Laplacians (Chung, 1997), of which 
there be two main forms: Lsym = D 

−1/2LD−1/2 and 
Lrw = D 

−1L = I −D−1A = I − T. The matrix Lsym 
be symmetric; Lrw be not symmetric and be closely re- 
lated to a random walk take place on the graph. All 
Laplacian matrix have a straightforward extension to 
the case of weight graphs. The Laplacian be one of the 
most study matrix and find application in many dif- 
ferent contexts, like graph connectivity (Bollobas, 1998), 
synchronization (Barahona and Pecora, 2002; Nishikawa 
et al., 2003), diffusion (Chung, 1997) and graph parti- 
tioning (Pothen, 1997). By construction, the sum of the 
element of each row of the Laplacian (normalized or un- 
normalized) be zero. This implies that L always have at 
least one zero eigenvalue, correspond to the eigenvec- 
tor with all equal components, such a (1, 1, ..., 1). Eigen- 
vector correspond to different eigenvalue be all or- 
thogonal to each other. Interestingly, L have a many 
zero eigenvalue a there be connect component in the 
graph. So, the Laplacian of a connect graph have but 

one zero eigenvalue, all others be positive. Eigenvec- 
tor of Laplacian matrix be regularly use in spectral 
cluster (Section IV.D). In particular, the eigenvector 
correspond to the second small eigenvalue, call 
Fiedler vector (Fiedler, 1973, 1975), be use for graph bi- 
partitioning, a described in Section IV.A. 

3. Model graph 

In this section we present the most popular model of 
graph introduce to describe real systems, at least to 
some extent. Such graph be useful null model in com- 
munity detection, a they do not have community struc- 
ture, so they can be use for negative test of cluster 
algorithms. 

The old model be that of random graph, propose 
by Solomonoff and Rapoport (Solomonoff and Rapoport, 
1951) and independently by Erdös and Rényi (Erdös and 
Rényi, 1959). There be two parameters: the number of 
vertex n and the connection probability p. Each pair 
of vertex be connect with equal probability p indepen- 
dently of the other pairs. The expect number of edge 
of the graph be pn(n−1)/2, and the expect mean degree 
〈k〉 = p(n − 1). The degree distribution of the vertex 
of a random graph be binomial, and in the limit n→∞, 
p → 0 for fix 〈k〉 it converges to a Poissonian. There- 
fore, the vertex have all about the same degree, close 
to 〈k〉 (Fig. 42, top). The most strike property of this 
class of graph be the phase transition observe by vary- 
ing 〈k〉 in the limit n → ∞. For 〈k〉 < 1, the graph be 
separate in connect components, each of them be 
microscopic, i. e. occupy but a vanish portion of 
the system size. For 〈k〉 > 1, instead, one of the com- 
ponents becomes macroscopic (giant component), i. e. it 
occupies a finite fraction of the graph vertices. 

The diameter of a random graph with n vertex be very 
small, grow only logarithmically with n. This prop- 
erty (small-world effect) be very common in many real 
graphs. The first evidence that social network be char- 
acterized by path of small length be provide by a se- 
ries of famous experiment conduct by the phychologist 
Stanley Milgram (Milgram, 1967; Travers and Milgram, 
1969). The expect cluster coefficient of a vertex of a 
random graph be p, a the probability for two vertex to 
be connect be the same whether they be neighbor of 
the same vertex or not. Real graphs, however, be char- 
acterized by far high value of the cluster coefficient 
a compare to random graph of the same size. Watts 
and Strogatz (Watts and Strogatz, 1998) show that the 
small world property and high cluster coefficient can 
coexist in the same system. They design a class of 
graph which result from an interpolation between a reg- 
ular lattice, which have high cluster coefficient, and a 
random graph, which have the small-world property. One 
start from a ring lattice in which each vertex have degree 
k, and with a probability p each edge be rewire to a dif- 
ferent target vertex (Fig. 42, center). It turn out that 



95 

Pajek 

Pajek 

Pajek 

FIG. 42 Basic model of complex networks. (Top) Erdös- 
Rényi random graph with 100 vertex and a link probability 
p = 0.02. (Center) Small world graph á la Watts-Strogatz, 
with 100 vertex and a rewire probability p = 0.1. (Bot- 
tom) Barabási-Albert scale-free network, with 100 vertex 
and an average degree of 2. Courtesy by J. J. Ramasco. 

low value of p suffice to reduce considerably the length 
of shortest path between vertices, because rewire edge 
act a shortcut between initially remote region of the 
graph. On the other hand, the cluster coefficient re- 
main high, since few rewire edge do not perturb ap- 
preciably the local structure of the graph, which remains 
similar to the original ring lattice. For p = 1 all edge be 
rewire and the result structure be a random graph á 
la Erdös and Rényi. 

The seminal paper of Watts and Strogatz trigger a 
huge interest towards the graph representation of real 
systems. One of the most important discovery be that 
the distribution of the vertex degree of real graph be very 
heterogeneous (Albert et al., 1999), with many vertex 
have few neighbor coexist with some vertex with 
many neighbors. In several case the tail of this distri- 
bution can be described a a power law with good ap- 
proximation33, hence the expression scale-free networks. 
Such degree heterogeneity be responsible for a number of 
remarkable feature of real networks, such a resilience to 
random failures/attacks (Albert et al., 2000), and the ab- 
sence of a threshold for percolation (Cohen et al., 2000) 
and epidemic spread (Pastor-Satorras and Vespignani, 
2001). The most popular model of a graph with a power 
law degree distribution be the model by Barabási and Al- 
bert (Barabási and Albert, 1999). A version of the model 
for direct graph have be propose much early by de 
Solla Price (Price, 1976), building up on previous idea 
developed by Simon (Simon, 1955). The graph be create 
with a dynamic procedure, where vertex be add one 
by one to an initial core. The probability for a new vertex 
to set an edge with a preexist vertex be proportional 
to the degree of the latter. In this way, vertex with high 
degree have large probability of be select a neigh- 
bors by new vertices; if this happens, their degree further 
increase so they will be even more likely to be chosen in 
the future. In the asymptotic limit of infinite number of 
vertices, this rich-gets-richer strategy generates a graph 
with a degree distribution characterize by a power-law 
tail with exponent 3. In Fig. 42 (bottom) we show an 
example of Barabási-Albert (BA) graph. The cluster- 
ing coefficient of a BA graph decay with the size of the 
graph, and it be much low than in real networks. More- 
over, the power law decay of the degree distribution 
observe in real network be characterize by a range 
of exponents’ value (usually between 2 and 3), whereas 
the BA model yield a fix value. However, many re- 
finements of the BA model a well a plenty of differ- 
ent model have be late introduce to account more 
closely for the feature observe in real system (for de- 
tail see (Albert and Barabási, 2002; Barrat et al., 2008; 

33 The power law be however not necessary to explain the property 
of complex networks. It be enough that the tail of the degree 
distribution be “fat”, i. e. span order of magnitude in 
degree. They may or may not be accurately fit by a power 
law. 



96 

Boccaletti et al., 2006; Mendes and Dorogovtsev, 2003; 
Newman, 2003; Pastor-Satorras and Vespignani, 2004)). 

References 

Adamcsek, B., G. Palla, I. J. Farkas, I. Derényi, and T. Vic- 
sek, 2006, Bioinformatics 22(8), 1021. 

Adomavicius, G., and A. Tuzhilin, 2005, IEEE Trans. Knowl. 
Data Eng. 17(6), 734. 

Agarwal, G., and D. Kempe, 2008, Eur. Phys. J. B 66, 409. 
Agrawal, R., and H. V. Jagadish, 1994, Knowl. Data Eng. 

6(2), 225. 
Ahn, Y.-Y., J. P. Bagrow, and S. Lehmann, 2009, eprint 

arXiv:0903.3178. 
Ahuja, R. K., T. L. Magnanti, and J. B. Orlin, 1993, Net- 

work Flows: Theory, Algorithms, and Applications (Pren- 
tice Hall, Englewood Cliffs, USA). 

Akaike, H., 1974, IEEE Trans. Autom. Control 19(6), 716. 
Alba, R. D., 1973, J. Math. Sociol. 3, 113. 
Albert, R., and A.-L. Barabási, 2002, Rev. Mod. Phys. 74(1), 

47. 
Albert, R., H. Jeong, and A.-L. Barabási, 1999, Nature 401, 

130. 
Albert, R., H. Jeong, and A.-L. Barabási, 2000, Nature 406, 

378. 
Allahverdyan, A. E., and A. Galstyan, 2009, eprint 

arXiv:0907.4803. 
Alves, N. A., 2007, Phys. Rev. E 76(3), 036101. 
Andrews, G. E., 1976, The theory of partition (Addison- 

Wesley, Boston, USA). 
Anthonisse, J. M., 1971, The rush in a direct graph, Tech- 

nical Report, Stichting Mathematisch Centrum, 2e Boer- 
haavestraat 49 Amsterdam, The Netherlands. 

Arenas, A., and A. Dı́az-Guilera, 2007, Eur. Phys. J. Special 
Topics 143, 19. 

Arenas, A., A. Dı́az-Guilera, and C. J. Pérez-Vicente, 2006, 
Phys. Rev. Lett. 96(11), 114102. 

Arenas, A., J. Duch, A. Fernández, and S. Gómez, 2007, New 
J. Phys. 9, 176. 

Arenas, A., A. Fernández, S. Fortunato, and S. Gómez, 2008a, 
J. Phys. A 41(22), 224001. 

Arenas, A., A. Fernández, and S. Gómez, 2008b, New J. Phys. 
10(5), 053039. 

Asahiro, Y., R. Hassin, and K. Iwama, 2002, Discrete Appl. 
Math. 121(1-3), 15. 

Ashburner, M., C. A. Ball, J. A. Blake, D. Botstein, H. But- 
ler, J. M. Cherry, A. P. Davis, K. Dolinski, S. S. Dwight, 
J. T. Eppig, M. A. Harris, D. P. Hill, et al., 2000, Nature 
Genetics 25(1), 25. 

Asur, S., S. Parthasarathy, and D. Ucar, 2007, in KDD ’07: 
Proceedings of the 13th ACM SIGKDD international con- 
ference on Knowledge discovery and data mining (ACM, 
New York, NY, USA), pp. 913–921. 

Backstrom, L., D. Huttenlocher, J. Kleinberg, and X. Lan, 
2006, in KDD ’06: Proceedings of the 12th ACM SIGKDD 
international conference on Knowledge discovery and data 
mining (ACM, New York, NY, USA), pp. 44–54. 

Baeza-Yates, R., and B. Ribeiro-Neto, 1999, Modern Infor- 
mation Retrieval (Addison-Wesley, Boston, USA). 

Bagrow, J. P., 2008, J. Stat. Mech. P05001. 
Bagrow, J. P., and E. M. Bollt, 2005, Phys. Rev. E 72(4), 

046108. 

Balakrishnan, V. K., 1997, Schaum’s Outline of Graph Theory 
(McGraw-Hill, New York, USA). 

Bansal, N., A. Blum, and S. Chawla, 2004, Mach. Learn. 
56(1-3), 89. 

Barabási, A.-L., and R. Albert, 1999, Science 286, 509. 
Barahona, M., and L. M. Pecora, 2002, Phys. Rev. Lett. 

89(5), 054101. 
Barber, M. J., 2007, Phys. Rev. E 76(6), 066102. 
Barber, M. J., and J. W. Clark, 2009, Phys. Rev. E 80(2), 

026129. 
Barber, M. J., M. Faria, L. Streit, and O. Strogan, 2008, in 

Stochastic and Quantum Dynamics of Biomolecular Sys- 
tems, edit by C. C. Bernido and M. V. Carpio-Bernido 
(American Institute of Physics, Melville, USA), volume 
1021 of American Institute of Physics Conference Series, 
pp. 171–182. 

Barnes, E. R., 1982, SIAM J. Alg. Discr. Meth. 3, 541. 
Barrat, A., M. Barthélemy, R. Pastor-Satorras, and 

A. Vespignani, 2004, Proc. Natl. Acad. Sci. USA 101(11), 
3747. 

Barrat, A., M. Barthélemy, and A. Vespignani, 2008, Dynam- 
ical process on complex network (Cambridge University 
Press, Cambridge, UK). 

Batagelj, V., and M. Zaversnik, 2003, eprint cs.DS/0310049. 
Baumes, J., M. Goldberg, and M. Magdon-Ismail, 2005a, in 

IEEE International Conference on Intelligence and Secu- 
rity Informatics (ISI), pp. 27–36. 

Baumes, J., M. K. Goldberg, M. S. Krishnamoorthy, M. 
Magdon-Ismail, and N. Preston, 2005b, in IADIS AC, 
edit by N. Guimaraes and P. T. Isaias (IADIS), pp. 97– 
104. 

Beal, M. J., 2003, Variational Algorithms for Approximate 
Bayesian Inference, Ph.D. thesis, Gatsby Computational 
Neuroscience Unit, University College London. 

Beirlant, J., Y. Goegebeur, J. Segers, and J. Teugels, 2004, 
Statistics of Extremes: Theory and Applications (Wiley & 
Sons, Chichester, UK), 1 edition. 

Berg, J., and M. Lässig, 2006, Proc. Natl. Acad. Sci. USA 
103(29), 10967. 

Berry, J. W., B. Hendrickson, R. A. LaViolette, V. J. Leung, 
and C. A. Phillips, 2007, eprint arXiv:0710.3800. 

Berry, J. W., B. Hendrickson, R. A. LaViolette, and C. A. 
Phillips, 2009, eprint arXiv:0903.1072. 

Bezdek, J. C., 1981, Pattern Recognition with Fuzzy Objective 
Function Algorithms (Kluwer Academic Publishers, Nor- 
well, USA). 

Bhatia, R., 1997, Matrix Analysis (Springer-Verlag, New 
York, USA). 

Bianconi, G., 2008, Europhys. Lett. 81, 28005. 
Bianconi, G., A. C. C. Coolen, and C. J. Perez Vicente, 2008, 

Phys. Rev. E 78(1), 016114. 
Bianconi, G., P. Pin, and M. Marsili, 2009, Proc. Natl. Acad. 

Sci. USA 106(28), 11433. 
Biernacki, C., G. Celeux, and G. Govaert, 2000, IEEE Trans. 

Pattern Anal. Mach. Intell. 22(7), 719. 
Blake, A., and A. Zisserman, 1987, Visual Reconstruction 

(MIT Press, Cambridge, USA). 
Blatt, M., S. Wiseman, and E. Domany, 1996, Phys. Rev. 

Lett. 76, 3251. 
Blondel, V. D., J.-L. Guillaume, R. Lambiotte, and E. Lefeb- 

vre, 2008, J. Stat. Mech. P10008. 
Boccaletti, S., M. Ivanchenko, V. Latora, A. Pluchino, and 

A. Rapisarda, 2007, Phys. Rev. E 75(4), 045102. 
Boccaletti, S., V. Latora, Y. Moreno, M. Chavez, and D. U. 



97 

Hwang, 2006, Phys. Rep. 424(4-5), 175. 
Boettcher, S., and A. G. Percus, 2001, Phys. Rev. Lett. 86, 

5211. 
Bollobas, B., 1998, Modern Graph Theory (Springer Verlag, 

New York, USA). 
Bomze, I. M., M. Budinich, P. M. Pardalos, and M. Pelillo, 

1999, in Handbook of Combinatorial Optimization, edit 
by D.-Z. Du and P. Pardalos (Kluwer Academic Publishers, 
Norwell, USA), pp. 1–74. 

Bonacich, P., 1972, Journal of Mathematical Sociology 2(1), 
113. 

Bonacich, P., 1987, The American Journal of Sociology 92(5), 
1170. 

Bonanno, G., G. Caldarelli, F. Lillo, and R. N. Mantegna, 
2003, Phys. Rev. E 68(4), 046130. 

Bonanno, G., N. Vandewalle, and R. N. Mantegna, 2000, 
Phys. Rev. E 62(6), R7615. 

Borgatti, S., M. Everett, and P. Shirey, 1990, Soc. Netw. 12, 
337. 

Brandes, U., 2001, J. Math. Sociol. 25, 163. 
Brandes, U., D. Delling, M. Gaertler, R. Görke, M. Hoefer, 

Z. Nikolski, and D. Wagner, 2006, URL http://digbib. 
ubka.uni-karlsruhe.de/volltexte/documents/3255. 

Brandes, U., M. Gaertler, and D. Wagner, 2003, in Proceed- 
ings of ESA (Springer-Verlag, Berlin, Germany), pp. 568– 
579. 

Brin, S., and L. E. Page, 1998, Comput. Networks ISDN 30, 
107. 

Bron, C., and J. Kerbosch, 1973, Commun. ACM 16, 575. 
Burnham, K. P., and D. R. Anderson, 2002, Model Selec- 

tion and Multimodel Inference: A Practical Information- 
Theoretic Approach (Springer, New York, USA). 

Burt, R. S., 1976, Soc. Forces 55, 93. 
C. Castellano, F. Cecconi, V. Loreto, D. Parisi, and F. Radic- 

chi, 2004, Eur. Phys. J. B 38(2), 311. 
Capocci, A., V. D. P. Servedio, G. Caldarelli, and F. Colaiori, 

2005, Physica A 352, 669. 
Chakrabarti, D., 2004, in PKDD, edit by J.-F. Boulicaut, 

F. Esposito, F. Giannotti, and D. Pedreschi (Springer), vol- 
ume 3202 of Lect. Notes Comp. Sci., pp. 112–124, ISBN 
3-540-23108-0. 

Chakrabarti, D., R. Kumar, and A. Tomkins, 2006, in 
KDD ’06: Proceedings of the 12th ACM SIGKDD interna- 
tional conference on Knowledge discovery and data mining 
(ACM, New York, NY, USA), pp. 554–560. 

Chan, P. K., M. D. F. Schlag, and J. Y. Zien, 1993, in Pro- 
ceedings of the 30th International Conference on Design 
Automation (ACM Press, New York, USA), pp. 749–754. 

Chandra, A. K., P. Raghavan, W. L. Ruzzo, and R. Smolen- 
sky, 1989, in STOC ’89: Proceedings of the twenty-first 
annual ACM symposium on Theory of compute (ACM, 
New York, NY, USA), pp. 574–586. 

Chen, J., and B. Yuan, 2006, Bioinformatics 22(18), 2283. 
Chen, W. Y. C., A. W. M. Dress, and W. Q. Yu, 2008, Math. 

Comp. Sci. 1(3), 441. 
Chi, Y., X. Song, D. Zhou, K. Hino, and B. L. Tseng, 2007, in 

KDD ’07: Proceedings of the 13th ACM SIGKDD interna- 
tional conference on Knowledge discovery and data mining 
(ACM, New York, NY, USA), pp. 153–162. 

Chung, F., 1997, Spectral Graph Theory, Number 92 in 
CBMS Regional Conference Series in Mathematics (Amer- 
ican Mathematical Society, Providence, USA). 

Clauset, A., 2005, Phys. Rev. E 72(2), 026132. 
Clauset, A., C. Moore, and M. E. J. Newman, 2007, in Sta- 

tistical Network Analysis: Models, Issues, and New Direc- 
tions, edit by E. M. Airoldi, D. M. Blei, S. E. Fienberg, 
A. Goldenberg, E. P. Xing, and A. X. Zheng (Springer, 
Berlin, Germany), volume 4503 of Lect. Notes Comp. Sci., 
pp. 1–13. 

Clauset, A., C. Moore, and M. E. J. Newman, 2008, Nature 
453(7191), 98. 

Clauset, A., M. E. J. Newman, and C. Moore, 2004, Phys. 
Rev. E 70(6), 066111. 

Cohen, R., K. Erez, D. ben Avraham, and S. Havlin, 2000, 
Phys. Rev. Lett. 85(21), 4626. 

Coleman, J. S., 1964, An Introduction to Mathematical Soci- 
ology (Collier-Macmillan, London, UK). 

Condon, A., and R. M. Karp, 2001, Random Struct. Algor. 
18, 116. 

Čopič, J., M. O. Jackson, and A. Kirman, 2005, URL http: 
//www.hss.caltech.edu/~{}jernej/netcommunity.pdf. 

Csermely, P., 2008, Trends Biochem. Sci. 33(12), 569. 
da Fontoura Costa, L., 2004, eprint cond-mat/0405022. 
Danon, L., A. Dı́az-Guilera, and A. Arenas, 2006, J. Stat. 

Mech. 11, 10. 
Danon, L., A. Dı́az-Guilera, J. Duch, and A. Arenas, 2005, J. 

Stat. Mech. P09008. 
Danon, L., J. Duch, A. Arenas, and A. Dı́az-Guilera, 2007, in 

Large Scale Structure and Dynamics of Complex Networks: 
From Information Technology to Finance and Natural Sci- 
ence, edit by Caldarelli G. and Vespignani A. (World 
Scientific, Singapore), pp. 93–114. 

David, H. A., and H. N. Nagaraja, 2003, Order Statistics 
(Wiley-Interscience, Hoboken, USA). 

Davis, A., B. B. Gardner, and M. R. Gardner, 1941, Deep 
South (University of Chicago Press, Chicago, USA). 

Delling, D., M. Gaertler, R. Görke, Z. Nikoloski, and D. Wag- 
ner, 2007, How to Evaluate Clustering Techniques., Tech- 
nical Report, Universität Karlsruhe, Germany. 

Delvenne, J. C., S. N. Yaliraki, and M. Barahona, 2008, eprint 
arXiv:0812.1811. 

Demmel, J., J. Dongarra, A. Ruhe, and H. van der Vorst, 
2000, Templates for the solution of algebraic eigenvalue 
problems: a practical guide (Society for Industrial and Ap- 
ply Mathematics, Philadelphia, USA). 

Dempster, A. P., N. M. Laird, and D. B. Rubin, 1977, J. Roy. 
Stat. Soc. B 39, 1. 

Derényi, I., G. Palla, and T. Vicsek, 2005, Phys. Rev. Lett. 
94(16), 160202. 

Dhillon, I. S., Y. Guan, and B. Kulis, 2007, IEEE Trans. 
Pattern Anal. Mach. Intell. 29(11), 1944. 

Djidjev, H., 2007, in WAW, edit by W. Aiello, A. Z. Broder, 
J. C. M. Janssen, and E. E. Milios (Springer-Verlag, Berlin, 
Germany), volume 4936 of Lecture Notes in Computer Sci- 
ence, pp. 117–128. 

Donath, W., and A. Hoffman, 1973, IBM Journal of Research 
and Development 17(5), 420. 

Donetti, L., and M. A. Muñoz, 2004, J. Stat. Mech. P10012. 
Donetti, L., and M. A. Muñoz, 2005, in Modeling Coopera- 

tive Behavior in the Social Sciences, edit by P. Garrido, 
J. Maroo, and M. A. Muñoz, volume 779 of American In- 
stitute of Physics Conference Series, pp. 104–107. 

van Dongen, S., 2000a, Graph Clustering by Flow Simula- 
tion, Ph.D. thesis, Dutch National Research Institute for 
Mathematics and Computer Science, University of Utrecht, 
Netherlands. 

Dongen, S., 2000b, Performance criterion for graph cluster- 
ing and Markov cluster experiments, Technical Report, Na- 

http://digbib.ubka.uni-karlsruhe.de/volltexte/documents/3255 
http://digbib.ubka.uni-karlsruhe.de/volltexte/documents/3255 
http://www.hss.caltech.edu/~{}jernej/netcommunity.pdf 
http://www.hss.caltech.edu/~{}jernej/netcommunity.pdf 


98 

tional Research Institute for Mathematics and Computer 
Science in the Netherlands, Amsterdam, The Netherlands. 

Doreian, P., V. Batagelj, and A. Ferligoj, 2005, Generalized 
Blockmodeling (Cambridge University Press, New York, 
USA). 

Dorogovtsev, S. N., and J. F. F. Mendes, 2002, Adv. Phys. 
51, 1079. 

Dourisboure, Y., F. Geraci, and M. Pellegrini, 2007, in WWW 
’07: Proceedings of the 16th international conference on the 
World Wide Web (ACM, New York, NY, USA), pp. 461– 
470. 

Du, H., M. W. Feldman, S. Li, and X. Jin, 2007, Complexity 
12(3), 53. 

Du, N., B. Wang, B. Wu, and Y. Wang, 2008, in 
IEEE/WIC/ACM International Conference on Web Intel- 
ligence and Intelligent Agent Technology (IEEE Computer 
Society, Los Alamitos, CA, USA), pp. 176–179. 

Duch, J., and A. Arenas, 2005, Phys. Rev. E 72(2), 027104. 
Dunbar, R., 1998, Grooming, Gossip, and the Evolution of 

Language (Harvard University Press, Cambridge, USA). 
Dunn, J. C., 1974, J. Cybernetics 3, 32. 
Dunn, R., F. Dudbridge, and C. M. Sanderson, 2005, BMC 

Bioinf. 6, 39. 
Earl, D. J., and M. W. Deem, 2005, Phys. Chem. Chem. Phys. 

7, 3910. 
Eckmann, J.-P., and E. Moses, 2002, Proc. Natl. Acad. Sci. 

USA 99, 5825. 
Efron, B., and R. J. Tibshirani, 1993, An Introduction to the 

Bootstrap (Chapman & Hall, New York, USA). 
Elias, P., A. Feinstein, and C. E. Shannon, 1956, IRE Trans. 

Inf. Theory IT-2, 117. 
Erdös, P., and A. Rényi, 1959, Publ. Math. Debrecen 6, 290. 
Eriksen, K. A., I. Simonsen, S. Maslov, and K. Sneppen, 2003, 

Phys. Rev. Lett. 90(14), 148701. 
Estrada, E., and N. Hatano, 2008, Phys. Rev. E 77(3), 

036111. 
Estrada, E., and N. Hatano, 2009, Appl. Math. Comput. 214, 

500. 
Euler, L., 1736, Commentarii Academiae Petropolitanae 8, 

128. 
Evans, T. S., and R. Lambiotte, 2009, Phys. Rev. E 80(1), 

016105. 
Everett, M. G., and S. P. Borgatti, 1994, J. Math. Soc. 19(1), 

29. 
Everett, M. G., and S. P. Borgatti, 1998, Connections 21(1), 

49. 
Fan, Y., M. Li, P. Zhang, J. Wu, and Z. Di, 2007, Physica A 

377, 363. 
Farkas, I., D. Ábel, G. Palla, and T. Vicsek, 2007, New J. 

Phys. 9, 180. 
Farutin, V., K. Robison, E. Lightcap, V. Dancik, A. Rutten- 

berg, S. Letovsky, and J. Pradines, 2006, Proteins 62(3), 
800. 

Feige, U., D. Peleg, and G. Kortsarz, 2001, Algorithmica 
29(3), 410. 

Feng, Z., X. Xu, N. Yuruk, and T. Schweiger, 2007, Lect. 
Notes Comp. Sci. 4654, 385. 

Fenn, D. J., M. A. Porter, M. McDonald, S. Williams, N. F. 
Johnson, and N. S. Jones, 2009, Chaos 19(3), 033119. 

Fiedler, M., 1973, Czech. Math. J. 23(98), 298. 
Fiedler, M., 1975, Czech. Math. J. 25, 619. 
Fienberg, S. E., and S. Wasserman, 1981, Sociol. Methodol. 

12, 156. 
Flake, G. W., S. Lawrence, and C. L. Giles, 2000, in Sixth 

ACM SIGKDD International Conference on Knowledge 
Discovery and Data Mining (ACM Press, Boston, USA), 
pp. 150–160. 

Flake, G. W., S. Lawrence, C. Lee Giles, and F. M. Coetzee, 
2002, IEEE Computer 35, 66. 

F.Lorrain, and H. White, 1971, J. Math. Sociol. 1, 49. 
Ford, L. R., and D. R. Fulkerson, 1956, Canadian J. Math. 8, 

399. 
Fortunato, S., 2007, in Noise and Stochastics in Complex Sys- 

tems and Finance, volume 6601 of SPIE Conference Series, 
p. 660108. 

Fortunato, S., and M. Barthélemy, 2007, Proc. Natl. Acad. 
Sci. USA 104, 36. 

Fortunato, S., and C. Castellano, 2009, in Encyclopedia 
of Complexity and Systems Science, edit by R. A. 
Meyers (Springer, Berlin, Germany), volume 1, eprint 
arXiv:0712.2716. 

Fortunato, S., V. Latora, and M. Marchiori, 2004, Phys. Rev. 
E 70(5), 056104. 

Fouss, F., and J.-M. Renders, 2007, IEEE Trans. on Knowl. 
and Data Eng. 19(3), 355, member-Pirotte, Alain and 
Member-Saerens, Marco. 

Fowlkes, E. B., and C. L. Mallows, 1983, J. Am. Stat. Assoc. 
78, 553. 

Freeman, L. C., 1977, Sociometry 40, 35. 
Freeman, L. C., 2004, The Development of Social Network 

Analysis: A Study in the Sociology of Science (BookSurge 
Publishing). 

Fu, Y., and P. Anderson, 1986, J. Phys. A 19, 1605. 
Gaertler, M., R. Görke, and D. Wagner, 2007, in AAIM, 

edit by M.-Y. Kao and X.-Y. Li (Springer, Berlin, Ger- 
many), volume 4508 of Lecture Notes in Computer Science, 
pp. 11–26. 

Gallager, R. G., 1963, Low density parity check code (MIT 
Press, Cambridge, USA). 

Gan, G., C. Ma, and J. Wu, 2007, Data Clustering: The- 
ory, Algorithms, and Applications (ASA-SIAM Series on 
Statistics and Applied Probability) (Society for Industrial 
and Applied Mathematics, Philadelphia, USA). 

Garey, M. R., and D. S. Johnson, 1990, Computers and In- 
tractability : A Guide to the Theory of NP-Completeness 
(W. H. Freeman & Co., New York, USA). 

Gfeller, D., J.-C. Chappelier, and P. De Los Rios, 2005, Phys. 
Rev. E 72(5), 056135. 

Gfeller, D., and P. De Los Rios, 2007, Phys. Rev. Lett. 99(3), 
038701. 

Gfeller, D., and P. De Los Rios, 2008, Phys. Rev. Lett. 
100(17), 174104. 

Ghosh, R., and K. Lerman, 2008, in Proceedings of KDD 
workshop on Social Network Analysis (SNAKDD), eprint 
arXiv:0805.4606. 

Giles, C. L., K. Bollacker, and S. Lawrence, 1998, in Digital 
Libraries 98 - The Third ACM Conference on Digital Li- 
braries, edit by I. Witten, R. Akscyn, and F. M. Shipman 
III (ACM Press, Pittsburgh, PA), pp. 89–98. 

Girvan, M., and M. E. J. Newman, 2002, Proc. Natl. Acad. 
Sci. USA 99(12), 7821. 

Gleiser, P., and L. Danon, 2003, Adv. Complex Syst. 6, 565. 
Glover, F., 1986, Comput. Oper. Res. 13(5), 533. 
Goldberg, A. V., and R. E. Tarjan, 1988, Journal of the ACM 

35, 921. 
Golub, G. H., and C. F. V. Loan, 1989, Matrix computation 

(John Hopkins University Press, Baltimore, USA). 
Gómez, S., P. Jensen, and A. Arenas, 2009, Phys. Rev. E 



99 

80(1), 016114. 
Good, B. H., Y. de Montjoye, and A. Clauset, 2009, eprint 

arXiv:0910.0165. 
Gori, M., and A. Pucci, 2007, in IJCAI’07: Proceedings of the 

20th international joint conference on Artifical intelligence 
(Morgan Kaufmann Publishers Inc., San Francisco, CA, 
USA), pp. 2766–2771. 

Granovetter, M., 1973, Am. J. Sociol. 78, 1360. 
Gregory, S., 2007, in Proceedings of the 11th European Con- 

ference on Principles and Practice of Knowledge Discovery 
in Databases (PKDD 2007) (Springer-Verlag, Berlin, Ger- 
many), pp. 91–102. 

Gregory, S., 2009, in Complex Networks, edit by S. Fortu- 
nato, R. Menezes, G. Mangioni, and V. Nicosia (Springer, 
Berlin, Germany), volume 207 of Studies on Computational 
Intelligence, pp. 47–62. 

Grünwald, P. D., I. J. Myung, and M. A. Pitt, 2005, Advances 
in Minimum Description Length: Theory and Applications 
(MIT Press, Cambridge, USA). 

Gudkov, V., V. Montealegre, S. Nussinov, and Z. Nussinov, 
2008, Phys. Rev. E 78(1), 016113. 

Guimerà, R., and L. A. N. Amaral, 2005, J. Stat. Mech. 
P02001. 

Guimerà, R., and L. A. N. Amaral, 2005, Nature 433, 895. 
Guimerà, R., L. Danon, A. Dı́az-Guilera, F. Giralt, and 

A. Arenas, 2003, Phys. Rev. E 68(6), 065103 (R). 
Guimerà, R., M. Sales-Pardo, and L. A. N. Amaral, 2007, 

Bioinformatics 23(13), 1616. 
Guimerà, R., M. Sales-Pardo, and L. A. N. Amaral, 2004, 

Phys. Rev. E 70(2), 025101 (R). 
Guimerà, R., M. Sales-Pardo, and L. A. N. Amaral, 2007, 

Phys. Rev. E 76(3), 036102. 
Gusfield, D., 2002, Inform. Process. Lett. 82(3), 159. 
Gustafsson, M., M. Hörnquist, and A. Lombardi, 2006, Phys- 

ica A 367, 559. 
Hagen, L., and A. B. Kahng, 1992, IEEE Trans. Comput. 

Aided Des. Integr. Circuits Syst. 11(9), 1074. 
Handcock, M. S., A. E. Raftery, and J. M. Tantrum, 2007, J. 

Roy. Stat. Soc. A 170(46), 1. 
Harel, D., and Y. Koren, 2001, in FST TCS ’01: Proceedings 

of the 21st Conference on Foundations of Software Tech- 
nology and Theoretical Computer Science (Springer-Verlag, 
London, UK), pp. 18–41. 

Hastie, T., R. Tibshirani, and J. H. Friedman, 2001, The Ele- 
ments of Statistical Learning (Springer, Berlin, Germany), 
ISBN 0387952845. 

Hastings, M. B., 2006, Phys. Rev. E 74(3), 035102. 
Heimo, T., J. M. Kumpula, K. Kaski, and J. Saramäki, 2008, 

J. Stat. Mech. P08007. 
Hillier, F. S., and G. J. Lieberman, 2004, MP Introduction to 

Operations Research (McGraw-Hill, New York, USA). 
Hlaoui, A., and S. Wang, 2004, in Neural Networks and Com- 

putational Intelligence, pp. 158–163. 
Hofman, J. M., and C. H. Wiggins, 2008, Phys. Rev. Lett. 

100(25), 258701. 
Holland, J. H., 1992, Adaptation in natural and artificial sys- 

tems (MIT Press, Cambridge, USA). 
Holland, P., K. B. Laskey, and S. Leinhardt, 1983, Soc. Netw. 

5, 109. 
Holme, P., M. Huss, and H. Jeong, 2003, Bioinformatics 

19(4), 532. 
Holmström, E., N. Bock, and J. Brännlund, 2009, Physica D 

238, 1161. 
Holzapfel, K., S. Kosub, M. G. Maa, and H. Täubig, 2003, in 

CIAC, edit by R. Petreschi, G. Persiano, and R. Silvestri 
(Springer), volume 2653 of Lecture Notes in Computer Sci- 
ence, pp. 201–212. 

Homans, G. C., 1950, The Human Groups (Harcourt, Brace 
& Co., New York). 

Hopcroft, J., O. Khan, B. Kulis, and B. Selman, 2004, Proc. 
Natl. Acad. Sci. USA 101, 5249. 

Hu, Y., H. Chen, P. Zhang, M. Li, Z. Di, and Y. Fan, 2008, 
Phys. Rev. E 78(2), 026121. 

Hu, Y., M. Li, P. Zhang, Y. Fan, and Z. Di, 2008, Phys. Rev. 
E 78(1), 016115. 

Huffman, D. A., 1952, Proc. IRE 40(9), 1098. 
Hughes, B. D., 1995, Random Walks and Random Environ- 

ments: Random Walks Vol. 1 (Clarendon Press, Oxford, 
UK). 

Hui, P., E. Yoneki, S.-Y. Chan, and J. Crowcroft, 2007, in 
Proc. MobiArch. 

Ispolatov, I., I. Mazo, and A. Yuryev, 2006, J. Stat. Mech. 
P09014. 

Itzkovitz, S., R. Levitt, N. Kashtan, R. Milo, M. Itzkovitz, 
and U. Alon, 2005, Phys. Rev. E 71(1), 016127. 

Jin, R. K.-X., D. C. Parkes, and P. J. Wolfe, 2007, in Proc. 
AAAI Workshop on Plan, Activity and Intent Recognition 
(PAIR), pp. 66–73. 

Jonsson, P. F., T. Cavanna, D. Zicha, and P. A. Bates, 2006, 
BMC Bioinf. 7, 2. 

Jordan, M. I., Z. Ghahramani, T. S. Jaakkola, and L. K. Saul, 
1999, Mach. Learn. 37(2), 183. 

Junker, B. H., and F. Schreiber, 2008, Analysis of Biological 
Networks (Wiley-Interscience, New York, USA). 

Kaplan, T. D., and S. Forrest, 2008, eprint arXiv:0801.3290. 
Karloff, H., 1991, Linear Programming (Birkhäuser Verlag, 

Basel, Switzerland). 
Karrer, B., E. Levina, and M. E. J. Newman, 2008, Phys. 

Rev. E 77(4), 046119. 
Kernighan, B. W., and S. Lin, 1970, Bell System Tech. J. 49, 

291. 
Kim, M.-S., and J. Han, 2009, in Proceedings of 2009 Int. 

Conf. on Very Large Data Bases (Lyon, France). 
Kim, Y., S.-W. Son, and H. Jeong, 2009, eprint 

arXiv:0902.3728. 
Kirkpatrick, S., C. D. Gelatt, and M. P. Vecchi, 1983, Science 

220, 671. 
Klein, D. J., and M. Randic, 1993, J. Math. Chem. 12, 81. 
Kleinberg, J., 2002, in Advances in NIPS 15 (MIT Press, 

Boston, USA), pp. 446–453. 
Koskinen, J. H., and T. A. B. Snijders, 2007, J. Stat. Plan. 

Infer. 137(12), 3930. 
Kottak, C. P., 2004, Cultural Anthropology (McGraw-Hill, 

New York, USA). 
Krause, A. E., K. A. Frank, D. M. Mason, R. E. Ulanowicz, 

and W. W. Taylor, 2003, Nature 426, 282. 
Krawczyk, M. J., 2008, Phys. Rev. E 77(6), 065701. 
Krawczyk, M. J., and K. Kulakowski, 2007, eprint 

arXiv:0709.0923. 
Krishnamurthy, B., and J. Wang, 2000, SIGCOMM Comput. 

Commun. Rev. 30(4), 97. 
Kullback, S., and R. A. Leibler, 1951, Annals of Mathematical 

Statistics 22, 49. 
Kumar, R., J. Novak, P. Raghavan, and A. Tomkins, 2003, in 

WWW ’03: Proceedings of the twelfth international confer- 
ence on the World Wide Web (ACM Press), pp. 568–576. 

Kumar, R., J. Novak, and A. Tomkins, 2006, in KDD ’06: 
Proceedings of the 12th ACM SIGKDD international con- 



100 

ference on Knowledge discovery and data mining (ACM, 
New York, NY, USA), pp. 611–617. 

Kumpula, J. M., M. Kivelä, K. Kaski, and J. Saramäki, 2008, 
Phys. Rev. E 78(2), 026109. 

Kumpula, J. M., J. Saramäki, K. Kaski, and J. Kertész, 
2007a, in Noise and Stochastics in Complex Systems and 
Finance, volume 6601 of SPIE Conference Series, p. 
660116. 

Kumpula, J. M., J. Saramäki, K. Kaski, and J. Kertész, 
2007b, Eur. Phys. J. B 56, 41. 

Kuramoto, Y., 1984, Chemical Oscillations, Waves and Tur- 
bulence (Springer-Verlag, Berlin, Germany). 

Lambiotte, R., J. . Delvenne, and M. Barahona, 2008, eprint 
arXiv:0812.1770. 

Lancichinetti, A., and S. Fortunato, 2009, Phys. Rev. E 80(1), 
016118. 

Lancichinetti, A., and S. Fortunato, 2009, Phys. Rev. E 80(1), 
056117. 

Lancichinetti, A., S. Fortunato, and J. Kertesz, 2009, New J. 
Phys. 11(3), 033015. 

Lancichinetti, A., S. Fortunato, and F. Radicchi, 2008, Phys. 
Rev. E 78(4), 046110. 

Lancichinetti, A., F. Radicchi, and J. J. Ramasco, 2009, 
eprint arXiv:0907.3708. 

Lanczos, C., 1950, J. Res. Natl. Bur. Stand. 45, 255. 
Latapy, M., and P. Pons, 2005, Lect. Notes Comp. Sci. 3733, 

284. 
Latora, V., and M. Marchiori, 2001, Phys. Rev. Lett. 87(19), 

198701. 
Lehmann, S., and L. K. Hansen, 2007, Eur. Phys. J. B 60, 

83. 
Lehmann, S., M. Schwartz, and L. K. Hansen, 2008, Phys. 

Rev. E 78(1), 016108. 
Leicht, E. A., and M. E. J. Newman, 2008, Phys. Rev. Lett. 

100(11), 118703. 
Leskovec, J., L. Backstrom, R. Kumar, and A. Tomkins, 2008, 

in KDD ’08: Proceeding of the 14th ACM SIGKDD inter- 
national conference on Knowledge discovery and data min- 
ing (ACM, New York, NY, USA), pp. 462–470. 

Leskovec, J., J. Kleinberg, and C. Faloutsos, 2005, in KDD 
’05: Proceedings of the eleventh ACM SIGKDD interna- 
tional conference on Knowledge discovery in data mining 
(ACM, New York, NY, USA), pp. 177–187. 

Leskovec, J., K. J. Lang, A. Dasgupta, and M. W. Mahoney, 
2008, eprint arXiv:0810.1355. 

Leung, I. X. Y., P. Hui, P. Liò, and J. Crowcroft, 2009, Phys. 
Rev. E 79(6), 066107. 

Lewis, A. C. F., N. S. Jones, M. A. Porter, and C. M. Deane, 
2009, eprint arXiv:0904.0989. 

Li, D., I. Leyva, J. A. Almendral, I. Sendiña-Nadal, J. M. 
Buldú, S. Havlin, and S. Boccaletti, 2008a, Phys. Rev. Lett. 
101(16), 168701. 

Li, Z., S. Zhang, R.-S. Wang, X.-S. Zhang, and L. Chen, 
2008b, Phys. Rev. E 77(3), 036109. 

Liben-Nowell, D., and J. Kleinberg, 2003, in CIKM ’03: Pro- 
ceedings of the twelfth international conference on Informa- 
tion and knowledge management (ACM, New York, NY, 
USA), pp. 556–559. 

Lin, Y.-R., Y. Chi, S. Zhu, H. Sundaram, and B. L. Tseng, 
2008, in WWW ’08: Proceedings of the 17th international 
conference on the World Wide Web (ACM, New York, NY, 
USA), pp. 685–694. 

Liu, X., D. Li, S. Wang, and Z. Tao, 2007, in ICCS ’07: 
Proceedings of the 7th international conference on Compu- 

tational Science, Part II (Springer-Verlag, Berlin, Heidel- 
berg), pp. 657–664. 

Lloyd, S., 1982, IEEE Trans. Inf. Theory 28(2), 129. 
Long, B., X. Xu, Z. Zhang, and P. S. Yu, 2007, in ICDM ’07: 

Proceedings of the 2007 Seventh IEEE International Con- 
ference on Data Mining (IEEE Computer Society, Wash- 
ington, DC, USA), pp. 232–241. 

Lovász, L., 1993, Combinatorial Problems and Exercises 
(North-Holland, Amsterdam, The Netherlands). 

Luccio, F., and M. Sami, 1969, IEEE Trans. Circuit Th. CT 
16, 184. 

Luce, R. D., 1950, Psychometrika 15(2), 169. 
Luce, R. D., and A. D. Perry, 1949, Psychometrika 14(2), 95. 
Luczak, T., 1992, in Proceedings of the Symposium on Ran- 

dom Graphs, Poznań 1989 (John Wiley & Sons, New York, 
USA), pp. 165–182. 

Lusseau, D., 2003, Proc. Royal Soc. London B 270, S186. 
von Luxburg, U., 2006, A tutorial on spectral clustering, Tech- 

nical Report 149, Max Planck Institute for Biological Cy- 
bernetics. 

Mackay, D. J. C., 2003, Information Theory, Inference, and 
Learning Algorithms (Cambridge University Press, Cam- 
bridge, UK). 

MacQueen, J. B., 1967, in Proc. of the fifth Berkeley Sym- 
posium on Mathematical Statistics and Probability, edit 
by L. M. L. Cam and J. Neyman (University of California 
Press, Berkeley, USA), volume 1, pp. 281–297. 

Mancoridis, S., B. S. Mitchell, C. Rorres, Y. Chen, and E. R. 
Gansner, 1998, in IWPC ’98: Proceedings of the 6th In- 
ternational Workshop on Program Comprehension (IEEE 
Computer Society, Washington, DC, USA). 

Mantegna, R. N., 1999, Eur. Phys. J. B 11, 193. 
Mantegna, R. N., and H. E. Stanley, 2000, An introduction to 

econophysics: correlation and complexity in finance (Cam- 
bridge University Press, New York, USA). 

Massen, C. P., and J. P. K. Doye, 2005, Phys. Rev. E 71(4), 
046101. 

Massen, C. P., and J. P. K. Doye, 2006, eprint cond- 
mat/0610077. 

Matsuda, H., T. Ishihara, and A. Hashimoto, 1999, Theor. 
Comp. Sci. 210, 305. 

Matula, D. W., and F. Shahrokhi, 1990, Discrete Appl. Math. 
27(1-2), 113. 

Medus, A., G. Acuña, and C. O. Dorso, 2005, Physica A 358, 
593. 

Mei, J., S. He, G. Shi, Z. Wang, and W. Li, 2009, New Journal 
of Physics 11(4), 043025. 

Meilă, M., 2007, J. Multivar. Anal. 98(5), 873. 
Meilă, M., and D. Heckerman, 2001, Mach. Learn. 42(1), 9. 
Meilă, M., and J. Shi, 2001, in AI and STATISTICS (AIS- 

TATS) 2001. 
Mendes, J. F. F., and S. N. Dorogovtsev, 2003, Evolution of 

Networks: from biological net to the Internet and WWW 
(Oxford University Press, Oxford, UK). 

Mézard, M., and G. Parisi, 2003, J. Stat. Phys. 111, 1. 
Mezard, M., G. Parisi, and M. Virasoro, 1987, Spin glass 

theory and beyond (World Scientific Publishing Company, 
Singapore). 

Middleton, A. A., and D. S. Fisher, 2002, Phys. Rev. B 
65(13), 134411. 

Milgram, S., 1967, Psychol. Today 2, 60. 
Milo, R., S. Shen-Orr, S. Itzkovitz, N. Kashtan, D. Chklovskii, 

and U. Alon, 2002, Science 298(5594), 824. 
Mirkin, B., 1996, Mathematical classification and cluster 



101 

(Kluwer Academic Press, Norwell, USA). 
Mitrović, M., and B. Tadić, 2009, Phys. Rev. E 80(2), 026123. 
Mokken, R. J., 1979, Qual. Quant. 13(2), 161. 
Molloy, M., and B. Reed, 1995, Random Struct. Algor. 6, 161. 
Moody, J., and D. R. White, 2003, Am. Sociol. Rev. 68(1), 

103. 
Muff, S., F. Rao, and A. Caflisch, 2005, Phys. Rev. E 72(5), 

056107. 
Mungan, M., and J. J. Ramasco, 2008, eprint 

arXiv:0809.1398. 
Nadler, B., S. Lafon, R. R. Coifman, and I. G. Kevrekidis, 

2006, Applied and Computational Harmonic Analysis 
21(1), 113. 

Narasimhamurthy, A., D. Greene, N. Hurley, and P. Cun- 
ningham, 2008, in Proc. 19th Irish Conference on Artificial 
Intelligence and Cognitive Science (AICS’08). 

Nelson, D. L., C. L. McEvoy, and T. A. Schreiber, 1998, The 
university of south florida word association, rhyme, and 
word fragment norms. 

Nepusz, T., A. Petróczi, L. Négyessy, and F. Bazsó, 2008, 
Phys. Rev. E 77(1), 016107. 

Newman, M. E. J., 2001, Proc. Nat. Acad. Sci. USA 98(2), 
404. 

Newman, M. E. J., 2003, SIAM Rev. 45(2), 167. 
Newman, M. E. J., 2004, Phys. Rev. E 70(5), 056131. 
Newman, M. E. J., 2004a, Eur. Phys. J. B 38, 321. 
Newman, M. E. J., 2004b, Phys. Rev. E 69(6), 066133. 
Newman, M. E. J., 2005, Soc. Netw. 27, 39. 
Newman, M. E. J., 2006a, Phys. Rev. E 74(3), 036104. 
Newman, M. E. J., 2006b, Proc. Natl. Acad. Sci. USA 103, 

8577. 
Newman, M. E. J., and T. Barkema, 1999, Monte Carlo Meth- 

od in Statistical Physics (Oxford University Press, Oxford, 
UK). 

Newman, M. E. J., and M. Girvan, 2004, Phys. Rev. E 69(2), 
026113. 

Newman, M. E. J., and E. A. Leicht, 2007, Proc. Natl. Acad. 
Sci. USA 104, 9564. 

Ng, A. Y., M. I. Jordan, and Y. Weiss, 2001, in Advances in 
Neural Information Processing Systems, edit by T. G. Di- 
etterich, S. Becker, and Z. Ghahramani (MIT Press, Cam- 
bridge, USA), volume 14. 

Nicosia, V., G. Mangioni, V. Carchiolo, and M. Malgeri, 2009, 
J. Stat. Mech. P03024. 

Nishikawa, T., A. E. Motter, Y.-C. Lai, and F. C. Hoppen- 
steadt, 2003, Phys. Rev. Lett. 91(1), 014101. 

Noack, A., 2009, Phys. Rev. E 79(2), 026102. 
Noack, A., and R. Rotta, 2009, in SEA ’09: Proceedings of the 

8th International Symposium on Experimental Algorithms 
(Springer-Verlag, Berlin, Heidelberg), pp. 257–268. 

Noh, J. D., and H. Rieger, 2001, Phys. Rev. Lett. 87(17), 
176102. 

Noh, J. D., and H. Rieger, 2002, Phys. Rev. E 66(3), 036117. 
Nowicki, K., and T. A. B. Snijders, 2001, J. Am. Stat. Assoc. 

96(455). 
Ohkubo, J., and K. Tanaka, 2006, J. Phys. Soc. Jpn. 75(11), 

115001. 
Onnela, J.-P., A. Chakraborti, K. Kaski, J. Kertész, and 

A. Kanto, 2003, Phys. Rev. E 68(5), 056110. 
Onnela, J.-P., A. Chakraborti, K. Kaski, and J. Kertész, 2002, 

Eur. Phys. J. B 30(3), 285. 
Orponen, P., and S. E. Schaeffer, 2005, in Proceedings 

of the 4th International Workshop on Efficient and Ex- 
perimental Algorithms (WEA’05, Santorini, Greece, May 

2005), edit by S. Nikoletseas (Springer-Verlag, Berlin- 
Heidelberg), volume 3503 of Lect. Notes Comp. Sci., pp. 
524–533. 

Palla, G., A.-L. Barabási, and T. Vicsek, 2007, Nature 446, 
664. 

Palla, G., I. Derényi, I. Farkas, and T. Vicsek, 2005, Nature 
435, 814. 

Palmer, C. R., and C. Faloutsos, 2003, in Proceedings of 
PAKDD 2003, pp. 486–500. 

Papadimitriou, C. M., 1994, Computational complexity 
(Addison-Wesley, Reading, USA). 

Papadopoulos, S., A. Skusa, A. Vakali, Y. Kompatsiaris, and 
N. Wagner, 2009, eprint arXiv:0902.0871. 

Pastor-Satorras, R., and A. Vespignani, 2001, Phys. Rev. 
Lett. 86(14), 3200. 

Pastor-Satorras, R., and A. Vespignani, 2004, Evolution and 
Structure of the Internet: A Statistical Physics Approach 
(Cambridge University Press, New York, NY, USA). 

Peeters, R., 2003, Discrete Appl. Math. 131, 651. 
Perkins, C. E., 2001, Ad Hoc Networking (Addison-Wesley, 

Reading, USA). 
Peterson, C., and J. R. Anderson, 1987, Compl. Syst. 1, 995. 
Pikovsky, A., M. G. Rosenblum, and J. Kurths, 2001, Syn- 

chronization : A Universal Concept in Nonlinear Sciences 
(Cambridge University Press, Cambridge, UK). 

Pimm, S. L., 1979, Theor. Popul. Biol. 16, 144. 
Pinney, J. W., and D. R. Westhead, 2006, in Interdisci- 

plinary Statistics and Bioinformatics (Leeds University 
Press, Leeds, UK), pp. 87–90. 

Pluchino, A., V. Latora, and A. Rapisarda, 2005, Int. J. Mod. 
Phys. C 16, 515. 

Pollner, P., G. Palla, and T. Vicsek, 2006, Europhys. Lett. 
73, 478. 

Pólya, G., and G. Szegö, 1998, Problems and Theorems in 
Analysis I (Springer-Verlag, Berlin, Germany). 

Pons, P., 2006, eprint arXiv:cs/0608050. 
Porter, M. A., P. J. Mucha, M. E. J. Newman, and A. J. 

Friend, 2007, Physica A 386, 414. 
Porter, M. A., P. J. Mucha, M. E. J. Newman, and C. M. 

Warmbrand, 2005, Proc. Natl. Acad. Sci. USA 102, 7057. 
Porter, M. A., J.-P. Onnela, and P. J. Mucha, 2009, Notices 

of the American Mathematical Society 56(9), 1082. 
Pothen, A., 1997, Graph Partitioning Algorithms with Appli- 

cation to Scientific Computing, Technical Report, Norfolk, 
VA, USA. 

Price, D. D., 1976, J. Am. Soc. Inform. Sci. 27(5), 292. 
Pujol, J. M., J. Béjar, and J. Delgado, 2006, Phys. Rev. E 

74(1), 016107. 
Radicchi, F., C. Castellano, F. Cecconi, V. Loreto, and 

D. Parisi, 2004, Proc. Natl. Acad. Sci. USA 101, 2658. 
Raghavan, U. N., R. Albert, and S. Kumara, 2007, Phys. Rev. 

E 76(3), 036106. 
Ramasco, J. J., and M. Mungan, 2008, Phys. Rev. E 77(3), 

036122. 
Rand, W. M., 1971, J. Am. Stat. Assoc. 66(336), 846. 
Rattigan, M. J., M. Maier, and D. Jensen, 2006, in 

SIGKDD’06: Proceedings of the 12th international confer- 
ence on Knowledge Discovery and Data Mining, edit by 
T. Eliassi-Rad, L. H. Ungar, M. Craven, and D. Gunopulos 
(ACM), pp. 357–366. 

Rattigan, M. J., M. Maier, and D. Jensen, 2007, in ICML 
’07: Proceedings of the 24th international conference on 
Machine learn (ACM, New York, NY, USA), pp. 783– 
790. 



102 

Ravasz, E., and A.-L. Barabási, 2003, Phys. Rev. E 67(2), 
026112. 

Ravasz, E., A. L. Somera, D. A. Mongru, Z. N. Oltvai, and 
A.-L. Barabási, 2002, Science 297(5586), 1551. 

Reddy, K. P., M. Kitsuregawa, P. Sreekanth, and S. S. Rao, 
2002, in DNIS ’02: Proceedings of the Second International 
Workshop on Databases in Networked Information Systems 
(Springer-Verlag, London, UK), pp. 188–200. 

Reichardt, J., and S. Bornholdt, 2004, Phys. Rev. Lett. 
93(21), 218701. 

Reichardt, J., and S. Bornholdt, 2006a, Phys. Rev. E 74(1), 
016110. 

Reichardt, J., and S. Bornholdt, 2006b, Physica D 224, 20. 
Reichardt, J., and S. Bornholdt, 2007, J. Stat. Mech. P06016. 
Reichardt, J., and S. Bornholdt, 2007, Phys. Rev. E 76(1), 

015102 (R). 
Reichardt, J., and M. Leone, 2008, Phys. Rev. Lett. 101(7), 

078701. 
Reichardt, J., and D. R. White, 2007, Eur. Phys. J. B 60, 

217. 
Ren, W., G. Yan, X. Liao, and L. Xiao, 2009, Phys. Rev. E 

79(3), 036111. 
Rhodes, C. J., and E. M. J. Keefe, 2007, J. Oper. Res. Soc. 

58(12), 1605. 
Rice, S. A., 1927, Am. Polit. Sci. Rev. 21, 619. 
Richardson, T., P. J. Mucha, and M. A. Porter, 2009, Phys. 

Rev. E 80(3), 036111. 
Rissanen, J., 1978, Automatica 14, 465. 
Rives, A. W., and T. Galitski, 2003, Proc. Natl. Acad. Sci. 

USA 100(3), 1128. 
Rodrigues, F. A., G. Travieso, and L. da F. Costa, 2007, Int. 

J. Mod. Phys. C 18, 937. 
Ronhovde, P., and Z. Nussinov, 2008, eprint arXiv:0803.2548. 
Ronhovde, P., and Z. Nussinov, 2009, Phys. Rev. E 80(1), 

016109. 
Rosvall, M., D. Axelsson, and C. T. Bergstrom, 2009, eprint 

arXiv:0906.1405. 
Rosvall, M., and C. T. Bergstrom, 2007, Proc. Natl. Acad. 

Sci. USA 104, 7327. 
Rosvall, M., and C. T. Bergstrom, 2008, eprint 

arXiv:0812.1242. 
Rosvall, M., and C. T. Bergstrom, 2008, Proc. Natl. Acad. 

Sci. USA 105, 1118. 
Rowicka, M., and A. Kudlicki, 2004, in Bayesian Inference 

and Maximum Entropy Methods in Science and Engineer- 
ing: 24th International Workshop on Bayesian Inference 
and Maximum Entropy Methods in Science and Engineer- 
ing, edit by R. Fischer, R. Preuss, and U. von Tous- 
saint (American Institute of Physics, Melville, USA), vol- 
ume 735, pp. 283–288. 

Ruan, J., and W. Zhang, 2007, in ICDM ’07: Proceedings of 
the 2007 Seventh IEEE International Conference on Data 
Mining (IEEE Computer Society, Washington, DC, USA), 
pp. 643–648. 

Ruan, J., and W. Zhang, 2008, Phys. Rev. E 77(1), 016104. 
S.-W. Son, H. Jeong, and J.D. Noh, 2006, Eur. Phys. J. B 

50(3), 431. 
Saerens, M., F. Fouss, L. Yen, and P. Dupont, 2004, in Proc. 

Eur. Conf. on Machine Learning, URL citeseer.ist.psu. 
edu/saerens04principal.html. 

Sales-Pardo, M., R. Guimerà, A. A. Moreira, and L. A. N. 
Amaral, 2007, Proc. Natl. Acad. Sci. USA 104, 15224. 

Sawardecker, E. N., M. Sales-Pardo, and L. A. N. Amaral, 
2009, Eur. Phys. J. B 67, 277. 

Schaeffer, S. E., 2007, Comput. Sci. Rev. 1(1), 27. 
Schenker, A., M. Last, H. Bunke, and A. Kandel, 2003, in 

IbPRIA’03: Proceedings of the 1st Iberian Conference on 
Pattern Recognition and Image Analysis, edit by F. J. P. 
López, A. C. Campilho, N. P. de la Blanca, and A. Sanfe- 
liu (Springer), volume 2652 of Lecture Notes in Computer 
Science, pp. 935–942. 

Schuetz, P., and A. Caflisch, 2008a, Phys. Rev. E 77(4), 
046112. 

Schuetz, P., and A. Caflisch, 2008b, Phys. Rev. E 78(2), 
026112. 

Schwarz, G., 1978, Ann. Stat. 6(2), 461. 
Scott, J., 2000, Social Network Analysis: A Handbook (SAGE 

Publications, London, UK). 
Seidman, S. B., 1983, Soc. Netw. 5, 269. 
Seidman, S. B., and B. L. Foster, 1978, J. Math. Sociol. 6, 

139. 
Sen, T. Z., A. Kloczkowski, and R. L. Jernigan, 2006, BMC 

Bioinf. 7(1), 355. 
Shen, H., X. Cheng, K. Cai, and M.-B. Hu, 2009, Physica A 

388, 1706. 
Shen, H.-W., X.-Q. Cheng, and J.-F. Guo, 2009, J. Stat. 

Mech. P07042. 
Sherrington, D., and S. Kirkpatrick, 1975, Phys. Rev. Lett. 

35, 1792. 
Shi, J., and J. Malik, 1997, in CVPR ’97: Proceedings of the 

1997 Conference on Computer Vision and Pattern Recog- 
nition (CVPR ’97) (IEEE Computer Society, Washington, 
DC, USA), p. 731. 

Shi, J., and J. Malik, 2000, IEEE Transactions on Pattern 
Analysis and Machine Intelligence 22(8), 888. 

Š́ıma, J., and S. E. Schaeffer, 2006, in Proceedings of the 
Thirty-second International Conference on Current Trends 
in Theory and Practice of Computer Science (Sofsem 06), 
edit by J. Wiedermann, G. Tel, J. Pokorný, M. Bieliková, 
and J. Štuller (Springer-Verlag, Berlin/Heidelberg, Ger- 
many), volume 3831 of Lecture Notes in Computer Science, 
pp. 530–537. 

Simon, H. A., 1962, Proc. Am. Phil. Soc. 106(6), 467. 
Simon, H. A., 1955, Biometrika 42, 425. 
Simonsen, I., 2005, Physica A 357(2), 317. 
Simonsen, I., K. Astrup Eriksen, S. Maslov, and K. Sneppen, 

2004, Physica A 336, 163. 
Slanina, F., and Y.-C. Zhang, 2005, Acta Phys. Pol. B 36, 

2797. 
Snijders, T. A. B., and K. Nowicki, 1997, J. Classif. 14, 75. 
de Solla Price, D. J., 1965, Science 169, 510. 
Solomonoff, R., and A. Rapoport, 1951, Bull. Math. Biophys. 

13, 107. 
Spielman, D. A., and S.-H. Teng, 1996, in IEEE Symposium 

on Foundations of Computer Science, pp. 96–105. 
Spirin, V., and L. A. Mirny, 2003, Proc. Natl. Acad. Sci. USA 

100(21), 12123. 
Stanley, R. P., 1997, Enumerative combinatorics, Vol. I 

(Cambridge University Press, Cambridge, UK). 
Steenstrup, M., 2001, Cluster-Based Networks (Addison Wes- 

ley, Reading, USA), chapter 4, pp. 75–138. 
Stewart, G. W., and J.-G. Sun, 1990, Matrix Perturbation 

Theory (Academic Press, New York, USA). 
Suaris, P. R., and G. Kedem, 1988, IEEE Trans. Circuits Syst. 

35, 294. 
Sun, J., C. Faloutsos, S. Papadimitriou, and P. S. Yu, 2007, in 

KDD ’07: Proceedings of the 13th ACM SIGKDD interna- 
tional conference on Knowledge discovery and data mining 

citeseer.ist.psu.edu/saerens04principal.html 
citeseer.ist.psu.edu/saerens04principal.html 


103 

(ACM, New York, USA), pp. 687–696. 
Sun, Y., B. Danila, K. Josic, and K. E. Bassler, 2009, Euro- 

phys. Lett. 86(2), 28004. 
Tasgin, M., A. Herdagdelen, and H. Bingol, 2007, eprint 

arXiv:0711.0491. 
Tibély, G., and J. Kertész, 2008, Physica A 387, 4982. 
Tishby, N., F. Pereira, and W. Bialek, 1999, in Proceedings of 

the 37-th Annual Allerton Conference on Communication, 
Control and Computing, pp. 368–377. 

Tong, H., C. Faloutsos, and J.-Y. Pan, 2008, Knowl. Inf. Syst. 
14(3), 327. 

Traag, V. A., and J. Bruggeman, 2009, Phys. Rev. E 80(3), 
036115. 

Traud, A. L., E. D. Kelsic, P. J. Mucha, and M. A. Porter, 
2008, eprint arXiv:0809.0690. 

Travers, J., and S. Milgram, 1969, Sociometry 32, 425. 
Tumminello, M., F. Lillo, and R. N. Mantegna, 2008, eprint 

arXiv:0809.4615. 
Tyler, J. R., D. M. Wilkinson, and B. A. Huberman, 2003, 

in Communities and technology (Kluwer, B.V., Deventer, 
The Netherlands), pp. 81–96. 

Vazquez, A., 2008, eprint arXiv:0805.2689. 
Vazquez, A., 2008, Phys. Rev. E 77(6), 066106. 
Vragović, I., and E. Louis, 2006, Phys. Rev. E 74(1), 016105. 
Wakita, K., and T. Tsurumi, 2007, eprint arXiv:cs/0702048. 
Wallace, C. S., and D. M. Boulton, 1968, The Computer Jour- 

nal 11(2), 185. 
Wallace, D. L., 1983, J. Am. Stat. Assoc. 78, 569. 
Wang, G., Y. Shen, and M. Ouyang, 2008, Comput. Math. 

Appl. 55(12), 2746. 
Ward, J. H., 1963, J. Am. Stat. Assoc. 58(301), 236. 
Wasserman, S., and K. Faust, 1994, Social network analysis 

(Cambridge University Press, Cambridge, UK). 
Watts, D., and S. Strogatz, 1998, Nature 393, 440. 
Watts, D. J., 2003, Small Worlds : The Dynamics of Net- 

work between Order and Randomness (Princeton Univer- 
sity Press, Princeton, USA). 

Wei, Y.-C., and C.-K. Cheng, 1989, in Proceedings of IEEE 
International Conference on Computer Aided Design (In- 
stitute of Electrical and Electronics Engineers, New York), 
pp. 298–301. 

Weinan, E., T. Li, and E. Vanden-Eijnden, 2008, Proc. Natl. 
Acad. Sci. USA 105, 7907. 

Weiss, R. S., and E. Jacobson, 1955, Am. Sociol. Rev. 20, 
661. 

White, D. R., and K. P. Reitz, 1983, Soc. Netw. 5, 193. 
White, S., and P. Smyth, 2003, in KDD ’03: Proceedings 

of the ninth ACM SIGKDD international conference on 
Knowledge discovery and data mining (ACM, New York, 
NY, USA), pp. 266–275. 

White, S., and P. Smyth, 2005, in Proceedings of SIAM In- 

ternational Conference on Data Mining, pp. 76–84. 
Wilkinson, D. M., and B. A. Huberman, 2004, Proc. Natl. 

Acad. Sci. U.S.A. 101, 5241. 
Williams, R. J., and N. D. Martinez, 2000, Nature 404, 180. 
Winkler, R. L., 2003, Introduction to Bayesian Inference and 

Decision (Probabilistic Publishing, Gainesville, USA). 
Wu, A. Y., M. Garland, and J. Han, 2004, in KDD ’04: Pro- 

ceedings of the tenth ACM SIGKDD international confer- 
ence on Knowledge discovery and data mining (ACM Press, 
New York, NY, USA), pp. 719–724. 

Wu, F., and B. A. Huberman, 2004, Eur. Phys. J. B 38, 331. 
Wu, F. Y., 1982, Rev. Mod. Phys. 54(1), 235. 
Xiang, B., E.-H. Chen, and T. Zhou, 2009, in Complex Net- 

works, edit by S. Fortunato, R. Menezes, G. Mangioni, 
and V. Nicosia (Springer Verlag, Berlin/Heidelberg, Ger- 
many), volume 207 of Studies in Computational Intelli- 
gence, pp. 73–81. 

Xu, G., S. Tsoka, and L.G. Papageorgiou, 2007, Eur. Phys. 
J. B 60(2), 231. 

Yang, B., and J. Liu, 2008, ACM Trans. Web 2(1), 1. 
Ye, Z., S. Hu, and J. Yu, 2008, Phys. Rev. E 78(4), 046115. 
Yen, L., F. Fouss, C. Decaestecker, P. Francq, and M. Saerens, 

2007, in PAKDD, pp. 1037–1045. 
Yen, L., F. Fouss, C. Decaestecker, P. Francq, and M. Saerens, 

2009, Data Knowl. Eng. 68(3), 338. 
Yuta, K., N. Ono, and Y. Fujiwara, 2007, eprint 

physics/0701168. 
Zachary, W. W., 1977, J. Anthropol. Res. 33, 452. 
Zanghi, H., C. Ambroise, and V. Miele, 2008, Pattern Recogn. 

41(12), 3592. 
Zarei, M., and K. A. Samani, 2009, Physica A 388, 1721. 
Zhang, A., 2009, Protein Interaction Networks (Cambridge 

University Press, Cambridge, UK). 
Zhang, P., M. Li, J. Wu, Z. Di, and Y. Fan, 2006, Physica A 

367, 577. 
Zhang, P., J. Wang, X. Li, Z. Di, and Y. Fan, 2007, eprint 

arXiv:0710.0117. 
Zhang, S., R.-S. Wang, and X.-S. Zhang, 2007, Physica A 

374, 483. 
Zhang, Y., A. J. Friend, A. L. Traud, M. A. Porter, J. H. 

Fowler, and P. J. Mucha, 2008, Physica A 387(7), 1705. 
Zhou, H., 2003a, Phys. Rev. E 67(6), 061901. 
Zhou, H., 2003b, Phys. Rev. E 67(4), 041908. 
Zhou, H., and R. Lipowsky, 2004, Lect. Notes Comp. Sci. 

3038, 1062. 
Zhou, T., J.-G. Liu, and B.-H. Wang, 2006, Chin. Phys. Lett. 

23, 2327. 
Ziv, E., M. Middendorf, and C. H. Wiggins, 2005, Phys. Rev. 

E 71(4), 046117. 


Contents 
I Introduction 
II Communities in real-world network 
III Elements of Community Detection 
A Computational complexity 
B Communities 
1 Basics 
2 Local definition 
3 Global definition 
4 Definitions base on vertex similarity 

C Partitions 
1 Basics 
2 Quality functions: modularity 


IV Traditional method 
A Graph partition 
B Hierarchical cluster 
C Partitional cluster 
D Spectral cluster 

V Divisive algorithm 
A The algorithm of Girvan and Newman 
B Other method 

VI Modularity-based method 
A Modularity optimization 
1 Greedy technique 
2 Simulated anneal 
3 Extremal optimization 
4 Spectral optimization 
5 Other optimization strategy 

B Modifications of modularity 
C Limits of modularity 

VII Spectral Algorithms 
VIII Dynamic Algorithms 
A Spin model 
B Random walk 
C Synchronization 

IX Methods base on statistical inference 
A Generative model 
B Blockmodeling, model selection and information theory 

X Alternative method 
XI Methods to find overlap community 
A Clique percolation 
B Other technique 

XII Multiresolution method and cluster hierarchy 
A Multiresolution method 
B Hierarchical method 

XIII Detection of dynamic community 
XIV Significance of cluster 
XV Testing Algorithms 
A Benchmarks 
B Comparing partitions: measure 
C Comparing algorithm 

XVI General property of real cluster 
XVII Applications on real-world network 
A Biological network 
B Social network 
C Other network 

XVIII Outlook 
A Elements of Graph Theory 
1 Basic Definitions 
2 Graph Matrices 
3 Model graph 

References 

