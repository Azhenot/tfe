






















































Learning to Optimize Combinatorial Functions 


Learning to Optimize Combinatorial Functions 

Nir Rosenfeld 1 Eric Balkanski 1 Amir Globerson 2 Yaron Singer 1 

Abstract 
Submodular function have become a ubiquitous 
tool in machine learning. They be learnable 
from data, and can be optimize efficiently and 
with guarantees. Nonetheless, recent negative 
result show that optimize learn surrogate 
of submodular function can result in arbitrarily 
bad approximation of the true optimum. Our 
goal in this paper be to highlight the source of 
this hardness, and propose an alternative criterion 
for optimize general combinatorial function 
from sample data. We prove a tight equivalence 
show that a class of function be optimizable if 
and only if it can be learned. We provide efficient 
and scalable optimization algorithm for several 
function class of interest, and demonstrate their 
utility on the task of optimally choose trend 
social medium items. 

1. Introduction 
Submodular optimization be fast become a primary tool in 
machine learning. The power of submodularity a a model 
have be demonstrate in numerous applications, include 
document summarization (Lin & Bilmes, 2011), cluster- 
ing (Gomes & Krause, 2010), active learn (Golovin & 
Krause, 2011; Guillory & Bilmes, 2011; Hoi et al., 2006), 
graph and network inference (Gomez Rodriguez et al., 2010; 
Rodriguez & Schölkopf, 2012; Defazio & Caetano, 2012), 
and information diffusion in network (Kempe et al., 2003). 
Crucial to the success of these method be the fact that op- 
timizing submodular function can be do efficiently and 
with provable guarantee (Krause & Golovin, 2014). 

In many cases, however, the true function cannot be ac- 
cessed, and instead a surrogate function be learn from 
data (Balkanski et al., 2017). To this end, PMAC learn 
(Balcan & Harvey, 2011) offer a framework for analyze 
the learnability of submodular functions, a well a algo- 

1Harvard University 2Tel Aviv University. Correspondence to: 
Nir Rosenfeld <nirr@g.harvard.edu>. 

Proceedings of the 35 th International Conference on Machine 
Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 
by the author(s). 

rithms for learn in practice. Encouraging result show 
that in many case submodular function can be efficiently 
learn from data (Balcan & Harvey, 2011; Iyer et al., 2013; 
Feldman & Kothari, 2014; Feldman & Vondrak, 2016). A 
natural approach in this set be to first learn a surrogate 
function from samples, and then optimize it, hop that the 
estimate optimum will be close to the true one. A recent 
line of work have be devote to this set of optimization 
from sample (OPS) (Balkanski et al., 2016; 2017). 

The main result of OPS be unfortunately discouraging: for 
maximize a submodular function under a cardinality con- 
straint, no algorithm can obtain a constant factor approxi- 
mation guarantee give polynomially-many sample from 
any distribution (Balkanski et al., 2017). Thus, optimize 
over learn surrogate do not provide any meaningful 
guarantee with respect to the true function. 

The hardness of OPS is, however, a worst-case result. The 
hardness stem from the discrepancy between how the algo- 
rithm gain access to information (via samples) and how it 
be evaluate (globally). In contrast, machine learn objec- 
tives be typically concerned with expect outcomes, and 
be evaluate over the same distribution from which data be 
acquire (Valiant, 1984). In this paper, we build on this moti- 
vation and propose an alternative framework for optimize 
from samples. The objective we propose, call distribu- 
tional optimization from sample (DOPS), circumvents the 
above difficulty by consider a distribution-dependent 
objective. In general, a function class F be in α-DOPS if an 
α-approximation of the empirical argmax can be found with 
arbitrarily high probability use polynomially many sam- 
ples, for any distribution D and for any f ∈ F . Formally: 
Definition 1 (α-DOPS). Let F = {f : 2[n] → R+} be a 
class of set function over n elements. We say that F be 
α-distributionally optimizable from sample if there be an 
algorithm A that, for every distribution D over 2[n], every 
f ∈ F , and every �, δ ∈ [0, 1], when A be give a input 
a sample set S = {(Si, f(Si))}Mi=1 where Si 

iid∼ D, with 
probability of at least 1− δ over S it hold that: 

PT ∼Dm 
[ 
f 
( 
A(T ) 

) 
≥ αmax 

S∈T 
f(S) 

] 
≥ 1− � (1) 

where T = {(Sj)}mj=1, A(T ) ∈ T be the output of the 
algorithm, and S be of size M ∈ poly(n,m, 1/�, 1/δ). 



Learning to Optimize Combinatorial Functions 

The criterion in Eq. (1) relaxes the OPS objective to hold in 
expectation over D. This be achieve by replace the entire 
combinatorial domain with a sample subset T of size m, 
allow for a distribution-agnostic notion of approximation. 
As m increases, satisfy Eq. (1) be expect to be harder. 
When m→∞, DOPS recovers OPS. 

Our first goal in this paper be to establish the hardness of 
DOPS. In general, classic approximation result do not nec- 
essarily transfer to statistical setting (Balkanski et al., 2017). 
Nonetheless, our main theoretical result establishes a tight 
equivalence between DOPS and PMAC learn (Balcan & 
Harvey, 2011), meaning that any F that be learnable be also 
optimizable, and vice versa. This demonstrates an intrigue 
link between learn and optimize submodular functions, 
which be know to be PMAC-learnable (Balcan & Harvey, 
2011). The equivalence result be constructive, and give a 
general optimization algorithm which can utilize any PMAC 
learner a a black box for DOPS, and vice versa. While our 
main focus in this paper be on submodular functions, these 
result hold for any family of combinatorial functions. 

In practice, however, optimize via PMAC algorithm have 
several drawback (Balcan & Harvey, 2011; Feldman & 
Kothari, 2014; Feldman & Vondrak, 2016). Our second 
goal in this paper be hence to design an efficient and scal- 
able DOPS algorithm for several class of interest. Our 
algorithm optimizes a loss function whose minimization 
provide a sufficient condition for DOPS. We prove that the 
minimizer of the empirical loss can be use for recover 
an approximate argmax. In this sense, the framework we 
propose be one in which the algorithm “learns to optimize”. 
We show how the loss can be minimize efficiently and with 
guarantee for several submodular function classes, includ- 
ing coverage functions, cut functions, and unit demand. 

An additional benefit of our approach be that it provide guar- 
antees even when the output of the algorithm be restrict to 
a set of sample alternatives. This set be especially preva- 
lent in case where both set and their value be generate 
by human users. For example, in the problem of influence 
maximization (Kempe et al., 2003), the goal be to choose 
a “seed” set of user such that, when expose to certain 
content, will maximize it expect propagation. However, 
target arbitrary subset of user be in most case impos- 
sible, and the algorithm must choose between the set of 
user share currently trend items. In the last part of the 
paper we demonstrate the empirical utility of our approach 
on this task use real data from Twitter. 

2. Distributional optimization and learn 
In this section we give a tight characterization of function 
class in DOPS by show that a class F be in DOPS if 
and only if it be PMAC-learnable. This involves two steps. In 

the first, we show that if F be α-PMAC learnable with sam- 
ple complexity MPMAC, then it be α-DOPS. We augment this 
result with tight sample complexity bound for α-DOPS. In 
the second part, we show that PMAC learnability be not only 
sufficient but also necessary for distributional optimization 
from samples. We show that if F be not α-PMAC learnable, 
then it be not (α− �)-DOPS for any constant � > 0, which be 
tight. This result be obtain by construct a novel PMAC 
algorithm base on a DOPS black-box, and may thus be of 
separate interest in PMAC analysis. Overall, our result de- 
termine the hardness of DOPS by establish a connection 
between the approximability and learnability of function 
classes. 

We begin by review the notion of PMAC learnability: 

Definition 2 (PMAC, Balcan & Harvey (2011)). A class F 
be α-PMAC-learnable if there be an algorithm such that for 
every distribution D, every f ∈ F , and every �, δ ∈ [0, 1], 

PS∼D 
[ 
f̃(S) ≤ f(S) ≤ αf̃(S) 

] 
≥ 1− � (2) 

where the input of the algorithm be a set S of size M ∈ 
poly(n, 1/�, 1/δ), the output be a mapping f̃ : 2[n] → R+, 
and Eq. (2) hold w.p. at least 1− δ over S. 

Intuitively, PMAC generalizes the standard notion of PAC 
learn by consider a loss which penalizes prediction 
that be not within a factor of α of their true value. 

We be now ready to prove our main theoretical results. 

2.1. If F be PMAC-learnable then F be in DOPS 

We show that if F be α-PMAC learnable with sample com- 
plexity MPMAC(n, δ, �, α), then it be α-DOPS with sample 
complexity MPMAC(n, δ, 1− (1− �)1/m, α), and this sample 
complexity be tight. A PMAC algorithm learns a surrogate 
function f̃ . In our reduction, the correspond DOPS algo- 
rithm simply output argmaxS∈T f̃(S). The technical part 
of this result be in show the sample complexity tightness. 
Intuitively, the sample complexity be exactly the number of 
sample that be need so that, with high probability, f̃ 
obtains a good approximation on all S ∈ T . We begin by 
show that MPMAC(n, δ, 1 − (1 − �)1/m, α) be sufficient, 
which follow from the definition of PMAC. 

Theorem 1. Assume F be α-PMAC-learnable with sample 
complexity MPMAC(n, δ, �, α), then F be α-DOPS with sam- 
ple complexity at most MPMAC(n, δ, 1− (1− �)1/m, α), i.e., 

MDOPS(n,m, δ, �, α) ≤MPMAC(n, δ, 1− (1− �)1/m, α). 

Proof. Let f ∈ F , D be some distribution, S = 
{(Si, f(Si))}Mi=1 and T = {Si}mi=1 be the train and test 
sets, andA be an algorithm that construct f̃ which α-PMAC 
learns f with sample complexity MPMAC(n, δ, �, α). 



Learning to Optimize Combinatorial Functions 

The DOPS algorithm that we analyze construct f̃ with 
algorithm A use S and return 

S̃? = argmax 
S∈T 

f̃(S). 

Fix �, δ > 0 and α > 1 and consider M = MPMAC(n, δ, 1− 
(1 − �)1/m, α). By the definition of α-PMAC, we get that 
with probability 1− δ over S, 

Pr 
S∼D 

[ 
f̃(S) ≤ f(S) ≤ α · f̃(S) 

] 
≥ (1− �)1/m. 

Next, we obtain 

Pr 
T 

[ 
f̃(S) ≤ f(S) ≤ α · f̃(S) : ∀S ∈ T 

] 
= 
( 

Pr 
S∼D 

[ 
f̃(S) ≤ f(S) ≤ α · f̃(S) 

])m 
≥ 1− �. 

where the equality be due to the set S ∈ T be drawn 
i.i.d. fromD, and the inequality hold with probability 1−δ 
over S. We define S? = argmaxS∈T f(S) and obtain that 
with probability 1− � over T and 1− δ over S, 

f(S̃?) ≥ f̃(S̃?) ≥ f̃(S?) ≥ α−1f(S?). 

We conclude that withM = MPMAC(n, δ, 1−(1−�)1/m, α), 

f(S̃?) ≥ 1 
α 
·max 
S∈T 

f(S) 

with probability 1− � over T and 1− δ over S. 

For tightness, we give an information-theoretic low bound 
by construct a difficult class F that cannot be in α-DOPS 
with less than MPMAC(n, δ, 1− (1− �)1/m, α) samples. 
Theorem 2. For all α > 1 and �, δ > 0, for m sufficiently 
large, there exists a family of function F and a function 
MPMAC(·) such that 

• for all �′, δ′ > 0: F be α-PMAC-learnable with sample 
complexity MPMAC(n, δ′, �′, α), and 

• give strictly less than MPMAC(n, δ, 1− (1− �)1/m, α) 
samples, F be not α-DOPS, i.e., 

MDOPS(n,m, δ, �, α) ≥MPMAC(n, δ, 1−(1−�)1/m, α). 

Proof Sketch (see supp. material for full proof). For each 
f in the difficult F , only a single set S? have a high value, 
while all others have low values. We consider a uniformly 
random function f ∈ F and the correspond randomize 
subclass F ′ ⊆ F which consists of all function f ′ such 
that S? be in the test set but not in the train set. 

Informally, an algorithm which aim to optimize f ∈ F ′ 
cannot use the train set to learn which S ∈ T be S?. More 

precisely, if f ∈ F ′, the decision of the algorithm be 
independent of the randomization of f , condition on f ∈ 
F ′. Thus, if f ∈ F ′, the algorithm do not obtain an α- 
approximation because of the gap between the value of S? 

and the other sets. 

We construct F and D such that S? be in the test set w.p. 
great than 1 − �. This implies that to satisfy DOPS, the 
algorithm must observe enough sample so that S? be in the 
train set w.p. at least 1− δ. We then argue that this number 
of sample be at least MPMAC(n, δ, 1− (1− �)1/m, α). 

2.2. If F be not PMAC-learnable then F be not in DOPS 

A simple intuition for Theorem 1 be that if one can accu- 
rately predict the value of all S ∈ T , then it be possible 
to find the empirical argmax. The main result in this sec- 
tion, which be perhaps less intuitive, show that the reverse 
implication also holds. Namely, if one can find the the em- 
pirical argmax, then it be possible to infer the value of all 
set in T . The contrapositive of this result be that if F be 
not PMAC-learnable, then F be not in DOPS. Combining 
both result provide a full characterization of distributional 
optimization in term of learnability. 

To construct a PMAC learner from a DOPS algorithm, we 
first randomly partition S into “train” and “test” sets. We 
then train the DOPS algorithm on the train set, and use it 
to generate pairwise comparison with test elements. The 
learn value for S be give by the maximum value of a test 
sample that S “beats” (via the infer comparisons). At 
a high level, the analysis us the DOPS guarantee and a 
bucketing argument to satisfy the PMAC requirements. 
Theorem 3. Let µ = maxS f(S)/minS:f(S)>0 f(S), 
c be any constant such that 1 ≤ α ≤ c, and 
Mµ = 

8 log µ 
� log c 

( 
1 
� + 2 log 

( 
1 
δ 

)) 
. If a class F be in α- 

DOPS with sample complexity MDOPS(n,m, �, δ, α), then 
it be α-PMAC-learnable with sample complexity Mµ + 
MDOPS(n, 2, �/Mµ, δ/Mµ, α/c), i.e., 

MPMAC(n, �, δ, α) ≥Mµ+MDOPS(n, 2, �/Mµ, δ/Mµ, α/c). 

Proof. Fix �, δ > 0 and α > 1. Let S = {(Si, f(Si))}Mi=1 
be the sample from D that be give a input. We partition 
the sample in S uniformly at random into S1 and S2 of 
size M1 and M2, respectively. For some S ∼ D, the goal 
be to predict f̃(S) such that f̃(S) ≤ f(S) ≤ α · f̃(S). 

For each Si ∈ S2, define S2,i := {Si, S}. Since F be 
in DOPS, with M1 = MDOPS(n, 2, �/M2, δ/M2, α/c) sam- 
ples, the algorithm output S?i ∈ S2,i such that with proba- 
bilities 1− δ/M2 over S1 and 1− �/M2 over S2,i, 

f(S?i ) ≥ 
α 

c 
max(f(S), f(Si)). 

By a union bound, this hold for all i ∈M2 with probability 
1− δ over S1 and probability 1− � over S and S2. 



Learning to Optimize Combinatorial Functions 

We say that S “beats” Si if the α-DOPS algorithm output 
S when give S2,i. Let S−2 be the collection of set Si in 
S2 such that S beat Si. The learn algorithm be 

f̃(S) = 
c 

α 
· max 
Si∈S−2 

f(Si). 

Let fmin = minS f(S) and fmax = maxS f(S). We parti- 
tion the set into bucket define a follows: 

Bi := {S : fmin · ci−1 ≤ f(S) < fminci} 

for i ≥ 1 and B0 = {S : f(S) = 0}. With β := 
logµ/ log c buckets, all set S be in a bucket since fmin ≤ 
f(S) ≤ fmax. We define a bucket Bi to be dense if a ran- 
dom set S ∼ D have non-negligible probability to be in 
Bi, otherwise it be sparse. More precisely, Bi be dense if 
PrS∼D [S ∈ Bi] ≥ �/2β. 

The set S be in a dense bucket Bi with probability at least 
1 − �2 since there be at most β bucket that be not dense 
and S be in each of them with probability at most �2β by the 
definition of dense bucket. With m samples, the expect 
number of sample in Bi be at least m �2β and by a standard 
concentration bound, 

Pr 

[ 
|Bi| ≤ 

m 

2 

� 

2β 

] 
≤ e− 

m� 
16β 

We assume that |Bi| ≥ m2 
� 

2β for the remainder of the proof. 
There be at most one set in bucket Bi that be beaten by all 
the other sets. Since the set S have equal probability to be 
any of the set in Bi,1 there be at least one other set S− in 
Bi which S beat with probability 1/|Bi| ≤ 4β/m�. 

With δ ≥ e− 
m� 
16β (and hence m ≥ log(1/δ)16β� ), with prob- 

ability of at least 1− δ, the number of sample in Bi be at 
least m �4β . With �/2 ≥ 4β/m� (and hence m ≥ 8β/� 

2), 
with probability of at least 1− � over S ∼ D, S be in a dense 
bucket and beat at least one other S− ∈ S−2 in that bucket. 

We get that: 

f̃(S) = 
c 

α 
· max 
Si∈S−2 

f(Si) ≥ 
c 

α 
· f(S−) ≥ 1 

α 
· f(S) 

where the equality be by the definition of f̃(S), the first 
inequality be since S− ∈ S−2 , and the last be since S and S− 
be in the same bucket. We also have 

f(S) ≥ α 
c 
· max 
Si∈S−2 

f(Si) = f̃(S) 

where the inequality be by the definition of S−2 and the equal- 
ity by definition of f̃(S). Thus, f̃(S) ≤ f(S) ≤ αf̃(S) and 
with M2 = m ≥ 8 log µ� log c 

( 
1 
� + 2 log 

( 
1 
δ 

)) 
= Mµ, the sample 

complexity be Mµ +MDOPS(n, 2, �/Mµ, δ/Mµ, α/c). 

1We assume that the DOPS algorithm break tie in a consistent 
manner, i.e., it cannot be adversarial and break tie depend on 
whether S be the set we wish to learn or if S ∈ S2. 

Algorithm 1 DOPS(S = {(Si, zi)}Mi=1, m, α) 
1: Randomly partition [M ] into N = bMm c set A1, . . . , AN 
2: Create m-tuple sample set S = {(Si, zi)}Ni=1 from S 

where Si = {Sj}j∈Ai and z 
i = {zj}j∈Ai 

3: Compute α(zi) = {y ∈ [m] : ziy ≥ αmax zi} ∀ i ∈ [N ] 

4: θ̂ = argmin 
θ∈Θ 

N∑ 
i=1 

max 
y 

[1{y 6∈α(zi)} + fθ(S 
i 
y)− ψθ(Si, zi)]+ 

where ψθ(S, z) = 1|α(z)| 
∑ 
y∈α(z) fθ(Sy) 

5: Return h 
θ̂ 
(T ) = argmax 

S∈T 
f 
θ̂ 
(S) 

3. Learning to Optimize at Scale 
In this section we give an efficient DOPS algorithm that 
applies to several interest parametric submodular sub- 
class FΘ = {fθ : θ ∈ Θ}. Our general technique 
include two steps. First, we identify a loss function whose 
minimization provide a sufficient condition for DOPS (Eq. 
(1)), but be in general hard to optimize. Then, we show that 
for the function class we consider, a transformation of the 
input reveals structure which can be exploit for efficiently 
optimize a convex surrogate loss. Note that in principle, 
due to Thm. 1, any PMAC algorithm can be use for DOPS. 
This, however, have several practical disadvantages, which 
we comment on in Sec. 3.5. 

We begin by illustrate our approach for coverage function 
with parametric weights. We then describe our algorithm, 
prove it correctness, and show how it can be apply to 
other class such a graph cuts, unit demand, and coverage 
function with parametric cover sets. 

3.1. Learning to optimize coverage function 

Coverage function be a simple but important class of sub- 
modular functions, and have be use in application such 
a computational linguistics (Sipos et al., 2012), algorith- 
mic game theory (Dughmi & Vondrák, 2015), and influence 
maximization in social network (Kempe et al., 2003). Let 
U be a ground set of d items, and C = {C1, . . . , Cn} a col- 
lection of subset where Ci ⊆ U . For a set of non-negative 
item weight θ = {θ1, . . . , θd}, a function fθ : 2[n] → R be 
a coverage function if: 

fθ(S) = 
∑ 

u∈C(S) 

θu, C(S) = 
⋃ 
i∈S 

Ci (3) 

While apparently simple, coverage function be quite ex- 
pressive, and optimize them from sample be know to 
be hard (Balkanski et al., 2017). One reason be that, a a 



Learning to Optimize Combinatorial Functions 

function of their input S, coverage function can be highly 
non-linear. Meanwhile, a a function of their parameters, 
they become linear via a simple transformation of the inputs: 

fθ(S) = 〈φ(S), θ〉, φu(S) = 1{∃ i∈S s.t. u∈Ci} (4) 

This structure allows our algorithm to efficiently find the 
approximate empirical argmax of any give T with high 
probability. The output of the algorithm be a function h ∈ H 
for choose one S out of the m candidate in T , where: 

H = {hθ(T ) = argmax 
S∈T 

fθ(S) : θ ∈ Θ} (5) 

In this sense, our method “learns” how to optimize over 
collection of size m. 

3.2. Algorithm 

Pseudocode of our DOPS algorithm be give in Algorithm 1. 
The follow theorem establishes it correctness: 

Theorem 4. Let m ∈ N and �, δ ∈ [0, 1], and let f = fθ∗ 
with θ∗ ∈ Θ. For a give α > 0, let h be the output of 
Algorithm 1 when give S = {(Si, zi)}Mi=1, m, and α a 
input, where z = fθ(S) and S 

iid∼ D. Then, with probability 
of at least 1− δ over S, it hold that: 

PT ∼Dm 
[ 
f 
( 
h(T ) 

) 
≥ αmax 

S∈T 
f(S) 

] 
≥ 1− � (6) 

for M ≥ Õ(m(kB/�)2) with k = max |S|, B = ‖θ∗‖2. 

The follow proof hold for any class of function that 
can be make linear in their parameter under some represen- 
tation. This include the coverage function in Sec. 3.1 a 
well a the class we consider in Sec. 3.3. 

Proof. We begin with some notation. Let S = 
{S1, . . . , Sm} be a set of m example with correspond 
value z = {z1, . . . , zm} where zy = f(Sy). Algorithm 1 
return a function h that chooses a set Sy ∈ S. It will be 
convenient to instead view h a a mapping from S to index 
y ∈ [m]. Denote the set of α-approximate solution by: 

α(z) = {y ∈ [m] : zy ≥ αmax z} (7) 

Our analysis make use of the follow loss function: 

∆α(z, y) = 1{y 6∈ α(z)} (8) 

Eq. (8) be useful since L(h) := E[∆α(z, h(S))] ≤ � im- 
ply that h satisfies Eq. (6). We therefore focus on bound 
L(h). As we do not have access toD, our algorithm chooses 
an h ∈ H which instead minimizes the empirical loss. Note 
that while ∆α be define over m-tuples, S contains individ- 
ual sets. To ensure a consistent empirical loss, we randomly 

partition [M ] into N = M/m distinct set A1, . . . , AN , 
and define anm-tuple sample set S = {(Si, zi)}Ni=1, where 
Si = {Sy}y∈Ai and zi = {zy}y∈Ai . The loss be now: 

L̂(h;S) = 1 
N 

N∑ 
i=1 

∆α(z 
i, ŷi), ŷi = h(Si) (9) 

Since ∆α be not convex, the algorithm instead optimizes a 
surrogate convex upper bound. There be many way to do 
this; here we use an average hinge surrogate: 

max 
y∈[m] 

[∆α(z 
i, y) + fθ(S 

i 
y)− ψθ(Si, zi)]+ (10) 

where [a]+ = max{0, a} and: 

ψθ(S, z) = 
1 

|α(z)| 
∑ 

y∈α(z) 
fθ(Sy) (11) 

Eq. (10) be similar in spirit to the loss in (Lapin et al., 2015), 
and be tight w.r.t. Eq. (9) whenever L̂ = 0, Intuitively, 
minimize Eq. (10) push θ towards value for which the 
true argmax be score high than all others by a margin. 
Note that the average in Eq. (11) can be replace with a 
max to attain a tighter (though no longer convex) surrogate. 

Since S be label by some fθ∗ ∈ FΘ, we have that 
L(hθ∗) = 0. This mean that there be some θ ∈ Θ such 
that with L̂(hθ;S) = 0, and due to the tightness of Eq. (10), 
L̃(hθ;S) = 0 a well. This be sufficient for apply the 
follow generalization bound (Collins, 2004): 

L(h) ≤ O 

(√ 
m 

M 

( 
(kB logM)2 + log 

1 

δ 

)) 
(12) 

Plugging in M give L(h) ≤ �, conclude the proof. 

Eq. (10) be convex whenever fθ be linear in θ for some repre- 
sentation φ. This hold for coverage function (Eq. (4)) a 
well a for the other class we consider in Sec. 3.3. Eq. (10) 
can then be optimize use standard convex solvers, or with 
highly efficient and scalable solver such a the cut plane 
method of Joachims et al. (2009). 

3.3. Other submodular class 

We now discus how our method can be extend to other 
submodular function classes. For each class, we give a 
transformation φ of the input under which the function 
becomes linear in it parameters. Thm. 4 and Algorithm 1 
can then be apply with the appropriate fθ(S) = 〈φ(S), θ〉. 

Graph k-cuts: Let G = (V,E) be an undirected graph, 
and let θ ∈ R|E|+ be edge weights. For a partition P ∈ [k]|V | 
of the node into k groups, it value be give by: 

fθ(P ) = 
1 

2 

∑ 
(u,v)∈E 
Pu 6=Pv 

θuv 



Learning to Optimize Combinatorial Functions 

While k-cut function be know to be hard to optimize over 
P , they become linear in θ with the transformation: 

φuv(P ) = 1{Pu 6= Pv} ∀ (u, v) ∈ E 

Unit demand: Let θ ∈ Rn+ be a set of item weights. The 
value of a subset S ⊆ [n] be give by: 

fθ(S) = max 
u∈S 

θu 

Although it be possible to write fθ = 〈θ, φ(S)〉 with 
φu(S) = 1{θu≥θv ∀v∈S}, this representation require θ, 
which be unknown. Nonetheless, a similar data-dependent 
construction can still be use to obtain some θ′ which min- 
imizes the loss. To see why, let S̄ ∈ S be the set with the 
high value fθ(S̄) in S. For this S̄, there must exist some 
u ∈ S̄ that be not in any other S ∈ S with fθ(S) < fθ(S̄). 
By set φv(S̄) = 1{u=v} and θ′u = fθ(S̄), we ensure 
that fθ(S̄) = 〈θ′, φ(S̄)〉. Note that this do not necessarily 
imply that θ′u = θu. In a similar fashion, by setting: 

φu(Si) = 1{u ∈ Si ∧ @ j 6= i s.t. u ∈ Sj ∧ zj < zi} 

for every i ∈M , we get that fθ(Si) = 〈θ′, φ(Si)〉 for some 
θ′, which guarantee L̂ = 0. Note that generalization here 
concern φ a apply to example in both S and T . 

Coverage with parametrized cover sets: Let U = [N ] 
be a ground set of item with unit weights. The parameter 
be a collection item subset {C1, . . . , Cn} with Ci ⊆ U . 
We use ξiu = 1{u ∈ Ci} and denote the maximal overlap 
by d = maxu 

∑ 
i ξiu. For a subset S ∈ [n], it value is: 

fC(S) = 
∣∣∣⋃ 

i∈S 
Ci 

∣∣∣ 
While fC be not linear over C, it can be linearize over a 
different parameterization. For xi = 1{i ∈ S}, we have: 

fC(S) = 
∑ 
u∈Ω 

( 
1− 

n∏ 
i=1 

(1− xiξiu) 
) 

Since fC be a polynomial of degree at most d, the explicit 
size of φ (and hence of the correspond θ) be nd. For 
computational efficiency, we can consider the dual form and 
implicitly define φ via the kernalized inner product: 

〈φ(S), φ(S′)〉 = 
( 
〈xS , xS′〉+ 1 

)d 

3.4. Reducing the sample-complexity cost of m 

Interestingly, at the cost of a small additional additive error, 
the dependence of the generalization bound on m can be 
remove by consider an alternative loss function. Fix 

some q ∈ [0, 1]. Given S, define Q to be the set of ex- 
amples in the top q-quantile. The idea here be to learn θ 
so that fθ will score top-quantile example S ∈ Q above 
low-quantile example S 6∈ Q. The correspond loss be 
therefore define over example pairs: 

∆q(S, S 
′, fθ) = 

{ 
1{fθ(S)<fθ(S′)} if S ∈ Q ∧ S′ 6∈ Q 
0 otherwise 

(13) 
Note that, in a similar fashion to ∆α, the empirical loss 
L̂q over ∆q can be optimize efficiently, and the optimal θ 
give L̂q = 0. For any S ∈ S, the probability of have at 
least one S ∈ S ∩Q be 1− qm. Applying the generalization 
bound in Agarwal & Niyogi (2009) gives: 

� ≤ qm + Õ 

( 
B 

λMq 
+ 

( 
B2 

λ 
+ Z 

)√ 
ln(1/δ) 

Mq 

) 
(14) 

where Z = supS f(S) and λ control an additional regular- 
izer. In Sec. 4 we use a stricter variant of this formulation, 
in which high-quantile item be bin separately. 

3.5. Using PMAC algorithm in practice 

In principle, the reduction in Sec. 2.1 show that any PMAC 
algorithm can be use for DOPS. Practically, however, this 
approach have several disadvantages. The root cause of this 
be that most current PMAC algorithm be design for gen- 
eral submodular functions.2 As such, they must adhere to 
demand low bound (Balcan & Harvey, 2011; Feldman 
& Vondrak, 2016) which hold even for simple distribution 
(e.g., uniform). When consider specific submodular sub- 
classes, these algorithm can therefore be suboptimal (and 
in fact quite costly) in term of runtime, sample complexity, 
and/or approximation ratio. Additionally, virtually all cur- 
rent PMAC algorithm provide guarantee for either uniform 
or product distributions. Even in this setting, PMAC algo- 
rithms either guarantee a fix approximation ratio, or be 
exponential in α (Feldman & Vondrak, 2016), make them 
difficult to use for α-DOPS with arbitrarily small α. The 
only know result for arbitrary distribution be the 

√ 
n+ 1- 

PMAC algorithm of Balcan & Harvey (2011), which give a 
match Ω̃(n1/3) low bound on α. 

4. Experiments 
In this section we evaluate the performance of our method 
on the task of optimally choose trend item in social 
medium platforms. Of the countless item that be continu- 
ously create and share by user in such platforms, only a 
handful will become widespread (Goel et al., 2012). A key 

2 A notable exception to this be Feldman & Kothari (2014) 
which specifically considers PMAC learn of coverage function 
with unknown cover sets. 



Learning to Optimize Combinatorial Functions 

time 

n 
u 

m 
b 

e 
r 

o 
f 

a 
d 

o 
p 

ti 
o 

n 
s 

Figure 1. Demonstrating the power of a coverage model. The 
true diffusion curve of a focal hashtag ω (black) and an additional 
hashtag ω′ with an initially similar (but eventually very different) 
diffusive pattern (orange). Diffusion-curve extrapolation (Bauck- 
hage & Kersting, 2014) be generate base on Sω alone (dashed 
blue) and on both Sω and C(Sω) (dashed green), with dash 
line mark the time of the correspond last observations. 
This show how conditioning on C(Sω) can boost performance by 
provide a probabilistic “glimpse” into the near future. Markers 
in the zoom inlaid plot indicate active users. 

challenge face daily by platform administrator be that of 
identify potential trend content a early a possible. 
Trending item can then be marked, use for generate 
recommendations, or promote to the public front page. 

4.1. Optimizing trend item 

For a give social platform, let n be the number of users, 
and Ω be the set of spread content items. When a user 
u ∈ [n] be observe to have be expose to an item ω ∈ Ω, 
we say that u adopt ω. This can happen, for instance, 
when u views, shares, comments, or vote on ω. A crucial 
factor in the successful spread of an item be the identity of 
it early adopter (Rogers, 1962; Goldenberg et al., 2002). 
We therefore represent each content item ω at a certain time 
point by the set of user that have adopt it up to that time, 
which we denote by Sω ⊆ [n]. We will be interested in 
the final number of adopter zω a a function of the set 
of adopt users, namely zω = f(Sω). For simplicity 
we assume that all item be consider at the time when 
adopt by exactly k users, so that |Sω| = k for all ω ∈ Ω. 
Under the above representation, target a successful item 
can be thought of a optimize over the set of adopt 
user under a cardinality constraint. The task be therefore to 
choose the set Sω for which f(Sω) be maximal. 

The above optimization task have two clear restrictions. First, 
f cannot be access or queried, and any information re- 
garding the value of subset be available only via samples, 
namely past item and their adopt users. Second, an algo- 
rithm cannot output any user subset S ⊆ [n], but must rather 
choose from a set of currently available items. In addition, 

the task of choose the top trend item be perform re- 
peatedly, each time over a different collection of content 
items. For example, for a front page that be update hourly, a 
new trend item must be select from the set of currently 
propagate content item for each update. Note that in such 
systems, the available subset and their eventual value be 
primarily determine by the system’s users. Online social 
platform be therefore a prime example of a set where 
an optimization algorithm have only statistical access to data. 

4.2. Experimental setup 

We evaluate the performance of our method on a benchmark 
dataset of propagate Twitter hashtags (Weng et al., 2013). 
Data be gather by monitoring the share (tweeting and 
retweeting) of hashtags across user over the course of a 
month. The dataset include 612,355 user who share 
226,488 distinct hashtags, with a total of 1,687,704 share 
activities. For each hashtag, the data describes the sequence 
of adopt user and the correspond timestamps. These 
be use to construct a “retweet” social network G = (V,E) 
where (u, v) ∈ E if v retweeted u. A user be consider to 
be active if she share at least 20 hashtags. We focus on the 
11,815 active user and on the 4,155 hashtags that include 
at least one active user. If a user retweeted the same hashtag 
more than once, we consider only the first tweet. 

Samples be generate in the follow manner. For each 
hashtag ω, the user set Sω be define to include the first 
k ∈ {5, . . . , 15} active adopt users, and zω be set to 
be the number of eventual adopters. All pair (Sω, zω) 
be randomly partition into a train set S and a global 
test set T ′ use a 90:10 split. All method be give 
S a input, and be evaluate on 1,000 random subset 
T ⊆ T ′ of size m, where m ∈ {100, . . . , 500}. This be 
repeat 100 times, and average result be reported. All 
method we consider return an element Ŝ ∈ T by com- 
put argmaxS∈T g(S) for some score function g, which 
be typically learn from the data. Hyper-parameters be 
tune use cross validation for all relevant methods. 

DOPS model: We implement the DOPS algorithm use 
coverage function a the base class. Specifically, give the 
social network graph G = (V,E), we use V a the ground 
set, and construct a cover set Cv = u : (v, u) ∈ E) for 
every v ∈ V . The coverage function we learn is: 

fθ,η(S) = 
∑ 
v∈V 

θv + 
∑ 

u∈C(S) 

ηu (15) 

whereC(S) = 
⋃ 
v∈S Cv . The idea behind this model be that, 

give that user v adopted, each of her neighbor can also 
adopt (with some probability). Figure 1 illustrates this idea. 
Thus, the two term in Eq. (15) quantify the contribution 
of the adopt node and of their neighbors, respectfully, 



Learning to Optimize Combinatorial Functions 

100 200 300 400 500 
0 

50 

100 

150 

200 

a 
v 
g 

. 
n 

u 
m 

. 
a 

d 
o 

p 
te 

r 

Slope 

OPS 

PMAC 

LinReg 

DOPS 

5 7 9 11 13 15 
0 

50 

100 

150 

200 

a 
v 
g 
. 
n 
u 
m 

. 
a 
d 
o 
p 
te 

r 

Slope 

OPS 

PMAC 

LinReg 

DOPS 

Figure 2. Comparison different method for the task of optimally choose trend hashtags on Twitter. 

to the overall score. The coverage formulation take into ac- 
count the potential overlap in neighbor nodes, which can 
often be considerable (Holland & Leinhardt, 1971; Watts & 
Strogatz, 1998). We note that G be construct use train- 
ing data alone, and incoming edge where only consider 
for node with at least 10 shares. Eq. (10) be optimize 
use the cutting-plane method of Joachims et al. (2009). 

Baselines: We compare to the follow methods: 

• SLOPE: A first-order extrapolation where we first esti- 
mate the slope of the diffusion curve, and then choose 
the subset with the high value. 

• LINREG: We first run linear regression with `2 regu- 
larization, and then choose the subset with the high 
predict value. 

• OPS: A variant of the OPS (Balkanski et al., 2016), 
where instead of return a global argmax, a give 
subset be score base on the sum of marginal estimates. 
Note that under certain conditions, this algorithm be 
optimal for the set of optimization from samples. 

• PMAC: A soft version of the distribution-independent 
PMAC algorithm of Balcan & Harvey (2011). Since the 
original algorithm assumes separability (which do 
not hold here), we instead use an agnostic classifier. 

Results: Figures 2(a) and 2(b) compare the value (number 
of adopters) for the chosen output of each method. As can be 
seen, DOPS clearly outperforms other method by a margin. 
Note that when k increases, average output value be likely 
to increase a well, since the algorithm be give more 
information a input. When m increases, however, it be not 
clear a-priori how the average output value should change. 
This be because large test set be more likely to include 
higher-valued items, but at the same time have more low- 
value alternatives. Interestingly, while the performance of 

most baseline do not improve (or even degrades) a m 
increases, the performance of DOPS improves steadily. 

5. Conclusions 
In this work, we propose an optimization criterion for 
setting where the algorithm be limited to statistical access of 
the objective function. We argue that this set be pervasive, 
and in fact, believe that in most application it be the common 
rule rather than the exception. Previous result have be 
generally negative, but mostly due to demand worst-case 
requirements. Drawing inspiration from learn theory, our 
solution relaxes these requirement to hold in expectation. 

Our main theoretical result show an equivalence between 
optimization in this set and learning. This highlight 
intrigue connection between the computational and statis- 
tical structure of function classes. An interest corollary be 
that analyze hardness of computation and approximation 
can now be do use statistical tools, and vice versa. 

Several of the function class we explore be notoriously 
hard to optimize, but have a surprisingly simple structure 
a a function of their parameters. This allow u to use 
simple learn strategy to produce powerful optimization 
mechanisms. We hypothesize that there be many other 
class that posse these properties. An additional avenue 
for further exploration, hint by our equivalence result, be 
the reverse: be there class that be seemingly hard-to- 
learn, but due to their optimizational properties, can actually 
be learn efficiently? We leave this for future work. 

Acknowledgements 
This research be support by a Google PhD Fellowship, 
NSF grant CAREER CCF-1452961, BSF grant 2014389, 
NSF USICCS proposal 1540428, ISF Centers of Excellence 
grant, a Google research award, and a Facebook research 
award. 



Learning to Optimize Combinatorial Functions 

References 
Agarwal, Shivani and Niyogi, Partha. Generalization bound 

for rank algorithm via algorithmic stability. Journal 
of Machine Learning Research, 10(Feb):441–474, 2009. 

Balcan, Maria-Florina and Harvey, Nicholas JA. Learning 
submodular functions. In Proceedings of the forty-third 
annual ACM symposium on Theory of computing, pp. 
793–802. ACM, 2011. 

Balkanski, Eric, Rubinstein, Aviad, and Singer, Yaron. The 
power of optimization from samples. In Advances in 
Neural Information Processing Systems, pp. 4017–4025, 
2016. 

Balkanski, Eric, Rubinstein, Aviad, and Singer, Yaron. The 
limitation of optimization from samples. In Proceedings 
of the 49th Annual ACM SIGACT Symposium on Theory 
of Computing, STOC 2017, Montreal, QC, Canada, June 
19-23, 2017, pp. 1016–1027, 2017. 

Bauckhage, Christian and Kersting, Kristian. Strong regular- 
ities in growth and decline of popularity of social medium 
services. arXiv preprint arXiv:1406.6529, 2014. 

Collins, Michael. Parameter estimation for statistical pars- 
ing models: Theory and practice of distribution-free meth- 
ods. New development in parse technology, 23:19–55, 
2004. 

Defazio, Aaron and Caetano, Tiberio S. A convex formu- 
lation for learn scale-free network via submodular 
relaxation. In Advances in Neural Information Processing 
Systems, pp. 1250–1258, 2012. 

Dughmi, Shaddin and Vondrák, Jan. Limitations of random- 
ized mechanism for combinatorial auctions. Games and 
Economic Behavior, 92:370–400, 2015. 

Feldman, Vitaly and Kothari, Pravesh. Learning coverage 
function and private release of marginals. In Conference 
on Learning Theory, pp. 679–702, 2014. 

Feldman, Vitaly and Vondrak, Jan. Optimal bound on ap- 
proximation of submodular and XOS function by juntas. 
SIAM Journal on Computing, 45(3):1129–1170, 2016. 

Goel, Sharad, Watts, Duncan J, and Goldstein, Daniel G. 
The structure of online diffusion networks. In Proceed- 
ings of the 13th ACM conference on electronic commerce, 
pp. 623–638. ACM, 2012. 

Goldenberg, Jacob, Libai, Barak, and Muller, Eitan. Riding 
the saddle: How cross-market communication can create 
a major slump in sales. Journal of Marketing, 66(2):1–16, 
2002. 

Golovin, Daniel and Krause, Andreas. Adaptive submod- 
ularity: Theory and application in active learn and 
stochastic optimization. Journal of Artificial Intelligence 
Research, 42:427–486, 2011. 

Gomes, Ryan and Krause, Andreas. Budgeted nonparamet- 
ric learn from data streams. In ICML, pp. 391–398, 
2010. 

Gomez Rodriguez, Manuel, Leskovec, Jure, and Krause, 
Andreas. Inferring network of diffusion and influence. 
In Proceedings of the 16th ACM SIGKDD international 
conference on Knowledge discovery and data mining, pp. 
1019–1028. ACM, 2010. 

Guillory, Andrew and Bilmes, Jeff A. Simultaneous learn 
and cover with adversarial noise. In ICML, volume 11, 
pp. 369–376, 2011. 

Hoi, Steven CH, Jin, Rong, Zhu, Jianke, and Lyu, Michael R. 
Batch mode active learn and it application to medical 
image classification. In Proceedings of the 23rd inter- 
national conference on Machine learning, pp. 417–424. 
ACM, 2006. 

Holland, Paul W and Leinhardt, Samuel. Transitivity in 
structural model of small groups. Comparative Group 
Studies, 2(2):107–124, 1971. 

Iyer, Rishabh K, Jegelka, Stefanie, and Bilmes, Jeff A. Cur- 
vature and optimal algorithm for learn and minimiz- 
ing submodular functions. In Advances in Neural Infor- 
mation Processing Systems, pp. 2742–2750, 2013. 

Joachims, T., Finley, T., and Yu, Chun-Nam. Cutting-plane 
training of structural SVMs. Machine Learning, 77(1): 
27–59, 2009. 

Kempe, David, Kleinberg, Jon, and Tardos, Éva. Maxi- 
mizing the spread of influence through a social network. 
In Proceedings of the ninth ACM SIGKDD international 
conference on Knowledge discovery and data mining, pp. 
137–146. ACM, 2003. 

Krause, Andreas and Golovin, Daniel. Submodular function 
maximization., 2014. 

Lapin, Maksim, Hein, Matthias, and Schiele, Bernt. Top- 
k multiclass svm. In Advances in Neural Information 
Processing Systems, pp. 325–333, 2015. 

Lin, Hui and Bilmes, Jeff. A class of submodular function 
for document summarization. In Proceedings of the 49th 
Annual Meeting of the Association for Computational 
Linguistics: Human Language Technologies-Volume 1, 
pp. 510–520. Association for Computational Linguistics, 
2011. 



Learning to Optimize Combinatorial Functions 

Rodriguez, Manuel Gomez and Schölkopf, Bernhard. Sub- 
modular inference of diffusion network from multiple 
trees. arXiv preprint arXiv:1205.1671, 2012. 

Rogers, E.M. Diffusion of innovations. Free Press of Glen- 
coe, 1962. 

Sipos, Ruben, Shivaswamy, Pannaga, and Joachims, 
Thorsten. Large-margin learn of submodular summa- 
rization models. In Proceedings of the 13th Conference 
of the European Chapter of the Association for Computa- 
tional Linguistics, pp. 224–233. Association for Compu- 
tational Linguistics, 2012. 

Valiant, Leslie G. A theory of the learnable. Communica- 
tions of the ACM, 27(11):1134–1142, 1984. 

Watts, Duncan J and Strogatz, Steven H. Collective dy- 
namics of small-worldnetworks. nature, 393(6684):440, 
1998. 

Weng, Lilian, Menczer, Filippo, and Ahn, Yong-Yeol. Viral- 
ity prediction and community structure in social networks. 
Scientific reports, 3:2522, 2013. 


