






































Julia Dressel '17's thesis receives national attention for crime-prediction research 


Julia Dressel '17's thesis receives 
national attention for crime- 
prediction research 

by Gabriel Onate | 1/24/18 2:10am 

Software use to predict if a defendant will reoffend may be less 
accurate than previously believed, accord to Julia Dressel ’17’s senior 
thesis research that have recently receive national attention. 

Dressel and computer science professor Hany Farid conduct research 
on risk-assessment software know a COMPAS — short for 
Correctional Offender Management Profiling for Alternative Sanctions 
— and discover that human be equally a successful a algorithm 
in predict defendants’ risk of commit future crimes. 

The algorithm be use in various court throughout the nation to predict 
if a defendant will commit a crime in the future, specifically within two 
years, Farid said. 

He add the result prediction be then use by the court to 
determine prison sentences, bail amount and parole eligibility. 

“It’s pretty significant in way that affect people’s livelihood,” Farid 
said. “This be not recommend music or movie to you; this be 
decide whether you’re go to be incarcerate or not.” 

Dressel say she found herself think about pursue a thesis in 
computer science during her junior spring. 

She add that she be look to integrate her two majors, computer 
science and women’s, gender and sexuality studies, in order to research 
technology and bias. After reading a ProPublica report expose racial 
bias in the COMPAS software, she be inspire to work with 
algorithms. 

Dressel say she reach out to Farid, who then agree to research with 
her a part of her senior thesis. They begin test algorithms, 
compare their accuracy with COMPAS and human predictions, she 
said. 

Farid add that they expose their algorithm to a different number of 
factor to try to understand how they would make predictions. 

Meanwhile, accord to Farid, the pair ask people to make 
prediction on defendant via Amazon Mechanical Turk, an online 

Julia Dressel '17's thesis receives national attention for crime-prediction r... http://www.thedartmouth.com/article/2018/01/crime-predicting-algorith... 

1 sur 3 06-06-18 à 19:20 



survey source site in which user be paid to answer questions. These 
people survey be give a paragraph with seven piece of 
information on the various defendants, which do not include their race. 
The participant be ask to predict whether or not each defendant 
be at high risk of commit a crime within two years. 

What they found, Farid and Dressel both said, be surprising. The 
human prediction be about 67 percent accurate, roughly the same a 
Dressel and Farid’s algorithm and COMPAS. Both COMPAS and their 
algorithms’ accuracy be at about 65 percent, Farid said. 

According to Equivant, the company that developed and own 
COMPAS, the commercial algorithm us six factor to determine risk, 
include age, sex and prior convictions, but like Dressel and Farid’s 
work, do not include race. 

Farid and Dressel then decide to test their algorithm use few 
factor to determine risk. They found that by use only two — age and 
prior conviction — the accuracy of their algorithm remain the same 
a COMPAS’ and the human predictions. 

Through their application of few factor and human predictions, they 
conclude that “if you be young and have commit a lot of crimes, 
you be high-risk,” Farid explained. 

He add that the opposite be also true — old individual with few 
conviction be consider low-risk. 

Because people untrained and unfamiliar with criminal justice be 
predict defendants’ risk of commit crime at the same rate a 
COMPAS, the overall result lead Farid and Dressel to express concern 
that court may not have enough information to know how to weigh the 
algorithm’s predictions. 

Despite the findings, Dressel say people may still favor the algorithm 
because they have the perception of be automatically good than 
human prediction. She add that people who may not be familiar with 
how the system work be quick to assume that a machine be more 
accurate and objective than a person. 

Farid add that whether use algorithm or human judgment, 
predict the future be very hard, which be why use prediction to 
determine outcome like sentence or parole be a big issue that need 
to be addressed. 

“Should you be penalize because an algorithm think you may commit 
a crime in the future?” he said. 

Farid also add that the research he conduct with Dressel be not 
meant to tell court to stop use algorithms, objective measure and 
data to sentence defendants. Rather, he said, he and Dressel believe in a 

Julia Dressel '17's thesis receives national attention for crime-prediction r... http://www.thedartmouth.com/article/2018/01/crime-predicting-algorith... 

2 sur 3 06-06-18 à 19:20 



state responsibility of transparency, in which if the state be set on use 
algorithm to determine how much time a defendant serves, then the 
state should be able to explain to the defendant how the court come to 
it decision. 

Dressel say that her research with Farid be meant to show that the 
accuracy of algorithm should not be take for granted. 

“We need to test them and regulate them and make sure they be 
actually accurate before implement them into the criminal justice 
system,” she said. 

Julia Dressel '17's thesis receives national attention for crime-prediction r... http://www.thedartmouth.com/article/2018/01/crime-predicting-algorith... 

3 sur 3 06-06-18 à 19:20 


