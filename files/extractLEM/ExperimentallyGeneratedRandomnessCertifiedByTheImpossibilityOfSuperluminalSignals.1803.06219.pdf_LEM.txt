


















































Experimentally Generated Randomness Certified by 
the Impossibility of Superluminal Signals 

Peter Bierhorst,1∗ Emanuel Knill,1,6 Scott Glancy,1 Yanbao Zhang,1† 

Alan Mink,2,3 Stephen Jordan,2 Andrea Rommal,4 Yi-Kai Liu,2 

Bradley Christensen,5 Sae Woo Nam,1 Martin J. Stevens,1 Lynden K. Shalm1 

1National Institute of Standards and Technology, Boulder 80305, CO, USA 
2 National Institute of Standards and Technology, Gaithersburg 20899, MD, USA 

3 Theiss Research, La Jolla, CA, 92037, USA 
4 Muhlenberg College, Allentown, PA, 18104, USA 

5 Department of Physics, University of Wisconsin, Madison, WI, 53706, USA 
6Center for Theory of Quantum Matter, University of Colorado, Boulder, Colorado 80309, USA 
†Present address: NTT Basic Research Laboratories and NTT Research Center for Theoretical 

Quantum Physics, NTT Corporation, 3-1 Morinosato-Wakamiya, Atsugi, Kanagawa 243-0198, Japan 
∗ E-mail: peter.bierhorst@nist.gov 

From dice to modern complex circuits, there have be many attempt to build increas- 
ingly good device to generate random numbers. Today, randomness be fundamental to 
security and cryptographic systems, a well a safeguard privacy. A key challenge 
with random number generator be that it be hard to ensure that their output be unpre- 
dictable [1–3]. For a random number generator base on a physical process, such a a 
noisy classical system or an elementary quantum measurement, a detailed model describ- 
ing the underlie physic be require to assert unpredictability. Such a model must make 
a number of assumption that may not be valid, thereby compromise the integrity of the 
device. However, it be possible to exploit the phenomenon of quantum nonlocality with a 
loophole-free Bell test to build a random number generator that can produce output that 
be unpredictable to any adversary limited only by general physical principle [1–11]. With 
recent technological developments, it be now possible to carry out such a loophole-free Bell 
test [12–14]. Here we present certify randomness obtain from a photonic Bell experi- 
ment and extract 1024 random bit uniform to within 10−12. These random bit could not 
have be predict within any physical theory that prohibits superluminal signal and 
allows one to make independent measurement choices. To certify and quantify the ran- 

1 

ar 
X 

iv 
:1 

80 
3. 

06 
21 

9v 
1 

[ 
qu 

an 
t- 

ph 
] 

2 
2 

Fe 
b 

20 
18 



domness, we describe a new protocol that be optimize for apparatus characterize by 
a low per-trial violation of Bell inequalities. We thus enlist an experimental result that 
fundamentally challenge the notion of determinism to build a system that can increase 
trust in random sources. In the future, random number generator base on loophole- 
free Bell test may play a role in increase the security and trust of our cryptographic 
system and infrastructure. 

The search for certifiably unpredictable random number generator be motivate by appli- 
cations, such a secure communication, for which the predictability of pseudorandom string 
make them unsuitable. Private randomness be require to initiate and authenticate virtually every 
secure communication [15], and public randomness from randomness beacon can be use for 
public certification and resource distribution in many setting [16]. To certify randomness, one 
can perform an experiment know a a Bell test [17], which in it simplest form performs mea- 
surements on an entangle system locate in two physically separate measurement stations, 
with each station choose between two type of measurements. After multiple experimental 
trial with vary measurement choices, if the measurement data violates condition know a 
“Bell inequalities,” then the data can be certify to contain randomness under weak assump- 
tions. 

Our randomness generation employ a “loophole-free” Bell test, which notably be character- 
ized by high detection efficiency and space-like separation of the measurement station during 
each experimental trial. The bit be unpredictable assume that (1) the choice of measure- 
ment setting be independent of the experimental device and pre-existing classical informa- 
tion about them and (2) in each experimental trial, the measurement outcome at each station 
be independent of the setting choice at the other station. The first assumption be ultimately 
untestable, but the premise that it be possible to choose measurement setting independently of 
a system be measure be often tacitly invoked in the interpretation of many scientific exper- 
iments and law of physic [18]. The second assumption can only be violate if one admits a 
theory that permit send signal faster than the speed of light, give our trust that the space- 
like separation of the relevant event in the experiment be accurately verify by the timing 
electronics and that result be final when recorded. We also trust that the classical compute 
equipment use to process the data operates accord to specification. 

Under the above assumptions, the output randomness be certify to be unpredictable with 
respect to a real or hypothetical actor “Eve” in possession of the pre-existing classical informa- 
tion, physically isolated from the device while they be under our control, and without access 
to data produce during the protocol. The bit remain unpredictable to Eve if she learns the set- 
ting at any time after her last interaction with the devices. If the device be trusted, which be 
reasonable if we built them, then this may be well before the start of the protocol, in which case 
the setting can come from public randomness [2,10]. In particular, one can use an exist pub- 
lic randomness source, such a the NIST random beacon [16], to generate much need private 
randomness a output. Since the assumption do not constrain the specific physical realization 
of the device and do not require specific state or measurements, they implement a “device- 
independent” framework [19] which allows an individual user to assure security with minimal 

2 



assumption about the devices. If Eve have quantum memory, it be possible to ensure that Eve’s 
side information be effectively classical by verify that the device have no long-term quantum 
memory of past interaction with Eve. While this introduces weak device-dependence, for the 
foreseeable future this verification task be comparable to that require to enforce the absence of 
communication from the device to Eve. 

The only previous experimental production of certify randomness from Bell test data be 
report in the ground-breaking paper by Pironio et al. [5]. Their Bell test be implement 
with ion in two separate ion-traps, closing the detection loophole [20] but without space-like 
separation. Indeed, Bell test achieve space-like separation without other experimental loop- 
hole have be perform only recently [12–14, 21]. Under more restrictive assumption than 
ours, the maximum amount of randomness in principle available in the data of Pironio et al. 
be quantify a 42 bit with an error parameter of 0.01, but they do not extract a uniformly 
distribute bit string from their data. Pironio et al. argue that any interaction between measure- 
ment station in their experiment be negligible, because they be locate in separate ion-traps, 
each in it own vacuum chamber. However, any shield between the station be necessarily 
incomplete; for example they must have an open quantum channel to establish entanglement. 
Mundane physical effect can allow local-realistic system to appear to violate Bell inequal- 
ities when shield be incomplete. Relying instead on the impossibility of faster-than-light 
communication provide strong assurance of the unpredictability of the randomness. 

We generate randomness use an improve version of the loophole-free Bell test report 
in Ref. [13]. Five new data set be collected, with the best-performing data set yield 1024 
new random bit uniform to within 10−12. We also obtain 256 random bit from the main data 
set analyze in Ref. [13], albeit only uniform to within 0.02. The experiment, illustrate in Fig. 
1, consist of a source of entangle photon and two measurement station name “Alice” and 
“Bob”. During an experimental trial, at each station a random choice be make between two 
measurement setting label 0 and 1, after which a measurement outcome of detection (+) or 
nondetection (0) be recorded. Each station’s implementation of the measurement set be 
space-like separate from the other station’s measurement event, and no postselection be em- 
ployed in collect the data. See the Methods section for details. For trial i, we model Alice’s 
setting choice with the random variable Xi and Bob’s with Yi, both of which take value in 
the set {0, 1}. Alice’s and Bob’s measurement outcome random variable be respectively Ai 
and Bi, both of which take value in the set {+, 0}. When refer to a generic single trial, we 
omit indices. With this notation, a general Bell inequality for our scenario can be express in 
the form [22] ∑ 

abxy 

sabxyP(A = a,B = b|X = x, Y = y) ≤ β, (1) 

where the sabxy be fix real coefficient indexed by a, b, x, y that range over all possible value 
of A,B,X, Y . The upper bound β be require to be satisfied whenever the settings-conditional 
outcome probability be induced by a model satisfy “local realism” (LR). LR distributions, 
which cannot be certify to contain randomness, be those for which P(A = a,B = b|X = 
x, Y = y) be of the form 

∑ 
λ P(A = a|X = x,Λ = λ)P(B = b|Y = y,Λ = λ)P(Λ = λ) for 

3 



a random variable Λ represent local hidden variables. The Bell inequality be non-trivial if 
there exists a quantum-realizable distribution that can violate the bound β. 

It have long be know that experimental violation of Bell inequality such a Eq. 1 indi- 
cate the presence of randomness in the data. To quantify randomness with respect to Eve, we 
represent Eve’s initial classical information by a random variable E. We formalize the assump- 
tion that measurement setting can be generate independently of the system be measure 
and Eve’s information with the follow condition: 

P(Xi = x, Yi = y|E = e, pasti) = P(Xi = x, Yi = y) = 
1 

4 
∀x, y, e, (2) 

where pasti represent event in the past of the i’th trial, specifically include the trial setting 
and outcome for trial 1 through i − 1. Our other assumption, that measurement outcome be 
independent of remote measurement choices, be formalize a follows: 

P(Ai = a|Xi = x, Yi = y, E = e, pasti) = P(Ai = a|Xi = x,E = e, pasti) 
P(Bi = b|Xi = x, Yi = y, E = e, pasti) = P(Bi = b|Yi = y, E = e, pasti) ∀x, y, e. (3) 

These equation be commonly refer to a the “non-signaling” assumptions, although they 
be often state without the conditionals E and pasti. Our space-like separation of setting and 
remote measurement provide assurance that the experiment obeys Eqs. 3. We remark that if one 
assumes the measure system obey quantum physics, strong constraint be possible [23,24]. 

Given Eqs. 2 and 3, our protocol produce random bit in two sequential parts. For the first 
part, “entropy production”, we implement n trial of the Bell test, from which we compute a 
statistic V related to a Bell inequality (Eq. 1). V quantifies the Bell violation and determines 
whether or not the protocol pass or aborts. If the protocol passes, we certify an amount of 
randomness in the outcome string even condition on the set string and E. In the second 
part, “extraction,” we process the outcome string into a shorter string of bit whose distribution 
be close to uniform. We use our customize implementation of the Trevisan extractor [25] 
derive from the framework of Mauerer, Portmann and Scholz [26] and the associate open 
source code. We call this the TMPS algorithm, see Supplementary Information (SI) S.4 for 
details. 

We apply a new method of certify the amount of randomness in Bell tests. Previous 
method for related model with various set of assumption [2–8, 27–29] be ineffective in 
our experimental regime (SI S.7), which be characterize by a small per-trial violation of Bell 
inequalities. Other recent work that explore how to effectively certify randomness from a wider 
range of experimental regime assume that measure state be independent and identically 
distribute (i.i.d.) or that the regime be asymptotic [9–11, 30]. Our method, which do not 
require these assumptions, build on the Prediction-Based Ratio (PBR) method for reject LR 
[31]. Applying this method to training data (see below), we obtain a real-valued “Bell function” 
T with argument A,B,X, Y that satisfies T (A,B,X, Y ) > 0 with expectation E(T ) ≤ 1 
for any LR distribution satisfy Eq. 2. From T we determine the maximum value 1 + m 

4 



of E(T ) over all distribution satisfy Eqs. 2 and 3, where we require that m > 0. Such 
a function T induces a Bell inequality (Eq. 1) with β = 4 and sabxy = T (a, b, x, y). Define 
Ti = T (Ai, Bi, Xi, Yi) and V = 

∏n 
i=1 Ti. If the experimenter observes a value of V large than 

1, this indicates a violation of the Bell inequality and the presence of randomness in the data. 
The randomness be quantify by the follow theorem, proven in the SI S.2. Below, we denote 
all of the setting of both station with XY = X1Y1X2Y2...XnYn, and other sequence such a 
AB and ABXY be similarly interleave over n trials. 

Entropy Production Theorem. Suppose T be a Bell function satisfy the above conditions. 
Then in an experiment of n trial obey Eqs. 2 and 3, the follow inequality hold for all 
�p ∈ (0, 1) and vthresh satisfy 1 ≤ vthresh ≤ (1 + (3/2)m)n�−1p : 

Pe (Pe(AB|XY) > δ AND V ≥ vthresh) ≤ �p (4) 

where δ = [1+(1− n√�pvthresh)/(2m)]n and Pe denotes the probability distribution condition 
on the event {E = e}, where e be arbitrary. The expression Pe(AB|XY) denotes the random 
variable that take the value Pe(AB = ab|XY = xy) when ABXY take the value abxy. 

In words, the theorem say that with high probability, if V be at least a large a vthresh, then the 
output AB be unpredictable, in the sense that no individual outcome {AB = ab} occurs with 
probability high than δ, even give the information {XYE = xye}. The theorem support a 
protocol that abort if V take a value less than vthresh, and pass otherwise. If the probability 
of passing be 1, then − log2(δ) would be a so-called “smooth min-entropy”, a quantity that 
characterizes the number of uniform bit of randomness that be in principle available in AB 
[32, 33]. We show in the SI S.3 that for constant �p, − log2(δ) be proportional to the number 
of trials. How many bit we can actually extract depends on �fin, the final output’s maximum 
allow distance from uniform. We also show in the SI that the Entropy Production Theorem 
can still be prove if Eq. 2 be weaken so that setting probability need not be know but be 
constrain to be within α of 1/4 with α < 1/4, while still be conditionally independent 
of early outcome give early settings. Such a weaken be relevant for experiment [12– 
14] that use physical random number generator to choose the settings, for which the setting 
probability cannot be know exactly. 

To extract the available randomness in AB, we use the TMPS algorithm to obtain an extrac- 
tor, specifically a function Ext that take a input the string AB and a length d “seed” bit string 
S, where S be uniform and independent of ABXY. Its output be a length t bit string. S can be 
obtain from d additional instance of the random variable Xi, so Eq. 2 ensures the need 
independence and uniformity condition on S. In order for the output to be within a distance �fin 
of uniform independent of XY and E, the entropy production and extractor parameter must 
satisfy the constraint give in the next theorem, proven in the SI S.5. In the statement of the 
theorem, the measure of distance use be the “total variation (TV) distance,” express by the 
left side of Eq. 6, and “pass” be the event that V exceeds vthresh. 

5 



Protocol Soundness Theorem. Let 0 < �ext, κ < 1. Suppose that P(pass) ≥ κ and suppose that 
that the protocol parameter satisfy 

t+ 4 log2 t ≤ − log2 δ + log2 κ+ 5 log2 �ext − 11. (5) 

Then the output U = Ext(AB,S) of the function obtain by the TMPS algorithm satisfies 

1 

2 

∑ 
u,xyse 

∣∣∣P(U = u,XYSE = xyse|pass)−Punif(U = u)P(XYE = xye|pass)Punif(S = s)∣∣∣ 
≤ �p/P(pass) + �ext, (6) 

where Punif denotes the uniform probability distribution. 

The number of seed bit d require satisfies d = O(log(t) log(nt/�ext)2), and SI S.4 give an 
explicit bound. 

The theorem provide several option for quantify the uniformity of the randomness pro- 
duced. A goal be for the protocol to be nearly indistinguishable accord to TV distance from 
an ideal protocol, where in an ideal protocol the randomness be perfectly uniform conditional on 
passing. For this, the ideal protocol can be chosen to have the same probability of passing with 
behavior match that of the real protocol when aborting. The theorem implies that the uncon- 
ditional distribution of the protocol be within TV distance max(�p + �ext, κ) of that of an ideal 
protocol (SI S.5). For this distance, if the probability of passing be comparable to κ, then the 
conditional TV distance from uniform, give in Eq. 6, could be large. It be desirable that even 
for the bad case probability of passing, the conditional TV distance be small. Accordingly, we 
quantify the uniformity for our implementation with �fin = max(�p/κ + �ext, κ). Then, for any 
probability of passing great than �fin, conditionally on passing, the TV distance from uniform 
be at most �fin. 

We apply our protocol to five data set use the setup base on that described in Ref. [13] 
with improvement described in the Methods section. Each data set be collect in five to ten 
minutes, improve on the approximately one month duration of data acquisition report in 
Ref. [5]. Before start the protocol, we set aside the first 5 × 106 trial of each data set a 
training data, which we use to choose parameter need by the protocol. With the training 
data removed, the number n of trial use by the protocol be between 2.5× 107 and 5.5× 107 
for each data set. We use the training data to determine a Bell function T with statistically 
strong violation of LR on the training data accord to the PBR method [31]; see SI S.3. 
The function T obtain for the fifth data set, which be long in duration and produce the 
most randomness, be give in Table 1 a an example. We compute threshold vthresh so that a 
sample of n i.i.d. trial from the distribution infer from the training data would have a high 
probability for exceed vthresh. 

For the fifth data set, a sample of n i.i.d. trial from the distribution infer from the training 
data would have approximately 0.99 probability of exceed a threshold of vthresh = 1.5×1032. 
This would allow the extraction of 1024 bit uniform to within �fin = 10−12, use �p = κ2 = 

6 



Table 1: Bell function T obtain from Data Set 5. We use a numerical method base on 
maximum likelihood to infer a non-signaling distribution base on the raw count of the training 
trials, namely the first 5×106 trials. We then determine the function T that maximizes E(lnT ) 
accord to this distribution, subject to the constraint that E(T )LR ≤ 1 for all LR distribution 
and T (0, 0, x, y) = 1 for all x, y. The latter constraint improves the signal-to-noise for our 
data. The function T yield m = 0.0100425, and E(T ) = 1.000003931 for the non-signaling 
distribution infer from the training data. One can also interpret the number below a the 
coefficient sabxy in Eq. 1, which defines a Bell inequality with β = 4. The value of T be 
round down at the tenth digit. 

ab = ++ ab = +0 ab = 0+ ab = 00 
xy = 00 1.0243556353 0.9704647804 0.9735507658 1 
xy = 01 1.0256127409 0.9491951243 0.9960775334 1 
xy = 10 1.0227274988 0.9962782754 0.9461091383 1 
xy = 11 0.9273040563 1.0037217225 1.0039224645 1 

9.025 × 10−25 and �ext = 5 × 10−14. These value be chosen base on a numerical study 
of the constraint on the number t of bit extract for fix value of �fin = 10−12. Running 
the protocol on the remain 55, 110, 210 trial with these parameters, the product 

∏n 
i=1 Ti 

exceed vthresh, and so the protocol passed. Applying the extractor to the result output 
string AB with a seed of length d = 315, 844, we extract 1024 bits, certify to be uniform to 
within 10−12, the first ten of which be 1110001001. Figure 2 display the extractable bit for 
alternative choice of �fin for all five data sets. 

We also apply the protocol to data from the experiment of Ref. [13]. This experiment be 
more conservative in take additional measure to ensure that it be loophole-free, include 
space-like separation of the measurement choice from both the downconversion event and 
the remote measurement outcomes. We extract 256 bit at �fin = 0.02 from the best data 
set, XOR 3, report in Ref. [13]. The distance from an ideal protocol a explain after the 
Protocol Soundness Theorem be 4.00 × 10−4, without accounting for possible bias in the 
random source used. For detail see SI S.6. 

For the data set produce 1024 new near random bits, our protocol use 1.10 × 108 uni- 
form bit to choose the setting and 3.16 × 105 uniform bit to choose the seed. Because the 
extractor use be a “strong” extractor, the seed bit be still uniform conditional on passing, so 
they can be recover at the end of the protocol for us elsewhere. This be not the case for 
the settings-choice bit because the probability of passing be less than 1. To reduce the entropy 
use for the settings, our protocol can be modify to use highly bias setting choice [5]. Re- 
ducing setting entropy be not a priority if the setting and seed bit come from a public source 
of randomness, in which case the output bit can still be certify to be unknown to external 
observer such a Eve and the current protocol be an effective method for private randomness 
generation [2, 10]. 

For future work, we hope to take advantage of the adaptive capability of the Entropy 

7 



Production Theorem (SI S.2) to dynamically compensate for experimental drift during run time. 
In view of advance toward practical quantum compute it be desirable to study the protocol in 
the presence of quantum side information, which may require more conservative randomness 
generation. We also look forward to technical improvement in experimental equipment for 
large violation and high trial rates. These will enable faster generation of random bit with 
low error and support the use of bias setting choices. 

Existing randomness generation system rely on detailed assumption about the specific 
physic underlie the devices. With the advent of loophole-free Bell tests, it be now possi- 
ble to build quantum device that exploit quantum nonlocality to remove many of the device- 
dependent assumption in current technological implementations. Our device-independent ran- 
dom number generator be an example of such a system. Such generator can provide the best 
method currently know for physically produce randomness, thereby improve the security 
of a wide range of applications. 

Methods We use polarization-entangled photon generate by a nonlinear crystal pumped by 
a pulsed, picosecond laser at approximately 775 nm in a configuration similar to that report 
in Ref. [13], but with several improvement to increase the rate of randomness extraction. The 
laser’s repetition rate be 79.3 MHz, and each pulse that enter the crystal have a probability of 
≈ 0.003 of create an entangle photon pair in the state |ψ〉 ≈ 0.982 |HH〉+ 0.191 |V V 〉 at a 
center wavelength of 1550 nm. By pump the crystal with approximately five time a much 
power, and use a 20 mm long crystal, we be able to substantially increase the per-pulse 
probability of generate a downconversion event compare with Ref. [13] while maintain 
similar overall system efficiencies. The two entangle photon from each pair be separately 
sent to one of the two measurement station (187±1) m apart. At Alice and Bob, a Pockels cell 
and polarizer combine to allow the rapid switch of measurement base and measurement of 
the polarization state of the incoming photons. Each Pockels cell operate at a rate of 100 kHz, 
allow u to perform 100,000 trial per second (the driver electronics on the Pockels cell set 
this rate). The photon be then detect use fiber-coupled superconducting single-photon 
nanowire detectors, with Bob’s detector operating at approximately 90% efficiency and Alice’s 
detector operating with approximately 92% efficiency [34]. For this experiment, the total sym- 
metric system herald efficiency be (75.5 ± 0.5%), which be above the 71.5% threshold 
require to close the detection-loophole for our experimental configuration after accounting for 
unwanted background count at our detector and slight imperfection in our state preparation 
and measurement components. 

With this configuration, Bob complete his measurement (294.4 ± 3.7) n before a hypo- 
thetical switch signal travel at light speed from Alice’s Pockels cell could arrive at his 
station. Similarly, Alice complete her measurement (424.2±3.7) n before such a signal from 
Bob’s Pockels cell could arrive at her location. Each trial’s outcome value be obtain by 
aggregate the photon detection or non-detection event from several short time interval last- 
ing 1024 ps, each of which be time to correspond to one pulse of the pump laser. If any photon 
be detect in the short intervals, the outcome be “+”, and if no photon be detected, the 

8 



outcome be “0”. The experiment of Ref. [13] use at most 7 short intervals, but here we be 
able to include 14 interval while maintain space-like separation, which further increase 
the probability of observe a photon during each trial. For demonstration purposes, Alice 
and Bob each use Python’s random.py module with the default generator (the Mersenne 
twister) to pick their setting at each trial. This pseudorandom source be predictable, and for 
secure application of the protocol in an adversarial scenario, such a if the photon pair source 
or measurement device be obtain from an untrusted provider, setting choice must be base 
on random source that be effectively not predictable. However, base on our knowledge of 
device construction, we know that our device have no physical resource for predict pseudo- 
random number and expect that measurement setting be effectively independent of relevant 
device so that Eqs. 2 and 3 still hold. We remark that the setting choice for the XOR 3 data 
set be base on physical random sources. 

With the improve detection efficiency, the high per-trial probability of for Alice and Bob 
to detect a photon, and a high signal-to-background count ratio we be able to improve both 
the magnitude of our Bell violation a well a reduce the number of trial require to achieve a 
statistically significant violation by an order of magnitude. 

References 
[1] Acı́n, A. & Masanes, L. Certified randomness in quantum physics. Nature 540, 213 

(2016). 

[2] Pironio, S. & Massar, S. Security of practical private randomness generation. Phys. Rev. 
A 87, 012336 (2013). 

[3] Miller, C. & Shi, Y. Robust protocol for securely expand randomness and distribute 
key use untrusted quantum devices. J. ACM 63, 33:1–33:63 (2016). 

[4] Colbeck, R. & Kent, A. Private randomness expansion with untrusted devices. J. Phys. A: 
Math. Theor. 44, 095305 (2011). 

[5] Pironio, S. et al. Random number certify by Bell’s theorem. Nature 464, 1021–4 (2010). 

[6] Vazirani, U. & Vidick, T. Certifiable quantum dice - or, exponential randomness ex- 
pansion. In STOC’12 Proceedings of the 44th Annual ACM Symposium on Theory of 
Computing, 61 (2012). 

[7] Fehr, S., Gelles, R. & Schaffner, C. Security and composability of randomness expansion 
from Bell inequalities. Phys. Rev. A 87, 012335 (2013). 

[8] Chung, K.-M., Shi, Y. & Wu, X. Physical randomness extractors: Generating random 
number with minimal assumption (2014). ArXiv:1402.4797 [quant-ph]. 

9 



[9] Nieto-Silleras, O., Pironio, S. & Silman, J. Using complete measurement statistic for 
optimal device-independent randomness evaluation. New Journal of Physics 16, 013035 
(2014). 

[10] Bancal, J.-D., Sheridan, L. & Scarani, V. More randomness from the same data. New 
Journal of Physics 16, 033011 (2014). 

[11] Thinh, L., de la Torre, G., Bancal, J.-D., Pironio, P. & Scarani, V. Randomness in post- 
select events. New Journal of Physics 18, 035007 (2016). 

[12] Hensen, B. et al. Loophole-free Bell inequality violation use electron spin separate 
by 1.3 km. Nature 526, 682 (2015). 

[13] Shalm, L. K. et al. Strong loophole-free test of local realism. Phys. Rev. Lett. 115, 250402 
(2015). 

[14] Giustina, M. et al. Significant-loophole-free test of bell’s theorem with entangle photons. 
Phys. Rev. Lett. 115, 250401 (2015). 

[15] Paar, C. & Pelzl, J. Understanding Crypotgraphy (Springer-Verlag Berlin Heidelberg, 
New York, 2010). 

[16] Fischer, M. J., Iorga, M. & Peralta, R. A public randomness service. In SECRYPT 2011, 
434–38 (2011). 

[17] Bell, J. On the Einstein Podolsky Rosen paradox. Physics 1, 195–200 (1964). 

[18] Bell, J. S., Shimony, A., Horne, M. A. & Clauser, J. F. An exchange on local beables. 
Dialectica 39, 85–96 (1985). 

[19] Colbeck, R. Quantum and Relativistic Protocols for Secure Multi-Party Computation. 
Ph.D. thesis, University of Cambridge (2007). 

[20] Pearle, P. M. Hidden-variable example base upon data rejection. Phys. Rev. D 2, 1418– 
1425 (1970). 

[21] Rosenfeld, W. et al. Event-ready Bell test use entangle atom simultaneously closing 
detection and locality loopholes. Phys. Rev. Lett. 119, 010402 (2017). 

[22] Brunner, N., Cavalcanti, D., Pironio, S., Scarani, V. & Wehner, S. Bell nonlocality. Rev. 
Mod. Phys. 86, 419–78 (2014). 

[23] Cirel’son, B. S. Quantum generalization of Bell’s inequality. Lett. Math. Phys. 4, 93–100 
(1980). 

10 



[24] Navascués, M., Pironio, S. & Acı́n, A. A convergent hierarchy of semidefinite program 
characterize the set of quantum correlations. New Journal of Physics 10, 073013 (2008). 

[25] Trevisan, L. Extractors and pseudorandom generators. J. ACM 48, 860–79 (2001). 

[26] Mauerer, W., Portmann, C. & Scholz, V. A modular framework for randomness extraction 
base on Trevisan’s construction (2012). ArXiv:1212.0520 [cs.IT]. 

[27] Coudron, M. & Yuen, H. Infinite randomness expansion with a constant number of de- 
vices. In STOC’14 Proceedings of the 46th Annual ACM Symposium on Theory of Com- 
puting, 427–36 (2014). 

[28] Dupuis, F., Fawzi, O. & Renner, R. Entropy accumulation (2016). ArXiv:1607.01796 
[quant-ph]. 

[29] Arnon-Friedman, R., Renner, R. & Vidick, T. Simple and tight device-independent secu- 
rity proof (2016). ArXiv:1607.01797 [quant-ph]. 

[30] Miller, C. & Shi, Y. Universal security for randomness expansion from the spot-checking 
protocol (2014). ArXiv:1411.6608 [quant-ph]. 

[31] Zhang, Y., Glancy, S. & Knill, E. Asymptotically optimal data analysis for reject local 
realism. Phys. Rev. A 84, 062118 (2011). 

[32] Trevisan, L. & Vadhan, S. Extracting randomness from samplable distributions. In FOCS 
’00 Proceedings of the 41st Annual Symposium on Foundations of Computer Science 
(IEEE Computer Society, Washington, DC, 2000). 

[33] Renner, R. Security of Quantum Key Distribution. Ph.D. thesis, ETH, ETH, Switzerland 
(2006). ArXiv:quant-ph/0512258. 

[34] Marsili, F. et al. Detecting single infrared photon with 93% system efficiency. Nature 
Photonics 7, 210–214 (2013). 

Acknowledgments We thank Carl Miller and Kevin Coakley for comment on the manuscript. 
A.M. acknowledges financial support through NIST grant 70NANB16H207. 

Author Contributions P.B. lead the project and implement the protocol. P.B., E.K., S.G. and 
Y.Z. developed the protocol theory. A.M., S.J., A.R. and Y.-K. L. be responsible for extractor 
theory and implementation. B.C., S.W.N., M.J.S. and L.K.S. collect and interpret the data. 
PB., E.K., S.G. and L.K.S. write the manuscript. 

Author Information This work be a contribution of the National Institute of Standards and 
Technology and be not subject to U.S. copyright. The author declare no compete finan- 
cial interests. Correspondence and request for material should be address to P.B. (pe- 
ter.bierhorst@nist.gov). 

11 



Figure 1: The location of the Source (S), Alice (A) and Bob (B). Each trial, the source 
lab produce a pair of photon in the non-maximally polarization-entangled state |ψ〉 ≈ 
0.982 |HH〉 + 0.191 |V V 〉, where H (V ) denotes horizontal (vertical) polarization. One pho- 
ton be sent to Alice’s lab while the other be sent to Bob’s lab to be measure a show in inset 
(b). Alice’s compute optimal polarization measurement angles, relative to a vertical polarizer, 
be {a = −3.7o, a′ = 23.6o} while Bob’s be {b = 3.7o, b′ = −23.6o}. Both Alice and Bob 
use a fast Pockels cell (PC), two half-waveplates (HWP), a quarter-waveplates (QWP), and a 
polarize beam displacer to switch between their respective polarization measurements. A 
pseudorandom number generator (RNG) governs the choice of each measurement set every 
trial. After passing through the polarization optics, the photon be couple into a single-mode 
fiber and sent to a superconducting nanowire detector. The signal from the detector be then 
amplify and sent to a time tagger where their arrival time be record and the measurement 
outcome be fixed. A 10 MHz oscillator keep Alice and Bob’s timetagger clock locked. Alice 
and Bob be (187 ± 1) m apart. At this distance, Alice’s measurement outcome be space-like 
separate from the trigger of Bob’s Pockels cell and vice-versa. 

12 



ǫ 
fin 

10-16 10-14 10-12 10-10 10-8 10-6 10-4 10-2 100 

E 
xt 

ra 
ct 

ab 
le 

B 
it 

1000 

2000 

3000 

4000 

5000 

6000 

Set 1 
Set 2 
Set 3 
Set 4 
Set 5 

Figure 2: Extractable bit a a function of error. The figure show the tradeoff between final 
error �fin and number of extractable bit t for value of vthresh pre-chosen to yield estimate 
passing probability exceed 95%. These threshold be met in each case. For all data 
set we set �p = κ2 = (0.95 �fin)2 and �ext = 0.05 �fin, a split that be generally found to be 
near-optimal when numerically maximize t in Eq. 5 for fix value of �fin. 

13 



Experimentally Generated Randomness Certified 
by the Impossibility of Superluminal Signals 

(Supplementary Information) 
Peter Bierhorst, Emanuel Knill, Scott Glancy, Yanbao Zhang, 

Alan Mink, Stephen Jordan, Andrea Rommal, Yi-Kai Liu, 
Bradley Christensen, Sae Woo Nam, Martin J. Stevens, Lynden K. Shalm 

After preliminary to establish notation and summarize need property of total variation 
distance and non-signaling distribution in S.1, we give the proof of the Entropy Production 
Theorem in S.2. We explain how we chose the Bell function T , whose product determines 
whether we obtain the desire amount of randomness, in S.3. We then discus the parameter 
of the extractor obtain by the TMPS algorithm (S.4) and prove the Protocol Soundness The- 
orem (S.5). Details on how we analyze the experimental data set be in S.6. Justification for 
our claim that previous method do not obtain any randomness from our low per-trial-violation 
data be give in S.7. 

S.1 Preliminaries 
We use the standard convention that capital letter refer to random variable (RVs) and corre- 
sponding lowercase letter refer to value that the RVs can take. All our RVs take value in finite 
set such a the set of bit string of a give length or a finite subset of the reals, so that our RVs 
can be view a function on a finite probability space. We usually just work with the induced 
joint distribution on the set of value assume by the RVs. When work with conditional 
probabilities, we implicitly exclude point where the conditioner have zero probability whenever 
appropriate. We use P(. . .) to denote probability and E(. . .) for expectations. Inside P(. . .) 
and when use a conditioners, logical statement involve RVs be event specification to be 
interpret a the event for which the statement be true. For example, P(R > δ) be equivalent to 
P({ω : R(ω) > δ}), which be the probability of the event that the RV R take a value great 
than δ. The same convention applies when denote event with {. . .}. For example, the event 
in the previous example be write a {R > δ}. While formally event be sets, we commonly 
use logical language to describe relationship between events. For example, the statement that 
{R > δ} implies {S > �} mean that a a set, {R > δ} be contain in {S > �}. When 
they appear outside the the mention contexts, logical statement be constraint on RVs. For 
example, the statement R > δ mean that all value r of R satisfy r > δ, or equivalently, for all 
ω, R(ω) > δ. As usual, comma separate statement be combine conjunctively (with “and”). 
(In the main text, for clarity, we have use an explicit “AND” for this purpose.) 

If there be free RVs inside P(. . .) or in the conditioner of E(. . . | . . .) outside event specifi- 
cations, the final expression defines a new RV a a function of the free RVs. An example from 
the Entropy Production Theorem be the expression P(AB|XY), which defines the RV that take 
the value P(AB = ab|XY = xy) when the event {ABXY = abxy} occurs. Values of RVs 
such a x appear by themselves in P(. . .) denote the event {X = x}. Thus we abbreviate 

1 



expression such a P(AB = ab|XY = xy) by P(ab|xy). Sometimes it be necessary to dis- 
ambiguate the probability distribution with respect to which E(. . .) be to be computed. In such 
case we use a subscript at the end of the expression consist of a symbol for the probability 
distribution, so E(T )Q be the expectation of T with respect to the distribution Q. In a few in- 
stances, we use JφK for logical expression φ to denote the {0, 1}-valued function evaluate to 
1 iff φ be true. 

The amount of randomness that can be extract from an RV R be quantify by the min- 
entropy, define a − log2 maxr P(R = r). The error of the output of an extractor be give a 
the total variation (TV) distance from uniform. Given two probability distribution P1 and P2 
for R, the TV distance between them be give by 

TV(P1,P2) = 
1 

2 

∑ 
r 

|P1(R = r)− P2(R = r)| 

= 
∑ 

r:P1(r)>P2(r) 

(P1(R = r)− P2(R = r)) 

= 
∑ 
r 

JP1(r) > P2(r)K (P1(R = r)− P2(R = r)) . (S1) 

As the name implies, the TV distance be a metric. In particular, it satisfies the triangle inequality: 

TV(P1,P3) ≤ TV(P1,P2) + TV(P2,P3). (S2) 

See Ref. [35] for this and other basic property of TV distances. 
We sometimes compute TV distance for distribution of specific RVs, conditional or uncon- 

ditional ones. For this we introduce the notation PX for the distribution of value ofX accord 
to P, and PX|Y=y for the distribution of X condition on the event {Y = y}. With this nota- 
tion, PXPY refers to the product distribution that assigns probability PX(X = x)PY (Y = y) to 
the event {X = x, Y = y}. 

For the proof of the Protocol Soundness Theorem, we need two result involve the TV 
distance. According to the first result, if P and Q be joint distribution of RVs V and W , 
where the marginals of W satisfy P(w) = Q(w), then the distance between them be give by 
the average conditional distance. This be explicitly calculate a follows: 

TV(PVW ,QVW ) = 
∑ 
w 

∑ 
v 

JP(v, w) > Q(v, w)K (P(v, w)−Q(v, w)) 

= 
∑ 
w 

∑ 
v 

JP(v|w)P(w) > Q(v|w)Q(w)K (P(v|w)P(w)−Q(v|w)Q(w)) 

= 
∑ 
w 

∑ 
v 

JP(v|w) > Q(v|w)K (P(v|w)−Q(v|w))P(w) 

= 
∑ 
w 

TV(PV |W=w,QV |W=w)P(w). (S3) 

2 



The second result be a special case of the data-processing inequality for TV distance. See 
Ref. [36] for this and many other data-processing inequalities. Let V be a random variable 
take value in a finite set V , and let F : V → W be a function so that F (V ) be a random 
variable take value in the setW . Then if P and Q be two distribution of V , 

TV 
( 
PV ,QV 

) 
≥ TV 

( 
PF (V ),QF (V ) 

) 
. (S4) 

Here be a proof of this inequality. WriteW = {s1, ..., sc}, and for each i ∈ {1, . . . , c}, define 
Vi = {v : f(v) = si}. The Vi form a partition of V . Then we have 

TV 
( 
PF (V ),QF (V ) 

) 
= 

1 

2 

c∑ 
i=1 

|P(V ∈ Vi)−Q(V ∈ Vi)| 

= 
1 

2 

c∑ 
i=1 

∣∣∣∣∣∑ 
v∈Vi 

[P(V = v)−Q(V = v)] 

∣∣∣∣∣ 
≤ 1 

2 

c∑ 
i=1 

∑ 
v∈Vi 

|P(V = v)−Q(V = v)| 

= TV 
( 
PV ,QV 

) 
. (S5) 

We need to refer to the sequence of RVs associate with the first i − 1 trials. To do this 
we use notation such a (AB)<i for the outcome sequence A1B1A2B2...Ai−1Bi−1, (XY)<i 
for the setting sequence X1Y1...Xi−1Yi−1, and (ABXY)<i for the joint outcome and setting 
sequence A1B1X1Y1...Ai−1Bi−1Xi−1Yi−1. In general we often juxtapose RVs to indicate the 
“joint” RV. From our assumption Eqs. 2 and 3 and the fact that pasti subsumes the trial setting 
and outcome from trial 1 through i− 1, we obtain 

∀i ∈ (1, ..., n), Pe (XiYi|(ABXY)<i) = Pe(XiYi) = 1/4, (S6) 

and 

Pe(Ai|XiYi, (ABXY)<i) = Pe(Ai|Xi, (ABXY)<i) 
Pe(Bi|XiYi, (ABXY)<i) = Pe(Bi|Yi, (ABXY)<i). (S7) 

Eq. S6 can be weaken to accommodate imperfect setting randomness by replace it with 
the follow two assumptions, where α ∈ [0, 1/4) be a parameter control deviation from 
uniformity: 

∀i ∈ (1, ..., n), 1/4− α ≤ Pe (XiYi|(ABXY)<i) ≤ 1/4 + α (S8) 
Pe(XiYi|(ABXY )<i) = Pe(XiYi|(XY )<i) (S9) 

Eq. S6 be a strictly strong assumption a it implies both Eq. S8 (with α = 0) and Eq. S9. 
Eqs. S7, S8, and S9 be the form of our assumption use in the proof of the Entropy Production 

3 



Theorem. Eq. S9 express conditional independence of all past outcome and the upcoming 
setting give the past settings. It be a special case of the Markov-chain condition in Ref. [28]. 

For a generic trial of a two station Bell test, a distribution be define to be non-signaling if 

P(A|XY ) = P(A|X) and P(B|XY ) = P(B|Y ). (S10) 

Such distribution form a convex polytope and include the local realist (LR) distributions. 
Using the convention of [22], these be define a follows: Let λ range over the set of six- 
teen four-element vector of the form (a0, a1, b0, b1) with element in {+, 0}. Each λ induces 
settings-conditional deterministic distribution accord to 

Pλ(ab|xy) = 

{ 
1, if a = ax and b = by, 
0, otherwise. 

(S11) 

Then a probability distribution P be LR iff it conditional probability P(ab|xy) can be write 
a a convex combination of the Pλ(ab|xy). That be 

P(ab|xy) = 
∑ 
λ 

qλPλ(ab|xy), (S12) 

with qλ a λ-indexed set of nonnegative number sum to 1. This definition agrees with the 
one give in the main text. 

The eight “Popescu-Rohrlich (PR) boxes” [37] be example of non-signaling distribution 
that be not LR. One of the PR box be define by 

PPR(ab|xy) = 

{ 
1/2 if xy 6= 11 and a = b, or if xy = 11 and a 6= b, 
0 otherwise, 

(S13) 

and the other seven be obtain by relabeling setting or outcomes. We take advantage of the 
fact that a PR box contains one bit of randomness conditional on the setting and that the PR 
box together with the 16 deterministic LR distribution of Eq. S11 form the set of extreme 
point of the non-signaling polytope [38]. 

S.2 Proof of the Entropy Production Theorem 
The condition on T give in the main text be that (1) T > 0, (2) E(T )P ≤ 1 for every LR 
distribution P, (3) there exists anm > 0 such that E(T )Q ≤ 1+m for every non-signaling distri- 
bution Q if the setting distribution be uniform a in Eq. 2, and (4) the bound 1+m be achievable. 
Our proof of the Entropy Production Theorem do not require that the fourth condition be sat- 
isfied. Furthermore, we prove the Entropy Production Theorem with a weaken form of the 
second and third conditions, assume that T satisfies condition (2) and (3) with any setting 
distribution satisfy Eq. S8. In the following, we call this relaxed version of condition (1)-(3) 

4 



“the Bell-function condition with bound m and setting parameter α”. We also generalize the 
Entropy Production Theorem by allow the Ti to be chosen base on (abxy)<i. We call Ti a 
“past-parametrized family of Bell functions” if for all (abxy)<i, Ti(aibixiyi, (abxy)<i) satis- 
fies the Bell-function condition with bound m and setting parameter α when consider a a 
function of the result aibixiyi from the i’th trial. By prove the theorem for past-parametrized 
Bell function T , we allow for the possibility of dynamically adapt T during run time, a 
feature that could compensate for experimental drift in future implementation of the protocol. 
The theorem and it proof can also be directly apply to the special case where Ti be the same 
function for all trial i and α = 0. 

Theorem 1. Let Ti be a past-parametrized family of Bell function a define in the previous 
paragraph. Then in an experiment of n trial obey Eq. S7, Eq. S8 and Eq. S9, the follow 
inequality hold for all �p ∈ (0, 1) and vthresh satisfy 1 ≤ vthresh ≤ (1 + (3/2)m)n�−1p : 

Pe (Pe(AB|XY) > δ, V ≥ vthresh) ≤ �p (S14) 

where δ = [1+(1− n√�pvthresh)/2m]n and Pe represent the probability distribution condition 
on the event {E = e}. 

We include the constraint vthresh ≤ (1+(3/2)m)n�−1p for technical reasons. Higher value of 
vthresh be unreasonably large and result in pas probability that be too low to be relevant. Note 
that this bound ensures δ ≥ 2−2n, a fact that will be useful in prove the Protocol Soundness 
Theorem in (S.5). 

Proof. Since the condition on {E = e} appear uniformly throughout, in this proof we omit 
the subscript on Pe specify conditioning on {E = e}. 

The strategy of the proof be to first obtain an upper bound on the one-trial outcome probabil- 
ities from the expectation of Bell function T . This bound can be chain to give a bound on 
the probability of the outcome sequence a a monotonically decrease function of the prod- 
uct of the conditional expectation of the Ti. That is, a large product of expectation yield a 
small maximum probability and therefore more extractable randomness. This product can- 
not be directly observed, so we relate it to the observe product V of the Ti via the Markov 
inequality apply to an associate positive, mean-1 martingale. In the following, we suppress 
the argument aibixiyi and (ABXY)<i of Ti. 

The one-trial outcome probability be bound by mean of the follow lemma: 

Lemma 1. Let T satisfy the Bell-function condition with bound m > 0 and setting parameter 
α. For any non-signaling distribution P satisfy Eq. S8, 

max 
abxy 

P(ab|xy) ≤ 1 + 1− E[T (A,B,X, Y )]P 
2m 

. (S15) 

Proof. The settings-conditional distribution P(ab|xy) be non-signaling, so it can be obtain a 
a convex combination of extremal such distributions. The convex combination require at most 

5 



one PR box ( [39], Corollary 2.1), so we write P(ab|xy) = pQ(ab|xy) + (1 − p)Q′(ab|xy), 
where Q be the PR box and Q′ be LR. We thus have 

E(T )P = 
∑ 
abxy 

T (abxy)P(abxy) = 
∑ 
xy 

(∑ 
ab 

T (abxy)P(ab|xy) 

) 
P(xy) 

= p 
∑ 
abxy 

T (abxy)Q(ab|xy)P(xy) + (1− p) 
∑ 
abxy 

T (abxy)Q′(ab|xy)P(xy) 

≤ p(1 +m) + (1− p) = 1 + pm, (S16) 

where the inequality above hold because Q(ab|xy)P(xy) and Q′(ab|xy)P(xy) respectively 
define non-signaling and LR distribution satisfy Eq. S8, and hence these distribution re- 
spectively satisfy E(T ) ≤ 1 +m and E(T ) ≤ 1. The above inequality can be re-written a p ≥ 
(E(T )P − 1)/m. Now since the PR box assigns xy-conditional probability 1/2 to at least one 
outcome different from ab, it follow that the xy-conditional probability relative to P of an out- 
come different from ab be at least p/2. Therefore, P(ab|xy) ≤ 1−p/2 ≤ 1−(E(T )P−1)/(2m). 
Since ab and xy be arbitrary, this give the inequality the lemma. 

We can now establish a bound on P(ab|xy) a follows: 

P(ab|xy) = 
n∏ 
i=1 

P(aibi|(ab)<i,xy) 

= 
n∏ 
i=1 

P(aibi|(abxy)<i, xiyi) 

≤ 
n∏ 
i=1 

[ 
1 + 

1− E(Ti|(abxy)<i) 
2m 

] 
. (S17) 

Here, the first identity be the chain rule for conditional probabilities, and the second follow 
from repeat application of the follow identity, which hold for all j in (i+ 1, i+ 2, ..., n) 
(where we recall that (xy)<n+1 = xy and (ab)<i(xy)<i+1 = (abxy)<i, xiyi). The third 
equality below be a consequence of Eq. S9: 

P(aibi|(ab)<i, (xy)<j+1) = 
P(aibi, (ab)<i, (xy)<j+1) 
P((ab)<i, (xy)<j+1) 

= 
P(xjyj|aibi, (ab)<i, (xy)<j)P(aibi, (ab)<i, (xy)<j) 

P(xjyj|(ab)<i, (xy)<j)P((ab)<i, (xy)<j) 

= 
P(xjyj|(xy)<j)P(aibi, (ab)<i, (xy)<j) 
P(xjyj|(xy)<j)P((ab)<i, (xy)<j) 

= P(aibi|(ab)<i, (xy)<j). (S18) 

Finally, the inequality in Eq. S17 be a consequence of our assumption in Eq. S7 that the past- 
dependent distribution be non-signaling, which allows u to apply the bound from Lemma 1. 

6 



Now, by twice use the fact that the geometric mean of a set of positive number be always less 
than or equal to their arithmetic mean, we continue from the last line of Eq. S17: 

n∏ 
i=1 

[ 
1 + 

1− E(Ti|(abxy)<i) 
2m 

] 
= 

{ n∏ 
i=1 

[ 
1 + 

1− E(Ti|(abxy)<i) 
2m 

]} 1nn 

≤ 

∑ni=1 
[ 
1 + 1−E(Ti|(abxy)<i) 

2m 

] 
n 

n 

= 

1 + 1 
2m 
− 

∑n 
i=1 

[ 
E(Ti|(abxy)<i) 

2m 

] 
n 

n 

≤ 

1 + 1 
2m 
− 

[ 
n∏ 
i=1 

E(Ti|(abxy)<i) 
2m 

] 1 
n 

n 

= 

( 
1 + 

1− [ 
∏n 

i=1 E(Ti|(abxy)<i)] 
1 
n 

2m 

)n 
. (S19) 

Referring back to the statement of the theorem, we see that δ can be express a f(�pvthresh) 
where f(x) = [1+(1− n 

√ 
x)/2m]n. Expressing Eq. S19 in term of this same function f , we see 

that the event {P(AB|XY) > δ} implies the event {f ( 
∏n 

i=1 E(Ti|(ABXY)<i)) > δ}. The 
latter event be the same a { 

∏n 
i=1 E(Ti|(ABXY)<i) < f−1(δ) = �pvthresh}, since f−1 be strictly 

decreasing. Conjoining the event {V ≥ vthresh} to both side of the implication, we have 
{P(AB|XY) > δ, V ≥ vthresh} implies { 

∏n 
i=1 E(Ti|(ABXY)<i) < �pvthresh, V ≥ vthresh}, 

and so by the monotonicity of probabilities, 

P (P(AB|XY) > δ, V ≥ vthresh) ≤ P 

( 
n∏ 
i=1 

E(Ti|(ABXY)<i) < �pvthresh, V ≥ vthresh 

) 
. 

(S20) 
The event {Φ} whose probability appear on the left-hand side of this equation be the event 
in the theorem statement whose probability we be require to bound. For any value of the 
RVs, the two inequality in the event on the right-hand side imply the inequality in the event 
{Ψ} = {V/ 

∏n 
i=1 E(Ti|(ABXY)<i) ≥ 1/�p}. Hence P(Φ) ≤ P(Ψ). It remains to show that 

P(Ψ) ≤ �p. For this purpose we define the sequence {Wc}nc=1 of RVs by 

Wc = 
c∏ 
i=1 

Ti 
E(Ti|(ABXY)<i) 

, (S21) 

so that {Ψ} = {Wn ≥ 1/�p}. 

7 



By definition, Wc > 0 and the factor Ti/E(Ti|(ABXY)<i) have expectation 1 conditional 
on the past. Sequences of RVs with these property be refer to a test martingale [40] and 
satisfy that E(Wn) = 1, which can be verify directly by induction: 

E(Wc|(ABXY)<c) = E 

( 
c∏ 
i=1 

Ti 
E(Ti|(ABXY)<i) 

∣∣∣∣∣(ABXY)<c 
) 

= E 

(( 
c−1∏ 
i=1 

Ti 
E(Ti|(ABXY)<i) 

) 
1 

E(Tc|(ABXY)<c) 
Tc 

∣∣∣∣∣(ABXY)<c 
) 

= 

( 
c−1∏ 
i=1 

Ti 
E(Ti|(ABXY)<i) 

) 
1 

E(Tc|(ABXY)<c) 
E (Tc|(ABXY)<c) 

= Wc−1, (S22) 

where in the second last line, we pull out factor that be function of the conditioner (ABXY)<c 
by apply the rule that if F be a function of H , then E(FG|H) = FE(G|H). Taking the un- 
conditional expectation of both side of Eq. S22 and invoke the law of total expectation, we 
have E(Wc) = E(Wc−1), and so inductively, E(Wn) = E(W1). Since E(W1) = 1, the claim 
follows. To finish the proof of the Entropy Production Theorem, we apply Markov’s inequality 
to obtain P(Wn ≥ 1/�p) ≤ �p and consequently P(Φ) ≤ �p. 

Now that we have prove the Entropy Production Theorem for any past-parametrized family 
of Bell functions, we can justify a strategy of set the remain Bell function to Ti = 1 
after vthresh be exceed by the run product mid-protocol. Formally, since the run 
product Vi−1 = 

∏i−1 
i=j Tj be a function of (ABXY)<i, we can define Ti = T conditional on 

{Vi−1 < vthresh} and Ti = 1 conditional on the complement. This optional strategy can be use 
to eliminate the possibility that statistical fluctuation or experimental drift could cause 

∏n 
i=1 Ti 

to be less than vthresh even though the run product exceed vthresh at some point prior to n. 

S.3 Choosing the Bell Function T 
The Entropy Production Theorem do not indicate how to find function T satisfy the spec- 
ified conditions. We seek a high typical value of V = 

∏n 
i=1 Ti, a this permit large value of 

vthresh and consequently more extractable randomness at the same value of �p and m. Here, 
we describe a procedure for construct a function T that can be expect to perform well if 
the trial result be i.i.d. with know distribution. We estimate the distribution from an initial 
portion of the run that we set aside a training data, and in a stable experiment we expect that 
the trial results’ statistic be i.i.d. to a good approximation. Note however that the optimistic 
i.i.d. assumption be only use a a heuristic to construct T ; once T be chosen the guarantee of 
the Entropy Production Theorem hold regardless of whether the trial result be actually i.i.d. 

8 



We first focus on the scenario where Eq. S6 be assume to hold, then show how to proceed if 
this be replace with the weaker assumption Eq. S8 and Eq. S9. 

The observe measurement outcome frequency for training data generally yield a weakly 
signal distribution that do not exactly satisfy the non-signaling constraint in Eq. S10, due 
to statistical fluctuation. Hence one can obtain an estimate distribution by determine the 
maximum likelihood non-signaling distribution for the observe measurement outcome fre- 
quencies a described in Ref. [31]. Let N(xy) be the number of training trial at set xy and 
f(ab|xy) = N(ab|xy)/N(xy) be the empirical frequency of outcome ab give set xy. Let 
Q(a, b, x, y) be a candidate for the probability distribution from which these frequency be 
sampled. Then up to an additive term independent of Q accounting for the setting probabili- 
ties, the log-likelihood of f give Q be L(Q) = 

∑ 
a,b,x,yN(xy)f(ab|xy) ln(Q(a, b|x, y)). We 

maximize a variant of this function to find our estimate distribution Q(a, b, x, y): 

Maximize 
Q 

∑ 
abxy 

f(ab|xy) lnQ(a, b, x, y) (S23) 

Subject to Q(x, y) = 1/4 for x, y ∈ {0, 1} 
Q(a|x, y) = Q(a|x) for x, y ∈ {0, 1}, a ∈ {+, 0} 
Q(b|x, y) = Q(b|y) for x, y ∈ {0, 1}, b ∈ {+, 0}. 

The first group of constraint encode our knowledge that all setting combination be equally 
likely, and the remain constraint be the non-signaling constraints. Note that the conditional 
expression in these constraint be equivalently express a linear function of Q(a, b, x, y) 
after use the identity Q(x, y) = 1/4. 

Once the estimate distribution Q be obtained, we maximize the typical value of V by 
take advantage of the observation that the condition on T imply that V −1 be a conservative p- 
value against local realism [31]. Such p-values be study in Ref. [31], which give a general 
strategy, the PBR method, for maximize E(ln(V ))Q. This be useful because typical value of 
V be close to exp(nE(ln(T ))Q): Since ln(V ) = 

∑n 
i=1 ln(Ti) be a sum of i.i.d. bound term 

(given our optimistic assumption), the central limit theorem ensures that lnV be approximately 
normally distribute with mean nE(ln(T ))Q. We therefore perform the follow optimization 
problem to find T : 

Maximize 
T 

E(ln(T ))Q (S24) 

Subject to E(T )Pλ ≤ 1 ∀λ 
T (0, 0, x, y) = 1 ∀x, y, 

where Pλ refers to the 16 conditionally deterministic LR distribution in Eq. S11 with uniform 
setting distributions. This ensures that E(T )PLR ≤ 1 for all LR distribution PLR with uniform 
setting distributions. The second constraint be motivate by the fact that in our experiments, an 

9 



overwhelm fraction of the trial have no detection for both stations. While it be possible that 
a good E(ln(T ))Q can be obtain without this constraint, we have found that the improvement 
be small and likely not statistically significant give the amount of training data use to deter- 
mine the result distribution. Since the objective function be concave and the constraint be 
linear, the optimization problem give in Eq. S23 and Eq. S24 be readily solve numerically 
with standard tools. 

Given the assumption that the trial result be i.i.d., the previous paragraph show that the 
typical value for V be exponential in the number of trials, V = e−nE(ln(T ))−o(n). If the exper- 
iment be successful in show violation of local realism, E(ln(T )) be positive. Neglecting the 
contribution from o(n), with vthresh = enE(ln(T )), we can bound − ln(δ) a 

− ln(δ) = −n ln(1 + (1− (�penE(ln(T )))1/n)/(2m)) 
= −n ln(1 + (1− eE(ln(T ))+ln(�p)/n)/(2m)) 
≥ −n(1− eE(ln(T ))+ln(�p)/n)/(2m) 
= n(eE(ln(T ))+ln(�p)/n − 1)/(2m) 
≥ (nE(ln(T )) + ln(�p))/(2m). (S25) 

where we use − ln(1 + x) ≥ −x and ex − 1 ≥ x. This show that asymptotically (with �p 
constant) we get at least E(ln(T )) log2(e)/(2m) = E(log2(T ))/(2m) bit of randomness per 
trial. For the empirical distribution obtain from the fifth data set (“Data Set 5”) use for the 
protocol accord to Eq. S23, we obtain E(log2(T ))/2m = 1.42×10−4. The bound in Eq. S25 
show that we can get an asymptotically positive number of bit of randomness per trial even 
with �p exponentially small in n. 

Now we turn to the problem of find a function satisfy the condition E(T )PLR ≤ 1 
for all LR distribution PLR with setting distribution constrain only by the weaker condition 
Eq. S8, which replaces the strong exact uniformity condition of Eq. S6. To do this, we show 
that it be sufficient to check only distribution with the extremal setting distribution where two 
setting have probability 1/4+α and the two other setting distribution have probability 1/4− 
α. To see why this be possible, for a fix positive Bell function T , let P be an LR distribution 
whose setting distribution be constrain by Eq. S8. Taking advantage of the representation in 
Eq. S12, 

E(T )P = 
∑ 
abxy 

T (abxy)P(ab|xy)P(xy) = 
∑ 
abxy 

T (abxy) 

(∑ 
λ 

qλPλ(ab|xy) 

) 
P(xy) 

= 
∑ 
λ 

qλ 
∑ 
abxy 

T (abxy)Pλ(ab|xy)P(xy) ≤ max 
λ 

∑ 
abxy 

T (abxy)Pλ(ab|xy)P(xy), (S26) 

so the expect value of T with respect to P be always less than or equal to the expect value 
of T with respect to a conditionally deterministic LR distribution Pλ with the same setting 
distribution. Since each deterministic LR distribution assigns conditional probability 1 to a sin- 
gle outcome ab for each of the four set choice xy, the sum 

∑ 
abxy T (abxy)Pλ(ab|xy)P(xy) 

10 



contains only four nonzero terms. Consider the two large value of T (abxy) and the two small- 
est value of T (abxy) appear in the four nonzero terms. Note that 

∑ 
abxy T (abxy)Pλ(ab|xy)P(xy) ≤∑ 

abxy T (abxy)Pλ(ab|xy)P∗(xy), where P∗(XY ) be the distribution that assigns probability 
1/4 + α to the two setting correspond to the two large T , and probability 1/4 − α to 
the two setting correspond to the two small T . Hence for any T , we can ensure that 
E(T )P ≤ 1 hold for all LR distribution by check that E(T )P ≤ 1 hold for each condi- 
tional distribution PλAB|XY couple with each of the i = 1, . . . , 

( 
4 
2 

) 
= 6 setting distribution 

SiXY assign probability 1/4 +α to two setting and 1/4−α to two other settings. This lead 
u to the maximization problem 

Maximize 
T 

E(ln(T ))Q (S27) 

Subject to E(T )Pλ 
AB|XY S 

i 
XY 
≤ 1 ∀λ, i 

T (0, 0, x, y) = 1 ∀x, y. 

The new problem maximizes the same objective function a in Eq. S24 subject to a larger, but 
still finite, number of constraints. It can be solve numerically to find a Bell function for the 
weak setting distribution. 

S.4 The TMPS Algorithm 
A strong randomness extractor with parameter (σ, �, q, d, t) be a function Ext : {0, 1}q × 
{0, 1}d → {0, 1}t with the property that for any random string R of length q and min-entropy at 
least σ, and an independent, uniformly distribute seed string S of length d, the distribution of 
the concatenation Ext(RS) with S of length t+ d be within TV distance � of uniform. There be 
construction of extractor that extract most of the input min-entropy σ with few seed bits. For 
a review of the achievable asymptotic tradeoffs, see Ref. [41], chapter 6. For explicit extractor 
that perform well if not optimally, we use a version of Trevisan’s construction [25] imple- 
mented by Mauerer, Portmann and Scholz [26], which we adapted1 to make it functional in our 
environment and to incorporate recent construction achieve improve parameter [42]. We 
call this construction the TMPS algorithm. For a fix choice of σ, � and q, the TMPS algorithm 
can construct a strong randomness extractor for any value t obey the follow bound: 

t+ 4 log2 t ≤ σ − 6 + 4 log2(�). (S28) 

Given t, the length of the seed satisfies 

d ≤ w2 ·max {2, 1 + d[log2(t− e)− log2(w − e)]/[log2 e− log2(e− 1)]e} , (S29) 

wherew be the small prime large than 2×dlog2(4qt2/�2)e. We note that the TMPS extractor 
be secure against classical and quantum side information [26], and this security be reflect in 
the parameter constraints. Since we do not take direct advantage of this security, it be in principle 

1Our adapt source code be available at https://github.com/usnistgov/libtrevisan. 

11 

https://github.com/usnistgov/libtrevisan 


possible to improve the parameter in the Protocol Soundness Theorem. It may also be possible 
relax the requirement of seed uniformity with more advanced constructions. For the purpose 
randomness amplification this be theoretically accomplish in Ref. [43]. 

For the bound on the the number of seed bit give after the Protocol Soundness Theorem 
in the main text, we have q = 2n and � = �ext/2. Since for any r, there be a prime w satisfy 
r < w ≤ 2r, w = O(log(n) + log(t/�)) = O(log(nt/�)), where we pull out exponent from 
the log, and drop and arbitrarily increase the implicit constant in front of each term to 
match summands. The coefficient of w2 in the bound on d be O(log(t)), because of the “minus” 
sign in front of the term contain w. Multiplying give d = O(log(t) log(nt/�ext)2). 

S.5 Proof of the Protocol Soundness Theorem 
The distinction between the station be need to establish the inequality in the Entropy Pro- 
duction Theorem and play no further role in this section. We therefore simplify the notation by 
abbreviate C = AB and either Z = XY or Z = XYE. In the former case P(. . .) refers to 
probability conditional on {E = e}. Otherwise, P(. . .) involves no implicit conditions. The 
Protocol Soundness Theorem hold regardless of which definition of Z be in force. We write 
Rpass to refer to the RV that take value 1 conditional on the passing event {V ≥ vthresh} and 0 
otherwise. The constant �p and δ appear below be the same a in the Entropy Production 
Theorem. 

Theorem 2. Let 0 < �ext, κ < 1. Suppose P(pass) ≥ κ, and suppose t be a positive integer 
satisfy 

t+ 4 log2 t ≤ − log2 δ + log2 κ+ 5 log2 �ext − 11. (S30) 

Then if Ext : {0, 1}2n × {0, 1}d → {0, 1}t be obtain by the TMPS algorithm with parameter 
σ = − log2[2δ/(κ�ext)] and � = �ext/2, and S be a random bit string of length d independent of 
the joint distribution of C,Z, Rpass, then the joint distribution of U = Ext(CS), Z, S and Rpass 
satisfies 

TV 
( 
PUZS|Rpass=1,PunifU PunifS PZ|Rpass=1 

) 
≤ �p/P(pass) + �ext, (S31) 

where Punif denotes the uniform probability distribution. 

At this point it be tempt to just apply an extractor to AB with parameter σ give by the 
nominal �p-smooth min-entropy σ = − log2(δ). However, this do not guarantee the strong 
condition Eq. S31. Specifically, there be three reason that Eq. S14 of the Entropy Production 
Theorem do not immediately support the application of an extractor to AB. The first be that 
a specified, the extractor input should have min-entropy − log2 maxab P(AB = ab) = σ with 
no smoothness error. The second be that the settings-conditional smooth min-entropies can be 
substantially small than the nominal one. The third be that the min-entropy be also affected by 
the probability of passing be less than 1. Accounting for these effect require an analysis 
of the settings- and pass-conditional distribution and the extractor parameter specify in the 
theorem. 

12 



Proof. The proof proceeds in two main step inspire by the correspond argument in Ref. [2]. 
In the first we determine a probability distribution P∗ that be within �p of P but satisfies an ap- 
propriate bound on the conditional probability of C with probability 1 rather than 1− �p. The 
distribution P∗’s marginals agree with those of P on ZS. The probability conditional on abort- 
ing also agree, and uniformity and independence of S be preserved. In the second step, we apply 
a proposition from Ref. [44] on apply extractor to distribution such a P∗ whose average 
maximum conditional probability satisfy a specify bound. The proposition enables u to 
determine the extractor parameter that achieve the require final distance �p/P(pass) + �ext in 
the theorem. 

The Entropy Production Theorem guarantee that P(P(C|Z) > δ,Rpass = 1) ≤ �p. In the 
case where E be include in Z, this follow by the uniformity in {E = e} of the theorem’s 
conclusion: 

P(P(C|Z, E) > δ,Rpass = 1) = 
∑ 
e 

P(P(C|Z, E) > δ,Rpass = 1|E = e)P(E = e) 

= 
∑ 
e 

P(P(C|Z, E = e) > δ,Rpass = 1|E = e)P(E = e) 

≤ 
∑ 
e 

�pP(e) 

= �p. (S32) 

Using the follow construction, one may observe that for any random variable U with 
value in a set of cardinality K and γ satisfy 1/K ≤ γ, and any distribution P′ of U , 
there exists P′′ such that P′′(U = u) ≤ γ for all possible outcome u and P′′ be within TV 
distance P′(P′(U) > γ) of P′. To construct P′′, for u such that P′(u) > γ, set P′′(u) = γ. To 
compensate for the reduce probabilities, increase the value of P′ to obtain those of P′′ without 
exceed γ on the set {u : P′(u) ≤ γ} so that P′′ be a normalize probability distribution. 
This be possible because in construct P′′ from P′, the total reduction in probability on {u : 
P′(u) > γ} give by r− = 

∑ 
u:P′(u)>γ(P′(u) − γ) be less than the maximum total increase 

possible give by r+ = 
∑ 

u:P′(u)≤γ(γ − P′(u)), a a consequence of γ ≥ 1/K. To see this, 
compute r+ − r− = 

∑ 
u(γ − P′(u)) ≥ 

∑ 
u(1/K − P′(u)) = 0. The distance TV(P′,P′′) be 

give by 
∑ 

u:P′(u)>γ(P′(u) − γ) ≤ P′(P′(U) > γ). We can now construct P∗ by define it 
conditional distribution on C. For this, substitute U ← C, P′(U) ← P(C|z, Rpass = 1), γ ← 
δ/P(Rpass = 1|z) and P′′(U) ← P∗(C|z, Rpass = 1). The constraint on γ be satisfied because 
the upper bound on vthresh in the statement of the Entropy Production Theorem ensures that 
δ ≥ 2−2n. Each conditional distribution satisfies P∗(C|z, Rpass = 1) ≤ δ/P(Rpass = 1|z), which 
be equivalent to P∗(C, Rpass = 1|z) ≤ δ, and be within TV distance P 

( 
P(C|z, Rpass = 1) > 

δ/P(Rpass=1|z) 
∣∣z, Rpass = 1) of PC|z,Rpass=1. The joint probability distribution P∗ be determine 

pointwise from the already assign value of P∗(c|zrpass) for rpass = 1 a 

P∗(czsrpass) = 
{ 

P∗(c|zrpass)P(zsrpass) if rpass = 1 
P(czsrpass) otherwise. 

(S33) 

13 



Since the marginal distribution of ZSRpass be unchanged, the full TV distance between P and P∗ 
be give by the average conditional TV distance with respect to ZSRpass, see Eq. S3. Since the 
conditional TV distance be zero when Rpass = 0 and from independence of S, we obtain 

TV(P∗CZSRpass ,PCZSRpass) 

= 
∑ 
zsrpass 

TV 
( 
P∗C|zsrpass ,PC|zsrpass 

) 
P(zsrpass) 

= 
∑ 
zsrpass 

TV 
( 
P∗C|zsrpass ,PC|zsrpass 

) 
Jrpass = 1KP(zsrpass) 

≤ 
∑ 
zsrpass 

P 
( 
P(C, Rpass = 1|z) > δ 

∣∣z, Rpass = 1)Jrpass = 1KP(zsrpass) 
= 

∑ 
zrpass 

P 
( 
P(C, Rpass = 1|z) > δ 

∣∣z, Rpass = 1)Jrpass = 1KP(zrpass) 
= 

∑ 
czrpass 

JP(crpass|z) > δKP(c|zrpass)Jrpass = 1KP(zrpass) 

= 
∑ 
czrpass 

JP(crpass|z) > δKJrpass = 1KP(czrpass) 

= P(P(CRpass|Z) > δ,Rpass = 1) 
≤ P(P(C|Z) > δ,Rpass = 1) 
≤ �p. (S34) 

At this point we can also bound the TV distance conditional on passing. Since P∗(Rpass) = 
P(Rpass), we can apply Eq. S3 and the above bound on the distance to get 

�p ≥ TV 
( 
P∗CZSRpass ,PCZSRpass 

) 
= 

∑ 
r 

TV 
( 
P∗CZS|Rpass=r,PCZS|Rpass=r 

) 
P(Rpass = r) 

= TV 
( 
P∗CZS|Rpass=1,PCZS|Rpass=1 

) 
P(Rpass = 1). (S35) 

We conclude that 

TV 
( 
P∗CZS|Rpass=1,PCZS|Rpass=1 

) 
≤ �p/P(Rpass = 1). (S36) 

For the second main step, we need the average “guessing probability” of C give Z condi- 
tional on {Rpass = 1}. This be give by∑ 

z 

max 
c 

(P∗(c|z, Rpass = 1))P(z|Rpass = 1) ≤ 
∑ 
z 

δ 

P(Rpass = 1|z) 
P(z|Rpass = 1) 

= δ 
∑ 
z 

P(z) 
P(Rpass = 1) 

≤ δ/κ. (S37) 

14 



We remark that here it be necessary to assume the low bound κ on P(Rpass = 1) in order to 
proceed; otherwise the bound in Eq. S37 would become unbounded due to potentially arbitrarily 
small value of P(Rpass = 1). Now we can apply Proposition 1 of Ref. [44]. The next lemma 
extract the conclusion of this proposition in the form we need. It be obtain by substitute the 
variable and expression in the reference a follows: X ← C, Y ← S, E ← Z, E(X, Y ) ← 
Ext(CS), k ← − log2(δ/κ)−log2(2/�ext), �← �ext/2 and the distribution be replace with the 
correspond one that be conditional on {Rpass = 1}. The guess entropy in the reference 
be the negative logarithm of the the average guess probability in Eq. S37. 

Lemma 2. Suppose that Ext be a strong extractor with parameter 
(− log2(2δ/(κ�ext)), �ext/2, 2n, d, t). Write U = Ext(CS). Then we have the follow 
bound: 

TV 
( 
P∗UZS|Rpass=1,P 

unif 
U PSP∗Z|Rpass=1 

) 
≤ �ext. (S38) 

To apply the lemma, we obtain Ext by the TMPS algorithm with the parameter in the 
lemma. Expanding the logarithm a σ = − log2(δ) + log2(κ) + log2(�ext) − 1 and log2(�) = 
log2(�ext)− 1 and substitute in Eq. S28 give the requirement 

t+ 4 log2 t ≤ − log2(δ) + log2(κ) + 5 log2(�ext)− 11, (S39) 

a assert in the Protocol Soundness Theorem. The number of seed bit d be obtain from 
Eq. S29. 

It remains to determine the overall TV distance conditional on passing. Applying Eq. S4 
with V = C,Z,S and F define a F (C,Z,S) = 

( 
Ext(C,S),Z,S 

) 
, and apply Eq. S36, we 

have 

TV 
( 
P∗UZS|Rpass=1,PUZS|Rpass=1 

) 
≤ TV 

( 
P∗CZS|Rpass=1,PCZS|Rpass=1 

) 
≤ �p/P(Rpass = 1). (S40) 

Then by Eq. S2, Eq. S38 and Eq. S40, we have 

TV 
( 
PUZS|Rpass=1,PunifU PunifS P∗Z|Rpass=1 

) 
≤ �ext + �p/P(Rpass = 1). (S41) 

As P∗Z|Rpass=1 = PZ|Rpass=1, the statement of the theorem follows. 

As discuss in the main text, the Protocol Soundness Theorem implies that the uncondi- 
tional TV distance from an “ideal protocol” can be bound by max(�p + �ext, κ). This error 
parameter be closely related to the security definition appear in, for instance, Equation (1) 
of [45] and Definition 4 of [29]. To explain how we arrive at max(�p + �ext, κ), note that an 
ideal protocol may abort with positive probability, but condition on not abort it produce 
perfectly uniform output independent of side information. That is, the distribution of an ideal 
protocol PidealUZSRpass must satisfy P 

ideal 
UZS|Rpass=1 = P 

unif 
U PunifS PidealZ|Rpass=1, but the distribution of the 

ideal protocol be otherwise unconstrained when Rpass = 0. Given our actual protocol distribu- 
tion P we can define a particular ideal distribution with the same probability of passing a the 
actual protocol by set PidealUZS|Rpass=1 = P 

unif 
U PunifS PZ|Rpass=1, PidealUZS|Rpass=0 = PUZS|Rpass=0, and 

15 



Pideal(Rpass = 1) = P(Rpass = 1). If P(Rpass = 1) ≥ κ, the unconditional TV distance from P 
to this ideal protocol can be bound by 

TV (PUZSRpass ,PidealUZSRpass) = 
∑ 
r=0,1 

TV (PUZS|Rpass=r,PidealUZS|Rpass=r)P(Rpass = r) 

= TV (PUZS|Rpass=1,PidealUZS|Rpass=1)P(Rpass = 1) 
≤ [�p/P(Rpass = 1) + �ext]P(Rpass = 1) 
≤ �p + �ext, (S42) 

where above we used, in order, Eq. S3, PidealUZS|Rpass=0 = PUZS|Rpass=0, Eq. S31, and P(Rpass = 
1) ≤ 1. Alternatively, if P(Rpass = 1) < κ, we have 

TV (PUZSRpass ,PidealUZSRpass) = TV (PUZS|Rpass=1,P 
ideal 
UZS|Rpass=1)P(Rpass = 1) 

≤ 1 · κ 
= κ, (S43) 

a the TV distance can never be great than one. Thus we see that the distance from the ideal 
protocol be bound by max(�p + �ext, κ). However, a note in the main text, we consider 
a more conservative overall error parameter �fin = max(�p/κ + �ext, κ). This ensures that 
for all pas probability exceed κ, the pass-conditional distribution of the output be within 
�p/P(pass) + �ext ≤ �p/κ+ �ext ≤ �fin of PunifU PunifS PZ|Rpass=1. 

S.6 Protocol Application Details 
The Protocol Soundness Theorem support the protocol give in Table S1, with overall sound- 
ness error give by �fin = max(�p/κ+ �ext, κ). A protocol be furthermore complete if there exist 
real-world system that pas the protocol with reasonably high probability. The completeness 
of our protocol be support by quantum mechanics, which predicts experimental distribution 
that violate nontrivial Bell inequality [17] and pas the protocol with high probability. Com- 
pleteness be also witness by our repeat successful implementation of the protocol. 

The five new data set report in the main paper be take in 2017. Each trial in a data 
set encompass fourteen time intervals, and in a give trial, the outcome “+” be record if 
there be a detection in any one of these interval and “0” otherwise. The number of interval 
be fix and chosen in advance of run the protocol. The five data set be analyze in the 
order in which they be taken. We determine the Bell function T from training data consist 
of the first 5 × 106 trial a explain in S.3. We chose 5 × 106 trial so that we could obtain 
a Bell function T use an accurate estimate of the experimental distribution of measurement 
outcome without sacrifice too much data that could be use for randomness generation. After 
the protocol be officially run on a data set, the same data set be re-analyzed use different 
length of training portion to see if a different length should be use for subsequent data sets, 
but there be never clear evidence to suggest that we should have use a different length for the 
training portion. 

16 



Table S1: Protocol for Randomness Generation 
1. Choose a Bell function T satisfy the condition of the Entropy Production Theorem, 
a number of trial n to be run, a threshold for passing vthresh > 1, error parameter 
�p, �ext, κ > 0, and a positive integer t for which Eq. 5 be satisfied. 

2. (Entropy Production) Run a succession of n experimental trials, where in each trial 
i Alice and Bob randomly and uniformly choose respective setting Xi, Yi ∈ {0, 1}, and 
record respective output Ai, Bi ∈ {+, 0}. (Optional) Calculate 

∏i 
j=1 T (Aj, Bj, Xj, Yj) 

after each trial and re-set T to the constant function 1 for the remainder of the experiment 
if 
∏i 

j=1 T (Aj, Bj, Xj, Yj) > vthresh. 

3. Compute 
∏n 

i=1 T (Ai, Bi, Xi, Yi) and abort if this quantity do not exceed vthresh. 

4. (Extraction) Generate a random and uniform d-bit seed string S where d be give by 
Eq. S29 with q = 2n, � = �ext/2. Output U = Ext(AB,S) with the security guarantee 
give by Eq. 6. 

After training, we infer an expect value nµ and variance nσ2 of 
∑n 

i=1 ln(Ti) on the 
remain trial assume i.i.d. trial and Gaussian statistic accord to the central limit theo- 
rem, where n and µwere calculate accord to the distribution obtain from the optimization 
problem of Eq. S23. Note that under these assumptions, we treat 

∑n 
i=1 ln(Ti) a if it be a sum 

of independent and bound RVs. Since V = exp ( 
∑n 

i=1 ln(Ti)) we can then choose vthresh so 
that it have a 0.95 chance of be exceed accord to the Gaussian approximation, by set 
vthresh = e 

nµ−1.645 
√ 
nσ. For Data Sets 3, 4 and 5, vthresh be chosen to be small than this 

value to increase the chance of passing the protocol while still meeting desirable benchmark 
for extractable randomness. 

We now discus our application of the protocol to Data Set 5, and then summarize the main 
result for all five data set in Table S4. Data Set 5 set consists of 60,110,210 trials, roughly 
twice a long a each of the first four data sets. The count for each trial outcome from the 
first 5 × 106 trial be show in Table S2. The maximum likelihood non-signaling distribution 
correspond to these count be show in Table S3. We determine T from this distribution, 
the value of T be show in Table 1 of the main text. 

Table S2: Result count for the first 5× 106 trial of Data Set 5. 
ab = ++ ab = +0 ab = 0+ ab = 00 

xy = 00 3166 1851 2043 1243520 
xy = 01 3637 1338 13544 1230633 
xy = 10 3992 13752 1226 1230686 
xy = 11 357 17648 16841 1215766 

The 0.95 rule for determine vthresh give that there be 55,110,210 trial for the protocol 
yield vthresh = 8.79 × 1036. We chose a more conservative value of vthresh = 1.5 × 1032 to 

17 



Table S3: Maximum likelihood non-signaling distribution accord to the count in Table S2, 
round to eight decimal places. 

ab = ++ ab = +0 ab = 0+ ab = 00 
xy = 00 0.00063301 0.00036794 0.00041085 0.24858820 
xy = 01 0.00073159 0.00026936 0.00270824 0.24629081 
xy = 10 0.00080002 0.00277179 0.00024384 0.24618435 
xy = 11 0.00007087 0.00350093 0.00336896 0.24305924 

improve the odds of passing the protocol, while still allow for the extraction of 1024 bit 
uniform to within 10−12. This threshold corresponds to a probability of passing of roughly 
0.9916 accord to the i.i.d. scenario described above. Running the protocol, this threshold 
be exceeded, with a final value of V = 2.018× 1041. 

The run product 
∏c 

i=1 Ti first exceed vthresh at trial number c = 41, 243, 976, and 
one have the option of set the remain Ti = 1 regardless of outcome for the rest of the 
data run. The soundness of this procedure be justified by the adaptive property of the Entropy 
Production Theorem. In our application of the protocol, we implement a similar strategy 
without technically change the Bell function, by relabeling all outcome to 0 start at trial 
number c + 1. This also result in Ti = 1 for the remainder of the experiment. This strategy be 
justified a our assumption allow for Alice and Bob to cooperatively make arbitrary change to 
the experiment in advance of a trial base on the past, which include the current run prod- 
uct. Turning off the detector to guarantee outcome of 0 be one such change, and in principle 
there be sufficient time (at least 5µs) for the necessary communication to take place after the 
previous trial. 

Throughout, we do not consider the length d of the seed in make our choice and deter- 
mine d from the other parameter accord to Eq. S29. For apply the extractor to Data 
Set 5, we use 315,844 seed bits. The seed bit be collect from one of the random number 
generator use to select the setting in [13]. Specifically, each seed bit come from the XOR 
of two bit generate by the photon-sampling random number generator described in [13]. It 
take 317 second for our computer to construct the extractor accord to the TMPS algorithm 
and generate the explicit final output string. Here be the final output string that result from 
apply the extractor to the string AB, when AB be obtain with relabeling of all outcome 
to 0 start at trial number 41, 243, 977 (after vthresh be exceed by the run product). 

11100010011111111101001100001111100101010101001101111001111010110101101000011011000111010001101000111010011110011100101101100100 
10111111111001100010110010110111101100101111010011001101101111010100111001011010111111011110010100110001000101011000001111111101 
11011001110001111100010010011100011100000000010110010101101111001011001001000001101110110000000111110111001110001100101110001100 
10110110001100011101001001001010101000100001010101001001011101010101001010100111001101001010001010100001101111110110011011110000 
11100110100110010111001011000110010100101000110101100100000110111000101101001101110110111111001110110011100000001111001111101100 
10110000111110011100110111110110101111000001010001010110100010011101011000001001011100010110101101111100110100001110101110110101 
10001010011111011110111001000001000110111111110011101001110100111000000100101100010011101110100001110101111001001011111111001100 
01111011101001101010101100010010000011111110010101011010111111100011110110001010111011000001111000011111101100100010001001000010 

After the protocol be run, we ran consistency check on the data set to look for potential 
inconsistency with Eq. 3, the no-signaling assumption. Using the test described in Ref. [13], 
we examine the four signal equalities: 1: P(A|X = 0, Y ) = P(A|X = 0), 2: P(A|X = 

18 



Table S4: Summary of application of protocol to data sets. For fix goal choice of �fin, the 
error parameter be compute accord to the formula �p = κ2 = (0.95 �fin)2, �ext = 0.05 �fin. 
Error parameter be chosen in advance of run the protocol for Data Sets 3, 4 and 5; the 
�fin and t value for Data Sets 1 and 2 be marked with an asterisk a they be not chosen in 
advance and be only include for illustrative purposes. We remark that the quantity 1/vthresh 
can also be interpret a a p-value against local realism [31]. 

Data Set n m 95% cut off vthresh �fin t V > vthresh 
1 24865320 0.01066 4.68× 1016 4.68× 1016 10−6∗ 512∗ Yes 
2 24809970 0.01126 1.30× 105 1.30× 105 0.01∗ 61∗ Yes 
3 24818959 0.01163 9.74× 1019 1017 10−6 512 Yes 
4 24846822 0.01063 6.57× 1015 1015 10−6 256 Yes 
5 55110210 0.01004 8.79× 1036 1.5× 1032 10−12 1024 Yes 

Table S5: 2-tail p-values for consistency check 
Data Set Sig. 1 Sig. 2 Sig. 3 Sig. 4 

Data Set 1 0.507 0.777 0.290 0.323 
Data Set 2 0.765 0.965 0.115 0.684 
Data Set 3 0.633 0.072 0.381 0.099 
Data Set 4 0.144 0.320 0.844 0.356 
Data Set 5 0.879 0.131 0.554 0.885 

1, Y ) = P(A|X = 1), 3: P(B|X, Y = 0) = P(B|Y = 0), and 4: P(B|X, Y = 1) = 
P(B|Y = 1). For these test we use statistic whose asymptotic distribution would approach 
the standard normal with mean 0 and variance 1, if the trial be i.i.d. We report the p-values 
obtain from these test for all data set in Table S5, which do not suggest any inconsistencies. 

Prior to the analysis of the five data set report in the main text, the protocol be apply 
to data set take a part of the experiment report in Ref. [13]. These result be described 
in [46]. After set aside the first 5 × 107 trial of the data set XOR 3 a a training set to 
construct the function T and choose a threshhold vthresh base on the 95% rule, the protocol be 
apply to the rest of the data set with parameter �p = 3.1797× 10−4 and �ext = 3.533× 10−5, 
which be chosen to minimize �p/κ + �ext for κ = 1/3 while satisfy Eq. 5. This choice 
of parameter be suboptimal for minimize either �fin or max(�p + �ext, κ), the two figure 
of merit disucssed in the main text. However, the instance of the TMPS algorithm induced 
by the above choice of parameter would have be induced by other choice of parameter 
that perform good accord to these figure of merit. The same extraction be induced by 
�p = 3.6509 × 10−4, �ext = 3.5330 × 10−5, and κ = 4.0042 × 10−4, which lead to a distance 
of max(�p + �ext, κ) = 4.0042× 10−4 from an ideal protocol for the extraction of 256 bits. We 
can also choose �p = 3.370 × 10−4, �ext = 3.533 × 10−5, and κ = 0.0184 to induce the same 
extraction with an �fin parameter of 0.0184. 

Statistically significant setting nonuniformity be detect for some of the set examine 

19 



in [46]. This be consistent with the find in [13] that a combination of uncontrolled envi- 
ronmental variable and the synchronization electronics introduce small bias in the settings. 
This effect be not present in the 2017 data sets, which use a reliable pseudorandom source 
for setting randomness. As the Entropy Production Theorem can tolerate small bias in the 
setting distribution, we can explore how the protocol would have perform on XOR 3 have we 
selected, prior to run the protocol, a nonzero settings-bias parameter α. We note that the 
protocol parameter must be chosen prior to execute a secure protocol, and since we do not 
choose a nonzero α in advance of examine XOR 3, we report the follow calculation only 
a a retrospective diagnostic. In principle it be impossible to measure α through statistical test 
of the output of the random number generator that choose the settings, because the setting 
probability can appear random, unbiased, and independent even while change from trial to 
trial within the bound of a potentially large α. To choose an example α to study, we exam- 
ined 95 % confidence interval for the individual setting probability from the six data set 
in [13]. The large absolute difference from 0.5 among the endpoint of these six interval be 
0.000211 for Alice and 0.000150 for Bob. Assuming independence between Alice and Bob (an 
assumption which be not contradict by our statistical tests), we compute the most and least 
likely measurement configuration give this large difference from 0.5 for Alice’s and Bob’s 
setting probability, and found that these would be contain in the interval (0.25−α, 0.25+α) 
for α = 0.000181. For this example choice of α, perform the modify optimization problem 
described in S.3 yield a T function with m = 0.01179, and for this T function, the expect 
threshold compute accord to the 95 % rule be vthresh = 5.25× 105, if we assume the “worst- 
case” setting distribution among the six extremal setting distribution that assign probabil- 
ity 0.25 + α to two setting configuration and 0.25 − α to two other setting configurations. 
This threshold be pass when the protocol be re-run now with this non-zero α. For �p value 
of (0.01, 0.001, 0.0001, 0.00001) we get correspond − log2 δ value of (524, 383, 242, 101), 
which be a moderate reduction compare to the correspond value of (582, 444, 306, 168) 
obtain by the run the protocol with α = 0. Alternatively, we can fix �p and study how 
− log2 δ change with α. For one particular choice of �p = 3.1797 × 10−4, which be the 
small �p value consider early in analysis of XOR 3, α value of (0, 0.00001, 0.0001, 
0.001) yield − log2 δ value of (367, 366, 321, 94). The large value α = 0.001 in this list may 
be consider a conservative choice: if in the first calculation above we have use 99.999998 % 
instead of 95 % confidence intervals, we would have obtain a value of α ≈ 0.001/3 instead 
of α = 0.000181. 

S.7 Performance of Previous Protocols. 
Other protocol in the literature could not be use for our data set for various reasons. Many 
protocol apply to different measurement scenarios. For instance, [4] describes a protocol in- 
volving three separate measurement stations, and while [27] provide impressive expansion 
rate and be secure against quantum side information, it require eight separate devices. Other 
protocol explore quantum side information in Refs. [3, 8, 30] either also apply to different 

20 



experimental setup or provide only asymptotic security result a the number of trial n ap- 
proaches infinity. The first protocol achieve security against quantum side information [6] 
applies to a bipartite experiment like ours but require system that achieve per-trial Bell vio- 
lations much high than ours. Another study [11] of bipartite experiment with data regime 
characteristic of photonic system applies to i.i.d. scenarios. 

The protocol of Refs. [5, 29] be applicable to our experimental scenario while make 
minimal assumptions, and give enough trial could work for any violation regime. Ref. [5] 
obtain protocol for assumption equivalent to ours, but consider also the case where the 
distribution be in addition assume to be quantum achievable. Ref. [29], which us the 
Entropy Accumulation Theorem of Ref. [28], obtain protocol assume that the distribution 
be quantum achievable, but allow for quantum side information. However, these protocol 
be ineffective for the number of trial in our data sets, which we illustrate with a heuristic 
argument. Both protocol be base on the Clauser-Horne-Shimony-Holt (CHSH) Bell function 
[47] 

T c(a, b, x, y) = 

 
1 if (x, y) 6= (1, 1) and a = b 
1 if (x, y) = (1, 1) and a 6= b 
0 otherwise. 

(S44) 

The statistic T c = n−1 
∑n 

i=1 T 
c 
i use by these protocol for witness accumulate violation 

satisfies E(T c) ≤ 0.75 under LR, while E(T c) = 0.75009787 for the distribution in Table 
S3. The completely predictable LR theory that only produce “00” outcome regardless of the 
setting satisfies E(T c) = 0.75, but in an experiment of n = 55, 110, 210 trials, this theory can 
produce a value of T c exceed 0.75009787 with probability roughly 0.047. Thus, base on 
this statistic alone, we cannot infer the presence of any low-error randomness. 

The protocol of Ref. [5] (the PM protocol for short, see [2, 7] for amendments), can be 
modify to work with any Bell function, and there be method for obtain good Bell func- 
tions [9, 10] or simultaneously use a suite of Bell function [48]. Here, we demonstrate that 
for any choice of Bell function, the method of [5] a refine in [2] cannot be expect to effec- 
tively certify any randomness from an experiment distribute accord to Table S3 unless the 
number of trial exceeds 1.56× 108, which be large than the number of trial in our data runs. 

For the most informative comparison to our protocol, we consider the PM protocol without 
their additional constraint that the distribution be induced by a quantum state. To derive a bound 
on the performance of the PM protocol, we refer to Theorem 1 of [2]. This theorem involves 
a choice of Bell function denote by I (analogous to our T ), a threshold Jm (analogous to our 
vthresh) to be exceed by the Bell estimator Ī = n−1 

∑n 
i=1 Ii, and a function f that we discus 

below. To be able to extract some randomness, the theorem require that 

nf(Jm − µ) > 0. (S45) 

The parameter µ be give by (Imax + INS) 
√ 

(2/n) ln(1/�) where Imax be the large value in the 
range of the Bell function I , INS ≤ Imax be the large possible expect value of I for non- 
signal distributions, and 0 < � ≤ 1 be a free parameter that be add to the TV distance 

21 



from uniform for the final output string. Smaller choice of �, which be analogous to our �p, be 
desirable but require large n for the constraint Eq. S45 to be positive a we will see below. We 
also note that Eq. S45 be a necessary but not sufficient condition for extract randomness; in 
particular, we ignore the negative contribution from the parameter �′ of [2] (somewhat analogous 
to the parameter κ in the statement of the Protocol Soundness Theorem in S.5) a well a any 
error introduce in the extraction step. 

For Eq. S45, we can without loss of generality consider only Bell function for which 0 ≤ 
IL < INS ≤ Imax, where IL be the maximum expectation of I for LR distributions. Further, 
because the relevant quantity below be invariant when the Bell function be rescaled, we can 
assume IL = 1. According to Ref. [2]’s Eq. 8 and the follow paragraph, we can write 
f(x) = − log2(g(x)), where g be monotonically decrease and concave, and satisfies 

max 
ab 

P(ab|xy) ≤ g(E(I)P) (S46) 

for all xy and non-signaling distribution P. (Recall that we be not use the strong constraint 
that P be induced by a quantum state.) According to Eq. S15 we can define g(x) = 1 + (1 − 
x)/(2(INS − 1)). Later we argue that this definition of g cannot be improved. Substituting into 
Eq. S45 we get the inequality 

−n log2 

1 + 1− Jm + (Imax + INS) 
√ 

2 
n 

ln 1 
� 

2(INS − 1) 

 > 0. (S47) 
Since 2(INS − 1) be positive, this be equivalent to√ 

2 

n 
ln 

1 

� 
< 

Jm − 1 
Imax + INS 

. (S48) 

Noting that Imax + INS ≥ 2INS, this implies√ 
2 

n 
ln 

1 

� 
< 
Jm − 1 

2INS 
. (S49) 

Thus, the number of trial need to extract randomness by the PM protocol be bound below 
accord to 

n > 8 
ln(1/�)I2NS 
(Jm − 1)2 

. (S50) 

For a give anticipate experimental distribution Pant, Jm be best chosen to be at most E(I)Pant . 
Otherwise, the probability that Ī exceeds Jm be small. However, for the maximum amount of 
extractable randomness, Jm should be close to E(I)Pant . Consider the infer distribution from 
the first 5× 106 trial of Data Set 5. By follow the procedure give in Section 2 of [39], we 
can write this distribution a a convex combination of a PR box with weight p = 3.915× 10−4 

22 



and an LR distribution with weight 1 − p. From this we see that one should choose Jm ≤ 
E(I)Pant = pINS + (1 − p) ≤ pINS + 1. Substituting into Eq. S50 and use � ≤ 0.05 (a rather 
high bound on the allowable TV distance from uniform) give 

n > 8 
ln(1/�) 

p2 
≥ 1.56× 108, (S51) 

which be already more than twice the number of trial use to generate randomness in Data 
Set 5. For small error value comparable to the one we report, this bound only increases: 
achieve � = 10−12 would require at least 1.44× 109 trials. 

To finish our argument that the PM protocol cannot improve on this bound under our as- 
sumptions, consider the definition of g. If we could find a function g′ ≤ g with g′(x) < g(x) 
for some x ∈ (1, INS], then f = − log2(g′) might yield a small low bound on n. Note that 
for x ≤ 1, g′(x) ≥ g′(1) and g′(1) must be at least 1 because, refer to Eq. S46, there be a 
conditionally deterministic LR distribution P satisfy E(I)P = 1 and maxab P(ab|xy) = 1. 
Hence Eq. S45 cannot be satisfied for argument x of f(x) = − log2(g′(x)) with x ≤ 1. Given 
x ∈ (1, INS], write x = (1 − p) + pINS. Let Q be the PR box achieve E(I)Q = INS and 
Q′ a conditionally deterministic LR theory achieve E(I)Q′ = 1. Then E(I)(1−p)Q′+pQ′ = x. 
Furthermore, there be a set xy at which the LR theory’s outcome be inside the support of the 
PR box’s outcomes. To see this, by symmetry it suffices to consider the PR box of Eq. S13. Its 
outcome be opposite at set 11 and identical at the other three. A deterministic LR theory’s 
outcome be opposite at an even number of settings, so either it be opposite at set 11, or it be 
identical at one of the others. For set xy, the bound in Eq. S46 be achieve for our definition 
of g. Hence any other valid replacement g′ for g must satisfy g′(x) ≥ g(x) for x ∈ (1, INS], and 
so Eq. S45 with f(x) = − log2(g′(x)) implies Eq. S45 with f(x) = − log2(g(x)). Thus the 
low bound on n derive above will apply to g′ a well. 

References 
[35] Levin, D. A., Peres, Y. & Wilmer, E. L. Markov chain and mix time (American 

Mathematical Soc., 2009). 

[36] Pardo, M. & Vajda, I. About distance of discrete distribution satisfy the data process- 
ing theorem of information theory. IEEE transaction on information theory 43, 1288–1293 
(1997). 

[37] Popescu, S. & Rohrlich, D. Quantum nonlocality a an axiom. Found. Phys. 24, 379–85 
(1994). 

[38] Barrrett, J. et al. Nonlocal correlation a an information-theoretic resource. Phys. Rev. A 
71, 022101 (2005). 

23 



[39] Bierhorst, P. Geometric decomposition of Bell polytopes with practical applications. J. 
Phys. A: Math. Theor. 49, 215301 (2016). 

[40] Shafer, G., Shen, A., Vereshchagin, N. & Vovk, V. Test martingales, Bayes factor and 
p-values. Statistical Science 26, 84–101 (2011). 

[41] Vadhan, S. P. Pseudorandomness, vol. 7 of Foundations and Trends in Theoretical Com- 
puter Science (2012). 

[42] Ma, X., Zhang, Z. & Tan, X. Explicit combinatorial design (2012). ArXiv:1109.6147v2 
[math.CO]. 

[43] Kessler, M. & Arnon-Friedman, R. Device-independent randomness amplification and 
privatization (2017). ArXiv:1705.04148 [quant-ph]. 

[44] König, R. & Terhal, B. The bounded-storage model in the presence of a quantum adver- 
sary. IEEE T. Inform. Theory 54, 749–62 (2008). 

[45] Portmann, C. & Renner, R. Cryptographic security of quantum key distribution (2014). 
ArXiv:1409.3525 [quant-ph]. 

[46] Bierhorst, P. et al. Experimentally generate random number certify by the impossibil- 
ity of superluminal signal (2017). ArXiv:1702.05178 [quant-ph]. 

[47] Clauser, J., Horne, A., Shimony, A. & Holt, R. Proposed experiment to test local hidden- 
variable theories. Phys. Rev. Lett. 23, 880–884 (1969). 

[48] Nieto-Silleras, O., Bamps, C., Silman, J. & Pironio, S. Device-independent randomness 
generation from several Bell estimator (2016). ArXiv:1611.00352 [quant-ph]. 

24 


S.1 Preliminaries 
S.2 Proof of the Entropy Production Theorem 
S.3 Choosing the Bell Function T 
S.4 The TMPS Algorithm 
S.5 Proof of the Protocol Soundness Theorem 
S.6 Protocol Application Details 
S.7 Performance of Previous Protocols. 

