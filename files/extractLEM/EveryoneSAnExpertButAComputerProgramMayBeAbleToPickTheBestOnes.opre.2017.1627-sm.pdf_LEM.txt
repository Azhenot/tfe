

































Bansal, Gutierrez, and Keiser: Quantile Judgments to Deduce Probability Distributions 
Operations Research 00(0), pp. 000–000, c© 0000 INFORMS 1 

Online Appendix A 

1. Proof of Lemma 1 

Clearly μ0 = E[X0] = 1. For a location-scale random variable X, we have X = θ1 + θ2Z where Z be the 

standardize random variable correspond to X, when θ1 = 0 and θ2 = 1. Denoting E[Zj ] = κj , we obtain 

claim (a) from 

E[Xj ] = E[(θ1 + θ2Z) 
j ] = 

j∑ 

i=0 

( 
j 

i 

) 

θi1θ 
j−i 
2 κj−i (16) 

where the last equality follow from the binomial expansion of the term (θ1 + θ2Z)j . 

To obtain (b) we substitute X = θ1 + θ2Z and μ1 = θ1 + θ2κ1 from (16) into E[(X −μ1)j ] to get 

E[(X −μ1) 
j ] = E[(θ1 + Zθ2 − θ1 −κ1θ2) 

j ] = θj2E[(Z −κ1) 
j ] (17) 

From the binomial expansion of the last term, and use E[Zj−i] = κj−i, we obtain θ 
j 
2E[(Z − κ1) 

j ] = 

θj2 
∑j 

i=0 

( 
j 

i 

) 
(−κ1)iκj−i. � 

2. Proof of Theorem 1 

The Lagrangian of the problem be 

L = wk 
tΩwk − [Z 

twk − ak][λ] (18) 

where λ = [λ1, λ2] 
t be the vector of Lagrange multiplier for vector θt = (θ1, θ2) ∈ R×R++. Then, the first 

order optimality condition be give by the follow m +2 equations: 

∇wkL =2Ωwk −Zλ = 0, (19) 

∇λL =−Z 
twk + ak = 0. (20) 

This be a set of m + 2 linear equation with the same number of unknowns. It can also be see from the 

formulation that this system of equation have a full rank so a unique solution exists. We first reduce (19) by 

solve for λ; to this end we pre-multiply (19) by ZtΩ−1, and obtain 

2Ztwk = Z 
tΩ−1Zλ (21) 

The inverse Ω−1 exists because Ω be positive definite. Now, substitute Ztwk = ak from (20), we obtain 

from (21) 

λ = 2(ZtΩ−1Z)−1ak (22) 

The inverse (ZtΩ−1Z)−1 exists because Z have a full rank and Ω−1 be positive definite. Substituting λ from 

(22) into (19) reduces (19) to a system of m equation with m unknowns, and we solve this system a follow 

2Ωwk −Zλ = 0⇒ 2Ωwk = 2Z(Z 
tΩ−1Z)−1ak ⇒wk = Ω 

−1Z(ZtΩ−1Z)−1ak (23) 

� 



Bansal, Gutierrez, and Keiser: Quantile Judgments to Deduce Probability Distributions 
2 Operations Research 00(0), pp. 000–000, c© 0000 INFORMS 

3. Proof of Proposition 2 

We show above that 

wktZ = akt. (24) 

For the estimation of mean μ1, we have a1 = [1, κ1], which then implies that 
∑ 

w∗1i = 1. Similarly, for the 

estimation of standard deviation μ2, a2 = 
[ 
0, 
√ 

κ2 −κ21 
] 
, which implies that 

∑ 
w∗2i = 0. � 

4. Proof of the Variance of μ̂k for Section 5.1 

We be interested in the variance of wktq̂. Since wktq̂ = wkt(Zθ + �) = wktZθ + wkt� and the term 

wktZθ be a constant, it follow that the variance of wktq̂ be equal to the variance of wkt� which be give by 

wktΩwk for k = 1,2. Replacing the expression for wk obtain in Theorem 1 we obtain the variance a 

wk 
tΩwk = ak 

t 

(ZtΩ−1Z)−1ZtΩ−1ΩΩ−1Z(ZtΩ−1Z)−1ak = ak 
t 

(ZtΩ−1Z)−1ak. (25) 

Note that a1 = [1, κ1] 
t for estimate μ1, a2= 

[ 
0, 
√ 

κ2 −κ21 
]t 

for estimate μ2. 

� 

5. Proof of Proposition 3 

(a) For the mean, we note that variance of the distribution of a sample mean of size N1 be equal to μ22/N1 

where μ22 be the population variation. Equating this variance with the variance [1, κ1](Z 
tΩ−1Z)−1[1, κ1] 

t 

obtain above in (25), we obtain N1 = 
μ2 

2 

[1,κ1](ZtΩ−1Z)−1[1,κ1] 
t . 

(b) Stuart and Ord (1994) show on p 352 that the variance of sample standard deviation can be approximate 

a 

V ar(S)≈ 
E[(x−μ1)4]− (E[(x−μ1)j ])2 

4N2μ22 
(26) 

We know from Lemma 1 that 

E[(X −μ1) 
i] = θi2 

i∑ 

j=0 

(−κ1) 
jκi−j (27) 

From Lemma 1, we know that θ2 = μ2/ 
√ 

κ2 −κ21. Substituting this in (27), we obtain E[(X − μ1) 
i] = 

μi2 
∑i 

j=0(−κ1) 
jκi−j/ 

(√ 
κ2 −κ21 

)i 
Substituting this in (26), we obtain 

V ar(S)≈ 
μ2 

2 

4N2 

 

 
 

∑4 
j=0(−κ1) 

jκ4−j 

(κ2 −κ21)2 
− 

(∑2 
j=0(−κ1) 

jκ2−j 

)2 

(κ2 −κ21)2 

 

 
 (28) 

Equating this with the variance in (25) [0, 
√ 

κ2 −κ21](Z 
tΩ−1Z)−1[0, 

√ 
κ2 −κ21] 

t 
, we obtain 

N2 ≈ 
μ2 

2 

 

 
∑4 

j=1(−κ1) 
jκ4−j 

(κ2−κ 
2 
1) 

2 − 
(∑2j=1(−κ1)jκ2−j) 

2 

(κ2−κ 
2 
1) 

2 

 

 

4[0, 
√ 

κ2−κ21](Z 
tΩ−1Z)−1[0, 

√ 
κ2−κ21] 

t . � 

6. Proof of Proposition 4 

(a) We start by note the general result in Theorem 1: w∗k 
t = akt(Z 

t 
Ω−1Z)−1Z 

t 
Ω−1. Next, we define each of 



Bansal, Gutierrez, and Keiser: Quantile Judgments to Deduce Probability Distributions 
Operations Research 00(0), pp. 000–000, c© 0000 INFORMS 3 

these component when j=1,2,...,n expert provide quantile judgments. The matrix Zt = [Z0 
t,Z0 

t, ...,Z0 
t] 

where Z0 
t appear n times, once for each expert. The subscript 0 simply suggests that this be a constant 

matrix since all expert provide judgment for the same set of quantiles.. The matrix Ω be a mn×mn block 

diagonal matrix with diagonal block rjΩ0 where Ω0 be of size m×m. Then, 

1. (Z 
t 
Ω−1Z) = Z0 

t 

Ω−10 Z0[ 
∑N 

j=1(1/rj)] = Z0 
t 

Ω−10 Z0R where R = [ 
∑N 

j=1(1/rj)] 

2. Z 
t 
Ω−1 = [Z0 

t 

Ω−10 (1/r1),Z0 
t 

Ω−10 (1/r2), ...,Z0 
t 

Ω−10 (1/rN)] 

3. It follow from point 1 and 2 above that w∗k 
t = akt(Z0 

t 

Ω−10 Z0) 
−1Z 

t 

0Ω 
−1 
0 [(1/r1)/R, (1/r2)/R, ..., (1/rN)/R]. 

Now we can write this expression a w∗k 
t = wck 

t[(1/r1)/R, (1/r2)/R, ..., (1/rN)/R] where wck 
t = 

akt(Z0 
t 

Ω−10 Z0) 
−1Z 

t 

0Ω 
−1 
0 . Further, the vector w 

∗ 
k 
t be compose of the m weight for each expert j : w∗k 

t = 

[w1k 
t 
,w2k 

t 
, ...,wnk 

t]. It follow from these two relation that wjk = αjw 
c 
k where the expert j ’s marginal weight 

be equal to αj = (1/rj)/R. 

(b) Consider the case when expert j be the only expert available with matrix Ω0 for elicit quantiles Z0. 

Then R = (1/rj). Substituting this expression in point 3 above, it follow that the weight for this expert be 

equal to (1/rj)/R = 1, and the weight for his quantile judgment be equal to his independent weights. 

� 

7. Proof for Proposition 5: 1) The proof follow from the text above the proposition. 

2) We will first obtain explicit expression for the weight w∗k = Ω 
−1Z(ZtΩ−1Z)−1ak with Ω = KΩ′ 

with Ω′ = I, and then show that these weight be identical to the weight obtain use the formulation 

minμ1,μ2 

{ 
∑m 

i=1 

( 
Φ−1(pi;μ1, μ2)− q̂i 

)2 
} 

. For rigor purposes, we provide the result for a more general case 

when the diagonal element of Ω′ be equal to 1, and the off-diagonal element be equal to the correlation 

value ρ, and for brevity we will provide the proof for μ1. The analysis for μ2 be analogous. 

To obtain the explicit expression of the weight we need three intermediate results. 

(a) Ω−1 = 1 
(1−ρ)K2 

( 
I − ρM1 

1+(m−1)ρ 

) 
. To establish this claim define M1 a an (m×m) matrix of one and verify 

that 

ΩΩ−1 = 
1 

1− ρ 

( 

(1− ρ)I + ρM1 

)( 

I − 
ρ 

1+ (m− 1)ρ 
M1 

) 

, 

= 
1 

1− ρ 

[ 

(1− ρ)I + ρM1 − 
ρ(1− ρ) 

1+ (m− 1)ρ 
M1 − 

ρ2m 

1+ (m− 1)ρ 
M1 

] 

= I. 

(b) 

ZtΩ−1 = 
1 

K2(1+ (m− 1)ρ) 

( 
1 ∙ ∙ ∙ 1 ∙ ∙ ∙ 1 

(1+(m−1)ρ)z1−S1ρ 
1−ρ 

∙ ∙ ∙ (1+(m−1)ρ)zi−S1ρ 
1−ρ 

∙ ∙ ∙ (1+(m−1)ρ)zm−S1ρ 
1−ρ 

) 

. 

To establish this claim we use (a) to obtain 

Z 
t 

Ω−1 = 
1 

(1− ρ)K2 

( 
1 ∙ ∙ ∙ 1 ∙ ∙ ∙ 1 
z1 ∙ ∙ ∙ zi ∙ ∙ ∙ zm 

)( 
I − 

ρ 

1+ (m− 1)ρ 
M1 

) 

= 
1 

K2(1+ (m− 1)ρ) 

( 
1 ∙ ∙ ∙ 1 

(1+(m−1)ρ)z1−S1ρ 
1−ρ 

∙ ∙ ∙ (1+(m−1)ρ)zm−S1ρ 
1−ρ 

) 

. 

(c) Denote S1 ≡ 
∑m 

i=1 zi and S2 ≡ 
∑m 

i=1 z 
2 
i , then the inverse of (2× 2) matrix Z 

tΩ−1Z be obtain a 

(ZtΩ−1Z)−1 = 
K2 

mS2 −S21 

( 
S2(1+ (m− 1)ρ)−S21ρ −S1(1− ρ) 

−S1(1− ρ) m(1− ρ) 

) 

. 



Bansal, Gutierrez, and Keiser: Quantile Judgments to Deduce Probability Distributions 
4 Operations Research 00(0), pp. 000–000, c© 0000 INFORMS 

Therefore, the weight for the mean be obtain a w∗μ1 = [1, κ1](Z 
tΩ−1Z)−1ZtΩ−1, which on simplifica- 

tion reduce to 

wi = 
( 
S2 − ziS1 + nziκ1 −S1κ1 − 2κ1S1 +2mκ 

2 
1 

) 
mS2 −S 

2 
1(29) 

2) We now show that these weight coincide with the weight obtain for the minimization of the least 

square minμ1,μ2 F = 

{ 
∑m 

i=1 

( 
μ2 − 

κ1√ 
κ2−κ21 

μ2 + zi 
μ2√ 

κ2−κ21 
− q̂i 

)2 
} 

. We will drop the index over the summa- 

tion in the rest of the proof. Taking the first order derivatives, we obtain: 

∂F 

∂μ1 
= 2 

∑( 
μ1 + μ2 

zi −κ1√ 
κ2 −κ21 

− q̂i 
) 
= 0 (30) 

∂F 

∂μ2 
= 2 

∑( 
μ1 + μ2 

zi −κ1√ 
κ2 −κ21 

− q̂i 
) zi −κ1√ 

κ2 −κ21 
= 0 (31) 

Now, we can write (30) a mμ1 + μ2 
∑ 

zi√ 
κ2−κ21 

−μ2 
mκ1√ 
κ2−κ21 

− 
∑ 

q̂i = 0, or, use 
∑ 

zi = S1 equivalently, 

μ1 = 
μ2(mκ1 −S1) 

m 
√ 

κ2 −κ21 
+ 

∑ 
q̂i 

m 
(32) 

Next, we can simplify (31) use 
∑ 

z2i = S2 and obtain, 

μ2 = 

√ 
κ2 −κ21( 

∑ 
qizi − 

∑ 
qiκ1 + μ1(S1 −mκ1)) 

S2 − 2κ1S1 + nκ21 
(33) 

Now, substitute (33) into (32), and simplification, we obtain 

μ1 = 

∑ 
qi 
( 
S2 − ziS1 + nziκ1 −S1κ1 − 2κ1S1 +2mκ21 

) 

mS2 −S21 
(34) 

which implies the weight of 

wμi = 

( 
S2 − ziS1 + nziκ1 −S1κ1 − 2κ1S1 +2mκ21 

) 

mS2 −S21 
(35) 

These weight be identical to the weight obtain in the least square formulation in (29). The weight 

for μ2 can be show to be equal similarly. � 

References: 

Stuart, Alan, J Keith Ord. 1994. Kendalls advanced theory of statistics. vol. i. distribution theory. Arnold, 

London . 


