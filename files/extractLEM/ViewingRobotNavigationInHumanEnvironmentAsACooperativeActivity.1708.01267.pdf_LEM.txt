







































Untitled 


Viewing Robot Navigation in Human 

Environment a a Cooperative Activity 

Harmish Khambhaita and Rachid Alami 

Abstract We claim that navigation in human environment can be view a co- 

operative activity especially in constrain situations. Humans concurrently aid and 

comply with each other while move in a share space. Cooperation help pedestri- 

an to efficiently reach their own goal and respect convention such a the personal 

space of others. To meet human comparable efficiency, a robot need to predict the 

human trajectory and plan it own trajectory correspondingly in the same share 

space. In this work, we present a navigation planner that be able to plan such coop- 

erative trajectories, simultaneously enforce the robot’s kinematic constraint and 

avoid other non-human dynamic obstacles. Using robust social constraint of 

project time to a possible future collision, compatibility of human-robot motion 

direction, and proxemics, our planner be able to replicate human-like navigation be- 

havior not only in open space but also in confine areas. Besides adapt the robot 

trajectory, the planner be also able to proactively propose co-navigation solution by 

jointly compute human and robot trajectory within the same optimization frame- 

work. We demonstrate richness and performance of the cooperative planner with 

simulated and real world experiment on multiple interactive navigation scenarios. 

1 INTRODUCTION 

Taking inspiration from the joint action literature [1] and from our previous contri- 

butions on robot planning ability for human-robot task achievement [2], we pro- 

pose a reactive navigation planner that build and maintains a set of stream of exe- 

cution for the robot and the human in it close vicinity. Indeed, it have be show 

Harmish Khambhaita 

LAAS-CNRS, Universit de Toulouse, CNRS, Toulouse, France, e-mail: harmish@laas.fr 

Rachid Alami 

LAAS-CNRS, Universit de Toulouse, CNRS, Toulouse, France, e-mail: alami@laas.fr 

1 



2 Harmish Khambhaita and Rachid Alami 

that it be sometimes pertinent to endow the robot with the ability to plan not only 

for itself but also for it human partner. This ability take it full meaning and perti- 

nence when it be necessary that both act in order to solve a problem. In navigation, 

this corresponds to very constrain environments. 

While navigation in a populate environment can generally be model a a kind 

of coordination activity, since each individual have his own goal and all share an 

environment, this very same activity can be transform into a problem that need 

cooperation of two or several individual when the environment becomes very con- 

strained: a give individual cannot find his path unless another individual partici- 

pate and help in find a solution. 

This be exactly the kind of problem we want to tackle: 

• We would like to develop a robot navigation system that be able to manage usual 
coordination issues, but that be also able to manage intricate situations. 

• Besides, we would like, to come up with a scheme that allows the robot to be 
proactive by propose an acceptable solution and, whenever possible, to take 

“most of the load” when the human and the robot have to share the load to solve 

a problem. 

• And, finally, we would like the robot to take into account human acceptability 
and comfort issues. 

Fig. 1 show a typical case where both robot and human can safely and smoothly 

pas each other if they cooperate and facilitate the other party by give enough 

space to move. It be the duty of both to avoid a collision and help the other party to 

advance towards their destination. The solution do not include only the contribu- 

tion of the robot but also of the human. This be why we claim that our planner be a 

cooperative planner. 

In this work, we propose a cooperative navigation planner that predicts a plau- 

sible trajectory for the human and accordingly plan for a robot trajectory that 

satisfies a set of social constraints. It generates both robot and human trajectory 

within a unified planning framework, thus facilitate both agent to avoid any other 

static or dynamic obstacle present in the share space. Generation of these trajec- 

tory becomes one multi-constrained problem and it be solve use a graph-based 

optimal solver. We not only use proxemics, but also apply time-to-collision and 

directional constraint during optimization. Another important aspect in term of 

perceive safety and comfort be that the propose planner inherently balance be- 

tween trajectory modification and speed adaptation. We also show improvement in 

the fluency of interaction with use of the propose cooperative navigation planner. 

The key contribution of this paper be three-fold: 

1. An optimization base framework for compute the robot trajectory and pre- 

dicting probable trajectory of nearby human that respect motion and social 

constraints. 

2. Prudently devise social constraint for (a) safety, (b) time-to-collision, and (c) 

directional compatibility of human-robot motion. 

3. A demonstration of the success of propose approach in everyday interactive 

navigation situations, especially in confine spaces. 



Viewing Robot Navigation in Human Environment a a Cooperative Activity 3 

Fig. 1: A corridor-crossing scenario with propose cooperative planner. The robot be 

able to calculate it own trajectory (in red) and proposes a trajectory for the human 

(in blue) that solves the co-navigation problem. Here the robot assumes that hu- 

man want to go to the other end of the corridor. We have add cylindrical shape 

landmark on the plan robot trajectory and predict human trajectory by the co- 

operative planner. The landmark show future human and robot position at every 

second. The color of the landmark on the human and robot trajectory correspond to 

same future time. We can see that the robot move to it right well in advance (even 

if it be not absolutely necessary at the moment the robot see the human). With such 

proactive behavior the robot be offering the solution to the co-navigation situation. 

The robot do not accelerate until the human pass so that the human do not feel 

threatened, in this example it pass the human at approximately 0.6 m/s and late 
accelerates to 0.8 m/s. If the human reject the solution (bottom figure) suggest 
by the robot and move in the opposite direction to what the robot have predicted, the 

robot be able to quickly react by change it path that adheres to human’s wish. 

Robot’s global path be show in green, where a a velocity base prediction of hu- 

man path be show in yellow. 



4 Harmish Khambhaita and Rachid Alami 

Our approach aim to balance and tune the effort between the human and the 

robot to solve a co-navigation task. It provide additional advantage of streamline 

robot behavior from open space to very constrain environmental conditions. In 

it spirit, our approach be similar to the previously propose approach for geomet- 

ric [3] and symbolic [4] planning systems, where the robot synthesizes a share plan 

for the human and itself. 

2 RELATEDWORKS 

Acting together 

Research in psychology [5] and philosophy [6] have lead to a good understand of 

human behavior during joint action and collaboration and have help to identify 

the key element for human-robot joint action [7]. 

In [8], Tomassello et al. define a goal a the representation of a desire state 

and an intention a an action plan chosen in order to reach the goal. Bratman add 

that if there be a share intention to perform an action, the partner should agree on 

the mesh sub-parts of a share plan [9], which be elaborate base on common 

ground [10]. 

The reactive scheme that we propose here implement some of the joint action 

principles. It take into account the (navigation) intention of the human; it adapts 

permanently to his behavior; it be proactive and do it best to facilitate the action 

of the human. 

Social convention 

The theory of proxemics [11] have provide rule for realize more human like be- 

havior during robot motion and non-motion task [12]. The most of state-of-the-art 

human-aware navigation planner add proxemics cost around human in a grid- 

base map representation of the robot operating environment [13]. Using this cost- 

map the path planning algorithm can generate path that low the total cost over 

the entire path, thereby keep a safe distance from human to maximize human 

comfort. The human-aware navigation planner described by Sisbot et al. [14] al- 

ready provide safe path consider not only proxemics distance but also other 

social criterion like visibility and hidden zone around static human in the environ- 

ment. 

In extension to that work we define a safety constraint in optimization framework 

around the trajectory of move humans. However, to avoid over-cautious behavior 

of the robot, we only apply the safety cost around the respective point in time along 

the human-robot trajectory pairs. That means, the optimization procedure ensures 



Viewing Robot Navigation in Human Environment a a Cooperative Activity 5 

give safety distance between plan position of the robot and predict position 

of the human at all future time point t = 1, t = 2, . . . up to the planning horizon. 
Since these cost generate function regard human a static obstacles, typi- 

cally the planning framework perform continuous re-planning of the robot path to 

cope up with dynamic situations. Nevertheless, only immediate path of the robot 

be re-planned for the planning algorithm to reach real-time compliance. The result- 

ing robot motion be robust and safe but not necessarily social. The robot often 

oscillates or stop completely while move near human [15]. 

The directional cost model introduce by Kruse et al. [16] have show to increase 

legibility of the robot motions, where a robot attempt to solve a spatial conflict by 

adjust velocity instead of path when possible. Humans prefer robot follow 

this strategy, particularly in path cross situation [15]. We exploit this result and 

introduce directional cost in our optimization framework. The directional cost 

discourages face-to-face motion towards a person. It also make the robot slow down 

while move very near to the human because of the model inverse proportionality 

of this constraint to the distance between the human and the robot. 

Human motion prediction 

The requirement for human motion prediction arises when we intend to design a 

robot navigation system that be socially acceptable [17]. Prediction of human tra- 

jectories independent of robot plans, however, do not alleviate the problem of 

purely reactive robot behavior [18]. For example, consider a corridor situation where 

a robot and a person could only cross each other in a side-by-side configuration 

(fig. 1). If the person be walk in the middle of the corridor, due to their predict 

path, the robot will fail to find a collision free trajectory use a reactive planner. 

Therefore, prediction of human trajectory have to consider that the human do see 

the robot and will also try to contribute to collision avoidance with the robot by 

modify their own trajectories. In other words, there be a need for a planner that 

can proactively suggest a solution to the interactive navigation situations. 

More recent approach have paid scrupulous attention to human path predic- 

tion base on renowned social force model [19], which facilitates the navigation 

planner to cope with uncertain human motions. These method predict a class of 

homotypically distinct trajectory for human and design a planner that, from hu- 

man demonstrations, can learn navigation policy for robot to move on human-like 

trajectory [17]. Although, this scheme work fine in large or open space where 

the robot have enough latitude to move, it may require re-learning of the model pa- 

rameters for specialized or constrain situations, such a cross long corridor or 

passing through a door. 



6 Harmish Khambhaita and Rachid Alami 

Planning for the robot and the human 

Concerning the ability for the robot to plan not only for itself but also for it hu- 

man partner, we have developed early a task planner call HATP planner (Human 

Aware Task Planner) [20, 21]. The HATP planning framework extends the tradi- 

tional hierarchical task network planning domain representation and semantics by 

make them more suitable to produce plan which involve human and robot act- 

ing together toward a joint goal. HATP be use by the robot to produce human-robot 

share plan which be then use to anticipate human action, to suggest a course of 

action to humans, or possibly to ask help from the human if needed. 

This effectively enriches the interaction capability of the robot by provide the 

system with what be in essence a prediction of the human behavior. This prediction 

be also use by the robot execution controller to monitor the engagement of the 

human partner during plan achievement. Another key property be to produce plan 

that would be possibly prefer by the human partner. For instance, HATP include 

cost-based plan selection a well a mechanism call social rule to promote plan 

that be consider a suitable for human-robot interaction. 

We have also apply the same approach to a different type of problem that call 

for elaborate geometric reason and planning abilities: robot-human handover in 

a workspace possibly clutter by obstacles. The question be where to perform the 

task and how to balance between the effort of the human and the robot [22, 3]. 

Similarly, the planner we propose here manages explicitly one elastic band per 

agent and plan for all. A number of social constraint have be specially devise 

to produce plan that would be possibly prefer by the human encounter the 

robot. The robot and the human band tightness be different in order to force the 

robot take most of the load. 

Another approach, present by Ferrer et al. [23], us the social force model for 

both to predict human path and control the robot motion. In this approach, every 

iteration of planning step us the human prediction information which be depen- 

dent on the path calculate during the previous iteration. Advantage of such scheme 

be robot act proactively in give situation, however, human prediction be only 

reaction to the robot motion. Our approach be rather cooperative, where optimiza- 

tion process coherently provide a solution for the interactive navigation situation. 

Comparable result could be achieve with propose cooperative planner in non- 

constrain cases, but in situation such a door cross the cooperative planner 

avoids unnecessary detours. In situation like corridor cross with cooperative 

planner the robot prefers wait in a place where it limits, a much a possible, ob- 

struction to the human motion, instead of move backwards due to repulsive human 

interaction force when use a social force model base planner. 

The intention aware reactive avoidance scheme propose by [24] us counter- 

factual reason to calculate probability over a possible set of navigational goals. 

Using such probability set, this approach predicts human motion towards most prob- 

able goal and generates locally optimal motion for multiple robots. The time scale 

collision cone base approach aim to solve the same problem, albeit give same 

treatment to human and non-human obstacle [25]. While be effective in densely 



Viewing Robot Navigation in Human Environment a a Cooperative Activity 7 

crowd environments, a a virtue of remain purely reactive, such approach 

could lead to needle detour in intricate situations. Our focus is, rather, on sophis- 

ticated interactive motion with single person to a group of people in semi crowd 

environments. 

3 METHODOLOGY 

Elastic band be a well-studied approach for dynamic obstacle avoidance that only 

locally modifies the robot path to keep a safe distance from previously unknown 

obstacle [26]. However, the modify path often do not satisfy the kinodynamic 

constraint of the robot. Therefore, a general scheme be to use a controller module 

that take the output path (elastic band) and generates feasible trajectory that the 

robot can follow [27]. Recent proposal of time elastic band evades this problem 

by explicitly consider temporal information [28]. It locally deforms the robot 

path and computes a trajectory augment with a series of time-difference value 

between each successive poses, instead of a purely geometric path. Timed elastic 

band make it easy to take kinodynamic and nonholonomic constraint into account, 

formalize the optimization problem a a non-linear least square problem. We 

have substantially extend this work by introduce prediction and optimization of 

human trajectory in the same framework, in [29] we give preliminary description 

of out approach. Besides, we have brought in carefully select social constraint in 

to the optimization framework. 

We address the task of robot navigation among human by apply least square 

optimization to simultaneously minimize multiple cost-functions that represent 

cost associate with human-robot cooperation a well a robot dynamics. The op- 

timization framework explicitly include prediction of plausible trajectory within 

the same non-linear least square problem. Compared to early work [30], we cre- 

ate elastic-bands also for the human and extend their hyper-graph structure to han- 

dle human separately from ordinary obstacle use well-grounded human-aware 

planning constraints. The result scheme combine in one step the robot-plans, 

human-plans and robot-reacts process. 

3.1 Elastic Band and Graph Optimization 

The time elastic band approach [28] augments each of the n∈N 2D poses, de- 
fin a P := {pi=[xi,yi,θi] 

T} 
n 

i=0, of the robot path with time interval between each 

consecutive poses, denote a T := {∆ t j} 
n−1 
j=0. The result tuple B := {P,T } rep- 

resents a trajectory that be subject to deformation by the optimization algorithm. In 

addition to the robot trajectory BR , we also represent a set of human trajectory 
{BHk} 

m 

k=0 
a time elastic bands, when there be m∈N human in the vicinity of the 

robot. 



8 Harmish Khambhaita and Rachid Alami 

The gist of our approach be to jointly optimize the robot and human trajectory 

in term of social and kinodynamic constraints. It require to solve the follow 

multivariate multi-objective optimization problem use the weighted-sum model: 

f (BR ,BHk) =∑ 
a 

γa fa(BR )+∑ 
b 

γb fb(BHk) 

+∑ 
c 

γc fc(BR ,BHk) 
(1) 

{B∗R ,B 
∗ 
Hk 
}= argmin 

{BR ,BHk 
} 

f (BR ,BHk) (2) 

where {B∗R ,B 
∗ 
Hk 
} denotes the set optimize robot and human trajectories. The 

component objective function for the robot trajectory, human trajectory and 

human-robot social constraint be denote by fa, fb and fc respectively. 

We inherit the kinodynamic and nonholonomic constraint from [28] impose on 

the robot trajectory. These constraint enforce physical limit of velocity and accel- 

eration between consecutive pose of the trajectory, a minimum clearance distance 

from obstacle for each of the poses, and fast execution time for the whole tra- 

jectory. Similarly we impose kinodynamic constraint on human trajectories, with 

human velocity and acceleration limit obtain from empirical study of pedes- 

trians interaction data [31]. While predict human trajectory the optimization 

algorithm try to maintain nominal human velocity (and not the fast velocity 

that human can move with). Constraints on human-robot cooperative motion be 

discuss in detail in Sec. 3.2. 

In our approach we have modify the error function use for safety-clearance 

from obstacle a following, 

fobs(d,do,ε,S) = 

 
 

 

(do+ε)−d 
Sd+1 if 0� d < (do+ ε), 

(do+ ε)−d if d < 0, 

0 otherwise. 

(3) 

where d be the distance between obstacle and a robot pose during current iter- 

ation of the optimization process, do be low bound for obstacle clearance, ε be a 

parameter to control the accuracy of the approximation. This equation be non-linear 

between the low bound and zero, and the parameter S adjust the non-linearity. 

Such construction of the error function enables u to manipulate relative impor- 

tance of safety clearance between robot-obstacle and robot-human. That is, we can 

make robot push itself more towards an obstacle rather than towards a human in 

constrain situations. 

Similarly to [28], we have adopt the general optimization framework g2o [32] 

which require mapping of the least-squares problem into a graph representation. 

Each node in the graph represent a pose along the trajectory and edge that connect 

two node represent constraints, a show in fig. 2. It be possible to write separate 

error function for each of the optimization constraints. This graph base structure 

provide and easy interface to initialize and maintain the structure of variable 



Viewing Robot Navigation in Human Environment a a Cooperative Activity 9 

and constraint that be use during the optimization process. The g2o framework 

employes Levenberg-Marquardt to solve the non-linear least square problem de- 

fin by the graph structure. The graph typically result in a sparse information 

matrix, consequently the g2o framework us state-of-the-art sparse linear system 

solver [33]. Result of the optimization adjusts the position and orientation of each 

of the pose a well a time difference between the consecutive pose of the trajec- 

tory such that the whole trajectory minimizes the impose constraints. 

Since, the result trajectory be an optimally deform version of the initial path, 

this representation of trajectory be similar to an elastic band. By adjust weight 

on the constraint for robot and human separately (the parameter γa and γb in 

equation 1), we can balance and tune the “tightness” of the elastic band for effective 

effort sharing. 

The optimization process run in two computation loops. Inner loop corresponds 

to iterative loop for the least-squares solver. After each full run of the inner loop, 

the optimization process update the graph structure use late result of the solver. 

During this update, new node be add between two node in the graph if the time- 

difference between the two node exceeds certain threshold (which an optimization 

parameter) in order to maintain same time difference between each pair of neighbour 

nodes. Therefore, the human and robot time-difference nodes, show a hi∆T0 and 

r∆T0 in the graph structure be synchronize during this outer loop of graph update. 

Both inner and outer loop run for several iterations, where the number of iteration 

directly affect the quality of produce trajectory and optimization time. 

3.2 Social Constraints 

We have select the above mention graph-based solver because it enables u to 

introduce the social constraint and rule which be appropriate for efficient human- 

robot cooperative planning. Since we have the whole trajectory of human and robot 

at our disposal, we have add social constraint between human and robot node in 

the graph structure that correspond to the same time-step during their trajectories. 

That means, we add an edge for the safety constraint between nth node of human 

and robot trajectory, another edge between n+ 1th nodes, and so on. Nevertheless, 
we only add edge to the node correspond to part of the human path that fall 

withing the local planning area center at the robot. 

Safety Constraint: The safety constraint us proxemics base cost function to 

ensure minimum safety distance between correspond human and robot poses. 

Therefore the error function associate with the safety constraint is, 

fsa f ety(d,ds,ε) = 

� 
(ds+ ε)−d if d < (ds+ ε), 

0 otherwise. 
(4) 

where d be a low bound on allow safe distance between human and robot 

pose at the same time-stamp during the trajectory. There be multiple way one can 



10 Harmish Khambhaita and Rachid Alami 

c o 
b 

o1 

c 
ob 

c 
ob 

rx1 

r∆T0 

cvelr ,caccr ,ckinrrx0 

c s 
a 
fe 

ty 
,c 

tt 
c 
,c 

d 
ir 

c s 
a 
fe 

ty 
,c 

tt 
c 
,c 

d 
ir 

h0x1 

h0∆T0 

cvelh ,cacch ,ckinhh0x0 

c s 
e 
p 

c s 
e 
p 

c s 
a 
fe 

ty 
,c 

tt 
c 
,c 

d 
ir 

c s 
a 
fe 

ty 
,c 

tt 
c 
,c 

d 
ir 

h1x1 

h1∆T0 

cvelh ,cacch ,ckinhh1x0 

Fig. 2: Graph structure. The bottom row have consecutive node for robot trajectory 

(rx0, rx1, . . . ); edge enforce velocity, acceleration, and kinodynamic constraint 

connects these nodes. We combine the three edge into one for easy depiction. 

Penalty impose by these edge depends on time difference between consecutive 

nodes, therefore the time-diff node r∆T0 connects with them. Pose and time-diff 

node be subject to change by the optimization process. Similarly, the middle and 

the top row represent trajectory for human 0 and 1 respectively, albeit with dif- 

ferent weight for constraints. Obstacles node (o1), show with double circle, be a 

fix node, meaning the optimization process cannot alter it position. The edge cob 
show the constraint for keep minimum distance from obstacles. The edge csep 
represent the constraint to keep minimum separation between two humans. Nodes 

of the robot and a human that belong to the same time-step of their trajectory be 

connect by three edge (csa f ety, cttc and cdir) that impose social constraints. 



Viewing Robot Navigation in Human Environment a a Cooperative Activity 11 

represent the footprint of the robot in this planning scheme, for simple circle to com- 

plex polygon. Humans footprint be represent a circle with specify radius. d be 

the outer distance between human and robot. Calculating the outer distance between 

a polygon shape robot and a circle shape human be computationally more expen- 

sive than calculate outer distance between human and robot that be both circle 

shaped. Thus, it be advisable to represent the robot with a simpler footprint. That 

means, the optimization procedure ensures give safety distance between plan 

position of the robot and predict position of the human at all future time point 

t = 1, t = 2, . . . up to the planning horizon. 
The graph structure injects an edge for this safety constraint not only to each 

human-robot trajectory pair but also to each human-human trajectory pair, albeit 

with different parameter for the error function. Such construction of the graph 

structure ensures that the optimization process respect proxemics cost between hu- 

mans. 

Time-to-Collision Constraint: A novel social constraint use in the propose 

scheme be time-to-collision, that is, the project time to a possible future collision 

with a human. Empirical study have show that time-to-collision between self and 

other governs the pedestrian interaction across wide variety of situation [34]. We 

make use of these result by apply high cost to human-robot configuration 

that result in less time-to-collision. Our hypothesis is, the time-to-collision constraint 

will push the robot to act early enough, thus clearly show the robot motion in- 

tentions to the human counterpart. 

fttc(ttc,τ,ε) = 

� 
[(τ+ε)−ttc]α 

C2 
if ttc< (τ+ ε), 

0 otherwise. 
(5) 

where τ be the low bound on time at which the robot predicts a collision occur- 

ring with the human. In other words, τ = 8 indicates that the robot start add cost 
between the configuration (node) of human and robot whenever the compute time- 

to-collision go below 8 s. The parameter α be a scale parameter for strengthen 

or weaken the penalty on particular human robot configuration due to compute 

time to collision and C2 be the square distance between human and robot center 

points. 

ttc be the predict time to collision between a human and the robot. Here we 

consider both human and robot have a disc-like shape, however, with different 

radius. Time to collision define a the time when the boundary of these two move 

disc meet base on their current linear velocities.With this constraint our robot be 

able to proactively propose, a co-navigation solution sufficiently well ahead of time 

compare to other state-of-the-art approaches. 

Directional Constraint: We have add the directional constraint, which defines 

a compatibility measure between human and robot configurations. Motivation for 

this social constraint come from our previous work [15] which aim to improve the 

legibility of the robot motions. Similar to equation 4, the directional constraint be 

also low bound by a threshold ς , and define as, 



12 Harmish Khambhaita and Rachid Alami 

fdir(cdir,ς ,ε) = 

� 
(ς + ε)− cdir if cdir < (ς + ε), 

0 otherwise. 
(6) 

where the directional cost be define as, 

cdir = 
−→vR · 

−−−→pR pH + 
−→vH · 

−−−→pH pR 
C2 

(7) 

−→vR and 
−→vH be robot and human velocity vector respectively, and 

−−−→pR pH defines 
the vector from robot position to human position in 2D vector space and C2 be the 

square distance between center point of robot and human. This measure penalizes 

motion where human and robot be move straight towards each other. Moreover, 

high relative velocity mean high penalty values. Directional constraint establishes 

tread-off between the effect of slow down or change the path. 

With these social constraint we have test the propose planner in simulation 

and on two real robotic platforms. The Sec. 4 discus the result of our test in 

detail. 

3.3 Human-Aware Planning Architecture 

The elastic band approach can only locally deforms the robot trajectory, thus it re- 

quire an initial path to bootstrap the optimization. A simple grid-based global plan- 

ning algorithm, for example A∗, be suitable for compute this initial path. 

The well-known and versatile robot navigation architecture move base [35] 

also differentiates between global planning for generate a path from the start po- 

sition to the goal position in arbitrarily large environment, and local planning for 

avoid immediate obstacle by locally modify the robot trajectory. We have 

adopt move base for our robot navigation architecture within which the pro- 

pose human-robot cooperative planner fit a a local planner. Fig. 3 depicts the 

full navigation architecture. 

It be preferable to reason differently for move and static human in the robot 

operating environment. If position of any human be know at the time of global 

planning, it be good to incorporate the proxemics cost around static human al- 

ready while calculate the global path. Hence, we have developed a plugin for 

layer costmap library [36] (which be part of the move base framework) 

that add safety and visibility cost introduce by [14] around human position in the 

occupancy grid-map. 

We be use a separate module to predict first path for tracked human in the 

robot environment that the cooperative local planner us for optimization. This al- 

low u to switch between different prediction method depend on the interactive 

situation at hand. For example, in a corridor cross situation we use the heuristic 

that the most probable goal of the human be to go to other side of the corridor and 

so we create and imaginary goal position behind the current robot position when a 



Viewing Robot Navigation in Human Environment a a Cooperative Activity 13 

Base Controller 

Sensors 

Obstacle 

Perception 

Human 

MapNavigation Goal 

Localization 

Local Planning 

Filter 

Human 

Prediction 

Human Path 

Costmap 

Global 

Costmap 

Local 

Planner 

Global 

Local Planner 

Cooperative 

Fig. 3: Overview of the navigation software architecture. 

human be first detected. In open areas, we use the velocity-obstacle method [37] 

to generate a short-term path for the tracked humans. 

Since in this cooperative planning scheme we be treat human differently 

than other obstacle in the environment, we filter out the human position data from 

the obstacle detection sensor (laser scanner in out experiments). 

4 EXPERIMENTS 

Before conduct experiment in the real world, we test the propose social con- 

straints and validate them in a simulation environment. We have design a human 

navigation simulator with a framework similar to move base, thereby use sepa- 

rate global and local planning modules. The global planning module us the same 

global costmap that of the robot, for planning global path for human between 

give start and goal positions. As the local planning module we have developed 

simple teleport controller to update human position and velocity, make human 

move on the global path with a constant velocity. By expose the human trajecto- 

ries from the cooperative planner to the human navigation simulator a new path for 

the human to follow, we can simulate full interactive navigation situations. The hu- 

man simulator can simulate motion of multiple humans, thus allow u to test our 

planner also on semi-crowded environments. For simulate a PR21 robot, we have 

1 http://wiki.ros.org/Robots/PR2 



14 Harmish Khambhaita and Rachid Alami 

Fig. 4: Interface for test the cooperative navigation planner in simulation. 

use the generic open source simulation engine MORSE2. Fig. 4 show a screenshot 

of the simulation interface. In out previous work [38], we have compare the pro- 

pose cooperative planner with two other state-of-the-art human-aware navigation 

planner in several canonical path cross situations. 

We have port the cooperative planner to two service robotic platforms, the 

PR2 and the Pepper3 robot. For real world experiments, our objective be to validate 

the navigation planning system, not the human detection and track algorithms. 

Therefore we employ off-the-shelf motion capture system from OptiTrack4. It 

publishes position and velocity of tracked human at a certain frequency (10 Hz 

during our experiments5). 

On the PR2 robot we have also activate a module for coordinate the head mo- 

tion with the navigation planner to facilitate communication of robot’s navigational 

intention [39]. 

Fig. 5 demonstrates the capability of cooperative planning with a series of ex- 

periments in real world interactive situations. We have observe it perform good 

compare to purely reactive planning schemes. It should be note that, for all inter- 

active situation show here the planer be not particularly “informed” about the 

task. The behavior such a stop near the door and facilitate human in con- 

fin corridor emerge because of the integrate social constraint in the optimiza- 

2 https://www.openrobots.org/wiki/morse 
3 https://www.ald.softbankrobotics.com/en/pepper 
4 http://www.optitrack.com/ 
5 Although the motion capture system delivers data at high frequency (about 100 Hz), we apply 

a move average filter and re-sample the filter data at 10 Hz to have good estimate of velocity 



Viewing Robot Navigation in Human Environment a a Cooperative Activity 15 

(a) (b) (c) (d) 

(e) (f) (g) (h) 

Fig. 5: Trajectories generate by cooperative planner for different interactive navi- 

gation tasks. (a and e) A corridor cross situation where human and robot share 

effort to avoid collide with each other. (b and f) A more confine corridor cross 

situation where the robot facilitates the human to cross the corridor with sufficient 

space. (c and g) An open area cross situation where two human decides to move 

on either side of the robot. Although in this situation the original plan suggest by 

the robot be to pas both person on it right side, when the person decide oth- 

erwise the robot comply and quickly adapt it own path accordingly. (d and h) 

A door cross situation where the human want to pas through a door, the robot 

facilitates the human by stop near the door. The robot stop not because of a 

planning failure but because it have plan a cooperative strategy where it wait 

until the human pass through. 

tion framework. Fig. 6 show the effect of tune the effort between a human and a 

robot for a share navigation task. 

During a navigation task, if the human decides to move on other path than one 

suggest by the robot (e.g., choose to pas by another side of the robot), the 

robot quickly adapts it trajectory. In situation where robot have enough space to 

move well advance in time, the robot proactively chooses a path that be both legible 

and comfortable for the human counterpart. 

5 CONCLUSION AND FUTUREWORK 

Proposed cooperative planning scheme have several advantage over state-of-the-art 

human-aware planning schemes. Our robot do not stay purely reactive but now 

it can also propose a path for the human assume she will consider the propose 



16 Harmish Khambhaita and Rachid Alami 

(a) (b) (c) 

Fig. 6: Balancing the share effort between human and robot. (a) Human and robot 

share equal effort. (b) The robot share most of the effort and move far away from 

predict human path. (c) Although never use in real world situations, it be possible 

to design a rude behavior of the robot where it expect human to make more effort 

for avoid a collision. 

solution that benefit both agents. This be crucial especially in confine spaces, such 

a corridor where two agent can navigate only in side-by-side configuration. 

This approach open up a new avenue for quickly test and compare different 

social constraints. We plan to define new social constraint that will enable further in- 

teractive motion scenario such a actively approach a person, queue behavior 

in long hallway like environment with multiple humans, guide a group of peo- 

ple, and more. We be prepare for a series of experiment and a user study which 

compare the cooperative planner against other proactive planning approaches. 

The computational cost of the cooperative planner increase with the number 

of human surround the robot a well a number and type of social constraint 

use for optimization. This be a limit factor for use the cooperative planner in 

crowd situation. We plan to improve over this limitation by parallelly evaluate 

the error function and utilize GPU capability provide by state-of-the-art sparse 

matrix solvers. 

Acknowledgements This work be support by the European Union’s Horizon 2020 research and 

innovation programme under grant agreement No. 688147 (MuMMER project). 

References 

1. N. Sebanz, H. Bekkering, and G. Knoblich, “Joint action: Bodies and mind move together,” 

Trends in Cognitive Sciences, vol. 10, no. 2, pp. 70 – 76, 2006. 

2. S. Lemaignan, M. Warnier, E. A. Sisbot, A. Clodic, and R. Alami, “Artificial cognition for 

social human–robot interaction: An implementation,” Artificial Intelligence, vol. 247, pp. 45 

– 69, 2017. 

3. J. Waldhart, M. Gharbi, and R. Alami, “Planning handover involve human and robot in 

constrain environment,” in Proc. IEEE/RSJ International Conference on Intelligent Robots 



Viewing Robot Navigation in Human Environment a a Cooperative Activity 17 

and Systems (IROS), September 28 - October 2, 2015, pp. 6473–6478. 

4. J. Shah, J. Wiken, B. C. Williams, and C. Breazeal, “Improved Human-Robot Team Perfor- 

mance Using Chaski, A Human-Inspired Plan Execution System,” in Proc. ACM/IEEE Inter- 

national Conference on Human-Robot Interaction (HRI), March 6-9, 2011, pp. 29–36. 

5. G. Knoblich, S. Butterfill, and N. Sebanz, “Psychological Research on Joint Action,” Psychol- 

ogy of Learning and Motivation, vol. 54, pp. 59 – 101, 2011. 

6. E. Pacherie, “The Phenomenology of Joint Action: Self-Agency Vs. Joint-Agency,” in Joint 

Attention: New Developments, S. Axel, Ed., 2012. 

7. A. Clodic, R. Alami, and R. Chatila, “Key Elements for Human-Robot Joint Action,” in So- 

ciable Robots and the Future of Social Relations, 2014, vol. 273, pp. 23 – 33. 

8. M. Tomasello, M. Carpenter, J. Call, T. Behne, and H. Moll, “Understanding and share 

intentions: The origin of cultural cognition,” Behavoral and Brain Sciences, vol. 28, no. 5, 

pp. 675–691, 2005. 

9. M. E. Bratman, “Shared Intention,” Ethics, vol. 104, no. 1, pp. 97–113, 1993. 

10. H. H. Clark, R. Schreuder, and S. Buttrick, “Common ground at the understand of demon- 

strative reference,” Journal of Verbal Learning and Verbal Behavior, vol. 22, no. 2, pp. 245 – 

258, 1983. 

11. E. T. Hall, The Hidden Dimension: Man’s Use of Space in Public and Private, 1966. 

12. J. A. Rios Martinez, A. Spalanzani, and C. Laugier, “From Proxemics Theory to Socially- 

Aware Navigation: A Survey,” International Journal of Social Robotics, vol. 7, no. 2, pp. 

137–153, 2014. 

13. T. Kruse, A. K. Pandey, R. Alami, and A. Kirsch, “Human-aware robot navigation: A survey,” 

Robotics and Autonomous Systems, vol. 61, no. 12, pp. 1726 – 1743, 2013. 

14. E. A. Sisbot, L. F. Marin-Urias, R. Alami, and T. Siméon, “A Human Aware Mobile Robot 

Motion Planner,” IEEE Transactions on Robotics, vol. 23, no. 5, pp. 874–883, 2007. 

15. T. Kruse, A. Kirsch, H. Khambhaita, and R. Alami, “Evaluating Directional Cost Models 

in Navigation,” in Proc. ACM/IEEE International Conference on Human-Robot Interaction 

(HRI), 2014, pp. 350–357. 

16. T. Kruse, P. Basili, S. Glasauer, and A. Kirsch, “Legible Robot Navigation in the Proximity 

of Moving Humans,” in Proc. IEEE Workshop on Advanced Robotics and Its Social Impacts 

(ARSO), 2012, pp. 83–88. 

17. M. Kuderer, H. Kretzschmar, C. Sprunk, and W. Burgard, “Feature-Based Prediction of Tra- 

jectories for Socially Compliant Navigation,” in Proc. Robotics: Science and Systems (RSS), 

July 9-13, 2012. 

18. G. Ferrer and A. Sanfeliu, “Proactive Kinodynamic Planning use the Extended Social Force 

Model and Human Motion Prediction in Urban Environments,” in Proc. IEEE/RSJ Interna- 

tional Conference on Intelligent Robots and Systems (IROS), 2014, pp. 1730–1735. 

19. D. Helbing and P. Molnár, “Social force model for pedestrian dynamics,” Physical Review E, 

vol. 51, no. 5, pp. 4282–4286, 1995. 

20. S. Alili, R. Alami, and V. Montreuil, “A Task Planner for an Autonomous Social Robot,” in 

Distributed Autonomous Robotic Systems 8, H. Asama, H. Kurokawa, J. Ota, and K. Sekiyama, 

Eds., 2009, pp. 335–344. 

21. R. Lallement, L. de Silva, and R. Alami, “HATP: An HTN Planner for Robotics,” CoRR, vol. 

abs/1405.5345, 2014. 

22. J. Mainprice, M. Gharbi, T. Siméon, and R. Alami, “Sharing effort in planning human-robot 

handover tasks,” in Proc. IEEE International Symposium on Robot and Human Interactive 

Communication (RO-MAN), 2012, pp. 764–770. 

23. G. Ferrer and A. Sanfeliu, “Multi-Objective Cost-to-Go Functions on Robot Navigation in 

Dynamic Environments,” in Proc. IEEE/RSJ International Conference on Intelligent Robots 

and Systems (IROS), 2015, pp. 3824–3829. 

24. A. Bordallo, F. Previtali, N. Nardelli, and S. Ramamoorthy, “Counterfactual reason about 

intent for interactive navigation in dynamic environments,” in Proc. IEEE/RSJ International 

Conference on Intelligent Robots and Systems (IROS), September 28 - October 2, 2015, pp. 

2943–2950. 



18 Harmish Khambhaita and Rachid Alami 

25. A. Nagariya, B. Gopalakrishnan, A. K. Singh, K. Gupta, and K. M. Krishna, “Mobile robot 

navigation amidst human with intent and uncertainties: A time scale collision cone ap- 

proach,” in Proc. IEEE Conference on Decision and Control (CDC), December 15-18, 2015, 

pp. 2773–2779. 

26. S. Quinlan and O. Khatib, “Elastic Bands: Connecting Path Planning and Control,” in Proc. 

IEEE International Conference on Robotics and Automation (ICRA), 1993, pp. 802–807. 

27. M. Khatib, H. Jaouni, R. Chatila, and J.-P. Laumond, “Dynamic path modification for car- 

like nonholonomic mobile robots,” in Proc. IEEE International Conference on Robotics and 

Automation (ICRA), April 20-25, 1997, pp. 2920–2925. 

28. C. Rösmann, W. Feiten, T. Woesch, F. Hoffmann, and T. Bertram, “Trajectory modifica- 

tion consider dynamic constraint of autonomous robots,” in Proc. German Conference 

on Robotics (ROBOTIK), 2012, pp. 1–6. 

29. H. Khambhaita and R. Alami, “A Human-Robot Cooperative Navigation Planner,” in Proc. the 

Companion of the ACM/IEEE International Conference on Human-Robot Interaction (HRI), 

2017, pp. 161–162. 

30. C. Rösmann, W. Feiten, T. Wösch, F. Hoffmann, and T. Bertram, “Efficient Trajectory Opti- 

mization use a Sparse Model,” in Proc. European Conference on Mobile Robots (ECMR), 

September 25-27, 2013, pp. 138–143. 

31. R. W. Bohannon, “Comfortable and maximum walk speed of adult age 20—79 years: 

Reference value and determinants,” Age and Ageing, vol. 26, no. 1, pp. 15–19, 1997. 

32. R. Kümmerle, G. Grisetti, H. Strasdat, K. Konolige, and W. Burgard, “G2o: A General Frame- 

work for Graph Optimization,” in Proc. IEEE International Conference on Robotics and Au- 

tomation (ICRA), 2011, pp. 3607–3613. 

33. T. Davis, Direct Methods for Sparse Linear Systems, 2006. 

34. I. Karamouzas, B. Skinner, and S. J. Guy, “Universal Power Law Governing Pedestrian Inter- 

actions,” Physical Review Letters, vol. 113, no. 23, p. 238701, 2014. 

35. E. Marder-Eppstein, “move base: A ROS package that let you move a robot to desire 

position use the navigation stack.” 

36. D. V. Lu, D. Hershberger, and W. D. Smart, “Layered Costmaps for Context-Sensitive Naviga- 

tion,” in Proc. IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 

September 14-18, 2014, pp. 709–715. 

37. P. Fiorini and Z. Shiller, “Motion Planning in Dynamic Environments Using Velocity Obsta- 

cles,” The International Journal of Robotics Research, vol. 17, no. 7, pp. 760–772, 1998. 

38. H. Khambhaita and R. Alami, “Assessing the Social Criteria for Human-Robot Collaborative 

Navigation: A Comparison of Human-Aware Navigation Planners,” in Proc. IEEE Interna- 

tional Symposium on Robot and Human Interactive Communication (RO-MAN), 2017. 

39. H. Khambhaita, J. Rios-Martinez, and R. Alami, “Head-Body Motion Coordination for Hu- 

man Aware Robot Navigation,” in Proc. International Workshop on Human-Friendlly Robotics 

(HFR), September 29-30, 2016. 


