






















































CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays with Deep Learning 


CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays 
with Deep Learning 

Pranav Rajpurkar * 1 Jeremy Irvin * 1 Kaylie Zhu 1 Brandon Yang 1 Hershel Mehta 1 

Tony Duan 1 Daisy Ding 1 Aarti Bagul 1 Curtis Langlotz 2 Katie Shpanskaya 2 

Matthew P. Lungren 2 Andrew Y. Ng 1 

Abstract 

We develop an algorithm that can detect 
pneumonia from chest X-rays at a level ex- 
ceeding practice radiologists. Our algo- 
rithm, CheXNet, be a 121-layer convolutional 
neural network train on ChestX-ray14, cur- 
rently the large publicly available chest X- 
ray dataset, contain over 100,000 frontal- 
view X-ray image with 14 diseases. Four 
practice academic radiologist annotate a 
test set, on which we compare the perfor- 
mance of CheXNet to that of radiologists. 
We find that CheXNet exceeds average radi- 
ologist performance on pneumonia detection 
on both sensitivity and specificity. We extend 
CheXNet to detect all 14 disease in ChestX- 
ray14 and achieve state of the art result on 
all 14 diseases. 

1. Introduction 

More than 1 million adult be hospitalize with pneu- 
monia and around 50,000 die from the disease every 
year in the US alone (CDC, 2017). Chest X-rays 
be currently the best available method for diagnose 
pneumonia (WHO, 2001), play a crucial role in clin- 
ical care (Franquet, 2001) and epidemiological study 
(Cherian et al., 2005). However, detect pneumo- 
nia in chest X-rays be a challenge task that relies on 
the availability of expert radiologists. In this work, we 
present a model that can automatically detect pneu- 
monia from chest X-rays at a level exceed practice 

*Equal contribution 1Stanford University, Com- 
puter Science Department 2Stanford University, 
Medical School. Correspondence to: Pranav Ra- 
jpurkar <pranavsr@cs.stanford.edu>, Jeremy Irvin 
<jirvin16@cs.stanford.edu>. 

Project website at https://stanfordmlgroup. 
github.io/projects/chexnet 

Output 
Pneumonia Positive (85%) 

Input 
Chest X-Ray Image 

CheXNet 
121-layer CNN 

Figure 1. ChexNet be a 121-layer convolutional neural net- 
work that take a chest X-ray image a input, and output 
the probability of a pathology. On this example, CheXnet 
correctly detects pneumonia and also localizes area in the 
image most indicative of the pathology. 

radiologists. 

Our model, ChexNet (shown in Figure 1), be a 121- 
layer convolutional neural network that input a chest 
X-ray image and output the probability of pneumonia 
along with a heatmap localize the area of the im- 
age most indicative of pneumonia. We train CheXNet 
on the recently release ChestX-ray14 dataset (Wang 

ar 
X 

iv 
:1 

71 
1. 

05 
22 

5v 
1 

[ 
c 

.C 
V 

] 
1 

4 
N 

ov 
2 

01 
7 

https://stanfordmlgroup.github.io/projects/chexnet 
https://stanfordmlgroup.github.io/projects/chexnet 


CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays with Deep Learning 

0.0 0.2 0.4 0.6 0.8 1.0 
1 - Specificity 

0.0 

0.2 

0.4 

0.6 

0.8 

1.0 

Se 
n 

iti 
vi 

ty 

Figure 2. CheXNet outperforms the average of the radiologist at pneuomonia detection use X-ray images. ChexNet 
be test against 4 practice radiologist on sensitivity (which measure the proportion of positive that be correctly 
identify a such) and specificity (which measure the proportion of negative that be correctly identify a such). A 
single radiologist’s performance be represent by an orange marker, while the average be represent by green. CheXNet 
output the probability of detect pneumonia in a Chest X-ray, and the blue curve be generate by vary the threshold 
use for the classification boundary. The sensitivity-specificity point for each radiologist and for the average lie below the 
blue curve, signify that CheXNet be able to detect pneumonia at a level match or exceed radiologists. 

et al., 2017), which contains 112,120 frontal-view chest 
X-ray image individually label with up to 14 differ- 
ent thoracic diseases, include pneumonia. We use 
dense connection (Huang et al., 2016) and batch nor- 
malization (Ioffe & Szegedy, 2015) to make the opti- 
mization of such a deep network tractable. 

Detecting pneumonia in chest radiography can be diffi- 
cult for radiologists. The appearance of pneumonia in 
X-ray image be often vague, can overlap with other di- 
agnoses, and can mimic many other benign abnormal- 
ities. These discrepancy cause considerable variabil- 
ity among radiologist in the diagnosis of pneumonia 
(Neuman et al., 2012; Davies et al., 1996; Hopstaken 
et al., 2004). To estimate radiologist performance, we 
collect annotation from four practice academic radi- 
ologists on a subset of 420 image from ChestX-ray14. 
On these 420 images, we measure performance of in- 
dividual radiologist use the majority vote of other 
radiologist a ground truth, and similarly measure 
model performance. 

We find that the model exceeds the average radiolo- 
gist performance at the pneumonia detection task on 
both sensitivity and specificity. To compare CheXNet 
against previous work use ChestX-ray14, we make 
simple modification to ChexNet to detect all 14 dis- 

eas in ChestX-ray14, and find that we outperform 
best publish result on all 14 diseases. Automated 
detection of disease from chest X-rays at the level of 
expert radiologist would not only have tremendous 
benefit in clinical settings, it would be invaluable in 
delivery of health care to population with inadequate 
access to diagnostic image specialists. 

2. CheXNet 

2.1. Problem Formulation 

The pneumonia detection task be a binary classification 
problem, where the input be a frontal frontal-view chest 
X-ray image X and the output be a binary label t ∈ 
{0, 1} indicate the absence or presence of pneumonia 
respectively. For a single example in the training set, 
we optimize the binary cross entropy loss 

L(X, t) = −t log p(T = 1|X)− (1− t) log p(T = 0|X) 

where p(T = i|X) be the probability that the network 
assigns to the label i. 

2.2. Model Architecture and Training 

CheXNet be a 121-layer Dense Convolutional Net- 
work (DenseNet) (Huang et al., 2016) train on the 



CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays with Deep Learning 

ChestX-ray 14 dataset. DenseNets improve flow of in- 
formation and gradient through the network, make 
the optimization of very deep network tractable. We 
replace the final fully connect layer with one that 
have a single output, after which we apply a sigmoid 
nonlinearity, output the probability that the im- 
age contains pneumonia. 

The weight of the network be randomly initialize 
and train end-to-end use Adam with standard pa- 
rameters (β1 = 0.9 and β2 = 0.999) (Kingma & Ba, 
2014). We train the model use minibatches of size 
16, where we oversample the minority (positive) class 
(Buda et al., 2017). We use an initial learn rate of 
0.01 that be decayed by a factor of 10 each time the 
validation loss plateau after an epoch, and pick the 
model with the low validation loss. 

3. Data 

3.1. Training 

We use the ChestX-ray14 dataset release by Wang 
et al. (2017) which contains 112,120 frontal-view X-ray 
image of 30,805 unique patients. Wang et al. (2017) 
annotate each image with up to 14 different thoracic 
pathology label use automatic extraction method 
on radiology reports. We label image that have pneu- 
monia a one of the annotate pathology a positive 
example and label all other image a negative exam- 
ples for the pneumonia detection task. We randomly 
split the entire dataset into 80% training, and 20% 
validation. 

Before inputting the image into the network, we 
downscale the image to 224×224 and normalize base 
on the mean and standard deviation of image in the 
ImageNet training set. We also augment the training 
data with random horizontal flipping. 

3.2. Test 

We collect a test set of 420 frontal chest X-rays. An- 
notation be obtain independently from four prac- 
ticing radiologist at Stanford University, who be 
ask to label all 14 pathology in Wang et al. (2017). 
The radiologist have 4, 7, 25, and 28 year of experi- 
ence, and one of the radiologist be a sub-specialty fel- 
lowship train thoracic radiologist. Radiologists do 
not have access to any patient information or knowl- 
edge of disease prevalence in the data. Labels be 
enter into a standardize data entry program. 

4. CheXNet vs. Radiologist 
Performance 

We ass radiologist performance on the test set on 
the pneumonia detection task. Recall that each of the 
image in test420 have a ground truth label from 4 prac- 
ticing radiologists. We evaluate the performance of an 
individual radiologist by use the majority vote of 
the other 3 radiologist a ground truth. Similarly, we 
evaluate CheXNet use the majority vote of 3 of 4 
radiologists, repeat four time to cover all group of 
3. 

We compare CheXNet against radiologist on the Re- 
ceiver Operating Characteristic (ROC) curve, which 
plot model sensitivity against 1 - specificity. Figure 2 
illustrates the model ROC curve a well a the four 
radiologist and average radiologist operating points: a 
single radiologist’s performance be represent by an 
orange marker, while the average be represent by 
green. CheXNet output the probability of detect- 
ing pneumonia in a Chest X-ray, and the ROC curve 
be generate by vary the threshold use for the 
classification boundary. CheXNet have an AUROC of 
0.788. The sensitivity-specificity point for each radi- 
ologist and for the average lie below the ROC curve, 
signify that CheXNet be able to detect pneumonia 
at a level match or exceed radiologists. 

We identify two limitation of this setup. First, nei- 
ther the model nor the radiologist be permit 
to use prior examination or patient history, which 
have be show to decrease radiologist performance 
(Berbaum et al., 1985; Potchen et al., 1979). Second, 
only frontal radiograph be present to the radi- 
ologists and model during diagnosis, but it have be 
show that up to 15% of accurate diagnosis require the 
lateral view (Raoof et al., 2012). We thus expect that 
this setup provide a conservative estimate of human 
radiologist performance. 

5. ChexNet vs. Previous State of the 
Art on the ChestX-ray14 Dataset 

We extend the algorithm to classify multiple thoracic 
pathology by make three changes. First, instead of 
output one binary label, ChexNet output a vec- 
tor t of binary label indicate the absence or presence 
of each of the follow 14 pathology classes: Atelec- 
tasis, Cardiomegaly, Consolidation, Edema, Effusion, 
Emphysema, Fibrosis, Hernia, Infiltration, Mass, Nod- 
ule, Pleural Thickening, Pneumonia, and Pneumotho- 
rax. Second, we replace the final fully connect layer 
in CheXNet with a fully connect layer produce a 
14-dimensional output, after which we apply an ele- 



CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays with Deep Learning 

Pathology Wang et al. (2017) Yao et al. (2017) CheXNet (ours) 

Atelectasis 0.716 0.772 0.8209 
Cardiomegaly 0.807 0.904 0.9048 
Effusion 0.784 0.859 0.8831 
Infiltration 0.609 0.695 0.7204 
Mass 0.706 0.792 0.8618 
Nodule 0.671 0.717 0.7766 
Pneumonia 0.633 0.713 0.7632 
Pneumothorax 0.806 0.841 0.8932 
Consolidation 0.708 0.788 0.7939 
Edema 0.835 0.882 0.8932 
Emphysema 0.815 0.829 0.9260 
Fibrosis 0.769 0.767 0.8044 
Pleural Thickening 0.708 0.765 0.8138 
Hernia 0.767 0.914 0.9387 

Table 1. CheXNet outperforms the best publish result on all 14 pathology in the ChestX-ray14 dataset. In detect 
Mass, Nodule, Pneumonia, Pneumothorax, and Emphysema, CheXNet have a margin of >0.05 AUROC over previous state 
of the art results. 

mentwise sigmoid nonlinearity. The final output be the 
predict probability of the presence of each pathology 
class. Third, we modify the loss function to optimize 
the sum of binary cross entropy loss 

L(X, t) = 

14∑ 
c=1 

[−tc log p(Tc = 1|X) 

−(1− tc) log p(Tc = 0|X)], 

where p(Tc = 1|X) be the predict probability that 
the image contains the pathology c and p(Tc = 0|X) 
be the predict probability that the image do not 
contain the pathology c. 

Following previous work on ChestX-ray14 (Wang 
et al., 2017; Yao et al., 2017), we randomly split the 
dataset into training (70%), validation (10%), and test 
(20%) sets; the choice of split have be show to have 
insignificant effect on performance. We compare the 
per-class Area Under the ROC Curve (AUROC) of the 
model against the previous state of the art held by Yao 
et al. (2017) on 13 class and Wang et al. (2017) on 
the remain 1 class. 

We find that CheXNet achieves state of the art result 
on all 14 pathology classes. Table 1 illustrates the 
per-class AUROC comparison on the test set. On At- 
electasis, Mass, Nodule, Pneumonia, and Emphysema, 
we outperform previous state of the art considerably 
(> 0.05 increase in AUROC). 

6. Model Interpretation 

To interpret the network predictions, we also produce 
heatmaps to visualize the area of the image most in- 
dicative of the disease use class activation mapping 
(CAMs) (Zhou et al., 2016). To generate the CAMs, 
we feed an image into the fully train network and 
extract the feature map that be output by the final 
convolutional layer. Let fk be the kth feature map and 
let wc,k be the weight in the final classification layer 
for feature map k lead to pathology c. We obtain 
a map Mc of the most salient feature use in classi- 
fying the image a have pathology c by take the 
weight sum of the feature map use their associ- 
ated weights. Formally, 

Mc = 
∑ 
k 

wc,kfk. 

We identify the most important feature use by the 
model in it prediction of the pathology c by upscal- 
ing the map Mc to the dimension of the image and 
overlay the image. 

Figure 3 show several example of CAMs on the pneu- 
monia detection task a well a the 14-class pathology 
classification task. 

7. Related Work 

Recent advancement in deep learn and large 
datasets have enable algorithm to surpass the per- 
formance of medical professional in a wide variety of 
medical image tasks, include diabetic retinopathy 



CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays with Deep Learning 

(a) Patient with multifocal com- 
munity acquire pneumonia. The 
model correctly detects the airspace 
disease in the left low and right up- 
per lobe to arrive at the pneumonia 
diagnosis. 

(b) Patient with a left lung nodule. 
The model identifies the left low 
lobe lung nodule and correctly clas- 
sifies the pathology. 

(c) Patient with primary lung ma- 
lignancy and two large masses, one 
in the left low lobe and one in 
the right upper lobe adjacent to the 
mediastinum. The model correctly 
identifies both mass in the X-ray. 

(d) Patient with a right-sided pneu- 
mothroax and chest tube. The 
model detects the abnormal lung 
to correctly predict the presence of 
pneumothorax (collapsed lung). 

(e) Patient with a large right pleural 
effusion (fluid in the pleural space). 
The model correctly label the effu- 
sion and focus on the right low 
chest. 

(f) Patient with congestive heart 
failure and cardiomegaly (enlarged 
heart). The model correctly identi- 
fies the enlarge cardiac silhouette. 

Figure 3. ChexNet localizes pathology it identifies use Class Activation Maps, which highlight the area of the X-ray 
that be most important for make a particular pathology classification. 

detection (Gulshan et al., 2016), skin cancer classifica- 
tion (Esteva et al., 2017), arrhythmia detection (Ra- 
jpurkar et al., 2017), and hemorrhage identification 
(Grewal et al., 2017). 

Automated diagnosis from chest radiograph have re- 
ceived increase attention with algorithm for pul- 
monary tuberculosis classification (Lakhani & Sun- 
daram, 2017) and lung nodule detection (Huang et al., 
2017). Islam et al. (2017) study the performance 
of various convolutional architecture on different ab- 
normality use the publicly available OpenI dataset 
(Demner-Fushman et al., 2015). Wang et al. (2017) 
release ChestX-ray-14, an order of magnitude large 
than previous datasets of it kind, and also bench- 
marked different convolutional neural network archi- 

tectures pre-trained on ImageNet. Recently Yao et al. 
(2017) exploit statistical dependency between la- 
bel in order make more accurate predictions, outper- 
form Wang et al. (2017) on 13 of 14 classes. 

8. Conclusion 

Pneumonia account for a significant proportion of 
patient morbidity and mortality (Gonçalves-Pereira 
et al., 2013). Early diagnosis and treatment of pneu- 
monia be critical to prevent complication include 
death (Aydogdu et al., 2010). With approximately 2 
billion procedure per year, chest X-rays be the most 
common image examination tool use in practice, 
critical for screening, diagnosis, and management of a 



CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays with Deep Learning 

variety of disease include pneumonia (Raoof et al., 
2012). However, two third of the global population 
lack access to radiology diagnostics, accord to an 
estimate by the World Health Organization (Mollura 
et al., 2010). There be a shortage of expert who can in- 
terpret X-rays, even when image equipment be avail- 
able, lead to increase mortality from treatable dis- 
eas (Kesselman et al., 2016). 

We develop an algorithm which exceeds the perfor- 
mance of radiologist in detect pneumonia from 
frontal-view chest X-ray images. We also show that 
a simple extension of our algorithm to detect multi- 
ple disease outperforms previous state of the art on 
ChestX-ray14, the large publicly available chest X- 
ray dataset. With automation at the level of experts, 
we hope that this technology can improve healthcare 
delivery and increase access to medical image ex- 
pertise in part of the world where access to skilled 
radiologist be limited. 

9. Acknowledgements 

We would like to acknowledge the Stanford Center for 
Artificial Intelligence in Medicine and Imaging for clin- 
ical dataset infrastructure support (AIMI.stanford. 
edu). 

References 

Aydogdu, M, Ozyilmaz, E, Aksoy, Handan, Gursel, 
G, and Ekim, Numan. Mortality prediction in 
community-acquired pneumonia require mechan- 
ical ventilation; value of pneumonia and intensive 
care unit severity scores. Tuberk Toraks, 58(1):25– 
34, 2010. 

Berbaum, K, Franken Jr, EA, and Smith, WL. The 
effect of comparison film upon resident interpre- 
tation of pediatric chest radiographs. Investigative 
radiology, 20(2):124–128, 1985. 

Buda, Mateusz, Maki, Atsuto, and Mazurowski, Ma- 
ciej A. A systematic study of the class imbalance 
problem in convolutional neural networks. arXiv 
preprint arXiv:1710.05381, 2017. 

CDC, 2017. URL https://www.cdc.gov/features/ 
pneumonia/index.html. 

Cherian, Thomas, Mulholland, E Kim, Carlin, John B, 
Ostensen, Harald, Amin, Ruhul, Campo, Mar- 
garet de, Greenberg, David, Lagos, Rosanna, 
Lucero, Marilla, Madhi, Shabir A, et al. Standard- 
ized interpretation of paediatric chest radiograph 
for the diagnosis of pneumonia in epidemiological 

studies. Bulletin of the World Health Organization, 
83(5):353–359, 2005. 

Davies, H Dele, Wang, Elaine E-l, Manson, David, 
Babyn, Paul, and Shuckett, Bruce. Reliability of 
the chest radiograph in the diagnosis of low res- 
piratory infection in young children. The Pediatric 
infectious disease journal, 15(7):600–604, 1996. 

Demner-Fushman, Dina, Kohli, Marc D, Rosenman, 
Marc B, Shooshan, Sonya E, Rodriguez, Laritza, 
Antani, Sameer, Thoma, George R, and McDonald, 
Clement J. Preparing a collection of radiology ex- 
aminations for distribution and retrieval. Journal of 
the American Medical Informatics Association, 23 
(2):304–310, 2015. 

Esteva, Andre, Kuprel, Brett, Novoa, Roberto A, 
Ko, Justin, Swetter, Susan M, Blau, Helen M, and 
Thrun, Sebastian. Dermatologist-level classification 
of skin cancer with deep neural networks. Nature, 
542(7639):115–118, 2017. 

Franquet, T. Imaging of pneumonia: trend and algo- 
rithms. European Respiratory Journal, 18(1):196– 
208, 2001. 

Gonçalves-Pereira, João, Conceição, Catarina, and 
Póvoa, Pedro. Community-acquired pneumo- 
nia: identification and evaluation of nonresponders. 
Therapeutic advance in infectious disease, 1(1):5– 
17, 2013. 

Grewal, Monika, Srivastava, Muktabh Mayank, Ku- 
mar, Pulkit, and Varadarajan, Srikrishna. Radnet: 
Radiologist level accuracy use deep learn for 
hemorrhage detection in ct scans. arXiv preprint 
arXiv:1710.04934, 2017. 

Gulshan, Varun, Peng, Lily, Coram, Marc, Stumpe, 
Martin C, Wu, Derek, Narayanaswamy, Arunacha- 
lam, Venugopalan, Subhashini, Widner, Kasumi, 
Madams, Tom, Cuadros, Jorge, et al. Development 
and validation of a deep learn algorithm for de- 
tection of diabetic retinopathy in retinal fundus pho- 
tographs. Jama, 316(22):2402–2410, 2016. 

Hopstaken, RM, Witbraad, T, Van Engelshoven, 
JMA, and Dinant, GJ. Inter-observer variation in 
the interpretation of chest radiograph for pneumo- 
nia in community-acquired low respiratory tract 
infections. Clinical radiology, 59(8):743–752, 2004. 

Huang, Gao, Liu, Zhuang, Weinberger, Kilian Q, and 
van der Maaten, Laurens. Densely connect convo- 
lutional networks. arXiv preprint arXiv:1608.06993, 
2016. 

AIMI.stanford.edu 
AIMI.stanford.edu 
https://www.cdc.gov/features/pneumonia/index.html 
https://www.cdc.gov/features/pneumonia/index.html 


CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays with Deep Learning 

Huang, Peng, Park, Seyoun, Yan, Rongkai, Lee, 
Junghoon, Chu, Linda C, Lin, Cheng T, Hussien, 
Amira, Rathmell, Joshua, Thomas, Brett, Chen, 
Chen, et al. Added value of computer-aided ct image 
feature for early lung cancer diagnosis with small 
pulmonary nodules: A match case-control study. 
Radiology, pp. 162725, 2017. 

Ioffe, Sergey and Szegedy, Christian. Batch normaliza- 
tion: Accelerating deep network training by reduc- 
ing internal covariate shift. In International Confer- 
ence on Machine Learning, pp. 448–456, 2015. 

Islam, Mohammad Tariqul, Aowal, Md Abdul, Min- 
haz, Ahmed Tahseen, and Ashraf, Khalid. Ab- 
normality detection and localization in chest x-ray 
use deep convolutional neural networks. arXiv 
preprint arXiv:1705.09850, 2017. 

Kesselman, Andrew, Soroosh, Garshasb, Mollura, 
Daniel J, and Group, RAD-AID Conference Writ- 
ing. 2015 rad-aid conference on international radi- 
ology for develop countries: The evolve global 
radiology landscape. Journal of the American Col- 
lege of Radiology, 13(9):1139–1144, 2016. 

Kingma, Diederik and Ba, Jimmy. Adam: A 
method for stochastic optimization. arXiv preprint 
arXiv:1412.6980, 2014. 

Lakhani, Paras and Sundaram, Baskaran. Deep learn- 
ing at chest radiography: Automated classification 
of pulmonary tuberculosis by use convolutional 
neural networks. Radiology, pp. 162326, 2017. 

Mollura, Daniel J, Azene, Ezana M, Starikovsky, 
Anna, Thelwell, Aduke, Iosifescu, Sarah, Kimble, 
Cary, Polin, Ann, Garra, Brian S, DeStigter, Kris- 
ten K, Short, Brad, et al. White paper report of 
the rad-aid conference on international radiology for 
develop countries: identify challenges, oppor- 
tunities, and strategy for image service in the 
develop world. Journal of the American College 
of Radiology, 7(7):495–500, 2010. 

Neuman, Mark I, Lee, Edward Y, Bixby, Sarah, 
Diperna, Stephanie, Hellinger, Jeffrey, Markowitz, 
Richard, Servaes, Sabah, Monuteaux, Michael C, 
and Shah, Samir S. Variability in the interpretation 
of chest radiograph for the diagnosis of pneumo- 
nia in children. Journal of hospital medicine, 7(4): 
294–298, 2012. 

Potchen, EJ, Gard, JW, Lazar, P, Lahaie, P, and 
Andary, M. Effect of clinical history data on chest 
film interpretation-direction or distraction. In Inves- 
tigative Radiology, volume 14, pp. 404–404, 1979. 

Rajpurkar, Pranav, Hannun, Awni Y, Haghpanahi, 
Masoumeh, Bourn, Codie, and Ng, Andrew Y. 
Cardiologist-level arrhythmia detection with con- 
volutional neural networks. arXiv preprint 
arXiv:1707.01836, 2017. 

Raoof, Suhail, Feigin, David, Sung, Arthur, 
Raoof, Sabiha, Irugulpati, Lavanya, and Rosenow, 
Edward C. Interpretation of plain chest 
roentgenogram. CHEST Journal, 141(2):545–558, 
2012. 

Wang, Xiaosong, Peng, Yifan, Lu, Le, Lu, Zhiyong, 
Bagheri, Mohammadhadi, and Summers, Ronald M. 
Chestx-ray8: Hospital-scale chest x-ray database 
and benchmark on weakly-supervised classification 
and localization of common thorax diseases. arXiv 
preprint arXiv:1705.02315, 2017. 

WHO. Standardization of interpretation of chest ra- 
diographs for the diagnosis of pneumonia in chil- 
dren. 2001. 

Yao, Li, Poblenz, Eric, Dagunts, Dmitry, Covington, 
Ben, Bernard, Devon, and Lyman, Kevin. Learning 
to diagnose from scratch by exploit dependen- 
cies among labels. arXiv preprint arXiv:1710.10501, 
2017. 

Zhou, Bolei, Khosla, Aditya, Lapedriza, Agata, Oliva, 
Aude, and Torralba, Antonio. Learning deep fea- 
tures for discriminative localization. In Proceedings 
of the IEEE Conference on Computer Vision and 
Pattern Recognition, pp. 2921–2929, 2016. 


