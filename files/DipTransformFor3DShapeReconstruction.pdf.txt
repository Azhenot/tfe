




















































Dip Transform for 3D Shape Reconstruction


Dip Transform for 3D Shape Reconstruction

KFIR ABERMAN∗, AICFVE Beijing Film Academy, Tel-Aviv University
OREN KATZIR*, AICFVE Beijing Film Academy, Tel-Aviv University
QIANG ZHOU, Shandong University
ZEGANG LUO, Shandong University
ANDREI SHARF, Ben-Gurion University of the NEGEV, AICFVE Beijing Film Academy
CHEN GREIF, University of British Colombia
BAOQUAN CHEN†, Shandong University
DANIEL COHEN-OR, Tel-Aviv University

Fig. 1. 3D scanning using a dip scanner. The object is dipped using a robot arm in a bath of water (le), acquiring a dip transform. The quality of the
reconstruction is improving as the number of dipping orientations is increased (from le to right).

e paper presents a novel three-dimensional shape acquisition and re-
construction method based on the well-known Archimedes equality between
uid displacement and the submerged volume. By repeatedly dipping a shape
in liquid in dierent orientations and measuring its volume displacement,
we generate the dip transform: a novel volumetric shape representation that
characterizes the object’s surface. e key feature of our method is that it
employs uid displacements as the shape sensor. Unlike optical sensors, the
liquid has no line-of-sight requirements, it penetrates cavities and hidden
parts of the object, as well as transparent and glossy materials, thus bypass-
ing all visibility and optical limitations of conventional scanning devices.
Our new scanning approach is implemented using a dipping robot arm
and a bath of water, via which it measures the water elevation. We show
results of reconstructing complex 3D shapes and evaluate the quality of the
reconstruction with respect to the number of dips.

CCS Concepts: •Computing methodologies→ Shape modeling;

Additional Key Words and Phrases: shape reconstruction, volume, data
acquisition

∗Joint rst authors.
†Corresponding author.

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for prot or commercial advantage and that copies bear this notice and the full citation
on the rst page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permied. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specic permission and/or a
fee. Request permissions from permissions@acm.org.
© 2017 ACM. 0730-0301/2017/7-ART79 $15.00
DOI: hp://dx.doi.org/10.1145/3072959.3073693

ACM Reference format:
Kr Aberman, Oren Katzir*, Qiang Zhou, Zegang Luo, Andrei Sharf, Chen
Greif, Baoquan Chen, and Daniel Cohen-Or. 2017. Dip Transform for 3D
Shape Reconstruction. ACM Trans. Graph. 36, 4, Article 79 (July 2017),
11 pages.
DOI: hp://dx.doi.org/10.1145/3072959.3073693

1 INTRODUCTION
3D shape acquisition and reconstruction methods are based on opti-
cal devices, most commonly laser scanners, that sample the visible
shape surface. ese scanners yield point clouds which are oen
noisy and incomplete. Many techniques have been developed to
amend such point clouds, denoise them, and complete their missing
parts using various priors [Berger et al. 2014]. All these surface-
based reconstruction techniques assume a reasonable sampling rate
of the surface. Notably, these techniques fall short in cases where
the shapes contain highly occluded parts that are inaccessible to
the scanner’s line-of-sight. us, complex shapes such as the three-
elephant statue in Figure 2(a) and Figure 2(b) cannot be properly
acquired nor reconstructed based on conventional (optical) scan-
ners. Moreover, some objects, like Figure 2(c), are made of glossy or
transparent materials, which pose another challenge that common
optics cannot deal with.

In this work, we take a completely dierent approach to shape
reconstruction. e idea is to cast surface reconstruction into a
volumetric problem. Our technique is based on the ancient uid dis-
placement discovery made by Archimedes, stating that: the volume
of uid displaced is equal to the volume of the part that was submerged.
By dipping an object in liquid along an axis, we can measure the

ACM Transactions on Graphics, Vol. 36, No. 4, Article 79. Publication date: July 2017.



79:2 • K. Aberman et al.

displacement of the liquid volume displacement and transform it
into a series of thin volume slices of the shape along the dipping axis.
By repeatedly dipping the object in various orientations (see Figure
1), we generate dierent volumetric displacements and transform
them into what we call a “dip transform”.

3D reconstruction proceeds by measuring the volumes of oblique
thin slices of the shape. We refer to the volumes of these slices as
samples, and collect such samples along dierent angles. is, in
turn, equips us with the ability to generate enough data to recover
the geometry of the input shape. Since our technique is based on
using volume samples that are generated by liquid accessing the
object, we can acquire occluded and inaccessible parts in a relatively
straightforward fashion.

Figure 3 illustrates the dip transform of 2D and 3D shapes. Input
shapes (top row) are rotated and dipped along dierent orientations
to form the dip transform (boom row). In the dip transform 2D im-
ages, each column represents measurements along one axis and the
rows represent volume displacements (or slices). We show that the
dip transform is invertible and thus the shape can be reconstructed
back from it.

Our technique of reconstructing 3D shapes with the dip trans-
form is related to computed tomography (see Section 2). Common
tomography methods use optical systems with penetrating waves
to sample the absorption of the radiation along multiple parallel
beams. We show that the dip transform is equivalent to the Radon
transform for binary volumes. While tomography acquisition de-
vices based on radiation systems are expensive, bulky and must be
used in a safe special environment, our dip-based tomography is
inexpensive and safe, while capturing hidden parts and structures.
As such, it provides an appealing alternative approach, generating
a complete shape at a low computational cost, using a novel data
acquisition technique.

e inverse transform requires solving an underdetermined prob-
lem. e matrices involved are large and sparse and are nearly
orthogonal. As such, they have nonzero paerns and structural
properties that can be exploited to accelerate the numerical com-
putations. Given a set of samples of a given object, we use a pre-
computed factorized matrix to compute the inverse dip transform
in nearly linear time in the number of samples and obtain a stable
numerical solution to the problem. When the dimensions of the
problem are small to medium size, we solve the problem by (implic-
itly) computing the pseudo-inverse, giving rise to a solution with
minimum norm. For very large problems we apply LSQR or LSMR,
which are decomposition-free and minimize the norm of the residual

(a) (b) (c)

Fig. 2. These three elephants statues are examples for complex shapes that
cannot be fully reconstructed by conventional (optical) 3D scanners.

or related quantities over a Krylov subspace, using matrix-vector
products.

e key advantage of the presented approach is that it employs
liquid as the sensor. Unlike optical sensors, the liquid has no line-
of-sight requirements, it penetrates into cavities and hidden parts
of the subject, bypassing all visibility and optical limitations of
conventional scanning devices. We demonstrate the merits of our
approach by presenting various results of reconstructing complex
objects, which include large portions of hidden regions.

2 RELATED WORK
e problem of surface reconstruction from scanned points has been
researched extensively in the last couple of decades. Nevertheless
scan based acquisition and reconstruction are beyond the scope of
this work, see e.g. [Berger et al. 2014] for a comprehensive survey.

Computed tomography (CT) is the process of reconstructing an
unknown volume from a collection of two-dimensional projections
(shadow images) corresponding to dierent positions of the electro-
magnetic radiation source and representing the integral of emissions
or absorptions from a given view. A classical way of reconstructing
volume densities from line integrals captured by the projection im-
ages is via the Fourier Slice eorem [Bracewell 1956; Kak and Slaney
2001; Radon 1917], which states that the volume densities can be
recovered from a number of 1D inverse Fourier transforms of lines
in the projection images. Alternatively, Algebraic Reconstruction
Techniques (ART) iteratively solve a set of linear equations [Gordon
et al. 1970; Kak and Slaney 2001] for the volume densities, using the
Kaczmarz iterative scheme.

CT plays a central role in medical imaging as well as in many
computer graphics related applications. Trifonov et al. [2006] use
visible light tomography to acquire objects made of glass and other
transparent media. Specically, they measure the refraction of light
through the transparent object and use tomographic reconstruction
to reconstruct the object’s volume.

Still, 3D reconstruction of transparent and specular objects has
been a challenging problem in computer vision and graphics. Trans-
parent and specular objects, may have complex interior and exterior
structures that can reect and refract light in complex ways. Since
it is beyond the scope of this paper, we refer to the state-of-the-art
survey of this eld [Ihrke et al. 2010].

Stochastic tomography has been introduced in [Gregson et al.
2012] for the purpose of capturing turbulent uid mixing behavior.
Instead of using the Radon transform (Fourier slice theorem) or al-
gebraic reconstruction techniques (ART), their method uses random
walks to reconstruct the volume from an array of cameras. Zhao et
al. [2011] use an X-ray CT system to capture the inner structure of
fabrics and model their appearance. To accurately render a material,
a CT scan is used to capture its inner volume which is then used
to compute the material’s scaering properties. Recently, Ijiri et
al. [2014] use an X-ray CT system to accurately capture the intri-
cate internal structures of real-world 3D owers. ey segment the
volume into ower organs and apply active contours to smoothly
reconstruct their surface.

ACM Transactions on Graphics, Vol. 36, No. 4, Article 79. Publication date: July 2017.



Dip Transform for 3D Shape Reconstruction • 79:3

(a) (b) (c) (d)

Fig. 3. Examples of 2D and 3D objects (first row) and their corresponding sinograms (second row), G (t ;θ ). The 2D sinogramns are described in (a)-(c) for the
range of 0 ≤ θ < 180, θT = (cos θ, sin θ ). A 3D sinogram is described in (d), for the range of 0 ≤ θ < 90, 0 ≤ ϕ < 360, θT = (sin θ cosϕ, sin θ sinϕ, cos θ ).

3 3D DIP TRANSFORM
According to Archimedes equality, which couples buoyancy and
volume, dipping an object in a bath of water allows for measuring
the volume of slices along the dipping orientation (perpendicular to
the water surface) from the water displacement level. Based on this
principle, let us dene a 3D dip transform of an object.

3.1 Definition
Suppose we are given an input object, represented as a volumetric
binary function,

F (x) =



1 x ∈ Ω,
0 otherwise,

(1)

where Ω ∈ R3 is the object’s interior domain. We dene the accu-
mulated volume of F (x) over time t , with orientation θ , as the dip
transform of the object, given by:

F (t ;θ ) =
∫ ∞
−∞

F (x)u
(
xT θ − t

)
dx, (2)

where u (t ) is a step function that equals 1 if t ≥ 0 and 0 otherwise.
e time derivative of the dip transform, G (t ;θ ) = ∂F∂t (t ;θ ), is

equivalent to the Radon transform of a binary object [Herman 2009]:

G (t ;θ ) =
∫ ∞
−∞

F (x) δ
(
xTθ − t

)
dx, (3)

where δ (t ) is the Dirac delta function. Relying on the Archimedes
equality, we get ∫

G (t ;θ )dt = V , ∀θ ,

where V is the volume of the object.

θ

t

Fig. 4. Dip signals of a 2D elephant shape in various orientations. Each
column in the sinogram (le) shows the change in the water level raising for
a dierent angle for 0◦ ≤ θ < 180◦. The dierent profiles (right) contribute
to the shape reconstruction. The angles from le to right, top to boom,
are θ = 20◦, θ = 50◦, θ = 90◦ and θ = 130◦.

Analogously to the computed tomography (CT) eld, G (t ;θ ) can
be visualized using a sinogram – a visual representation of the
object’s projections. In our case, each column in the sinogram repre-
sents a dipping prole, which is acquired along a specic orientation,
as illustrated in Figure 4. e dierent proles contribute to the
shape reconstruction. Examples of 2D and 3D sinograms of dierent
shapes are shown in Figure 3.

In practice, the object is dipped in dierent orientations θ i ∈ Θ,
the water elevation rate is sampled in a constant rate, T , and a set
of sampled measurements, Gθ i [n] = G (nT ;θ i ), is extracted.

ACM Transactions on Graphics, Vol. 36, No. 4, Article 79. Publication date: July 2017.



79:4 • K. Aberman et al.

3.2 Reconstruction
In order to reconstruct F (x), an inverse transform is applied. We
rst dene a discrete version of the problem. Denoting the sampled
measurements by дθ ∈ RM , we recast the reconstruction model as
a least-squares optimization problem:

arg min
F̃

∑
θ i ∈Θ

дθ i − SRθ i F̃
2 , (4)

where Θ is a set of dip orientations, Rθ i is a rotation operator which
rotates the object by an angle of θ i around its center, and S is a
summation operator that sums over the rows of the rotated matrix,
counts the number of active voxels, and outputs an M-length vector.
We note that дθ i is equivalent to a vector of volumes of slices, where
the height of the slices is uniform. e unknown degrees of freedom
that form F̃ are given as a matrix of dimensions M × K × L. Our
eventual goal is to nd a voxelized binary solution in {0, 1}M×K×L
that approximates F (x); this solution represents the inversion.

e matrices S and R are dened via

S =

*.....
,

S̄ 0 0 · · · 0
0 S̄ 0 · · · 0
... 0

. . . 0
0 0 · · · S̄

+/////
-

R =

*.....
,

R̄θ 1
R̄θ 2
...

R̄θK

+/////
-

,

where R̄θ is the rotation operator in matrix notation which rotates a
vectorized object, generated by using bi-linear interpolation, and S̄
is a row summing matrix, which is operated on a vectorized matrix
and sums the rows of the original matrix. In mathematical terms,
S = I ⊗ v where I is an M ×M unit matrix and v is a column vector
of ones of size KL.

For notational convenience we express (4) in vectorized form, as
follows:

arg min
f

д − Bf 2 , (5)

where f ∈ RN is the vectorized version of F̃ (column stack), д is a
chained version of all the measured дθ , and B = SR ∈ RM×N is the
chained “rotate and sum” matrix aer the vectorization procedure.
Finally, we use clamping to convert f into a binary solution, namely
a vector in {0, 1}N .

3.3 Numerical Solution
In this section we discuss several techniques for solving (5), which
denes the inverse dip transform.

In practice, acquiring dip signals by measuring water’s elevation
rate is a time consuming process. In addition, this mechanical oper-
ation may limit the number of dipping angles. us, a typical setup
of a dip transform reconstruction constitutes an underdetermined
problem, where the number of measurements does not uniquely
dene the desired object.

Conventional inverse Radon transform-based methods assume
a full representation of the data within the measurements, and
therefore do not t our case. Instead, we aim at developing a compu-
tationally inexpensive method that computes the inverse transform
while exploiting the structure of the dipping matrices.

Our underdetermined minimization problem (5) features innitely
many solutions, and one way to express them is by

f = fp + z,

where fp is a particular solution that satises Bfp = д, and z is a
vector in the null-space of B, namely a vector that satises Bz = 0.
A common way of selecting a specic f , is to compute the solution
that minimizes ‖ f ‖2 – this is known as the min-norm solution. is
method seeks a solution in the active space of the operator, eliminat-
ing the null space. Oen the null space contains high frequencies,
and eliminating them may have a regularizing eect. Computing it
is typically done via the pseudo-inverse of B. We solve

f = B†д,

where

B† = B (BBT )−1,

and we assume that B has full row rank. In cases where the reg-
ularizing eect is not accomplished, Tikhonov or other types of
regularization may be seamlessly incorporated into the solution
procedure. In our case we could add a small diagonal shi to BBT
before inverting it to accomplish the desired eect. Cases of rank
deciency can be dealt with by computing the QR factorization of
B and eliminating linearly dependent rows. It is easy to show that
the solution in this case has the smallest norm.

In order to convert the solution back to a binary image we de-
termine the value of the binary voxel using a threshold on the
resulting image, using Otsu’s method [Otsu 1975]. e steps in the
reconstruction algorithm are demonstrated in Figure 6.

Computing the pseudo inverse of B through its singular value
decomposition (SVD) is the most numerically stable procedure, but
it is unsuitable for the current problem, because the computation
of the SVD does not respect sparsity. Instead, we compute the
Cholesky factorization of BBT once and for all: we seek a square
lower triangular matrix G, such that BBT = GGT . We then store
the factor G and use it repeatedly as we replace v throughout the
computation. To form BBT , we exploit the block structure of B
and construct the matrix product block by block. e solution of д
requires backward substitution and forward substitution forGT and
G, respectively. Forming the decomposition takes O (W 3) oating
point operations, whereas the backward and forward substitutions
are O (W 2). us, if we repeat the calculations for dierent vectors
v , the overall computational cost is modest.

Taking a close look at B = SR reveals that it is a sparse matrix
with a unique structure. For Rθi , which rotates the object using a bi-
linear interpolation, R typically has 4 nonzero entries per row in 2D
reconstruction and 8 nonzero entries per row in 3D reconstruction.
e matrix S also has a limited number of nonzero entries. e
sparsity paern of SR for 2D reconstruction is shown in Figure 5.
Only 4% of the matrix entries are nonzero.

In a huge-scale seing a direct decompositional approach may
consume prohibitive storage resources. In such cases we resort to
iterative solvers such as LSQR [Paige and Saunders 1982] or LSMR
[Fong and Saunders 2011], with an appropriate preconditioning
approach that exploits the special structure of S and R.

ACM Transactions on Graphics, Vol. 36, No. 4, Article 79. Publication date: July 2017.



Dip Transform for 3D Shape Reconstruction • 79:5

Fig. 5. A sample from B = SR . The object size was N = 50 × 50, number of
orientations K = 15 and number of measurements for each angle T = 50.
Only 4% of the matrix is non zero. Row wise there are approximately N
non-zero entries (white), column-wise there are roughly K .

4 DIPPING AND VOLUME SAMPLING
Seing up the 3D dipping device is challenging as it involves physi-
cal measurements of water level, whose accuracy can be compro-
mised by many factors such as ripples, tank’s cross-section, recorder
sensitivity, etc. In addition, rotating and lowering an object in the
tank need to be performed in a mechanically-controlled manner,
and be precisely calibrated.

We consider three dierent physical setups to measure the dip
transform in practice (see Figure 7):

(1) Dipping – Object is lowered at constant speed into a tank
which is partially lled with water. e water elevation is
recorded, thereby measuring the slices’ volume.

(2) Draining – Object is xed underwater in a tank. A tap at
the boom of the tank is released, draining the water from
the tank at a constant ow rate and the water lowering is
recorded. is rate is proportional to the volume of the
slices.

(3) Flooding – Similarly to Dipping, the object is lowered at
constant speed, however, here water fully lled tank. As the
object is dipped, water overows into a second tank, where
the water elevation rate is recorded. e second tank is
thinner, enhancing water elevation rate, which potentially
leading to higher accuracy.

Each setup has its advantages and disadvantages; we provide a
few details below.

e draining process involves an operation of a mechanical tap
which introduces noise upon opening and closing it. Furthermore,
the draining process may create whirlpools around the tap, resulting
in noise in the water level measurement.

e ooding installation involves water transferring from one
tank to another. Water level reading in the second tank is error
prone as water may not be transferred properly to the second tank.
For example, the water surface tension may prevent the water from
dripping completely into the second tank even in an overow sce-
nario. Also, such water transfer takes time, thus it signicantly
reduces the measuring speed. We have selected the dipping setup
to be used during our experiments. Although the object is lowered
at a constant step size into the water, the amount of water elevation
is changed within each step. When the body is lowered d units
in the ith step and the water level rises δi units, the volume slice
measurement corresponds to d + δi vertically along of the oriented

object. Since in our discrete seing in (4) the object’s voxels are
accumulated within equally spaced slices, we have to preprocess the
measurements so they t the algorithm input. us, we interpolate
the acquired non-uniform slices into a continuous function and
resample it uniformly. e new samples represent volumes of slices
with the same width. e number of slices is determined by the
user. at said, the nest level of details is bounded by the original
water elevation rate; the lower the rate, the ner the level of detail
of the reconstructed geometry. Figure 8 exhibits physical measures
of a spherical ball, interpolated and resampled.

It should be noted that our dipping scheme assumes that the
object has no vertical caps in any orientation. A cap is a vertical
cavity that forms a vessel, in which water can be accumulated if
the object is elevated vertically and air can be trapped, generating
air pockets when the object is dipped in the opposite orientation.
Most caps, if they exist, would be small and would have a minor
eect akin to noise on the dip transform. Nevertheless, caps can be
detected by dipping and then liing back the object with the liquid
trapped in the cap, yielding two dierent water levels. Flipping the
object vertically allows detecting air pockets as they become caps.

5 EXPERIMENTS AND RESULTS
To test the feasibility of our technique we have constructed both
3D dipping simulator, which virtually dips known models, and a
physical 3D dipping robot, shown in Figure 9. We have tested our
technique both qualitatively and quantitatively.

5.1 Dipping Simulator
We have implemented a 3D dipping simulator to allow experiments
using a wide range of 3D objects, as well as dierent dipping scenar-
ios (varying number of dips, noise, etc.). To simulate our mechanism,
a 3D model, represented as mesh surface, is rst converted into a
volume representation, using standard voxelization method [Patil
and Ravi 2005]. Dipping in a specic orientation is simulated by
dividing the object by equally spaced surfaces in the requested ori-
entation. e number of voxels in each slab is counted, resulting in
a single dip measurement. By collecting a set of dip measurements,
we then apply our numerical solution to reconstruct the volume
from the dip transform. It should be noted that the number of dip-
ping orientations inuences the quality of reconstruction. As the
number of dipping proles increases, more details are visible.

In order to demonstrate the evolution of a shape as a function of
the number of dips, we performed the dipping process on several
objects, using an increasing number of orientations.

Figure 10 demonstrates the quality of our reconstruction, using
the raw voxels representation, as a function of the number of dips.
As can be observed, as the number of dips increases more geometric
details are reconstructed. Note specically the ne reconstructed
details of the octopus arms.

In Figure 11 we show our reconstruction evolution of dierent 3D
models, with a resolution of 2403. While low number of orientations
captures the raw shape of the object, using 10% of the required dips
(which are theoretically needed for perfect reconstruction) results in
high quality reconstructions. Table 1 summarizes several statistics
for these models including a reconstruction error using the METRO
method [Cignoni et al. 1998].

ACM Transactions on Graphics, Vol. 36, No. 4, Article 79. Publication date: July 2017.



79:6 • K. Aberman et al.

(a) (b) (c) (d)

Fig. 6. Underdetermined Reconstruction. (a) A subset of 20 dipping angles (columns) is selected. (b) Reconstructed image using LSMR with 20 dips. (c)
Histogram of the reconstructed image. It can be seen the there are two clusters, around 0 and around 1, that divides the image to background and foreground.
(d) Resulting shape aer thresholding, using Ostu’s method.

Fig. 7. Water scanning methods. (a) Dipping - the object is lowered into
the tank and the water level rise rate is measured. (b) Draining - the water
is drained using a tap at the boom of the tank and the water lowering
rate is measured. (c) Flooding - the object is lowered into a fully filled tank,
causing an overflow and a transfer of water into a second tank where the
rate of the water level elevation is measured.

Our method requires no line-of-sight between the sensor and the
captured area, thus, able to reconstruct occluded parts of complex
objects such as the hollow cube in Figure 12, It can be seen that the
inner parts of the cube, which are completely occluded due to the
shape of the body, are reconstructed as can be seen by slicing the
objects into slabs.

In addition, we examined the robustness of our method, which
can be understood from Figure 13. In 13(a) we have tested the recon-
struction error (using METRO [Cignoni et al. 1998]) for increasing
number of dips. We averaged over results from dierent objects
and dierent resolutions, thus, we present the reconstruction er-
ror as a function of the percentage of dip orientations (from the
number required for perfect reconstruction in each resolution). is

Fig. 8. Dipping method resampling. In order to comply with the inverse dip
transform requirement, non-uniform slices of a spherical ball, with a diame-
ter of 260 [mm], are converted into uniform slices. The ball measurements
are interpolated and resampled. The number of uniform slices is dictated
by the required voxel-resolution.

Model Volume [%] Error

Hand 19.41 0.02
Mother-Child 7.71 0.0125
Star 1.76 0.0126
Elephant 12.04 0.017
DNA ball 1.84 0.0433

Table 1. Statistics on the examples shown in Figure 11. The objects in the
list are sorted top to boom, with respect to Figure 11. The distances are
calculated using METRO w.r.t to the bounding box diagonal of the object.

observation supports the high quality reconstruction achieved using

ACM Transactions on Graphics, Vol. 36, No. 4, Article 79. Publication date: July 2017.



Dip Transform for 3D Shape Reconstruction • 79:7

Fig. 9. Applying the dip transform in practice using the dipping robot – a
mechanical arm able to dip a fixed object in dierent orientations and track
the rate of water elevation.

only 10% of the required angles, as shown in Figure 11. In addition,
since our practical system introduces noise to the measurements, we
have added a white gaussian noise, to the virtual object’s dips, and
measured the quality of reconstruction as a function of the signal to
noise ratio (SNR). Since our method solves an optimization problem
with a matrix structure regularization, it can handle noise, in the
sense that the error correlates with the noise in a linear nature. e
results in 13(b), which demonstrate false positive and false negative,
shows that the reconstruction error is considerable, even for low
SNR.

5.2 The Dipping Robot
Following the discussion in Section 4 we constructed a fully auto-
matic system, which incorporates the dipping method. e setup is
rather simple, consisting of a robot arm with one linear axis low-
ering the object (moving perpendicular to the water surface) and
two rotation arms responsible for seing the object’s orientation.
e vertical step was set to 2[mm] and the rotational to 1◦. e
water sensor used is non-contact absolute position transducer, plus
a oating ball, with accuracy of 0.1[mm]. Figure 9, shows our 3D
dipping robot in action.

Reconstructing an object from real dip measurements is a chal-
lenging task. System noise (due to jier and water ripples) should
be considered and a practical number of dipping orientations may
not be suciently diverse. However, geometric priors on the re-
constructed body, such as smoothness and symmetry, may help to
improve the quality of reconstruction.

In order to reconstruct a 3D object we perform the following
stages:

(1) Noise smoothing - the measured signals are smoothed,
using a normalized 5 samples gaussian kernel, in order
to reduce noise which mainly lies in high frequency and
does not degrade the object’s details due to the smoothness
assumption.

(2) Symmetry exploitation - Orientations which yield the
same dipping signal are measured only once and the result-
ing signal is duplicated to all of the appropriate locations.

(3) Dipping signals interpolation - In order to generate dip-
ping signals of missing orientations or to generate more
samples between two consecutive measurements, interpo-
lation between neighboring samples is performed.

(4) Reconstruction - using the smoothed duplicated interpo-
lated samples, our reconstruction algorithm is generated.

In the experiments, we dipped dierent objects as shown in the
le column of Figure 15. ese objects exhibit symmetry which
enables signicant reduction in the number of required orientations.
For example, the cats object (Figure 15 rst row) was dipped in 35 dif-
ferent orientations, followed by noise removal smoothing. Figure 14
compares between a real noisy dip measurement, its smoothed ver-
sion and the simulated ground truth dip. In order to extend the
number of dips, we next exploited the unique geometry of the ob-
ject which has symmetry of 120◦ around the z axis and an additional
reection symmetry within each third. us, the number of real dips
was duplicated into 210 virtual dips. ese dips were interpolated,
resulting a total number of 420 dips.

is number of dips enables resolution of 403, which can be
upsampled and smoothed, due to the smoothness property of the
object. e reconstruction of our dipping algorithm on the real
measurements is shown in Figure 15(d). In addition, our dipping
reconstruction is compared qualitatively to a scan of a 3D struc-
tured light scanner. As can be seen in Figure 15(c), the structured
light scanner can not reconstruct self occluded parts of the objects.
However, our dipping reconstruction results in a complete object.

6 CONCLUSIONS AND FUTURE WORK
e paper presents a novel three-dimensional shape acquisition
and reconstruction method based on the well-known Archimedes
equality between uid displacement and the submerged volume. A
strong feature of our method is that it relies on uid displacement
as the fundamental shape sensor. e liquid has no line-of-sight
requirements, which is advantageous compared to optical sensors.
Furthermore, our technique allows for seamless penetration into
cavities and hidden parts of the object as well as transparent and
glossy materials, thus bypassing all visibility and optical limitations
of conventional scanning devices. Our results demonstrate the

ACM Transactions on Graphics, Vol. 36, No. 4, Article 79. Publication date: July 2017.



79:8 • K. Aberman et al.

(a) 100 dips (b) 325 dips (c) 550 dips (d) 775 dips (e) 1000 dips

Fig. 10. Reconstruction for dierent number of dip orientations. The octopus resolution is 1203. For low number of angles the fine details are lost (legs, eyes,
etc.), and as the number of angles increases more of the shape is reconstructed.

capability of acquisition and reconstruction for a wide range of
shapes with large occlusions and hidden regions.

One obvious limitation of the proposed method is its speed of
acquisition. e mechanical arm dips the object vertically step by
step, and it is necessary to read the liquid level in between steps,
which introduces a temporal boleneck. We are currently exploring
ways for improving this by developing a continuous dipping and
reading process, whereby we measure the ratio between the vertical
dipping speed and the liquid elevation. We are also investigating
faster computational methods. Future work may include the devel-
opment of sparse recovery techniques based on compressed sensing,
which exploit the redundancy that exists in the binary representa-
tion of the voxels, to signicantly reduce the number of dipping
orientations. is approach may lead to a much smaller optimiza-
tion problem, which in turn will allow for further acceleration of the
solution procedure, and the reduction of the overall computational
time required to solve the inverse transform problem.

Another limitation that we have discussed is “no-cap” assumption.
e dipping method assumes that the object has no signicant cap
or vessel. is may introduce errors once the liquid is spilled into
the cap and lls it up. We are considering dealing with such caps by
measuring the level of liquid also during a vertical li of the object.
e amount of liquid trapped in the cap can be measured to assess
the volume of the cap. Analyzing the proles of the liquid level
measured on up and down movements may reveal some additional
geometric features of the shape of the cap.

e success of this volumetric technique leads us to speculate that
we may be able to consider a multi-modal acquisition setup where
the reconstruction combines the information gained by the various
modalities. For example, we may be able to utilize the strengths
of laser scanners for sampling the shape-visible exterior and the
volumetric and occluded information reconstructed from the dip
transform.

7 ACKNOWLEDGEMENTS
We thank the anonymous reviewers for their helpful comments.
is project was supported in part by the Joint NSFC-ISF Research
Program 61561146397, jointly funded by the National Natural Sci-
ence Foundation of China and the Israel Science Foundation (No.
61561146397), the National Basic Research grant (973) (No. 2015CB352501)
and the NSERC of Canada grant 261539.

REFERENCES
Mahew Berger, Andrea Tagliasacchi, Lee M. Seversky, Pierre Alliez, Joshua A. Levine,

Andrei Sharf, and Claudio T. Silva. 2014. State of the Art in Surface Reconstruction
from Point Clouds. In Eurographics 2014 - State of the Art Reports, Sylvain Lefebvre
and Michela Spagnuolo (Eds.). e Eurographics Association. DOI:hps://doi.org/
10.2312/egst.20141040

R. N. Bracewell. 1956. Strip Integration in Radio Astronomy. Australian Journal of
Physics 9 (June 1956), 198. DOI:hps://doi.org/10.1071/PH560198

Paolo Cignoni, Claudio Rocchini, and Roberto Scopigno. 1998. Metro: measuring error
on simplied surfaces. In Computer Graphics Forum, Vol. 17. Wiley Online Library,
167–174.

David Chin-Lung Fong and Michael Saunders. 2011. LSMR: An iterative algorithm for
sparse least-squares problems. SIAM Journal on Scientic Computing 33, 5 (2011),
2950–2971.

Richard Gordon, Robert Bender, and Gabor T. Herman. 1970. Algebraic reconstruction
techniques (ART) for three-dimensional electron microscopy and x-ray photography.
Journal of eoretical Biology 29 (1970), 471–481.

James Gregson, Michael Krimerman, Mahias B. Hullin, and Wolfgang Heidrich. 2012.
Stochastic Tomography and Its Applications in 3D Imaging of Mixing Fluids. ACM
Trans. Graph. 31, 4, Article 52 (July 2012), 10 pages. DOI:hps://doi.org/10.1145/
2185520.2185548

Gabor T. Herman. 2009. Fundamentals of Computerized Tomography: Image Reconstruc-
tion from Projections (2nd ed.). Springer Publishing Company, Incorporated.

Ivo Ihrke, Kiriakos N. Kutulakos, Hendrik P. A. Lensch, Marcus Magnor, and Wolfgang
Heidrich. 2010. Transparent and Specular Object Reconstruction. Computer Graphics
Forum (2010). DOI:hps://doi.org/10.1111/j.1467-8659.2010.01753.x

Takashi Ijiri, Shin Yoshizawa, Hideo Yokota, and Takeo Igarashi. 2014. Flower Modeling
via X-ray Computed Tomography. ACM Trans. Graph. 33, 4, Article 48 (July 2014),
10 pages. DOI:hps://doi.org/10.1145/2601097.2601124

Avinash C. Kak and Malcolm Slaney. 2001. Principles of computerized tomographic
imaging. Society for Industrial and Applied Mathematics, Philadelphia (Pa.). hp:
//opac.inria.fr/record=b1100961

Nobuyuki Otsu. 1975. A threshold selection method from gray-level histograms. Auto-
matica 11, 285-296 (1975), 23–27.

Christopher C Paige and Michael A Saunders. 1982. LSQR: An algorithm for sparse
linear equations and sparse least squares. ACM transactions onmathematical soware
8, 1 (1982), 43–71.

Sandeep Patil and B Ravi. 2005. Voxel-based representation, display and thickness
analysis of intricate shapes. In Ninth International Conference on Computer Aided
Design and Computer Graphics (CAD-CG’05). IEEE, 6–pp.

J. Radon. 1917. Über die Bestimmung von Funktionen durch ihre Integralwerte längs
gewisser Mannigfaltigkeiten. Akad. Wiss. 69 (1917), 262–277.

Borislav Trifonov, Derek Bradley, and Wolfgang Heidrich. 2006. Tomographic Recon-
struction of Transparent Objects. In Proceedings of the 17th Eurographics Conference
on Rendering Techniques (EGSR ’06). Eurographics Association, Aire-la-Ville, Switzer-
land, Switzerland, 51–60. DOI:hps://doi.org/10.2312/EGWR/EGSR06/051-060

Shuang Zhao, Wenzel Jakob, Steve Marschner, and Kavita Bala. 2011. Building Volu-
metric Appearance Models of Fabric Using Micro CT Imaging. In ACM SIGGRAPH
2011 Papers (SIGGRAPH ’11). ACM, New York, NY, USA, Article 44, 10 pages. DOI:
hps://doi.org/10.1145/1964921.1964939

ACM Transactions on Graphics, Vol. 36, No. 4, Article 79. Publication date: July 2017.

https://doi.org/10.2312/egst.20141040
https://doi.org/10.2312/egst.20141040
https://doi.org/10.1071/PH560198
https://doi.org/10.1145/2185520.2185548
https://doi.org/10.1145/2185520.2185548
https://doi.org/10.1111/j.1467-8659.2010.01753.x
https://doi.org/10.1145/2601097.2601124
http://opac.inria.fr/record=b1100961
http://opac.inria.fr/record=b1100961
https://doi.org/10.2312/EGWR/EGSR06/051-060
https://doi.org/10.1145/1964921.1964939


Dip Transform for 3D Shape Reconstruction • 79:9

Fig. 11. 3D-dip reconstructions using dierent number of orientations. An increasing number of orientations (from le to right) allows beer reconstruction of
the dipped object (shown on the right). The objects resolution is 2403. The models are reconstructed using 1%-3% (first column), 5% (second column) and 10%
(third column) from the required number of orientations for perfect reconstruction.

ACM Transactions on Graphics, Vol. 36, No. 4, Article 79. Publication date: July 2017.



79:10 • K. Aberman et al.

Fig. 12. 3D dip reconstruction of a hollow cube (le). The cube inner shape
is reconstructed as seen by slicing the reconstruction to 3 slabs (right).

0 5 10 15 20 25 30
0.1

0.15

0.2

0.25

0.3

0.35

Dips [%]

R
ec
o
n
st
ru

ct
io
n
E
rr
o
r

(a) (b)

Fig. 13. Reconstruction errors. (a) METRO reconstruction error for dierent
percentage of dip orientations (from the number required for perfect recon-
struction). The reconstructed error decreases dramatically with the number
of orientations, allowing the use of only a small portion of the required
dipping orientations. (b) Normalized reconstruction error as a function of
the SNR. Noise is introduced to the samples. False positive error marks the
creation of false object’s parts in the reconstruction, while false-negative
point to missing object’s parts. The errors were calculated using dierent
objects with dierent resolutions.

0 10 20 30 40 50 60 70 80 90 100
-1000

0

1000

2000

3000

4000

5000

6000

W
at
er

el
ev
at
io
n
d
iff

[m
m
]

Original robot dip
Smoothed robot dip
Ideal simulated dip

Fig. 14. A measurement of the dipping robot, before (red) and aer (blue)
smoothing. The profile is compared to an ideal dip in the same orientation
(green).

ACM Transactions on Graphics, Vol. 36, No. 4, Article 79. Publication date: July 2017.



Dip Transform for 3D Shape Reconstruction • 79:11

(a) (b) (c) (d)

Fig. 15. 3D dip reconstructions comparison. (a) Picture of the objects during the dipping (b) Profile picture of the printed objects (c) Structured light scanner
reconstruction (d) Our 3D reconstruction using the dipping robot. Occluded parts of the body have no line-of-sight to the scanner sensor, while the dipping
robot, using water, is able to reconstruct these hidden parts.

ACM Transactions on Graphics, Vol. 36, No. 4, Article 79. Publication date: July 2017.


	Abstract
	1 Introduction
	2 Related Work
	3 3D Dip Transform
	3.1 Definition
	3.2 Reconstruction
	3.3 Numerical Solution

	4 Dipping and Volume Sampling
	5 Experiments and Results
	5.1 Dipping Simulator
	5.2 The Dipping Robot

	6 Conclusions and Future Work
	7 Acknowledgements
	References

