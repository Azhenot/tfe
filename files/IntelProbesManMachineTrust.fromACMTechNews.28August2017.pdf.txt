






































EE Times - Intel Probes Man-Machine 'Trust'


Junko Yoshida, Chief International
Correspondent
8/24/2017 11:00 AM EDT

 8 comments post a comment

Tweet

Blog

Intel Probes Man-Machine ‘Trust’

Acceptance of a self-
driving car isn't just a
question of trust
versus control. Why
should I want one?
What values and

benefits does it deliver?

In hopes of playing a leadership role in the coming era of driverless cars, Intel is making a
gutsy move. The chip giant is initiating qualitative studies toward solving the eternal human-
machine quandary: Can you ever trust a machine?

And if so, would the machine have to look like Darryl Hannah?

Intel recently conducted a qualitative study with 10 volunteers with no previous exposure to
driverless cars. The subjects were invited to the company’s Chandler, Arizona, campus. Test
proctors asked them to ride in a driverless test car and offer feedback on the experience.
Although admitting the sample was small, Intel cheerfully shared with reporters some of the
nuggets — and a few surprises — that emerged from the study. Intel reps told us that they
hope to verify the results in a series of larger tests to be conducted in different geographical
regions.

Intel has recently conducted Car & Rider Trust Study. (Source: Intel)

First off, the skeptic on my shoulder found it slightly preposterous for a semiconductor
company to conduct a socio-psychological study focused on an objective as touchy-feely as
“trust.”

My first instinct was that a study done by a company whose vested interest is convincing
people to use its [driverless] technology has little credibility. Any conclusion could be
dismissed as suspect and self-serving.

On the other hand, I found myself applauding Intel for dealing head-on with the thorniest
issue of driverless cars: Will driverless cars ever gain passengers’ trust? Do consumers
really want this stuff?

These are questions that most technologists avoid. They see such issues as outside their
engineering domain and responsibilities.

Mike Demler, senior analyst at The Linley Group, agreed. “First of all, I’d give credit to Intel
for doing this. Ten people is by no means a statistically significant sample, but the human
aspects of autonomous transportation have been largely ignored. Too many companies —
Google, for example — are too prone to falling in love with their technology without taking
human factors into consideration.”

ShareShare 84

EE Times - Intel Probes Man-Machine 'Trust' http://www.eetimes.com/author.asp?section_id=36&doc_id=1332188&pr...

1 sur 4 28/08/2017 19:29



Seven key areas of tension
Intel is fully aware that people “are downright scared of robot cars,” as they put it. The
company quoted a recent American Automobile Association study, which found that 75% of
Americans are afraid to ride in self-driving cars.

Inevitably, it is incumbent upon technology companies such as Intel to educate the media
and consumers and demonstrate that autonomous cars are, indeed, safe. In that sense,
consumer testing like this is good public relations.

Asked about the methodology of the study, Jack Weast, Chief Systems Architect of Intel
Autonomous Driving Group, explained that first, Intel took its time pre-briefing the volunteers,
explaining how sensors and sensor fusion work and what makes the car drive itself. During
the ride, a safety driver inside a vehicle kept his hands off the steering wheel. He was not
allowed to speak. Participants, in the back seat, were asked to say whatever popped into
their heads. Their comments and behavior were captured on audio and video. After the ride,
Intel did another interview.

As Weast told us, the study found “seven key areas of tension” in the man-machine
interaction. They unfolded in different scenarios, while participants’ comments were often
somewhat contradictory.

1. Can a driverless car handle roundabouts?
The first and the most obvious area of tension was in the area of “human versus machine
judgment.” Participants were uneasy about a driverless car’s judgment when the car needs
to handle difficult situations such as roundabouts or other drivers cutting off the driverless
car. Their repeated question was: “How does a machine make this sort of judgment?” On the
other hand, volunteers expressed the belief that self-driving vehicles should be safer
because they eliminate human error.

2. How do I tell a driverless car where exactly in a mall to drop me off?
Participants liked having free time in their own personal space. But they were also concerned
about “a lack of assistance, a lack of accountability,” said Weast. They asked, “Nobody is
monitoring this?” Having no driver in the car was also unnerving to some participants. With
no driver, they wondered how to tell the car a specific entrance and a specific dropoff point.
Picture a big shopping mall, said Weast. The driverless car may have the address of the
mall, but not the right entrance where the passenger wants to go. “When it gets closer to the
destination, especially near the drop-off, we must have a way to fine-tune the car to respond
to the passenger’s request.”

3. Put a sock in it, Hal
Participants appreciated knowing what the driverless car is doing during their ride. However,
they also thought that there was too much information. “Stop bothering me, it’s not important”
or “I’d like to take a nap.”

Next page: Voice, context, gesture

4. Why a steering wheel?
For many people, it’s not easy to give up control of the vehicle. Seeing a steering wheel
turning by itself — sometimes in a very abrupt way — made some volunteers anxious. They
even discussed the benefits of removing these legacy instruments so that they won’t get
nervous. Participants, however, appreciated other new tricks, such as using their own mobile
devices to summon a vehicle and unlock it, explained Weast. “For them, it was a new form of
control.”

5. Prove it to me that it’s working
Participants were able to see how a driverless car is working by watching statistics on an in-
vehicle display. But they often ignored the display to look outside, watch the road, and
confirm that the driverless car is, well, driving, said Weast. “Rather than usual data such as
miles per gallon, we may need something else — a proof — to satisfy passengers showing
how the driverless car is working well.”

6. Alexa impact: Can I talk to it?
While participants were comforted by the car’s human “voice,” many wondered, “Can I talk to
the car?” Participants wondered if the driverless car would listen — and obey — when they
want to change a route or stop the car because they, or their kids, were feeling sick. Some
participants are obviously used to having smart speakers like Amazon Echo to which they
can ask questions to and expect an answer, explained Weast.

7. Should a driverless car follow rules to a T?

EE Times - Intel Probes Man-Machine 'Trust' http://www.eetimes.com/author.asp?section_id=36&doc_id=1332188&pr...

2 sur 4 28/08/2017 19:29



Participants became aware of nuanced differences between a machine and a human when it
comes to the interpretation of safety. While acknowledging their own not-so-safe driving
behavior, “many participants concluded that boring is safe,” said Weast.

Voice, context, gesture
Asked about takeaways from the study, Weast explained that participants like its voice
interface, but they also wanted to talk to the car. “Especially when a car comes close to a
destination, we need a tool to fine-tune, making a vehicle understand a passenger’s needs.”
More importantly, he added, “Voice may not be enough. People want to point to a certain
thing and tell the car, ‘Take me there.’”

So, beyond processing natural language and understanding the context, noted Weast, the
car may have to understand “gesture.”

Phil Magney, founder and principal advisor for Vision Systems Intelligence (VSI), told us, “In
the automated vehicle space, there are really two tracks to consider.”

One is active ADAS (from Level 1 to Level 3), he noted. “In these vehicles, trust is with the
driver because they are always in the loop. In these deployments, trust is built up gradually
but will not be an issue that prevents adoption of these features.”

He added, “In this category of incremental automation, HMI is critical for well-known issues of
monitoring driver state and readiness. How the car communicates with the driver will be
adaptable through OTA updates to the HMI functions.”

Next page: In-vehicle vs. out-of-vehicle trust

In-vehicle vs. out-of-vehicle trust
The second market is the commercial Level 4 automated vehicles wherein the driver is out of
the loop or not present at all. Magney stressed, “Here is where the challenges lie for human
trust, and trust concerns not only the passengers, but surrounding actors as well
(passengers in other vehicles, pedestrians on foot, cyclists, etc.).”

He explained, “In-vehicle trust with the passengers is going to be critical. Nobody really
knows how big this problem will be. It is too early to tell.”

“The Intel sample was very small and the results were contradictory, so it is very hard to
know what the right solution will be.”

Magney added, “Out-of-vehicle trust is not talked about but is very important. For example,
human-driven cars are always communicating with other actors through signals, horns, and
human visual contact. Take the driver out of the loop and communication with actors is
challenged because you cannot make eye contact with a driver. For example, a pedestrian at
a crossing often proceeds to cross once visual contact is made with the driver. So, in L4
driverless vehicles, there needs to be a way for that vehicle to signal its intentions to the
outside actors.”

In short, Magney is saying that the automotive industry will need several iterations of trial and
error before it can build a reasonable in-vehicle trust with passengers. When it comes to out-
of-vehicle trust, though, nothing is ready yet.

Multiple dimensions of trust
Of course, as I noted before, trust is a high bar. It’s not simple to build a trusted relationship
between me and a 3,000-pound, 70-mph robot.

EE Times - Intel Probes Man-Machine 'Trust' http://www.eetimes.com/author.asp?section_id=36&doc_id=1332188&pr...

3 sur 4 28/08/2017 19:29



EMAIL THIS PRINT COMMENT

For example, trust isn’t limited to technical designs for the man-machine interface (although I
understand that was Intel’s main concern). The issue is deeply related to other questions like:
Do I trust Intel? Do I trust the software — millions of lines of code — running in this driverless
car? Do I trust the designer of this autonomous car? Are regulators doing enough to protect
passengers like me? When I have an accident in a driverless car, is the law on my side? All
of these social and legal factors will play into building trust between me and My Mother the
Car.

The Linley Group’s Demler also wonders if Intel’s study started “in the wrong place.”

The focus of Intel’s study was on the passenger experience in a driverless car under a
scenario like a ride-hailing service. But Demler suggested, “I would have started by asking a
more fundamental question that Intel only briefly touched on: ‘If you could have a car that
drives itself, would you want one?’”

Why should I want one?
Demler said, “Acceptance of a self-driving car isn’t just a question of trust versus control.
Why should I want one? What values and benefits does it deliver? These types of questions
are critical for any product development.”

He stressed, “But this is where we too often see the technologist’s bias come into play, in just
assuming their invention is a good thing. From a product development point of view, it’s
critical to first establish the customer’s wants. I haven’t heard anyone in autonomous vehicle
development start from that basis. In all the projections of self-driving car penetration, what if
people just don’t want one?”

Demler summed up: “If you identify wants first, then demonstrate that your product can
deliver on those wants, trust comes naturally. In this Intel test, it’s sort of like taking people at
an amusement park and asking them how they liked the rides. Yeah, you’ll get different
responses to the experiences, but what did you really learn that will contribute to product
success?”

— Junko Yoshida, Chief International Correspondent, EE Times

Copyright © 2017 UBM Electronics, A AspenCore company, All rights reserved. Privacy Policy | Terms of
Service

EE Times - Intel Probes Man-Machine 'Trust' http://www.eetimes.com/author.asp?section_id=36&doc_id=1332188&pr...

4 sur 4 28/08/2017 19:29


