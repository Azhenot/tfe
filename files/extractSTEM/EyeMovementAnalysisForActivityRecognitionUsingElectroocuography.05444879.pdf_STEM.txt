




































untitl 


eye movement analysi for activ recognit 
use electrooculographi 

andrea bulling, student member, ieee, jami A. ward, han gellersen, and 

gerhard tröster, senior member, ieee 

abstract—in thi work, we investig eye movement analysi a a new sens modal for activ recognition. eye movement data 

be record use an electrooculographi (eog) system. We first describ and evalu algorithm for detect three eye 

movement characterist from eog signals—saccades, fixations, and blinks—and propos a method for assess repetit pattern 

of eye movements. We then devis 90 differ featur base on these characterist and select a subset of them use minimum 

redund maximum relev (mrmr) featur selection. We valid the method use an eight particip studi in an offic 

environ use an exampl set of five activ classes: copi a text, read a print paper, take handwritten notes, watch a 

video, and brows the web. We also includ period with no specif activ (the null class). use a support vector machin 

(svm) classifi and person-independ (leave-one-person-out) training, we obtain an averag precis of 76.1 percent and recal of 

70.5 percent over all class and participants. the work demonstr the promis of eye-bas activ recognit (ear) and open 

up discuss on the wider applic of ear to other activ that be difficult, or even impossible, to detect use common sens 

modalities. 

index terms—ubiquit computing, featur evalu and selection, pattern analysis, signal processing. 

Ç 

1 introduct 

human activ recognit have becom an importantappl area for pattern recognition. research in 
comput vision have tradit be at the forefront of 
thi work [1], [2]. the grow use of ambient and body- 
worn sensor have pave the way for other sens 
modalities, particularli in the domain of ubiquit 
computing. import advanc in activ recognit be 
achiev use modal such a bodi movement and 
postur [3], sound [4], or interact between peopl [5]. 

there are, however, limit to current sensor config- 
urations. acceleromet or gyroscopes, for example, be 
limit to sens physic activity; they cannot easili be use 
for detect predominantli visual tasks, such a reading, 
brows the web, or watch a video. common ambient 
sensors, such a reed switch or light sensors, be limit in 
that they onli detect basic activ events, e.g., enter or 
leav a room or switch an applianc on or off. further to 
these limitations, activ sens use subtl cues, such a 
user attent or intention, remain larg unexplored. 

A rich sourc of information, a yet unus for activ 
recognition, be the movement of the eyes. the movement 
pattern our eye perform a we carri out specif 
activ have the potenti to reveal much about the 
activ themselves—independ of what we be 
look at. thi includ inform on visual tasks, such 
a read [6], inform on predominantli physic 
activities, such a drive a car, but also on cognit 
process of visual perception, such a attent [7] or 
salienc determin [8]. In a similar manner, locat or 
a particular environ may influenc our eye move- 
ments. becaus we use our eye in almost everyth that 
we do, it be conceiv that eye movement provid use 
inform for activ recognition. 

develop sensor to record eye movement in daili life 
be still an activ topic of research. mobil set call for 
highli miniaturized, low-pow eye tracker with real-tim 
process capabilities. these requir be increasingli 
address by commonli use video-bas systems, of 
which some can now be worn a rel light headgear. 
however, these remain expensive, with demand video 
process task requir bulki auxiliari equipment. 
electrooculographi (eog)—th measur techniqu 
use in thi work—i an inexpens method for mobil 
eye movement recordings; it be comput light 
weight and can be implement use wearabl sensor 
[9]. thi be crucial with a view to long-term record in 
mobil real-world settings. 

1.1 paper scope and contribut 

the aim of thi work be to ass the feasibl of 
recogn human activ use eye movement analysis, 
so-cal eye-bas activ recognit (ear).1 the specif 
contribut are: 

ieee transact ON pattern analysi and machin intelligence, vol. 33, no. 4, april 2011 741 

. A. bull be with the comput laboratory, univers of cambridge, 15 
JJ thomson ave., william gate building, cambridg cb3 0fd, uk, and 
the school of comput and communications, lancast university, 
infolab 21, south drive, lancast la1 4wa, uk. 
e-mail: andreas.bulling@acm.org. 

. G. tröster be with the depart of inform technolog and 
electr engineering, swiss feder institut of technolog (eth) 
zurich, gloriastrass 35, 8092 zurich, switzerland. 
e-mail: troester@ife.ee.ethz.ch. 

. j.a. ward and H. gellersen be with the school of comput and 
communications, lancast university, infolab 21, south drive, lan- 
caster la1 4wa, uk. e-mail: {j.ward, hwg}@comp.lancs.ac.uk. 

manuscript receiv 26 nov. 2009; accept 26 feb. 2010; publish onlin 
30 mar. 2010. 
recommend for accept by B. schiele. 
for inform on obtain reprint of thi article, pleas send e-mail to: 
tpami@computer.org, and refer ieeec log number 
tpami-2009-11-0785. 
digit object identifi no. 10.1109/tpami.2010.86. 1. An earli version of thi paper be publish in [10]. 

0162-8828/11/$26.00 � 2011 ieee publish by the ieee comput societi 



1. the introduct of eye movement analysi a a new 
sens modal for activ recognition, 

2. the develop and character of new algo- 
rithm for detect three basic eye movement type 
from eog signal (saccades, fixations, and blinks) and 
a method to ass repetit eye movement patterns, 

3. the develop and evalu of 90 featur 
deriv from these eye movement types, and 

4. the implement of a method for continu ear 
and it evalu use a multiparticip eog data 
set involv a studi of five real-world offic 
activities. 

1.2 paper organ 

We first survey relat work, introduc eog, and describ 
the main eye movement characterist that we identifi a 
use for ear. We then detail and character the 
recognit methodology: the method use for remov 
drift and nois from eog signals, and the algorithm 
develop for detect saccades, fixations, blinks, and for 
analyz repetit eye movement patterns. base on 
these eye movement characteristics, we develop 90 features; 
some directli deriv from a particular characteristic, 
other devis to captur addit aspect of eye move- 
ment dynamics. 

We rank these featur use minimum redund 
maximum relev (mrmr) featur select and a 
support vector machin (svm) classifier. To evalu both 
algorithm on a real-world example, we devis an experi- 
ment involv a continu sequenc of five offic 
activities, plu a period without ani specif activ (the 
null class). finally, we discu the find gain from 
thi experi and give an outlook to futur work. 

2 relat work 

2.1 electrooculographi applic 

eye movement characterist such a saccades, fixations, 
and blinks, a well a deliber movement pattern 
detect in eog signals, have alreadi be use for 
hands-fre oper of static human-comput [11] and 
human-robot [12] interfaces. eog-bas interfac have 
also be develop for assist robot [13] or a a control 
for an electr wheelchair [14]. such system be intend to 
be use by physic disabl peopl who have extrem 
limit peripher mobil but still retain eye-motor 
coordination. these studi show that eog be a measure- 
ment techniqu that be inexpensive, easi to use, reliable, and 
rel unobtrus when compar to head-worn 
camera use in video-bas eye trackers. while these 
applic all use eog a a direct control interface, our 
approach be to use eog a a sourc of inform on a 
person’ activity. 

2.2 eye movement analysi 

A grow number of research use video-bas eye 
track to studi eye movement in natur environments. 
thi have lead to import advanc in our understand of 
how the brain process tasks, and of the role that the visual 
system play in thi [15]. eye movement analysi have a long 
histori a a tool to investig visual behavior. In an earli 
study, hacisalihzad et al. use markov process to model 
visual fixat of observ recogn an object [16]. they 

transform fixat sequenc into charact string and 
use the string edit distanc to quantifi the similar of eye 
movements. elhelw et al. use discret time markov chain 
on sequenc of tempor fixat to identifi salient imag 
featur that affect the percept of visual realism [17]. 
they found that fixat cluster be abl to uncov the 
featur that most attract an observer’ attention. dempere- 
marco et al. present a method for train novic in 
assess tomographi imag [18]. they model the 
assess behavior of domain expert base on the 
dynam of their saccad eye movements. salvucci and 
anderson evalu mean for autom analysi of eye 
movement [19]. they describ three method base on 
sequence-match and hidden markov model that inter- 
prete eye movement a accur a human expert but 
in significantli less time. 

all of these studi aim to model visual behavior 
dure specif task use a small number of well-known 
eye movement characteristics. they explor the link 
between the task and eye movements, but do not recogn 
the task or activ use thi information. 

2.3 activ recognit 

In ubiquit computing, one goal of activ recognit be 
to provid inform that allow a system to best assist 
the user with hi or her task [20]. traditionally, activ 
recognit research have focu on gait, posture, and 
gesture. bao and intil use body-worn acceleromet to 
detect 20 physic activities, such a cycling, walking, and 
scrub the floor, under real-world condit [21]. logan 
et al. studi a wide rang of daili activities, such a use a 
dishwash or watch television, use a larg varieti 
and number of ambient sensors, includ rfid tag and 
infrar motion detector [22]. ward et al. investig the 
use of wrist-worn acceleromet and microphon in a 
wood workshop to detect activities, such a hammer or 
cut wood [4]. sever research investig the 
recognit of read activ in stationari and mobil 
set use differ eye track techniqu [6], [23]. 
our work, however, be the first to describ and appli a 
general-purpos architectur for ear to the problem of 
recogn everyday activities. 

3 background 

3.1 electrooculographi 

the eye can be model a a dipol with it posit pole at 
the cornea and it neg pole at the retina. assum a 
stabl corneo-retin potenti difference, the eye be the 
origin of a steadi electr potenti field. the electr 
signal that can be measur from thi field be call the 
electrooculogram (eog). 

If the eye move from the center posit toward the 
periphery, the retina approach one electrod while the 
cornea approach the oppos one. thi chang in 
dipol orient caus a chang in the electr potenti 
field and thu the measur eog signal amplitude. By 
analyz these changes, eye movement can be tracked. 
use two pair of skin electrod place at opposit side of 
the eye and an addit refer electrod on the forehead, 
two signal compon (eogh and eogv), correspond to 
two movement components—a horizont and a vertical— 
can be identified. eog typic show signal amplitud 

742 ieee transact ON pattern analysi and machin intelligence, vol. 33, no. 4, april 2011 



rang from 5 to 20 �V =degre and an essenti frequenc 
content between 0 and 30 Hz [24]. 

3.2 eye movement type 

To be abl to use eye movement analysi for activ 
recognition, it be import to understand the differ type 
of eye movement. We identifi three basic eye movement 
type that can be easili detect use eog: saccades, 
fixations, and blink (see fig. 1). 

3.2.1 saccad 

the eye do not remain still when view a visual scene. 
instead, they have to move constantli to build up a mental 
“map” from interest part of that scene. the main reason 
for thi be that onli a small central region of the retina, the 
fovea, be abl to perceiv with high acuity. the simulta- 
neou movement of both eye be call a saccade. the 
durat of a saccad depend on the angular distanc the 
eye travel dure thi movement: the so-cal saccad 
amplitude. typic characterist of saccad eye move- 
ment be 20 degre for the amplitude, and 10 to 100 m for 
the durat [25]. 

3.2.2 fixat 

fixat be the stationari state of the eye dure which 
gaze be held upon a specif locat in the visual scene. 
fixat be usual defin a the time between each two 
saccades. the averag fixat durat lie between 100 
and 200 m [26]. 

3.2.3 blink 

the frontal part of the cornea be coat with a thin liquid 
film, the so-cal “precorni tear film.” To spread thi 
fluid across the corneal surface, regular open and close 
of the eyelids, or blinking, be required. the averag blink 
rate vari between 12 and 19 blink per minut while at 
rest [27]; it be influenc by environment factor such a 
rel humidity, temperature, or brightness, but also by 
physic activity, cognit workload, or fatigu [28]. the 
averag blink durat lie between 100 and 400 m [29]. 

4 methodolog 

We first provid an overview of the architectur for ear 
use in thi work. We then detail our algorithm for 

remov baselin drift and nois from eog signals, for 
detect the three basic eye movement types, and for 
analyz repetit pattern of eye movements. finally, we 
describ the featur extract from these basic eye move- 
ment type and introduc the minimum redund 
maximum relev featur select and the support 
vector machin classifier. 

4.1 recognit architectur 

fig. 2 show the overal architectur for ear. the method 
be all implement offlin use matlab and C. input 
to the process chain be the two eog signal captur 
the horizont and the vertic eye movement components. 
In the first stage, these signal be process to remov ani 
artifact that might hamper eye movement analysis. In the 
case of eog signals, we appli algorithm for baselin drift 
and nois removal. onli thi initi process depend on 
the particular eye track techniqu used; all further stage 
be complet independ of the underli type of 
eye movement data. In the next stage, three differ eye 
movement type be detect from the process eye 
movement data: saccades, fixations, and blinks. the 
correspond eye movement event return by the 
detect algorithm be the basi for extract differ 
eye movement featur use a slide window. In the last 
stage, a hybrid method select the most relev of these 
features, and us them for classification. 

4.2 eog signal process 

4.2.1 baselin drift remov 

baselin drift be a slow signal chang superpos the eog 
signal but mostli unrel to eye movements. It have mani 
possibl sources, e.g., interfer background signal or 
electrod polar [30]. baselin drift onli margin 
influenc the eog signal dure saccades; however, all 

bull ET al.: eye movement analysi for activ recognit use electrooculographi 743 

fig. 1. denois and baselin drift remov horizont (eogh) and 
vertic (eogv) signal components. exampl of the three main eye 
movement type be mark in gray: saccad (s), fixat (f), and 

blink (b). 

fig. 2. architectur for eye-bas activ recognit on the exampl of 

eog. light gray indic eog signal processing; dark gray indic 

use of a slide window. 



other eye movement be subject to baselin drift. In a five- 
electrod setup, a use in thi work (see fig. 8), baselin 
drift may also differ between the horizont and vertic 
eog signal component. 

sever approach to remov baselin drift from 
electrocardiographi (ecg) signal have be propos 
(for example, see [31], [32], [33]). As ecg show repetit 
signal characteristics, these algorithm perform suffici 
well at remov baselin drift. however, for signal with 
nonrepetit characterist such a eog, develop 
algorithm for baselin drift remov be still an activ area 
of research. We use an approach base on wavelet 
transform [34]. the algorithm first perform an approxi- 
mat multilevel 1D wavelet decomposit at level nine 
use daubechi wavelet on each eog signal component. 
the reconstruct decomposit coeffici give a base- 
line drift estimation. subtract thi estim from each 
origin signal compon yield the correct signal 
with reduc drift offset. 

4.2.2 nois remov 

eog signal may be corrupt with nois from differ 
sources, such a the residenti power line, the measur 
circuitry, electrodes, and wires, or other interfer physio- 
logic sourc such a electromyograph (emg) signals. In 
addition, simultan physic activ may caus the 
electrod to loos contact or move on the skin. As mention 
before, eog signal be typic nonrepetitive. thi prohi- 
bit the applic of denois algorithm that make use of 
structur and tempor knowledg about the signal. 

sever eog signal characterist need to be preserv 
by the denoising. first, the steep of signal edg need 
to be retain to be abl to detect blink and saccades. 
second, eog signal amplitud need to be preserv to be 
abl to distinguish between differ type and direct of 
saccad eye movements. finally, denois filter must not 
introduc signal artifact that may be misinterpret a 
saccad or blink in subsequ signal process steps. 

To identifi suitabl method for nois removal, we 
compar three differ algorithm on real and synthet 
eog data: a low-pass filter, a filter base on wavelet 
shrinkag denois [35], and a median filter. By visual 
inspect of the denois signal, we found that the median 
filter perform best; it preserv edg steep of 
saccad eye movements, retain eog signal amplitudes, 
and do not introduc ani artifici signal changes. It be 
crucial, however, to choos a window size wmf that be small 
enough to retain short signal pulses, particularli those 
caus by blinks. A median filter remov puls of a width 
small than about half of it window size. By take into 
account the averag blink durat report earlier, we 
fix wmf to 150 ms. 

4.3 detect of basic eye movement type 

differ type of eye movement can be detect from the 
process eog signals. In thi work, saccades, fixations, 
and blink form the basi of all eye movement featur use 
for classification. the robust of the algorithm for 
detect these be key to achiev good recognit 
performance. saccad detect be particularli import 
becaus fixat detection, eye movement encoding, and the 

wordbook analysi be all reliant on it (see fig. 2). In the 
following, we introduc our saccad and blink detect 
algorithm and character their perform on eog 
signal record under constrain conditions. 

4.3.1 saccad and fixat detect 

for saccad detection, we develop the so-cal contin- 
uou wavelet transform—saccad detect (cwt-sd) algo- 
rithm (see fig. 3 for an example). input to cwt-sd be the 
denois and baselin drift remov eog signal compo- 
nent eogh and eogv. cwt-sd first comput the 
continu 1D wavelet coeffici at scale 20 use a haar 
mother wavelet. let s be one of these signal compon 
and the mother wavelet. the wavelet coeffici cab of s at 
scale a and posit b be defin 

cab ðsþ ¼ 
Z 

IR 

sðtþ 1ffiffiffi 
a 
p t� b 

a 

� � 
dt: 

By appli an application-specif threshold thsd on the 
coeffici ciðsþ ¼ c20i ðsþ, cwt-sd creat a vector M with 
element mi: 

Mi ¼ 
1; 8i : ciðsþ < �thsd; 
�1; 8i : ciðsþ > thsd; 
0; 8i : �thsd � ciðsþ � thsd: 

8< 
: 

thi step divid eogh and eogv in saccad 
(M ¼ 1;�1) and nonsaccad (fixational) (M ¼ 0) segments. 

saccad segment shorter than 20 m and longer than 
200 m be removed. these boundari approxim the 
typic physiolog saccad characterist describ in 
literatur [25]. cwt-sd then calcul the amplitud and 
direct of each detect saccade. the saccad amplitud 
SA be the differ in eog signal amplitud befor and 

744 ieee transact ON pattern analysi and machin intelligence, vol. 33, no. 4, april 2011 

fig. 3. continu wavelet transform—saccad detect algorithm. 
(a) denois and baselin drift remov horizont eog signal dure 
read with exampl saccad amplitud (sa); (b) the transform 
wavelet signal (eogwl), with application-specif small (�thsmall) and 
larg (�thlarge) thresholds; (c) marker vector for distinguish between 
small (msmall) and larg (mlarge) saccades; and (d) exampl charact 
encod for part of the eog signal. 



after the saccad (c.f. fig. 3). the direct be deriv from 
the sign of the correspond element in M. finally, each 
saccad be encod into a charact repres the 
combin of amplitud and direction. for example, a 
small saccad in eogh with neg direct get encod 
a “r” and a larg saccad with posit direct a “l.” 

human typic altern between saccad and fixa- 
tions. thi allow u to also use cwt-sd for detect 
fixations. the algorithm exploit the fact that gaze remain 
stabl dure a fixation. thi result in the correspond 
gaze points, i.e., the point in a visual scene that the gaze be 
direct at, to cluster togeth close in time. therefore, 
fixat can be identifi by threshold on the dispers 
of these gaze point [36]. for a segment S of length n 
compris of a horizont Sh and a vertic Sv eog signal 
component, the dispers be calcul a 

dispersionðsþ ¼ maxðshþ �minðshþ þmaxðsvþ �minðsvþ: 

initially, all nonsaccad segment be assum to 
contain a fixation. the algorithm then drop segment for 
which the dispers be abov a maximum threshold thfd of 
10,000 or if it durat be below a minimum threshold thfdt 
of 200 ms. the valu of thfd be deriv a part of the cwt- 
SD evaluation; that of thfdt approxim the typic averag 
fixat durat report earlier. 

A particular activ may requir saccad eye movement 
of differ distanc and direction. for example, read 
involv a fast sequenc of small saccad while scan 
each line of text, while larg saccad be requir to jump 
back to the begin of the next line. We opt to detect 
saccad with two differ amplitudes, “small” and “large.” 
thi requir two thresholds, thsdsmall and thsdlarg , to divid the 
rang of possibl valu of C into three band (see fig. 3): no 
saccad (�thsdsmall < C < thsdsmall ), small saccad (�thsdlarg < 
C < �thsdsmall or thsdsmall < C < thsdlarg ), and larg saccad 
(C < �thsdlarg or C > thsdlarg ). depend on it peak value, 
each saccad be then assign to one of these bands. 

To evalu the cwt-sd algorithm, we perform an 
experi with five participants—on femal and four 
male (age: 25-59 years, mean ¼ 36:8, sd ¼ 15:4). To cover 
effect of differ in electrod placement and skin 
contact, the experi be perform on two differ 
days; in between day the particip take off the eog 
electrodes. A total of 20 record be make per 
participant, 10 per day. each experi involv track 
the participants’ eye while they follow a sequenc of 
flash dot on a comput screen. We use a fix 
sequenc to simplifi label of individu saccades. the 
sequenc be compris of 10 eye movement consist of 
five horizont and eight vertic saccades. thi produc a 
total of 591 horizont and 855 vertic saccades. 

By match saccad event with the annot ground 
truth, we calcul true posit (tps), fals posit 
(fps), and fals neg (fns), and from these, precis 
( tptpþfp), recal ( 

TP 
tpþfn), and the F1 score (2 � 

precision�recal 
precisionþrecall). 

We then evalu the F1 score across a sweep on the cwt- 
SD threshold thsd ¼ 1 . . . 50 (in 50 steps) separ for the 
horizont and vertic eog signal components. fig. 4 
show the mean F1 score over all five particip with 
vertic line indic the standard deviat for select 
valu of thsd. what can be see from the figur be that 

similar threshold be use to achiev the top F1 score of 
about 0.94. It be interest to note that the standard 
deviat across all particip reach a minimum for a 
whole rang of valu around thi maximum. thi suggest 
that threshold that be also close to thi point can be 
select that still achiev robust detect performance. 

4.3.2 blink detect 

for blink detection, we develop the continu wavelet 
transform—blink detect (cwt-bd) algorithm. similarli to 
cwt-sd, the algorithm us a threshold thbd on the wavelet 
coeffici to detect blink in eogv. In contrast to a saccade, 
a blink be character by a sequenc of two larg peak in 
the coeffici vector directli follow each other: one 
positive, the other negative. the time between these peak be 
small than the minimum time between two success 
saccad rapidli perform in opposit direction. thi be 
because, typically, two saccad have at least a short fixat 
in between them. for thi reason, blink can be detect by 
appli a maximum threshold thbdt on thi time difference. 

We evalu our algorithm on eog signal record in a 
stationari set from five particip look at differ 
pictur (two femal and three males, age: 25-29 years, 
mean ¼ 26:4, sd ¼ 1:7). We label a total of 706 blink by 
visual inspect of the vertic eog signal component. with 
an averag blink rate of 12 blink per minute, thi correspond 
to about one hour of eye movement data. We evalu cwt- 
BD over sweep of it two main parameters: thbd ¼ 
100 . . . 50;000 (in 500 steps) and thbdt ¼ 100 . . . 1;000 m (in 
10 steps). 

the F1 score be calcul by match blink event 
with the annot ground truth. fig. 6 show the F1 score 
for five select valu of thbdt over all participants. cwt- 
BD perform best with thbdt between 400 and 600 m while 
reach top perform (f1 score: 0.94) use a thbdt of 
500 ms. time differ outsid thi range, a exemplarili 
show for 300 and 1,000 ms, be alreadi subject to a 
consider drop in performance. thi find nice 
reflect the valu for the averag blink durat cite 
earli from the literature. 

bull ET al.: eye movement analysi for activ recognit use electrooculographi 745 

fig. 4. evalu of the cwt-sd algorithm for both eog signal 
compon use a sweep of it main parameter, the threshold thsd. 
the figur plot the mean F1 score over all five participants; vertic 
line show the standard deviat for select thsd. maximum F1 score 
be indic by a dash line. 



4.4 analysi of repetit eye movement pattern 

activ such a read typic involv characterist 
sequenc of sever consecut eye movement [6]. We 
propos encod eye movement by map saccad 

with differ direct and amplitud to a discrete, 
character-bas representation. string of these charact 
be then collect in wordbook that be analyz to extract 
sequenc inform on repetit eye movement patterns. 

4.4.1 eye movement encod 

our algorithm for eye movement encod map the 
individu saccad inform from both eog compon 
onto a singl represent compris of 24 discret 
charact (see fig. 5a). thi produc a represent that 

can be more effici process and analyzed. 
the algorithm take the cwt-sd saccad from the 

horizont and vertic eog signal compon a it input. 
It first check for simultan saccad in both compon 
a these repres diagon eye movements. simultan 

saccad be character by overlap saccad segment 
in the time domain. If no simultan saccad be detected, 

the saccade’ charact be directli use to denot the eye 
movement. If two saccad be detected, the algorithm 
combin both accord to the follow scheme (see 
fig. 5b): the charact of two saccad with equal larg 
eog signal amplitud be merg to the charact exactli in 
between (e.g., “l” and “u” becom “n,” “r” and “u” becom 
“b”). If simultan saccad differ by more than 50 percent 
in eog signal amplitude, their charact be merg to the 
closest neighbor charact (e.g., “l” and “u” becom “o”). 
thi procedur encod each eye movement into a distinct 
character, thus, map saccad of both eog signal 
compon into one eye movement sequence. 

4.4.2 wordbook analysi 

base on the encod eye movement sequence, we propos a 
wordbook analysi to ass repetit eye movement 
pattern (see fig. 7). An eye movement pattern be defin a 
a string of l success characters. As an exampl with l ¼ 4, 
the pattern “lrbd” translat to larg left (l)! small right (r) 
! larg diagon right (b) ! small down (d). A slide 
window of length l and a step size of one be use to scan the 
eye movement sequenc for these patterns. each newli 
found eye movement pattern be add to the correspond 
wordbook wbl. for a pattern that be alreadi includ in 
wbl, it occurr count be increas by one. 

4.5 featur extract 

We extract four group of featur base on the detect 
saccades, fixations, blinks, and the wordbook of eye 
movement patterns. tabl 1 detail the name scheme 
use for all of these features. the featur be calcul 
use a slide window (window size wfe and step size sfe) 
on both eogh and eogv. from a pilot study, we be abl 
to fix wfe at 30 s and sfe at 0.25 s. 

featur calcul from saccad eye movement make 
up the larg proport of extract features. In total, 
there be 62 such featur compris the mean, variance, 
and maximum eog signal amplitud of saccad and the 
normal saccad rates. these be calcul for both 

746 ieee transact ON pattern analysi and machin intelligence, vol. 33, no. 4, april 2011 

fig. 5. (a) charact use to encod eye movement of differ 
direct and distance: dark gray indic basic and light gray diagon 
directions. (b) saccad detect in both eog signal compon and 
map to the eye movement sequenc of the jump point stimulus. 
simultan saccad in both compon be combin accord to 
their direct and amplitud (e.g., “l” and “u” becom “n,” and “r” and 
“u” becom “b”). 

fig. 6. evalu of the cwt-bd algorithm over a sweep of the blink 
threshold thbd, for five differ maximum time differ thbdt . the 
figur plot the mean F1 score over all participants; vertic line show 
the standard deviat for select thbd. maximum F1 score be indic 
by a dash line. 



eogh and eogv, for small and larg saccades, for saccad 
in posit or neg direction, and for all possibl 
combin of these. 

We calcul five differ featur use fixations: the 
mean and varianc of the eog signal amplitud within a 
fixation,; the mean and the varianc of fixat duration, 
and the fixat rate over window wfe. 

for blinks, we extract three features: blink rate and the 

mean and varianc of the blink duration. 
We use four wordbooks. thi allow u to account for all 

possibl eye movement pattern up to a length of four 
(l ¼ 4), with each wordbook contain the type and 
occurr count of all pattern found. for each wordbook 
we extract five features: the wordbook size, the maximum 
occurr count, the differ between the maximum and 
minimum occurr counts, and the varianc and mean of 
all occurr counts. 

4.6 featur select and classif 

for featur selection, we chose a filter scheme over the 
commonli use wrapper approach becaus of the low 
comput cost and thu shorter runtim give the 
larg data set. We use minimum redund maximum 
relev featur select for discret variabl [37], [38]. 
the mrmr algorithm select a featur subset of arbitrari 
size S that best character the statist properti of the 
give target class base on the ground truth labeling. In 
contrast to other method such a the F -test, mrmr also 
consid relationship between featur dure the selec- 
tion. among the possibl underli statist measur 
describ in the literature, mutual inform be show 
to yield the most promis result and be thu select in 
thi work. our particular mrmr implement combin 
the measur of redund and relev among class 
use the mutual inform differ (mid). 

for classification, we chose a linear support vector 
machine. our svm implement us a fast sequenti 
dual method for deal with multipl class [39], [40]. 
thi reduc train time consider while retain 
recognit performance. 

these two algorithm be combin into a hybrid featur 

select and classif method. In a first step, mrmr 

rank all avail featur (with S ¼ 90). dure classifica- 
tion, the size of the featur set be then optim with 

respect to recognit accuraci by sweep S. 

5 experi 

We design a studi to establish the feasibl of ear in a 

real-world setting. our scenario involv five office-bas 

activities—copi a text, read a print paper, take 

handwritten notes, watch a video, and brows the 

web—and period dure which particip take a rest (the 

null class). We chose these activ for three reasons. first, 

they be all commonli perform dure a typic work 

day. second, they exhibit interest eye movement pattern 

that be both structur divers and have vari level of 

complexity. We believ they repres the much broader 

rang of activ observ in daili life. finally, be abl 

to detect these activ use on-bodi sensor such a eog 

may enabl novel attent user interfac that take into 

account cognit aspect of interact such a user inter- 

ruptibl or level of task engagement. 
originally, we record 10 participants, but two be 

withdrawn due to poor signal quality: one particip have 

strong patholog nystagmus. nystagmu be a form of 

involuntari eye movement that be character by alternat- 

ing smooth pursuit in one direct and saccad movement 

in the other direction. the horizont eog signal compon 

turn out to be sever affect by the nystagmu and no 

reliabl saccad inform could be extracted. for the 

second participant, most probabl due to bad electrod 

placement, the eog signal be complet distorted. 
all of the remain eight particip (two femal and 

six males), age between 23 and 31 year (mean ¼ 26:1, 
sd ¼ 2:4) be daili comput users, report 6 to 14 hour 
of use per day (mean ¼ 9:5, sd ¼ 2:7). they be ask to 
follow two continu sequences, each compos of five 

different, randomli order activities, and a period of rest 

(see fig. 8b). for these, no activ be requir of the 

particip but they be ask not to engag in ani of the 

other activities. each activ (includ null) last about 

five minutes, result in a total data set of about eight hours. 

bull ET al.: eye movement analysi for activ recognit use electrooculographi 747 

fig. 7. exampl wordbook analysi for eye movement pattern of length 
l ¼ 3. A slide window scan a sequenc of eye movement encod 
into charact for repetit patterns. newli found pattern be add to 
the wordbook; otherwise, onli the occurr count (last column) be 
increas by one. 

tabl 1 
name scheme for the featur use in thi work 

for a particular feature, e.g., s-ratesphor, the capit letter repres 
the group—saccad (s), blink (b), fixat (f), or wordbook (w)—and 
the combin of abbrevi after the dash describ the particular 
type of featur and the characterist it covers. 



5.1 apparatu 

We use a commerci eog device, the mobi8, from 
twent medic system intern (tmsi). It be worn 
on a belt around each participant’ waist and record a 
four-channel eog at a sampl rate of 128 hz. particip 
be observ by an assist who annot activ 
chang with a wireless remot control. data record and 
synchron be handl by the context recognit 
network toolbox [41]. 

eog signal be pick up use an array of five 24 mm 
ag/agcl wet electrod from tyco healthcar place 
around the right eye. the horizont signal be collect 
use one electrod on the nose and anoth directli across 
from thi on the edg of the right eye socket. the vertic 
signal be collect use one electrod abov the right 
eyebrow and anoth on the low edg of the right eye 
socket. the fifth electrode, the signal reference, be place 
in the middl of the forehead. five particip (two femal 
and three males) wore spectacl dure the experiment. for 
these participants, the nose electrod be move to the side 
of the left eye to avoid interfer with the spectacl (see 
fig. 8a). 

the experi be carri out in an offic dure 
regular work hours. particip be seat in front of 
two adjac 17 inch flat screen with a resolut of 1;280� 
1;024 pixel on which a browser, a video player, a word 
processor, and text for copi be on-screen and readi 
for use. free movement of the head and upper bodi be 
possibl throughout the experiment. 

5.2 procedur 

for the text copi task, the origin document be show 
on the right screen with the word processor on the left 
screen. particip could copi the text in differ ways. 
some touch type and onli check for error in the text 
from time to time; other continu switch attent 
between the screen or the keyboard while typing. becaus 
the screen be more than half a meter from the 
participants’ faces, the video be show full screen to elicit 
more distinct eye movements. for the brows task, no 
constraint be impos concern the type of websit or 
the manner of interaction. for the read and write tasks, 
a book (12 pt, one column with pictures) and a pad with a 
pen be provided. 

5.3 paramet select and evalu 

the same saccad and blink detect paramet be use 
throughout the evaluation: thbd ¼ 23;438, thbdt ¼ 390 ms, 
thsdlarg ¼ 13;750, and thsdsmall ¼ 2;000. the select of thsdsmall 
be base on the typic length of a short scan saccad 
dure reading, and thsdlarg on the length of a typic 
newlin movement. 

classif and featur select be evalu use 
a leave-one-person-out scheme: We combin the data set 
of all but one particip and use thi for training; test 
be do use both data set of the remain participant. 
thi be repeat for each participant. the result train 
and test set be standard to have zero mean and a 
standard deviat of one. featur select be alway 
perform sole on the train set. the two main 
paramet of the svm algorithm, the cost C and the 
toler of termin criterion �, be fix to C ¼ 1 and 
� ¼ 0:1. for each leave-one-person-out iteration, the predic- 
tion vector return by the svm classifi be smooth 
use a slide major window. it main parameter, the 
window size wsm, be obtain use a paramet sweep 
and fix at 2.4 s. 

6 result 

6.1 classif perform 

svm classif be score use a frame-by-fram 
comparison with the annot ground truth. for specif 
result on each particip or on each activity, class-rel 
precis and recal be used. 

tabl 2 show the averag precis and recall, and the 
correspond number of featur select for each 
participant. the number of featur use vari from onli 
nine featur (p8) up to 81 featur (p1). the mean 
perform over all particip be 76.1 percent preci- 
sion and 70.5 percent recall. P4 report the bad result, 
with both precis and recal below 50 percent. In contrast, 
P7 achiev the best result, indic by recognit 

748 ieee transact ON pattern analysi and machin intelligence, vol. 33, no. 4, april 2011 

fig. 8. (a) electrod placement for eog data collect (h: horizontal, 
v: vertical, and r: reference). (b) continu sequenc of five typic 
offic activities: copi a text, read a print paper, take 
handwritten notes, watch a video, brows the web, and period 
of no specif activ (the null class). 

tabl 2 
precision, recall, and the correspond number of featur select by the hybrid mrmr/svm method for each particip 

the participants’ gender be give in brackets; best and bad case result be indic in bold. 



perform in the 80 and 90 and use a moderate-s 
featur set. 

fig. 9 plot the classif result in term of precis 
and recal for each activ and participant. the best result 
approach the top right corner, while bad result be close 
to the low left. for most activities, precis and recal fall 
within the top right corner. recognit of read and 
copying, however, complet fail for p4, and brows 
also show notic low precision. similar but less 

strong characterist appli for the reading, writing, and 
brows task for p5. 

the sum confus matrix from all participants, 
normal across ground truth rows, be give in fig. 10. 
correct recognit be show on the diagonal; substitut 
error be off-diagonal. the larg between-class substitu- 

tion error not involv null fall between 12 and 
13 percent of their class times. most of these error involv 
brows that be fals return dure 13 percent each of 

read, write, and copi activities. A similar amount be 
substitut by read dure brows time. 

6.2 eye movement featur 

We first analyz how mrmr rank the featur on each 
of the eight leave-one-person-out train sets. the rank of a 
featur be the posit at which mrmr select it within a 
set. the posit correspond to the import with which 
mrmr ass the feature’ abil to discrimin between 
class in combin with the featur rank befor it. 
fig. 11 show the top 15 featur accord to the median 
rank over all set (see tabl 1 for a descript of the type 
and name of the features). each vertic bar repres the 
spread of mrmr ranks: for each feature, there be one rank 
per train set. the most use featur be those found 
with the high rank (close to one) for most train sets, 
indic by shorter bars. some featur be not alway 
includ in the final result (e.g., featur 63 onli appear in 
five sets). equally, a use featur that be rank lowli by 
mrmr might be the one that improv a classif (e.g., 

bull ET al.: eye movement analysi for activ recognit use electrooculographi 749 

fig. 9. precis and recal for each activ and participant. mean 

perform (p1 to p8) be mark by a star. 

fig. 10. sum confus matrix from all participants, normal 

across ground truth rows. 

fig. 11. the top 15 featur select by mrmr for all eight train sets. the x-axi show featur number and group; the key on the right show the 
correspond featur name a describ in tabl 1; the y-axi show the rank (top = 1). for each feature, the bar show: the total number of 
train set for which the featur be chosen (bold number at the top), the rank of the featur within each set (dots, with a number repres the 
set count), and the median rank over all set (black star). for example, a use featur be 47 (s)—a saccad featur select for all sets, in seven of 
which it be rank one or two; less use be 63 (b)—a blink featur use in onli five set and rank between 4 and 29. 



featur 68 be spread between rank five and 26, but be 
includ in all eight sets). 

thi analysi reveal that the top three features, a 
judg by high rank for all sets, be all base on 
horizont saccades: 47 (s-ratesphor), 56 (s-maxampphor), 
and 10 (s-meanampshor). featur 68 (f-rate) be use in all 
sets, seven of which rank it highly. featur 63 (b-rate) be 
select for five out of the eight sets, onli one of which 
give it a high rank. wordbook featur 77 (w-maxcount- 
l2) and 85 (w-maxcount-l3) be not use in one of the sets, 
but they be highli rank by the other seven. 

We perform an addit studi into the effect of 
optim mrmr for each activ class. We combin all 
train set and perform a one-versus-mani mrmr for 
each non-nul activity. the top five featur select 
dure thi evalu be show in tabl 3. for example, 
the tabl reveal that read and brows can be 
describ use wordbook features. write requir addi- 
tional fixat features. watch video be character by 
a mixtur of fixat and saccad featur for all direct 
and—a reading—th blink rate, while copi involv 
mainli horizont saccad features. 

7 discuss 

7.1 robust across particip 

the develop algorithm for detect saccad and blink 
in eog signal prove robust and achiev F1 score of up 
to 0.94 across sever peopl (see figs. 4 and 6). for the 
experiment evaluation, the paramet of both algorithm 
be fix to valu common for all participants; the same 
appli to the paramet of the featur select and 
classif algorithms. under these conditions, despit 
person-independ training, six out of the eight partici- 
pant return best averag precis and recal valu of 
between 69 and 93 percent. 

two participants, however, return result that be 
low than 50 percent. On closer inspect of the raw eye 
movement data, it turn out that for both the eog, signal 
qualiti be poor. chang in signal amplitud for saccad 
and blinks—upon which featur extract and thu 
recognit perform directli depend—wer not distinc- 
tive enough to be reliabl detected. As be found in an earli 
studi [6], dri skin or poor electrod placement be the most 
like culprits. still, the achiev recognit perform be 
promis for eye movement analysi to be implement in 
real-world applications, for example, a part of a read 
assistant, or for monitor workload to ass the risk of 
burnout syndrome. for such applications, recognit per- 
formanc may be further increas by combin eye move- 
ment analysi with addit sens modalities. 

7.2 result for each activ 

As might have be expected, read be detect with 
compar accuraci to that report earli [6]. however, 
the method use be quit different. the string match 
approach appli in the earli studi make use of a specif 
“read pattern.” that approach be not suit for activ 
involv less homogen eye movement patterns. for 
example, one would not expect to find a similarli uniqu 
pattern for brows or watch a video a there exist for 
reading. thi be becaus eye movement show much more 
variabl dure these activ a they be driven by an 
ever-chang stimulus. As show here, the feature-bas 
approach be much more flexibl and scale good with the 
number and type of activ that be to be recognized. 

accordingly, we be now abl to recogn four 
addit activities—web browsing, write on paper, 
watch video, and copi text—with almost, or above, 
70 percent precis and 70 percent recall. particularli 
impress be video, with an averag precis of 88 percent 
and recal of 80 percent. thi be indic of a task where 
the user might be concentr on a rel small field of 
view (like reading), but follow a typic unstructur 
path (unlik reading). similar exampl outsid the current 
studi might includ interact with a graphic user 
interfac or watch televis at home. write be similar 
to read in that the eye follow a structur path, albeit 
at a slow rate. write involv more eye “distractions”— 
when the person look up to think for example. brows 
be recogn less well over all particip (averag 
precis 79 percent and recal 63 percent)—but with a 
larg spread between people. A like reason for thi be that 
it be not onli unstructured, but also it involv a varieti of 
subactivities—includ reading—that may need to be 
modeled. the copi activity, with an averag precis of 
76 percent and a recal of 66 percent, be repres of 
activ with a small field of view that includ regular 
shift in attent (in thi case, to anoth screen). A 
compar activ outsid the chosen offic scenario 
might be driving, where the eye be on the road ahead 
with occasion check to the side mirrors. finally, the 
null class return a high recal of 81 percent. however, 
there be mani fals return (activ fals negatives) for 
half of the participants, result in a precis of onli 
66 percent. 

three of these activities—writing, copying, and brows 
—all includ section of reading. from quick check over 
what have be write or copi to longer perus of onlin 
text, read be a pervas subact in thi scenario. thi be 
confirm by the rel high rate of confus error 
involv reading, a show in fig. 10. 

750 ieee transact ON pattern analysi and machin intelligence, vol. 33, no. 4, april 2011 

tabl 3 
the top five featur select by mrmr for each activ over all train set (see tabl 1 for detail on featur names) 



7.3 featur group 

the featur group select by mrmr provid a snapshot 
of the type of eye movement featur use for activ 
recognition. 

featur from three of the four propos groups— 
saccade, fixation, and wordbook—wer all promin 
repres in our study. the fact that each group cover 
complementari aspect of eye movement be promis for 
the gener use of these featur for other ear problems. 
note that no one featur type perform well alone. the best 
result be obtain use a mixtur of differ features. 
among these, the fixat rate be alway selected. thi 
result be akin to that of canosa, who found that both fixat 
durat and saccad amplitud be strong indic of 
certain activ [42]. 

featur deriv from blink be less repres in the 
top ranks. one explan for thi be that for the short activ 
durat of onli five minutes, the particip do not 
becom fulli engag in the tasks, and be thu less like 
to show the characterist blink rate variat suggest by 
palomba et al. [43]. these featur may be found to be more 
discrimin for longer durat activities. coupl with 
the eas by which they be extracted, we believ blink 
featur be still promis for futur work. 

7.4 featur for each activ class 

the analysi of the most import featur for each activ 
class be particularli revealing. 

read be a regular pattern character by a specif 
sequenc of saccad and short fixat of similar duration. 
consequently, mrmr chose mostli wordbook featur 
describ eye movement sequenc in it top ranks, a 
well a a featur describ the fixat durat variance. 
the fifth feature, the blink rate, reflect that, for read a 
an activ of high visual engagement, peopl tend to blink 
less [43]. 

brows be structur divers and—depend on the 
websit be viewed—may be compris of differ 
activities, e.g., watch a video, typing, or look at a 
picture. In addit to the small, horizont saccad rate, 
mrmr also select sever workbook featur of vari 
lengths. thi be probabl due to our participants’ brows 
activ contain mostli sequenc of variabl length 
read such a scan headlin or search for a 
product in a list. 

write be similar to reading, but requir great fixat 
durat (it take longer to write a word than to read it) and 
great variance. mrmr correspondingli select averag 
fixat durat and it varianc a well a a wordbook 
feature. however, write be also character by short 
think pauses, dure which peopl invari look up. 
thi correspond extrem well to the choic of the fixat 
featur that captur varianc in vertic position. 

watch a video be a highli unstructur activity, but be 
carri out within a narrow field of view. the lack of 
wordbook featur reflect this, a do the mix select 
of featur base on all three types: varianc of both 
horizont and vertic fixat positions, small posit and 
neg saccad movements, and blink rate. the use of 
blink rate like reflect the tendenc toward blink inhibi- 
tion when perform an engag yet sedentari task [43]. 

finally, copi involv mani back and forth saccad 
between screens. mrmr reflect thi by choos a mixtur 

of small and larg horizont saccad features, a well a 
varianc in horizont fixat positions. 

these result suggest that for task that involv a know 
set of specif activ classes, recognit can be optim 
by onli choos featur know to best describ these 
classes. It remain to be investig how well such 
prototyp featur discrimin between activ class 
with veri similar characteristics. 

7.5 activ segment use eye movement 

segmentation—th task of spot individu activ 
instanc in continu data—remain an open challeng 
in activ recognition. We found that eye movement can 
be use for activ segment on differ level 
depend on the timescal of the activities. the low 
level of segment be that of individu saccad that 
defin eye movement in differ directions—“left,” 
“right,” and so on. An exampl for thi be the end-of-lin 
“carriag return” eye movement perform dure reading. 
the next level includ more complex activ that involv 
sequenc compos of a small number of saccades. for 
these activities, the wordbook analysi propos in thi 
work may prove suitable. In earli work, such short eye 
movement patterns, so-cal eye gestures, be success- 
fulli use for eye-bas human-comput interact [44]. 
At the high level, activ be character by complex 
combin of eye movement sequenc of potenti 
arbitrari length. unless wordbook be use that span these 
long sequences, dynam model of activ be required. 
for this, it would be interest to investig method such 
a hidden markov model (hmm), condit random 
field (crf), or an approach base on eye movement 
grammars. these method would allow u to model eye 
movement pattern at differ hierarch levels, and to 
spot composit activ from larg stream of eye move- 
ment data more easily. 

7.6 limit 

one limit of the current work be that the experiment 
scenario consid onli a hand of activities. It be 
import to note, however, that the recognit architec- 
ture and featur set be develop independ of these 
activities. In addition, the method be not limit to eog. all 
featur can be extract equal well from eye movement 
data record use a video-bas eye tracker. thi 
suggest that our approach be applic to other activities, 
settings, and eye track techniques. 

the studi also reveal some of the complex one might 
face in use the eye a a sourc of inform on a person’ 
activity. the ubiqu of the eyes’ involv in everyth 
a person do mean that it be challeng to annot 
precis what be be “done” at ani one time. It be also a 
challeng to defin a singl identifi activity. read be 
perhap one of the easi to captur becaus of the intens 
of eye focu that be requir and the well-defin path that 
the eye follow. A task such a web brows be more 
difficult becaus of the wide varieti of differ eye move- 
ment involved. It be challenging, too, to separ relev 
eye movement from momentari distractions. 

these problem may be solved, in part, by use video 
and gaze track for annotation. activ from the current 
scenario could be redefin at a small timescale, break 
brows into small activ such a “use scroll bar,” 

bull ET al.: eye movement analysi for activ recognit use electrooculographi 751 



“read,” “look at image,” or “type.” thi would also allow u 
to investig more complic activ outsid the office. 
An altern rout be to studi activ at larg timescales, 
to perform situat analysi rather than recognit of 
specif activities. long-term eye movement features, e.g., 
the averag eye movement veloc and blink rate over one 
hour, might reveal whether a person be walk along an 
empti or busi street, whether they be at their desk working, 
or whether they be at home watch television. annot 
will still be an issue, but one that mayb allevi use 
unsupervis or self-label method [21], [45]. 

7.7 consider for futur work 

addit eye movement characterist that be potenti 
use for activ recognition—such a pupil dilation, 
microsaccades, vestibulo-ocular reflex, or smooth pursuit 
movements—wer not use here becaus of the difficulti in 
measur them with eog. these characterist be still 
worth investig in the futur a they may carri informa- 
tion that complement that avail in the current work. 

eye movement also reveal inform on cognit 
process of visual perception, such a visual memory, 
learning, or attention. If it be possibl to infer these 
process from eye movements, thi may lead to cognition- 
awar system that be abl to sens and adapt to a person’ 
cognit state [46]. 

8 conclus 

thi work reveal two main find for activ recognit 
use eye movement analysis. first, we show that eye 
movement alone, i.e., without ani inform on gaze, 
can be use to success recogn five offic activities. 
We argu that the develop methodolog can be extend 
to other activities. second, good recognit result be 
achiev use a mixtur of featur base on the 
fundament of eye movements. sequenc inform on 
eye movement patterns, in the form of a wordbook analysis, 
also prove use and can be extend to captur 
addit statist properties. differ recognit task 
will like requir differ combin of these features. 

the import of these find lie in their signific 
for eye movement analysi to becom a gener tool for the 
automat recognit of human activity. 

refer 
[1] S. mitra and T. acharya, “gestur recognition: A survey,” ieee 

trans. systems, man, and cybernetics, part C: applic and rev., 
vol. 37, no. 3, pp. 311-324, may 2007. 

[2] P. turaga, R. chellappa, v.s. subrahmanian, and O. udrea, 
“machin recognit of human activities: A survey,” ieee 
trans. circuit and system for video technology, vol. 18, no. 11, 
pp. 1473-1488, nov. 2008. 

[3] B. najafi, K. aminian, A. paraschiv-ionescu, F. loew, c.j. bula, 
and P. robert, “ambulatori system for human motion analysi 
use a kinemat sensor: monitor of daili physic activ 
in the elderly,” ieee trans. biomed eng., vol. 50, no. 6, pp. 711- 
723, june 2003. 

[4] j.a. ward, P. lukowicz, G. tröster, and t.e. starner, “activ 
recognit of assembl task use body-worn microphon 
and accelerometers,” ieee trans. pattern analysi and machin 
intelligence, vol. 28, no. 10, pp. 1553-1567, oct. 2006. 

[5] N. kern, B. schiele, and A. schmidt, “recogn context for 
annot a live life recording,” person and ubiquit 
computing, vol. 11, no. 4, pp. 251-263, 2007. 

[6] A. bulling, j.a. ward, H. gellersen, and G. tröster, “robust 
recognit of read activ in transit use wearabl 
electrooculography,” proc. sixth int’l conf. pervas computing, 
pp. 19-37, 2008. 

[7] s.p. liversedg and j.m. findlay, “saccad eye movement and 
cognition,” trend in cognit sciences, vol. 4, no. 1, pp. 6-14, 2000. 

[8] j.m. henderson, “human gaze control dure real-world scene 
perception,” trend in cognit sciences, vol. 7, no. 11, pp. 498-504, 
2003. 

[9] A. bulling, D. roggen, and G. tröster, “wearabl eog goggles: 
seamless sens and context-awar in everyday environ- 
ments,” J. ambient intellig and smart environments, vol. 1, no. 2, 
pp. 157-171, 2009. 

[10] A. bulling, j.a. ward, H. gellersen, and G. tröster, “ey 
movement analysi for activ recognition,” proc. 11th int’l 
conf. ubiquit computing, pp. 41-50, 2009. 

[11] Q. ding, K. tong, and G. li, “develop of an eog (electro- 
oculography) base human-comput interface,” proc. 27th int’l 
conf. eng. in medicin and biolog soc., pp. 6829-6831, 2005. 

[12] Y. chen and w.s. newman, “A human-robot interfac base on 
electrooculography,” proc. ieee int’l conf. robot and automa- 
tion, vol. 1, pp. 243-248, 2004. 

[13] w.s. wijesoma, k.s. wee, o.c. wee, a.p. balasuriya, k.t. san, and 
k.k. soon, “eog base control of mobil assist platform for 
the sever disabled,” proc. ieee int’l conf. robot and 
biomimetics, pp. 490-494, 2005. 

[14] R. barea, L. boquete, M. mazo, and E. lopez, “system for assist 
mobil use eye movement base on electrooculography,” 
ieee trans. neural system and rehabilit eng., vol. 10, no. 4, 
pp. 209-218, dec. 2002. 

[15] m.m. hayho and d.h. ballard, “ey movement in natur 
behavior,” trend in cognit sciences, vol. 9, pp. 188-194, 2005. 

[16] s.s. hacisalihzade, l.w. stark, and j.s. allen, “visual percept 
and sequenc of eye movement fixations: A stochast model 
approach,” ieee trans. systems, man, and cybernetics, vol. 22, no. 
3, pp. 474-481, may/jun 1992. 

[17] M. elhelw, M. nicolaou, A. chung, g.-z. yang, and m.s. atkins, 
“A gaze-bas studi for investig the percept of visual 
realism in simul scenes,” acm trans. appli perception, 
vol. 5, no. 1, pp. 1-20, 2008. 

[18] L. dempere-marco, X. hu, s.l.s. macdonald, s.m. ellis, d.m. 
hansell, and g.-z. yang, “the use of visual search for knowl- 
edg gather in imag decis support,” ieee trans. medic 
imaging, vol. 21, no. 7, pp. 741-754, juli 2002. 

[19] d.d. salvucci and j.r. anderson, “autom eye-mov 
protocol analysis,” human-comput interaction, vol. 16, no. 1, 
pp. 39-86, 2001. 

[20] D. abowd, A. dey, R. orr, and J. brotherton, “context-awar 
in wearabl and ubiquit computing,” virtual reality, vol. 3, 
no. 3, pp. 200-211, 1998. 

[21] L. bao and s.s. intille, “activ recognit from user-annot 
acceler data,” proc. second int’l conf. pervas computing, 
pp. 1-17, 2004. 

[22] B. logan, J. healey, M. philipose, E. tapia, and s.s. intille, “A 
long-term evalu of sens modal for activ recog- 
nition,” proc. ninth int’l conf. ubiquit computing, pp. 483-500, 
2007. 

[23] f.t. keat, S. ranganath, and y.v. venkatesh, “ey gaze base 
read detection,” proc. ieee conf. converg technolog for the 
asia-pacif region, vol. 2, pp. 825-828, 2003. 

[24] M. brown, M. marmor, and vaegan, “iscev standard for clinic 
electro-oculographi (eog),” documenta ophthalmologica, vol. 113, 
no. 3, pp. 205-212, 2006. 

[25] a.t. duchowski, eye track methodology: theori and practice. 
springer-verlag new york, inc., 2007. 

[26] b.r. manor and E. gordon, “defin the tempor threshold for 
ocular fixat in free-view visuocognit tasks,” 
J. neurosci methods, vol. 128, nos. 1/2, pp. 85-93, 2003. 

[27] c.n. karson, k.f. berman, e.f. donnelly, w.b. mendelson, j.e. 
kleinman, and r.j. wyatt, “speaking, thinking, and blinking,” 
psychiatri research, vol. 5, no. 3, pp. 243-246, 1981. 

[28] R. schleicher, N. galley, S. briest, and L. galley, “blink and 
saccad a indic of fatigu in sleepi warnings: look 
tired?” ergonomics, vol. 51, no. 7, pp. 982-1010, 2008. 

[29] h.r. schiffman, sensat and perception: An integr approach, 
fifth ed. john wiley & sons, 2001. 

752 ieee transact ON pattern analysi and machin intelligence, vol. 33, no. 4, april 2011 



[30] j.j. gu, M. meng, A. cook, and G. faulkner, “A studi of natur 
eye movement detect and ocular implant movement control 
use process eog signals,” proc. ieee int’l conf. robot and 
automation, vol. 2, pp. 1555-1560, 2001. 

[31] N. pan, v.m. I, m.p. un, and p.s. hang, “accur remov of 
baselin wander in ecg use empir mode decomposition,” 
proc. joint meet sixth int’l symp. noninvas function sourc 
imag of the brain and heart and the int’l conf. function 
biomed imaging, pp. 177-180, 2007. 

[32] v.s. chouhan and s.s. mehta, “total remov of baselin drift 
from ecg signal,” proc. 17th int’l conf. comput theori and 
applications, pp. 512-515, 2007. 

[33] L. xu, D. zhang, and K. wang, “wavelet-bas cascad 
adapt filter for remov baselin drift in puls waveforms,” 
ieee trans. biomed eng., vol. 52, no. 11, pp. 1973-1975, nov. 
2005. 

[34] m.a. tinati and B. mozaffary, “A wavelet packet approach to 
electrocardiograph baselin drift cancellation,” int’l J. biomed 
imaging, vol. 2006, pp. 1-9, 2006. 

[35] d.l. donoho, “de-nois by soft-thresholding,” ieee trans. 
inform theory, vol. 41, no. 3, pp. 613-627, may 1995. 

[36] d.d. salvucci and j.h. goldberg, “identifi fixat and 
saccad in eye-track protocols,” proc. symp. eye track 
research & applications, pp. 71-78, 2000. 

[37] H. peng, F. long, and C. ding, “featur select base on 
mutual inform criteria of max-dependency, max-relevance, 
and min-redundancy,” ieee trans. pattern analysi and machin 
intelligence, vol. 27, no. 8, pp. 1226-1238, aug. 2005. 

[38] H. peng, “mrmr featur select toolbox for matlab,” 
http://research.janelia.org/peng/proj/mrmr/, feb. 2008. 

[39] K. crammer and Y. singer, “ultraconserv onlin algorithm 
for multiclass problems,” J. machin learn research, vol. 3, 
pp. 951-991, 2003. 

[40] c.-j. lin, “liblinear—a librari for larg linear classifica- 
tion,” http://www.csie.ntu.edu.tw/~cjlin/liblinear/, feb. 2008. 

[41] D. bannach, P. lukowicz, and O. amft, “rapid prototyp of 
activ recognit applications,” ieee pervas computing, 
vol. 7, no. 2, pp. 22-31, apr.-jun 2008. 

[42] r.l. canosa, “real-world vision: select percept and task,” 
acm trans. appli perception, vol. 6, no. 2, pp. 1-34, 2009. 

[43] D. palomba, M. sarlo, A. angrilli, A. mini, and L. stegagno, 
“cardiac respons associ with affect process of 
unpleas film stimuli,” int’l J. psychophysiology, vol. 36, no. 1, 
pp. 45-57, 2000. 

[44] A. bulling, D. roggen, and G. tröster, “it’ in your eyes— 
toward context-awar and mobil hci use wearabl 
eog goggles,” proc. 10th int’l conf. ubiquit computing, pp. 84- 
93, 2008. 

[45] T. huynh, M. fritz, and B. schiele, “discoveri of activ pattern 
use topic models,” proc. 10th int’l conf. ubiquit computing, 
pp. 10-19, 2008. 

[46] A. bulling, D. roggen, and G. tröster, “what’ in the eye for 
context-awareness?” ieee pervas computing, 2010, 
doi:10.1109/mprv.2010.49. 

andrea bull receiv the msc degre in 
comput scienc from the technic univers 
of karlsruhe, germany, in 2006, and the phd 
degre in inform technolog and electr 
engin from the swiss feder institut of 
technolog (eth) zurich, switzerland, in 2010. 
hi research interest be in cognition-awar 
system and multimod activ and context 
recognit with applic in ubiquit com- 
put and human-comput interaction. He be 

current a postdoctor research associ at the univers of cam- 
bridge, unit kingdom, and lancast university, unit kingdom, 
fund by a feodor lynen research fellowship of the alexand von 
humboldt foundation, germany. He be a student member of the ieee. 
for more details, see http://www.andreas-bulling.eu/. 

jami A. ward receiv the beng degre with 
joint honor in comput scienc and electron 
from the univers of edinburgh, scotland, in 
2000, and the phd degre in activ recognit 
(ar) use body-worn sensor from the swiss 
feder institut of technolog (eth) zurich in 
2006. He spent a year work a an analogu 
circuit design in austria befor join the 
wearabl comput lab at eth in zurich, 
switzerland. In addit to hi work on ar, he be 

activ involv in develop improv method for evalu AR 
performance. He be current a research associ at lancast 
university, unit kingdom. 

han gellersen receiv the msc and phd 
degre in comput scienc from the technic 
univers of karlsruhe, germany, in 1996. from 
1993 to 1996, he be a research assist at the 
telemat institute, and from 1996 to 2000, be 
a director of the telecooper office. sinc 
2001, he have be a professor for interact 
system at lancast university, unit king- 
dom. hi research interest be in ubiquit 
comput and context-awar systems. He be 

activ involv in the format of the ubiquit comput research 
commun and have initi the ubicomp confer series. He also 
serf a an editor of the person and ubiquit comput journal. 

gerhard tröster receiv the msc degre in 
electr engin from the technic 
univers of karlsruhe, germany, in 1978, 
and the phd degre in electr engin 
from the technic univers of darmstadt, 
germany, in 1984. dure eight year at 
telefunken, germany, he be respons 
for variou research project focu on key 
compon of digit telephony. sinc 1993, 
he have be a professor for wearabl 

comput at the swiss feder institut of technolog (eth) in 
zurich, switzerland. hi field of research includ wearabl 
computing, smart textiles, electron packaging, and miniatur 
digit signal processing. He be a senior member of the ieee. 

. for more inform on thi or ani other comput topic, 
pleas visit our digit librari at www.computer.org/publications/dlib. 

bull ET al.: eye movement analysi for activ recognit use electrooculographi 753 


