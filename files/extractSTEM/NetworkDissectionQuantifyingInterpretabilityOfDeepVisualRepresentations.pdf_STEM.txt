


















































network dissection: 
quantifi interpret of deep visual represent 

david bau∗, bolei zhou∗, aditya khosla, aud oliva, and antonio torralba 
csail, mit 

{davidbau, bzhou, khosla, oliva, torralba}@csail.mit.edu 

abstract 

We propos a gener framework call network dissec- 
tion for quantifi the interpret of latent representa- 
tion of cnn by evalu the align between individ- 
ual hidden unit and a set of semant concepts. given ani 
cnn model, the propos method draw on a broad data 
set of visual concept to score the semant of hidden unit 
at each intermedi convolut layer. the unit with 
semant be give label across a rang of objects, parts, 
scenes, textures, materials, and colors. We use the propos 
method to test the hypothesi that interpret of unit 
be equival to random linear combin of units, then 
we appli our method to compar the latent represent 
of variou network when train to solv differ super- 
vise and self-supervis train tasks. We further analyz 
the effect of train iterations, compar network train 
with differ initializations, examin the impact of network 
depth and width, and measur the effect of dropout and batch 
normal on the interpret of deep visual represen- 
tations. We demonstr that the propos method can shed 
light on characterist of cnn model and train method 
that go beyond measur of their discrimin power. 

1. introduct 
observ of hidden unit in larg deep neural net- 

work have reveal that human-interpret concept some- 
time emerg a individu latent variabl within those net- 
works: for example, object detector unit emerg within net- 
work train to recogn place [40]; part detector emerg 
in object classifi [11]; and object detector emerg in gen- 
er video network [32] (fig. 1). thi intern structur 
have appear in situat where the network be not con- 
strain to decompos problem in ani interpret way. 

the emerg of interpret structur suggest that 
deep network may be learn disentangl represent 
spontaneously. while it be commonli understood that a net- 
work can learn an effici encod that make econom 
use of hidden variabl to distinguish it states, the appear- 

lamp in place net wheel in object net peopl in video net 

figur 1. unit 13 in [40] (classifi places) detect tabl lamps. 
unit 246 in [11] (classifi objects) detect bicycl wheels. A 
unit in [32] (self-supervis for gener videos) detect people. 

anc of a disentangl represent be not well-understood. 
A disentangl represent align it variabl with a 
meaning factor of the underli problem structure, 
and encourag disentangl represent be a signific 
area of research [5]. If the intern represent of a deep 
network be partli disentangled, one possibl path for under- 
stand it mechan be to detect disentangl structure, 
and simpli read out the separ factors. 

however, thi propos rais question which we address 
in thi paper: 
• what be a disentangl representation, and how can it 

factor be quantifi and detected? 
• Do interpret hidden unit reflect a special align 

of featur space, or be interpret a chimera? 
• what condit in state-of-the-art train lead to rep- 

resent with great or lesser entanglement? 
To examin these issues, we propos a gener analyt 

framework, network dissection, for interpret deep visual 
represent and quantifi their interpretability. us- 
ing broden, a broadli and dens label data set, our 
framework identifi hidden units’ semant for ani give 
cnn, then align them with human-interpret concepts. 
We evalu our method on variou cnn (alexnet, vgg, 
googlenet, resnet) train on object and scene recognition, 
and show that emerg interpret be an axis-align 
properti of a represent that can be destroy by rotat 
without affect discrimin power. We further examin 
how interpret be affect by train data sets, train 
techniqu like dropout [28] and batch normal [13], 
and supervis by differ primari tasks. 

∗ indic equal contribut 
sourc code and data avail at http://netdissect.csail.mit.edu 

1 

http://netdissect.csail.mit.edu 


1.1. relat work 

A grow number of techniqu have be develop to 
understand the intern represent of convolut neu- 
ral network through visualization. the behavior of a cnn 
can be visual by sampl imag patch that maxim 
activ of hidden unit [37, 40], or by use variant of 
backpropag to identifi or gener salient imag fea- 
ture [17, 26, 37]. the discrimin power of hidden layer 
of cnn featur can also be understood by isol por- 
tion of networks, transfer them or limit them, and 
test their capabl on special problem [35, 24, 2]. 
visual digest the mechan of a network down to 
imag which themselv must be interpreted; thi motiv 
our work which aim to match represent of cnn with 
label interpret directli and automatically. 

most relev to our current work be explor of the 
role of individu unit insid neural networks. In [40] hu- 
man evalu be use to determin that individu unit 
behav a object detector in a network that be train to 
classifi scenes. [20] automat gener prototyp 
imag for individu unit by learn a featur invers 
mapping; thi contrast with our approach of automat 
assign concept labels. recent [3] suggest an ap- 
proach to test the intermedi layer by train sim- 
ple linear probes, which analyz the inform dynam 
among layer and it effect on the final prediction. 

2. network dissect 
how can we quantifi the clariti of an idea? the notion of 

a disentangl represent rest on the human percept 
of what it mean for a concept to be mix up. therefor 
when we quantifi interpretability, we defin it in term of 
align with a set of human-interpret concepts. our 
measur of interpret for deep visual representa- 
tion proce in three steps: 

1. identifi a broad set of human-label visual concepts. 

2. gather hidden variables’ respons to know concepts. 

3. quantifi align of hidden variable−concept pairs. 

thi three-step process of network dissect be reminisc 
of the procedur use by neuroscientist to understand simi- 
lar represent question in biolog neuron [23]. sinc 
our purpos be to measur the level to which a represent 
be disentangled, we focu on quantifi the correspond 
between a singl latent variabl and a visual concept. 

In a fulli interpret local cod such a a one-hot- 
encoding, each variabl will match exactli with one human- 
interpret concept. although we expect a network to learn 
partial nonloc represent in interior layer [5], and 
past experi show that an emerg concept will often 
align with a combin of a sever hidden unit [11, 2], 

street (scene) flower (object) headboard (part) 

swirli (texture) pink (color) metal (material) 

figur 2. sampl from the broden dataset. the ground truth for 
each concept be a pixel-wis dens annotation. 

our present aim be to ass how well a represent be 
disentangled. therefor we measur the align between 
singl unit and singl interpret concepts. thi do 
not gaug the discrimin power of the representation; 
rather it quantifi it disentangl interpretability. As we 
will show in sec. 3.2, it be possibl for two represent 
of perfectli equival discrimin power to have veri 
differ level of interpretability. 

To ass the interpret of ani give cnn, we draw 
concept from a new broadli and dens label imag data 
set that unifi label visual concept from a heterogen 
collect of label data sources, describ in sec. 2.1. We 
then measur the align of each hidden unit of the cnn 
with each concept by evalu the featur activ of each 
individu unit a a segment model for each concept. To 
quantifi the interpret of a layer a a whole, we count 
the number of distinct visual concept that be align with 
a unit in the layer, a detail in sec. 2.2. 

2.1. broden: broadli and dens label dataset 

To be abl to ascertain align with both low-level 
concept such a color and higher-level concept such a 
objects, we have assembl a new heterogen data set. 

the broadli and dens label dataset (broden) uni- 
fie sever dens label imag data sets: ade [43], open- 
surfac [4], pascal-context [19], pascal-part [6], and the 
describ textur dataset [7]. these data set contain 
exampl of a broad rang of objects, scenes, object parts, 
textures, and materi in a varieti of contexts. most exam- 
ple be segment down to the pixel level except textur 
and scene which be give for full-images. In addition, 
everi imag pixel in the data set be annot with one of 
the eleven common color name accord to the human 
percept classifi by van de weijer [31]. A sampl of 
the type of label in the broden dataset be show in fig. 2. 

the purpos of broden be to provid a ground truth set of 
exemplar for a broad set of visual concepts. the concept 
label in broden be normal and merg from their orig- 
inal data set so that everi class correspond to an english 
word. label be merg base on share synonyms, disre- 
gard posit distinct such a ‘left’ and ‘top’ and 

2 



tabl 1. statist of each label type includ in the data set. 
categori class sourc avg sampl 

scene 468 ade [43] 38 
object 584 ade [43], pascal-context [19] 491 
part 234 ade [43], pascal-part [6] 854 

materi 32 opensurfac [4] 1,703 
textur 47 dtd [7] 140 
color 11 gener 59,250 

avoid a blacklist of 29 overli gener synonym (such 
a ‘machine’ for ‘car’). multipl broden label can appli 
to the same pixel: for example, a black pixel that have the 
pascal-part label ‘left front cat leg’ have three label in bro- 
den: a unifi ‘cat’ label repres cat across data sets; a 
similar unifi ‘leg’ label; and the color label ‘black’. onli 
label with at least 10 imag sampl be included. tabl 1 
show the averag number of imag sampl per label class. 

2.2. score unit interpret 

the propos network dissect method evalu everi 
individu convolut unit in a cnn a a solut to a 
binari segment task to everi visual concept in broden 
(fig. 3). our method can be appli to ani cnn use a for- 
ward pa without the need for train or backpropagation. 

for everi input imag x in the broden dataset, the acti- 
vation map ak(x) of everi intern convolut unit k be 
collected. then the distribut of individu unit activ 
ak be computed. for each unit k, the top quantil level Tk 
be determin such that P (ak > tk) = 0.005 over everi 
spatial locat of the activ map in the data set. 

To compar a low-resolut unit’ activ map to 
the input-resolut annot mask Lc for some concept 
c, the activ map be scale up to the mask resolut 
sk(x) from ak(x) use bilinear interpolation, anchor 
interpol at the center of each unit’ recept field. 
sk(x) be then threshold into a binari segmentation: 

mk(x) ≡ sk(x) ≥ tk, select all region for which the 
activ exce the threshold tk. these segment 
be evalu against everi concept c in the data set by com- 
put intersect mk(x) ∩ lc(x), for everi (k, c) pair. 

the score of each unit k a segment for concept c be 
report a a data-set-wid intersect over union score 

iouk,c = 

∑ 
|mk(x) ∩ lc(x)|∑ 
|mk(x) ∪ lc(x)| 

, (1) 

where | · | be the cardin of a set. becaus the data set 
contain some type of label which be not present on some 
subset of inputs, the sum be comput onli on the subset 
of imag that have at least one label concept of the same 
categori a c. the valu of iouk,c be the accuraci of unit k 
in detect concept c; we consid one unit k a a detector 
for concept c if iouk,c exce a threshold. our qualit 
result be insensit to the iou threshold: differ thresh- 
old denot differ number of unit a concept detector 

tabl 2. test cnn model 
train network data set or task 

none alexnet random 

supervis 

alexnet imagenet, places205, places365, hybrid. 
googlenet imagenet, places205, places365. 

vgg-16 imagenet, places205, places365, hybrid. 
resnet-152 imagenet, places365. 

self alexnet 

context, puzzle, egomotion, 
tracking, moving, videoorder, 
audio, crosschannel,colorization. 
objectcentric. 

across all the network but rel order remain stable. 
for our comparison we report a detector if iouk,c > 0.04. 
note that one unit might be the detector for multipl con- 
cepts; for the purpos of our analysis, we choos the top 
rank label. To quantifi the interpret of a layer, we 
count the number uniqu concept align with units. We 
call thi the number of uniqu detectors. 

the iou evalu the qualiti of the segment of a 
unit be an object confid score for interpret that 
be compar across networks. thu thi score enabl u 
to compar interpret of differ represent and 
lay the basi for the experi below. note that network 
dissect work onli a well a the underli data set: if a 
unit match a human-understand concept that be absent 
in broden, then it will not score well for interpretability. 
futur version of broden will be expand to includ more 
kind of visual concepts. 

3. experi 

for test we prepar a collect of cnn model with 
differ network architectur and supervis of primari 
tasks, a list in tabl 2. the network architectur includ 
alexnet [15], googlenet [29], vgg [27], and resnet [12]. 
for supervis training, the model be train from scratch 
(i.e., not pretrained) on imagenet [25], places205 [42], and 
places365 [41]. imagenet be an object-centr data set, which 
contain 1.2 million imag from 1000 classes. places205 
and places365 be two subset of the place database, which 
be a scene-centr data set with categori such a kitchen, 
live room, and coast. places205 contain 2.4 million im- 
age from 205 scene categories, while places365 contain 
1.6 million imag from 365 scene categories. “hybrid” 
refer to a combin of imagenet and places365. for 
self-supervis train tasks, we select sever recent mod- 
el train on predict context (context) [9], solv puz- 
zle (puzzle) [21], predict ego-mot (egomotion) [14], 
learn by move (moving) [1], predict video frame 
order (videoorder) [18] or track (tracking) [33], detect- 
ing object-centr align (objectcentric) [10], coloriz- 
ing imag (colorization) [38], predict cross-channel 
(crosschannel) [39], and predict ambient sound from 
frame (audio) [22]. the self-supervis model we ana- 
lyze be compar to each other in that they all use alexnet 

3 



input imag network be probe pixel-wis segment 

freez train network weight 

C 
o 

n 
v 

C 
o 

n 
v 

C 
o 

n 
v 

C 
o 

n 
v 

C 
o 

n 
v 

upsampl target layer 

O 
n 

e 
U 

n 
it 

A 
c 
ti 
v 
a 

ti 
o 

n 

C 
o 

lo 
r 

T 
e 
x 
tu 

re 
s 

M 
a 

te 
ri 

a 
l 

S 
c 
e 

n 
e 

s 

P 
a 

rt 
s 

evalu on segment task 

O 
b 

je 
c 
t 

figur 3. illustr of network dissect for measur semant align of unit in a give cnn. here one unit of the last convolut 
layer of a give cnn be probe by evalu it perform on 1197 segment tasks. our method can probe ani convolut layer. 

or an alexnet-deriv architecture. 
In the follow experiments, we begin by valid our 

method use human evaluation. then, we use random uni- 
tari rotat of a learn represent to test whether 
interpret of cnn be an axis-independ property; 
we find that it be not, and we conclud that interpret 
be not an inevit result of the discrimin power of a 
representation. next, we analyz all the convolut layer 
of alexnet a train on imagenet [15] and a train on 
place [42], and confirm that our method reveal detector 
for higher-level concept at high layer and lower-level con- 
cept at low layers; and that more detector for higher-level 
concept emerg under scene training. then, we show that 
differ network architectur such a alexnet, vgg, and 
resnet yield differ interpretability, while differ su- 
pervis train task and self-supervis train task also 
yield a varieti of level of interpretability. final we show 
the impact of differ train conditions, examin the rela- 
tionship between discrimin power and interpretability, 
and investig a possibl way to improv the interpret 
of cnn by increas their width. 

3.1. human evalu of interpret 

We evalu the qualiti of the unit interpret found 
by our method use amazon mechan turk (amt). 
rater be show 15 imag with highlight patch 
show the most highly-activ region for each unit in 
alexnet train on places205, and ask to decid (yes/no) 
whether a give phrase describ most of the imag patches. 

tabl 3 summar the results. first, we determin 
the set of interpret unit a those unit for which rater 
agre with ground-truth interpret from [40]. over thi 
set of units, we report the portion of interpret gener 
by our method that be rat a descriptive. within thi 
set we also compar to the portion of ground-truth label 
that be found to be descript by a second group of raters. 
the propos method can find semant label for unit that 
be compar to descript write by human annot 
at the high layer. At the low layer, the low-level color 
and textur concept avail in broden be onli suffici 

tabl 3. human evalu of our network dissect approach. 
interpret unit be those where rater agre with ground-truth 
interpretations. within thi set we report the portion of interpreta- 
tion assign by our method that be rat a descriptive. human 
consist be base on a second evalu of ground-truth labels. 

conv1 conv2 conv3 conv4 conv5 
interpret unit 57/96 126/256 247/384 258/384 194/256 
human consist 82% 76% 83% 82% 91% 
network dissect 37% 56% 54% 59% 71% 

to match good interpret for a minor of units. human 
consist be also high at conv5, which suggest that 
human be good at recogn and agre upon high- 
level visual concept such a object and parts, rather than 
the shape and textur that emerg at low layers. 

3.2. measur of axis-align interpret 

We conduct an experi to determin whether it be 
meaning to assign an interpret concept to an individ- 
ual unit. two possibl hypothesi can explain the emerg 
of interpret in individu hidden layer units: 

hypothesi 1. interpret unit emerg becaus inter- 
pretabl concept appear in most direct in repre- 
sentat space. If the represent local relat 
concept in an axis-independ way, project to ani 
direct could reveal an interpret concept, and in- 
terpret of singl unit in the natur basi may not 
be a meaning way to understand a representation. 

hypothesi 2. interpret align be unusual, and in- 
terpret unit emerg becaus learn converg to 
a special basi that align explanatori factor with indi- 
vidual units. In thi model, the natur basi repres 
a meaning decomposit learn by the network. 

hypothesi 1 be the default assumption: in the past it have 
be found [30] that with respect to interpret “there 
be no distinct between individu high level unit and 
random linear combin of high level units.” 

network dissect allow u to re-evalu thi hypothe- 
sis. We appli random chang in basi to a represent 

4 



baselin rotat 0.2 rotat 0.4 rotat 0.6 rotat 0.8 rotat 1 
0 

10 

20 

30 

40 

N 
u 
m 

b 
e 
r 

o 
f 
u 
n 
iq 

u 
e 
d 

e 
te 

c 
to 

r object 
part 

scene 

materi 

textur 

color 

figur 4. interpret over chang in basi of the represent 
of alexnet conv5 train on places. the vertic axi show the 
number of uniqu interpret concept that match a unit in the 
representation. the horizont axi show α, which quantifi the 
degre of rotation. 

learn by alexnet. under hypothesi 1, the overal level 
of interpret should not be affect by a chang in ba- 
sis, even a rotat caus the specif set of repres 
concept to change. under hypothesi 2, the overal level of 
interpret be expect to drop under a chang in basis. 

We begin with the represent of the 256 convolu- 
tional unit of alexnet conv5 train on places205 and 
examin the effect of a chang in basis. To avoid ani is- 
sue of condit or degeneracy, we chang basi us- 
ing a random orthogon transform Q. the rotat 
Q be drawn uniformli from so(256) by appli gram- 
schmidt on a normally-distribut QR = A ∈ r2562 with 
positive-diagon right-triangular R, a describ by [8]. in- 
terpret be summar a the number of uniqu visual 
concept align with units, a defin in sec. 2.2. 

denot alexnet conv5 a f(x), we find that the num- 
ber of uniqu detector in qf(x) be 80% few than the 
number of uniqu detector in f(x). our find be inconsis- 
tent with hypothesi 1 and consist with hypothesi 2. 

We also test small perturb of basi use Qα for 
0 ≤ α ≤ 1, where the fraction power Qα ∈ so(256) be 
chosen to form a minim geodes gradual rotat from 
I to Q; these intermedi rotat be comput use a 
schur decomposition. fig. 4 show that interpret of 
qαf(x) decreas a larg rotat be applied. 

each rotat represent have exactli the same discrim- 
in power a the origin layer. write the origin net- 
work a g(f(x)), note that g′(r) ≡ g(qt r) defin a neural 
network that process the rotat represent r = qf(x) 
exactli a the origin g oper on f(x). We conclud that 
interpret be neither an inevit result of discrimina- 
tive power, nor be it a prerequisit to discrimin power. 
instead, we find that interpret be a differ qualiti that 
must be measur separ to be understood. 

3.3. disentangl concept by layer 

use network dissection, we analyz and compar the 
interpret of unit within all the convolut layer 
of places-alexnet and imagenet-alexnet. places-alexnet 
be train for scene classif on places205 [42], while 
imagenet-alexnet be the ident architectur train for 
object classif on imagenet [15]. 

the result be summar in fig. 5. A sampl of unit 
be show togeth with both automat infer inter- 
pretat and manual assign interpret take from 
[40]. We can see that the predict label match the human 
annot well, though sometim they captur a differ- 
ent descript of a visual concept, such a the ‘crosswalk’ 
predict by the algorithm compar to ‘horizont lines’ 
give by the human for the third unit in conv4 of places- 
alexnet in fig. 5. confirm intuition, color and textur 
concept domin at low layer conv1 and conv2 while 
more object and part detector emerg in conv5. 

3.4. network architectur and supervis 

how do differ network architectur and train su- 
pervis affect disentangl interpret of the learn 
representations? We appli network dissect to evalu a 
rang of network architectur and supervisions. for simplic- 
ity, the follow experi focu on the last convolut 
layer of each cnn, where semant detector emerg most. 

result show the number of uniqu detector that 
emerg from variou network architectur train on ima- 
genet and place be plot in fig. 7, with exampl show 
in fig. 6. In term of network architecture, we find that in- 
terpret of resnet > vgg > googlenet > alexnet. 
deeper architectur appear to allow great interpretability. 
compar train data sets, we find place > imagenet. 
As discuss in [40], one scene be compos of multipl 
objects, so it may be benefici for more object detector to 
emerg in cnn train to recogn scenes. 

result from network train on variou supervis and 
self-supervis task be show in fig. 8. here the network 
architectur be alexnet for each model, We observ that 
train on places365 creat the larg number of uniqu 
detectors. self-supervis model creat mani textur de- 
tector but rel few object detectors; apparently, su- 
pervis from a self-taught primari task be much weaker 
at infer interpret concept than supervis train 
on a larg annot data set. the form of self-supervis 
make a difference: for example, the color model be 
train on colorless images, and almost no color detect 
unit emerge. We hypothes that emerg unit repres 
concept requir to solv the primari task. 

fig. 9 show some typic visual detector identifi in 
the self-supervis cnn models. for the model audio and 
puzzle, some object and part detector emerge. those de- 
tector may be use for cnn to solv the primari tasks: 

5 



conv1 conv2 conv3 conv4 conv5 
0 

5 

10 

15 

20 

25 

30 

35 

40 

N 
u 

m 
b 

e 
r 

o 
f 

u 
n 

iq 
u 

e 
d 

e 
te 

c 
to 

r 

alexnet on places205 

object 

part 

scene 

materi 

textur 

color 

vein (texture) h:green 

orang (color) h:color yellow 

red (color) h:pink or red 

sky (object) h:ski 

lacelik (texture)h:black&whit 

line (texture) h:grid pattern 

grass (object) h:grass 

band (texture) h:corrug 

perfor (texture) h:pattern 

chequer (texture) h:window 

tree (object) h:tree 

crosswalk (part) h:horiz. line 

bed (object) h:bed 

car (object) h:car 

mountain (scene) h:montain 

conv1 conv2 conv3 conv4 conv5 
0 

5 

10 

15 

20 

25 

30 

35 

40 

N 
u 

m 
b 

e 
r 

o 
f 

u 
n 

iq 
u 

e 
d 

e 
te 

c 
to 

r 

alexnet on imagenet 

object 

part 

scene 

materi 

textur 

color 

red (color) h:red 

yellow (color) h:yellow 

sky (object) h:blue 

woven (texture) h:yellow 

band (texture) h:stripe 

grid (texture) h:mesh 

food (material) h:orang 

sky (object) h:blue sky 

dot (texture) h:nose 

muzzl (part) h:anim face 

swirli (texture) h:round 

head (part) h:face 

wheel (part) h:wheel 

cat (object) h:anim face 

leg (part) h:leg 

conv1 conv2 conv3 conv4 conv5 

figur 5. A comparison of the interpret of all five convolut layer of alexnet, a train on classif task for place (top) 
and imagenet (bottom). At right, three exampl of unit in each layer be show with identifi semantics. the segment gener by 
each unit be show on the three broden imag with high activation. top-scor label be show abov to the left, and human-annot 
label be show abov to the right. some disagr can be see for the domin judgment of meaning. for example, human annot 
mark the first conv4 unit on place a a ‘windows’ detector, while the algorithm match the ‘chequered’ texture. 

hous dog train plant airplan 

R 
e 
N 
et 
-1 
52 

res5c unit 1410 iou=0.142 res5c unit 1573 iou=0.216 res5c unit 924 iou=0.293 res5c unit 264 iou=0.126 res5c unit 1243 iou=0.172 

res5c unit 301 iou=0.087 res5c unit 1718 iou=0.193 res5c unit 2001 iou=0.255 res5c unit 766 iou=0.092 res5c unit 1379 iou=0.156 

G 
oo 
gL 
eN 

et 

inception_4 unit 789 iou=0.137 inception_4 unit 750 iou=0.203 inception_5b unit 626 iou=0.145 inception_4 unit 56 iou=0.139 inception_4 unit 92 iou=0.164 

inception_4 unit 175 iou=0.115 inception_4 unit 225 iou=0.152 inception_5b unit 415 iou=0.143 inception_4 unit 714 iou=0.105 inception_4 unit 759 iou=0.144 

VG 
G 
-1 
6 

conv5_3 unit 243 iou=0.070 conv5_3 unit 142 iou=0.205 conv5_3 unit 463 iou=0.126 conv5_3 unit 85 iou=0.086 conv5_3 unit 151 iou=0.150 

conv5_3 unit 102 iou=0.070 conv5_3 unit 491 iou=0.112 conv5_3 unit 402 iou=0.058 conv4_3 unit 336 iou=0.068 conv5_3 unit 204 iou=0.077 

figur 6. A comparison of sever visual concept detector identifi by network dissect in resnet, googlenet, and vgg. each network 
be train on places365. the two highest-i match among convolut unit of each network be shown. the segment gener by 
each unit be show on the four maxim activ broden images. some unit activ on concept generalizations, e.g., googlenet 4e’ 
unit 225 on hors and dogs, and 759 on white ellipsoid and jets. 

the audio model be train to associ object with a sound 
source, so it may be use to recogn peopl and cars; 
while the puzzl model be train to align the differ part 
of object and scene in an image. for color and 
tracking, recogn textur might be good enough for 
the cnn to solv primari task such a color a desatu- 
rat natur image; thu it be unsurpris that the textur 
detector dominate. 

3.5. train condit vs. interpret 

train condit such a the number of train iter- 
ations, dropout [28], batch normal [13], and random 
initi [16], be know to affect the represent 
learn of neural networks. To analyz the effect of train- 
ing condit on interpretability, we take the places205- 
alexnet a the baselin model and prepar sever variant 
of it, all use the same alexnet architecture. for the vari- 

6 



R 
e 

N 
et 

15 
2- 

Pl 
ac 

e 
36 

5 

R 
e 

N 
et 

15 
2- 

Im 
ag 

eN 
et 

VG 
G 
-P 

la 
ce 

s2 
05 

VG 
G 
-H 

yb 
rid 

VG 
G 
-P 

la 
ce 

s3 
65 

G 
oo 

gL 
eN 

et 
-P 

la 
ce 

s3 
65 

G 
oo 

gL 
eN 

et 
-P 

la 
ce 

s2 
05 

G 
oo 

gL 
eN 

et 
-im 

ag 
eN 

et 

VG 
G 
-im 

ag 
eN 

et 

Al 
ex 

N 
et 

-P 
la 
ce 

s3 
65 

Al 
ex 

N 
et 

-H 
yb 

rid 

Al 
ex 

N 
et 

-P 
la 
ce 

s2 
05 

Al 
ex 

N 
et 

-im 
ag 

eN 
et 

Al 
ex 

N 
et 

-ra 
nd 

om 

0 

50 

100 

150 

200 

250 

300 

350 
N 

u 
m 

b 
e 

r 
o 

f 
u 

n 
iq 

u 
e 

d 
e 

te 
c 
to 

r 
object 

part 

scene 

materi 

textur 

color 

figur 7. interpret across differ architectur and training. 

Al 
ex 

N 
et 

-P 
la 
ce 

s3 
65 

Al 
ex 

N 
et 

-H 
yb 

rid 

Al 
ex 

N 
et 

-P 
la 
ce 

s2 
05 

Al 
ex 

N 
et 

-im 
ag 

eN 
et 

tra 
ck 

in 
g 

ob 
je 
ct 
ce 

nt 
ric 

au 
di 
o 

m 
ov 

in 
g 

co 
lo 
riz 

at 
io 
n 

pu 
zz 

le 

cr 
o 

sc 
ha 

nn 
el 

eg 
om 

ot 
io 
n 

co 
nt 

ex 
t 

fra 
m 

eo 
rd 

er 

Al 
ex 

N 
et 

-ra 
nd 

om 

0 

20 

40 

60 

80 

100 

N 
u 
m 

b 
e 
r 

o 
f 
u 
n 
iq 

u 
e 
d 

e 
te 

c 
to 

r 

object 

part 

scene 

materi 

textur 

color 

supervis self-supervis 

figur 8. semant detector emerg across differ supervis 
of the primari train task. all these model use the alexnet 
architectur and be test at conv5. 
audio puzzl color track 
chequer (texture) 0.102 head (part) 0.091 dot (texture) 0.140 chequer (texture) 0.167 

car (object) 0.063 perfor (texture) 0.085 head (part) 0.056 grass (object) 0.120 

head (part) 0.061 sky (object) 0.069 sky (object) 0.048 red-c (color) 0.100 

figur 9. the top rank concept in the three top categori in four 
self-supervis networks. some object and part detector emerg 
in audio. detector for person head also appear in puzzl and 
colorization. A varieti of textur concept domin model with 
self-supervis training. 

10 
0 

10 
2 

10 
4 

10 
6 

train iter 

0 

10 

20 

30 

40 

N 
u 

m 
b 

e 
r 

o 
f 

u 
n 

iq 
u 

e 
d 

e 
te 

c 
to 

r 

object 

part 

scene 

materi 

textur 

color 

ba 
se 

lin 
e 

re 
pe 

at 
1 

re 
pe 

at 
2 

re 
pe 

at 
3 

N 
oD 

ro 
po 

ut 

Ba 
tc 
hN 

or 
m 

0 

20 

40 

60 

80 

100 

N 
u 

m 
b 

e 
r 

o 
f 

u 
n 

iq 
u 

e 
d 

e 
te 

c 
to 

r object 
part 

scene 

materi 

textur 

color 

figur 10. the evolut of the interpret of conv5 of 
places205-alexnet over 2,400,000 train iterations. the baselin 
model be train to 300,000 iter (mark at the red line). 

number of detector 

ba 
se 

lin 
e 

re 
pe 

at 
1 

re 
pe 

at 
2 

re 
pe 

at 
3 

N 
oD 

ro 
po 

ut 

Ba 
tc 
hN 

or 
m 

0 

50 

100 

150 

200 
object 

part 

scene 

materi 

textur 

color 

number of uniqu detector 

ba 
se 

lin 
e 

re 
pe 

at 
1 

re 
pe 

at 
2 

re 
pe 

at 
3 

N 
oD 

ro 
po 

ut 

Ba 
tc 
hN 

or 
m 

0 

20 

40 

60 

80 

100 
object 

part 

scene 

materi 

textur 

color 

figur 11. effect of regular on the interpret of cnns. 

ant repeat1, repeat2 and repeat3, we randomli initi 
the weight and train them with the same number of itera- 
tions. for the variant nodropout, we remov the dropout in 
the FC layer of the baselin model. for the variant batch- 
norm, we appli batch normal at each convolut 
layer of the baselin model. repeat1, repeat2, repeat3 all 
have nearli the same top-1 accuraci 50.0% on the valid 
set. the variant without dropout have top-1 accuraci 49.2%. 
the variant with batch norm have top-1 accuraci 50.5%. 

In fig. 10 we plot the interpret of snapshot of the 
baselin model at differ train iterations. We can see 
that object detector and part detector begin emerg at 
about 10,000 iter (each iter process a batch of 
256 images). We do not find evid of transit across 
differ concept categori dure training. for example, 
unit in conv5 do not turn into textur or materi detector 
befor becom object or part detectors. 

fig. 11 show the interpret of unit in the cnn 
over differ train conditions. We find sever effects: 
1) compar differ random initializations, the model 
converg to similar level of interpretability, both in term 
of the uniqu detector number and the total detector number; 
thi match observ of converg learn discuss 
in [16]. 2) for the network without dropout, more textur 
detector emerg but few object detectors. 3) batch nor- 
maliz seem to decreas interpret significantly. 

the batch normal result serf a a caution that 
discrimin power be not the onli properti of a represen- 
tation that should be measured. our intuit for the loss of 
interpret under batch normal be that the batch 
normal ‘whitens’ the activ at each layer, which 
smooth out scale issu and allow a network to easili 
rotat ax of intermedi represent dure training. 
while whiten appar speed training, it may also have 
an effect similar to random rotat analyz in sec. 3.2 
which destroy interpretability. As discuss in sec. 3.2, how- 
ever, interpret be neither a prerequisit nor an obstacl 
to discrimin power. find way to captur the benefit 
of batch normal without destroy interpret be 
an import area for futur work. 

3.6. discrimin vs. interpret 

activ from the high layer of cnn be often 
use a gener visual features, show great discrimin 

7 



color 

0.1 0.3 0.5 0.7 
accuraci on action40 

0 

20 

40 

60 

80 

100 

N 
um 

be 
r 

of 
u 

ni 
qu 

e 
ob 

je 
ct 

d 
et 

ec 
to 

r 

frameord 

resnet152-places365 

vgg-hybrid 

vgg-places205 

vgg-places365 
resnet152-imagenet 

vgg-imagenet 

googlenet-imagenet 

alexnet-places365 

alexnet-imagenet 

alexnet-places205-bn 

alexnet-hybrid 

alexnet-random egomot 

objectcentricmov 

puzzl 

track 
audio 
crosschannel 

context 

alexnet-places205 
googlenet-places205 

googlenet-places365 

figur 12. the number of uniqu object detector in the last con- 
volut layer compar to each represent classif 
accuraci on the action40 data set. supervis and unsupervis 
represent clearli form two clusters. 

and gener abil [42, 24]. here we benchmark deep 
featur from sever network train on sever standard 
imag classif data set for their discrimin abil- 
iti on a new task. for each train model, we extract the 
represent at the high convolut layer, and train a 
linear svm withc = 0.001 on the train data for action40 
action recognit task [34]. We comput the classif 
accuraci averag across class on the test split. 

fig. 12 plot the number of the uniqu object detector 
for each representation, compar to that representation’ 
classif accuraci on the action40 test set. We can see 
there be posit correl between them. thu the super- 
vision task that encourag the emerg of more concept 
detector may also improv the discrimin abil of 
deep features. interestingly, the best discrimin repre- 
sentat for action40 be the represent from resnet152- 
imagenet, which have few uniqu object detector com- 
par to resnet152-places365. We hypothes that the 
accuraci on a represent when appli to a task be de- 
pendent not onli on the number of concept detector in the 
representation, but on the suitabl of the set of repres 
concept to the transfer task. 

3.7. layer width vs. interpret 

from alexnet to resnet, cnn for visual recognit 
have grown deeper in the quest for high classif 
accuracy. depth have be show to be import to high 
discrimin ability, and we have see in sec. 3.4 that 
interpret can increas with depth a well. however, 
the width of layer (the number of unit per layer) have be 
less explored. one reason be that increas the number of 
convolut unit at a layer significantli increas compu- 
tation cost while yield onli margin improv in 
classif accuracy. nevertheless, some recent work [36] 
show that a care design wide residu network can 
achiev classif accuraci superior to the commonli 
use thin and deep counterparts. 

To explor how the width of layer affect interpret 
of cnns, we do a preliminari experi to test how width 

number of detector 

co 
nv 

1 

co 
nv 

2 

co 
nv 

3 

co 
nv 

4 

co 
nv 

5 

co 
nv 

1 

co 
nv 

2 

co 
nv 

3 

co 
nv 

4 

co 
nv 

5 
0 

100 

200 

300 

400 
object 

part 

scene 

materi 

textur 

color 

number of uniqu detector 

co 
nv 

1 

co 
nv 

2 

co 
nv 

3 

co 
nv 

4 

co 
nv 

5 

co 
nv 

1 

co 
nv 

2 

co 
nv 

3 

co 
nv 

4 

co 
nv 

5 
0 

20 

40 

60 

80 

100 

120 object 
part 

scene 

materi 

textur 

color 

alexnet alexnet-gap-widealexnetalexnet-gap-wid 

figur 13. comparison between standard alexnet and alexnet- 
gap-wid (alexnet with wider conv5 layer and gap layer) 
through the number of uniqu detector (the left plot) and the 
number of detector (the right plot). widen the layer bring the 
emerg of more detectors. network be train on places365. 

affect emerg of interpret detectors: we remov the 
FC layer of the alexnet, then tripl the number of unit 
at the conv5, i.e., from 256 unit to 768 units. final we 
put a global averag pool layer after conv5 and fulli 
connect the pool 768-featur activ to the final class 
prediction. We call thi model alexnet-gap-wide. 

after train on places365, the alexnet-gap-wid ob- 
tain similar classif accuraci on the valid set a 
the standard alexnet ( 0.5% top1 accuraci lower), but it have 
mani more emerg concept detectors, both in term of the 
number of uniqu detector and the number of detector unit 
at conv5, a show in fig. 13. We have also increas the 
number of unit to 1024 and 2048 at conv5, but the number 
of uniqu concept do not significantli increas further. 
thi may indic a limit on the capac of alexnet to sep- 
arat explanatori factors; or it may indic that a limit on 
the number of disentangl concept that be help to solv 
the primari task of scene classification. 

4. conclus 
thi paper propos a gener framework, network dis- 

section, for quantifi interpret of cnns. We appli 
network dissect to measur whether interpret be an 
axis-independ phenomenon, and we found that it be not. 
thi be consist with the hypothesi that interpret unit 
indic a partial disentangl representation. We appli 
network dissect to investig the effect on interpretabil- 
iti of state-of-th art cnn train techniques. We have 
confirm that represent at differ layer disentangl 
differ categori of meaning; and that differ train 
techniqu can have a signific effect on the interpret 
of the represent learn by hidden units. 

acknowledgements. thi work be partli support by the nation 
scienc foundat under grant no. 1524817 to a.t.; the vannevar bush 
faculti fellowship program sponsor by the basic research offic of the 
assist secretari of defens for research and engin and fund 
by the offic of naval research through grant n00014-16-1-3116 to a.o.; 
the mit big data initi at csail, the toyota research institut / 
mit csail joint research center, googl and amazon awards, and a 
hardwar donat from nvidia corporation. b.z. be support by a 
facebook fellowship. 

8 



refer 
[1] P. agrawal, J. carreira, and J. malik. learn to see by moving. In 

proc. iccv, 2015. 
[2] P. agrawal, R. girshick, and J. malik. analyz the perform of 

multilay neural network for object recognition. proc. eccv, 2014. 
[3] G. alain and Y. bengio. understand intermedi layer use 

linear classifi probes. arxiv:1610.01644, 2016. 
[4] S. bell, K. bala, and N. snavely. intrins imag in the wild. acm 

trans. on graphic (siggraph), 2014. 
[5] Y. bengio, A. courville, and P. vincent. represent learning: A 

review and new perspectives. ieee transact on pattern analysi 
and machin intelligence, 35(8):1798–1828, 2013. 

[6] X. chen, R. mottaghi, X. liu, S. fidler, R. urtasun, and A. yuille. 
detect what you can: detect and repres object use holist 
model and bodi parts. In proc. cvpr, 2014. 

[7] M. cimpoi, S. maji, I. kokkinos, S. mohamed, and A. vedaldi. de- 
scribe textur in the wild. In proc. cvpr, 2014. 

[8] P. diaconis. what be a random matrix? notic of the ams, 
52(11):1348–1349, 2005. 

[9] C. doersch, A. gupta, and A. A. efros. unsupervis visual repre- 
sentat learn by context prediction. In proc. cvpr, 2015. 

[10] R. gao, D. jayaraman, and K. grauman. object-centr represent 
learn from unlabel videos. arxiv:1612.00500, 2016. 

[11] A. gonzalez-garcia, D. modolo, and V. ferrari. Do semant part 
emerg in convolut neural networks? arxiv:1607.03738, 2016. 

[12] K. he, X. zhang, S. ren, and J. sun. deep residu learn for imag 
recognition. In proc. cvpr, 2016. 

[13] S. ioff and C. szegedy. batch normalization: acceler deep net- 
work train by reduc intern covari shift. arxiv:1502.03167, 
2015. 

[14] D. jayaraman and K. grauman. learn imag represent tie 
to ego-motion. In proc. iccv, 2015. 

[15] A. krizhevsky, I. sutskever, and G. E. hinton. imagenet classif 
with deep convolut neural networks. In advanc in neural 
inform process systems, page 1097–1105, 2012. 

[16] Y. li, J. yosinski, J. clune, H. lipson, and J. hopcroft. converg 
learning: Do differ neural network learn the same representations? 
arxiv:1511.07543, 2015. 

[17] A. mahendran and A. vedaldi. understand deep imag representa- 
tion by invert them. proc. cvpr, 2015. 

[18] I. mikjjsra, C. L. zitnick, and M. hebert. shuffl and learn: unsu- 
pervis learn use tempor order verification. In proc. eccv, 
2016. 

[19] R. mottaghi, X. chen, X. liu, n.-g. cho, s.-w. lee, S. fidler, R. ur- 
tasun, and A. yuille. the role of context for object detect and 
semant segment in the wild. In proc. cvpr, 2014. 

[20] A. nguyen, A. dosovitskiy, J. yosinski, T. brox, and J. clune. syn- 
thesiz the prefer input for neuron in neural network via deep 
gener networks. In advanc in neural inform process 
systems, 2016. 

[21] M. noroozi and P. favaro. unsupervis learn of visual represen- 
tation by solv jigsaw puzzles. In proc. eccv, 2016. 

[22] A. owens, J. wu, J. H. mcdermott, W. T. freeman, and A. torralba. 
ambient sound provid supervis for visual learning. In proc. 
eccv, 2016. 

[23] R. Q. quiroga, L. reddy, G. kreiman, C. koch, and I. fried. invari 
visual represent by singl neuron in the human brain. nature, 
435(7045):1102–1107, 2005. 

[24] A. S. razavian, H. azizpour, J. sullivan, and S. carlsson. cnn 
featur off-the-shelf: an astound baselin for recognition. 
arxiv:1403.6382, 2014. 

[25] O. russakovsky, J. deng, H. su, J. krause, S. satheesh, S. ma, 
Z. huang, A. karpathy, A. khosla, M. bernstein, et al. imagenet 
larg scale visual recognit challenge. int’l journal of comput 
vision, 2015. 

[26] K. simonyan, A. vedaldi, and A. zisserman. deep insid convolu- 
tional networks: visualis imag classif model and salienc 
maps. intern confer on learn represent work- 
shop, 2014. 

[27] K. simonyan and A. zisserman. veri deep convolut network 
for large-scal imag recognition. arxiv:1409.1556, 2014. 

[28] N. srivastava, G. E. hinton, A. krizhevsky, I. sutskever, and 
R. salakhutdinov. dropout: a simpl way to prevent neural network 
from overfitting. journal of machin learn research, 15(1):1929– 
1958, 2014. 

[29] C. szegedy, W. liu, Y. jia, P. sermanet, S. reed, D. anguelov, D. er- 
han, V. vanhoucke, and A. rabinovich. go deeper with convolu- 
tions. In proc. cvpr, 2015. 

[30] C. szegedy, W. zaremba, I. sutskever, J. bruna, D. erhan, I. good- 
fellow, and R. fergus. intrigu properti of neural networks. 
arxiv:1312.6199, 2013. 

[31] J. van De weijer, C. schmid, J. verbeek, and D. larlus. learn 
color name for real-world applications. ieee transact on imag 
processing, 18(7):1512–1523, 2009. 

[32] C. vondrick, H. pirsiavash, and A. torralba. gener video with 
scene dynamics. arxiv:1609.02612, 2016. 

[33] X. wang and A. gupta. unsupervis learn of visual representa- 
tion use videos. In proc. cvpr, 2015. 

[34] B. yao, X. jiang, A. khosla, A. L. lin, L. guibas, and L. fei-fei. 
human action recognit by learn base of action attribut and 
parts. In proc. iccv, 2011. 

[35] J. yosinski, J. clune, Y. bengio, and H. lipson. how transfer be 
featur in deep neural networks? In advanc in neural inform 
process systems, 2014. 

[36] S. zagoruyko and N. komodakis. wide residu networks. 
arxiv:1605.07146, 2016. 

[37] M. D. zeiler and R. fergus. visual and understand convolu- 
tional networks. proc. eccv, 2014. 

[38] R. zhang, P. isola, and A. A. efros. color imag colorization. In 
proc. eccv. springer, 2016. 

[39] R. zhang, P. isola, and A. A. efros. split-brain autoencoders: un- 
supervis learn by cross-channel prediction. In proc. cvpr, 
2017. 

[40] B. zhou, A. khosla, A. lapedriza, A. oliva, and A. torralba. object 
detector emerg in deep scene cnns. intern confer on 
learn representations, 2015. 

[41] B. zhou, A. khosla, A. lapedriza, A. torralba, and A. oliva. places: 
An imag databas for deep scene understanding. arxiv:1610.02055, 
2016. 

[42] B. zhou, A. lapedriza, J. xiao, A. torralba, and A. oliva. learn 
deep featur for scene recognit use place database. In advanc 
in neural inform process systems, 2014. 

[43] B. zhou, H. zhao, X. puig, S. fidler, A. barriuso, and A. torralba. 
scene pars through ade20k dataset. proc. cvpr, 2017. 

9 


