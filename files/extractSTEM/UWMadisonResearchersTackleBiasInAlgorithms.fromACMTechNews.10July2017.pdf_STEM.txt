






































uw-madison research tackl bia in algorithm 


uw-madison research tackl bia 
in algorithm 

If you’v ever appli for a loan or check your credit score, algorithm have 

play a role in your life. these mathemat model allow comput to use 

data to predict mani thing — who be like to pay back a loan, who may be a 

suitabl employee, or whether a person who have broken the law be like to 

reoffend, to name just a few examples. 

yet while some may assum that comput remov human bia from decision- 

making, research have show that be not true. bias on the part of those 

design algorithms, a well a bia in the data use by an algorithm, can 

introduc human prejudic into a situation. A seemingli neutral process 

becom fraught with complications. 

for the past year, univers of 

wisconsin–madison faculti in the 

depart of comput scienc 

have be work on tool to 

address unfair in algorithms. 

now, a $1 million grant from the 

nation scienc foundat will 

acceler their efforts. their 

project, “formal method for 

program fairness,” be fund 

through nsf’ softwar and 

hardwar foundat program. 

uw-madison comput scienc 

professor aw albarghouthi 

(https://www.cs.wisc.edu/people/aws), shuchi chawla 

(http://www.cs.wisc.edu/people/shuchi), lori d’antoni 

(https://www.cs.wisc.edu/people/loris) and jerri zhu 

(http://www.cs.wisc.edu/people/jerryzhu) be lead the develop of a 

tool call fairsquare. comput scienc graduat student samuel drew 

(http://pages.cs.wisc.edu/~sdrews/) and david merrel 

(https://dpmerrell.github.io/) be also involved. 

what set fairsquar apart be that it will not onli detect bias, but also employ 

autom solutions. “ultimately, we’d like thi to be a regulatori tool when 

you’r deploy an algorithm make sensit decisions. you can verifi it’ 

inde fair, and then fix it if it’ not,” say albarghouthi. 

decision-mak algorithm can be mysteri even to those who use them, 

say the researchers, make a tool like fairsquar necessary. 

uw-madison research tackl bia in algorithm http://news.wisc.edu/uw-madison-researchers-tackle-bias-in-algorithms/ 

1 sur 2 10/07/2017 20:17 



for example, consid a bank that us a third-parti tool to evalu who 

qualifi for a mortgag or small busi loan, and at what interest rate. the 

bank may not know how the softwar be classifi potenti customers, how 

accur it predict truli are, or whether result reflect racial or other type 

of bias. 

“mani compani use these algorithm don’t understand what (the 

algorithms) be doing,” say albarghouthi. “an algorithm seem to work for 

them, so they use it, but usual there be no feedback or explainability” on how 

exactli it be working. that make these algorithm difficult to regul in term 

of avoid illeg bias, he says. 

compani design and sell these product be typic not eager to share 

their proprietari knowledge, make their algorithm what be know a 

“black box.” 

say d’antoni, “we’r tri to give 

peopl the abil to ask about 

behavior of an algorithm. doe it 

prefer a certain gender, or certain 

behaviors, for example?” 

the stake behind these algorithm 

can be high, a journalist have 

noted. 

In a 2016 stori by the investig 

journal organ propublica, 

a team of report examin a 

product use in law enforc to 

predict offenders’ likelihood of reoffending. the report uncov troubl 

racial bias, though the softwar compani in question disput their 

conclusions. 

accord to propublica, “(b)lack be almost twice a like a white to be 

label a high risk but not actual reoffend.” with white offenders, the 

opposit mistak occurred. white be much more like than black to be 

peg a low-risk yet go on to commit addit crimes. 

the UW research be attack the problem by isol fair a a 

properti of a softwar program that must be formal defin and proven. 

thi point to addit questions, say drews. “who decid what’ fair? how 

can you be certain you’r come up with a mathemat formula that mean 

the thing you want it to prove?” 

the fairsquar team be make connect with uw–madison scholar in 

other field who can help illumin certain aspect of thi research, such a 

legal and ethic ramifications. 

“comput be so much more involv in people’ life these days,” say drews, 

make the develop of fairsquar not onli a signific comput 

challeng but also one with far-reach social impact. 

add merrell, “machin learn algorithm have becom veri commonplace, 

but they aren’t alway use in respons ways. I hope our research will help 

engin build safe, reliabl and ethic systems.” 

uw-madison research tackl bia in algorithm http://news.wisc.edu/uw-madison-researchers-tackle-bias-in-algorithms/ 

2 sur 2 10/07/2017 20:17 


