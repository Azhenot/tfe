




















































eye movement dure everyday behavior predict person trait 


origin research 
published: 13 april 2018 

doi: 10.3389/fnhum.2018.00105 

frontier in human neurosci | www.frontiersin.org 1 april 2018 | volum 12 | articl 105 

edit by: 

antonio fernández-caballero, 

universidad de castilla-la mancha, 

spain 

review by: 

mazyar fallah, 

york university, canada 

bennett I. berthenthal, 

indiana univers bloomington, 

unit state 

*correspondence: 

andrea bull 

bulling@mpi-inf.mpg.d 

received: 06 novemb 2017 

accepted: 05 march 2018 

published: 13 april 2018 

citation: 

hopp S, loetscher T, morey SA and 

bull A (2018) eye movement 

dure everyday behavior predict 

person traits. 

front. hum. neurosci. 12:105. 

doi: 10.3389/fnhum.2018.00105 

eye movement dure everyday 
behavior predict person trait 
sabrina hopp 1, tobia loetscher 2, stephani A. morey 3 and andrea bull 4* 

1machin learn and robot lab, univers of stuttgart, stuttgart, germany, 2 school of psychology, univers of south 

australia, adelaide, sa, australia, 3 school of psychology, flinder university, adelaide, sa, australia, 4 perceptu user 

interfac group, max planck institut for informatics, saarbrücken, germani 

besid allow u to perceiv our surroundings, eye movement be also a window 

into our mind and a rich sourc of inform on who we are, how we feel, and 

what we do. here we show that eye movement dure an everyday task predict 

aspect of our personality. We track eye movement of 42 particip while they 

ran an errand on a univers campu and subsequ assess their person 

trait use well-establish questionnaires. use a state-of-the-art machin learn 

method and a rich set of featur encod differ eye movement characteristics, 

we be abl to reliabl predict four of the big five person trait (neuroticism, 

extraversion, agreeableness, conscientiousness) a well a perceptu curios onli from 

eye movements. further analysi reveal new relat between previous neglect 

eye movement characterist and personality. our find demonstr a consider 

influenc of person on everyday eye movement control, therebi complement 

earli studi in laboratori settings. improv automat recognit and interpret 

of human social signal be an import endeavor, enabl innov design of 

human–comput system capabl of sens spontan natur user behavior to 

facilit effici interact and personalization. 

keywords: eye tracking, real world, personality, machin learning, gaze behavior, eye-bas user model 

eye movement facilit effici sampl of visual inform from the world around us. for 
example, in everyday social interactions, we often understand, predict, and explain the behavior and 
emot state of other by how their eye move (emery, 2000). the exact mechan by which 
eye movement be controlled, and the rang of factor that can influenc it, be subject to intens 
research (wolfe, 1994; martinez-cond et al., 2004; foulsham et al., 2011; rucci and victor, 2015). 
understand the type of inform eye movement convey be of current interest to a rang 
of fields, from psycholog and the social scienc to comput scienc (henderson et al., 2013; 
bull et al., 2011; bull and zander, 2014; bixler and d’mello, 2015; steil and bulling, 2015). 
one emerg bodi of research suggest that the way in which we move our eye be modul 
by who we are—bi our person (isaacowitz, 2005; rauthmann et al., 2012; risko et al., 2012; 
baran et al., 2015; hopp et al., 2015). 

person trait character an individual’ pattern of behavior, thinking, and feel (kazdin, 
2000). studi report relationship between person trait and eye movement suggest that 
peopl with similar trait tend to move their eye in similar ways. optimists, for example, spend less 
time inspect neg emot stimulu (e.g., skin cancer images) than pessimist (isaacowitz, 
2005). individu high in open spend a longer time fixat and dwell on locat when 
watch abstract anim (rauthmann et al., 2012), and perceptu curiou individu 
inspect more of the region in a naturalist scene (risko et al., 2012). but pioneer studi on 
the associ between person and eye movement share two methodolog limitations. 

https://www.frontiersin.org/journals/human-neurosci 
https://www.frontiersin.org/journals/human-neuroscience#editorial-board 
https://www.frontiersin.org/journals/human-neuroscience#editorial-board 
https://www.frontiersin.org/journals/human-neuroscience#editorial-board 
https://www.frontiersin.org/journals/human-neuroscience#editorial-board 
https://doi.org/10.3389/fnhum.2018.00105 
http://crossmark.crossref.org/dialog/?doi=10.3389/fnhum.2018.00105&domain=pdf&date_stamp=2018-04-13 
https://www.frontiersin.org/journals/human-neurosci 
https://www.frontiersin.org 
https://www.frontiersin.org/journals/human-neuroscience#articl 
https://creativecommons.org/licenses/by/4.0/ 
mailto:bulling@mpi-inf.mpg.d 
https://doi.org/10.3389/fnhum.2018.00105 
https://www.frontiersin.org/articles/10.3389/fnhum.2018.00105/ful 
http://loop.frontiersin.org/people/511465/overview 
http://loop.frontiersin.org/people/40153/overview 
http://loop.frontiersin.org/people/498085/overview 
http://loop.frontiersin.org/people/537430/overview 


hopp et al. dure everyday behavior 

first, these earli studi typic either investig the 
link between gaze and person descript (e.g., use 
correlation, risko et al., 2012; rauthmann et al., 2012) or 
predict singl gaze characteristics, such a the number of 
fixat (isaacowitz, 2005; risko et al., 2012; rauthmann 
et al., 2012), from person scores. for practic applications, 
however, the more relev question be whether, in turn, eye 
movement can be use to predict person traits. intriguingly, 
machin learn techniqu provid a way of answer thi 
question without the need to make a-priori hypothesi about the 
import of individu gaze characteristics. instead, the most 
inform characterist can be automat determin from 
a potenti larg and divers set of eyemov characterist 
and patterns; therebi also uncov previous unknown link 
between person and gaze. the potenti of machin learn 
for predict behavior, cognit state and person have be 
highlight in a few studi (henderson et al., 2013; bull and 
zander, 2014; bixler and d’mello, 2015; hopp et al., 2015). 
A recent laboratori study, for example, success predict 
people’ epistem curios about answer to trivia question 
from oculomotor behavior (baran et al., 2015). 

the second limit of earli studi be their restrict 
to laboratori condit – an approach that have be critic 
becaus it may not lead to valid theori of human behavior 
in natur set (kingston et al., 2003, 2008). In most 
studies, care select stimulu – such a images, animations, 
or trivia question – be present to particip for 
defin durat on a comput screen, and participants’ eye 
movement be then relat to the person trait under 
investig (isaacowitz, 2005; rauthmann et al., 2012; risko 
et al., 2012; baran et al., 2015). however, principl guid 
the eye when look at comput screen and when engag 
in dynam real-world behavior differ significantli (foulsham 
et al., 2011; tatler et al., 2011; tatler, 2014). compel evid 
for such differ be provid in a studi which track eye 
movement of particip when they be explor differ 
real world environ and when watch video of these 
environ (marius’t hart et al., 2009). the distribut of 
eye movement obtain in the laboratori onli predict the 
gaze distribut in the laboratori with around 60% accuracy— 
indic signific differ in eye movement between 
laboratori and real world situat (foulsham et al., 2011). It 
therefor remain unclear whether these person trait found 
to be relat to eye movement in the laboratori (isaacowitz, 
2005; rauthmann et al., 2012; risko et al., 2012; baran et al., 
2015) gener to real-world behaviors. If so, then link between 
eye movement and person have import ramif 
for the emerg field of social signal processing, social 
robotics, and eye-bas user modeling. these interdisciplinari 
fields—at the intersect of comput science, social science, 
and psychology—focu on the develop of system that 
can sense, model, and understand everyday human social 
signal (vinciarelli et al., 2009;wagner et al., 2011; vinciarelli and 
pentland, 2015) and that exhibit human-lik behavior, includ 
person (fong et al., 2003). ultimately, such socially-awar 
comput have the potenti to offer interact capabl that 
close resembl natur human-human interactions. 

In the present work we demonstrate, for the first time, that 
the visual behavior of individu engag in an everyday task 
can predict four of the big five person trait (mccrae and 
costa, 2010), along with perceptu curios (collin et al., 2004). 
To thi end, we develop and studi a larg set of featur that 
describ variou characterist of everyday visual behavior. thi 
approach go beyond exist analysi of individu featur 
and provid a principl demonstr of the link between 
eye movement and personality. our find not onli valid 
the role of person in explain eye movement behavior in 
daili life, they also reveal new eye movement characterist a 
predictor of person traits. 

1. method 

fifti student and staff of flinder univers particip in 
the study: 42 femal and eight males, with a mean age of 21.9 
year (sd 5.5). the conveni sampl be recruit through an 
advertis on the school of psychology’ onlin particip 
manag system and the sampl size be base on risko 
et al. (2012). written inform consent be obtain from all 
particip and particip receiv aud15 for take part 
in the study. ethic approv be obtain from the human 
research ethic committe at flinder univers and the studi 
be conduct in accord with the declar of helsinki. 

1.1. apparatu 
binocular gaze data be track use a state-of-the-art 
head-mount video-bas eye tracker from sensormotor 
instrument (smi) at 60hz. the tracker have a report gaze 
estim accuraci of 0.5◦ and precis of 0.1◦. the tracker 
record gaze data, along with a high-resolut scene video on 
a mobil phone that be carri in a cross-bodi bag. 

1.2. questionnair 
person trait be assess use three establish self-report 
questionnaires: 1) the neo five-factor inventori (neo-ffi- 
3) compris 60 question assess neuroticism, extraversion, 
openness, agreeableness, and conscienti (mccrae and 
costa, 2010); 2) perceptu curiosity, a 16-item questionnair 
assess a person’ interest in novel perceptu stimul 
and visual-sensori inspect (collin et al., 2004); and 3) 
the curios and explor inventori (cei-ii), a 10-item 
questionnair assess trait curios (kashdan et al., 2009). 

1.3. procedur 
upon arriv in the laboratory, particip be introduc 
to the studi and fit with the eye tracker. the tracker be 
first calibr use a standard 3-point calibr routine. 
particip be then give aud5 and instruct to walk 
around campu for approxim 10 min and to purchas ani 
item of their choic (such a a drink or confectionary) from 
a campu shop of their choice. upon return, the track be 
stop and the glass be removed. particip be then 
ask to fill in the person and curios questionnaires. 

frontier in human neurosci | www.frontiersin.org 2 april 2018 | volum 12 | articl 105 

https://www.frontiersin.org/journals/human-neurosci 
https://www.frontiersin.org 
https://www.frontiersin.org/journals/human-neuroscience#articl 
lphilipp 
text surligné 

lphilipp 
note 
sampl size of about 50 be rather low!!! 

lphilipp 
note 



hopp et al. dure everyday behavior 

2. data process 

the data from one particip be lose due to technic 
problem with the eye track equipment. ani sampl where the 
pupil could not be detected, or the gaze direct be estim 
to be beyond 150% of it range, be mark a erroneous. 
six particip with more than 50% erron sampl in 
their record be exclud from further analysis; one other 
particip be exclud becaus gaze direct be estim to 
be constant for 38% of samples. for the remain 42 particip 
an averag of 12.51 minut (sd = 2.71) of eye track data 
be collected, with an averag track loss of 19.58% (sd = 0.12). 
the record includ an averag 2.36 minut insid the shop 
(sd= 1.70). 

We independ bin person score for each trait 
into three score rang (low, medium, and high). the bin 
be perform in a data-driven fashion so that approxim 
one third of the particip be assign to each score 
range. the middl bin’ boundari be defin a the score 
percentil at 1/3 and 2/3 respectively. becaus person score 
approxim follow a gaussian distribution, the rang of 
medium score be small than the rang for the two extrem 
classes. tabl 2 in the appendix list all result boundari 
between score ranges. 

both data and sourc code be publicli avail on github1. 

2.1. featur extract 
follow best practic in eye-bas user model (bull 
et al., 2011), the time seri of gaze data be process use 
a slide window approach to make the data independ of 
the individu durat of the record while not blur out 
gaze characterist due to averag effects. that is, onli data 
from a time window of a certain length be consid at one 
time. differ window size be evalu dure our train 
routin (see below for details). the window be slid over the 
entir record such that all subsequ window have an overlap 
of 50%. time window that have more than 50% erron 
sampl (i.e., where the pupil could not be detect or the gaze 
direct be estim to be beyond 150% of it range), less 
than 2 non-erron samples, or not a singl detect fixat 
or saccade, be discarded. for each result time window, a 
vector of 207 featur be extract (see the appendix for a list 
of all features). these featur include: 

1. statist over raw gaze data: these be introduc 
in baran et al. (2015) for the detect of epistem curios 
under laboratori conditions. mani of the featur be 
specif to the user interfac used, for instanc the distanc 
of the participant’ gaze from a box in the interfac but 
other such a minimum, mean and maximum of gaze x or 
y coordin be adopt to our setting. 

2. heatmap of raw gaze data have be link to curios in 
a studi on a static scene view task (risko et al., 2012). 
analogously, an 8 by 8 heatmap of gaze point have be 
extract here. over time a heatmap cell correspond to 
differ place in the world due to head and bodi motion. 

1https://github.molgen.mpg.de/sabrina-hoppe/everyday-eye-movements- 

predict-person 

sinc some gaze point be extrapol to posit quit 
far from the actual scene video, gaze point be onli use 
if they fell within the interv span 95% of the data in 
both horizont and vertic direction. the heatmap cell be 
enumer from 0 in the top left corner, through 7 in the top 
right corner, to 63 in the bottom right corner. 

3. statist over fixations, saccad and blink have frequent 
be use in eye track studi (bull et al., 2011; 
rauthmann et al., 2012; risko et al., 2012). fixat 
be detect use a dispersion-threshold algorithm with a 
threshold of 2.5% of the track rang width (5) with an 
addit threshold on the minimum durat of 100ms. all 
movement between two fixat be inspect a candid 
saccad and be accept if they do not exceed a maximum 
durat of 500m and have a peak veloc of at least 200% 
of the track rang per second. both fixat and saccad 
with more than 50% erron sampl be discarded. 
additionally, the eye track softwar provid inform 
on blink and pupil diameter. from all event (i.e., fixations, 
saccades, and blinks), a number of statist be comput 
such a the mean durat of fixat and the direct of 
saccades. A full list of these featur can be found in the 
appendix. 

note that “fixations” of up to 500m be like to includ 
smooth pursuit that we do not consid separ sinc 
robust pursuit detect be still an open research question even 
for control laboratori set (hopp and bulling, 2016). 

4. inform on the tempor cours of saccad and fixat 
have previous be encod in so-cal n-gram featur 
for eye-bas user model (bull et al., 2011). n-gram 
describ a seri of gaze events, e.g., saccad with differ 
amplitud (larg or small) and direct bin into 8 
possibl direct (e.g., [“long saccad up,” “short fixation,” 
“short saccad up”] for n = 3). finally, a histogram of n- 
gram be comput by count how often each n-gram, 
i.e., each possibl combin of saccad and fixations, 
occurred. for each n between 1 and 4, the follow featur 
be extract from the histogram: number of differ n- 
gram (i.e., number of non-zero entri in the histogram), 
maximum/minimum/mean/vari of the histogram entri 
and the most/least frequent n-gram. 

for each person trait, a separ random forest 

classifi (breiman, 2001) consist of 100 decis tree 
be train on these featur to predict one of the three 

person score rang (low, medium, high) use scikit- 

learn (pedregosa et al., 2011). each decis tree resembl a 

tree-shap flow-chart of decisions, where we set the maximum 
depth of each tree to 5 and allow up to 15 featur to be 

consid per decision. befor each train procedure, a 

standard scaler be fit to the train data and appli to both 
train and test sampl to ensur a mean of zero and a standard 

deviat of one for each feature. 
We have no a priori hypothesi concern which window 

size for the sliding-window approach would be most effective, or 
which particular featur would be useful. We therefor chose an 
automat approach name nest cross valid to optim the 
open paramet dure training, i.e., window size and featur 

frontier in human neurosci | www.frontiersin.org 3 april 2018 | volum 12 | articl 105 

https://github.molgen.mpg.de/sabrina-hoppe/everyday-eye-movements-predict-person 
https://github.molgen.mpg.de/sabrina-hoppe/everyday-eye-movements-predict-person 
https://github.molgen.mpg.de/sabrina-hoppe/everyday-eye-movements-predict-person 
https://www.frontiersin.org/journals/human-neurosci 
https://www.frontiersin.org 
https://www.frontiersin.org/journals/human-neuroscience#articl 


hopp et al. dure everyday behavior 

selection. In a nutshell, a nest cross valid cycl through 
set of participants: one train set, one valid set, and 
one test set. for instance, in the first iteration, particip 1- 
32 might be use for training, particip 33–37 for validation, 
and particip 38–42 for testing. In the second iteration, 
particip 5–37 might be use for training, then particip 
10–42 and so on. In all iterations, sever classifi base on 
differ window size and subset of featur be train on 
the train set and evalu on the valid set. the best 
perform window size and subset of featur be chosen base 
on the perform on the valid set. A classifi be then 
train on the union of train and valid set and test on 
the test set to gener the final perform score report here. 
It be import to select paramet base on perform on 
the valid set and then re-train and evalu on anoth test 
set, becaus with thi scheme, the paramet be never directli 
optim for the final evaluation. therefore, cross valid 
effect mitig the risk of overfitting—th algorithm be 
forc to gener to unseen data. 

2.2. classifi evalu 
classifi perform be evalu in term of averag F1 score 
across the three score ranges. the F1 score for a particular rang 
R be defin a the harmon mean of precis (the probabl 
that the true person score rang for a random person out 
of those for which R be predict be inde R) and recal 
(the probabl that R will be predict for a randomli chosen 
particip whose true person score be within r). sinc the 
train procedur for random forest classifi be inher non- 
deterministic, we go through the whole nest cross-valid 
scheme 100 time with differ initi random states. 

We compar our classifi against sever random baselin 
to determin how like our classif success be accord 
to simpler or trivial classifiers: 

1. theoret chanc level: if all predict be make 
uniformli at random and all score rang be equal likely, 
the result F1 score for three balanc class should be 0.33. 
slight deviat from these assumptions, e.g., unbalanc 
classes, could in practic lead to differ results. thus, we 
implement a simpl classifi that randomli sampl one 
of the three score rang for each person from a uniform 
distribution. 

2. predict the most frequent score range: for thi evaluation, 
the train and test set be built in an ident manner to 
the actual train process, but instead of fit a classifier, the 
most frequent score rang on the train set be determin 
and then predict for everi person in the test set. note 
that thi might be slightli differ from the theoret 33% 
becaus the split into train and test set might distort the 
label frequencies. 

3. the label permut test (ojala and garriga, 2010) be 
propos to determin the level of perform after ani 
relat between featur and score rang be obfuscated, i.e., 
the train data be artifici shuffl such that the relat 
between gaze and person be lost. If thi classifi be abl to 
perform abov a theoret chanc level it might for instanc 

have pick up class frequencies. thus, it can serv a a test 
of how much actual inform from the gaze featur be 
learn by our origin classifi (bode et al., 2012). 

each of these baselin be comput 100 times, so a set of 100 
F1 score per baselin be obtain and compar to those of our 
classifier. 

3. result 

figur 1 show the mean F1 score for our classifi a well a 
for all baselin for each trait. As can be see from the figure, 
our classifi perform well abov chanc (that is, confid 
interv do not overlap with ani of the baselin performances) 
for neurotic (40.3%), extravers (48.6%), agreeabl 
(45.9%), conscienti (43.1%), and perceptu curios 
(pcs, 37.1%). for open (30.8%) and the curios and 
explor inventori (cei, 27.2%) our classifi perform below 
chanc level. 

In the abov evaluation, all record data be use 
irrespect of participants’ context: that is, regardless of whether 
they be on their way to the shop, or insid the shop. To evalu 
the reliabl of classifi within and across differ part of 
the recording, time at which peopl enter and left the shop 
be manual annot base on the record scene video. 
We then compar their predict across differ subset 
of the data: (1) independ of the participant’ activ (two 
half of the recording: split halves); (2) within one activ 
(the way to the shop vs. the way back to the laboratory: way 
I vs. ii); and (3) across activ (navig on the way vs. 
shop inside: shop vs. way). for each comparison, we use 
the 100 classifi train for the first part of the paper and 
reconstruct the predict for singl time window (i.e., 
the predict befor major voting). major vote be 
perform over time window from the context in question only, 
such a from time window when the particip be insid 
the shop. As each classifi have be train and evalu 100 
times, thi lead to 100 pair of predict for each comparison. 
reliabl be then evalu by the averag correl 
between these pair of predict after correct for the 
skew of the sampl distribut of correl coefficients, 
use the fisher transform (fisher, 1915). the result 
pearson product-mo correl coeffici be show in 
tabl 1. the coeffici rang from 0.39 to 0.83, indic a 
moder to strong correl between these differ real-world 
contexts. 

To investig in more detail how eye movement 
characterist be link to individu person traits, we 
further calcul the rel import of all featur from 
the random forest classifi a suggest in breiman (2001). A 
random forest classifi compris sever decis trees. the 
import of a featur in the random forest be defin a it 
averag import across all the compon decis trees. 
within a singl decis tree, a feature’ import be defin via 
all decis that be make base on that feature: the great the 
number of decis made, the small the mean classif 
error and the more data be pass through these decis in the 

frontier in human neurosci | www.frontiersin.org 4 april 2018 | volum 12 | articl 105 



hopp et al. dure everyday behavior 

figur 1 | mean F1 score of 100 instanc of our classifi and three baselin per trait. the whisker indic the 95% confid interv around the mean, 

comput by bootstrap with 1,000 iter on the set of 100 F1 score for each trait. all result be obtain use a cross-valid scheme such that onli 

predict for unseen particip be use for evaluation. the dash line show the theoret chanc level for a classifi that randomli pick one person 

score rang for each participant, independ of gaze. 

tabl 1 | pearson product-mo correl coeffici of predict 

obtain from differ part of the recording: in the first half vs. the second half 

(split halves), on the way to the shop vs. on the way back to the laboratori (way I 

vs. ii) and insid the shop vs. outsid the shop (shop vs. way). 

half I vs. half II way I vs. way II shop vs. way 

neurotic 0.77 0.75 0.63 

extravers 0.83 0.75 0.61 

open 0.64 0.60 0.39 

agreeabl 0.63 0.56 0.44 

conscienti 0.69 0.72 0.43 

perceptu curios 0.68 0.65 0.46 

curios and explor 0.68 0.65 0.44 

tree structure, the more import the featur that the decis 
be base on breiman (2001). 

figur 2 show the most import featur for our trait- 
specif classifi sort in ascend order by their median 
import across all traits. the featur be chosen a the 
small set contain the individu ten most import 
featur for each trait accord to our method, a well a those 
featur previous link to person in rauthmann et al. 
(2012), risko et al. (2012), and baran et al. (2015). 

As can be see from figur 2, five of the 19 most import 
featur be link to n-gram (bull et al., 2011), which 
describ a seri of n saccades. In contrast to the saccade- 
base n-grams, n-gram encod fixation–saccad sequenc 
be less important. heatmap featur similar to those in risko 
et al. (2012), which captur how often a particip look 
into certain area of their visual field, be the second most 
import class of features. moreover, the averag varianc in 
pupil diamet dure fixat and blink rate turn out to be 
informative. complement the F1 score that be commonli 

report when evaluatingmachin learningmethod with respect 
to performance, we also provid correl coeffici between 
person score and the differ eye movement featur 
extract from a slide window with a length of 15 s (see tabl 3 
in the appendix). 

4. discuss 

one key contribut of our work be to demonstrate, for the 
first time, that an individual’ level of neuroticism, extraversion, 
agreeableness, conscientiousness, and perceptu curios can 
be predict onli from eye movement record dure an 
everyday task. thi find be import for bridg between 
tightli control laboratori studi and the studi of natur eye 
movement in unconstrain real-world environments. 

while predict be not yet accur enough for practic 
applications, they be clearli abov chanc level and outperform 
sever baselin (see figur 1). the propos machin learn 
approach be particularli success in predict level of 
agreeableness, conscientiousness, extraversion, and perceptu 
curiosity. It therefor corrobor previou laboratory-bas 
studi that have show a link between person trait and eye 
movement characterist (isaacowitz, 2005; risko et al., 2012; 
rauthmann et al., 2012; baran et al., 2015). 

the trait-specif eye movement characterist be reliable: 
compar predict after split the record into two 
half yield reliabl valu rang between 0.63 and 0.83, 
indic moder to strong correl between predict 
deriv from the differ half of the recording. the reliabl 
valu be low (0.39–0.63) when the predict be 
base on the comparison between two task activ (walk 
and shopping). these find suggest that trait-specif eye 
movement vari substanti across activities. futur work 

frontier in human neurosci | www.frontiersin.org 5 april 2018 | volum 12 | articl 105 

https://www.frontiersin.org/journals/human-neurosci 
https://www.frontiersin.org 
https://www.frontiersin.org/journals/human-neuroscience#articl 
lphilipp 
note 
error bar relat to random seed set. noth to do with error bar on input data, includ error bar estim on deem ground truth :) 



hopp et al. dure everyday behavior 

figur 2 | the top half of the figur show the import of the top-10 featur for each trait, sort by their median import across all traits. the bottom half 

show the import of further featur that be relat to person or curios in prior work. the box repres the distribut over featur import 

obtain from the 100 model we trained. each of the box span the inter-quartil rang (iqr); the whisker extend to the minimum and maximum. the dark bar 

insid each box repres the median. for each classifier, mani featur remain unus and therefor have an import of zero. where most import valu 

be zero, the box be often invisible. 

could therefor establish which activ be best suit to elicit 
trait-specif eye movements, a thi could significantli improv 
both predict accuraci and reliabl for practic applications. 

A second contribut of our work be to shed addit 
light on the close link between person trait and an 
individual’ eye movements. thank to the machin learn 
approach, we could automat analyz a larg set of eye 
movement characterist and rank them by their import 
for person trait prediction. go beyond characterist 
investig in earli works, thi approach also allow u 
to identifi new link between previous under-investig 
eye movement characterist and person traits. thi 
be possibl because, unlik classic analysi approaches, 
the propos machin learn method do not reli on 
a priori hypothesi regard the import of individu 
eye movement characteristics. specifically, characterist that 
captur rich tempor inform on visual behavior seem 
to convey fundament inform relat to all person 
traits, and consist outperform classic characterist that 
have be isol for investig in laboratori situations, 
such a fixat durat (isaacowitz, 2005; rauthmann et al., 
2012; risko et al., 2012). By extract the most import 
eye movement characterist for each person trait (see 
figur 2) we also found that the import of characterist 
vari for differ person traits. for example, pupil diamet 
be import for predict neurotic but be less use 

for predict other traits. It be import to note that the 
goal of the current studi be not to shed light on the 
underli reason for whi certain eye movement characterist 
be more common in particular person types. instead, it 
be specif design to explor whether machin learn 
can be use to classifi person from eye movement in an 
everyday task. 

the predict accuraci and reliabl score obtain from 
42 particip be veri promising. however, in comput vision, 
state-of-the-art machin learningmethod be commonli train 
on million of sampl (russakovski et al., 2015). these 
large-scal dataset have facilit data-driven develop and 
automat learn of features, often outperform previou 
manual design characterist (le, 2013). for the field of 
person research, obtain larg dataset with a more 
repres sampl of the gener popul than the 
conveni sampl of the current studi will be an import 
next step. consequently, large-scal real-world gaze dataset 
be like to improv automat infer of person 
and stimul research on the automat represent of 
gaze characteristics, with the potenti to further improv 
perform a well a deepen our understand of the interplay 
between gaze and personality. importantly, whether the poor 
perform of our algorithm in predict open and cei 
be due to the experiment design (rel small sampl and 
the specif task of run an errand) or due the possibl that 

frontier in human neurosci | www.frontiersin.org 6 april 2018 | volum 12 | articl 105 

https://www.frontiersin.org/journals/human-neurosci 
https://www.frontiersin.org 
https://www.frontiersin.org/journals/human-neuroscience#articl 


hopp et al. dure everyday behavior 

there be no link between open and the way eye be move 
cannot be answer at thi stage. 

four import question aris from our findings: (1) how 
well do our find gener to non-univers populations, 
differ person traits, differ set and other real-world 
activities? (2) how be the predict of person trait affect 
by temporari user states, such a mood, fatigu or even the 
person’ awar of the eye tracker (risko and kingstone, 
2011)? (3) how do gaze-bas signal interact with further social 
cue that be link to personality, such a bodi postur (ball and 
breese, 2000) or digit footprint (youyou et al., 2015)? and (4) 
how can a system exploit sever cue to deriv a more holist 
view on the user’ personality? 

answer these question will guid research to improv our 
understand of how human eye movement be modul 
in the real world (kingston et al., 2003; risko and kingstone, 
2011), and how they fit into the broad spectrum of human non- 
verbal behavior. In turn, improv theoret understand will 
assist the emerg interdisciplinari research field of social signal 
processing, toward develop of system that can recogn 
and interpret human social signal (vinciarelli et al., 2009; 
wagner et al., 2011; vinciarelli and pentland, 2015). 

such knowledg of human non-verb behavior might also 
be transfer to social interact robots, design to exhibit 
human-lik behavior (fong et al., 2003). these system might 
ultim interact with human in a more natur and social 
accept way, therebi becom more effici and flexible. 

author contribut 

TL design and oversaw the study; SM collect the data; SH 
implement and evalu the machin learn method and 
gener all result and figures; AB advis these analyses; sh, 
tl, and AB write the paper. 

fund 

thi work be funded, in part, by the australian research 
council, the cluster of excel on multimod comput 
and interact (mmci) at saarland university, germany, a 
well a a ph.d. scholarship by the german nation academ 
foundation. 

acknowledg 

TL wish to thank jason mccarley, mike nicholls, 
and the brain and cognit laboratori (flinder 
university) for valuabl discuss when set up the 
experiment. 

supplementari materi 

the supplementari materi for thi articl can be found 
onlin at: https://www.frontiersin.org/articles/10.3389/fnhum. 
2018.00105/full#supplementary-materi 

refer 

ball, g., and breese, J. (2000). relat person and behavior: postur and 

gestures. berlin; heidelberg: springer. 

baranes, a., oudeyer, P. y., and gottlieb, J. (2015). eye movement 

reveal epistem curios in human observers. vis. res. 117, 81–90. 

doi: 10.1016/j.visres.2015.10.009 

bixler, r., and d’mello, S. K. (2015). automat gaze-bas user-independ 

detect of mind wander dure computer reading. user model. user 

adapt. inter. 26, 33–68. doi: 10.1007/s11257-015-9167-1 

bode, s., sewell, D. k., lilburn, s., forte, J. d., smith, P. l., and stahl, J. (2012). 

predict perceptu decis bia from earli brain activity. J. neurosci. 32, 

12488–12498. doi: 10.1523/jneurosci.1708-12.2012 

breiman, L. (2001). random forests. mach. learn. 45, 5–32. 

doi: 10.1023/a:1010933404324 

bulling, a., ward, J. a., gellersen, h., and tröster, G. (2011). eye movement 

analysi for activ recognit use electrooculography. ieee trans. patt. 

anal. mach. intell. 33, 741–753. doi: 10.1109/tpami.2010.86 

bulling, a., and zander, T. O. (2014). cognition-awar computing. ieee perv. 

comput. 13, 80–83. doi: 10.1109/mprv.2014.42 

collins, R. p., litman, J. a., and spielberger, C. D. (2004). the 

measur of perceptu curiosity. pers. individ. dif. 36, 1127–1141. 

doi: 10.1016/s0191-8869(03)00205-8 

emery, N. J. (2000). the eye have it: the neuroethology, function 

and evolut of social gaze. neurosci. biobehav. rev. 24, 581–604. 

doi: 10.1016/s0149-7634(00)00025-7 

fisher, R. A. (1915). frequenc distribut of the valu of the correl 

coeffici in sampl from an indefinit larg population. biometrika 10, 

507–521. doi: 10.2307/2331838 

fong, t., nourbakhsh, i., and dautenhahn, K. (2003). A survey 

of social interact robots. rob. auton. syst. 42, 143–166. 

doi: 10.1016/s0921-8890(02)00372-x 

foulsham, t., walker, e., and kingstone, A. (2011). the where, what and when of 

gaze alloc in the lab and the natur environment. vis. res. 51, 1920–1931. 

doi: 10.1016/j.visres.2011.07.002 

henderson, J. m., shinkareva, S. v., wang, j., luke, S. g., and olejarczyk, J. 

(2013). predict cognit state from eye movements. plo one 8:e64937. 

doi: 10.1371/journal.pone.0064937 

hoppe, s., and bulling, A. (2016). end-to-end eye movement detect use 

convolut neural networks. arxiv preprint arxiv:1609.02452. 

hoppe, s., loetscher, t., morey, s., and bulling, A. (2015). “recognit 

of curios use eye movement analysis,” in proceed of the 2017 

acm intern joint confer on pervas and ubiquit comput 

(ubicomp 2015) (osaka), 185–188. 

isaacowitz, D. M. (2005). the gaze of the optimist. pers. soc. psychol. bull. 31, 

407–415. doi: 10.1177/0146167204271599 

kashdan, T. b., gallagher, M. w., silvia, P. j., winterstein, B. p., breen, W. 

e., terhar, d., et al. (2009). the curios and explor inventory-ii: 

development, factor structure, and psychometrics. J. res. pers. 43, 987–998. 

doi: 10.1016/j.jrp.2009.04.011 

kazdin, A. E. (ed.). (2000). encyclopedia of psychology, vol. 1–8. washington, dc: 

american psycholog association. 

kingstone, a., smilek, d., and eastwood, J. D. (2008). cognit ethology: a 

new approach for studi human cognition. br. J. psychol. 99, 317–340. 

doi: 10.1348/000712607x251243 

kingstone, a., smilek, d., ristic, j., friesen, C. k., and eastwood, J. D. 

(2003). attention, researchers! it be time to take a look at the real 

world. curr. dir. psychol. sci. 12, 176–180. doi: 10.1111/1467-8721. 

01255 

le, Q. V. (2013). “build high-level featur use larg scale unsupervis 

learning,” in ieee intern confer on acoustics, speech and signal 

process (vancouver, bc: ieee), 8595–8598. 

marius’t hart, b., vockeroth, j., schumann, f., bartl, k., schneider, e., 

koenig, p., et al. (2009). gaze alloc in natur stimuli: compar 

frontier in human neurosci | www.frontiersin.org 7 april 2018 | volum 12 | articl 105 

https://www.frontiersin.org/articles/10.3389/fnhum.2018.00105/full#supplementary-materi 
https://doi.org/10.1016/j.visres.2015.10.009 
https://doi.org/10.1007/s11257-015-9167-1 
https://doi.org/10.1523/jneurosci.1708-12.2012 
https://doi.org/10.1023/a:1010933404324 
https://doi.org/10.1109/tpami.2010.86 
https://doi.org/10.1109/mprv.2014.42 
https://doi.org/10.1016/s0191-8869(03)00205-8 
https://doi.org/10.1016/s0149-7634(00)00025-7 
https://doi.org/10.2307/2331838 
https://doi.org/10.1016/s0921-8890(02)00372-x 
https://doi.org/10.1016/j.visres.2011.07.002 
https://doi.org/10.1371/journal.pone.0064937 
https://doi.org/10.1177/0146167204271599 
https://doi.org/10.1016/j.jrp.2009.04.011 
https://doi.org/10.1348/000712607x251243 
https://doi.org/10.1111/1467-8721.01255 
https://www.frontiersin.org/journals/human-neurosci 
https://www.frontiersin.org 
https://www.frontiersin.org/journals/human-neuroscience#articl 


hopp et al. dure everyday behavior 

free explor to head-fix view conditions. vis. cogn. 17, 1132–1158. 

doi: 10.1080/13506280902812304 

martinez-conde, s., macknik, S. l., and hubel, D. H. (2004). the role of 

fixat eye movement in visual perception. nat. rev. neurosci. 5, 229–240. 

doi: 10.1038/nrn1348 

mccrae, R. r., and costa, P. (2010). neo nventori profession manual. odessa, 

fl: psycholog assess resources. 

ojala, m., and garriga, G. C. (2010). permut test for studi classifi 

performance. J. mach. learn. res. 11, 1833–1863. doi: 10.1109/icdm.2009.108 

pedregosa, f., varoquaux, g., gramfort, a., michel, v., thirion, b., grisel, o., et 

al. (2011). scikit-learn: machin learn in python. J. mach. learn. res. 12, 

2825–2830. 

rauthmann, J. f., seubert, C. t., sachse, p., and furtner, M. R. (2012). eye a 

window to the soul: gaze behavior be relat to personality. J. res. pers. 46, 

147–156. doi: 10.1016/j.jrp.2011.12.010 

risko, E. f., anderson, N. c., lanthier, s., and kingstone, A. (2012). curiou 

eyes: individu differ in person predict eye movement behavior in 

scene-viewing. cognit 122, 86–90. doi: 10.1016/j.cognition.2011.08.014 

risko, E. f., and kingstone, A. (2011). eye wide shut: impli social 

presence, eye track and attention. attent. percept. psychophys. 73, 291–296. 

doi: 10.3758/s13414-010-0042-1 

rucci, m., and victor, J. D. (2015). the unsteadi eye: an information-process 

stage, not a bug. trend neurosci. 38, 195–206. doi: 10.1016/j.tins.2015.01.005 

russakovsky, o., deng, j., su, h., krause, j., satheesh, s., ma, s., et al. (2015). 

imagenet larg scale visual recognit challenge. int. J. comput. vis. 115, 

211–252. doi: 10.1007/s11263-015-0816-i 

steil, j., and bulling, A. (2015). “discoveri of everyday human activ from 

long-term visual behaviour use topic models,” in proceed of the 2015 

acm intern joint confer on pervas and ubiquit comput 

(ubicomp 2015) (osaka), 75–85. 

tatler, B. (2014). “ey movement from laboratori to life,” in current trend in eye 

track research, ed M. horsley, M. eliot, B. knight, and R. reilli (cham: 

springer). doi: 10.1007/978-3-319-02868-2_2 

tatler, B. w., hayhoe, M. m., land, M. f., and ballard, D. H. (2011). eye guidanc 

in natur vision: reinterpret salience. J. vis. 11:5. doi: 10.1167/11.5.5 

vinciarelli, a., pantic, m., and bourlard, H. (2009). social signal processing: 

survey of an emerg domain. imag vis. comput. 27, 1743–1759. 

doi: 10.1016/j.imavis.2008.11.007 

vinciarelli, a., and pentland, A. S. (2015). new social signal in a new interact 

world: the next frontier for social signal processing. ieee sys. man cybern. 

magazin 1, 10–17. doi: 10.1109/msmc.2015.2441992 

wagner, j., lingenfelser, f., bee, n., and andré, E. (2011). social signal 

interpret (ssi). künstl intell. 25, 251–256. doi: 10.1007/s13218-011-0115-x 

wolfe, J. M. (1994). guid search 2.0 a revis model of visual search. psychon. 

bull. rev. 1, 202–238. doi: 10.3758/bf03200774 

youyou, w., kosinski, m., and stillwell, D. (2015). computer-bas person 

judgment be more accur than those make by humans. proc. natl. acad. 

sci. u.s.a. 112, 1036–1040. doi: 10.1073/pnas.1418680112 

conflict of interest statement: the author declar that the research be 

conduct in the absenc of ani commerci or financi relationship that could 

be constru a a potenti conflict of interest. 

copyright © 2018 hoppe, loetscher, morey and bulling. thi be an open-access 

articl distribut under the term of the creativ common attribut licens (cc 

by). the use, distribut or reproduct in other forum be permitted, provid 

the origin author(s) and the copyright owner be credit and that the origin 

public in thi journal be cited, in accord with accept academ practice. 

No use, distribut or reproduct be permit which do not compli with these 

terms. 

frontier in human neurosci | www.frontiersin.org 8 april 2018 | volum 12 | articl 105 

https://doi.org/10.1080/13506280902812304 
https://doi.org/10.1038/nrn1348 
https://doi.org/10.1109/icdm.2009.108 
https://doi.org/10.1016/j.jrp.2011.12.010 
https://doi.org/10.1016/j.cognition.2011.08.014 
https://doi.org/10.3758/s13414-010-0042-1 
https://doi.org/10.1016/j.tins.2015.01.005 
https://doi.org/10.1007/s11263-015-0816-i 
https://doi.org/10.1007/978-3-319-02868-2_2 
https://doi.org/10.1167/11.5.5 
https://doi.org/10.1016/j.imavis.2008.11.007 
https://doi.org/10.1109/msmc.2015.2441992 
https://doi.org/10.1007/s13218-011-0115-x 
https://doi.org/10.3758/bf03200774 
https://doi.org/10.1073/pnas.1418680112 
http://creativecommons.org/licenses/by/4.0/ 
http://creativecommons.org/licenses/by/4.0/ 
http://creativecommons.org/licenses/by/4.0/ 
http://creativecommons.org/licenses/by/4.0/ 
http://creativecommons.org/licenses/by/4.0/ 
https://www.frontiersin.org/journals/human-neurosci 
https://www.frontiersin.org 
https://www.frontiersin.org/journals/human-neuroscience#articl 

eye movement dure everyday behavior predict person trait 
1. method 
1.1. apparatu 
1.2. questionnair 
1.3. procedur 

2. data process 
2.1. featur extract 
2.2. classifi evalu 

3. result 
4. discuss 
author contribut 
fund 
acknowledg 
supplementari materi 
refer 




