









































gener adversari network for 
extrem learn imag compress 

eirikur agustsson∗, michael tschannen∗, fabian mentzer∗, 
radu timofte, and luc van gool 

eth zurich 

abstract. We propos a framework for extrem learn imag com- 
pression base on gener adversari network (gans), obtain 
visual pleas imag at significantli low bitrat than previou 
methods. thi be make possibl through our gan formul of learn 
compress combin with a generator/decod which oper on the 
full-resolut imag and be train in combin with a multi-scal dis- 
criminator. additionally, our method can fulli synthes unimport 
region in the decod imag such a street and tree from a semant 
label map extract from the origin image, therefor onli requir the 
storag of the preserv region and the semant label map. A user studi 
confirm that for low bitrates, our approach significantli outperform 
state-of-the-art methods, save up to 67% compar to the next-best 
method bpg. 

keywords: deep imag compression, gener adversari networks, 
compress autoencoder, semant label map. 

our (0.036bpp) bpg (0.039bpp) 

fig. 1: imag produc by our global gener compress network train 
with an adversari loss, along with the correspond result for bpg [1]. 

1 introduct 

imag compress system base on deep neural network (dnns), or deep 
compress system for short, have becom an activ area of research recently. 

∗equal contribution. 

ar 
X 

iv 
:1 

80 
4. 

02 
95 

8v 
1 

[ 
c 

.C 
V 

] 
9 

A 
pr 

2 
01 

8 



2 E. agustsson, M. tschannen, F. mentzer, R. timofte, and L. van gool 

q 

D 

Gx 

s 
x̂ 

ŵw 
E 

(a) global gener compress (gc) 

q 

D 

G 

x 

s 
x̂ 

ŵw 
m 

E 

F 

(b) select gener compress (sc) 

fig. 2: structur of the propos compress networks. E be the encod for the 
imag x and option the semant label map s. q quantiz the latent code 
w to ŵ. G be the generator, produc the decompress imag x̂, and D the 
discrimin use for adversari training. for sc, F extract featur from s 
and the subsampl heatmap multipli ẑ (pointwise) for spatial bit allocation. 

these system often outperform state-of-the-art engin codec such a bpg 
[1], webp [2], and jpeg2000 [3] on perceptu metric [4–8]. besid achiev- 
ing high compress rate on natur images, they can be easili adapt to 
specif target domain such a stereo or medic images, and promis effici 
process and index directli from compress represent [9]. however, 
for bitrat below 0.1 bit per pixel (bpp) these algorithm still incur sever 
qualiti reductions. more generally, a the bitrat tend to zero, preserv the 
full imag content becom imposs and common distort measur such a 
peak signal-to-nois ratio (psnr) or multi-scal structur similar (ms-ssim) 
[10] becom meaningless a they favor exact preserv of local (high-entropy) 
structur over preserv texture. To further advanc deep imag compress 
it be therefor of great import to develop new train object beyond 
psnr and ms-ssim. A promis candid toward thi goal be adversari 
loss [11] which be show recent to captur global semant inform 
and local texture, yield power gener that produc visual appeal 
high resolut imag from semant label map [12, 13]. 

In thi paper, we propos and studi a gener adversari network (gan)- 
base framework for extrem imag compression, target bitrat below 0.1 
bpp. We present a principl gan formul for deep imag compress that 
allow for differ degre of content generation. In contrast to prior work on 
deep imag compress which appli adversari loss to imag patch for 
artifact suppress [6, 14] and gener of textur detail [15] or represent 
learn for thumbnail imag [16], our generator/decod oper on the full- 
resolut imag and be train with a multi-scal discrimin [13]. 

We studi two mode of oper (correspond to uncondit and con- 
dition gan [11, 17]), name 

– global gener compress (gc), preserv the overal imag content 
while gener structur of differ scale such a leaf of a tree or win- 
dow in the facad of buildings, and 

– select gener compress (sc), complet gener part of the 
imag from a semant label map while preserv user-defin region with 
a high degre of detail. 



gener adversari network for extrem learn imag compress 3 

A typic use case for GC be bandwidth constrain scenarios, where one 
want to preserv the full imag a much a possible, while fall back to syn- 
thesiz content instead of blocky/blurri blob for region where there be not 
suffici bit to store the origin pixels. SC could be appli in a video call 
scenario where one want to fulli preserv peopl in the video stream, but a 
visual pleas synthes background serf our purpos a well a the true 
background. In the GC oper mode the imag be transform into a bit- 
stream and encod use arithmet coding. SC requir a semantic/inst 
label map of the origin imag which can be obtain use off-the-shelf seman- 
tic/inst segment networks, e.g., pspnet [18] and mask r-cnn [19], 
and which be store a a vector graphic. thi amount to a small, imag dimen- 
sion independ overhead in term of cod cost. On the other hand, the size 
of the compress imag be reduc proport to the area which be gener 
from the semant label map, typic lead to a signific overal reduct 
in storag cost. 

for gc, a comprehens user studi show that our compress system 
yield visual consider more appeal result than bpg [1] (the current 
state-of-the-art engin compress algorithm) and the recent propos 
autoencoder-bas deep compress (aedc) system [8]. In particular, for the 
street scene imag from the cityscap data set, user prefer the imag pro- 
duce by our method over bpg even when bpg us more than doubl the 
bits. To the best of our knowledge, these be the first result show that a 
deep compress method outperform bpg in a user study. In the SC oper 
mode, our system seamlessli combin preserv imag content with synthes 
content, even for region that cross multipl object boundaries. By partial gen- 
erat imag content we achiev bitrat reduct of over 50% without notabl 
degrad imag quality. In both cases, the semant inform a measur 
by the mean intersect over union (miou) between the semant label map of 
the origin and reconstruct imag be significantli good preserv a for the 
two baselin [1, 8]. 

2 relat work 

deep imag compress have recent emerg a an activ area of research. the 
most popular dnn architectur for thi task be to date auto-encod [4, 5, 
20, 21, 9] and recurr neural network (rnns) [22, 23]. these dnn transform 
the input imag into a bit-stream, which be in turn losslessli compress use 
entropi cod method such a huffman cod or arithmet coding. To re- 
duce cod rates, mani deep compress system reli on context model to 
captur the distribut of the bit stream [5, 23, 21, 6, 8]. common loss function 
to measur the distort between the origin and decompress imag be the 
mean-squar error (mse) [4, 5, 20, 21, 7, 9], or perceptu metric such a ms- 
ssim [23, 6–8]. some author reli on advanc techniqu includ multi-scal 
imag decomposit [6], progress encoding/decod strategi [22, 23], and 
gener divis normal (gdn) layer [5, 24]. 



4 E. agustsson, M. tschannen, F. mentzer, R. timofte, and L. van gool 

gener adversari network (gans) [11] have emerg a a popular tech- 
niqu for learn gener model for intract distribut in an unsuper- 
vise manner. despit stabil issu [25–28], they be show to be capabl 
of gener more realist and sharper imag than prior approach such a 
variat autoencod [29]. while initi struggl with gener high 
resolut imag [30, 25], they be steadili improved, now reach resolu- 
tion of 1024 × 1024px [31, 32] for some datasets. anoth direct that have 
show great progress be condit gan [11, 17], obtain impress result 
for image-to-imag translat [12, 13, 33, 34] on variou dataset (e.g. map to 
satellit images), reach resolut a high a 1024× 2048px [13]. 

arguabl the most close relat work to our be [6], which us an adver- 
sarial loss term to train a deep compress system. however, thi loss term be 
appli to small imag patch and it purpos be to suppress artifact rather 
than to gener imag content. furthermore, it us a non-standard gan for- 
mulat that do not (to the best of our knowledge) have an interpret in 
term of diverg between probabl distributions, a in [11, 35]. [16] us 
a gan framework to learn a gener model over thumbnail images, which 
be then use a a decod for thumbnail imag compression. other work use 
adversari train for compress artifact remov (for engin codecs) [14] 
and singl imag super-resolut [15]. finally, relat to our SC mode, spatial 
alloc bitrat base on salienc of imag content have a long histori in the 
context of engin compress algorithms, see e.g. [36–38]. 

3 background 

3.1 gener adversari network 

given a data set X , gener adversari network (gans) can learn to ap- 
proxim it (unknown) distribut px through a gener g(z) that tri to 
map sampl z from a fix prior distribut pz to the distribut px. 

the gener G be train in parallel with a discrimin D by search- 
ing (use stochast gradient descent (sgd)) for a saddl point of a mini-max 
object 

min 
G 

max 
D 

e[f(d(x))] + e[g(d(g(z)))], (1) 

where G and D be dnn and f and g be scalar functions. the origin paper 
[11] us the “vanilla gan” object with f(y) = log(y) and g(y) = log(1− y). 
thi correspond to G minim the KL diverg between the distribut 
of x and g(z). the KL diverg be a member of a more gener famili of 
f -divergences, and nowozin et al.[35] show that for suitabl choic of f and 
g, all such diverg can be minim with (1). In particular, if one us 
f(y) = (y − 1)2 and g(y) = y2, one obtain the least-squar gan [28] (which 
correspond to the pearson χ2 divergence), which we adopt in thi paper. We 
refer to the diverg minim over G a 

lgan := max 
D 

e[f(d(x))] + e[g(d(g(z)))]. (2) 



gener adversari network for extrem learn imag compress 5 

3.2 condit gener adverari network 

for condit gan (cgans) [11, 17], each data point x be associ with 
addit inform s, where (x, s) have an unknown joint distribut px,s. 
We now assum that s be give and that we want to use the gan to model 
the condit distribut px|s. In thi case, both the gener g(z, s) and 
discrimin d(z, s) have access to the side inform s, lead to the diver- 
genc 

lcgan := max 
D 

e[f(d(x, s))] + e[g(d(g(z, s), s))], (3) 

3.3 deep imag compress 

To compress an imag x ∈ X , we follow the formul of [20, 8] where one 
learn an encod E, a decod G, and a finit quantiz q. the encod E 
map the imag to a latent featur map w, whose valu be then quantiz 
to L level {c1, · · · , cl} ⊂ R to obtain a represent ŵ = q(e(x)) that can 
be encod to a bitstream. the decod then tri to the recov the imag by 
form a reconstruct x̂ = g(ŵ). To be abl to backpropag through the 
non-differenti q, one can use a differenti relax of q, a in [8]. 

the averag number of bit need to encod ŵ be measur by the entropi 
h(ŵ), which can be model with a prior [20] or a condit probabl model 
[8]. the trade-off between reconstruct qualiti and bitrat to be optim be 
then 

e[d(x, x̂)] + βh(ŵ). (4) 

where d be a loss that measur how perceptu similar x̂ be to x. 
given a differenti model of the entropi h(ŵ), the weight β control 

the bitrat of the model (high β push the bitrat down). however, sinc the 
number of dimens dim(ŵ) and the number of level L be finite, the entropi 
be bound by (see, e.g., [39]) 

h(ŵ) ≤ dim(ŵ) log2(l). (5) 

It be therefor also valid to set β = 0 and control the maximum bitrat through 
the bound (5) (i.e., adjust L or dim(ŵ) through the architectur of e). while 
potenti lead to suboptim bitrates, thi avoid to model the entropi 
explicitli a a loss term. 

4 gan for extrem imag compress 

4.1 global gener compress 

our propos gan for extrem imag compress can be view a a combi- 
nation of (conditional) gan and learn compression. with an encod E and 
quantiz q, we encod the imag x to a compress represent ŵ = q(e(x)). 
thi represent be option concaten with nois v drawn from a fix 



6 E. agustsson, M. tschannen, F. mentzer, R. timofte, and L. van gool 

prior pv, to form the latent vector z. the decoder/gener G then tri to gen- 
erat an imag x̂ = g(z) that be consist with the imag distribut px while 
also recov the specif encod imag x to a certain degre (see fig. 2 (a)). 
use z = [ŵ,v], thi can be express by our saddle-point object for (non- 
conditional) gener compression, 

min 
e,g 

max 
D 

e[f(d(x))] + e[g(d(g(z))] + λe[d(x, g(z))] + βh(ŵ), (6) 

where λ > 0 balanc the distort term against the gan loss and entropi 
terms. use thi formulation, we need to encod a real image, ŵ = e(x), to 
be abl to sampl from pŵ. however, thi be not a limit a our goal be to 
compress real imag and not to gener complet new ones. 

sinc the last two term of (6) do not depend on the discrimin D, they 
do not affect it optim directly. xthi mean that the discrimin still 
comput the same f diverg lgan a in (2), so we can write (6) a 

min 
e,g 

lgan + λe[d(x, g(z))] + βh(ŵ). (7) 

We note that equat (6) have complet differ dynam than a normal 
gan, becaus the latent space z contain ŵ, which store inform about 
a real imag x. A crucial ingredi be the bitrat limit on h(ŵ). If we 
allow ŵ to contain arbitrarili mani bit by set β = 0 and let L and 
dim(ŵ) be larg enough, E and G could learn to near-losslessli recov x from 
g(z) = g(q(e(x))), such that the distort term would vanish. In thi case, 
the diverg between px and pg(z) would also vanish and the gan loss would 
have no effect. 

By constrain the entropi of ŵ, E and G will never be abl to make d 
fulli vanish. In thi case, e,g need to balanc the gan object lgan and 
the distort term λe[d(x, g(z))], which lead to g(z) on one hand look 
“realistic”, and on the other hand preserv the origin image. for example, if 
there be a tree for which E cannot afford to store the exact textur (and make 
d small) G can synthes it to satisfi lgan, instead of show a blurri green 
blob. 

In the extrem case where the bitrat becom zero (i.e., h(ŵ) → 0, e.g., 
by set β = ∞ or dim(ŵ) = 0), ŵ becom deterministic. In thi setting, z 
be random and independ of x (through the v component) and the object 
reduc to a standard gan plu the distort term, which act a a regularizer. 

We refer to the set in (6) a global gener compress (gc), sinc 
e,g balanc reconstruct and gener automat over the entir image. 

As for the condit gan in sec. 3.2, we can easili extend the global 
gener compress of the previou section to a condit case. here, we 
also consid thi setting, where the addit inform s for an imag x be 
a semant label map of the scene (see dash line in fig. 2 (a)), with a small 
difference: instead of feed the semant to G, we give them to the encod 
E a an input. thi avoid separ encod the inform s, sinc it be 
contain in the represent ŵ. As for the condit gan, D also receiv 
the semant s a an input. 



gener adversari network for extrem learn imag compress 7 

4.2 select gener compress 

for the global gener compress and it condit variant describ in the 
previou section, e,g automat navig the trade-off between gener 
and preserv over the entir image, without ani guidance. here, we consid 
a differ setting, where we guid the network in term of which region should 
be preserv and which region should be synthesized. We refer to thi set 
a select gener compress (sc) and give an overview in fig. 2 (b). 

for simplicity, we consid a binari setting, where we construct a single- 
channel binari heatmap m of the same spatial dimens a ŵ. region of 
zero correspond to region that should be fulli synthesized, wherea region of 
one correspond to region that should be preserved. however, sinc our task 
be compression, we constrain the fulli synthes region to have the same se- 
mantic s a the origin imag x. We assum the semant s be separ 
stored, and thu feed them through a featur extractor F befor feed them to 
the gener G. To guid the network with the semantics, we mask the (pixel- 
wise) distort d, such that it be onli comput over the region to be preserved. 
additionally, we zero out the latent featur ŵ in the region that should be syn- 
thesized. provid that the heatmap m be also stored, we then onli encod the 
entri of ŵ correspond to the preserv regions, greatli reduc the bitrat 
need to store it. 

At bitrat where ŵ be normal much larg than the storag cost for s and 
m (about 2kb per imag when encod a a vector graphic), thi approach can 
give larg bitrat savings. 

5 experi 

5.1 network architectur 

the architectur for our encod E and gener G be base on the global 
gener network propos in [13], which in turn be base on the architectur 
of [40]. 

for the gc, the encod E convolut process the imag x and option- 
alli the label map s, with spatial dimens W ×h, into a featur map of size 
W 
16 × 

H 
16 × 960 (with 6 layers, of which four have 2-stride convolutions), which 

be then project down to C channel (where C ∈ {2, 4, 8, 16} be much small 
than 960). thi result in a featur map w of dimens w16 × 

H 
16 × C, which 

be quantiz over L center to obtain the discret ŵ. the gener G project 
ŵ up to 960 channels, process these with 9 residu unit [41] at dimens 
W 
16× 

H 
16×960, and then mirror E by convolut process the featur back 

to spatial dimens W × H (with transpos convolut instead of stride 
ones). 

similar to E, the featur extractor F for SC process the semant map 
s down to the spatial dimens of ŵ, which be then concaten to ŵ for 
generation. In thi case, we consid slightli high bitrat and downscal by 
8× instead of 16× in the encod E, such that dim(ŵ) = W8 × 

H 
8 × C. the 



8 E. agustsson, M. tschannen, F. mentzer, R. timofte, and L. van gool 

gener then first process ŵ down to w16 × 
H 
16 × 960 and then proce a for 

gc. 
for both GC and sc, we use the multi-scal architectur of [13] for the 

discrimin D, which measur the diverg between px and pg(z) both 
local and globally. 

5.2 loss and hyperparamet 

for the entropi term βh(ŵ), we adopt the simplifi approach describ in 
sec. 3.3, where we set β = 0, use L = 5 center C = {−2, 1, 0, 1, 2}, and control 
the bitrat through the upper bound h(ŵ) ≤ dim(ŵ) log2(l). for example, for 
gc, with C = 2 channels, we obtain 

h(ŵ) 

W ×H 
= 

log2(5) · w×h16·16 · 2 
W ×H 

= 0.0181 bit per pixel (bpp). 

We note that thi be an upper bound; the actual entropi of h(ŵ) be gener 
smaller, sinc the learn distribut will neither be uniform nor i.i.d, which 
would be requir for the bound to hold with equality. By use a histogram a 
in [20] or a context model a in [8], we could reduc thi bitrat either in a post 
process step, or jointli dure train a in the respect works. 

for the distort term we adopt d(x, x̂) = mse with coeffici λ = 10. 
furthermore, we adopt the featur match and vgg perceptu losses, lfm 
and lvgg, a propos in [13] with the same weights, which improv the qualiti 
for imag synthes from semant label maps. these loss can be view a 
a part of d(x, x̂). however, we do not mask them in sc, sinc they also help to 
stabil the gan in thi oper mode (a in [13]). 

5.3 evalu 

data sets: We train the propos method on two popular data set that come 
with hand-annot semant label maps, name cityscap [42] and ade20k 
[43]. both of these data set be previous use with gan [12, 33], henc 
we know that gan can model their distribution—at least to a certain extent. 
cityscap contain 2975 train and 500 valid imag of dimens 2048× 
1024px, which we resampl to 1024× 512px for our experiments. the train 
and valid imag be annot with 34 and 19 classes, respectively. from 
the ade20k data set we use the sceneparse150 subset with 20 210 train and 
2000 valid imag of a wide varieti of size (200×200px to 975×975px), each 
annot with 150 classes. dure training, the ade20k imag be rescal 
such that the width be 512px. 

gener to kodak: the kodak imag compress dataset [44] have a long 
tradit in the imag compress literatur and be still the most frequent 
use dataset for comparisons. 

while we do not have train data nor semant label avail for the 
kodak dataset, our GC model can also be train without semant map and 



gener adversari network for extrem learn imag compress 9 

thu do not need such label at test time. thu we can ass how well our 
model gener to kodak by train GC without semant on ade20k (i.e., 
non-conditional) and then test on kodak. the onli adjust we make 
when use our model be to slightli blur the imag (σ = 1.0) to avoid larg 
gradient in the imag which be not present in the train data (due to re- 
size with anti-aliasing). We do not observ ani improv for bpg when 
use blur, so we use bpg with standard settings. 

baselines: We compar our method to the hevc-bas imag compress al- 
gorithm bpg [1] (in the default 4:2:2 chroma format) and to the aedc net- 
work [8]. bpg be the current state-of-the-art engin imag compress codec 
and outperform other recent codec such a jpeg2000 and webp on differ 
data set in term of ms-ssim (see, e.g., [6]). We train the aedc network (with 
bottleneck depth C = 4) on cityscap exactli follow the procedur in [8] 
except that we use earli stop to prevent overfit (note that cityscap be 
much small than the imagenet dataset use in [8]). the so-obtain model have 
a bitrat of 0.07 bpp and obtain a slightli good ms-ssim than bpg at the 
same bpp on the valid set. As an addit baseline, we train our partial 
synthesi with an mse loss onli (all other train paramet be maintained, 
see sec. 5.4). 

quantit evaluation: qualiti measur such a psnr and ms-ssim com- 
monli use to ass the qualiti of compress system becom meaningless at 
veri low bitrat a they penal chang in local structur rather than preser- 
vation of the global content (thi also becom appar through our baselin 
train for mse, see sec. 5.5). We therefor measur the capac of our method 
to preserv the imag semant a proxi for the imag qualiti and compar 
it with the baselines. specifically, we use pspnet [45] and comput the mean 
intersection-over-union (iou) between the label map obtain for the decom- 
press valid imag and the ground truth label map. A similar approach 
be follow by imag translat work [12, 13] to ass imag qualiti of gener- 
ate images. 

user study: To quantit evalu the perceptu qualiti of our GC network 
in comparison with bpg and aedc we conduct a user studi use the amazon 
mechan turk (amt) platform1. for cityscap we consid 3 set for 
our method use C = 2, 4, 8 which correspond to 0.018, 0.036, and 0.072 bpp, 
respectively, and perform one-to-on comparison of the imag produc by our 
method to those of aedc at 0.07 bpp and bpg at 5 oper point in the rang 
[0.039, 0.1] bpp. A slightli differ setup be use for ade20k: We onli consid 
the 0.036 and 0.072 oper points, and employ the GC network train with 
semant label map for the latter oper point. To test the gener to 
the kodak dataset [44], we use the model train on ade20k for 0.036bpp. 

for each pair of method on cityscap and ade20k, we compar the 
decompress imag obtain for a set of 20 randomli pick valid images, 

1 https://www.mturk.com/ 



10 E. agustsson, M. tschannen, F. mentzer, R. timofte, and L. van gool 

have a refer the downscal 1024 × 512px images. for each pair on 
kodak, we use all 24 imag of the dataset. 9 randomli select user be 
ask to select the best decompress result for each test imag and pair of 
methods. 

visual comparisons: finally, we perform extens visual comparison of all our 
method and the baselin (see supplementari materi for more examples). 

5.4 train 

We employ the adam optim [46] with a learn rate of 0.0002 and set the 
mini-batch size to 1. our network be train for 50 epoch on cityscap and 
for 20 epoch on ade20k, asid from the network test on kodak which be 
train for 50 epoch on ade20k. 

for SC we consid two differ train modes: random instanc (ri) 
which randomli select 25% of the instanc in the semant label map and 
preserv these, and random box (rb) which pick an imag locat uniformli 
at random and preserv a box of dimens randomli select from the interv 
[200, 400] and [150, 300] for cityscap and ade20k, respectively. while the RI 
mode be appropri for most use cases, the RB can creat more challeng 
situat for the gener a it need to integr the preserv box seamlessli 
into the gener content. additionally, we add a mse loss term between the 
input imag and the reconstruct image, act on the mask region only, for 
train SC networks. 

5.5 result 

global gener compression: fig. 5 (left) show the mean iou on the cityscap 
valid set a a function of bpp for our GC network with C = 2, 4, 8, along 
with the valu obtain for the baselines. additionally, we plot mean iou for 
our network train with an mse loss, and the network obtain when feed 
semant label map to E and D dure training. It can be see that at a give 
target bpp, our network outperform bpg and aedc a well a our network 
train for mse by a larg margin. furthermore, feed the semant label to 
the encod and discrimin increas the mean valid iou. 

In tabl 1 and 2 we report the percentag of prefer of the imag pro- 
duce by the propos method over the imag produc by the other compress 
method for cityscap and ade20k, respectively. for each method vs. method 
comparison 180 human opinion be collected. for both data sets, the per- 
ceptual qualiti of our result be good than that of the baselin approach at 
compar bpp. for cityscapes, at 0.036 bpp our method be pick by the user 
over bpg in 81.87% of the cases, while at 0.072 bpp our method be prefer 
over bpg and aedc in 70.18% and 84.21% of the cases, respectively. 

In figs. 1, 3, and 4 we present exampl valid imag from cityscap 
and ade20k, respectively, produc by our GC network at differ bpp along 
with the imag obtain from the baselin algorithm at the same bpp. the GC 



gener adversari network for extrem learn imag compress 11 

our (0.072bpp) bpg (0.074bpp) aedc (0.074bpp) 

fig. 3: visual exampl of imag produc by our GC network with C = 8 along 
with the correspond result for bpg and aedc. 

our (0.036bpp) bpg (0.092bpp) our (0.072bpp) bpg (0.082bpp) 

fig. 4: visual exampl of imag produc by our GC network (left: C = 4; 
right: C = 8) along with the correspond result for bpg. 

produc imag with finer structur than bpg, which suffer from smooth 
patch and block artifacts. aedc and our network train for mse both 
produc blurri images. 

gener to kodak: We show the result for an exampl kodak imag in 
figur 6, obtain with a model train on ade20k for GC (without seman- 
tics) use C = 4 channel (0.036bpp). while there be some color shift notic 
(which could be account for by reduc the domain mismatch and/or increas- 
ing the weight of the perceptu loss), we see that our method can realist 
synthes detail where bpg fails. 

the user studi result in tabl 3 show that our method be prefer over 
bpg, even when bpg us an 80% larg bitrat of 0.065bpp compar to our 
method at 0.036bpp. 

select gener compression: We plot the mean iou for the cityscap val- 
idat set for our SC network and the baselin in fig. 5 (right) a a function 
of bpp. again, our network obtain a high mean iou than the baselin at the 
same bpp, for both the RI and RB train modes. the mean iou be almost 
constant a a function of bpp. 



12 E. agustsson, M. tschannen, F. mentzer, R. timofte, and L. van gool 

prefer of bpg [1] aedc [8] 
our result [%] vs. 0.039 bpp 0.056 bpp 0.072 bpp 0.079 bpp 0.1 bpp 0.069 bpp 

o 
u 
r 

C = 2, 0.018 bpp 76.02 52.05 45.03 38.01 29.24 71.93 
C = 4, 0.036 bpp 81.87 67.25 59.65 50.88 35.67 80.12 
C = 8, 0.072 bpp 83.63 74.27 70.18 67.84 50.88 84.21 

tabl 1: user studi quantit prefer result [%] on cityscapes. for each 
pair of method we report the percentag of case in which the imag produc 
by our GC method be prefer by human subject over the result of the other 
compress method. for compar bpp our method be clearli the prefer 
method. On average, bpg be onli perceptu good than our when a bitrat 
more than twice a larg be used. 

prefer of bpg [1] 
our result [%] vs. 0.054 bpp 0.064 bpp 0.072 bpp 0.082 bpp 0.1 bpp 

o 
u 
r C = 4, 0.036 bpp 66.67 52.63 36.26 / / 

C = 8, 0.072 bpp, w. sem. 80.12 73.68 57.31 52.63 41.52 

tabl 2: user studi quantit prefer result [%] on ade20k. for com- 
parabl bpp our method be clearli preferred. 

prefer of bpg [1] 
our result [%] vs. 0.038 bpp 0.060 bpp 0.065 bpp 0.072 bpp 

our C = 4, 0.036 bpp 87.10 57.60 54.84 47.00 

tabl 3: user studi quantit prefer result [%] on kodak. our method be 
prefer over bpg at 0.065bpp, which correspond to a 45% bitrat reduction. 

0.00 0.02 0.04 0.06 0.08 0.10 0.12 

10% 

20% 

30% 

40% 

50% 
miou vs. bpp (gc) 

our (semantics) 

our 

our (mse) 

bpg 

aedc 

0.00 0.04 0.08 0.12 0.16 0.20 

10% 

20% 

30% 

40% 

50% 
miou vs. bpp (sc) 

our (instance) 

our (box) 

our (mse) 

bpg 

aedc 

pix2pixhd 

fig. 5: left: mean iou a a function of bpp on the cityscap valid set for 
our GC networks, option train with semant label map at G and D (se- 
mantics) and with mse loss onli (mse). right: mean iou for our SC network 
train in the RI (instance) and RB (box) train modes. the pix2pixhd base- 
line [13] be train from scratch for 50 epochs, use the same downsampl 
1024× 512px train imag a for our method. 



gener adversari network for extrem learn imag compress 13 

kodak imag 13 our (0.036bpp) 

bpg (0.073bpp) jpeg2000 (0.037bpp) 

webp (0.078bpp) jpeg (0.248bpp) 

fig. 6: origin kodak imag 13 along with the decompress version use in 
the user studi (ours), obtain use our GC network with C = 4. We also 
show decompress bpg, jpeg, jpeg2000, and webp version of the image. 
If a codec be not abl to produc an output a low a 0.036bpp, we chose the 
low possibl bitrat for that codec. 

fig. 7 and 8 show exampl cityscap valid imag produc by the 
SC network train in the RI mode with C = 8 and C = 4, respectively, where 
differ semant class be preserved. while class such a tree and street 
look more realist than less structur class such a build or cars, most 
configur of mask yield visual pleas results, while lead to larg bpp 



14 E. agustsson, M. tschannen, F. mentzer, R. timofte, and L. van gool 

road (0.146 bpp, -55%) car (0.227 bpp, -15%) everyth (0.035 bpp, -89%) 

peopl (0.219 bpp, -33%) build (0.199 bpp, -39%) no synth. (0.326 bpp, -0%) 

fig. 7: synthes differ class use our SC network with C = 8. In each 
imag except for no synthesis, we addit synthes the class vegetation, 
sky, sidewalk, ego vehicle, wall. the heatmap in the low left corner show the 
synthes part in gray. We show the bpp of each imag a well a the rel 
save due to the select generation. 

base (0.062 bpp) +build (0.038 bpp) bpg (0.043 bpp) 

fig. 8: exampl imag obtain by our SC network (C = 4) synthes road, 
vegetation, sky, sidewalk, ego vehicle, wall for “base” on the left and addit 
build in the center. right show bpg at the low support bpp. 

origin 0.103bpp 0.103bpp 

fig. 9: exampl imag obtain by our SC network (C = 8) preserv a box 
and synthes the rest of the image. 

reduct compar to the network preserv the entir image. notably, the 
GC network can gener an entir imag from the semant label map only. 

In fig. 9 we present an exampl cityscap valid imag produc by an 
SC network (with C = 8) train in the RB mode, with a rectangular area pre- 
served. our network seamlessli integr the preserv region into the gener 
part of the image. fig. 10 show exampl imag from the ade20k valid 
set produc by SC network (with C = 8) for both the RB and RI train 
mode. 



gener adversari network for extrem learn imag compress 15 

fig. 10: exampl ade20k valid imag produc by our SC network with 
(C = 8) preserv randomli select instanc (left, network train with ri) 
or box-shap region (right, network train with rb). 

6 discuss 

the quantit evalu of the semant preserv capac (fig. 5) indi- 
cate that both the GC and the SC network good preserv semant than the 
baselin at the same bpp when evalu with pspnet. thi have to be take 
with a grain of salt, however, in the case where our network be provid with 
the semant label maps. It be not surpris that these network outperform 
bpg and aedc, which be not design or train specif to preserv 
semant information. note though that our GC network onli drop slightli in 
miou when train without semant (fig. 5 left), still have much high 
semant preserv capac than bpg and aedc. 

qualitatively, our GC network preserv more and sharper structur than the 
baselin methods, for both the cityscap and ade20k images. for both data 
sets, the user studi show that at a give target bpp human on averag prefer 
the pictur produc by our GC network over bpg. for cityscapes, where we 
train an aedc model, our imag be on averag also prefer over aedc. 
the cityscap imag obtain by our GC network with C = 2 (0.018bpp) 
and C = 4 (0.036 bpp) be even prefer over bpg at 0.056 and bpg at 
0.079 bpp, respectively, show that our method outperform bpg even when 
bpg us more than twice a mani bits. for ade20k, the result produc by 
our GC network be prefer on averag by a consider margin over bpg, 
although the prefer be less pronounc than for cityscapes. 

furthermore, we found that our model train on ade20k (with minor 
adjustments) can also gener well to the kodak dataset, be prefer over 
bpg for C = 4 (0.036bpp) even when bpg us 80% more bits. 

We note that while prior work [6, 8, 7] have outperform bpg in term 
of ms-ssim[10], they have not demonstr improv visual qualiti over bpg 
(which be optim for psnr). In particular, [7, 8] show a visual comparison but 
do not claim improv visual qualiti over bpg, wherea [6] do not compar 
with bpg visually. To the best of our knowledge, thi be the first time that a 
deep compress method be show to outperform bpg in a user study—and 
that with a larg margin. 



16 E. agustsson, M. tschannen, F. mentzer, R. timofte, and L. van gool 

In the SC oper mode, our network manag to seamlessli merg pre- 
serv and gener imag content both when preserv object instanc or 
box cross object boundaries. further, our network lead to reduct in 
bpp of 50% and more compar to the same network without synthesis, while 
leav the visual qualiti essenti unimpaired, when object with repetit 
structur be synthes (such a trees, streets, and sky). In some cases, the 
visual qualiti be even good than that of bpg at the same bitrate. the visual 
qualiti of more complex synthes object (e.g., buildings, people) be worse. 
however, thi be a limit of current gan technolog rather than our ap- 
proach. As the visual qualiti of gan improv further, SC network will a 
well. moreover, our SC network be base on simpl entropi cod without 
context model and it be not surpris that they do not outperform bpg in chal- 
leng scenario (in the case where no synthesi be performed, see fig. 7). indeed, 
bpg reli on advanc techniqu includ context modeling. We note that 
thi be mainli an engin problem; our network could be extend using, 
e.g., the context model from [8]. 

finally, the semant label map, which requir 0.036 bpp on averag for 
the downscal 1024 × 512px cityscap images, repres a rel larg 
overhead compar to the storag cost of the preserv imag parts. thi cost 
vanish a the imag size increases, sinc the semant mask can be store a an 
imag dimension-independ vector graphic. unfortunately, we could not train 
our model (nor the model of [13]) for imag larg than 1024 × 512px a thi 
requir a gpu with 24gb of memori (see [13]). We tri train on crop to 
reduc the memori usage, but thi lead to poor results—which could be explain 
by the fact that the discrimin then do not have a global view of the imag 
anymore. 

7 conclus 

We have propos a gan formul of learn compress that significantli 
outperform prior work for low bitrates, both in term of miou and human opin- 
ion. furthermore, our network can seamlessli combin preserv with gener 
imag content, produc realist look imag when synthes content with 
regular structure. 

promis direct for futur work be to develop a mechan to control 
spatial alloc of bit for gc, and to combin SC with salienc information. 
furthermore, it would be interest to incorpor a context model into our 
method, for exampl the one from [8], and to adapt the architectur so that it 
scale to even larg images. 



gener adversari network for extrem learn imag compress 17 

refer 

1. bellard, f.: bpg imag format. https://bellard.org/bpg/ 
2. : webp imag format. https://developers.google.com/speed/webp/ 
3. taubman, d.s., marcellin, m.w.: jpeg 2000: imag compress fundamentals, 

standard and practice. kluwer academ publishers, norwell, ma, usa (2001) 
4. theis, l., shi, w., cunningham, a., huszar, f.: lossi imag compress with 

compress autoencoders. in: intern confer on learn representa- 
tion (iclr). (2017) 

5. ballé, j., laparra, v., simoncelli, e.p.: end-to-end optim imag compression. 
arxiv preprint arxiv:1611.01704 (2016) 

6. rippel, o., bourdev, l.: real-tim adapt imag compression. in: proceed 
of the 34th intern confer on machin learning. volum 70 of pro- 
ceed of machin learn research., intern convent centre, sydney, 
australia, pmlr (06–11 aug 2017) 2922–2930 

7. ballé, j., minnen, d., singh, s., hwang, s.j., johnston, n.: variat imag 
compress with a scale hyperprior. in: intern confer on learn 
represent (iclr). (2018) 

8. mentzer, f., agustsson, e., tschannen, m., timofte, r., van gool, l.: condit 
probabl model for deep imag compression. in: ieee confer on comput 
vision and pattern recognit (cvpr). (2018) 

9. torfason, r., mentzer, f., ágústsson, e., tschannen, m., timofte, r., gool, l.v.: 
toward imag understand from deep compress without decoding. in: inter- 
nation confer on learn represent (iclr). (2018) 

10. wang, z., simoncelli, e.p., bovik, a.c.: multiscal structur similar for imag 
qualiti assessment. in: asilomar confer on signals, system computers, 2003. 
volum 2. (nov 2003) 1398–1402 vol.2 

11. goodfellow, i., pouget-abadie, j., mirza, m., xu, b., warde-farley, d., ozair, s., 
courville, a., bengio, y.: gener adversari nets. in: advanc in neural 
inform process systems. (2014) 2672–2680 

12. isola, p., zhu, j.y., zhou, t., efros, a.a.: image-to-imag translat with condi- 
tional adversari networks. in: proceed of the ieee confer on comput 
vision and pattern recognition. (2017) 1125–1134 

13. wang, t.c., liu, m.y., zhu, j.y., tao, a., kautz, j., catanzaro, b.: high- 
resolut imag synthesi and semant manipul with condit gans. in: 
ieee confer on comput vision and pattern recognit (cvpr). (2018) 

14. galteri, l., seidenari, l., bertini, m., del bimbo, a.: deep gener adversari 
compress artifact removal. in: proceed of the ieee confer on comput 
vision and pattern recognition. (2017) 4826–4835 

15. ledig, c., theis, l., huszar, f., caballero, j., cunningham, a., acosta, a., aitken, 
a., tejani, a., totz, j., wang, z., et al.: photo-realist singl imag super- 
resolut use a gener adversari network. in: proceed of the ieee 
confer on comput vision and pattern recognition. (2017) 4681–4690 

16. santurkar, s., budden, d., shavit, n.: gener compression. arxiv preprint 
arxiv:1703.01467 (2017) 

17. mirza, m., osindero, s.: condit gener adversari nets. arxiv preprint 
arxiv:1411.1784 (2014) 

18. zhao, h., shi, j., qi, x., wang, x., jia, j.: pyramid scene pars network. in: 
proceed of ieee confer on comput vision and pattern recognit 
(cvpr). (2017) 



18 E. agustsson, M. tschannen, F. mentzer, R. timofte, and L. van gool 

19. he, k., gkioxari, g., dollár, p., girshick, r.: mask r-cnn. in: comput vision 
(iccv), 2017 ieee intern confer on, ieee (2017) 2980–2988 

20. agustsson, e., mentzer, f., tschannen, m., cavigelli, l., timofte, r., benini, l., 
van gool, l.: soft-to-hard vector quantiz for end-to-end learn compress 
representations. arxiv preprint arxiv:1704.00648 (2017) 

21. li, m., zuo, w., gu, s., zhao, d., zhang, d.: learn convolut network for 
content-weight imag compression. arxiv preprint arxiv:1703.10553 (2017) 

22. toderici, g., o’malley, s.m., hwang, s.j., vincent, d., minnen, d., baluja, s., 
covell, m., sukthankar, r.: variabl rate imag compress with recurr neural 
networks. arxiv preprint arxiv:1511.06085 (2015) 

23. toderici, g., vincent, d., johnston, n., hwang, s.j., minnen, d., shor, j., covell, 
m.: full resolut imag compress with recurr neural networks. arxiv 
preprint arxiv:1608.05148 (2016) 

24. ballé, j., laparra, v., simoncelli, e.p.: end-to-end optim of nonlinear trans- 
form code for perceptu quality. arxiv preprint arxiv:1607.05006 (2016) 

25. salimans, t., goodfellow, i., zaremba, w., cheung, v., radford, a., chen, x.: 
improv techniqu for train gans. in: advanc in neural inform pro- 
cess systems. (2016) 2234–2242 

26. arjovsky, m., bottou, l.: toward principl method for train gener 
adversari networks. arxiv preprint arxiv:1701.04862 (2017) 

27. arjovsky, m., chintala, s., bottou, l.: wasserstein gan. arxiv preprint 
arxiv:1701.07875 (2017) 

28. mao, x., li, q., xie, h., lau, r.y., wang, z., smolley, s.p.: least squar gener- 
ativ adversari networks. in: 2017 ieee intern confer on comput 
vision (iccv), ieee (2017) 2813–2821 

29. kingma, d.p., welling, m.: auto-encod variat bayes. arxiv preprint 
arxiv:1312.6114 (2013) 

30. radford, a., metz, l., chintala, s.: unsupervis represent learn- 
ing with deep convolut gener adversari networks. arxiv preprint 
arxiv:1511.06434 (2015) 

31. zhang, h., xu, t., li, h., zhang, s., huang, x., wang, x., metaxas, d.: stack- 
gan: text to photo-realist imag synthesi with stack gener adversari 
networks. in: ieee int. conf. comput. vision (iccv). (2017) 5907–5915 

32. karras, t., aila, t., laine, s., lehtinen, j.: progress grow of gan for im- 
prove quality, stability, and variation. in: intern confer on learn 
represent (iclr). (2017) 

33. zhu, j.y., park, t., isola, p., efros, a.a.: unpair image-to-imag translat us- 
ing cycle-consist adversari networks. in: proceed of the ieee confer 
on comput vision and pattern recognition. (2017) 2223–2232 

34. liu, m.y., breuel, t., kautz, j.: unsupervis image-to-imag translat net- 
works. in: advanc in neural inform process systems. (2017) 700–708 

35. nowozin, s., cseke, b., tomioka, r.: f-gan: train gener neural sampler 
use variat diverg minimization. in: advanc in neural inform 
process systems. (2016) 271–279 

36. stella, x.y., lisin, d.a.: imag compress base on visual salienc at individu 
scales. in: intern symposium on visual computing, springer (2009) 157– 
166 

37. guo, c., zhang, l.: A novel multiresolut spatiotempor salienc detect 
model and it applic in imag and video compression. ieee transact on 
imag process 19(1) (2010) 185–198 



gener adversari network for extrem learn imag compress 19 

38. gupta, r., khanna, m.t., chaudhury, s.: visual salienc guid video compress 
algorithm. signal processing: imag commun 28(9) (2013) 1006–1022 

39. cover, t.m., thomas, j.a.: element of inform theory. john wiley & son 
(2012) 

40. johnson, j., alahi, a., fei-fei, l.: perceptu loss for real-tim style transfer 
and super-resolution. in: european confer on comput vision. (2016) 

41. he, k., zhang, x., ren, s., sun, j.: deep residu learn for imag recognition. 
in: ieee confer on comput vision and pattern recognit (cvpr). (june 
2016) 

42. cordts, m., omran, m., ramos, s., rehfeld, t., enzweiler, m., benenson, r., 
franke, u., roth, s., schiele, b.: the cityscap dataset for semant urban 
scene understanding. arxiv e-print (april 2016) 

43. zhou, b., zhao, h., puig, x., fidler, s., barriuso, a., torralba, a.: scene pars 
through ade20k dataset. in: proceed of the ieee confer on comput 
vision and pattern recognition. (2017) 

44. : kodak photocd dataset. http://r0k.us/graphics/kodak/ 
45. zhao, h., shi, j., qi, x., wang, x., jia, j.: pyramid scene pars network. arxiv 

e-print (decemb 2016) 
46. kingma, d.p., ba, j.: adam: A method for stochast optimization. corr 

abs/1412.6980 (2014) 



20 E. agustsson, M. tschannen, F. mentzer, R. timofte, and L. van gool 

gener adversari network for extrem learn 
imag compression: supplementari materi 

A compress detail 

recal that we use the upper bound eq. (5) to control the entropi of the bit- 
stream when train our networks. To verifi that thi upper bound be tight, we 
comput the actual bitrat in bpp for our GC network with C = 4 use an 
arithmet cod implementation. We find that use a uniform prior, it match 
the theoret bound up to the third signific digit. If we use a non-uniform 
per-imag probabl model, we obtain a bitrat reduct of 1.7%. 

We compress the semant label map for SC by quantiz the coordin 
in the vector graphic to the imag grid and encod coordin rel to 
preced coordin when travers object boundari (rather than rel to 
the imag frame). the so-obtain bitstream be then compress use arithmet 
coding. 

To ensur fair comparison, we do not count header size for ani of the baselin 
method throughout. 

B architectur detail 

We adopt the notat from [13] to describ our encod and generator/decod 
architectur and addit use q to denot the quantiz layer (see sec. 
3.3 for details). the output of q be encod and stored. 

– encod gc: c7s1-60,d120,d240,d480,d960,c3s1-c,q 
– encod sc: 
• semant label map encoder: c7s1-60,d120,d240,d480,d960 
• imag encoder: c7s1-60,d120,d240,d480,c3s1-c,q,c3s1-480,d960 

the output of the semant label map encod and the imag encod be 
concaten and fed to the generator/decoder. 

– generator/decoder: c3s1-960,r960,r960,r960,r960,r960,r960,r960, 
r960,r960,u480,u240,u120,u60,c7s1-3 

C visual 

In sec. c.1 and c.2 we present further visual exampl imag from cityscap 
and ade20k, respectively, obtain for SC when preserv randomli select 
semant class or box (see sec. 5.3 for detail on the experiments). the 
cityscapes, ade20k, and kodak imag use in the user studi along with the 
correspond bpg imag be show in sec. c.3, c.4, and c.52. 

2 https://data.vision.ee.ethz.ch/aeirikur/extremecompression/files/suppc5.pdf 



gener adversari network for extrem learn imag compress 21 

c.1 select compress (cityscapes) 

road (0.077 bpp) car (0.108 bpp) everyth (0.041 bpp) 

peopl (0.120 bpp) build (0.110 bpp) no synth (0.186 bpp) 

road (0.092 bpp) car (0.134 bpp) everyth (0.034 bpp) 

peopl (0.147 bpp) build (0.119 bpp) no synth (0.179 bpp) 

fig. 11: synthes differ class for two differ imag from cityscapes, 
use our SC network with C = 4. In each imag except for no synthesis, we 
addit synthes the class vegetation, sky, sidewalk, ego vehicle, wall. 

fig. 12: exampl imag obtain by our SC network (C = 8) preserv a box 
and synthes the rest of the image, on cityscapes. 



22 E. agustsson, M. tschannen, F. mentzer, R. timofte, and L. van gool 

c.2 select compress (ade20k) 

fig. 13: exampl ade20k valid imag obtain by our SC network (C = 8) 
preserv a box and synthes the remain imag area. the origin imag 
be show for comparison. 



gener adversari network for extrem learn imag compress 23 

fig. 14: preserv randomli chosen semant class in ade20k valid im- 
age and synthes the remain imag area use our SC network with 
C = 8. the origin imag be show for comparison. 



24 E. agustsson, M. tschannen, F. mentzer, R. timofte, and L. van gool 

c.3 global compress (cityscapes) 

our (0.036bpp) bpg (0.034bpp) 

our (0.036bpp) bpg (0.043bpp) 

our (0.036bpp) bpg (0.050bpp) 

our (0.036bpp) bpg (0.037bpp) 

our (0.036bpp) bpg (0.051bpp) 

our (0.036bpp) bpg (0.041bpp) 

our (0.036bpp) bpg (0.033bpp) 

our (0.036bpp) bpg (0.037bpp) 

our (0.036bpp) bpg (0.035bpp) 

our (0.036bpp) bpg (0.048bpp) 

fig. 15: decompress version of the first 10 imag use in the user studi on 
cityscapes, obtain use our GC network with C = 4 and bpg. 



gener adversari network for extrem learn imag compress 25 

our (0.036bpp) bpg (0.036bpp) 

our (0.036bpp) bpg (0.038bpp) 

our (0.036bpp) bpg (0.038bpp) 

our (0.036bpp) bpg (0.037bpp) 

our (0.036bpp) bpg (0.036bpp) 

our (0.036bpp) bpg (0.034bpp) 

our (0.036bpp) bpg (0.037bpp) 

our (0.036bpp) bpg (0.033bpp) 

our (0.036bpp) bpg (0.036bpp) 

our (0.036bpp) bpg (0.037bpp) 

fig. 16: decompress version of imag 11 − 20 use in the user studi on 
cityscapes, obtain use our GC network with C = 4 and bpg. 



26 E. agustsson, M. tschannen, F. mentzer, R. timofte, and L. van gool 

c.4 global compress (ade20k) 

our (0.036bpp) bpg (0.036bpp) 

our (0.036bpp) bpg (0.059bpp) 

our (0.036bpp) bpg (0.082bpp) 

our (0.036bpp) bpg (0.075bpp) 

our (0.036bpp) bpg (0.055bpp) 

our (0.036bpp) bpg (0.085bpp) 

our (0.036bpp) bpg (0.038bpp) 

our (0.036bpp) bpg (0.061bpp) 

our (0.036bpp) bpg (0.050bpp) 

our (0.036bpp) bpg (0.037bpp) 

our (0.036bpp) bpg (0.034bpp) 

our (0.036bpp) bpg (0.079bpp) 

fig. 17: decompress version of the first 12 imag use in the user studi on 
ade20k, obtain use our GC network with C = 4 and bpg. 



gener adversari network for extrem learn imag compress 27 

our (0.036bpp) bpg (0.054bpp) 

our (0.036bpp) bpg (0.074bpp) 

our (0.036bpp) bpg (0.065bpp) 

our (0.036bpp) bpg (0.137bpp) 

our (0.036bpp) bpg (0.037bpp) 

our (0.036bpp) bpg (0.036bpp) 

our (0.036bpp) bpg (0.037bpp) 

our (0.036bpp) bpg (0.036bpp) 

fig. 18: decompress version of imag 12 − 20 use in the user studi on 
ade20k, obtain use our GC network with C = 4 and bpg. 


