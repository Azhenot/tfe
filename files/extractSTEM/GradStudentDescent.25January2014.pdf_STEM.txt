






































grad student descent | scienc dryad 


scienc dryad 

data scienc blog 

grad student descent 

post on 2014/01/25 by sciencedryad 

(h ps://sciencedryad.files.wordpress.com/2014/01/picdatastorm.png)on januari 24, I a end a 1-day data scienc symposium at harvard 
univers with the fun titl ‘weather the data storm (h p://computefest.seas.harvard.edu/data-storm)‘. I imagin be in a tini boat 
on the endless beauti sea of data, and then a big data storm come up! number and piec of text fli through the air… they hit me hard 
in the face like hail, pile up in my boat… and i’m in dire need of some clever algorithm to take care of all that data, so that I won’t get 
hurt, my boat won’t sink! 

In line with the fun title, there be lot of fun talks. the funniest quot of the day clearli go to ryan adam 
(h p://www.seas.harvard.edu/directory/rpa) from harvard university, when he introduc a new name for a common machin learn 
‘method’: grad student descent. He talk about a ‘meta-problem’ of machin learning: most machin learn algorithm be suffici 
complex to give great result – if they be run with paramet that be adapt to the problem at hand. for example, to work with a neural 

grad student descent | scienc dryad https://sciencedryad.wordpress.com/2014/01/25/grad-student-descent/ 

1 sur 3 22/08/2017 13:54 



network you have to choos the number of layers, the weight regularization, the layer size, which non-linearity, the batch size, the learn 
rate schedule, the stop conditions… how do peopl choos these parameters? mostli with ad hoc, black magic methods. one method, 
common in academia, be ‘grad student descent’ (a pun on gradient descent), in which a graduat student fiddl around with the 
paramet until it works. it’ kind of sad, but it’ so true! Of course, ryan adam then go on to discu be er solut (‘meta- 
algorithms’ that automat find the parameters), but it be the ‘grad student descent’ that stuck to everyone’ mind. 

rachel schu (h p://idse.columbia.edu/rachel-schu -0) form new corp muse on the perenni question ‘what be a data scientist?’ she 
cite the well-known definit by josh will from cloudera, which I realli like: 

data scientist = “person who be be er at statist than ani softwar engin and be er at softwar engin than ani statistician.” 

but I hadn’t yet heard the clever rephras by will cukierski of kaggle: 

data scientist = “person who be bad at statist than ani statistician and bad at softwar engin than ani softwar engineer.” 

both quot nail down the interdisciplinari natur of the field of data scienc (and be realli funny). thi interdisciplinar be someth 
that I realli like. whenev I go to data scienc meetings, I meet peopl from so mani differ background – it be veri enriching, and the 
melt pot of so mani differ idea and way of think be enticing. It also match my own divers background, with lot of math, 
physics, statistics, biology, program thrown together… 

It be also great to see some data scienc tool celebrities. fernando perez, who start ipython in 2001, talk about the great featur of 
ipython – for example, I didn’t know that it also support other languag like R, julia, or sql. and jeff heer, creator of d3, show some 
awesom D3 visualizations, includ the most funni alternative-visu sequenc I have ever see (the first 15 second of thi video 
(h p://vimeo.com/29862153) by mike bostock). 

grad student descent | scienc dryad https://sciencedryad.wordpress.com/2014/01/25/grad-student-descent/ 

2 sur 3 22/08/2017 13:54 



thi entri be post in data science, meet and tag conference, data science, data scientist, harvard university, machin learning. 
bookmark the permalink. 

one thought on “grad student descent” 

angelika says: 
on 2015/10/26 at 11:01 
hi, after read thi amaz post i be also cheer to share my knowledg here with 
friends. 

repli 

creat a free websit or blog at wordpress.com. 

junior data engin 

busi & decis 

woluwé-saint- 
appli 

data engin 

grad student descent | scienc dryad https://sciencedryad.wordpress.com/2014/01/25/grad-student-descent/ 

3 sur 3 22/08/2017 13:54 


