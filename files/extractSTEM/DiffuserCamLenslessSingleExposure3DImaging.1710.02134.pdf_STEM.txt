


















































research articl 1 

diffusercam: lensless single-exposur 3D imag 
nick antipa1,*, grace kuo1,*, reinhard heckel1, ben mildenhall1, 
emrah bostan1, ren ng1, and laura waller1,+ 

1depart of electr engin & comput sciences, univers of california, berkeley, california 94720, usa 
*author contribut equal 
+correspond author: lwaller@alum.mit.edu 

compil octob 6, 2017 

We demonstr a compact and easy-to-build comput camera for single-shot 3D imag- 
ing. our lensless system consist sole of a diffus place in front of a standard imag sen- 
sor. everi point within the volumetr field-of-view project a uniqu pseudorandom pattern 
of caustic on the sensor. By use a physic approxim and simpl calibr scheme, we 
solv the large-scal invers problem in a comput effici way. the caustic pattern 
enabl compress sensing, which exploit sparsiti in the sampl to solv for more 3D voxel 
than pixel on the 2D sensor. our 3D voxel grid be chosen to match the experiment mea- 
sure two-point optic resolut across the field-of-view, result in 100 million voxel be 
reconstruct from a singl 1.3 megapixel image. however, the effect resolut vari sig- 
nificantli with scene content. becaus thi effect be common to a wide rang of comput 
cameras, we provid new theori for analyz resolut in such systems. 

1. introduct 

becaus optic sensor be 2d, captur 3D inform re- 
quir project onto a 2D sensor in such a way that the 3D data 
can be recovered. scan and multi-shot method can achiev 
high spatial resolution, but sacrific captur speed and requir 
complex hardware. In contrast, exist single-shot method be 
fast but have low resolution. most 3D imag requir bulki 
hardware, such a larg bench-top microscopes. In thi work, we 
introduc a compact and inexpens single-shot lensless system 
capabl of volumetr imaging, and show that it improv upon 
the sampl limit of exist single-shot system by leverag 
compress sensing. 

We present diffusercam, a lensless imag that us a dif- 
fuser to encod the 3D intens of volumetr object into a 
singl 2D image. the diffuser, a thin phase mask, be place a 
few millimet in front of a tradit 2D imag sensor. each 
point sourc in 3D space creat a uniqu pseudorandom caus- 
tic pattern that cover a larg portion of the sensor. due to 
these properties, compress sens algorithm can be use 
to reconstruct more voxel than pixel captured, provid that 
the 3D sampl be spars in some domain. We recov thi 3D 
inform by solv a sparsity-constrain optim prob- 
lem, use a physic model and simpl calibr scheme to 

make the comput and calibr scalable. thi allow u 
to reconstruct on a grid of 100 million voxels, sever order of 
magnitud more than previou work. 

We demonstr a prototyp diffusercam system built en- 
tire from commod hardware. It be simpl to calibrate, do 
not requir precis align dure construct and be light 
effici (a compar to amplitud masks). We reconstruct 3D 
object on a grid of 100 million voxel (non-uniformli spaced) 
from a singl 1.3 megapixel image, which provid high resolu- 
tion across a larg volume. our reconstruct show true depth 
sectioning, allow u to gener 3D render of the sample. 

our system us a nonlinear reconstruct algorithm, which 
result in object-depend performance. We quantifi thi by ex- 
periment measur the resolut of our prototyp use a 
varieti of test targets, and we show that the standard two-point 
resolut criterion be mislead and should be consid a 
best-cas scenario. additionally, we propos a new local condi- 
tion number analysi that explain the variabl resolv power 
and show that the theori be consist with our experiments. 

diffusercam us concept from lensless camera technolog 
and imag through complex media, integr togeth via 
comput imag design principles. thi new devic could 
enabl high-resolut lensless 3D imag of larg and dynam 

ar 
X 

iv 
:1 

71 
0. 

02 
13 

4v 
1 

[ 
c 

.C 
V 

] 
5 

O 
ct 

2 
01 

7 



research articl 2 

experiment setup 

diffus 

sensor 

calibr 

algorithm 3D reconstruct 
v̂ = argmin 

v≥0 
1 
2‖b−hv‖22 
+λ‖ψv‖1 

fig. 1. diffusercam setup and reconstruct pipeline. our lensless system consist of a diffus place in front of a sensor (bump 
on the diffus be exagger for illustration). the system encod a 3D scene into a 2D imag on the sensor. A one-tim calibra- 
tion consist of scan a point sourc axial while captur images. imag be reconstruct comput by solv a 
nonlinear invers problem with a sparsiti prior. the result be a 3D imag reconstruct from a singl 2D measurement. 

3D sampl in an extrem compact package. such camera 
will open up new applic in remot diagnostics, mobil 
photographi and in vivo microscopy. 

To review relat previou work, we start with lensless cam- 
era for 2D photography, which have show great promis be- 
caus of their small form factors. unlik tradit cameras, in 
which a point in the scene map to a pixel on the sensor, lensless 
camera map a point in the scene to mani point on the sensor, 
requir comput reconstruction. A typic lensless ar- 
chitectur replac the len with an encod element place 
directli in front of the sensor. incoher 2D lensless camera 
have be demonstr use amplitud mask [1], diffract 
mask [2, 3], random reflect surfac [4, 5], and modifi mi- 
crolen array [6] a the encod element. 2D lensless imag 
with coher illumin have be demonstr in [7, 8], and 
extend to 3D [9–12], but these method requir activ or coher- 
ent illumination. our system us a similar lensless architectur 
but extend both the design and imag reconstruct to enabl 
3D captur without the need for coher lighting. 

light field cameras, also call integr imagers, passiv 
captur 4D space-angl inform in a single-shot [13], which 
can be use for 3D reconstructions. thi concept can be built 
into a thin form factor with microlen array [14] or fresnel 
zone plate [15]. lenslet array-bas 3D captur scheme have 
also be use in microscopi [16], where improv result be 
obtain when wave-opt effect [17, 18] or in vivo tissu scat- 
tere [18, 19] be account for. all of these system must trade 
resolut or field-of-view for single-shot capture. diffusercam, 
in contrast, us compress sens to captur larg 3D vol- 
ume at high resolut in a singl exposure. 

diffus be often use a a proxi for gener scatter me- 
dia in the context of develop method for imag through 
scatter [20–22]. these work have similar mathemat mod- 
el to our system, but instead of tri to mitig the effect 
of unwant scattering, here we use the diffus a an optic 
element in our system design. therefore, we choos a thin, opti- 
calli smooth diffus that refract pseudorandomli (a oppos 
to true random scattering). such diffus have be show to 
produc high contrast pattern under incoher illumination, 
enabl light field imag [23], and have also be use to 
record coher hologram [10, 24]. multipl scatter with 
coher illumin have be demonstr a an encod 
mechan for 2D compress sens [25], but necessit an 

ineffici transmiss matrix calibr approach, limit re- 
construct to a few thousand pixels. We achiev similar bene- 
fit without need coher illumination, and, unlik previou 
work, we use compress sens to add depth information. 
finally, our system be design to enabl simpler calibr and 
more effici computation, allow for 3D reconstruct at 
megavoxel scale with superior imag quality. 

A. system overview 
diffusercam be part of the class of mask-bas lensless imag 
in which a phase or amplitud mask be place a small distanc 
in front of a sensor, with no main lens. our mask (the diffuser) 
be a thin transpar phase object with smoothli vari thick- 
ness (see fig. 1). when illumin by an incoher sourc 
suffici far from the sensor, the convex bump concentr 
light into high-frequ pseudorandom caustic pattern which 
be captur by the sensor. the caustic patterns, term point 
spread function (psfs), vari with the 3D posit of the source, 
therebi captur 3D information. 

To illustr how the caustic encod 3D information, fig. 2 
show simul of caustic psf a a function of point sourc 
locat in object space. A later shift of the point sourc caus 
a later translat of the psf. An axial shift of the point sourc 
caus (approximately) a scale of the psf. hence, each 3D 
posit in the volum gener a uniqu psf. the resolut 
of our camera depend on the structur and spatial frequenc 
present in the caustic patterns. becaus the caustic retain high 
spatial frequenc over a larg rang of depths, diffusercam 
attain good later resolut for object at ani depth within 
the volumetr field-of-view (fov). 

By assum that all point in the scene be incoher with 
each other, the measur can be model a a linear combi- 
nation of psf from differ 3D positions. We repres thi a 
matrix-vector multiplication: 

b = hv, (1) 

where b be a vector repres the 2D sensor measur 
and v be a vector repres the intens of the object at everi 
point in the 3D fov, sampl on a user-chosen grid (discuss in 
section 3). H be the forward model matrix whose column consist 
of each of the caustic pattern creat by the correspond 3D 
point on the object grid. the number of entri in b and the 
number of row of H be equal to the number of pixel on the 



research articl 3 

b depth depend of the psf 

a later depend of the psf 

fig. 2. caustic pattern shift with later shift of a point 
sourc in the scene and scale with axial shifts. (a) ray-trac 
render of caustic a the point sourc move laterally. for 
larg shift (far right), part of the pattern be clip by the sen- 
sor. (b) the caustic approxim magnifi a the sourc be 
brought closer. 

imag sensor, but the number of column in H be set by the 
choic of reconstruct grid. note that thi model do not 
account for partial occlus of sources. 

In order to reconstruct the 3D image, v, from the measur 
2D image, b, we must solv eq. (1) for v. however, if we use 
the full optic resolut of our system (see sec. 3b), v will 
exist on a grid that contain more voxel than there be pixel on 
the sensor. In thi case, H have mani more column than rows, 
so the problem be underdetermin and we cannot uniqu 
recov v simpli by invert eq. (1). To remedi this, we reli 
on sparsity-bas comput principl [26]. We exploit the 
fact that the object can be repres in a domain in which it 
be spars (few non-zero elements) and solv the `1 regular 
invers problem: 

v̂ = argmin 
v≥0 

1 
2‖b−hv‖22 + λ‖ψv‖1. (2) 

here, Ψ be a linear transform that sparsifi the 3D object, v ≥ 0 
be a nonneg constraint, and λ be a tune parameter. for 
object that be spars in nativ 3D space, such a fluoresc 
samples, we choos Ψ to be the ident matrix. for object that 
be not nativ sparse, but whose gradient be sparse, we choos 
Ψ to be the finit differ operator, so ‖ψv‖1 be the 3D total 
variat (tv) semi-norm [27]. 

equat (2) be the basi pursuit problem in compress sens- 
ing [26]. for thi optim procedur to succeed, H must 
have distributed, uncorrel columns. the diffus creat 
caustic that spread across mani pixel in a pseudorandom fash- 
ion and contain high spatial frequencies. therefore, ani shift 
or magnif of the caustic lead to a new pattern that be 
uncorrel with the origin one. As discuss in section 2B 
and 2c, these two properti lead to a matrix that allow u to 
reconstruct 3D imag v from the measur b = hv. 

2. method 

A. system architectur 

the hardwar setup for diffusercam consist of a diffus place 
at a fix distanc in front a sensor (see fig. 3a). the convex 
bump on the diffus surfac can be thought of a a set of 

randomly-spac microlens that have statist vari fo- 
cal length and f-numbers. the f-number determin the mini- 
mum featur size of the caustics, which set our optic resolu- 
tion. the averag focal length determin the distanc at which 
the caustic have high contrast (the caustic plane), which be 
where we place the sensor [23]. 

our prototyp be built use a pco.edg 5.5 color camera 
(6.5µm pixels). the diffus be an off-the-shelf engin dif- 
fuser (luminit 0.5◦) with a flat input surfac and an output 
surfac that be describ statist a gaussian lowpass fil- 
tere white nois with an averag spatial featur size of 140µm 
and averag slope magnitud of 0.7◦ (detail in supplementari 
fig. s1). thi correspond to an averag focal length of approx- 
imat 8 mm and averag f-number of 50. due to the high 
f-number, the caustic maintain high contrast over a larg rang 
of propag distances. therefore, the diffus need not be 
place precis at the caustic plane; in our prototype, d = 8.9 
mm from our sensor. additionally, we affix a 5.5 × 7.5 mm 
apertur directli on the textur side of the diffus to limit the 
support of the caustics. 

similar to a tradit camera, the pixel pitch should nyquist 
sampl the minimum featur of the caustics. the small 
featur gener by the caustic pattern be roughli twice the 
pixel pitch on our sensor, so we perform 2x2 bin on the 
data, yield 1.3 megapixel images, befor appli our 3D 
reconstruct algorithm. 

B. convolut forward model 

recov a 3D imag requir know the system transmis- 
sion matrix, H, which be extrem large. measur or store 
the full H would be impractical, requir million of calibr 
imag and oper on multi-terabyt matrices. the convo- 
lution model outlin below drastic reduc complex of 
both calibr and computation. 

We describ the object, v, a a set of point sourc locat 
at (x, y, z) on a non-cartesian grid and repres the rel 
radiant power collect by the apertur from each sourc a 
v(x, y, z). the caustic pattern at pixel (x′, y′) on the sensor due to 
a unit-pow point sourc at (x, y, z) be the psf, h(x′, y′; x, y, z). 
thus, b(x′, y′) repres the 2D sensor measur record 
after the light from everi point in v propag through the 
diffus and onto the sensor. thi let u explicitli write the 
matrix-vector multipl Hv by sum over all voxel in 
the fov: 

b(x′, y′) = ∑ 
(x,y,z) 

v(x, y, z)h(x′, y′; x, y, z). (3) 

the convolut model amount to a shift invari (or infi- 
nite memori effect [20, 21]) assumption, which greatli simplifi 
the evalu of eq. (3). consid the caustic creat by point 
sourc at a fix distance, z, from the diffuser. becaus the 
diffus surfac be slowli vari and smooth, the paraxi ap- 
proxim holds. thi impli that a later translat of the 
sourc by (∆x, ∆y) lead to a later shift of the caustic on the 
sensor by (∆x′, ∆y′) = (m∆x, m∆y), where m be the paraxi 
magnification. We valid thi behavior in both simul 
(see fig. 2) and experi (see section 3d). for notat 
convenience, we defin the on-axi caustic pattern at depth z a 
h(x′, y′; z) := h(x′, y′; 0, 0, z). thus, the off-axi caustic pattern 
be give by h(x′, y′; x, y, z) = h(x′ + mx, y′ + my; z). plug 



research articl 4 

diffusercam 

20 mm 

3 mm 

each box repres 
20 x 20 voxel 

x 

z 

c experiment 2-point resolut at z = 20 mm 

d 

axial distanc (μm) 
center 20 mm from diffus 

N 
ot 


re 

so 
lv 

ed 
B 

ar 
el 

y 
re 

so 
lv 

ed 
C 

le 
ar 

ly 
re 

so 
lv 

ed 

later axial 

x 
y 250 um 

x 
z 

0-60 
later 

distanc (μm) 

0-4480 

1 

In 
te 

n 
iti 

(a 
. u 

.) 

0 

1 

In 
te 

n 
iti 

(a 
. u 

.) 

0 

1 

In 
te 

n 
iti 

(a 
. u 

.) 

0-60 0-448 

0-60 0-448 

50 um 

50 um 

angl of incid (o) 

Pi 
xe 

l R 
e 

po 
n 

e 

x: αc = 41.5 
o 

y: αc = 30 
o 

d 

l w 

α 

β 

αc 

sensor 

diffuserapertur 
a b 

0 30 60 90 
0 

0.2 
0.4 
0.6 
0.8 

1 
xy 

fig. 3. experiment determin field-of-view (fov) and resolution. (a) system architectur with design parameters. (b) angular 
pixel respons of our sensor. We defin the angular cutoff (αc) a the angl at which the respons fall to 20%. (c) reconstruct 
imag of two point (captur separately) at vari separ later and axially, near the z = 20 mm depth plane. point be 
consid resolv if they be separ by a dip of at least 20%. (d) to-scal non-uniform voxel grid for 3D reconstruction, view 
from above. the voxel grid be base on the system geometri and nyquist-sampl two-point resolut over the entir fov. for 
visual purposes, each box repres 20×20 voxels, a show in red. 

into eq. (3), the sensor measur be then give by: 

b(x′, y′) = ∑ 
z 

∑ 
(x,y) 

v(x, y, z)h(x′ + mx, y′ + my; z) 

= C ∑ 
z 

[ 
v 
(−x′ 

m 
, 
−y′ 
m 

, z 
) 
∗ h 

( 
x′, y′; z 

)] 
. 

(4) 

here, ∗ repres 2D discret convolut over (x′, y′), which 
return array that be larg than the originals. hence, we crop 
to the origin sensor size, denot by the linear oper C. for 
an object discret into Nz depth slices, the number of column 
of H be Nz time larg than the number of element in b (i.e. the 
number of sensor pixels), so our system be underdetermined. 

the crop convolut model provid three benefits. first, 
it allow u to comput Hv a a linear oper in term of Nz 
images, rather than instanti H explicitli (which would re- 
quir petabyt of memori to store). In practice, we evalu 
the sum of 2D crop convolut use a singl circular 3D 
convolution, enabl the use of 3D ffts, which scale well to 
larg array size (for details, see supplementari sec. 2). second, 
it provid u with a theoret justif of our system’ ca- 
pabil for spars reconstruction. deriv in [28] show that 
translat copi of a random pattern provid close-to-optim 
compress sens performance. 

the third benefit of our convolut model be that it enabl 
simpl calibration. rather than measur the system respons 
from everi voxel (million of imag per depth), we onli need to 
captur a singl calibr imag of the caustic pattern from an 
on-axi point sourc at each depth plane.1 A typic calibr 

1while the scale effect describ in sec. 1A suggest that we could use onli 

thu consist of captur imag a a singl point sourc be 
move axially. thi take minutes, but need onli be perform 
once. the add apertur on diffusercam ensur that a point 
sourc at the minimum z distanc gener caustic that just fill 
the sensor, so that the entir psf be captur in each imag (see 
supplementari fig. s2). 

C. invers algorithm 
our invers problem be extrem larg in scale, with million of 
input and outputs. even with the convolut model describ 
above, use project gradient techniqu be extrem slow 
due to the time requir to comput the proxim oper of 
3D total variat [29]. To allevi this, we use the altern 
direct method of multipli (admm) [30]. We deriv a 
variabl split that leverag the specif structur of our 
problem. 

our algorithm us the fact that Ψ can be write a a circu- 
lar convolut for both the 3D TV and nativ sparsiti cases. 
additionally, we factor the forward model in eq. (4) into a di- 
agon component, D, and a 3D convolut matrix, M, such 
that H = DM (detail in sec. ). thus, both the forward oper- 
ator and the regular can be comput in 3D fouier space. 
thi enabl u to use variable-split [31–33] to formul the 
constrain counterpart of eq. (2): 

v̂ = argmin 
w≥0,u,v 

1 
2‖b−dv‖22 + λ‖u‖1 

s.t. v = mv, u = ψv, w = v, 
(5) 

one imag for calibr and scale it to predict psf at differ depths, we find 
that there be subtl chang in the caustic structur with depth. hence, we obtain 
good result when we calibr with psf measur at each depth. 



research articl 5 

where v, u, and w be auxiliari variables. We solv eq. (5) 
by follow the commonly-us augment lagrangian argu- 
ment [34]. use admm, thi result in the follow scheme 
at iter k: 

uk+1 ← T λ 
µ2 

( 
ψvk + ηk 

/ 
µ2 

) 
vk+1 ← (dᵀd + µ1 i)−1 

( 
ξk + µ1mvk + dᵀb 

) 
wk+1 ← max 

( 
ρk 
/ 

µ3 + vk, 0 
) 

vk+1 ← (µ1mᵀm + µ2ψᵀψ + µ3 i)−1 rk 

ξk+1 ← ξk + µ1(mvk+1 − vk+1) 
ηk+1 ← ηk + µ2(ψvk+1 − uk+1) 
ρk+1 ← ρk + µ3(vk+1 − wk+1), 

where 

rk = (µ3wk+1 − ρk) + Ψᵀ 
( 

µ2uk+1 − ηk 
) 
+ Mᵀ 

( 
µ1vk+1 − ξk 

) 
. 

note that Tν be a vectori soft-threshold oper with a 
threshold valu of ν [35], and ξ, η and ρ be the lagrang multi- 
plier associ with v, u, and w, respectively. the scalar µ1, µ2 
and µ3 be penalti paramet which we comput automat 
use the tune strategi in [30]. 

although our algorithm involv two large-scal matrix in- 
versions, both can be comput effici and in close form. 
sinc D be diagonal, (dᵀd + µ1 I) be itself diagonal, requir 
complex o(n) to invert use point-wis multiplication. ad- 
ditionally, all three matrix in (µ1mᵀm + µ2ψᵀψ + µ3 I) be 
diagon by the 3D discret fourier transform (dft) matrix, 
so invers of the entir term can be do use point-wis di- 
vision in 3D frequenc space. therefore, it invers have good 
comput complexity, o(n3 log n), sinc it be domin by 
two 3D fft be appli to n3 total voxels. We parallel 
our algorithm on the cpu use c++ and halid [36], a high 
perform program languag special for imag pro- 
cess (A comparison of regular and runtim be show in 
supplementari sec. 2c). 

A typic reconstruct requir at least 200 iterations. solv- 
ing for 2048 × 2048 × 128 = 537 million voxel take 26 
minut (8 second per iteration) on a 144-core workstat 
and requir 85 gigabyt of ram. A small reconstruct 
(512× 512× 128 = 33.5 million voxels) take 3 minut (1 sec- 
ond per iteration) on a 4-core laptop with 16 gigabyt of ram. 

3. system analysi 

unlik tradit cameras, the perform of comput 
camera depend on properti of the scene be imag (e.g. 
the number of sources). As a consequence, standard two-point 
resolut metric may be misleading, a they do not predict 
resolv power for more complex objects. To address this, we 
propos a new local condit number metric that good predict 
performance. We analyz resolution, fov and the valid of the 
convolut model, then combin these analysi to determin 
the appropri sampl grid for faith reconstruct real- 
world objects. 

A. field-of-view 
At everi depth in the volume, the angular half-fov be deter- 
mine by the most extrem later posit that contribut 
to the measurement. there be two possibl limit factors. 

y 

x 300 um 

e max 

0 

max 

0 
100 um 

z 

x 

y 

x 

100 um 

300 um 

f 

c d 

a b 

separ 
Δx = 45 um, Δz = 336 um 

separ 
Δx = 75 um, Δz = 448 um 

R 
ec 

on 
st 

ru 
ct 

ed 


2 
po 

in 
t 


R 

ec 
on 

st 
ru 

ct 
ed 


16 

p 
oi 

nt 
s 

R 
aw 

D 
at 

a 
16 

p 
oi 

nt 
s 

fig. 4. our comput camera have object-depend per- 
formance, such that the resolut depend on the number 
of points. (a) To illustrate, we show here a situat with two 
point success resolv at the two-point resolut limit 
(∆x, ∆z) = (45µm, 336µm) at a depth of approxim 20 
mm. (c) however, when the object consist of more point 
(16 point in a 4×4 grid in the x − z plane) at the same spac- 
ing, the reconstruct fails. (b,d) increas the separ to 
(∆x, ∆z) = (75µm, 448µm) give success reconstructions. 
(e,f) A close-up of the raw data show notic split of 
the caustic line for the 16 point case, make the point dis- 
tinguishable. heuristically, the 16 point resolut cutoff be a 
good indic of resolut for real-world objects. 

the first be the geometr angular cutoff, α, set by the apertur 
size, w, the sensor size, l, and the distanc from the diffus to 
the sensor, d (see fig. 3a). sinc the diffus bend light, we 
also take into account the diffuser’ maximum deflect angle, 
β. thi give a geometr angular half-fov at everi depth of 
l + w = 2d tan(α− β). the second limit factor be the angular 
respons of the sensor pixels. real-world sensor pixel may not 
accept light at the high angl of incid that our lensless cam- 
era accepts, so the sensor angular respons (shown in fig. 3b) 
may limit the fov. defin the angular cutoff of the sensor, αc, 
a the angl at which the camera respons fall to 20% of it 
on-axi value, we can write the overal fov equat as: 

fov = β + min[αc, tan−1( l+w2d )]. (6) 

sinc we imag in 3d, we must also consid the axial fov. 
In practice, the axial fov be limit by the rang of calibr 
depths. however, the system geometri creat bound on possi- 
ble calibr locations. calibr cannot be arbitrarili close 
to the sensor sinc the caustic would exceed the sensor size. 
To account for this, we impos a minimum object distanc such 
that an on-axi point sourc creat caustic that fill the sensor. 
theoretically, our system can captur sourc infinit far away, 



research articl 6 

but the axial resolut degrad with depth. the hyperfoc 
plane repres the axial distanc after which no more axial 
resolut be available, establish an upper bound. object 
beyond the hyperfoc focal plane have no depth information, 
but can be reconstruct to creat 2D imag for photograph 
applic [37], without ani hardwar modifications. 

In our prototype, the axial fov rang from the minimum cali- 
bration distanc (7.3 mm) to the hyperfoc plane (2.3 m). the an- 
gular fov be limit by the pixel angular accept (αc = 41.5◦ 

in x, αc = 30◦ in y). combin with our diffuser’ maximum 
deflect angl (β = 0.5◦) thi yield an angular fov of ±42◦ 
in x and ±30.5◦ in y. We valid the fov experiment by 
captur a scene at optic infin and measur the angular 
extent of the result (see supplementari fig. s3). 

B. resolut 
investig optic resolut be critic for both quantifi 
system perform and choos our reconstruct grid. al- 
though the raw data be collect on a fix sensor grid, we can 
choos the non-uniform 3D reconstruct grid arbitrarily. the 
choic of reconstruct grid be important. when the grid be cho- 
sen with voxel that be too large, resolut be lost, and when 
they be too small, extra comput be perform without reso- 
lution gain. In thi section we explain how to choos the grid of 
voxel for our reconstructions, with the aim of nyquist sampl 
the two-point optic resolut limit. 

b.1. two-point resolut 

A common metric for resolut analysi in tradit camera 
be two-point distinguishablity. We measur our system’ two- 
point resolut by imag scene contain two point sourc 
at differ separ distances, built by sum togeth im- 
age of a singl point sourc (1µm pinhole, wavelength 532nm) 
at two differ locations. 

We reconstruct the scene use our algorithm, with λ = 0 
to remov the influenc of the regularizer. To ensur best-cas 
resolution, we use the full 5 MP sensor data (no 2× 2 binning). 
the point sourc be consid distinguish if the recon- 
struction have a dip of at least 20% between the sources, a in the 
rayleigh criterion. figur 3c show reconstruct with point 
sourc separ both later and axially. 

our system have highli non-isotrop resolut (fig. 3d), but 
we can use our model to predict the two-point distinguishabil- 
iti over the entir volum from local experiments. due to 
the shift invari assumption, the later resolut be con- 
stant within a singl depth plane and the paraxi magnif 
caus the later resolut to vari linearli with depth. for 
axial resolution, the main differ between two point sourc 
be the size of their psf supports. We find pair of depth such 
that the differ in their support width be constant: 

c = 1z1 − 
1 
z2 . (7) 

here, z1 and z2 be neighbor depth and c be a constant deter- 
mine experimentally. 

base on thi model, we set the voxel space in our grid to 
nyquist sampl the 3D two-point resolution. figur 3d show 
a to-scal map of the result voxel grid. axial resolut 
degrad with distanc until it reach the hyperfoc plane 
(∼2.3 m from the camera), beyond which no depth inform 
be recoverable. due to the non-telecentr natur of the system, 
the voxel size be a function of depth, with the densest sampl 
occur close to the camera. object within 5 cm of the camera 

can be reconstruct with somewhat isotrop resolution; thi be 
where we place object in practice. 

b.2. multi-point resolut 

In a tradit camera, resolut be a function of the system 
and be independ of the scene. In contrast, comput 
camera that use nonlinear reconstruct algorithm may incur 
degrad of the effect resolut a the scene complex 
increases. To demonstr thi in our system, we consid a more 
complex scene consist of 16 point sources. figur 4 show 
experi use 16 point sourc arrang in a 4×4 grid in 
the (x, z) plane at two differ spacings. the first space be 
set to match the measur two-point resolut limit (∆x=45µm, 
∆z=336µm). despit be abl to separ two point at thi 
spacing, we cannot resolv all 16 sources. however, if we in- 
creas the sourc separ to (∆x=75µm, ∆z=448µm), all 16 
point be distinguish (fig. 4d). In thi example, the usabl 
later resolut of the system degrad by approxim 1.7× 
due to the increas scene complexity. As we show in section 
3c, the resolut loss do not becom arbitrarili bad a the 
scene complex increases. 

thi experi demonstr that exist resolut metric 
cannot be blindli use to determin perform of computa- 
tional camera like ours. how can we then analyz resolut 
if it depend on object properties? In the next section, we intro- 
duce a gener theoret framework for assess resolut in 
comput cameras. 

C. local condit number theori 
our goal be to provid new theori that describ how the effec- 
tive reconstruct resolut of comput camera chang 
with object complexity. To do so, we introduc a numer 
analysi of our forward model to determin how well it can be 
inverted. 

first, note that recov the imag v from the measur 
b = Hv compris simultan estim of the locat 
of all nonzero within our imag reconstruction, v, a well a 
the valu at each nonzero location. To simplifi the problem, 
suppos an oracl tell u the exact locat of everi sourc 
within the 3D scene. thi correspond to know a priori the 
support of v, so we then need onli determin the valu of the 
nonzero element in v. thi can be accomplish by solv 
a least squar problem use a sub-matrix consist of onli 
the column of H that correspond to the index of the nonzero 
voxels. If thi problem fails, then the more difficult problem 
of simultan determin the nonzero locat and their 
valu will certainli fail. 

In practice, the measur be corrupt by noise. the 
maxim effect thi nois can have on the least-squar estim 
of the nonzero valu be determin by the condit number 
of the sub-matrix describ above. We therefor say that the 
reconstruct problem be ill-pos if ani sub-matric of H be 
veri ill-conditioned. In practice, ill-condit matrix result 
in increas nois sensit and longer reconstruct times, 
a more iter be need to converg to a solution. 

the worst-cas scenario in our system be when multipl 
sourc be in a contigu block, sinc nearbi measur 
be alway most similar. therefore, we comput the condit 
number of sub-matric of H correspond to a group of point 
sourc with separ vari by integ number of voxels. 
We repeat thi calcul for differ number of sources. the 
result be show in fig. 5. As expected, the condit be 
bad when sourc be closer together. In thi case, increas 



research articl 7 

x 
y 

Δ 

Δ 

30 μm 

a b 

0 100 200 300 400 
0 

50 

100 

150 
2 
50 
100 
150 
200 

number of 
sourc 

250 

seper distanc (μm) 
C 

on 
di 

tio 
n 

N 
um 

be 
r 

fig. 5. our local condit number theori show how resolu- 
tion vari with object complexity. (a) virtual point sourc 
be simul on a fix grid and move by integ number 
of voxel to chang the separ distance. (b) local condi- 
tion number be plot for sub-matric correspond to 
grid of neighbor point sourc with vari separ 
(at depth 20 mm from the sensor). As the number of sourc 
increases, the condit number approach a limit, indic 
that resolut for complex object can be approxim by a 
limit number (but more than two) sources. 

nois sensit mean that even small amount of nois could 
prevent u from resolv the sources. thi trend match what 
we saw experiment in figs. 3 and 4. 

figur 5 show that the local condit number increas with 
the number of sourc in the scene, a expected. thi mean that 
resolut will degrad a more and more sourc be added. 
We can see in fig. 5 that, a the number of sourc increas 
linearly, the condit approach a limit case. hence, 
the resolut do not becom arbitrarili bad with increas 
number of sources. therefor we can estim the system reso- 
lution for complex object from distiguish measur 
of a limit number of point sources. thi be experiment 
valid in section 4, where we find that the experiment 16- 
point resolut be a good predictor of the resolut for a usaf 
target. 

unlik tradit resolut metrics, our new local condit 
number theori explain the resolut loss we observ experi- 
mentally. We believ that it be suffici gener to be applica- 
ble to other comput cameras, which like exhibit similar 
perform loss. 

D. valid of the convolut model 

In section 2b, we model the caustic pattern a shift invari 
at everi depth, lead to simpl calibr and effici com- 
putation. sinc our convolut model be an approximation, we 
wish to quantifi it applicability. figur 6a-c show regist 
close-up of experiment measur psf from plane wave 
incid at 0◦, 15◦ and 30◦. the convolut model assum that 
these regist psf be all exactli the same, though, in reality, 
they have subtl differences. To quantifi the similar across 
the fov, we plot the inner product between each off-axi psf 
and the on-axi psf (see fig. 6d). the inner product be great 
than 75% across the entir fov and particularli good within 
±15◦ of the optic axis, indic that the convolut model 
hold rel well. 

To investig how the spatial varianc of the psf impact sys- 
tem performance, we use the peak width of the cross-correl 
between the on-axi and off-axi psf to approxim the spot 

0 

1a psf at 0O c psf at 30ob psf at 15o 

-37 -20 0 20 37 
field posit (degrees) 

0 

1 

2 

3 

4 

5 

6 

N 
or 

m 
al 

iz 
ed 

sp 
ot 

si 
ze 

off-axi resolution 

-37 -20 0 20 37 
field posit (degrees) 

0 

0.2 

0.4 

0.6 

0.8 

1 

In 
ne 

r P 
ro 

du 
ct 

S 
im 

ila 
rit 

y 

d psf similar 
convolut 
model 
exhuast 
calibr 

fig. 6. experiment valid of the convolut model. (a)- 
(c) close-up of regist experiment psf for sourc at 0◦, 
15◦ and 30◦. the psf at 15◦ be visual similar to that on-axis, 
while the psf at 30◦ have subtl differences. (d) inner product 
between the on-axi psf and regist off-axi psf a a func- 
tion of sourc position. (e) result spot size (normal by 
on-axi spot). the convolut model hold well up to ±15◦, 
beyond which resolut degrad (solid). exhaust calibra- 
tion would improv the resolut (dashed), at the expens of 
complex in comput and calibration. 

size off-axis. figur 6e (solid) show that we retain the on-axi 
resolut up to ±15◦. beyond that, the resolut gradual 
degrades. To avoid model mismatch, one could replac the con- 
volut model with exhaust calibr over all posit 
in the fov. thi procedur would yield high resolut at the 
edg of the fov, a show by the dash line in fig. 6e. the 
gap between these line be what we sacrific in resolut by 
use the convolut model. however, in return, we gain sim- 
plifi calibr and effici computation, which make the 
large-scal problem feasible. 

4. experiment result 

imag of two object be present in fig. 7. both be illu- 
minat use white led and reconstruct with a 3D TV 
regularizer. We choos a reconstruct grid that approxim 
nyquist sampl the two-point resolut (bi 2× 2 bin the 
sensor pixel to yield a 1.3 megapixel measurement). calibra- 
tion imag be take at 128 differ z-planes, rang from 
z = 10.86mm to z = 36.26mm (from the diffuser), with space 
set accord to condit outlin in sec. 3b. the 3D imag 
be reconstruct on a 2048×2048×128 grid, but the angular 
fov restrict the usabl portion of thi grid to the center 100 
million voxels. note that the resolv featur size on thi 
reconstruct grid can still vari base on object complexity. 

the first object be a neg usaf 1951 fluoresc test 
target, tilt 45◦ about the y-axi (fig. 7a). slice of the recon- 
struct volum at differ z plane be show to highlight the 
system’ depth section capabilities. As describ in sec. 3b, 
the spatial scale chang with depth. analyz the resolut in 
the vertic direct (fig. 7a inset), we can easili resolv group 
2 element 4 and bare resolv group 2 element 5 at z = 24 



research articl 8 

b 
side 

10 mm 

top 

10 mm 

front 

1 mm 

raw dataa 

Z = 19.7 mm 

2 mm 

Z = 27.2 mm 

2 mm 

Z = 25.2 mm 

2 mm 

Z = 24 mm 

2 mm 

max projection0 

1 

2 mm 

2 mm 

raw data 

group 2 

2 

3 

4 
5 
6 

el 
em 

en 
t 

fig. 7. experiment 3D reconstructions. (a) tilt resolut target, which be reconstruct on a 4.2 MP later grid with 128 
z-plane and crop to 640×640×50 voxels. the larg panel show the max project over z. note that the spatial scale be not 
isotropic. inset be a magnif of group 2 with an intens cutline, show that we resolv element 5 at a distanc of 24 mm, 
which correspond to a featur size of 79 µm (approxim twice the later voxel size of 35µm at thi depth). the degrad reso- 
lution match our 16-point distinguish (75 µm at 20 mm depth). lower panel show depth slice from the recov volume. 
(b) reconstruct of a small plant, crop to 480×320×128 voxels, render from multipl angles. 

mm. thi correspond to resolv featur 79µm apart on the 
resolut target. thi resolut be significantli bad than the 
two-point resolut at thi depth (50µm), but similar to the 
16-point resolut (75µm). hence, we reinforc our claim that 
two-point resolut be a mislead metric for comput 
cameras, but multi-point distinguish can be extend to 
more complex objects. 

finally, we demonstr the abil of diffusercam to imag 
natur object by reconstruct a small plant (fig. 7b). multipl 
angl be render to demonstr the abil to captur the 3D 
structur of the leaves. 

5. conclus 

We demonstr a simpl optic system, with onli a diffus 
in front of a sensor, that be capabl of single-shot 3D imaging. 
the diffus encod the 3D locat of point sourc in caus- 
tic patterns, which allow u to appli compress sens to 
reconstruct more voxel than we have measurements. By use 
a convolut model that assum that the caustic pattern be 
shift invari at everi depth, we develop an effici admm 
algorithm for imag recoveri and simpl calibr scheme. We 
character the fov and two-point resolut of our system, 
and show how resolut vari with object complexity. thi 
motiv the introduct of a new condit number analysis, 
which we use to analyz how invers problem condit 
chang with object complexity. 

acknowledg 

thi work be fund by the gordon and betti moor founda- 
tion grant gbmf4562 and a nsf career grant to l.w. b.m. 
acknowledg fund from the hertz foundat and G. K. be 
a nation defens scienc and engin graduat fellow. 
r.h. and e.b. acknowledg fund from the swiss nsf (grant 
p2ezp2 159065 and p2elp2 172278, respectively). thi research 

be develop with fund from the defens advanc re- 
search project agenc (darpa), contract no. n66001-17-c- 
4015. the views, opinion and/or find express be those 
of the author and should not be interpret a repres the 
offici view or polici of the depart of defens or the 
u.s. government. the author thank dr. eric jona and the rice 
flatcam team for help discussions. 

refer 

1. M. S. asif, A. ayremlou, A. C. sankaranarayanan, A. veer- 
araghavan, and R. G. baraniuk, “flatcam: thin, bare-sensor 
camera use cod apertur and computation,” corr 
abs/1509.00116 (2015). 

2. D. G. stork and P. R. gill, “optical, mathematical, and com- 
putat foundat of lensless ultra-miniatur diffract 
imag and sensors,” intern journal on advanc in 
system and measur 7, 4 (2014). 

3. P. R. gill, J. tringali, A. schneider, S. kabir, D. G. stork, 
E. erickson, and M. kellam, “thermal escher sensors: pixel- 
effici lensless imag base on tile optics,” in “compu- 
tation optic sens and imaging,” (optic societi of 
america, 2017), pp. ctu3b–3. 

4. R. fergus, A. torralba, and W. T. freeman, “random len 
imaging,” tech. rep., massachusett institut of technolog 
(2006). 

5. A. stylian and R. pless, “sparklegeometry: glitter imag 
for 3d point tracking,” in “proceed of the ieee confer- 
enc on comput vision and pattern recognit work- 
shops,” (2016), pp. 10–17. 

6. J. tanida, T. kumagai, K. yamada, S. miyatake, K. ishida, 
T. morimoto, N. kondou, D. miyazaki, and Y. ichioka, “thin 
observ modul by bound optic (tombo): concept and 
experiment verification,” appli optic 40, 1806–1813 
(2001). 



research articl 9 

7. W. harm, C. roider, A. jesacher, S. bernet, and M. ritsch- 
marte, “lensless imag through thin diffus media,” op- 
tic express 22, 22146–22156 (2014). 

8. W. chi and N. george, “optic imag with phase-cod 
aperture,” optic express 19, 4294–4300 (2011). 

9. D. J. brady, K. choi, D. L. marks, R. horisaki, and S. lim, 
“compress holography,” opt. express 17, 13040–13049 
(2009). 

10. K. lee and Y. park, “exploit the speckle-correl scat- 
tere matrix for a compact reference-fre holograph imag 
sensor,” natur commun 7 (2016). 

11. W. bishara, t.-w. su, A. F. coskun, and A. ozcan, “lensfre 
on-chip microscopi over a wide field-of-view use pixel 
super-resolution,” optic express 18, 11181–11191 (2010). 

12. H. faulkner and J. rodenburg, “movabl apertur lensless 
transmiss microscopy: a novel phase retriev algorithm,” 
physic review letter 93, 023903 (2004). 

13. R. ng, M. levoy, M. bredif, G. duval†, M. horowitz, and 
P. hanrahan, “light field photographi with a hand-held 
plenopt camera,” stanford univers comput scienc 
tech report pp. 3418–3421 (2005). 

14. R. horisaki, S. irie, Y. ogura, and J. tanida, “three- 
dimension inform acquisit use a compound 
imag system,” optic review 14, 347–350 (2007). 

15. k.tajima, T. shimano, Y. nakamura, M. sao, and 
T. hoshizawa, “lensless light-field imag with multi- 
phase fresnel zone aperture,” in “2017 ieee intern 
confer on comput photographi (iccp),” (2017), 
pp. 76–82. 

16. M. levoy, R. ng, A. adams, M. footer, and M. horowitz, 
“light field microscopy,” acm trans. graph. (proc. sig- 
graph) 25 (2006). 

17. M. broxton, L. grosenick, S. yang, N. cohen, A. andalman, 
K. deisseroth, and M. levoy, “wave optic theori and 3-d 
deconvolut for the light field microscope,” optic express 
21, 25418–25439 (2013). 

18. h.-y. liu, E. jonas, L. tian, J. zhong, B. recht, and L. waller, 
“3d imag in volumetr scatter medium use phase- 
space measurements,” opt. express 23, 14461–14471 (2015). 

19. N. C. pégard, h.-y. liu, N. antipa, M. gerlock, H. adesnik, 
and L. waller, “compress light-field microscopi for 3d 
neural activ recording,” optica 3, 517–524 (2016). 

20. O. katz, P. heidmann, M. fink, and S. gigan, “non-invas 
single-shot imag through scatter layer and around 
corner via speckl correlations,” natur photon 8, 784– 
790 (2014). 

21. E. edrei and G. scarcelli, “memory-effect base deconvolu- 
tion microscopi for super-resolut imag through scat- 
tere media,” scientif report 6 (2016). 

22. A. K. singh, D. N. naik, G. pedrini, M. takeda, and W. os- 
ten, “look through a diffus and around an opaqu sur- 
face: A holograph approach,” optic express 22, 7694–7701 
(2014). 

23. N. antipa, S. necula, R. ng, and L. waller, “single-shot 
diffuser-encod light field imaging,” in “2016 ieee interna- 
tional confer on comput photographi (iccp),” 
(2016), pp. 1–11. 

24. Y. kashter, A. vijayakumar, and J. rosen, “resolv imag 
by blurring: superresolut method with a scatter mask 
between the observ object and the hologram recorder,” 
optica 4, 932–939 (2017). 

25. A. liutkus, D. martina, S. popoff, G. chardon, O. katz, 
G. lerosey, S. gigan, L. daudet, and I. carron, “imag with 

nature: compress imag use a multipli scatter 
medium,” scientif report 4 (2014). 

26. E. J. candè and M. B. wakin, “an introduct to compres- 
sive sampling,” ieee signal process magazin 25, 21–30 
(2008). 

27. L. I. rudin, S. osher, and E. fatemi, “nonlinear total varia- 
tion base nois remov algorithms,” physica D: nonlinear 
phenomena 60, 259–268 (1992). 

28. F. krahmer, S. mendelson, and H. rauhut, “suprema of 
chao process and the restrict isometri property,” com- 
mun. pur. appl. math. 67, 1877–1904 (2014). 

29. A. beck and M. teboulle, “fast gradient-bas algorithm 
for constrain total variat imag denois and deblur- 
ring problems,” ieee transact on imag process 18, 
2419–2434 (2009). 

30. S. boyd, N. parikh, E. chu, B. peleato, and J. eckstein, “dis- 
tribut optim and statist learn via the alter- 
nate direct method of multipliers,” foundat and 
trend in machin learn 3, 1–122 (2011). 

31. M. S. C. almeida and M. figueiredo, “deconvolv imag 
with unknown boundari use the altern direct 
method of multipliers,” ieee transact on imag process- 
ing 22, 3074–3086 (2013). 

32. A. matakos, S. ramani, and J. A. fessler, “acceler edge- 
preserv imag restor without boundari artifacts,” 
ieee transact on imag process 22, 2019–2029 (2013). 

33. M. V. afonso, J. M. bioucas-dias, and M. A. T. figueiredo, 
“fast imag recoveri use variabl split and constrain 
optimization,” ieee transact on imag process 19, 
2345–2356 (2010). 

34. J. noced and S. J. wright, numer optim (springer, 
2006). 

35. Y. wang, J. yang, W. yin, and Y. zhang, “A new altern 
minim algorithm for total variat imag reconstruc- 
tion,” siam journal on imag scienc 1, 248–272 (2008). 

36. J. ragan-kelley, C. barnes, A. adams, S. paris, F. durand, 
and S. amarasinghe, “halide: a languag and compil for 
optim parallelism, locality, and recomput in imag 
process pipelines,” acm sigplan notic 48, 519–530 
(2013). 

37. G. kuo, N. antipa, R. ng, and L. waller, “diffusercam: 
diffuser-bas lensless cameras,” in “comput optic 
sens and imaging,” (optic societi of america, 2017), 
pp. ctu3b–2. 


1 introduct 
A system overview 

2 method 
A system architectur 
B convolut forward model 
C invers algorithm 

3 system analysi 
A field-of-view 
B resolut 
b.1 two-point resolut 
b.2 multi-point resolut 

C local condit number theori 
D valid of the convolut model 

4 experiment result 
5 conclus 

