


















































control fals discoveri dure 
interact data explor 

zheguang zhao lorenzo De stefani emanuel zgraggen carsten binnig 
eli upfal tim kraska 

depart of comput science, brown univers 
{firstname_lastname}@brown.edu 

abstract 
recent tool for interact data explor significantli increas 

the chanc that user make fals discoveries. the crux be that these 
tool implicitli allow the user to test a larg bodi of differ hy- 
pothes with just a few click thu incur in the issu commonli 
know in statist a the “multipl hypothesi test error”. In 
thi paper, we propos solut to integr multipl hypothesi 
test control into interact data explor tools. A key insight 
be that exist method for control the fals discoveri rate (such 
a fdr) be not directli applic for interact data exploration. 
We therefor discu a set of new control procedur that be good 
suit and integr them in our system call aware. By mean 
of extens experi use both real-world and synthet data 
set we demonstr how awar can help expert and novic user 
alik to effici control fals discoveries. 

1 introduct 
“beer be good for you: studi find that sud contain anti-vir 

powers” [dailynew 10/12]. “secret to win a nobel prize? eat 
more chocolate” [time, 10/12]. “scientist find the secret of longer 
life for men (the bad news: castrat be the key)” [daili mail uk, 
09/12]. “A new studi show that drink a glass of wine be just a 
good a spend an hour at the gym” [fox news, 02/15]. 

there have be an explos of data-driven discoveri like the 
one mention above. while sever of these be legitimate, there 
be an increas concern that a larg amount of current publish 
research find be fals [19]. the reason behind thi trend be 
manifold. 

In thi paper we make the case that the rise of interact data 
explor (ide) tool have the potenti to worsen thi situat 
further. commerci tool like tableau or research prototyp like 
vizdom [9], dice [22] or immen [26], aim to enabl domain ex- 
pert and novic user alik to discov complex correl and to 
test hypothesi and differ between variou popul in an 
entir visual manner with just a few clicks; unfortunately, often ig- 
nore even the most basic statist rules. We recent perform a 
small user studi and ask peopl to explor censu data use such 
an interact data explor tool. within minutes, all particip 
be abl to extract multipl insights, such a “peopl with a ph.d. 
earn more than peopl with a low educ degree”. At the 
same time, almost none of the particip use a statist method 
to test whether the differ the visual observ visual from 
the histogram be actual meaningful. further, most user includ 
expert with statist training, do not consid that thi type of ex- 
ploration, that consist of repeat attempt to find interest facts, 
increas the chanc to observ seemingli signific correl 
by chance. 

thi problem be well know in the statist commun and 
refer to a the “multipl test problem” or “multipl hypothesi 

error” and it denot the fact the more test an analyst performs, the 
high be the chanc that a discoveri be observ by chance. let u 
assum an analyst test 100 potenti correlations, 10 of them be 
true, and she want to limit the chanc of a fals discoveri to 5% 
(i.e., the family-wis error rate should be p = 0.05). assum further 
that our test have a statist power (i.e, the likelihood to discov 
a real correlation) of 0.8; all veri common valu for a statist 
testing. with thi setting, the user will find ≈ 13 correl of 
which 5 (≈ 40%) be “bogus”. the analyst should use a multipl 
hypothesi test correct method, such a the bonferroni correct 
[6]. however, bonferroni correct significantli decreas the 
power of everi test and with it the chanc of find a true insight. 
thi be especi true in the case of interact data exploration, 
where the number of test be not know upfront and increment 
version of bonferroni correct need to be appli which would 
even further decreas the power of the tests. 

anoth interest question concern what should be consid 
a a hypothesi test when user interact explor data. for 
example, if a user see a visualization, which show no differ 
in salari between men and woman base on their education, but 
late on decid base on that insight to look at salari differ 
between marri men and women. should we still account for that? 
the answer in most case will be “yes” a the analyst probabl 
implicitli make a conclus base on that visualization, which then 
in turn trigger her next explor step. however, if she consid 
thi visual just a a descript statist of how the data look 
like, and make no infer base on it (i.e. it do not influenc 
the decis process of what to look at next), then it should not be 
consid a a hypothesis. the differ be subtl and usual 
veri hard to understand for non-expert users, while it might have a 
profound impact on the number of fals discoveri a user makes. 

finally, in the context of data explor there have be recent 
work on automat recommend visual [36, 23, 37] 
or correl [8]. these system yet again increas the chanc 
of fals discoveri sinc they automat test all (or at least a 
larg fraction) of possibl combin of featur until someth 
interest show up without consid the multipl hypothesi 
test problem. 

In thi paper, we make a first step toward integr automat 
multipl hypothesi test control into an interact data explo- 
ration tool. We propos a potenti user interfac and a meaning 
default hypothesi (i.e., the null hypothesis), which allow u to 
achiev control of the ratio of fals discoveri for everi user inter- 
action. specifically, we propos to consid everi visual a a 
hypothesi unless the user specifi otherwise. We further discu 
control procedur base on the family-wis error and discu whi 
they be too pessimist for interact data explor tool and 
whi the more modern criterion of control the fals discoveri rate 

ar 
X 

iv 
:1 

61 
2. 

01 
04 

0v 
1 

[ 
c 

.D 
B 

] 
4 

D 
ec 

2 
01 

6 



(fdr) be good suit for larg scale data exploration. the chal- 
leng of fdr, however, is, that the standard techniques, such a the 
benjamini-hochberg procedur be not increment and requir to 
test all the hypotheses, befor determin which hypothesi be 
rejected. thi clearli constitut a problem in the data explor 
set where user make discoveri incrementally. the recent 
α-invest techniqu [14] propos an increment procedur to 
control a variat of fdr, call margin fdr (mfdr), which 
howev reli on the user have a deep understand of how 
valuabl each individu test be suppos to be. again a contradic- 
tion to data exploration, where the user onli over time gain a feel 
about the import of certain questions. We therefor propos 
new strategi base on the α-invest procedur [14], which be 
particular tailor toward interact data explor tools. We 
implement these idea in a system call awar and we show how 
thi system can help expert and novic user alik to control fals 
discoveri through extens experi on both real-world and 
synthet data and workloads. 

the main contribut can be summar a follows: 
• We propos aware, a novel system which automat 

track hypothesi dure data exploration; 
• We discu sever multipl hypothesi test control meth- 

od and how well they work for data exploration; 
• base on the previou discussion, we develop newα-invest 

rule to control a variant of the fals discoveri rate (fdr), 
call margin fdr (mfdr); 
• We evalu our system use synthet and real-world dataset 

and show that our method inde achiev control of the 
number of fals discoveri when use an interact data 
explor system. 

the paper be structur a follows: in section 2 we discuss, by 
mean of an example, whi some visual should be consid 
hypothesi test and what be the main challeng encount when 
test hypothesi for the ide setting. In section 3 we present 
aware’ user interfac and discu how to automat track 
hypothesi and how to integr the user feedback into track 
the hypothesis. In section 4 we discu multipl hypothesi test 
techniqu know in literatur and show how well they fit in the 
ide setting. In section 5 we then propos new multipl hypothesi 
test procedur for ide base on the α-invest procedure. 
afterwards, in section 7 we present the result of our experiment 
evalu use both real-world and synthet data. finally, in 
section 8 and 9 we discu relat work and present our conclusions. 

2 A motiv exampl 
To motiv the variou aspect for multi-hypothesi control dur- 

ing data explor we outlin a potenti scenario that be inspir 
by vizdom [9]. similar workflow howev can be achiev with 
other system like tableau, immen [26] or dice [22]. 

let u assum that eve be a research at a non-profit organiza- 
tion and be work on a project relev to a specif country. she 
just obtain a new dataset contain censu inform and be 
now interest in get an overview of thi data a well a ex- 
tract new insights. she start off by consid the “gender” 
attribut and observ that the dataset contain the same number 
of record for men and woman (figur 1 a). she then move to 
a second visualization, display the distribut of peopl who 
earn abov or below $50k a year. eve link the two chart so that 
select in the “salary” visual now filter the “gender” vi- 
sualization. she notic that by select the salari abov $50k, 
the distribut of “gender” be skew toward men, suggest that 
men have high salari than woman (b). after creat a third 
visual for “gender”, select the record correspond to 
record with salari low than $50k (dash line indic invers 

of selection), she confirm her find “women in thi countri be 
predomin earn less than $50k” (c). eve now want to un- 
derstand what els influenc a person yearli salari and creat a 
chain of visual that select peopl who have phd degre 
and be not marri (d). extend thi chain use the “salary” 
attribut appear to suggest that thi sub-popul contain a lot of 
high-earn (e). By select the high-earn and extend the 
chain with two “age” visual allow her to compar the age 
distribut of unmarri phd earn more than $50k to those 
make less than $50k. In order to verifi that the observ visual 
differ be actual statist signific she perform a t-test by 
drag the two chart close to each other (f). 

while the exampl workflow contain onli one hypothesi test 
explicitli initi by the user, we argu that without account for 
other implicit hypothesi test there be a significantli increas of risk 
that the user may observ fals discoveri dure similar scenario 
of data exploration. thi open up new import questions: whi 
and when should visual be consid statist hypothesi 
tests? how should these test be formulated? 

2.1 hypothesi test 
In thi paper, we focu on the wide use frequentist infer 

approach and it p-valu outcome. In order to determin whether 
there be a correl between two observ phenomenon formal 
in a “research hypothesis” H that be actual statist relev 
(i.e., not product of nois in the data) we analyz it correspond 
“null hypothesis” H which refer to a gener statement or default 
posit accord to which there be no relationship between two 
measur phenomena. given thi relationship between H and H , 
the research hypothesish be also commonli refer a “altern 
hypothesis”. 

the test procedur will then determin whether to accept 
(resp., reject) a null hypothesi H which in turn correspond to 
reject (resp., accepting) the correspond altern hypothesi 
(or research hypothesis)h. In order to do so the p-valu of the null 
hypothesi H be evaluated. the p-valu be use in the context of 
null hypothesi test in order to quantifi the idea of statist 
signific of evid and it denot the probabl of obtain 
an outcom at least a extrem a the one that be actual observ 
in the data, under the assumpt that H be true. depend on 
the context, the p-valu of H be evalu use the appropri 
statist test (e.g., the t-test or the X 2-test). 

If the p-valu p associ to the null hypothesi H be less than 
or equal to the signific level α chosen by the test procedur 
(commonli 0.05 or 0.01), the test suggest that the observ data be 
inconsist with the null hypothesis, so the null hypothesi must 
be rejected.thi procedur guarante for a singl test, that the 
probabl of a “fals discovery” (also know a “fals positive” or 
“type I error”) – wrongli reject the null hypothesi of no effect – 
be at most α. thi do not impli that the altern hypothesi be 
true; it just state that the observ data have the likelihood of p ≤ α 
under the assumpt that the null hypothesi be true. the statist 
power or sensit of a binari hypothesi test be the probabl that 
the test correctli reject the null hypothesi H when the altern 
hypothesish be true. 

while the frequentist approach to hypothesi test have be crit- 
iciz [20, 28] and there have be a lot of work in develop 
altern approaches, such a bayesian test [5], it be still wide 
use in practic and we consid it a good first choic to build a 
system which automat control the multipl hypothesi error 
a they have two advantages: (1) novic user be more like to 
have experi with standard hypothesi test than the more de- 
mand bayesian test paradigm. (2) the frequentist infer 
approach do not requir to set a hard-to-determin prior a it be 



gender 

co 
un 

t 

male femal other 

A 

salari over 50k 

co 
un 

t 

true fals 
gender 

co 
un 

t 

male femal other 

gender 

co 
un 

t 

male other 

salari over 50k 

co 
un 

t 

true fals 

gender 

co 
un 

t 

male femal other 

B C 

educ 

co 
un 

t 

HS bachelor master phd 

marit statu 

co 
un 

t 

marri never 
marri 

not 
marri 

widow 

femal 

salari over 50k 

co 
un 

t 
true fals 

educ 

co 
un 

t 

HS bachelor master phd 

marit statu 

co 
un 

t 

marri never 
marri 

not 
marri 

widow 

age 

co 
un 

t 

10 20 30 50 60 7040 9080 

age 

co 
un 

t 

10 20 30 50 60 7040 9080 

0.011p 

t-test 

D 

E F 

salari over 50k 

co 
un 

t 

true fals 

educ 

co 
un 

t 

HS bachelor master phd 

marit statu 

co 
un 

t 

marri never 
marri 

not 
marri 

widow 

figur 1: An exampl interact data explor session 

the case with bayesian tests. 

2.2 visual a hypothes 
A visual per-s show a descript statist (e.g., the count 

of woman or the count of men) of the dataset and be not a hypothesis. 
It be reason to assum that in step A of figur 1 the user just 
look at the gender distribut and simpli acknowledg that the 
censu survey roughli the same amount of woman and men. how- 
ever, it becom an hypothesi test, if the user expect someth 
els and draw a conclusion/infer base on the visualization. 
for example, if the user somehow assum that there should be 
more men than woman in the data and therefor consid the 
fact that there be an equal amount a an insight. the notion of a 
visual be consid a a hypothesi becom even clearer 
in step (b) and (c) of the exampl work-flow. when look at 
the visual in (b) in isolation, it just depict a descript 
statistic. indeed, if the user would just take it a such and not make 
ani infer about it and/or base further explor on an insight 
extract from thi visualisation, then it would not be consid an 
hypothesis. We argu howev that the opposit be true more often 
than not. first, our analyt reason and sense-mak process 
be inher non-linear [29, 33]. our futur action be influenc 
by new knowledg we discov in previou observations. second, 
while suscept to certain type of bia [11], the human visual 
system be highli optim at pick up differ in visual sig- 
nal and at detect pattern [7]. An averag user be veri like 
drawn to the chang between the gender distribut of step (a) 
and step (b) and might therefor infer that woman earn less than 
men and potenti flag thi a an interest insight that deserv 
more investigation. thi be illustr in step (c) where the user now 
further drill down and visual compar the distribut of gender 
filter by salary. We qualit confirm thi notion through 
a form user studi where we manual cod user-report in- 
sights, follow a think-aloud protocol similar to the one propos 
in [16]. In thi studi we observ that user tend to pick up on 
even slight differ in visual and regard them a insight 
and user predominantli base futur explor path on previous 
infer insights. 

We conclud two things: (1) most of the time user inde treat 
visual a hypotheses, though there be exceptions, and (2) 
they often (wrongly) assum that what they see be statist signifi- 
cant. the latter be particularli true if the user do not care check 
the axi on the actual count. for example, if a user start to analyz 
the outlier of a billion record dataset and make the conclus 
that mainli uneduc white be caus the outliers, the dataset 

she be refer to might be compar small and the chanc of 
random might be much higher. the same argument also hold 
against the critic, that with enough data observ differ by 
chanc be much less likely, which be true. As part of visual data 
explor tools, user often explor sub-populations, and while the 
origin dataset might be large, the sub-popul might be small. 
thus, we argu that everi visual a part of a interact data 
explor tool should be treat a a hypothesi and that user 
should be inform about the signific of the insight they gain 
from the visualization. At the same time, a user should have the 
choic to declar a visual a just descriptive. 

2.3 heurist for visual hypothes 
A core question remains: what should the hypothesi for a visu- 

aliz be. ideally, user would tell the system everi singl time 
what they be think so that the hypothesi be adjust base on 
their assum insight(s) they gain from the visualization. however, 
thi be disrupt to ani interact data explor session. We 
rather argu that the system should use a good default hypothesis, the 
user can modifi (or even delete) if she so desires. for the purpos of 
thi work, we mainli focu on histogram a show in figur 1 and 
acknowledg that there exist mani other visualizations, which we 
consid a futur work. We deriv the follow heurist from 
two separ user studi where we observ over 50 particip 
use a ide tool to explor variou datasets. 

1. everi visual without ani filter condit be not a hy- 
pothesi (e.g., step A in figur 1) unless the user make it 
one. thi be reasonable, a user usual first gain a gener 
high-level impress of the data. furthermore, in order to 
make it an hypothesis, the user would need to provid some 
prior knowledge/expectation, for exampl a discuss before, 
that he expect more men than woman in the dataset. 

2. everi visual with a filter condit be a hypothesi 
with the null-hypothesi that the filter condit make no 
differ compar to the distribut of the whole dataset. 
for example, in step B of figur 1 the null hypothesi for the 
distribut of men vs. woman give the high salari class 
of over $50k would be that there be no differ compar 
to the equal distribut of men vs. woman over the entir 
dataset (the visual in step a). thi be again a reason 
assumpt a the distribut of an attribut give other be 
onli interesting, if it show some differ effect compar to 
look at the whole dataset. 

3. If two visual with the same but some negat filter 
condit be put next to each other, it be a test with the 



null-hypothesi that there be no differ between the two 
visual distributions, which supersed the previou hy- 
pothesis. thi be the case in step C: give that the user look 
explicitli at the distribut of male v femal give a salari 
over and under $50k be a strong hint from the user, that he 
want to compar these two distributions. 

As with everi heurist it be import to note, that the heurist 
can be wrong. therefor it be extrem import to allow the 
user to overwrit the default hypothesi a well a delet default 
hypothesi if one realli just act a a descript statist or be 
just gener a part to a big hypothesi test. furthermore, there 
exist of cours other potenti null-hypothesis. for example, in 
our workflow we assum by default that the user aim to compar 
distributions, which requir a χ2-test. however, mayb in some 
scenario compar the mean (i.e., a t-test) might be more appro- 
priat a the default test. yet, studi in detail what a good default 
null-hypothesi be depend on the data properti and domain, be 
beyond the scope of thi paper. 

2.4 heurist appli to the exampl 
for our exampl in figur 1 the result hypothesi could be 

a follows: step A be not an hypothesi base on rule 1 a it just 
visual the distribut of a singl attribut over the whole dataset. 
step B be the hypothesi m1 if the distribut of gender be differ 
give a salari over $50k. step C supersed the previou hypothesi 
and replac it with an hypothesi m′1 if the gender distribut 
between a salari over and under $50k be different, which be a sightli 
differ question. step D creat a hypothesi m2 if the marit 
statu for peopl with phd be differ compar to the entir 
dataset, wherea step- gener a hypothesi m3 if there be a 
differ salari distribut give not marri peopl with a phd. 
By studi the age distribut in step F the system first gener 
a default hypothesi m4 that the distribut of the age be differ 
give a phd and be not marri for differ salari classes. 
however, the user overwrit immedi the default hypothesi 
with an hypothesi m′4 about the averag age. furthermore, a 
the previou visual in step D and E might just have be 
step stone toward creat m4 the user might or might not 
delet hypothesi m2 and m3. however, if the insight our user 
gain from view the marit status, etc., influenc her to look 
at the age distribution, she might want to keep them a hypothesis. 

clearli thi be onli a veri small example, but it alreadi demon- 
strate the gener issues. not everi insight the user gain (e.g., 
the insight that woman earn less) be explicitli express a a test. 
At the same time, a more the user “surfs” around the high the 
chanc that she find someth which look interesting, but just 
appear becaus of chance. In the exampl above, by the time the 
user actual perform it first test (step f), she implicitli alreadi 
test at least one other hypothesi and potenti even four others. 
assum a target p-valu of α = 0.05, the chanc of a fals 
discoveri therefor increas to 1 − (1 − α)2 = 0.098 for two 
hypothesi and up to 1 − (1 − α)4 = 0.185 for four hypothesis. 
while the question of what should count a an hypothesi be highli 
depend on the user and can never be fulli control by ani 
system, we can however, enabl the system to make good sugges- 
tion and help user to track the risk of make fals discoveri by 
chance. furthermore, thi short workflow also demonstr that 
hypothesi be built by add but also by remov attributes. As 
we will discu later, there exist no good method so far to control 
the risk of make fals discoveri for increment session like the 
one creat by interact data explor systems. We therefor 
develop new method especi for interact data explor in 
section 5. 

finally, it should be noted, that the same problem also exist 

with exploratori analysi use sql or other tools. however, we 
argu that the situat be becom bad by the up-ris of visual 
explor tools, like tableau, which be often use by novic users, 
who not necessarili reflect enough on their explor path after 
they found someth interesting. 

3 the awar user interfac 
As argu in the previou section, user feedback be essenti in 

determining, track and control the right hypothesi dure 
the data explor process. with awar we creat a system 
that appli our heurist automat to all visualizations. We 
design awar ’s user interfac with a few goal in mind. 

first, the user should be abl to see the hypothesi the system 
assum so far, their p-valu , effect size and if they be consid 
signific and should be abl to change, add or delet hypothesi 
at ani give stage of the exploration. 

second, hypothesi reject decis should never chang base 
on futur user action unless the user explicitli ask for it. We 
therefor requir an increment procedur to control the multipl 
hypothesi risk that do not chang it reject decis even if 
more hypothesi test be executed. for example, the system should 
not state that their be a signific age differ for not marri 
highli educ people, and then late on revok it assess just 
becaus the user do more tests. more formally, if the system de- 
termin which hypothesi m1...mn be signific (i.e., it reject 
the null) or not and the user chang the last hypothesi or add an 
hypothesi mn+1, which should be the most common cases, the 
signific of hypothesi m1..mn should not change. however, 
if the user might change, delete, or add hypothesi k ∈ 1, .., n, de- 
pend on the use procedur we might allow that the signific 
of hypothesi mk+1 to mn might have to chang a well. 

third, individu hypothesi descript should be augment 
with inform about how much data nh1 the user have to add, 
under the assumpt that the new data will follow the current 
observ distribut of the data, to make an hypothesi significant. 
while sound counter-intuitive, a one might (wrongly) imply, 
it be possibl to make ani hypothesi true by add more data, 
calcul thi valu be in some field alreadi common practice. 
for example, in genet scientist often search (automatically) for 
correl between gene and high-level effect (like cancer). If 
such a correl be found, often becaus of the multipl hypothesi 
error the chanc of a true discoveri be tini (i.e., the p-valu be too 
high). In that case the scientist work backward and estim 
how much more gene she have to to sequenc in order to make 
the hypothesi relevant, expect that the new data (e.g., gene 
sequences) follow the same distribut of the data the scientist 
alreadi has. however, if the effect be just produc by chance, 
the new data will be more similar to the distribut of the null- 
hypothesi and the null will not be rejected. the requir valu be 
gener easi to calcul or approximate, and be highli valuabl 
for the end-user. A small valu for nh1 in relat to the number 
of total test hypothesi might be an indic that the power 
(i.e., the chanc to accept a true altern hypothesis) of the test 
be not suffici large. 

and finally, user should be abl to bookmark import hypothe- 
ses. our system us default hypothesi throughout the explor 
and the user might find it too cumbersom to correct everyon for 
hi real intentions, there might be more hypothesi gener than 
the user intend to test. even if all hypothesi be what the user 
be considering, some of them might be more import to her than 
others; the hypothesi the user would like to includ in a presen- 
tation or show to her boss. A key key question becomes, what be 
the expect number of fals discoveri among those import 



alpha 
2.5% 

5% 

salari | educ <> salaryh1 
0.027 

t-test 
salari | educ = salaryh0 

cohen' d 0.5 

H1 
0.001 

t-test H0 

cohen' d 0.8 
age | {chain} <> age | {chain-1} 

H1 
0.011 

t-test 

age | {chain} = age | {chain-1} 

H0 

cohen' d 0.5 

gender | marit = genderh1 
0.621 

chi squar 
gender | marit = genderh0 

cohen' d 0.01 

A 
B 

C 
D 

E salari | {chain-1} <> salari 

salari | {chain-1} = salari 

figur 2: the awar user interfac 

discoveries? 
figur 2 show the current interfac design of awar with a 

risk controller, which incorpor the abov ideas, run on a 
tablet. the user interfac featur an unbound 2D canva where 
chain of visual (such a the one show in figur 1) can be 
laid out in a free form fashion. A “risk-gauge” on the right-hand 
side of the display (figur 2 (a)) serf two purposes: it give 
user a summari of the underli procedur (e.g., the budget for 
the fals discoveri rate set to 5% with current remain wealth 
of 2.5%; both explain in the next two sections) and it provid 
access to a scrollabl list of all the hypothesi test (implicit and 
explicit) that have be execut so far. each list entri display 
detail about one test and it results. textual label describ the 
null- and alternative-hypothesi and color cod p-valu indic 
if the null-hypothesi be reject or accept (green for rejected, 
red for accepted). furthermore, it visual the distribut of 
null-hypothesi and altern hypothesi and show it difference, 
includ an indic of it color cod effect size (d). tap gestur 
on a specif item allow user to chang thing like the default 
hypothesi or the type of test. addit other inform such 
a an estim of the size of an addit data nh1 that could 
make the observ signific can be display in each item. 
In the exampl thi inform be encod through a set of small 
squar (b, C) where each squar indic the amount of data that 
be in the correspond distribution. In (b) the five red squar tell 
u that we need 5x the amount of data from the null-distribut to 
flip thi test form reject to accept or convers in (c) 11.5x 
the amount of data from the alternative-distribut to reject thi 
hypothesis. finally, we allow to mark import hypothesi by 
tap the “star” icon (e). 

4 background on multipl hypothesi error 
the previou section describ how we convey the multipl hy- 

pothesi error to the user and ask for user feedback to deriv the 
right hypothesis. In thi section we describ differ altern to 
calcul the potenti fals discoveri error and discu they appro- 
priat for the ide setting. the notat use in the rest of the 
paper be summar in appendix A. 

We consid a setting, in which we evalu the statist rel- 
evanc of hypothesi from a set H = h1,h2, . . . ,hm, creat 
increment by an ide system in a stream fashion. In order 
to verifi whether ani such hypothesi Hj be in fact statist 
relev we consid it correspond null hypothesi Hj . use 
the appropri statist test (e.g., the t-test or the X 2-test) the 
p-valu of Hj evalu and base on it the test procedur deter- 
mine whether to accept (resp., reject) a null hypothesi Hj which 

in turn correspond to reject (resp., accepting) the correspond 
altern hypothesi (or research hypothesis)h|. the hypothesi 
accord to which all null hypothesi be true be refer a the 
“complete” or “global” null hypothesis. 

the set of null hypothesi reject by a statist test be call 
“discoveries”and be denot a R. among these we distinguish the 
set of true discoveri S, and the set of fals discoveri or fals 
posit V ; i.e., |V |+|s|= |r| fals discoveri be commonli 
refer also a type 1 errors. null hypothesi in S be fals null 
hypotheses, while null hypothesi in V be true null hypotheses. 

4.1 hold-out dataset 
A possibl method to deal with the multipl hypothesi error be to 

split the datasetd into a explorationd1 and a validationd2 dataset 
[38]. D1 be then use for the data explor process, wherea the 
valid dataset be use to re-test all hypothesi in order to valid 
the result of the first phase. In the follow we will provid some 
exampl which will clarifi how, albeit useful, a hold-out dataset 
do not solv the multipl hypothesi test problem. 

let u consid a null hypothesi H , and let pD denot it associ- 
ate p-valu when H be evalu with respect of the entir dataset 
D. let assum we perform a test with significance-level α. In thi 
case the probabl of wrongli reject H be at most α suppos 
now that we randomli split the dataset into two dataset D1 and d2. 
for the same null hypothesi H we evalu the p-valu pd1 and 
pd2 each obtain by evalu H on D1 or D2 respectively. We 
then run a a test with significance-level α (like the one discuss 
above) for each of the datasets. We then decid to reject H if it 
have be reject by both the test procedur oper on the 
datasetsd1 ord2. If both procedur oper ond1 andd2 have 
significance-level α, then the probabl that the overal procedur 
end up reject H be at most α2. 

for the common valu of α = 0.05, the chanc of a type I error 
be thu reduc to 0.0025, which be good news. rather than fulli 
handl the multipl hypothesi problem, what we have achiev 
trough thi procedur be howev just the lower of the threshold 
for reject the null hypothesi (i.e., the signific level of the 
test). 

thi fact appear clearli in the follow scenario. suppos that 
the user want to evalu multipl hypothesi (e.g., 25) rather than 
just one. assum that these hypotheses, and their p-valu be 
independent, the probabl of observ at least one erron 
reject use the test techniqu base on the use of the holdout 
dataset would be: pf = 1 − (1 − pd)25 ≈ 0.06, which be high 
than the desir α signific level. 

albeit the lower of the achiev reduct of the signific 
level be inde use for reduc the chanc of type I errors, it 
come at the cost of a signific reduct of the power of the 
test procedure. 

let u consid the follow exampl scenario in which we aim 
to compar the mean M1 and M2 of two sampl one drawn from 
a popul with expect valu µ1 = 0 and the other from a 
popul with µ2 = 1, both have a standard deviat of σ = 4. 
In order to determin weather the observ differ betweenm1 
anm2 be actual statist significant, we test the null-hypothesi 
“there be no signific differ between µ1 and µ2” use the 
one-sid t-test and a sampl compos by 500 record from each 
population. given the properti of the t-test (see [13]), the statist 
power of our test would be 0.99, and the probabl of erron 
accept the null hypothesi would be at most 0.01. 

suppos now that we divid the dataset into a dataset for explo- 
ration and one for valid each compos by 250 records. the 
statist power for each of the individu t-test execut on the 
two dataset be now lower to 0.87, due to the reduct of the data 



be used. further, recal that the procedur base on the holdout 
set reject a null hypothesi onli if say hypothesi be reject by 
both sub-tests. thi impli that the actual overal power of the 
test procedur be 0.87 · 0.87 ≈ 0.76, which be significantli low 
than the 0.99 achiev by the test which us the entir data. 

In general, approach base on hold-out dataset be consid 
inferior compar to test over the entir dataset. In some sce- 
narios, like build machin learn models, hold-out dataset 
might even be the onli possibl to test a model or tune parameters. 
In those cases, a hold-out approach (like k-fold cross-validation) 
should be consid a test and should be control for the multipl 
hypothesi error a recent work suggest [10, 24, 30]. 

It be howev import to remark that in our work we aim to 
predict guarante on the statist signific of the statist 
predictor which be instead not achiev use prediction-driven 
approach such a cross-validation. 

4.2 family-wis error rate (fwer) 
traditionally, frequentist method for multipl comparison test- 

ing focu on correct for modest number of comparisons. A 
natur gener of the signific level to multipl hypothe- 
si test be the famili wise error rate, which be the probabl of 
incur at least one type I error in ani of the individu tests. the 
fwer be the probabl of make at least one type I error in the 
family: 

fwer = pr(v ≥ 1) = 1− pr(v = 0) (1) 

By assur that fwer ≤ α, that be the fwer be control 
at level α, we have that the probabl of even one type I error in 
evalu a famili of hypothesi be at most α. 

We say that a procedur control the fwer in the weak sense, 
if the fwer control at level α be guarante onli when all null 
hypothesi be true (i.e. when the complet null hypothesi be true). 
We say that a procedur control the fwer in the strong sense, if the 
fwer control at level α be guarante for ani configur of true 
and non-tru null hypothesi (includ the global null hypothesis). 

bonferroni correction: the bonferroni correct be the sim- 
plest statist procedur for multipl hypothesi test [6]. let 
α be the critic threshold for the test. the valu of α be usual 
select at 0.01 or 0.05. 

let pi the p-valu statist associ with the null hypothesi 
hi. when test m distinct null hypothesi use the bonferroni 
correction, a null hypothesi Hi be reject if pi ≤ α/m. the 
bonferroni procedur thu achiev control of the fwer at level α. 

unfortunately, the bonferroni correct can not be appli in our 
set a it requir knowledg of the total number of hypothesi 
be considered. An altern approach be to use a variat of the 
bonferroni correction, accord to which the j-th null hypothesi 
Hj be reject if pj ≤ α · 2−j . It be possibl to show that thi 
procedur inde control fwer at level α a j →∞ and do not 
need explicit knowledg of m. howev the accept threshold 
decreas exponenti with respect to the number of hypotheses, 
thu result in a high number of fals negatives. 

the main common issu with all fwer techniqu be that the 
power of the test significantli decreas a m increas due to 
the correspond decreas in the accept threshold (α/m in 
the origin bonferroni or α/2i in the sequenti variant). while 
some altern test procedur such a those of vǐdák [34], 
holm [18], hochberg [17], and sime [35] offer more power while 
control fwer, the achiev improv be gener minor. 
A review of sever of these techniqu be provid by shaffer 
in [32]. 

4.3 fals discoveri rate (fdr) 
In [2] benjamini and hochberg propos the notion of fals 

discoveri rate (fdr) a a less conserv approach to control 

error in multipl test which achiev a substanti increas in the 
power of the test procedure. 

fdr-control procedur be design to control the expect 
ratio Q = v/r of fals discoveri among all discoveri return 
by a procedure. In particular, the fdr of a statist procedur be 
defin as: 

fdr = E [q] = E 

[ 
V 

R 
|R > 0 

] 
P (R > 0). (2) 

however, if we defin fdr to be zero when R = 0, we can 
simplifi 2 to: 

fdr = E 

[ 
V 

R 

] 
(3) 

We say that a test procedur control fdr at level α if we 
have fdr ≤ α. design a statist test that control for fdr 
be not simple, a the fdr be a function of two random variabl 
that depend both on the set of null hypothesi and the set of alter- 
nativ hypotheses. the standard techniqu to control the fdr be 
the benjamini-hochberg procedure(bh), which oper a follows: 
let p1 ≤ p2 ≤ . . . ≤ pm be the sort order of the the p-valu 
for the m test null hypotheses. To control fdr at level α (for 
independ null p-values) determin the maximum k for which 
pk ≤ km · α, and reject the null hypothesi correspond to the 
p-valu p1, p2, . . . , pk. 

interestingly, under the complet null hypothesis, control the 
fdr at level α guarante also “weak control” over the fwer 
fwer = P (V ≥ 1) = E 

( 
V 
R 

) 
= fdr ≤ α. thi follow 

from the fact that the event of reject at least one true null hypoth- 
esi V ≥ 1 be exactli the event v/r = 1, and the event V = 0 be 
exactli the event v/r = 0 (recal v/r = 0 when V = R = 0). 
thi make the fdr rel easi to explain to the user a under 
complet random data, the chanc of one or more fals discoveri 
be at most α a in fwer. however, fdr do not howev ensur 
control of the fwer if there be some true discoveri to be make 
(i.e., it do not ensur “strong control” of the fwer). 

becaus of it increas power, fdr appear to be a good candi- 
date than fwer in the context interact data exploration, where 
usual a larg number of hypothesi be to be considered. unfor- 
tunately, both the origin benjamini-hochberg procedur and it 
variat for deal with depend hypothesi [3] be not incre- 
mental a they requir knowledg of the total number of hypothesi 
be test (similar to what be discuss for bonferroni) and 
of the sort list of all the p-valu correspond to each null 
hypothesi be evaluated. 

An adapt of the fdr techniqu to a set for which an 
unspecifi number of null hypothesi be observ increment 
be recent discuss in [15]. the main idea behind the sequen- 
tial fdr procedur be to convert the arbitrari sequenc of p-valu 
correspond to the null hypothesi observ on the stream of hy- 
pothes into an order sequenc akin to the one gener by the 
classic benjamini-hochberg procedure. the natur applic 
for thi techniqu be the progress refin of a model by consid- 
ere addit features. that is, it start construct a model for 
the data with someth know and general. the user then proce 
to refin the model by determin the most signific features. 

one drawback of the sequenti fdr method, be give by the 
fact that the order accord to which the hypothesi be observ 
on the stream heavili influenc the outcom of the procedure. for 
example, if an hypothesi with high p-valu be observ among the 
first in the stream, thi will harm the abil of the procedur of 
reject follow null hypotheses, even if they have low p-valu 
(see discuss in [15]). thi aspect make sequenti fdr not 
applic for data explor system for which the user be like to 
explor differ “avenues” of discoveri rather than focu on the 
special of a model. 



4.4 other approach 
although for most practic applications, fdr control pro- 

cedur constitut the de facto standard for multipl hypothesi 
test [12], mani other techniqu have be present in the litera- 
ture. among them, bayesian techniqu be particularli noteworthy. 
In [5], altern solut to the multpl hypothesi problem com- 
bine decis theori with bayesian fdr be discussed. however, 
a often the case with bayesian approaches, the comput cost 
for these procedur when appli to larg dataset be significant, 
and the result be highli depend on the prior model assumptions. 

anoth approach be correct for the multipl through simu- 
lation (e.g., the permut test [31]) that experiment evalu 
the probabl of an observ in the null distribution. thi ap- 
proach be also not practic in larg dataset becaus of the larg 
number of differ possibl observ and the need to evalu 
veri small p-valu of each of these distribut [21]. 

In thi paper, we elect to use a famili of multipl hypothesi 
test procedur know a α-invest introduc in [14] and then 
gener in [1]. these procedur be especi interest for 
the increment and interact natur of interact data exploration. 
the detail of α-invest and it applic to our set be exten- 
sive discuss in the next section. 

5 interact control use α-invest 
one drawback of the sequenti fdr procedur [15] a well a 

adapt of fwer control techniqu to the stream set 
be give by the fact that decis regard the reject or accep- 
tanc of previous consid null hypothesi could potenti 
be overturn in latter stage due to new hypothesi be consid- 
ered. although statist sound, thi fact could appear extrem 
counter intuit and confus to the user. the onli way to adopt 
the sequenti fdr procedur to data explor would be to batch 
all the hypothesi and onli present the final decis afterwards. 
In that sens sequenti fdr be increment but non-interact in 
data exploration. 

In order to have both increment and interact multipl hy- 
pothesi error control, we consid a differ approach for multipl 
hypothesi test base on the “α-invest ” test procedur 
introduc origin introduc by foster and stine in [14]. simi- 
larli to sequential-fdr , thi procedur do not requir explicit 
knowledg of the total number of hypothesi be test and can 
therefor be appli in the hypothesi stream setting. α-invest 
present howev sever crucial differ with respect to both 
tradit and sequenti fdr control procedures. 

In the following, we first introduc the gener outlin of the 
procedur a present in [14] and then discu sever invest 
strategi (call policies) that we have develop for interact 
data exploration. 

5.1 outlin of the procedur 
for α-invest , the quantiti be control be not the clas- 

sic fdr but rather an altern quantiti call “margin fdr 
(mfdr)”: 

mfdrη(j) = 
E [V (j)] 

E [r(j)] + η 
(4) 

where j denot the total number of test which have be executed, 
while V (j) (resp., r(j)) denot the number of fals (resp., total) 
discoveri obtain use the α-invest procedure. 

In particular, we say that a test procedur controlsmfdrη at 
level α if mfdrη(j) ≤ α. the paramet η be introduc in order 
to weight the impact of case for which the number of discoveri 
be limited. common choic for η be 1, (1 − α), wherea the 
procedur appear to lose in power for valu of η close to 0 [14]. 

under the complet null hypothesi we have V (j) = r(j) henc 

mfdrη(j) ≤ α impli that E [V (j)] ≤ αη/(1− α). If we 
chose η = 1−α then E [V (j)] ≤ α, and we can thu conclud that 
control of the mfdr1−α at level α impli weak control fo the 
fwer at level α [14]. We refer the reader to the origin paper of 
foster and stine [14] for an extens discuss on the relationship 
between mfdr and the classic fdr. A gener of the α- 
invest procedur be late introduc in [1]. the α-invest 
procedur do not in gener requir ani assumpt regard the 
independ of the hypothesi be tested, although opportun 
correct be necessari in order to deal with possibl dependencies. 
In our analysis, we howev assum that all the hypothesi and the 
correspond p-valu be inde independent. 

intuit the α-invest procedur work a follows: with 
everi test j the user set an αj-value, which have to be below the 
current wealth, which be in the begin usual α · (1− α) befor 
he perform the test. If the null-hypothesi be accept (pj > αj) 
the invest alpha valu be lost. To some degre thi be similar 
to the bonferroni-correct a one could consid the αj valu 
everybodi be compar to a α/m. So whenev a test be performed, 
the wealth decreas by α/m until the wealth be 0 and the user have 
to stop exploring. however, in contrast to the bonferroni-correction, 
with α-invest the user can regain wealth through a reject null- 
hypothesis, which make the procedur truli increment a it do 
no longer depend on the number of anticip hypothesi m and 
also more powerful. 

more formally, we denot a W (0) the initi α-wealth assign 
to the test procedure. If the goal of the test procedur be to 
control mfdrη at level α, then we shall set W (0) = α · η. here, 
η be commonli set to (1− α). We denot a W (j) the amount of 
“avail α-wealth” after j test have be executed. 

each time a null hypothesi Hj be be tested, it be assign 
a budget αj > 0. let pj denot the p-valu associ with the 
null hypothesi Hj . thi hypothesi be reject if pj ≤ αj . If 
Hj be reject than the test procedur obtain a “return” on it 
invest ω ≤ α. instead, if the null hypothesi Hj be accepted, 
αj/(1− αj) alpha wealth be deduct from the avail α-wealth: 

W (t)−w (t− 1) = 
{ 
ω if pj ≤ αj , 
− 

αj 
1−αj 

if pj > αj 
(5) 

the test procedur halt when the avail α-wealth reach 0. 
At that point in time, the user should stop explor to guarante that 
mfdr ≤ α. obvious again something, which be not desir 
a it be hard to convey to ani user, that he have to stop exploring. We 
will discu thi problem and potenti solut in section 5.8. 

the budget αj which can be assign to test must be such that 
regardless of the outcom of the test, the availableα-wealth avail 
after the test be not neg W (j) ≥ 0, henc αj ≤ W (j − 
1)/(1−w (j − 1)). further we impos that αj < 1. while thi 
constraint be not explic in [14], it be inde necessari for the 
correct function of the procedure. set αj = 1 would lead to 
the potenti deduct of an infinit amount of α-wealth, violat 
the non neg of W (j). set αj > 1 would instead lead to 
have a posit increas of the avail α-wealth regardless of 
the outcom of the test. In our analysi we will howev assum 
that all the hypothesi be consid be inde independ and 
their associ p-valu be independ a well. 

We refer a “α-invest rule” to the polici accord to which 
avail budget have to be assign to the hypothesi that need to 
be tested. furthermore, in [14] it be show that ani α-invest 
polici for which W (0) = η · α, ω = α, and which obey the rule 
in (5), control the mfdr at level α, for α, η ∈ [0, 1]. 

the freedom of assign to each hypothesi a specif level 
of confid independ of the order, and the possibl of “re- 
investing” the wealth obtain by previou reject constitut great 



advantag with respect to the sequenti fdr procedure. 

5.2 α-invest for data explor 
while it be rel straightforward to devis invest rules, it be 

difficult a priori to determin the “best way to invest” the avail 
alpha-wealth. If αj be pick too small, the statist power of 
everi test be reduc and the chanc be even high too loos the 
invest wealth give a true altern hypothesis. If αj be too 
large, the entir α wealth might be quickli exhaust and the user 
(in theory) have to stop explor or re-evalu all hi test (see also 
section 5.8). A polici be most like to be success if it can exploit 
some knowledg of the test setting. 

anoth complic be the construct of test for which one 
can obtain the need p-valu . To show that a test procedur 
control mfdr, we requir that condit on the prior j - 1 
outcom (denot a ri), the level of the test of Hj must not 
exceed αj : 

P (rj = 1|rj1, rj2, ..., r1) ≤ αj . (6) 

thi do not howev constitut a problem in our set a we 
be assum all hypothesi and their p-valu to be independent. 

while [14] propos variou invest rules, most of the propos 
procedur might test a hypothesi again and overturn an initi re- 
jection of a null-hypothesis. therefore, in the remaind of thi 
section we propos differ α-invest polici particular for inter- 
activ data exploration, which correspond to differ explor 
strategi and at exploit differ possibl properti of the data. 
howev it should be noted, that our first procedure, β-farsighted, 
be a gener of the “best-foot-forward policy” in [14]. 

for thi paper, we consid a set for which we observ a 
(potenti infinite) stream of null hypothesi for which at each of 
the discret time step a new null hypothesi be observ on the 
stream. We denot a Hj the hypothesi be consid at the 
j-th step. We further assum that say hypothesi be independent. 

all our polici assign to each hypothesi a strictli posit budget 
αj > 0 a long a ani α-wealth be available. If pj ≤ αj , the null 
hypothesi Hj be reject (i.e., it be consid a discovery). vice 
versa, if pj > αj be accepted. the current α-wealth W (j) be 
then updat accord to the rule in (5) and becaus of it control 
mfdr at level α a show in [14]. 

5.3 β-farsight invest rule 
like with real investment, the question be if one should invest short 

or long-term. with β-farsight we creat a policy, which tri to 
preserv wealth over long explor sessions. given β ∈ [0, 1), 
we say that a polici be β-farsight if it ensur that regardless of the 
outcom of the j-th test at least a fraction β of the current α-wealth 
W (j − 1) be preserv for futur tests, that be for j = 1, 2, . . .: 

W (j) ≥ βW (j − 1), 
W (j)−w (j − 1) ≥ (β − 1)w (j − 1) 

(7) 

We therefor defin the β-farsight procedur to controlmfdrη 
at level α in the procedur for invest rule 1. 

invest rule 1 β-farsight 
1: W (0) = ηα 
2: for j = 1, 2, ... do 
3: αj = min 

( 
α, 

W (j−1)(1−β) 
1+w (j−1)(1−β) 

) 
4: if p(hj) < αj then 
5: W (j) = W (j − 1) + ω 
6: els 
7: W (j) = W (j − 1)− 

αj 
1−αj 

= βW (j − 1) 
8: end if 
9: end for 

differ choic for the paramet β ∈ [0, 1) character how 
conserv the invest polici is. If there be high confid on 

the first observ hypothesi be true discoveries, small valu of 
beta (i.e., 0.25) would be more effective. vice versa, high valu of 
β (i.e. 0.9) ensur that even if the first hypothesi be true null, a 
larg part of the α-wealth be preserved. 

We say that an α invest polici be “thrifty” if it never fulli com- 
mit it avail α-wealth. the describ β-farsight be inde 
thrifty. while the procedur will never halt due to the avail 
α-wealth reach zero, after a long seri of accept of null 
hypothesi the avail budget may be reduc so much that it will 
be effect imposs to reject ani more null hypotheses. 

although these polici may appear wast a there be no re- 
ward for wealth which have not be invested, they be aim to 
preserv some of their current budget for futur test in case the 
hypothesi consid in the begin of the test procedur be 
not particularli trustworthy. 

thi invest rule be therefor particular suit for scenario be 
the total number of fals discoveri in long explor sessions, 
potenti across multipl users, should be controlled. 

5.4 γ-fix invest rule 
A differ non-thrifti procedur assign to each hypothesi the 

same budget α∗. In particular, we call γ-fix a procedur that 
assign to each null hypothesi a fix budget αj equal to a fraction 
of the initi α-wealth W (0), that be α∗ =W (0)/(w (0) + γ), a 
long a ani α-wealth be available. 

the detail of the γ-fix procedur controllingmfdrη at level 
α can be found in the procedur for invest rule 2. 

invest rule 2 γ-fix 
1: W (0) = ηα 
2: α∗ = W (0) 

γ+w (0) 

3: whilew (j − 1)− α∗ 
1−α∗ ≥ 0, for j = 1, 2, . . . do 

4: if p(hj) < α∗ then 
5: W (j) = W (j − 1) + ω 
6: els 
7: W (j) = W (j − 1)− α∗ 

1−α∗ = W (j − 1)− 
W (0) 
γ 

8: end if 
9: end while 

note that we defin α∗ a W (0)/(γ +W (0)) to ensur that the 
subtract of the wealth be constantli W (0)/γ. differ choic 
for the paramet γ character how conserv the invest 
polici is. If there be high confid on the first observ hypothesi 
be actual discoveri small valu of γ (i.e. 5,10,20) would make 
more sense. vice versa a high valu of γ ensur that even if the first 
hypothesi be true null, a larg part of the α wealth be preserved. 
good choic for that set would be γ = 50, 100. 

5.5 δ-hope invest rule 
In a slight variat of the γ-fix invest rule, we say that 

a polici be δ-hope if the budget be assign to each hypothesi 
“hoping” that at least one of the next δ hypothesi will be rejected. 
each time a null hypothesi be reject the budget obtain from 
the reject be re-invest when assign budget over the next δ 
null hypotheses. γ-fix and δ-hope oper by spread the 
amount of α-wealth over a fix number of hypothesi (either γ 
or δ), δ-hope be howev “less conservative” than γ-fix a it 
alway oper by invest all current avail α-wealth over 
the next δ hypotheses. So it be a much more optimist procedure, 
which work well if most altern hypothesi be expect to 
accepted. the detail of the δ-fix procedur control mfdrη 
at level α can be found in the procedur for invest rule 3. 

5.6 �-hybrid invest rule 
becaus α-invest allow contextu inform to be incor- 

porated, the power of the result procedur be relat to how well 



invest rule 3 δ-hope 
1: W (0) = ηα 
2: α∗ = W (0) 

δ+w (0) 

3: k∗ = 0 
4: whilew (j − 1)− α∗ 

1−α∗ ≥ 0, for j = 1, 2, . . . do 
5: if p(hj) < α∗ then 
6: W (j) = W (j − 1) + ω 
7: α∗ = min 

( 
α, 

W (j) 
δ+w (j) 

) 
8: k∗ = j 
9: els 

10: W (j) = W (j − 1)− α∗ 
1−α∗ = W (j − 1)− 

W (k∗) 
α∗ 

11: end if 
12: end while 

the design heurist fit the actual data explor scenario. for 
example, when the data exhibit more randomness, the γ-fix rule 
tend to have more power than the δ-hope rule. intuitively, the 
α-wealth decreas when test a true null hypothesis, becaus the 
expect of the chang of wealth be neg when the p-valu 
be uniformli distribut on [0, 1]. thu the initi α-wealth be on 
averag larg than the α-wealth avail at subsequ steps. fur- 
thermore, sinc the γ-fix rule invest a constant fraction of the 
initi wealth, the power tend to be larg than δ-hopeful. 

On the contrary, when the data be less random, the γ-fix rule 
becom less power than δ-hope rule. the reason be that in 
thi set more signific discoveri tend to keep the subsequ 
α-wealth high, potenti even high than the initi wealth. We 
studi thi differ in more detail in section 7. 

In order to have a robust perform in term of power and fals 
discoveri rate, we design �-hybrid invest rule that adjust the αj 
assign to the variou test base on the estim data randomness. 
our estim of the random of the data be base on the ratio of 
reject null hypothesi over a slide windowhd constitut by the 
last d null hypothesi observ on a stream. We then compar thi 
ration with a “random threshold” � ∈ (0, 1) and we conclud 
whether the data exhibit high random or not. the procedur 
be outlin in invest rule 4. 

invest rule 4 �-hybrid 
1: W (0) = ηα 
2: k∗ = 0 
3: Hd = [] // slide window of size d 
4: whilew (j − 1) > 0, for j = 1, 2, . . . do 
5: if rejected(hd)≤ |hd|� then 
6: αj = 

W (0) 
γ+w (0) 

7: els 
8: αj = min 

( 
α, 

W (k∗) 
δ+w (k∗) 

) 
9: end if 

10: ifw (j − 1)− 
αj 

1−αj 
≥ 0 then 

11: if p(hj) < αj then 
12: W (j) = W (j − 1) + ω 
13: k∗ = j 
14: hd[j] = Rj = 1 
15: els 
16: W (j) = W (j − 1)− 

αj 
1−αj 

17: hd[j] = Rj = 0 
18: end if 
19: end if 
20: end while 

5.7 invest base on support popul 
In thi section we discu how to adjust the budget of each hy- 

pothesi accord to the amount of data which be avail in order 
to comput the p-valu of that same hypothesis. the main intuit 
for thi procedur be that, a it be most like to observ high p-valu 
for hypothesi which reli on a small number of data points, we 

should should not invest a much α-wealth on those hypotheses. In 
thi section we discu how to bia the amount budget assign to 
each hypothesi so that hypothesi with more support data receiv 
more “trust” (in term of budget) from the procedure. 

let u denot a |n| the total amount of data be use and 
by |j| the avail data for test the j-th null hypothesi ht. 
A simpl way of correct the assign of the budget αj in 
ani of the previous mention hypothesi be to assign to the test 
of the hypothesi αjf( |j||n| ). depend on the choic of f(·) the 
impact of the correct may be more or less severe. some possibl 

choic for f(·) would be f( |t||n| ) = 
( 
|t| 
|n| 

)ψ 
for possibl valu of 

ψ = 1, 2/3, 1/2, 1/3, . . .. We present an exampl polici base on 
the γ-fix rule, the ψ-support rule in invest rule 5. 

invest rule 5 ψ-support 
1: W (0) = ηα 
2: α∗ = W (0) 

γ+w (0) 

3: whilew (j − 1) > 0, for j = 1, 2, . . . do 

4: αj = α∗ 
( 
|t| 
|n| 

) 1 
2 

5: ifw (j − 1)− 
αj 

1−αj 
≥ 0 then 

6: if p(hj) < αj then 
7: W (j) = W (j − 1) + ω 
8: els 
9: W (j) = W (j − 1)− 

αj 
1−αj 

10: end if 
11: end if 
12: end while 

5.8 what happen If the wealth be 0 
among all our propos invest policies, onli β-farsight 

be “thrifty”,that it be never fulli commit it avail α-wealth. 
still, the avail wealth for β-farsight could eventu becom 
extrem small, to the point that no more hypothesi can be rejected. 
all the remain procedur be “non-thrifty” and can thu reach 
zero α-wealth, in which case the user (theoretically) should stop 
exploring. 

It be onli natur to wonder if it would be possibl for the user to 
somehow “recover” some of the lose α-wealth and thu continu 
the test procedure. one possibl way to do so, would requir 
the user to reconsid and possibl overturn some of the previou 
decis on whether to reject or accept some null hypothesi us- 
ing altern test procedur (i.e., the benjamini-hochberg 
procedure). 

there be howev sever challeng to be face when pursu 
thi strategy: 1) great care have to be put on haw to combin result 
from differ test procedur (i.e., control of fdr for a subset 
of hypothesi and control of mfdr for a distinct subset of hypothe- 
ses) and 2) test hypothesi for a second time give the outcom 
of other test impli a clear (and strong) depend between the 
outcom of the test and the p-valu associ with the null hy- 
pothes be considered. therefore, depend on the context 
such control could onli be achiev give addit assumpt 
about the level of control or would requir add addit data or 
the use of a hold-out dataset. We aim to studi thi problem in detail 
a part of futur work. 

6 the most import discoveri 
In section 3 we argued, that the user should be abl to mark 

the import hypothesi (e.g., the one she want to includ in a 
publication). thi be particularli import a awar us default 
hypotheses, which the user might consid a less important. In the 
follow we show that if these “import discoveries” be select 
from all the discoveri give by a test procedur that control 



(a) 75% null: avg. disc (b) 75% null: avg. fdr (c) 75% null: avg. power (d) 100% null: avg. disc (e) 100% null: avg. fdr 

figur 3: exp.1a: static procedur on synthet data 

fdr at level α independ of their p-valu , then the fdr for 
the set of import discoveri be control at level α a well. 

theorem 1. assum that we execut a collect of hypoth- 
esi test with a reject rule that control the fdr at α. as- 
sume that the procedur reject the set of null hypothesi R = 
{r1, . . . , rr}, and let V ⊆ V be the set of fals discoveries. If the 
null hypothesi test be independ then for ani subset R′ ⊆ R 
we have e[|v ∩r′|/||r′] ≤ α. 

proof. let p1, . . . , p|r| be the p-valu of the reject hypothe- 
ses. sinc the reject rule control the fdr at α we have 

|r|∑ 
i=1 

i 

|r| 
P (|v |= i | P1 = p1, . . . , Pr = pr) = α (8) 

assum that |V |= i. A priori, the p-valu of null hypothe- 
s be i.i.d. uniformli distribut in [0, 1] []. subject to P1 = 
p1, . . . , Pr = pr , the set of the i null hypotheses’ p-valu be uni- 
formli distribut among all the i subset of the r valu {p1, . . . , pr}. 
let p′1, . . . , p′|r′| be the p-valu of the set of hypothesi R 

′, and 
let pvi , . . . p 

V 
|V | be the p-valu of the reject null hypotheses, then 

e[|v ∩ r′| | |V |= i] = 

e[|{p′1, . . . , p 
′ 
|r′|} ∩ {p 

V 
1 . . . P 

V 
|V |}| | |V |= i] = i 

|r′| 
|r| 

. 
(9) 

combin equat (8) and (9) we get: E 
[ |V ∩ r′| 
|r′| 

] 
= 

|r|∑ 
i=1 

E 

[ |V ∩ r′| 
|r′| 

| |V |= i 
] 
P (|v |= i | P1 = p1, . . . , Pr = pr) 

= 

|r|∑ 
i=1 

1 

|r′| 
i 
|r′| 
|r| 

P (|v |= i | P1 = p1, . . . , Pr = pr) = α 

(10) 

consid a set R′ of import discoveri select independ 
of the p-valu of the correspond null-hypothesi from a larg 
set of discoveri R for which then mfdr be control at level 
α. use a proof similar to the one discuss in theorem 1 it be 
possibl to show that the mfdr of R′ be control at level α a 
well. thi be an import result, a it impli that the user can select 
the import discoveri from a larg pool of discoveri while 
maintain the control of fdr (or mfdr) at level α. 

7 experiment evalu 
In thi section, we evalu the α-invest rule in differ data 

explor set to answer the follow questions: 
1. how do our α-invest rule compar to sequenti fdr? 
2. what be the averag power (the proport of truli signific 

discoveri that be correctli identified)? 
3. what be the averag fals discoveri rate? 
workload/data: We first conduct the simul analysi on 

synthet data, and then run user-studi workflow on a real-world 
dataset. the statist commun consid the simul analysi 
on synthet data to be the statist sound methodolog to evalu- 
ate a multipl hypothesi test procedur (see for exampl [2, 4]), 

becaus on real-world dataset and workflow the proport and 
signal-to-nois ratio of truli signific and insignific hypothesi 
be hard to determin and control. 

implement and setup: the procedur for all experi- 
ment are: (1) No multipl hypothesi control: per-comparison 
error rate (pcer) [4], (2) static: bonferroni correct (bonfer- 
roni) [6] and benjamini-hochberg (bhfdr) [4] (3) increment 
but non-interactive: sequenti fdr (seqfdr) [15] (4) increment 
and interactive: α-invest rule of thi paper. 

We modifi our system to also execut static procedures. We 
emphas that the static-versus-increment comparison onli serf 
a a refer a the static procedur be essenti not suitabl for 
data explor a discuss in section 4. 

for all configurations, we set α to 0.05 and estim the averag 
fals discoveries, the averag fdr (i.e., the averag of the ratio of 
the fals discoveri over all discoveries), and the averag power 
and their correspond 95% confid intervals. 

7.1 exp.1a: static procedur 
In the first experi we evalu the static multipl hypothesi 

control procedur over synthet data to motiv our choic of 
fdr (and similarli mfdr) over fwer and per-comparison error 
rate (pcer) (i.e. no multipl hypothesi control). 

We creat a larg simul studi similar to the one in [4] with 
m hypotheses, rang from 4-64. each hypothesi be compar 
the expect of two independ distribut normal random 
variabl of varianc 1 but differ expect vari from 5/4 
to 5. the true null hypothesi be gener uniformli distribut 
across all test and the proport of true null hypothesi be set 
to 75% and 100% (i.e., complet random data). We repeat the 
experi 1,000 times. 

figur 3 show the result for the static procedures, the bonferroni- 
correct (bonferroni), the benjamini-hochberg procedur (bhfdr) 
and per-comparison error rate (pcer). for each procedure, we show 
the averag number of discoveries, the averag fals discoveri rate 
(fdr) and the averag power. note that the power be 0 for all 
procedur over complet random data and thus, not shown. 

We observ that pcer have the high power figur 3(c), mean- 
ing that it can identifi the high proport of truli signific 
discoveries. however, pcer have also the high fals discoveri 
rate across all configur (see (b) and (e)). On complet ran- 
dom data, pcer averag 60% fals discoveri when test 64 
hypothesi in figur 3(e). therefor pcer be not the right control- 
ling target in multipl hypothesi test in data exploration. 

On the other hand, the bonferroni procedur have the low av- 
erag fals discoveri rate (see (b) and (e)), but the number of dis- 
coveri be also the low and the power also degrad quickli with 
an increas number of hypotheses. for thi reason, fwer be too 
pessimist for data exploration. 

As a result, we advoc to use fdr (and similarli mfdr) a the 
control target for data explor sinc we observ that the static 
fdr procedure, bhfdr, achiev a low averag error rate than 



4 8 16 32 64 
number of hypothesi 

0 

5 

10 

15 

20 

25 

30 

35 

40 

(a) 25% null: avg. discoveri 

4 8 16 32 64 
number of hypothesi 

0.00 

0.02 

0.04 

0.06 

0.08 

0.10 

(b) 25% null: avg. fdr 

4 8 16 32 64 
number of hypothesi 

0.0 

0.2 

0.4 

0.6 

0.8 

1.0 

(c) 25% null: avg. power 

4 8 16 32 64 
number of hypothesi 

0.00 

0.05 

0.10 

0.15 

0.20 

0.25 

(g) 100% null: avg. discoveri 

4 8 16 32 64 
number of hypothesi 

0 

1 

2 

3 

4 

5 

6 

7 

8 

9 

(d) 75% null: avg. discoveri 

4 8 16 32 64 
number of hypothesi 

0.00 

0.02 

0.04 

0.06 

0.08 

0.10 

(e) 75% null: avg. fdr 

4 8 16 32 64 
number of hypothesi 

0.0 

0.2 

0.4 

0.6 

0.8 

1.0 

(f) 75% null: avg. power 

4 8 16 32 64 
number of hypothesi 

0.00 

0.02 

0.04 

0.06 

0.08 

0.10 

(h) 100% null: avg. fdr 

figur 4: exp.1b: increment procedur on synthet data / vari number of hypothes 

10.0% 30.0% 50.0% 70.0% 90.0% 
sampl size 

0 

10 

20 

30 

40 

50 

(a) 25% null: avg. discov- 
eri 

10.0% 30.0% 50.0% 70.0% 90.0% 
sampl size 

0.00 

0.02 

0.04 

0.06 

0.08 

0.10 

(b) 25% null: avg. fdr 
10.0% 30.0% 50.0% 70.0% 90.0% 

sampl size 

0.0 

0.2 

0.4 

0.6 

0.8 

1.0 

(c) 25% null: avg. power 
10.0% 30.0% 50.0% 70.0% 90.0% 

sampl size 

0 

2 

4 

6 

8 

10 

12 

14 

16 

(d) 75% null: avg. discov- 
eri 

10.0% 30.0% 50.0% 70.0% 90.0% 
sampl size 

0.00 

0.02 

0.04 

0.06 

0.08 

0.10 

(e) 75% null: avg. fdr 
10.0% 30.0% 50.0% 70.0% 90.0% 

sampl size 

0.0 

0.2 

0.4 

0.6 

0.8 

1.0 

(f) 75% null: avg. power 

figur 5: exp.1c: increment procedur on synthet data / vari sampl size 

pcer and and high power than fwer. 

7.2 exp.1b: increment procedur 
As discuss befor it be not feasibl to use the static procedur 

for interact data explor where the number of hypothesi 
be neither know upfront nor the p-valu can all be comput 
beforehand. for the remaind of the evaluation, we therefor focu 
on increment procedures. 

figur 4 us the same setup a in section 7.1. the true null hy- 
pothes be gener uniformli distribut across all test and the 
proport of true null hypothesi be set to 25%, 75% and 100% 
(i.e., complet random data). In thi experiment, we compar the 
differ α-invest rule we developed, namely, β-farsight with 
β = 0.25, γ-fix with γ = 10, δ-hope with δ = 10, �-hybrid 
with � = 0.5, and ψ-support, against the non-interact sequential- 
fdr (seqfdr) procedure. the α for each procedur be set to 0.05 
and the �-hybrid us unlimit window size. the ψ-support rule 
be implement on top of γ-fixed. We pre-set the valu base on 
rule-of-thumb judgement and do not further tune them. 

figur 4(b)(e)(h) show that all procedur control the fdr at level 
α = 0.05, bar some variat in the realiz of the averag 
fdr between the procedur (here low be better). sequenti fdr 
have the high averag fdr close to 0.05, wherea the α-invest 
procedur on averag make less mistakes. next, we studi the 
differ in fdr and the power of the α-invest rules, give 
differ context of data exploration. 
7.2.1 vari number of hypothes 

with β = 0.25, β-farsight simul a scenario in which the 
user be more confid or care more about earli discoveri be 
significant. In thi setting, β-farsight be expect to make less sig- 
nific discov in a long run if the dataset have more randomness. 
figur 4(f) show that β-farsight have veri high power earli on 
dure the exploration, while it lower gradual a more hypothesi 

be made. On the other hand, if the dataset have less randomness, 
such a in the 25% null configuration, β-farsight be reward with 
the mani discoveri dure the exploration, and thu maintain it 
power for a longer run. 
7.2.2 vari degre of random 

figure4f show that when the data have more randomness, the 
γ-fix rule tend to be more power than δ-hope a the number 
of hypothesi increases. when the data have less randomness, the 
δ-hope rule becom more power than γ-fix rule. the reason 
be that the ω return from more frequent signific discoveri tend 
to keep the α-wealth high, and sinc δ-hope invest a fraction of 
the α-wealth from the last reject hypothesis, α per test tend to 
be high and henc the increas of power. 

In light of thi observation, we develop the previous men- 
tion �-hybrid that estim the random in the dataset base 
on the histori of hypothesi test and pick between γ-fix or δ- 
hopeful. figur 4 show that �-hybrid procedur use � = 50% of 
past reject a the random threshold achiev overal a more 
robust perform in term of power and fdr on vari degre of 
random than the aforement two procedur alone. when 
the dataset be complet random, our α-invest rule achiev 
similarli low fals discoveri rate a the sequenti fdr below 5%. 
thi provid the simulation-bas evid that our α-invest 
rule correctli control the mfdr at α = 5%. 

overal the result suggest that the perform of a give α- 
invest rule depend on how well it heurist fit the context such 
a the import of earli discoveri and the data randomness. β- 
farsight be suitabl when the earli hypothesi be more import 
than the late ones; wherea �-hybrid strategi provid more robust 
perform across vari degre of randomness. 



10% 30% 50% 70% 90% 
sampl size 

0 

20 

40 

60 

80 

100 

(a) census: avg. disc (b) census: avg. fdr 

10% 30% 50% 70% 90% 
sampl size 

0.0 

0.2 

0.4 

0.6 

0.8 

1.0 

(c) census: avg. power 

10% 30% 50% 70% 90% 
sampl size 

0.00 

0.05 

0.10 

0.15 

0.20 

(d) rand. census: avg. disc 

10% 30% 50% 70% 90% 
sampl size 

0.00 

0.02 

0.04 

0.06 

0.08 

0.10 

(e) rand. census: avg. fdr 

figur 6: exp.2: real workflow on censu and random censu data 

7.2.3 vari support size 
As part of interact data exploration, the user usual appli 

variou filter conditions, which chang the support size for the 
differ tests. To evalu the impact of vari support sizes, 
we use the same setup a in section 7.1, but fix the number of 
hypothesi to 64 and vari the sampl size from 10-90%. the 
result be show in figur 5. 

while again �-hybrid and ψ-support do well across all configu- 
rations, ψ-support achiev low averag fdr especi for less 
random dataset (see figur 5(b) and (e)). thi be expect a the 
merit of the ψ-support rule be that it factor the support size of the 
hypothesi into the budget. thu the rule tend to low the per-test 
signific level when a low test p-valu be observ on data of 
suspici low support size. 

7.3 exp.2: real workflow 
In thi experi we show the effect of our propos 

procedur with real user workflow on the censu dataset [25]. We 
collect the workflow of 115 hypothesi base on a user studi 
we performed. the hypothesi be mostli form by compar 
histogram distribut by differ filter conditions, similar to 
the exampl from section 2. We fix the order of the hypothesi 
throughout the experi a mani of the hypothesi may depend 
on each other. 

To determin ground truth, we run the bonferroni procedur with 
the user workflow on the full-siz censu dataset to label the signifi- 
cant observations. We then down-sampl the full data repetit for 
addit uncertainty. note that thi evalu method be a straw 
man a we do not know the actual truli signific observ on 
censu data. It be like to be bia toward toward more conser- 
vativ α-invest rule with more evenli distribut budgets, such 
a γ-fix and ψ-support. 

figur 6(a)-(c) show the result of the user workflow over the 
censu data. the γ-fix and ψ-support rule perform good with 
averag fdr significantli below α = 0.05, a show in figur 6(b). 
for the other rules, the subtl side-effect of our label gener can 
be seen: the averag fals discoveri rate for �-hybrid, β-farsight 
and δ-hope slightli inflat a the sampl size increases, and 
reach over α = 0.05 to 0.09 for 90% samples. the reason be two- 
fold: first, the mfdr a the ratio of expect be not necessarili 
bound for onli a particular fix set of workflows. second, the 
bonferroni procedur gener a ground truth with a bia toward 
conserv α-invest rule with more evenli distribut budgets. 
henc the more optimist α-invest rule tend to make more 
mistakes. thi observ lead to interest insight about the 
conserv of differ α-invest rules. 

To good demonstr how our procedur control the fals dis- 
coveri rate, we therefor repeat the same experi base on the 
real-world workflow but on random censu data. figur 6(d) 
and (e) show the result (note that the power for all procedur be 
by definit zero a all discoveri contribut to falsehood). We 
observ that the α-invest procedur remain compar to the 
seqfdr for high sampl size in term of averag fdr, although 

some variat exist such that some of the error rate have con- 
fidenc interv over the rang 0.05 to 0.10. We attribut thi 
variat to the characterist of our set of user-studi workflows. 
for small sampl sizes, we see high variations. We attribut thi 
variat to the characterist of our set of user-studi workflows. 

8 relat work 
there have be surprisingli littl work in control the number 

of fals discoveri dure data explor even. thi be especi 
astonish a the same type of fals discoveri can also happen with 
tradit analyt sql-queries. To our knowledg thi be one 
of the first work tri to achiev a more automat approach in 
track the user steps. 

most relat to thi work be all the variou statist method for 
signific test and multipl hypothesi control. earli work 
tri to improv the power of the famili wide error rate use 
adapt bonferroni procedur such a sǐdák [34], holm [18], 
hochberg [17], and sime [35]. however, all these method lack 
power in larg scale multi-comparison tests. 

the altern fals discoveri rate measur be first propos 
by benjamini and hochberg [4], and soon becom the statist 
criterion of choic in the static literatur and in larg scale data 
explor analysi for genom data [27]. the origin fdr 
method decid which hypothesi to reject onli after all hypothesi 
be tested. data explor motiv the studi of more advanc 
techniques, such a sequenti fdr [15] and α-invest [14], that 
work in a scenario where hypothesi arriv sequenti and the 
procedur need to decid "on the fly" whether to accept or reject 
each of the hypothesi befor test the next one, while maintain 
a bound on the fdr. depend on the observ order of hypotheses, 
sequenti fdr can overturn previous accept hypothesi into 
reject base on the subsequ hypotheses. 
α-invest procedur also have revisit polici that can po- 

tential overturn previou decisions. the implic be that these 
procedur be increment but non-interactive, becaus they requir 
observ all the hypothesi befor final the decisions. how- 
ever, it be often infeas to obtain all the possibl hypothesi a 
priori. therefor our work concern α-invest procedur with 
polici that be both increment and interactive. In addition, none 
of the work address the issu on how to automat integr 
these techniqu a part of an data explor tool. 

9 conclus and futur work 
In thi paper we present the first automat approach to con- 

troll the multipl hypothesi problem dure data exploration. 
We show how the awar system integr user feedback and 
present sever multipl hypothesi control techniqu base on 
α-investing, which control mfdr, and be especi suit for con- 
troll the error for interact data explor sessions. finally, 
our evalu show that the techniqu be inde capabl of 
control the number of fals discoveri use synthet and real 
world datasets. however, a lot of work remain to be do from 
creat and evalu other type of default hypothesi over devel- 



ope new test procedur (e.g., for interact bayesian tests) to 
investig techniqu to recov from case where the user run 
out of wealth. yet, we consid thi work a an import first step 
toward more sustain discoveri in a time where more data be 
analyz than ever before. 

10 refer 
[1] E. aharoni and S. rosset. gener α-investing: definitions, optim 

result and applic to public databases. journal of the royal statist 
society: seri B (statist methodology), 76(4):771–794, 2014. 

[2] Y. benjamini et al. control the fals discoveri rate. journal of the royal 
statist society, seri B, 57(5), 1995. 

[3] Y. benjamini et al. the control of the fals discoveri rate in multipl test 
under dependency. ann. statist., 29(4), 08 2001. 

[4] Y. benjamini and Y. hochberg. control the fals discoveri rate: a practic 
and power approach to multipl testing. journal of the royal statist 
society. seri B (methodological), page 289–300, 1995. 

[5] D. A. berri et al. bayesian perspect on multipl comparisons. journal of 
statist plan and inference, 82(1–2), 1999. 

[6] C. E. bonferroni. teoria statistica dell classi e calcolo dell probabilita. 
libreria internazional seeber, 1936. 

[7] A. burgess, R. wagner, R. jennings, and H. B. barlow. effici of human 
visual signal discrimination. science, 214(4516):93–94, 1981. 

[8] F. chirigati et al. data polygamy: the many-mani relationship among urban 
spatio-tempor data sets. In sigmod, 2016. 

[9] A. crotti et al. vizdom: interact analyt through pen and touch. pvldb, 
8(12), 2015. 

[10] J. demšar. statist comparison of classifi over multipl data sets. J. mach. 
learn. res., 7:1–30, dec. 2006. 

[11] E. dimara, A. bezerianos, and P. dragicevic. the attract effect in 
inform visualization. ieee transact on visual and comput 
graphics, 23(1), 2016. 

[12] B. efron and T. hastie. comput age statist inference, volum 5. 
cambridg univers press, 2016. 

[13] R. fisher. the design of experiments. oliv and boyd, edinburgh, scotland, 
1935. 

[14] D. P. foster and R. A. stine. α-investing: a procedur for sequenti control of 
expect fals discoveries. journal of the royal statist society: seri B 
(statist methodology), 70(2):429–444, 2008. 

[15] M. G. g’sell et al. sequenti select procedur and fals discoveri rate 
control. journal of the royal statist society: seri B (statist 
methodology), 78(2), 2016. 

[16] H. guo, S. gomez, C. ziemkiewicz, and D. laidlaw. A case studi use 
visual interact log and insight. ieee trans. vis. comput. graph., 
2016. 

[17] Y. hochberg. A sharper bonferroni procedur for multipl test of significance. 
biometrika, 75(4):800–802, 1988. 

[18] S. holm. A simpl sequenti reject multipl test procedure. scandinavian 
journal of statistics, page 65–70, 1979. 

[19] J. P. A. ioannidis. whi most publish research find be false. plo med, 
2(8), 2005. 

[20] H. jeffreys. the theori of probability. oup oxford, 1998. 
[21] M. I. jordan. the era of big data. isba bulletin, 18(2), 2011. 
[22] N. kamat et al. distribut and interact cube exploration. In ieee icde, 

2014. 
[23] A. key et al. vizdeck: self-organ dashboard for visual analytics. In 

sigmod, 2012. 
[24] R. kohavi. A studi of cross-valid and bootstrap for accuraci estim 

and model selection. In proceed of the 14th intern joint confer 
on artifici intellig - volum 2, ijcai’95, page 1137–1143, san 

francisco, ca, usa, 1995. morgan kaufmann publish inc. 
[25] M. lichman. uci machin learn repository, 2013. 
[26] Z. liu, B. jiang, and J. heer. immens: real-tim visual queri of big data. In 

comput graphic forum, volum 32, page 421–430. wiley onlin library, 
2013. 

[27] J. H. mcdonald. handbook of biolog statistics. sparki hous publishing, 
baltimore, maryland, usa, second edition, 2009. 

[28] J. neyman and E. L. scott. consist estim base on partial consist 
observations. econometrica: journal of the econometr society, page 1–32, 
1948. 

[29] P. pirolli and S. card. the sensemak process and leverag point for analyst 
technolog a identifi through cognit task analysis. In proceed of 
intern confer on intellig analysis, volum 5, page 2–4, 2005. 

[30] P. refaeilzadeh, L. tang, H. liu, and M. T. özsu. cross-validation, page 
532–538. springer us, boston, ma, 2009. 

[31] M. schemper. A survey of permut test for censor surviv data. 
commun in statistics-theori and methods, 13(13):1655–1665, 1984. 

[32] J. P. shaffer. multipl hypothesi testing. annual review of psychology, 46, 
1995. 

[33] Y. B. shrinivasan and J. J. van wijk. support the analyt reason 
process in inform visualization. In proceed of the sigchi confer 
on human factor in comput systems, page 1237–1246. acm, 2008. 

[34] Z. šidák. rectangular confid region for the mean of multivari normal 
distributions. journal of the american statist association, 62(318):626–633, 
1967. 

[35] R. J. simes. An improv bonferroni procedur for multipl test of 
significance. biometrika, 73(3):751–754, 1986. 

[36] M. vartak et al. seedb: effici data-driven visual recommend to 
support visual analytics. pvldb, 8(13), 2015. 

[37] K. wongsuphasawat et al. voyager: exploratori analysi via facet brows 
of visual recommendations. ieee trans. vis. comput. graph., 22(1), 
2016. 

[38] A. F. zuur, E. N. ieno, and C. S. elphick. A protocol for data explor to 
avoid common statist problems. method in ecolog and evolution, 
1(1):3–14, 2010. 

appendix 
A symbol tabl 

the follow tabl summar the import symbol and nota- 
tion use in thi paper. 

H the set {h1, . . . , hm} of null hypothesi observ on the stream. 
H the set {h1, , . . . ,hm} of correspond “altern hypotheis”. 
R the number of null hypothesi reject by the test procedur 

(i.e., the discoveries). 
V the number of erron reject null hypothesi 

(i.e., fals discoveries, fals positives, type I errors). 
S the number of correctli reject null hypothesi 

(i.e., true discoveries, true positives,). 
r(j) the number of discoveri after j hypothesi have be tested. 
V (j) the number of fals discoveri after j hypothesi have be tested. 
s(j) the number of fals discoveri after j hypothesi have be tested. 
m the number of hypothesi be tested. 
pj the p-valu correspond to the null hypothsishj . 
W (0) initi wealth for the α-invest procedures. 
W (j) wealth of the α-invest procedur after j tests. 
α signific level for the test with α ∈ (0, 1). 
η bia in the denomin formfdrη . 

tabl 1: notat refer 


1 introduct 
2 A motiv exampl 
2.1 hypothesi test 
2.2 visual a hypothes 
2.3 heurist for visual hypothes 
2.4 heurist appli to the exampl 

3 the awar user interfac 
4 background on multipl hypothesi error 
4.1 hold-out dataset 
4.2 family-wis error rate (fwer) 
4.3 fals discoveri rate (fdr) 
4.4 other approach 

5 interact control use -invest 
5.1 outlin of the procedur 
5.2 -invest for data explor 
5.3 -farsight invest rule 
5.4 -fix invest rule 
5.5 -hope invest rule 
5.6 -hybrid invest rule 
5.7 invest base on support popul 
5.8 what happen If the wealth be 0 

6 the most import discoveri 
7 experiment evalu 
7.1 exp.1a: static procedur 
7.2 exp.1b: increment procedur 
7.2.1 vari number of hypothes 
7.2.2 vari degre of random 
7.2.3 vari support size 

7.3 exp.2: real workflow 

8 relat work 
9 conclus and futur work 
10 refer 
A symbol tabl 

