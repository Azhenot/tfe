


















































proceed of machin learn for healthcar 2017 jmlr w&c track volum 68 

clinic intervent predict and understand with deep neural 
network 

harini suresh 1 hsuresh@mit.edu 

nathan hunt 1 nhunt@mit.edu 

alistair johnson 2 aewj@mit.edu 

leo anthoni celi 2 lceli@mit.edu 

peter szolovit 1 psz@mit.edu 

marzyeh ghassemi 1 mghassem@mit.edu 

1 comput scienc and artifici intellig lab, mit, cambridge, MA 
2 laboratori for comput physiology, mit, cambridge, MA 

abstract 

real-tim predict of clinic intervent remain a challeng within intens care unit (icus). 
thi task be complic by data sourc that be sparse, noisy, heterogen and outcom that be 
imbalanced. In thi work, we integr data across mani icu sourc — vitals, labs, notes, demo- 
graphic — and focu on learn rich represent of thi data to predict onset and wean of 
multipl invas interventions. In particular, we compar both long short-term memori network 
(lstm) and convolut neural network (cnn) for predict of five intervent tasks: in- 
vasiv ventilation, non-invas ventilation, vasopressors, colloid boluses, and crystalloid boluses. 
our predict be do in a forward-fac manner after a six hour gap time to support clinic 
action planning. We achiev state-of-the-art result on these predict task use deep archi- 
tectures. further, we explor the use of featur occlus to interpret lstm models, and compar 
thi to the interpret gain from examin input that maxim activ cnn outputs. We 
show that our model be abl to significantli outperform baselin for intervent prediction, and 
provid insight into model learning. 

1. introduct 

As intens care unit (icus) play an increas role in acut healthcar deliveri (vincent, 2013), 
clinician must anticip patients’ care need in a fast-paced, data-overload setting. the sec- 
ondari analysi of healthcar data be a critic step toward improv modern healthcare, a it af- 
ford the studi of care in real care set and patient populations. the widespread avail of 
electron healthcar data (charl et al., 2013; jamoom E and E, 2016) allow new investig 
into evidence-bas decis support, where we can learn when patient need a give intervention. 

c©2017. 



continuous, forward-fac event predict be particularli import in the icu set where we 
want to account for evolv clinic needs. 

In thi work, we focu on predict the onset and wean of interventions. the efficaci of 
clinic intervent can vari drastic among patients, and unnecessarili administ an inter- 
vention can be harm and expensive. We target intervent that span a wide sever of need 
in critic care: invas ventilation, non-invas (ni) ventilation, vasopressors, colloid boluses, 
and crystalloid boluses. mechan ventil be commonli use for breath assistance, but have 
mani potenti complic (yang and tobin) and small chang in ventil set can have 
larg impact in patient outcom (tobin, 2006). vasopressor be a common icu medication, but 
there be no robust evid of improv outcom from their use (müllner et al., 2004), and some 
evid they may be harm (d’aragon et al., 2015). fluid bolu be use to improv cardio- 
vascular function and organ perfusion. there be two bolu types: crystalloid and colloid. both be 
often consid a less aggress altern to vasopressors, but there be no multi-cent trial 
studi whether fluid bolu therapi should be give to critic ill patients, onli studi tri to 
distinguish which type of fluid should be give (malbrain et al., 2014). 

captur complex relationship across dispar data type be key for predict perform 
in our tasks. To thi end, we take advantag of the success of deep learn model in captur 
rich represent of data with littl hand-engin by domain experts. We use long short-term 
memori network (lstm) (hochreit and schmidhuber, 1997), which have be show to effec- 
tive model complic depend in timeseri data (bengio et al., 1994) and have achiev 
state-of-the-art result in mani differ applications: e.g. machin translat (hermann et al., 
2015), dialogu system (chorowski et al., 2015) and imag caption (xu et al., 2015). they be 
well-suit to our model task becaus patient symptom may exhibit import tempor depen- 
dencies. We compar the lstm model to a convolut neural network (cnn) architectur that 
have previous be explor for longitudin laboratori data (razavian et al., 2016). We train one 
model per intervent which predict all outcom for that intervent give ani patient record. 
In do so, we: 

1. achiev state-of-the-art predict result in forward-facing, hourli predict of clinic in- 
tervent (onset, weaning, or continuity). 

2. demonstr how featur occlus can be use in the lstm model to show which data 
modal and featur be most import in differ predict tasks. thi be an import 
step in make model more interpret by physicians. 

3. further aid in model interpret by highlight patient trajectori that lead to the most 
and least confid predict across outcom and featur in a cnn model. 

2. background and relat work 

clinic decision-mak often happen in set of limit knowledg and high uncertainty; for 
example, onli 10 of the 72 icu intervent evalu in random control trial (rcts) be 
associ with improv outcom (ospina-tascón et al., 2008). secondari analysi of electron 
health record (ehr) aim to gain insight from healthcar data previous collect for the primari 
purpos of facilit patient care. 

recent studi have appli recurr neural network (rnns) to model sequenti ehr 
data to tag icu signal with bill code label (che et al., 2016; lipton et al., 2015; choi et al., 
2015), and to identifi the impact of differ drug for diabet (krishnan et al., 2015). razavian 
et al. (2016) compar cnn to lstm for longitudin outcom predict on bill code use 
lab tests. with regard to interpretability, choi et al. (2016) use tempor attent to identifi im- 



portant featur in earli diagnost predict of chronic diseas from time-ord bill codes. 
other have focu on use represent of clinic note (ghassemi et al., 2014) or patient 
physiolog signal to predict mortal (ghassemi et al., 2015). 

previou work on intervent in icu popul have often either focu on a singl out- 
come or use data from special cohorts. such model with vasopressor a a predict target 
have achiev auc of 0.79 in patient receiv fluid resuscit (fialho et al., 2013), 0.85 in 
septic shock patient (salgado et al., 2016), and 0.88 for onset after a 4 hour gap and 0.71 for wean- 
ing, onli train on patient who do receiv a vasopressor (wu et al., 2016). however, we train 
our model on gener icu popul in order to make them more applicable. In the most recent 
prior work on interventions, also on a gener icu population, the best auc perform be 
0.67 (ventilation), 0.78 (vasopressor) for vasopressor onset predict after a 4 hour gap (ghassemi 
et al., 2017). these be lower to 0.66 and 0.74 with a longer predict gap time of 8 hours. 

3. data and preprocess 

see figur 1 for an overal descript of data flow. 

3.1 data sourc 

We use data from the multiparamet intellig monitor in intens care (mimic-iii v1.4) 
databas (johnson et al., 2016). mimic iii be publicli available, and contain over 58,000 hospit 
admiss from approxim 38,600 adults. We consid patient 15 and old who have icu 
stay of 12 – 240 hour and consid each patient’ first icu stay only. thi yield 34,148 uniqu 
icu stays. 

3.2 data extract and preprocess 

for each patient, we extract 5 static variabl (such a gender and age), 29 time-vari vital and 
lab (such a oxygen satur and blood urea nitrogen), and all available, de-identifi clinic 
note for each patient a timeseri across their entir stay (see tabl 3 in the appendix for a 
complet list of variables). 

static variabl be replic across all timestep for each patient. vital and lab measur 
be give timestamp that be round to the near hour. If an hour have multipl measur for 
a signal, those measur be averaged. 

3.3 represent of note and vital 

clinic narr note be transform to a 50-dimension vector of topic proport for each 
note use latent dirichlet alloc (blei et al., 2003; griffith and steyvers, 2004). these vector 
be replic forward and aggreg through time (ghassemi et al., 2014). for example, if a 
patient have a note A record at hour 3 and a note B at hour 7, hour 3–6 would contain the topic 
distribut from A, while hour 7 onward would contain the aggreg topic distribut from A 
and B combined. 

We compar raw physiolog data to physiolog words, where we categor the vital data 
by first convert each valu into a z-score base on the popul mean and standard deviat 
for that variable, and then round thi score to the near integ and cap it to be between -4 
and 4. each z-score valu then becom it own column, which explicitli allow for a represent 
of missing (e.g., all column for a particular variabl zeroed) that do not requir imput 
(figur 7 in appendix B) (wu et al., 2016). 



figur 1: data preprocess and featur extract with numer measur and lab values, 
clinic note and static demographics. 

figur 2: given data from a fixed-length (6 hour) slide window, model predict the statu of 
intervent in a predict window (4 hours) after a gap time (6 hours). window slide along the 
entir patient record, creat multipl exampl from each record. 

the physiolog variables, topic distribution, and static variabl for each patient be concate- 
nate into a singl featur vector per patient, per hour (esteban et al., 2016). the intervent state 
of each patient (a binari valu indic whether or not they be on the intervent of interest at 
each timestep) and the time of day for each timestep (an integ from 0 to 23 repres the hour) 
be also add to thi featur vector. use the time of day a a featur make it easi for the model 
to captur circadian rhythm that may be present in, e.g., the vital data. 

3.4 predict task 

We split each patient’ record into 6 hour chunk use a slide window and make a predict 
for a window of 4 hour after a gap time of 6 hour (figur 2). when predict ventilation, non- 
invas ventilation, or vasopressors, the model classifi the predict window a one of four 
possibl outcomes: 1) onset, 2) wean, 3) continu on an intervention, or 4) continu to stay off 
an intervention. In thi representation, a label of 0 indic “off” an intervent and a label of 1 
indic “on”. therefore, a predict window be an onset if there be a transit from a label of 0 
to 1 for the patient dure that window; wean be the opposite: a transit from 1 to 0. A window 
be classifi a “stay on” if the label for the entir window be 1 or “stay off” if 0. when predict 
colloid or crystalloid boluses, we classifi the predict window into one of two classes: 1) onset, 



onset wean stay off stay On 
ventil 0.005 0.017 0.798 0.18 
vasopressor 0.008 0.016 0.862 0.114 

non-invas ventil 0.024 0.035 0.695 0.246 
colloid bolu 0.003 - - - 

crystalloid bol 0.022 - - - 

tabl 1: proport of each intervent class. note that colloid and crystalloid bolu be not 
administ for specif durations, and thu have onli a singl class (onset). 

or 2) no onset, sinc these intervent be not administ for on-go durat of time. after 
split the patient record into fixed-length chunks, there be 1,154,101 examples. tabl 1 list the 
proport of each class for each intervention. 

4. method 

4.1 long short-term memori network (lstm) 

have see the input sequenc x1 . . . xt of a give example, we predict ŷt, a probabl distribut 
over the outcomes, with target outcom yt: 

h1 . . . ht = lstm(x1 . . . xt) (1) 
ŷt = softmax(wyht + by) (2) 

where xi ∈ RV ,wi ∈ rnc×l2 , ht ∈ rl2 , by ∈ rnc where V be the dimension of the input 
(number of variables), NC be the number of class we predict, and L2 be the second hidden layer 
size. figur 3a show a model schematic, and more model detail be provid in appendix C. 

4.2 convolut neural network (cnn) 

We employ a similar cnn architectur to razavian et al. (2016), except that we do not initi 
convolv the featur into an intermedi representation. We repres featur a channel and 
perform 1D tempor convolutions, rather than treat the input a a 2D image. our architectur 
consist of tempor convolut at three differ tempor granular with 64 filter each. the 
dimens of the filter be 1× i, where i ∈ {3, 4, 5}. 

We pad the input such that the output from the convolut layer be the same size, and we 
use a stride of 1. each convolut be follow by a max pool layer with a pool size of 3. the 
output from all three tempor granular be concaten and flattened, and follow by 2 fulli 
connect layer with dropout in between and a softmax over the output (figur 3b). 

4.3 experiment set 

We use a train/validation/test split of 70/10/20 and stratifi the split base on outcome. for the 
lstm, we use dropout with a keep probabl of 0.8 dure train (onli on stack layers), and 
L2 regular with lambda = 0.0001. We use 2 hidden lstm layer of 512 node each. for 
the cnn, we use dropout between fully-connect layer with a keep probabl of 0.5. We use 
a weight loss function dure optim to account for class imbalances. all paramet be 
determin use cross-valid with the valid set. We implement all model in tensor- 
flow version 1.0.1 use the adam optim on mini-batch of 128 examples. We determin when 



(a) the lstm consist of two hidden layer with 512 
node each. We sequenti feed in each hour’ data. 
At the end of the exampl window, we use the final 
hidden state to predict the output. 

(b) the cnn architectur perform tempor convolut 
at 3 differ granular (3, 4, and 5 hours), max-pool 
and combin the outputs, and run thi through 2 fulli 
connect layer to arriv at the prediction. 

figur 3: schemat of the a) lstm and b) cnn model architectures. 

to stop train with earli stop base on auc (area under the receiv oper characterist 
curve) perform on the valid set. 

4.4 evalu 

We evalu our result base on per-class auc a well a aggreg macro aucs. If there be 
K class each with a per-class auc of auck then the macro auc be defin a the averag of 
the per-class aucs, aucmacro = 1K 

∑ 
k auck. We use the macro auc a an aggreg score 

becaus it weight the auc of all class equally, regardless of class size (man et al., 2008). 
thi be import becaus of the larg class imbal present in the data. 

We use L2 regular logist regress (lr) a a baselin for comparison with the neural 
network (pedregosa et al., 2011). the same input be use for the LR model a for the numer 
lstm and cnn (imput time window of data) but the timestep be concaten into a singl 
input vector. 

4.5 interpret 

4.5.1 lstm feature-level occlus 

becaus of the addit time depend of recurr neural networks, get feature-level 
interpret from lstm be notori difficult. To achiev this, we borrow an idea from imag 
recognit to help understand how the lstm us differ featur of the patients. zeiler and 
fergu (2013) use occlus to understand how model process images: they remov a region of the 
imag (bi set all valu in that region to 0) and compar the model’ predict of thi occlud 
imag with the origin prediction. A larg shift in the predict impli that the occlud region 
contain import inform for the correct prediction. with our lstm model, we mask featur 
one by one from the patient (replac the give featur with random nois drawn from the same 
distribut by bootstrapping). We then compar the predict abil of the model with and without 
each feature; when thi differ be large, then the model be reli heavili on that featur to 
make the prediction. 

note that examin featur interact would requir a more complex analysi to occlud 
all pairs, triples, etc., but would not necessarili demonstr the direct or exact natur of the 
interaction. 



4.5.2 cnn filter/activ visual 

We get interpret from the cnn model in two ways. first, in order to understand how the 
cnn be use the patient data to predict certain tasks, we find and compar the top 10 real exampl 
that our model predict be most and least like to have a specif outcome. As our gap time be 6 
hours, thi mean that the model predict high probabl of onset of the give task 6 hour after 
the end of the identifi trajectories. 

second, we gener “hallucinations” from the model which maxim the predict probabl 
for a give task (erhan et al., 2009). thi be do by creat an object function that maxim 
the activ of a specif output node, and backpropag gradient back to the input image, 
adjust the imag so that it maxim activ the output node. 

5. result 

We found deep architectur achiev state-of-the-art predict result for our intervent tasks, 
compar to both our baselin a well a other work predict intervent onset and wean 
(ghassemi et al., 2017; Wu et al., 2016). the auc for each of our five intervent type and 4 
predict task be show for all model in tabl 2. all model use 6 hour chuck of “raw” data 
which have either be transform to a 0-1 rang (normal and mean imputed), or discret 
into physiolog word (describ in section 3.3). 

5.1 physiolog word improv predict task perform with high class imbal 

We observ a significantli increas auc for some intervent when use physiolog word 
— specif for ventil onset (from 0.61 to 0.75) and colloid bolu onset (from 0.52 to 0.72), 
which have the low proport of onset exampl (tabl 1). thi may be becaus physiolog 
word have a smooth effect. sinc we round the z-score for each valu to the near integer, if 
a patient have a heart rate of 87 at one hour and then 89 at the next, those valu will probabl be 
repres a the same word. thi effect may make the model invari to small fluctuat in 
the patient’ data and more resili to overfit small classes. In addition, the physiolog word 
represent have an explicit encod for miss data. thi be in contrast to the raw data that have 
be forward-fil and mean-imputed, introduc nois and make it difficult for the model to 
know how confid to be in the measur it be give (che et al., 2016). 

5.2 feature-level occlus identifi import per-class featur 

We be abl to interpret the lstm’ predict use featur occlus (section 4.5.1). We note 
that vitals, labs, topic and static data be import for differ intervent (figur 4). tabl 5 in 
appendix D have a complet list of the most probabl word for each topic mentioned. 

for mechan ventilation, the top five most import featur – ph, sodium, lactate, hemoglobin, 
and potassium – be consist for wean and onset . thi be sensible, becaus all be import 
lab valu use to ass a patient’ physiolog stability, and ventil be an aggress interven- 
tion. however, ventil onset addit place import on a patient’ glasgow coma score 
(gcs) and topic 4 (assess patient consciousness), like becaus patient sedat be a critic 
part of mechan ventilation. We also note that the scale of auc differ between ventil 
onset and wean be the larg observ (up to 0.30 for wean and 0.12 for onset). 

In vasopressor onset prediction, physiolog variabl such a potassium and hematocrit be 
consist important, which agre with clinic assess of cardiovascular state (bassi et al., 
2013). similarly, topic 3 (note mani physiolog values) be also import for both onset and 



intervent type 
task model vent ni-vent vaso col bol cri bol 

O 
n 

et 
A 

U 
C 

baselin 0.60 0.66 0.43 0.65 0.67 
lstm raw 0.61 0.75 0.77 0.52 0.70 

lstm word 0.75 0.76 0.76 0.72 0.71 
cnn 0.62 0.73 0.77 0.70 0.69 

W 
ea 

n 
A 

U 
C 

baselin 0.83 0.71 0.74 - - 
lstm raw 0.90 0.80 0.91 - - 

lstm word 0.90 0.81 0.91 - - 
cnn 0.91 0.80 0.91 - - 

St 
ay 

O 
n 

A 
U 

C 

baselin 0.50 0.79 0.55 - - 
lstm raw 0.96 0.86 0.96 - - 

lstm word 0.97 0.86 0.95 - - 
cnn 0.96 0.86 0.96 - - 

St 
ay 

O 
ff 

A 
U 

C 

baselin 0.94 0.71 0.93 - - 
lstm raw 0.95 0.86 0.96 - - 

lstm word 0.97 0.86 0.95 - - 
cnn 0.95 0.86 0.96 - - 

M 
ac 

ro 
A 

U 
C 

baselin 0.72 0.72 0.66 - - 
lstm raw 0.86 0.82 0.90 - - 

lstm word 0.90 0.82 0.89 - - 
cnn 0.86 0.81 0.90 - - 

tabl 2: comparison of model perform on five target interventions. model that perform 
best for a give (intervention, task) pair be bolded. 

weaning. note that the overal differ in auc for onset rang up to 0.16, but there be no signifi- 
cant decreas in auc for wean (< 0.02). thi be consist with previou work that demonstr 
wean to be a more difficult task in gener for vasopressor (wu et al., 2016). We also note that 
wean predict place import on time of day. As note by Wu et al. (2016), thi could be a 
side-effect of patient be left on intervent longer than necessary. 

for non-invas ventil onset and wean the learn topic be more import than phys- 
iolog variables. thi may mean that the need for less sever intervent can onli be detect 
from clinic insight deriv in notes. similar to vasopressors, we note that onset auc vari more 
than wean auc (0.14 v 0.01), and that time of day be import for weaning. 

for crystalloid and colloid bolu onsets, topic be all but one of the five most import featur 
for detection. colloid bolu in gener have more auc varianc for the topic featur (0.14 vs. 
0.05), which be like due to the larg class imbal compar to crystalloids. 

5.3 convolut filter target short-term trajectori 

We be abl to understand the cnn by examin maxim activ patient trajectori (section 
4.5.2). figur 5 show the mean with standard deviat error bar for four of the most differen- 
tiat featur of the 10 real patient trajectori that be the high and low activ for each 
task. the trend suggest that patient who will requir ventil in the futur have high diastol 
blood pressure, respiratori rate, and heart rate, and low oxygen satur – possibl correspond- 



(a) (b) (c) (d) 

(e) (f) (g) (h) 

figur 4: We be abl to make interpret predict use an lstm and occlud specif 
features. these figur display the eight featur that caus the larg decreas in predict auc 
for each intervent task. In general, physiolog data be more import for the more invas 
intervent – mechan ventil (4a, 4b) and vasopressor (4c, 4d) – while clinic note topic 
be more import for less invas task – non-invas ventil (4e, 4f) and fluid bolu (4g, 
4h). note that all wean task except for ventil have significantli less auc variance. 

ing to patient who be hyperventilating. for vasopressor onsets, we see a decreas systol blood 
pressure, heart rate and oxygen satur rate. these could either indic alter peripher perfu- 
sion or stress hyperglycemia. topic 3, which be import for vasopressor onset use occlus 
(figur 4), be also increased. 

non-invas ventil onset be associ with decreas creatinine, phosphate, oxygen satu- 
ration and blood urea nitrogen, potenti indic neuromuscular respiratori failure. for colloid 
and crystalloid boluses, we note gener indic of physiolog decline, a bolu be give for 
a wide rang of conditions. 

hallucin for vasopressor and ventil onset be show in figur 6. while the model 
be not train with ani physiolog priors, it identifi blood pressur drop a be maxim 
activ for vasopressor onset, and respiratori rate declin for ventil onset. thi suggest that 
it be abl to learn physiologically-relev factor that be import for intervent prediction. the 
hallucin give u more insight into underli properti of the network and what it be look 
for. however, sinc these trajectori be make to maxim the output of the model, they do not 
necessarili correspond to physiolog plausibl trajectories. 

6. conclus 

In thi work, we target forward-fac predict of icu intervent cover multipl phys- 
iolog organ systems. To our knowledge, our model be the first to use deep neural network to 



figur 5: trajectori of the 10 maxim and minim activ exampl for onset of each of 
the interventions. these be the six hour trajectori that occur befor anoth six hour gap time 
preced the onset. 

figur 6: trajectori gener by adjust input to maxim activ a specif output node of 
the cnn. 

predict both onset and wean of intervent use all avail modal of icu data. In these 
tasks, deep learn method beat state-of-the-art auc report in prior work for intervent pre- 
diction tasks. thi be sensibl give that prior work have focu on singl target with small 
dataset (wu et al., 2016) or unsupervis represent prior to supervis train (ghassemi 
et al., 2017). We also note that lstm model over physiolog word input significantli improv 
perform on the two intervent task with the low incid rate — possibl becaus thi 
represent encod import inform about what be “normal” for each physiolog value, 
or be more robust to missing in the physiolog data. 

importantly, we be abl to demonstr interpret for both models. In the lstms, we 
examin featur import use occlusion, and found that physiolog data be import in 
more invas tasks, while clinic note topic be more import for less invas interventions. 
thi could indic that there be more clinic discret at play for less invas tasks. We also 
found that all wean task save ventil have less auc variance, which could indic that these 
decis be also make with a larg amount of clinic judgment. 

the tempor convolut in our cnn filter over the multi-channel input learnt interest 
and clinically-relev trend in real patient trajectories, and these be further mimick in the 
hallucin gener by the network. As in prior work (razavian et al., 2016), we found that 
rnn often have similar or improv perform a compar to cnns. 



acknowledg 

thi research be fund in part by the intel scienc and technolog center for big data, the 
nation librari of medicin biomed informat research train grant 2t15 lm007092-22, 
nih nation institut of biomed imag and bioengin (nibib) grant r01-eb017205, 
and nih nation human genom research institut (nhgri) grant u54-hg007963. 

refer 

estevão bassi, marcelo park, and luciano cesar pont azevedo. therapeut strategi for high- 
dose vasopressor-depend shock. critic care research and practice, 2013, 2013. 

yoshua bengio, patric simard, and paolo frasconi. learn long-term depend with gradient 
descent be difficult. ieee transact on neural networks, 5(2):157–166, 1994. 

D. blei, A. ng, and M. jordan. latent dirichlet allocation. jmlr, 3(5):993–1022, 2003. 

dustin charles, meghan gabriel, and michael F furukawa. adopt of electron health record 
system among u non-feder acut care hospitals: 2008-2012. onc data brief, 9:1–9, 2013. 

zhengp che, sanjay purushotham, kyunghyun cho, david sontag, and yan liu. recurr neu- 
ral network for multivari time seri with miss values. arxiv preprint arxiv:1606.01865, 
2016. 

edward choi, mohammad taha bahadori, and jimeng sun. doctor ai: predict clinic event 
via recurr neural networks. corr, abs/1511.05942, 2015. url http://arxiv.org/ 
abs/1511.05942. 

edward choi, mohammad taha bahadori, jimeng sun, joshua kulas, andi schuetz, and walter 
stewart. retain: An interpret predict model for healthcar use revers time attent 
mechanism. In advanc in neural inform process systems, page 3504–3512, 2016. 

jan K chorowski, dzmitri bahdanau, dmitriy serdyuk, kyunghyun cho, and yoshua bengio. 
attention-bas model for speech recognition. In advanc in neural inform process 
systems, page 577–585, 2015. 

frederick d’aragon, emili P belley-cote, maureen O meade, françoi lauzier, neill KJ ad- 
hikari, matthia briel, manoj lalu, salmaan kanji, pierr asfar, alexi F turgeon, et al. blood 
pressur target for vasopressor therapy: A systemat review. shock, 43(6):530–539, 2015. 

dumitru erhan, yoshua bengio, aaron courville, and pascal vincent. visual higher-lay 
featur of a deep network. technic report, univers of montreal, 2009. 

cristób esteban, oliv staeck, stephan baier, yinchong yang, and volker tresp. predict 
clinic event by combin static and dynam inform use recurr neural networks. In 
healthcar informat (ichi), 2016 ieee intern confer on, page 93–101. ieee, 
2016. 

AS fialho, LA celi, F cismondi, SM vieira, SR reti, JM sousa, SN finkelstein, et al. disease- 
base model to predict fluid respons in intens care units. method inf med, 52(6):494–502, 
2013. 

http://arxiv.org/abs/1511.05942 
http://arxiv.org/abs/1511.05942 


marzyeh ghassemi, tristan naumann, final doshi-velez, nicol brimmer, rohit joshi, anna 
rumshisky, and peter szolovits. unfold physiolog state: mortal model in intens 
care units. In proceed of the 20th acm sigkdd intern confer on knowledg 
discoveri and data mining, page 75–84. acm, 2014. 

marzyeh ghassemi, marco AF pimentel, tristan naumann, thoma brennan, david A clifton, 
peter szolovits, and mengl feng. A multivari timeseri model approach to sever 
of ill assess and forecast in icu with sparse, heterogen clinic data. In proc. 
twenty-ninth aaai conf. on artifici intelligence, 2015. 

marzyeh ghassemi, mike wu, michael hughes, and final doshi-velez. predict intervent 
onset in the icu with switch state space models. In proceed of the amia summit on 
clinic research informat (cri), volum 2017. american medic informat association, 
2017. 

T. griffith and M. steyvers. find scientif topics. In pnas, volum 101, page 5228–5235, 
2004. 

karl moritz hermann, toma kocisky, edward grefenstette, lass espeholt, will kay, mustafa 
suleyman, and phil blunsom. teach machin to read and comprehend. In advanc in 
neural inform process systems, page 1693–1701, 2015. 

sepp hochreit and jürgen schmidhuber. long short-term memory. neural computation, 9(8): 
1735–1780, 1997. 

yang N jamoom E and hing E. office-bas physician electron health record adoption. offic of 
the nation coordin for health inform technology, 2016. 

alistair EW johnson, tom J pollard, Lu shen, li-wei H lehman, mengl feng, mohammad 
ghassemi, benjamin moody, peter szolovits, leo anthoni celi, and roger G mark. mimic-iii, 
a freeli access critic care database. scientif data, 3, 2016. 

rahul G krishnan, uri shalit, and david sontag. deep kalman filters. arxiv preprint 
arxiv:1511.05121, 2015. 

zachari C lipton, david C kale, charl elkan, and randal wetzell. learn to diagnos with 
lstm recurr neural networks. arxiv preprint arxiv:1511.03677, 2015. 

ML malbrain, paul E marik, ine witters, colin cordemans, andrew W kirkpatrick, derek J 
roberts, and niel van regenmortel. fluid overload, de-resuscitation, and outcom in critic 
ill or injur patients: a systemat review with suggest for clinic practice. anaesthesiol 
intens ther, 46(5):361–80, 2014. 

christoph manning, prabhakar raghavan, and hinrich schtze. introduct to inform re- 
trieval. cambridg univers press, 2008. 

marcu müllner, bernhard urbanek, christof havel, heidrun losert, gunnar gamper, and harald 
herkner. vasopressor for shock. the cochran library, 2004. 

gustavo A ospina-tascón, gustavo luiz büchele, and jean-loui vincent. multicenter, random- 
ized, control trial evalu mortal in intens care: doom to fail? critic care 
medicine, 36(4):1311–1322, 2008. 



F. pedregosa, G. varoquaux, A. gramfort, V. michel, B. thirion, O. grisel, M. blondel, P. pretten- 
hofer, R. weiss, V. dubourg, J. vanderplas, A. passos, D. cournapeau, M. brucher, M. perrot, 
and E. duchesnay. scikit-learn: machin learn in python. journal of machin learn 
research, 12:2825–2830, 2011. 

narg razavian, jake marcus, and david sontag. multi-task predict of diseas onset from 
longitudin lab tests. In jmlr (journal of machin learn research): mlhc confer 
proceedings, 2016. 

cátia M salgado, susana M vieira, luı́ F mendonça, stan finkelstein, and joão MC sousa. en- 
sembl fuzzi model in person medicine: applic to vasopressor administration. en- 
gineer applic of artifici intelligence, 49:141–148, 2016. 

martin J tobin. principl and practic of mechan ventilation, 2006. 

jean-loui vincent. critic care-wher have we be and where be we going? critic care, 17 
(suppl 1):s2, 2013. 

mike wu, marzyeh ghassemi, mengl feng, leo A celi, peter szolovits, and final doshi-velez. 
understand vasopressor intervent and weaning: risk predict in a public heterogen 
clinic time seri database. journal of the american medic informat association, page 
ocw138, 2016. 

kelvin xu, jimmi ba, ryan kiros, kyunghyun cho, aaron C courville, ruslan salakhutdinov, 
richard S zemel, and yoshua bengio. show, attend and tell: neural imag caption gener 
with visual attention. In icml, volum 14, page 77–81, 2015. 

karl L yang and martin J tobin. A prospect studi of index predict the outcom of trial of 
wean from mechan ventilation. new england journal of medicine, 324. 

matthew D. zeiler and rob fergus. visual and understand convolut networks. corr, 
abs/1311.2901, 2013. url http://arxiv.org/abs/1311.2901. 

http://arxiv.org/abs/1311.2901 


appendix 

appendix A. dataset statist 

tabl 3: variabl 

static variabl gender age ethnic 
icu admiss type 

vital and lab anion gap bicarbon blood pH 
blood urea nitrogen chlorid creatinin 

diastol blood pressur fraction inspir oxygen glascow coma scale total 
glucos heart rate hematocrit 

hemoglobin inr* lactat 
magnesium mean blood pressur oxygen satur 

partial thromboplastin time phosphat platelet 
potassium prothrombin time respiratori rate 

sodium systol blood pressur temperatur 
weight white blood cell count 

*intern normal ratio of the prothrombin time 

tabl 4: dataset statist 

train test total 
patient 27,318 6,830 34,148 
note 564,652 140,089 703,877 
elect admiss 4,536 1,158 5,694 
urgent admiss 746 188 934 
emerg admiss 22,036 5,484 27,520 
mean age 63.9 64.1 63.9 
black/african american 1,921 512 2,433 
hispanic/latino 702 166 868 
white 19,424 4,786 24,210 
ccu (coronari care unit) 4,156 993 5,149 
csru (cardiac surgeri recovery) 5,625 1,408 7,033 
micu (medic icu) 9,580 2,494 12,074 
sicu (surgic icu) 4,384 1,074 5,458 
tsicu (trauma sicu) 3,573 861 4,434 
femal 11,918 2,924 14,842 
male 15,400 3,906 19,306 
icu mortal 1,741 439 2,180 
in-hospit mortal 2,569 642 3,211 
30 day mortal 2,605 656 3,216 
90 day mortal 2,835 722 3,557 
vasopressor usag 8,347 2,069 10,416 
ventil usag 11,096 2,732 13,828 



appendix B. physiolog word gener 

see figur 7. 

figur 7: convert data from continu timeseri format to discret “physiolog words.” the 
numer valu be first z-score and rounded, and then each z-score be make into it own category. 
On the right, glucos -2 indic the presenc of a glucos valu that be 2 standard deviat 
below the mean. A row contain all zero for a give variabl indic that the valu for that 
variabl be miss at the timestep. 

appendix C. lstm model detail 

lstm perform the follow updat equat for a singl layer, give it previou hidden state 
and the new input: 

ft = σ(wf [ht−1, xt] + bf ) (3) 
it = σ(wi[ht−1, xt] + bi) (4) 

c̃t = tanh(wc[ht−1, xt] + bc) (5) 
ct = ft � ct−1 + it � c̃t (6) 

ot = σ(wo[ht−1, xt] + bo) (7) 
ht = ot � tanh(ct) (8) 

where Wf ,wi,wc,wo ∈ rl1×(l1+v ), bf , bi, bc, bo ∈ rl1 be learn parameters, and ft, it, c̃t, 
ct, ot, ht ∈ rl1 . In these equations, σ stand for an element-wis applic of the sigmoid (logis- 
tic) function, and � be an element-wis product. thi be gener to multipl layer by provid 
ht from the previou layer in place of the input. 

We calcul classif loss use categor cross-entropy, which set the loss for predic- 
tion for N exampl over M class as: 

l(ŷ1 . . . ŷn ) = − 
1 

N 

N∑ 
i=1 

M∑ 
j=1 

yij log ŷij 

where ŷij be the probabl our model predict for exampl i be in class j, and yij be the true 
value. 



appendix D. gener topic 

tabl 5: most probabl word in the topic most import for intervent predictions. 

topic top ten word possibl topic 
topic 1 pt care resp vent respiratori secret remain intub 

abg plan psv b support set cont place chang note 
wean rsbi coars cpap continu peep suction clear extu- 
bat rr mask wean 

respiratori fail- 
ure/infect 

topic 2 famili pt ni care patient dnr stitl dr home daughter support 
team meet wife son comfort note social doctor sw dni 
know time statu hospit contact pt’ work plan lastnam 

discuss of end- 
of-lif care 

topic 3 hr resp gi pt cont gu neuro b cv id note abd soft bp today 
stool social note progress clear remain nurs skin urin 
sat foley npn yellow stabl l 

multipl physio- 
logic chang 

topic 4 pain pt assess respons action plan control continu 
give dilaudid monitor chronic acut morphin iv po prn 
patient pca hr med bp drain cont nausea order relief sbp 
pericardi ass 

assess of 
patient responsive- 
ness 

topic 10 pt intub vent propofol sedat sedat fentanyl peep 
tube vers secret abg wean remain continu ett suc- 
tion plan p increas extub set ac sound min 
cpap sputum respiratori hr ogt 

continu need for 
ventil 

topic 38 ml dl mg pm meq assess icu ul total medic sys- 
tem review puls lab balanc comment code hour rr min 
respiratori rhythm prophylaxi admiss allergi blood 
urin mmhg statu dose 

mani lab test 

topic 48 ed pt patient transfer hospit pain admit deni ad- 
mission day nausea receiv ago present micu show 
vomit past report histori give blood bp old year ar- 
rival know osh diarrhea unit 

emerg ad- 
mission/transf 
patient 


introduct 
background and relat work 
data and preprocess 
data sourc 
data extract and preprocess 
represent of note and vital 
predict task 

method 
long short-term memori network (lstm) 
convolut neural network (cnn) 
experiment set 
evalu 
interpret 
lstm feature-level occlus 
cnn filter/activ visual 


result 
physiolog word improv predict task perform with high class imbal 
feature-level occlus identifi import per-class featur 
convolut filter target short-term trajectori 

conclus 
dataset statist 
physiolog word gener 
lstm model detail 
gener topic 


