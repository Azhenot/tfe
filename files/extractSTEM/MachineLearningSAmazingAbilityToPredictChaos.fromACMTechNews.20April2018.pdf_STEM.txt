






































machin learningâ•ž â•ÿamazingâ•ž abil to predict chao 


machin learning’ ‘amazing’ abil to predict chao 

bynatali wolchoverapril 18, 2018 

chao theori 

In new comput experiments, artificial-intellig algorithm can tell the futur of chaotic systems. 

half a centuri ago, the pioneer of chao theori discov that the “butterfli effect” make long-term predict impossible. even the small perturb to a complex system (like the weather, the economi or just about anyth else) can 
touch off a concaten of event that lead to a dramat diverg future. unabl to pin down the state of these system precis enough to predict how they’ll play out, we live under a veil of uncertainty. 

but now the robot be here to help. 

In a seri of result report in the journal physic review letter and chaos, scientist have use machin learn — the same comput techniqu behind recent success in artifici intellig — to predict the futur evolut of 
chaotic system out to stunningli distant horizons. the approach be be laud by outsid expert a groundbreak and like to find wide application. 

“I find it realli amaz how far into the futur they predict” a system’ chaotic evolution, say herbert jaeger, a professor of comput scienc at jacob univers in bremen, germany. 

the find come from veteran chao theorist edward ott and four collabor at the univers of maryland. they employ a machine-learn algorithm call reservoir comput to “learn” the dynam of an archetyp chaotic system 
call the kuramoto-sivashinski equation. the evolv solut to thi equat behav like a flame front, flicker a it advanc through a combust medium. the equat also describ drift wave in plasma and other phenomena, and 
serf a “a test bed for studi turbul and spatiotempor chaos,” say jaideep pathak, ott’ graduat student and the lead author of the new papers. 

jaideep pathak, michel girvan, brian hunt and edward ott of the univers of maryland, who (along with zhixin lu, now of the univers of pennsylvania) have show that machin learn be a power tool for predict chaos. 

fay levine/univers of maryland 

after train itself on data from the past evolut of the kuramoto-sivashinski equation, the researchers’ reservoir comput could then close predict how the flamelik system would continu to evolv out to eight “lyapunov times” into the 
future, eight time further ahead than previou method allowed, loos speaking. the lyapunov time repres how long it take for two almost-ident state of a chaotic system to exponenti diverge. As such, it typic set the horizon 
of predictability. 

“thi be realli veri good,” holger kantz, a chao theorist at the max planck institut for the physic of complex system in dresden, germany, say of the eight-lyapunov-tim prediction. “the machine-learn techniqu be almost a good a 
know the truth, so to say.” 

the algorithm know noth about the kuramoto-sivashinski equat itself; it onli see data record about the evolv solut to the equation. thi make the machine-learn approach powerful; in mani cases, the equat describ a 
chaotic system aren’t known, crippl dynamicists’ effort to model and predict them. ott and company’ result suggest you don’t need the equat — onli data. “thi paper suggest that one day we might be abl perhap to predict weather 
by machine-learn algorithm and not by sophist model of the atmosphere,” kantz said. 

besid weather forecasting, expert say the machine-learn techniqu could help with monitor cardiac arrhythmia for sign of impend heart attack and monitor neuron fire pattern in the brain for sign of neuron spikes. more 
speculatively, it might also help with predict rogu waves, which endang ships, and possibl even earthquakes. 

ott particularli hope the new tool will prove use for give advanc warn of solar storms, like the one that erupt across 35,000 mile of the sun’ surfac in 1859. that magnet outburst creat aurora boreali visibl all around the 
earth and blew out some telegraph systems, while gener enough voltag to allow other line to oper with their power switch off. If such a solar storm lash the planet unexpectedli today, expert say it would sever damag earth’ 
electron infrastructure. “if you knew the storm be coming, you could just turn off the power and turn it back on later,” ott said. 

he, pathak and their colleagu brian hunt, michel girvan and zhixin Lu (who be now at the univers of pennsylvania) achiev their result by synthes exist tools. six or seven year ago, when the power algorithm know a “deep 
learning” be start to master AI task like imag and speech recognition, they start read up on machin learn and think of clever way to appli it to chaos. they learn of a hand of promis result predat the deep-learn 
revolution. most importantly, in the earli 2000s, jaeger and fellow german chao theorist harald haa make use of a network of randomli connect artifici neuron — which form the “reservoir” in reservoir comput — to learn the 
dynam of three chaotic coevolv variables. after train on the three seri of numbers, the network could predict the futur valu of the three variabl out to an impress distant horizon. however, when there be more than a few 
interact variables, the comput becom imposs unwieldy. ott and hi colleagu need a more effici scheme to make reservoir comput relev for larg chaotic systems, which have huge number of interrel variables. 
everi posit along the front of an advanc flame, for example, have veloc compon in three spatial direct to keep track of. 

It take year to strike upon the straightforward solution. “what we exploit be the local of the interactions” in spatial extend chaotic systems, pathak said. local mean variabl in one place be influenc by variabl at nearbi place 
but not by place far away. “bi use that,” pathak explained, “we can essenti break up the problem into chunks.” that is, you can parallel the problem, use one reservoir of neuron to learn about one patch of a system, anoth reservoir 
to learn about the next patch, and so on, with slight overlap of neighbor domain to account for their interactions. 

parallel allow the reservoir comput approach to handl chaotic system of almost ani size, a long a proportion comput resourc be dedic to the task. 

If we have ignor we should use the machin learn to fill in the gap where the ignor resides. 

edward ott 

ott explain reservoir comput a a three-step procedure. say you want to use it to predict the evolut of a spread fire. first, you measur the height of the flame at five differ point along the flame front, continu to measur the 
height at these point on the front a the flicker flame advanc over a period of time. you feed these data-stream in to randomli chosen artifici neuron in the reservoir. the input data trigger the neuron to fire, trigger connect 
neuron in turn and send a cascad of signal throughout the network. 

the second step be to make the neural network learn the dynam of the evolv flame front from the input data. To do this, a you feed data in, you also monitor the signal strength of sever randomli chosen neuron in the reservoir. 
weight and combin these signal in five differ way produc five number a outputs. the goal be to adjust the weight of the variou signal that go into calcul the output until those output consist match the next set of 
input — the five new height measur a moment late along the flame front. “what you want be that the output should be the input at a slightli late time,” ott explained. 

To learn the correct weights, the algorithm simpli compar each set of outputs, or predict flame height at each of the five points, to the next set of inputs, or actual flame heights, increas or decreas the weight of the variou signal each 
time in whichev way would have make their combin give the correct valu for the five outputs. from one time-step to the next, a the weight be tuned, the predict gradual improve, until the algorithm be consist abl to predict 
the flame’ state one time-step later. 

“in the third step, you actual do the prediction,” ott said. the reservoir, have learn the system’ dynamics, can reveal how it will evolve. the network essenti ask itself what will happen. output be fed back in a the new inputs, whose 
output be fed back in a inputs, and so on, make a project of how the height at the five posit on the flame front will evolve. other reservoir work in parallel predict the evolut of height elsewher in the flame. 

In a plot in their prl paper, which appear in january, the research show that their predict flamelik solut to the kuramoto-sivashinski equat exactli match the true solut out to eight lyapunov time befor chao final wins, 
and the actual and predict state of the system diverge. 

the usual approach to predict a chaotic system be to measur it condit at one moment a accur a possible, use these data to calibr a physic model, and then evolv the model forward. As a ballpark estimate, you’d have to 
measur a typic system’ initi condit 100,000,000 time more accur to predict it futur evolut eight time further ahead. 

the machine-learn techniqu be almost a good a know the truth. 

machin learning’ ‘amazing’ abil to predict chao https://www.quantamagazine.org/machine-learnings-amazing-ability-to-... 

1 sur 2 20-04-18 à 19:16 



holger kantz 

that’ whi machin learn be “a veri use and power approach,” say ulrich parlitz of the max planck institut for dynam and self-organ in göttingen, germany, who, like jaeger, also appli machin learn to low- 
dimension chaotic system in the earli 2000s. “I think it’ not onli work in the exampl they present but be univers in some sens and can be appli to mani process and systems.” In a paper soon to be publish in chaos, parlitz and a 
collabor appli reservoir comput to predict the dynam of “excit media,” such a cardiac tissue. parlitz suspect that deep learning, while be more complic and comput intens than reservoir computing, will also 
work well for tackl chaos, a will other machine-learn algorithms. recently, research at the massachusett institut of technolog and eth zurich achiev similar result a the maryland team use a “long short-term memory” neural 
network, which have recurr loop that enabl it to store temporari inform for a long time. 

sinc the work in their prl paper, ott, pathak, girvan, Lu and other collabor have come closer to a practic implement of their predict technique. In new research accept for public in chaos, they show that improv 
predict of chaotic system like the kuramoto-sivashinski equat becom possibl by hybrid the data-driven, machine-learn approach and tradit model-bas prediction. ott see thi a a more like avenu for improv 
weather predict and similar efforts, sinc we don’t alway have complet high-resolut data or perfect physic models. “what we should do be use the good knowledg that we have where we have it,” he said, “and if we have ignor we 
should use the machin learn to fill in the gap where the ignor resides.” the reservoir’ predict can essenti calibr the models; in the case of the kuramoto-sivashinski equation, accur predict be extend out to 12 
lyapunov times. 

the durat of a lyapunov time vari for differ systems, from millisecond to million of years. (it’ a few day in the case of the weather.) the shorter it is, the touchier or more prone to the butterfli effect a system is, with similar state 
depart more rapidli for dispar futures. chaotic system be everywher in nature, go haywir more or less quickly. yet strangely, chao itself be hard to pin down. “it’ a term that most peopl in dynam system use, but they kind of 
hold their nose while use it,” say ami wilkinson, a professor of mathemat at the univers of chicago. “you feel a bit cheesi for say someth be chaotic,” she said, becaus it grab people’ attent while have no agreed-upon 
mathemat definit or necessari and suffici conditions. “there be no easi concept,” kantz agreed. In some cases, tune a singl paramet of a system can make it go from chaotic to stabl or vice versa. 

wilkinson and kantz both defin chao in term of stretch and folding, much like the repeat stretch and fold of dough in the make of puff pastries. each patch of dough stretch horizont under the roll pin, separ 
exponenti quickli in two spatial directions. then the dough be fold and flattened, compress nearbi patch in the vertic direction. the weather, wildfires, the stormi surfac of the sun and all other chaotic system act just thi way, 
kantz said. “in order to have thi exponenti diverg of trajectori you need thi stretching, and in order not to run away to infin you need some folding,” where fold come from nonlinear relationship between variabl in the systems. 

the stretch and compress in the differ dimens correspond to a system’ posit and neg “lyapunov exponents,” respectively. In anoth recent paper in chaos, the maryland team report that their reservoir comput could 
success learn the valu of these character expon from data about a system’ evolution. exactli whi reservoir comput be so good at learn the dynam of chaotic system be not yet well understood, beyond the idea that the 
comput tune it own formula in respons to data until the formula replic the system’ dynamics. the techniqu work so well, in fact, that ott and some of the other maryland research now intend to use chao theori a a way to good 
understand the intern machin of neural networks. 

machin learning’ ‘amazing’ abil to predict chao https://www.quantamagazine.org/machine-learnings-amazing-ability-to-... 

2 sur 2 20-04-18 à 19:16 


