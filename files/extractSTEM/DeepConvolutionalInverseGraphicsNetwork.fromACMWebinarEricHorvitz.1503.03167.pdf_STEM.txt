


















































deep convolut invers graphic network 

teja D. kulkarni*1, will whitney*2, pushmeet kohli3, joshua B. tenenbaum4 
1,2,4comput scienc and artifici intellig laboratory, mit 

1,4brain and cognit sciences, mit 
3microsoft research cambridge, UK 

1tejask@mit.edu 2wwhitney@mit.edu 3pkohli@microsoft.com 4jbt@mit.edu 
* first two author contribut equal to thi work. 

abstract 

thi paper present the deep convolut invers graphic network (dc-ign), 
a model that learn an interpret represent of images. thi represent 
be disentangl with respect to transform such a out-of-plan rotat and 
light variations. the dc-ign model be compos of multipl layer of convo- 
lution and de-convolut oper and be train use the stochast gradient 
variat bay (sgvb) algorithm [11]. We propos a train procedur to 
encourag neuron in the graphic code layer to repres a specif transforma- 
tion (e.g. pose or light). given a singl input image, our model can gener new 
imag of the same object with variat in pose and lighting. We present qual- 
it and quantit result of the model’ efficaci at learn a 3D render 
engine. 

1 introduct 

deep learn have lead to remark breakthrough in automat learn hierarch repre- 
sentat from images. model such a convolut neural network (cnns) [14], restrict 
boltzmann machine-bas gener model [8, 22], and auto-encod [2, 26] have be success- 
fulli appli to produc multipl layer of increasingli abstract visual representations. however, 
there be rel littl work on character the optim represent of the data. while cohen 
et al. [4] have consid thi problem by propos a theoret framework to learn irreduc 
represent have both invari and equivariances, come up with the best represent 
for ani give task be an open question. 

variou work [3, 4, 7] have be do on the theori and practic of represent learning, and from 
thi work a consist set of desideratum for represent have emerged: invariance, meaning 
of representations, abstraction, and disentanglement. In particular, bengio et al. [3] propos that a 
disentangl represent be one for which chang in the encod data be spars over real-world 
transformations; that is, chang in onli a few latent at a time should be abl to repres sequenc 
which be like to happen in the real world. 

the “vision a invers graphics” model suggest a represent for imag which provid these 
features. comput graphic consist of a function to go from compact descript of scene (the 
graphic code) to images, and thi graphic code be typic disentangl to allow for render 
scene with fine-grain control over transform such a object location, pose, lighting, texture, 
and shape. thi encod be design to easili and interpret repres sequenc of real data 
so that common transform may be compactli repres in softwar code; thi criterion be 
almost ident to that of bengio et al., and graphic code conveni align with the properti 
of an ideal representation. 

1 

ar 
X 

iv 
:1 

50 
3. 

03 
16 

7v 
4 

[ 
c 

.C 
V 

] 
2 

2 
Ju 

n 
20 

15 



observ 
imag 

filter = 96 
kernel size (ks) = 5 

150x150 

convolut + pool 

graphic code 

x 

q(zi|x) 

filter = 64 
KS = 5 

filter = 32 
KS = 5 

7200pose 
light 

shape 

.... 
filter = 32 

KS = 7 
filter = 64 

KS = 7 
filter = 96 

KS = 7 

P (x|z) 

encod 
(de-rendering) 

decod 
(renderer) 

unpool (nearest neighbor) + 
convolut 

{µ200,⌃200} 

figur 1: model architecture: deep convolut invers graphic network (dc-ign) have an 
encod and a decoder. We follow the variat autoencod [11] architectur with variations. the 
encod consist of sever layer of convolut follow by max-pool and the decod have 
sever layer of unpool (upsampl use near neighbors) follow by convolution. (a) dur- 
ing training, data x be pass through the encod to produc the posterior approxim q(zi|x), 
where zi consist of scene latent variabl such a pose, light, textur or shape. In order to learn 
paramet in dc-ign, gradient be back-propag use stochast gradient descent use the 
follow variat object function: −log(p (x|zi)) + kl(q(zi|x)||p (zi)) for everi zi. We can 
forc dc-ign to learn a disentangl represent by show mini-batch with a set of inact 
and activ transform (e.g. face rotating, light sweep in some direct etc). (b) dure test, 
data x can be pass through the encod to get latent zi. imag can be re-rend to differ 
viewpoints, light conditions, shape variat etc by just manipul the appropri graphic 
code group (zi), which be how one would manipul an off-the-shelf 3D graphic engine. 

recent work in invers graphic [10, 17, 16, 12] follow a gener strategi of defin a probabilis- 
tic or determinist model with latent parameters, then use an infer or optim algorithm 
to find the most appropri set of latent paramet give the observations. recently, tieleman et 
al. [24] move beyond thi two-stag pipelin by use a gener encod network and a domain- 
specif decod network to approxim a 2D render function. however, none of these ap- 
proach have be show to automat produc a semantically-interpret graphic code and 
to learn a 3D render engin to reproduc images. 

In thi paper, we present an approach for learn interpret graphic code for complex trans- 
format such a out-of-plan rotat and light variations. given a set of images, we use 
a hybrid encoder-decod model to learn a represent that be disentangl with respect to var- 
iou transform such a object out-of-plan rotat and light variations. To achiev this, 
we employ a deep direct graphic model with mani layer of convolut and de-convolut 
oper that be train use the stochast gradient variat bay (sgvb) algorithm [11]. 

We propos a train procedur to encourag each group of neuron in the graphic code layer to 
distinctli repres a specif transformation. To learn a disentangl representation, we train use 
data where each mini-batch have a set of activ and inact transformations, but we do not provid 
target valu a in supervis learning; the object function remain reconstruct quality. for 
example, a nod face would have the 3D elev transform activ but it shape, textur 
and other affin transform would be inactive. We exploit thi type of train data to forc 
chosen neuron in the graphic code layer to specif repres activ transformations, therebi 
automat creat a disentangl representation. given a singl face image, our model can re- 
gener the input imag with a differ pose and lighting. We present qualit and quantit 
result of the model’ efficaci at learn a 3D render engine. 

2 



2 relat work 

As mention before, a number of gener model have be propos in the literatur to obtain 
abstract visual representations. unlik most rbm-base model [8, 22, 15], our approach be train 
use back-propag with object function consist of data reconstruct and the variat 
bound. 

rel recently, kingma et al. [11] propos the sgvb algorithm to learn gener model 
with continu latent variables. In thi work, a feed-forward neural network (encoder) be use to 
approxim the posterior distribut and a decod network serf to enabl stochast reconstruc- 
tion of observations. In order to handl fine-grain geometri of faces, we work with rel 
larg scale imag (150 × 150 pixels). our approach extend and appli the sgvb algorithm to 
jointli train and util mani layer of convolut and de-convolut oper for the encod and 
decod network respectively. the decod network be a function that transform a compact graphic 
code ( 200 dimensions) to a 150× 150 image. We propos use unpool (nearest neighbor sam- 
pling) follow by convolut to handl the massiv increas in dimension with a manag 
number of parameters. 

recently, [6] propos use cnn to gener imag give object-specif paramet in a super- 
vise setting. As their approach requir ground-truth label for the graphic code layer, it cannot be 
directli appli to imag interpret tasks. our work be similar to ranzato et al. [21], whose work 
be amongst the first to use a gener encoder-decod architectur for featur learning. however, 
in comparison to our propos their model be train layer-wise, the intermedi represent 
be not disentangl like a graphic code, and their approach do not use the variat auto- 
encod loss to approxim the posterior distribution. our work be also similar in spirit to [23], but 
in comparison our model do not assum a lambertian reflect model and implicitli construct 
the 3D representations. anoth piec of relat work be desjardin et al. [5], who use a spike and 
slab prior to factor represent in a gener deep network. 

In comparison to exist approaches, it be import to note that our encod network produc the 
interpret and disentangl represent necessari to learn a meaning 3D graphic engine. 
A number of inverse-graph inspir method have recent be propos in the literatur [10, 
17, 16]. however, most such method reli on hand-craft render engines. the except to 
thi be work by hinton et al. [9] and tieleman [24] on transform autoencod which use a 
domain-specif decod to reconstruct input images. our work be similar in spirit to these work but 
have some key differences: (a) It us a veri gener convolut architectur in the encod and 
decod network to enabl effici learn on larg dataset and imag sizes; (b) it can handl 
singl static frame a oppos to pair of imag requir in [9]; and (c) it be generative. 

3 model 

As show in figur 1, the basic structur of the deep convolut invers graphic network 
(dc-ign) consist of two parts: an encod network which captur distribut over graphic 
code Z give data x and a decod network which learn a condit distribut to produc 
an approxim x̂ give Z. Z can be a disentangl represent contain a factor set of 
latent variabl zi ∈ Z such a pose, light and shape. thi be import in learn a meaning 
approxim of a 3D graphic engin and help teas apart the gener capabl of the 
model with respect to differ type of transformations. 

let u denot the encod output of dc-ign to be ye = encoder(x). the encod output be use to 
parametr the variat approxim q(zi|ye), where Q be chosen to be a multivari normal 
distribution. there be two reason for use thi parametrization: (1) gradient of sampl with 
respect to paramet θ of Q can be easili obtain use the reparametr trick propos in 
[11], and (2) variou statist shape model train on 3D scanner data such a face have the same 
multivari normal latent distribut [20]. given that model paramet We connect ye and zi, the 
distribut paramet θ = (µzi ,σzi) and latent Z can then be express as: 

µzi = We ∗ ye (1) 
σzi = diag(exp(w ∗ ye)) (2) 
∀i, zi ∼ N (µzi ,σzi) (3) 

3 



𝜙1 
𝛼1 

𝛼 

𝜙L 
1 

𝜙L 

z[4,n]z = z3z2z1 

𝜙correspond to 

output 

first sampl in batch x1 

from encod to encod 

intrins properti (shape, texture, etc) 

same a output for x1 

z[4,n]z3z2z1 

late sampl in batch xi z[4,n]z3z2z1 

uniqu for each 
xi in batch 

zero error signal 
for clamp output 

zero error signal 
for clamp output 

error signal 
from decod 

∇zki = z 
k 
i - mean z 

k 

backpropag 

z[4,n]z3z2z1 

z[4,n]z3z2z1 

backpropag with 
invari target 

z[4,n]z3z2z1 

k ∈ batch 

k ∈ batch 

caption: train on a minibatch in which onli 𝜙, the azimuth angl of the face, 
changes. 
dure the forward step, the output from each compon z_k != z_1 of the 
encod be forc to be the same for each sampl in the batch. thi reflect the fact 
that the gener variabl of the imag which correspond to the desir valu of 
these latent be unchang throughout the batch. By hold these output 
constant throughout the batch, z_1 be forc to explain all the varianc within the 
batch, i.e. the full rang of chang to the imag caus by chang 𝜙. 

dure the backward step, backpropag of gradient happen onli through the latent 
z_1, with gradient for z_k != z_1 set to zero. thi correspond with the clamp 
output from those latent throughout the batch. 

caption: In order to directli enforc invari of the latent correspond to 
properti of the imag which do not chang within a give batch, we calcul 
gradient for the z_k != z_1 which move them toward the mean of each 
invari latent over the batch. thi be equival to regular the 
latent z_{[2,n]} by the L2 norm of (zk - mean zk). 

figur 2: structur of the represent vector. φ be the azimuth of the face, α be the elev of 
the face with respect to the camera, and φL be the azimuth of the light source. 

We present a novel train procedur which allow network to be train to have disentangl and 
interpret representations. 

3.1 train with specif transform 

the main goal of thi work be to learn a represent of the data which consist of disentangl and 
semant interpret latent variables. We would like onli a small subset of the latent variabl 
to chang for sequenc of input correspond to real-world events. 

one natur choic of target represent for inform about scene be that alreadi design for 
use in graphic engines. If we can deconstruct a face imag by split it into variabl for pose, 
light, and shape, we can trivial repres the same transform that these variabl be use for 
in graphic applications. figur 2 depict the represent which we will attempt to learn. 

To achiev thi goal, we perform a train procedur which directli target thi definit of disen- 
tanglement. We organ our data into mini-batch correspond to chang in onli a singl scene 
variabl (azimuth angle, elev angle, azimuth angl of the light source); these be transforma- 
tion which might occur in the real world. We will term these the extrins variables, and they be 
repres by the compon z1,2,3 of the encoding. 

We also gener mini-batch in which the three extrins scene variabl be held fix but all 
other properti of the face change. that is, these batch consist of mani differ face under the 
same view condit and pose. these intrins properti of the model, which describ identity, 
shape, expression, etc., be repres by the remaind of the latent variabl z[4,200]. these mini- 
batch vari intrins properti be interspers stochast with those vari the extrins 
properties. 

We train thi represent use sgvb, but we make some key adjust to the output of the 
encod and the gradient which train it. the procedur (figur 3) be a follows. 

1. select at random a latent variabl ztrain which we wish to correspond to one of {azimuth 
angle, elev angle, azimuth of light source, intrins properties}. 

2. select at random a mini-batch in which that onli that variabl changes. 

3. show the network each exampl in the minibatch and captur it latent represent for 
that exampl zk. 

4. calcul the averag of those represent vector over the entir batch. 

5. befor put the encoder’ output into the decoder, replac the valu zi 6= ztrain with 
their averag over the entir batch. these output be “clamped”. 

6. calcul reconstruct error and backpropag a per sgvb in the decoder. 

7. replac the gradient for the latent zi 6= ztrain (the clamp neurons) with their differ 
from the mean (see section 3.2). the gradient at ztrain be pass through unchanged. 

8. continu backpropag through the encod use the modifi gradient. 

sinc the intrins represent be much higher-dimension than the extrins ones, it requir 
more training. accordingli we select the type of batch to use in a ratio of about 1:1:1:10, az- 
imuth:elevation:lighting:intrinsic; we arriv at thi ratio after extens testing, and it work well 
for both of our datasets. 

4 



forward backward 

encod 

decod 

out = mean zk 
k ∈ batchi i 

grad = zk mean zk 
k ∈ batchi i iz[4,n]z3z2z1 

out1 = z1 

grad1 = ∇z1 

∇out1 

encod 

decod 

clamp 

unclamp 

figur 3: train on a minibatch in which onli φ, the azimuth angl of the face, changes. 
dure the forward step, the output from each compon zi 6= z1 of the encod be alter to be the 
same for each sampl in the batch. thi reflect the fact that the gener variabl of the imag 
(e.g. the ident of the face) which correspond to the desir valu of these latent be unchang 
throughout the batch. By hold these output constant throughout the batch, the singl neuron z1 be 
forc to explain all the varianc within the batch, i.e. the full rang of chang to the imag caus 
by chang φ. dure the backward step z1 be the onli neuron which receiv a gradient signal from 
the attempt reconstruction, and all zi 6= z1 receiv a signal which nudg them to be closer to their 
respect averag over the batch. dure the complet train process, after thi batch, anoth 
batch be select at random; it likewis contain variat of onli one of φ, α, φl, intrinsic; all 
neuron which do not correspond to the select latent be clamped; and the train proceeds. 

(a) 

origin reconstuct pose (elevation) vari 

(b) 

origin reconstuct pose (azimuth) vari 

figur 4: manipul pose variables: qualit result show the gener capabl 
of the learn dc-ign decod to rerend a singl input imag with differ pose directions. (a) 
We chang the latent zelev smoothli from -15 to 15, leav all 199 other latent unchanged. 
(b) We chang the latent zazimuth smoothli from -15 to 15, leav all 199 other latent unchanged. 

thi train procedur work to train both the encod and decod to repres certain properti 
of the data in a specif neuron. By clamp the output of all but one of the neurons, we forc the 
decod to recreat all the variat in that batch use onli the chang in that one neuron’ value. 
By clamp the gradients, we train the encod to put all the inform about the variat in the 
batch into one output neuron. 

thi train method lead to network whose latent variabl have a strong equivari with the 
correspond gener parameters, a show in figur 6. thi allow the valu of the true gener- 
ate paramet (e.g. the true angl of the face) to be trivial extract from the encoder. 

5 



(a) 

origin reconstuct light direct vari 

(b) 

figur 5: (a) manipul light variables: qualit result show the gener capabil- 
iti of the learnt dc-ign decod to render origin static imag with differ light directions. the 
latent neuron zlight be chang to random valu but all other latent be clamped. (b) entangl 
versu disentangl representations. top: origin reconstruct (left) and transform (right) 
use a normally-train network. bottom: the same transform use the dc-ign. 

3.2 invari target 

By train with onli one transform at a time, we be encourag certain neuron to contain 
specif information; thi be equivariance. but we also wish to explicitli discourag them from 
have other information; that is, we want them to be invari to other transformations. sinc our 
mini-batch of train data consist of onli one transform per batch, then thi goal correspond 
to have all but one of the output neuron of the encod give the same output for everi imag in 
the batch. 

To encourag thi properti of the dc-ign, we train all the neuron which correspond to the inact 
transform with an error gradient equal to their differ from the mean. It be simplest to think 
about thi gradient a act on the set of subvector zinact from the encod for each input in 
the batch. each of these zinactive’ will be point to a close-togeth but not ident point in a 
high-dimension space; the invari train signal will push them all closer together. We don’t 
care where they are; the network can repres the face show in thi batch howev it likes. We 
onli care that the network alway repres it a still be the same face, no matter which way it’ 
facing. thi regular forc need to be scale to be much small than the true train signal, 
otherwis it can overwhelm the reconstruct goal. empirically, a factor of 1/100 work well. 

4 experi 

We train our model on about 12,000 batch of face gener from a 3D face model obtain 
from paysan et al. [20], where each batch consist of 20 face with random variat on face 
ident variabl (shape/texture), pose, or lighting. We use the rmsprop [25] learn algorithm 
dure train and set the meta learn rate to be equal to 0.0005, the momentum decay to be 0.1 
and weight decay to be 0.01. 

To ensur that these techniqu work on other type of data, we also train network to perform 
reconstruct on imag of wide vari 3D chair from mani perspect deriv from the pascal 
visual object class dataset a extract by aubri et al. [18, 1]. thi task test the abil of the 
dc-ign to learn a render function for a dataset with high variat between the element of the 
set; the chair vari from offic chair to wicker to modern designs, and viewpoint span 360 degre 
and two elevations. these network be train with the same method and paramet a the one 
above. 

6 



(a) 
2.0 1.5 1.0 0.5 0.0 0.5 1.0 1.5 2.0 

ground truth 
30 

20 

10 

0 

10 

20 

30 

In 
fe 

rr 
ed 

pose (azimuth) 

(b) 
0.4 0.2 0.0 0.2 0.4 

ground truth 
20 

15 

10 

5 

0 

5 

10 

15 

20 

In 
fe 

rr 
ed 

pose (elevation) 

(c) 
100 50 0 50 100 

ground truth 
15 

10 

5 

0 

5 

10 

15 

In 
fe 

rr 
ed 

light 

figur 6: gener of decod to render imag in novel viewpoint and light condi- 
tions: We gener sever dataset by vari light, azimuth and elevation, and test the invari- 
anc properti of dc-ign’ represent Z. We show quantit perform on three network 
configur a describ in section 4.1. (a,b,c) all dc-ign encod network reason predict 
transform from static test images. interestingly, a see in (a), the encod network seem to 
have learnt a switch node to separ process azimuth on left and right profil side of the face. 

4.1 3D face dataset 

the decod network learn an approxim render engin a show in figur (4,5). given a 
static test image, the encod network produc the latent Z depict scene variabl such a light, 
pose, shape etc. similar to an off-the-shelf render engine, we can independ control these to 
gener new imag with the decoder. for example, a show in figur 5, give the origin test 
image, we can vari the light of an imag by keep all the other latent constant and vari 
zlight. It be perhap surpris that the fully-train decod network be abl to function a a 3D 
render engine. 

We also quantit illustr the network’ abil to repres pose and light on a smooth linear 
manifold a show in figur 6, which directli demonstr our train algorithm’ abil to disen- 
tangl complex transformations. In these plots, the infer and ground-truth transform valu 
be plot for a random subset of the test set. interestingly, a show in figur 6(a), the encod 
network’ represent of azimuth have a discontinu at 0◦ (face straight forward). 

4.1.1 comparison with entangl represent 

To explor how much of a differ the dc-ign train procedur makes, we compar the novel- 
view reconstruct perform of network with entangl represent (baseline) versu disen- 
tangl represent (dc-ign). the baselin network with entangl represent be ident 
in everi way to the dc-ign, but be train with sgvb without use the train procedur we 
propos in thi paper. As in figur 4, we feed each network a singl input image, then attempt to use 
the decod to re-rend thi imag at differ azimuth angles. To do this, we first must figur out 
which latent of the entangl represent most close correspond to the azimuth. thi we do 
rather simply. first, we encod all imag in an azimuth-vari batch use the baseline’ encoder. 
then we calcul the varianc of each of the latent over thi batch. the latent with the larg 
varianc be then the one most close associ with the azimuth of the face, and we will call it 
zazimuth. onc that be found, the latent zazimuth be vari for both the model to render a novel 
view of the face give a singl imag of that face. figur 5 show that explicit disentangl be 
critic for novel-view reconstruction. 

4.2 chair dataset 

We perform a similar set of experi on the 3D chair dataset describ above. thi dataset 
contain still imag render from 3D cad model of 1357 differ chairs, each model skin 
with the photograph textur of the real chair. each of these model be render in 60 differ 
poses; at each of two elevations, there be 30 imag take from 360 degre around the model. We 
use approxim 1200 of these chair in the train set and the remain 150 in the test set; a 
such, the network have never see the chair in the test set from ani angle, so the test explor the 
network abil to gener to arbitrari chairs. We resiz the imag to 150 × 150 pixel and 
make them grayscal to match our face dataset. 

7 



(a) 

(b) 

figur 7: manipul rotation: each row be gener by encod the input imag (leftmost) 
with the encoder, then chang the valu of a singl latent and put thi modifi encod 
through the decoder. the network have never see these chair befor at ani orientation. (a) some 
posit examples. note that the dc-ign be make a conjectur about ani compon of the chair 
it cannot see; in particular, it guess that the chair in the top row have arms, becaus it can’t see that 
it doesn’t. (b) exampl in which the network extrapol to new viewpoint less accurately. 

We train these network with the azimuth (flat rotation) of the chair a a disentangl variabl 
repres by a singl node z1; all other variat between imag be undifferenti and repre- 
sent by z[2,200]. the dc-ign network succeed in achiev a mean-squar error (mse) of 
reconstruct of 2.7722× 10−4 on the test set. each imag have grayscal valu in the rang [0, 1] 
and be 150× 150 pixels. 
In figur 7 we have includ exampl of the network abil to re-rend previously-unseen chair 
at differ angl give a singl image. for some chair it be abl to render fairli smooth transitions, 
show the chair at mani intermedi poses, while for other it seem to onli captur a sort of 
keyfram representation, onli have distinct output for a few angles. interestingly, the task of 
rotat a chair see onli from one angl requir specul about unseen components; the chair 
might have arms, or not; a curv seat or a flat one; etc. 

5 discuss 

We have show that it be possibl to train a deep convolut invers graphic network with in- 
terpret graphic code layer represent from static images. By util a deep convolut 
and de-convolut architectur within a variat autoencod formulation, our model can be 
train end-to-end use back-propag on the stochast variat object function [11]. We 
propos a train procedur to forc the network to learn disentangl and interpret repre- 
sentations. use 3D face analysi a a work example, we have demonstr the invari and 
equivari characterist of the learn representations. 

To scale our approach to handl more complex scenes, it will like be import to experi with 
deeper architectur in order to handl larg number of object categori within a singl network 
architecture. It be also veri appeal to design a spatio-tempor base convolut architectur 
to util motion in order to handl complic object transformations. furthermore, the current 

8 



formul of sgvb be restrict to continu latent variables. however, real-world visual scene 
contain unknown number of object that move in and out of frame. therefore, it might be necessari 
to extend thi formul to handl discret distribut [13] or extend the model to a recurr 
setting. the decod network in our model can also be replac by a domain-specif decod [19] 
for fine-grain model-bas inference. We hope that our work motiv further research into 
automat learn interpret represent use variant of our model. 

acknowledg 

We thank thoma vetter for give u access to the basel face model. T. kulkarni be gracious 
support by the leventh fellowship. We would like to thank ilker yildrim, max kleiman-weiner, 
karthik rajagop and geoffrey hinton for help feedback and discussions. 

refer 
[1] M. aubry, D. maturana, A. efros, B. russell, and J. sivic. see 3d chairs: exemplar part-bas 2d-3d 

align use a larg dataset of cad models. In cvpr, 2014. 

[2] Y. bengio. learn deep architectur for ai. foundat and trend R© in machin learning, 2(1):1– 
127, 2009. 

[3] Y. bengio, A. courville, and P. vincent. represent learning: A review and new perspectives. pattern 
analysi and machin intelligence, ieee transact on, 35(8):1798–1828, 2013. 

[4] T. cohen and M. welling. learn the irreduc represent of commut lie groups. arxiv 
preprint arxiv:1402.4437, 2014. 

[5] G. desjardins, A. courville, and Y. bengio. disentangl factor of variat via gener entangling. 
arxiv preprint arxiv:1210.5474, 2012. 

[6] A. dosovitskiy, J. springenberg, and T. brox. learn to gener chair with convolut neural 
networks. arxiv:1411.5928, 2015. 

[7] I. goodfellow, H. lee, Q. V. le, A. saxe, and A. Y. ng. measur invari in deep networks. In 
advanc in neural inform process systems, page 646–654, 2009. 

[8] G. hinton, S. osindero, and y.-w. teh. A fast learn algorithm for deep belief nets. neural computation, 
18(7):1527–1554, 2006. 

[9] G. E. hinton, A. krizhevsky, and S. D. wang. transform auto-encoders. In artifici neural network 
and machin learning–icann 2011, page 44–51. springer, 2011. 

[10] V. jampani, S. nowozin, M. loper, and P. V. gehler. the inform sampler: A discrimin approach 
to bayesian infer in gener comput vision models. arxiv preprint arxiv:1402.0859, 2014. 

[11] D. P. kingma and M. welling. auto-encod variat bayes. arxiv preprint arxiv:1312.6114, 2013. 

[12] T. D. kulkarni, V. K. mansinghka, P. kohli, and J. B. tenenbaum. invers graphic with probabilist cad 
models. arxiv preprint arxiv:1407.1339, 2014. 

[13] T. D. kulkarni, A. saeedi, and S. gershman. variat particl approximations. arxiv preprint 
arxiv:1402.5715, 2014. 

[14] Y. lecun and Y. bengio. convolut network for images, speech, and time series. the handbook of 
brain theori and neural networks, 3361, 1995. 

[15] H. lee, R. grosse, R. ranganath, and A. Y. ng. convolut deep belief network for scalabl unsuper- 
vise learn of hierarch representations. In proceed of the 26th annual intern confer 
on machin learning, page 609–616. acm, 2009. 

[16] M. M. loper and M. J. black. opendr: An approxim differenti renderer. In comput vision– 
eccv 2014, page 154–169. springer, 2014. 

[17] V. mansinghka, T. D. kulkarni, Y. N. perov, and J. tenenbaum. approxim bayesian imag interpre- 
tation use gener probabilist graphic programs. In advanc in neural inform process 
systems, page 1520–1528, 2013. 

[18] R. mottaghi, X. chen, X. liu, n.-g. cho, s.-w. lee, S. fidler, R. urtasun, and A. yuille. the role of 
context for object detect and semant segment in the wild. In ieee confer on comput 
vision and pattern recognit (cvpr), 2014. 

[19] V. nair, J. susskind, and G. E. hinton. analysis-by-synthesi by learn to invert gener black boxes. 
In artifici neural networks-icann 2008, page 971–981. springer, 2008. 

9 



[20] P. paysan, R. knothe, B. amberg, S. romdhani, and T. vetter. A 3d face model for pose and illumin 
invari face recognition. genova, italy, 2009. ieee. 

[21] M. ranzato, F. J. huang, y.-l. boureau, and Y. lecun. unsupervis learn of invari featur hi- 
erarchi with applic to object recognition. In comput vision and pattern recognition, 2007. 
cvpr’07. ieee confer on, page 1–8. ieee, 2007. 

[22] R. salakhutdinov and G. E. hinton. deep boltzmann machines. In intern confer on artifici 
intellig and statistics, page 448–455, 2009. 

[23] Y. tang, R. salakhutdinov, and G. hinton. deep lambertian networks. arxiv preprint arxiv:1206.6445, 
2012. 

[24] T. tieleman. optim neural network that gener images. phd thesis, univers of toronto, 2014. 

[25] T. tieleman and G. hinton. lectur 6.5 - rmsprop, coursera: neural network for machin learning. 2012. 

[26] P. vincent, H. larochelle, I. lajoie, Y. bengio, and p.-a. manzagol. stack denois autoencoders: 
learn use represent in a deep network with a local denois criterion. the journal of machin 
learn research, 11:3371–3408, 2010. 

10 


1 introduct 
2 relat work 
3 model 
3.1 train with specif transform 
3.2 invari target 

4 experi 
4.1 3D face dataset 
4.1.1 comparison with entangl represent 

4.2 chair dataset 

5 discuss 

