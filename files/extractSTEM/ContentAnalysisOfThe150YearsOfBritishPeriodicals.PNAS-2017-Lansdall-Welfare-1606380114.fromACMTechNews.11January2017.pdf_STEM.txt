


















































PN 
A 

S 
PL 

U 
S 

CO 
M 

PU 
TE 

R 
SC 

IE 
N 

CE 
S 

SO 
CI 

A 
L 

SC 
IE 

N 
CE 

S 

content analysi of 150 year of british period 
thoma lansdall-welfarea, saatviga sudhahara, jame thompsonb, justin lewisc, findmypast newspap teamd,1, 
and nello cristianinia,2 

aintellig system laboratory, univers of bristol, bristol bs8 1ub, unit kingdom; bdepart of history, univers of bristol, bristol bs8 1tb, unit 
kingdom; cschool of journalism, media and cultur studies, univers of cardiff, cardiff cf10 3nb, unit kingdom; and dfindmypast newspap archiv 
limit (www.britishnewspaperarchive.co.uk), dunde dd2 1tp, scotland 

edit by kenneth W. wachter, univers of california, berkeley, ca, and approv novemb 30, 2016 (receiv for review april 21, 2016) 

previou studi have show that it be possibl to detect macro- 
scopic pattern of cultur chang over period of centuri by 
analyz larg textual time series, specif digit books. 
thi method promis to empow scholar with a quantit 
and data-driven tool to studi cultur and society, but it power 
have be limit by the use of data from book and simpl ana- 
lytic base essenti on word counts. thi studi address 
these problem by assembl a vast corpu of region newspa- 
per from the unit kingdom, incorpor veri fine-grain 
geograph and tempor inform that be not avail for 
books. the corpu span 150 year and be form by million of 
articles, repres 14% of all british region outlet of the 
period. simpl content analysi of thi corpu allow u to detect 
specif events, like wars, epidemics, coronations, or conclaves, 
with high accuracy, wherea the use of more refin techniqu 
from artifici intellig enabl u to move beyond count 
word by detect refer to name entities. these tech- 
niqu allow u to observ both a systemat underrepresenta- 
tion and a steadi increas of woman in the news dure the 20th 
centuri and the chang of geograph focu for variou concepts. 
We also estim the date when electr overtook steam and 
train overtook hors a a mean of transportation, both around 
the year 1900, along with observ other cultur transitions. We 
believ that these data-driven approach can complement the 
tradit method of close read in detect trend of conti- 
nuiti and chang in histor corpora. 

artifici intellig | digit human | comput histori | 
data scienc | culturom 

the idea of exploit larg textual corpu to detect macro-scop and long-term cultur trend have be discuss for 
mani year (1, 2), promis to empow historian and other 
human scholar with a tool for the studi of cultur and soci- 
ety. mani studi have be publish over the past few year 
(3–6), some go a far a to propos a quantit and data- 
driven approach to the studi of cultur chang and continuity, 
owe a much to the method of modern genom a to those 
of the humanities. 

A semin studi of 5 million english-languag book pub- 
lish over the arc of 200 year (1) show the potenti of thi 
approach, gener a debat about the possibl advantag and 
drawback of thi new methodology. the studi make variou 
claim about both the evolut of languag and that of cultur 
(for example, measur the time requir by variou technolo- 
gy to becom establish or the durat of celebr for vari- 
ou categori of peopl a well a studi chang in english 
grammar). however, one of the key critic be that it be 
base almost entir on count words, ignor both seman- 
tic and context (7). addit critic be that it do not cover 
period (8) and that the data sampl might have be biased, 
repres onli those book found in the librari (9). 

A late studi (10) discuss the possibl benefit of mine 
corpu of digit newspap and propos the use of “dis- 
tant reading” techniqu (11) in thi domain, but it be sever 
constrain by the tool that it used, which onli allow for the 

queri of individu words. It conclud by advoc for the 
use of big data method for newspap analysi and propos 
specif criterion for the design of such experiments. 

although the “culturomics” studi (1) be base on the idea 
of introduc quantit and measur aspect to the studi 
of cultur change, use high-throughput method for data 
acquisit and analysis, addit develop in the field of 
natur languag process (nlp) now allow for more sophis- 
ticat inform to be extract from text, allow previou 
critic to be overcom in mani way (12, 13). 

In thi study, follow on from a seri of articl pioneer- 
ing the use of high-throughput data for the studi of cultur 
(1, 4–6, 14, 15) and draw on the debat that follow their 
public (7–9), we assembl a massiv dataset of newspa- 
per and period aim at verifi or contextu some 
of the find of the studi on book (1) use uniqu and 
more refin method and incorpor into the interpret 
of result variou valuabl lesson learn from the subsequ 
debate. 

We first present n-gram trend a use in the culturom 
paper befor move beyond simpl word count method 
to incorpor more semant inform about name enti- 
tie and their properties. the corpu that we assembl be 
form by 28.6 billion word from 120 region or local news 
outlet contain in 35.9 million articl that be publish 
in the unit kingdom between 1800 and 1950. thi sam- 
ple repres approxim 14% of all region newspap 
publish over that period in the unit kingdom and cover 

signific 

the use of larg dataset have revolution the natur sci- 
enc and be wide believ to have the potenti to do so 
with the social and human sciences. mani digit effort 
be underway, but the high-throughput method of data pro- 
duction have not yet lead to a compar output in analysis. 
A notabl except have be the previou statist analy- 
si of the content of histor books, which start a debat 
about the limit of use big data in thi context. thi 
studi move the debat forward use a larg corpu of his- 
toric british newspap and tool from artifici intellig 
to extract macroscop trend in histori and culture, includ- 
ing gender bias, geograph focus, technology, and politics, 
along with accur date for specif events. 

author contributions: t.l.-w., j.t., and n.c. design research; t.l.-w., s.s., and n.c. per- 
form research; t.l.-w., s.s., j.t., j.l., and n.c. analyz data; f.n.t. suppli the data 
and the descript of it generation; and t.l.-w., j.t., j.l., and n.c. write the paper. 

conflict of interest statement: f.n.t. be a team within the compani findmypast. it main 
role have be to provid part of the data and rel text. 

thi articl be a pna direct submission. 

freeli avail onlin through the pna open access option. 

data deposition: the data report in thi paper be avail onlin at data.bris.ac.uk/ 
data/dataset/dobuvuu00mh51q773bo8ybkdz. 
1the findmypast newspap team: ami gregor, boon low, tobi atkin-wright, malcolm 

dobson, and richard callison. 
2to whom correspond should be addressed. email: nello.cristianini@bristol.ac.uk. 

www.pnas.org/cgi/doi/10.1073/pnas.1606380114 pna earli edit | 1 of 9 

http://www.britishnewspaperarchive.co.uk 
http://data.bris.ac.uk/data/dataset/dobuvuu00mh51q773bo8ybkdz 
http://data.bris.ac.uk/data/dataset/dobuvuu00mh51q773bo8ybkdz 
mailto:nello.cristianini@bristol.ac.uk 
http://www.pnas.org/cgi/doi/10.1073/pnas.1606380114 
http://crossmark.crossref.org/dialog/?doi=10.1073/pnas.1606380114&domain=pdf&date_stamp=2017-01-04 


newspap obtain from all of the main geograph region 
in the unit kingdom. We make variou effort to ensur that 
the data sampl be a repres a possibl of unit king- 
dom local newspapers, cover all main regions, time periods, 
and key outlets. 

To keep thi studi focu on the trend that we extract and 
not on the engin techniqu that be used, we have onli 
make use of method that have alreadi be deploy in other 
publish studi and can be consid stable. draw on the 
subject expertis of the multidisciplinari research team, knowl- 
edg of the historical, media, and sociolog context be use 
to inform each stage of the studi design: from the care selec- 
tion of newspap and the select of keyword to the interro- 
gation and interpret of the results. where appropriate, the 
data queri be sampl and read close to address potenti 
nois in the optic charact recognit (ocr) text or ensur 
that concept be be accur tracked. 

the studi be intent wide-ranging, enabl a broad 
assess of the potenti of the approach. given space con- 
straints, the discuss of histor context be render neces- 
sarili concise. contextu awar was, however, central to 
make sens of the findings. To give an example, analyz the 
term “suffragette”—a word popular by a specif segment 
of the medium a a politic exercis in “catchword” creation— 
can onli be understood in relat to both the histori of medium 
and the histori of the struggl for vote right of woman in 
britain. 

our hope be to concentr the attent of the reader on the 
main import point that we be tri to make: it be possibl 
today to detect long-term trend and chang in histori by mean 
of big data analysi of the vast corpu that be becom avail- 
able. these find can includ studi about politics, technol- 
ogy, the economy, values, gender, and much more. these trend 
and changes, which might otherwis go unnoticed, can be dis- 
cover by machine, enabl a complementari approach with 
closer investig by tradit scholars. 

result 
differ between book and newspapers. A start point for 
our studi be to compar some result for our corpu with those 
for the googl book corpu (1), show the similar and dif- 
ferenc between use a corpu of book and one of newspap 
and highlight that we can find the same trend in our corpu 
but also, that an analysi of newspap may be more sensit to 
certain cultur shifts—not becaus of their closer relation- 
ship to current events—than books. 

use a similar approach, we comput the use frequenc of 
1-gram and n-gram over time, where a 1-gram be a string of 
charact uninterrupt by a space that includ word (“adven- 
turous” and “puppy”), number (“1.215”), and typograph 
error (“wrods”), wherea an n-gram be an n-length sequenc of 
1-grams, such a the phrase “unit kingdom” (a 2-gram) and 
“in the past” (a 3-gram). the use frequenc for an n-gram be 
comput by divid the number of instanc of the n-gram in a 
give year by the total number of word in the corpu that year. 
We restrict n to three and limit our studi to n-gram that 
occur at least 10 time within the corpus. 

We found that the impact of key events, such a coronations, 
conclaves, wars, and epidemics, be much more obviou in our 
corpus, with peak allow u to identifi specif year in which 
event occurred. for the book corpus, the impact of key event 
be much less clear (fig. 1), highlight that region newspa- 
per be much closer than book to the event cover in both 
time and space. fig. 1 help to show the differ between 
the two type of write medium, with newspap offer a 
closer represent of histor shifts, wherea book be more 
reflect in natur and less time-bound (for example, a book’ 
narr might be set in the past). 

fig. 1. comparison between (a, C, E, and G) our corpu of british period- 
ical and (b, D, F, and H) the googl book corpu (1) use n-gram trend 
identifi (A and B) major wars, (C and D) coronations, (E and F) conclaves, 
and (G and H) epidem between 1800 and 1950 in the unit kingdom. 
event be clearli identifi in the period corpus, wherea it be more 
difficult to distinguish exact year of event in the book corpus. 

open-end measurements. We then look at more open-end 
questions, which includ measur of more gener and 
less well-establish relations. We divid our analysi into the 
follow spheres: valu and beliefs, unit kingdom politics, 
technology, economy, social change, and popular culture. again, 
we select topic and keyword in a way to avoid ambigui- 
tie and perform close read of some of the articl identi- 
fie by our analysi to ensur that the keyword repres the 
intend topic. 

In valu and beliefs, we test the hypothesi put forward by 
gibb and cohen (3) of a declin in so-cal “victorian values” 
dure the period under investigation. We find that mention of 
certain key victorian valu (3) be in overal decline, although 
term like “duty,” “courage,” and “endurance” find new impe- 
tu in time of war, wherea other key terms, notabl “thrift” and 
“patience,” do not exhibit a downward trend, qualifi straight- 
forward account of the suppos demis of victorian valu 
(fig. 2A and b). 

In unit kingdom politics, gladston and disra be often 
see a the key polit figur of the 19th century; however, our 
find suggest that gladston be significantli more newswor- 
thi dure the 19th centuri itself than disra (fig. 2c). thi 
find could be partli becaus of gladstone’ great polit 

2 of 9 | www.pnas.org/cgi/doi/10.1073/pnas.1606380114 lansdall-welfar et al. 

http://www.pnas.org/cgi/doi/10.1073/pnas.1606380114 


PN 
A 

S 
PL 

U 
S 

CO 
M 

PU 
TE 

R 
SC 

IE 
N 

CE 
S 

SO 
CI 

A 
L 

SC 
IE 

N 
CE 

S 

fig. 2. values, beliefs, and unit kingdom politics. n-gram trend show- 
ing (A and B) a declin in victorian valu a put forward by gibb and 
cohen (3), (c) that gladston be much more newsworthi than disraeli, 
(d) that liber be more mention than conserv until the 1930s, 
and (E and F) that refer to british ident take off in the 20th 
century. 

longevity, although it be notabl that gladston receiv more 
coverag even dure disraeli’ year a prime minist and be 
a tower figur in press coverag of the period in a way that 
disra be not. 

overall, the conserv and liber parti receiv broadli 
similar level of coverag dure the 19th century, although they 
be both eclips from the 1920 onward by the labour parti 
(fig. 2d). thi chang cannot, of course, be assum to reflect 
level of polit support, but it do suggest that the emerg 
and growth of the labour parti be set the agenda for the 
region and local press from 1920 to 1950 (notabl after the first 
labour parti govern in 1924). 

our find also suggest a veri clear timelin in the emer- 
genc of “britishness” a a popular idea, with the term “british” 
overtak the term “english” at the end of the 19th centuri 
(fig. 2 E and f). thereafter, we see a signific increas in 
the use of the term british in the first half of the 20th cen- 
tury, with dramat increas dure both world wars. the term 
english declin dure the same period (and indeed, suffer 
small dip dure world war 1 and world war 2)—to such an 
extent that the term “scottish” overtak it in the late 1940s, 
suggest that british replac english a a default nation 
identifier. although scholarship suggest that the develop 
of british predat thi rise (16), these data suggest that the 
domin of british in the popular imagin be a 20th 
centuri phenomenon. 

In technology, we track the spread of innov in energy, 
transportation, and communications. In the first area, we observ 
the steadi declin of steam and the constant increas of electric- 
ity, with a cross point in 1898 (fig. 3a). In the area of trans- 
portation, we observ how train overtook hors in popular 
in 1902, well after the dawn of the railway age that begin in the 
1840s, show the cultur signific of horsepow through- 
out the 19th centuri (fig. 3b). 

In the area of communications, we examin the rate of adop- 
tion of the telegraph, telephone, radio, and television, support 
previou find (1) that observ an ever-increas rate of 
uptak of new technolog that culmin with the rapid rise 
of televis (fig. 3c). 

In economy, we find that discuss of the economi a a dis- 
tinct concept and field begin in late victorian times. the declin 
in refer to polit economi and the growth of refer to 
the economi manifest the emerg of a sharper idea of the 
economi a a distinct knowabl entiti with it own featur and 
rhythms, separ from those of polit (fig. 3d). It be impor- 
tant, however, to note that, on closer reading, refer to the 
economi seem to be about the need for savings, which be appar- 
ent in 1922 and 1932. It be the secular trend evid compar 
the economi with polit economi that be suggestive. 

We also find that it be strike that the term panic emerg 
a correspond to volatil downward financi market with- 
out need to involv concern about moral or crime, link- 
ing clearli when inspect under closer read to bank 
crisi with pronounc peak in 1826, 1847, 1857, and 1866 
(fig. 3e). thi conjectur can be further explain and exam- 
ine collect with 19th centuri press and financi histori but 
would be difficult to express without thi complementary, distant- 
read approach. more speculatively, it be notabl that sampl 
region newspap and thus, mitig “london-centric” bias, 
nonetheless, reveal the central of financi market in the citi 
of london to discuss of panic. 

In social change, we observ sharp tempor boundari in 
phenomena, such a the suffragett movement and the period 
of anarchist activity; we observ the peak of unrest that cor- 
respond with well-known period of strike action in 1912 and 
1919, wherea the express revolt correspond with tension in 

fig. 3. technolog and economy. n-gram trend show (a) the steadi 
declin of steam and the rise of electricity, (b) the wan popular of 
hors and the increas in trains, (c) the rate of uptak for differ com- 
munic technologies, (d) “the economy” a a concept begin in 
late victorian time after a declin in “polit economy,” and (e) that the 
four larg peak for “panic” correspond with neg market movement 
link to bank crisi in 1826, 1847, 1857, and 1866. 

lansdall-welfar et al. pna earli edit | 3 of 9 



british colonies, notabl the lower canadian rebellion of 1837– 
1838 and the “indian mutiny” of 1857 (fig. 4a). 

the frequenc of suffragett have a clearli delimit time inter- 
val (1906–1918) (fig. 4b), which correspond with the period from 
the popular of the term in respons to the disrupt of pub- 
lic meet to the achiev of suffrag for many, although not 
all, adult woman in 1918. despit the mani year of polit cam- 
paign that preced it, we see a sharp rise in coverag of the suf- 
fragett (and suffragists) follow the dramat death of emili 
wild davidson, who be trampl to death by the king’ hors 
at ascot. thi sharp rise in coverag is, perhaps, an earli 20th cen- 
turi exampl of the import of a “media event” to a polit 
campaign and it abil to captur the journalist imagination. 

the time interv for anarch be mostli present in the inter- 
val from 1882 to 1920, correspond to the heyday of concern 
over anarchist direct action befor the rise of fascism and bol- 
shevism, wherea slaveri includ the movement for abolition 
and the american civil war (fig. 4c). 

fig. 4. social chang and popular culture. n-gram trend show that (a) 
“unrest” correspond with well-known period of social tension, wherea 
“revolt” correspond with tension in british colonies; (b) the suffragett 
movement fall within a delimit time interval; (c) “slavery” includ the 
movement for abolition and the american civil war, wherea “anarchist” 
correspond to the heyday of concern over anarchist direct action befor 
the rise of fascism and bolshevism; (d) the gender gap in mention of men 
and woman be closing, with woman make advanc dure the two wars; 
(e) the gender gap be also close when measur use the pronoun he and 
she; (f) actors, singers, and dancer begin to increas in the 1890s, rise sig- 
nificantli thereafter, wherea refer to politicians, by contrast, gradu- 
alli declin from the earli 20th century; and (g) footbal be more promin 
than cricket from 1909 on. 

As we might expect, the n-gram “men” be mention more 
often than “women,” and the same be true for the n-gram “he” 
compar with “she,” indic that we be access informa- 
tion about the actual number of men and woman in the news. 
It be interest to note that the rel proport of men and 
woman be not veri differ in today’ news (17). addit anal- 
ysi with more sophist method be report below, support- 
ing thi conclusion. We can also see a slow increas in the men- 
tion of woman and she over the cours of 150 year (fig. 4 D 
and e), suggest a steadi increas in the role of woman in pub- 
lic life over the whole period, with a more dramat rise in the 
conscious of woman a a group in the 20th centuri dure 
the two world wars. In both cases, we measur the slope of the 
line of best fit for the time seri repres the ratio between 
the rel frequenc of the n-gram woman and men a well 
a that for the n-gram she and he, find both to be positive. 

In popular culture, medium scholar have document the 
growth in human interest news (and the proportion declin 
in public affairs), with these data suggest a clear timelin 
for the increas import of popular cultur in news cov- 
erage. for example, we see refer to “actors,” “singers,” 
and “dancers” begin to increas in the 1890s, rise significantli 
thereafter, wherea refer to “politicians,” by contrast, grad- 
ualli declin from the earli 20th centuri (fig. 4f). We see the 
same pattern in the increas coverag of n-gram “football” 
and “cricket,” with footbal more promin than cricket from a 
earli a 1909 (fig. 4g). 

beyond count words. techniqu from nlp allow u to move 
beyond simpli count word frequenc and focu instead on 
the frequenc with which give entiti be mention in the text. 
name entiti includ people, locations, and organizations, and 
refer to them can be form by set of n-grams: generally, 
multipl refer can be use for the same entity. It be possi- 
ble to automat resolv these coreferences, therefor creat- 
ing an autom way to gener multipl n-gram relat to a 
give entity. 

thi step move u closer to the level of concept and seman- 
tic and also allow u to bypass mani of the risk associ 
with the select of keyword (materi and methods). It be fur- 
ther possibl to automat link name entiti with exist 
databas of entiti that have recent becom avail that 
offer an authorit list of people, locations, and organizations. 
these open-sourc list includ yago (18) and dbpedia (19), 
and they allow u to autom the inclus of extern infor- 
mation about differ entiti that be not present in the corpu 
itself, such a the gender and occup of a person or the coor- 
dinat of a location. pars the text in thi way result in the 
extract of 263,813,326 mention to 1,009,848 differ entiti 
in the corpus. 

discov everi time that a person mention within the 
corpu be also present in dbpedia (19) or anoth knowledg 
base often enabl u to map them to an occup type. thi 
procedur allow u to autom the studi (1) of fame for peo- 
ple in differ career over their lifetim (fig. 5a). 

among other things, we confirm their find that politician 
and writer be most like to achiev notorieti within their life- 
times, wherea scientist and mathematician be less like to 
achiev fame; however, we also observ a declin for politician 
and writer in news that be not observ in books, wherea 
time seem to be kinder to scientist and mathematicians. thi 
method have enorm potenti for medium content analysis, 
allow research to do widespread and detail analysi of 
the sourc use in news and explore, for example, the predom- 
inant polit and ideolog affili of the sourc use in 
news reporting. 

We also extract everi singl mention of a person in the cor- 
pu (regardless of whether they be present in extern resources) 

4 of 9 | www.pnas.org/cgi/doi/10.1073/pnas.1606380114 lansdall-welfar et al. 

http://www.pnas.org/cgi/doi/10.1073/pnas.1606380114 


PN 
A 

S 
PL 

U 
S 

CO 
M 

PU 
TE 

R 
SC 

IE 
N 

CE 
S 

SO 
CI 

A 
L 

SC 
IE 

N 
CE 

S 

fig. 5. peopl in history. (a) replic the studi (1) on famou person by occup use all extract entiti associ with a wikipedia entry, 
we found that politician and writer be most like to achiev notorieti within their lifetimes, wherea scientist and mathematician be less like to 
achiev fame but declin less sharply. (b) We comput the probabl that a give refer to a person be to a male or a femal person. We find that, 
although male be more present than femal dure the entir period under investigation, there be a slow but steadi increas of the presenc of woman 
after 1900, although it be difficult to attribut thi to a singl factor at the time. 

and infer gender use the anni plugin of gate, a standard 
tool for nlp (20). thi process give u over 35 million refer- 
enc to peopl with a resolv gender, allow u to calcul 
the overal probabl that a person mention in the news be 
male (or female) and finally, studi how thi probabl chang 
over time (fig. 5b). 

thi result confirms—with high sophistication—th result 
obtain use the n-gram trend (fig. 4 E and f), show 
that woman be consist repres less than men dure 
the entir period under investigation, and it allow u to explor 
the nuanc and charact of variou assumpt make about 
gender. thi more refin approach also show a slow but steadi 
increas of the presenc of woman after 1900. these result can 
be read in combin with analog one for modern news 
(17), show that gender bia within the medium do not seem 
to have chang veri much, with approxim three time a 
mani male a femal in modern newspapers. 

furthermore, revisit the concept that we explor with 
n-gram trends, we compil geograph map for the unit 
kingdom for each of the term display a gradual increas or 
declin (rather than a spike of activity) (fig. 6). We extract all 
locat found in the articl that mention one of the concepts, 
disambigu them again use dbpedia (19), and retriev 
their geograph coordinates. 

We observ that the term british and english be reason 
widespread in use across most of the unit kingdom in 1854. By 
1940, the use of english have dwindled, with british becom the 
default nation identifi (fig. 6a). 

dure 1885, we can see scatter mention of the liber 
parti around the unit kingdom, with a focu on london, 
wherea there be veri littl mention of the yet to be form labour 
party. however, by 1924, thi situat have changed, when the 
labour parti achiev it first minor govern and replac 
the liber parti a the parti mention across the country, 
again with a geograph focu around london (fig. 6b). 

the geograph focu of technolog advanc over time 
be also observed, which we show for the transit from steam 
to electr (fig. 6c) and from hors to train (fig. 6d). for 
steam, we can see that mention dure it high use year 
in 1854 be widespread, with concentr focu around 
major ports. however, the adopt of electr replac steam 
by 1947, with electr be mention particularli in refer- 
enc to london, leeds, and area of the southwest (fig. 6c). 
dure the earli peak of attent to hors in 1823, we see 
that mention be mainli diffus across the countri without 

a distinct pattern, indic of their use in rural commu- 
nities, and there be onli the odd mention of train, which on 
closer reading, be reveal to be gener in a differ con- 
text (refer to anim train or processions). By 1948, the 
declin of hors have clearli take effect, all but disappear 
from that map, wherea train be heavili mentioned, particu- 
larli around major cities, display a similar pattern to that of 
electricity. 

discuss 
the key aim of thi studi be to show an approach to under- 
stand continu and chang in histori base on the distant 
read of vast news corpora, which be complementari to the tra- 
dition close read by historians. We show that chang and 
continu detect in newspap content can reflect properti 
of culture, bia in representation, or actual real-world events. 

with thi approach, historian can explor the complex rela- 
tionship between public discours and live experi by detect- 
ing trend in statist signal extract from large-scal textual 
corpora. the method be intend to be use in combin with 
tradit approaches, which be need for both the design of 
the studi and the interpret of the findings. nevertheless, it 
provid conjectur and answer that would be veri difficult to 
formul by use close read alone. 

In particular, we show that comput approach can 
establish a meaning relationship between a give signal in 
large-scal textual corpu and verifi histor moments, 
which be show in the trend for coron and epidem dis- 
play in fig. 1, and that newspap provid increas clariti to 
the analysi of these event that may not be possibl in other cul- 
tural forms, such a books. We further show that the approach 
can reveal or confirm way in which news medium repres par- 
ticular peopl or issu over time, a evid by the exist 
of a gender bia that be still present in the medium today (17), and 
that histor trend in public discours can be make access 
through the same means. 

importantly, thi complementari approach provid a layer of 
cultur understand that can be use to augment establish 
histor perspectives, evid in thi studi by the tempor 
and geograph pattern in the uptak of variou technolog 
and concept show in fig 6, which can provid benefit to tradi- 
tional econom and technic histori of the period. 

In thi study, special care be devot to the choic of event 
that be use for analysi and the keyword chosen to repre- 
sent them, becaus we should all be awar of the risk of detect 

lansdall-welfar et al. pna earli edit | 5 of 9 



fig. 6. chang in geographi over time. map of the unit kingdom 
show the chang in geograph focu of locat extract from arti- 
cle contain the term (a) british and english, (b) liber parti and labour 
party, (c) steam and electricity, and (d) hors and train for the year in which 
each concept receiv it peak attention. 

spuriou signal in larg datasets. As recommend by nicholson 
(10), one should tri to choos word that have high sensitiv- 
iti and specif for the concept be investig and at the 
same time, be not too suscept to semant shift and error 
in the ocr process. each of these step could, in principle, 
be formal and autom to some extent: for example, the 
use of automat queri expans (21) could like return a 
viabl set of word that pertain to a specif concept [thi set 
approxim the lexic field (22) of that concept]. however, 
we feel that it be ultim the role of the historian to use her 
judgment and cultur knowledg in the choic of these key- 
word and the subsequ interpret of the results. In thi 
way, we focu our analysi on event and keyword that be 
not ambiguous: coronations, wars, technolog artifacts, etc., 

all of which be event and trend that can be repres by 
a small set of specif word and often have clear date attach 
to them. 

variou author have voic concern that digit human 
might be just a colon of the human by the sciences, 
but do so be not the purpos of thi study. On the contrary, we 
feel that the practic of close read cannot be replac by algo- 
rithmic means. indeed, our method can onli detect increas 
or decreas attent toward a give topic or idea over the 
decades, offer a complementari approach to close reading, 
but they cannot explain the reason behind those changes, which 
be best understood by other means. We believe, however, that 
other critic be less warranted: the inabl of comput 
method to introduc contextu knowledge, access semant 
information, or work in the presenc of ocr nois or the issu 
relat to bia in the origin corpu select be probabl all 
issu that can be solv or account for over time. 

futur work will inde includ denois of the data, link 
of the data with other corpu or data sources, good disam- 
biguat of entities, and more refin inform extract 
within a context. additionally, the evalu of suitabl key- 
word could be partial autom by includ inform 
about ocr nois to help guid the analyst, with recent develop- 
ment also offer the promis of captur the extent to which 
the mean of a specif word have chang over time (23). these 
direct be part of engin work alreadi underway. 

what cannot be autom be the understand of the impli- 
cation of these find for people, which will alway be the 
realm of the human and social scienc and will never be that 
of machines. 

materi and method 
data sourc background. the british library’ newspap collect be 
among the fine in the world, contain most of the run of newspap 
publish in the unit kingdom sinc 1800. the scale of the newspap 
publish industri from the earli 19th centuri onward be enormous, with 
mani citi and town publish sever newspap simultan and 
other newspap that aim for a wider counti circul provid an 
unrival pictur of provinci life span the whole of the 19th centuri 
and half of the 20th centuri (24). 

In may of 2010, findmypast begin a partnership with the british librari 
to digit million of page of these histor newspap and make them 
avail for the public to search onlin at www.britishnewspaperarchive. 
co.uk. 

new page be be scan all of the time a part of the 10-year 
project, which onc finished, will contain over 40 million newspap page 
from the british library’ newspap collection. To date, findmypast have 
make avail over 12 million page from 535 differ newspap titl 
publish between 1710 and 1959, add over 8,000 new page each day. 

the newspap collect be further supplement with digit news- 
paper record provid by the joint inform system committe (jisc) 
that cover the same geograph region and time period. the digit of 
these newspap be fund by the jisc to provid a repres sampl 
of unit kingdom newspap span all geograph regions, make 
them suitabl for a large-scal autom content analysi of britain dur- 
ing the 19th and 20th centuries. the data from the jisc form approxim 
20% of the result corpus. 

In thi study, we select a subset of the entir corpu that have be 
scan at the time, aim to assembl a corpu for the studi of britain 
between 1800 and 1950. To do so, we undertook sever signific step 
relat to the select of news outlet to provid a balanc represen- 
tation in term of geograph region, time period and qualiti of the texts, 
the digit process and extract of the associ metadata, and the 
extract of inform from the raw text of the corpus. 

the corpu be access under a subscript model at www.britishnews- 
papersarchive.co.uk, wherea enquir about bulk access to raw data 
should be direct to findmypast. the exact list of articl and newspa- 
per outlet from findmypast along with secondari data produc dur- 
ing thi studi be openli available, includ time seri of the million 
most frequent n-gram and the 100,000 most frequent name entiti 
extract by aida (25), which be avail at data.bris.ac.uk/data/dataset/ 
dobuvuu00mh51q773bo8ybkdz (26). 

6 of 9 | www.pnas.org/cgi/doi/10.1073/pnas.1606380114 lansdall-welfar et al. 

http://www.britishnewspaperarchive.co.uk 
http://www.britishnewspaperarchive.co.uk 
http://www.britishnewspapersarchive.co.uk 
http://www.britishnewspapersarchive.co.uk 
http://data.bris.ac.uk/data/dataset/dobuvuu00mh51q773bo8ybkdz 
http://data.bris.ac.uk/data/dataset/dobuvuu00mh51q773bo8ybkdz 
http://www.pnas.org/cgi/doi/10.1073/pnas.1606380114 


PN 
A 

S 
PL 

U 
S 

CO 
M 

PU 
TE 

R 
SC 

IE 
N 

CE 
S 

SO 
CI 

A 
L 

SC 
IE 

N 
CE 

S 

data selection. newspap issu be select from those that have be 
digit by findmypast from the british librari archiv with an eye to form 
a repres sampl of newspapers. the select be perform by 
committee, and the criterion for inclus be (i) the complet of the 
run of issues, (ii) the number of year that an issu covers, (iii) the geo- 
graphic region that the issu be from, (iv) the qualiti of the ocr output 
for the issue, and (v) the polit bia of issues. 

our princip aim be to cover all geograph region and time interv 
a fairli a allow by the avail data. issu be first separ into the 
regist geograph region for the publisher, and within each region, 
newspap issu be rank by a combin of the number of year cov- 
ere (favor issu with continu coverag of mani years), their aver- 
age ocr quality, and the total size of data avail for the issue. issu 
be then select from the rank until the region have good coverage. 
use domain knowledge, consider be also take to ensur that the 
select of newspap issu repres the balanc of polit opinion in 
the region press at the time. 

In total, the corpu includ 120 titl select to best cover the follow 
12 geograph region of the unit kingdom use the abov criterion for 
inclusion: east, east midlands, northern ireland, london, northwest, north- 
east, scotland, southeast, southwest, wales, west midlands, and yorkshire. 

We estim the number of region newspap within the unit 
kingdom dure the period from 1800 to 1950 use statist on the num- 
ber of newspap in circul (27). specifically, we take the averag num- 
ber of paper in circul from newspap directori for 1847, 1877, and 
1907. thi calcul give u an estim of 835 newspap titl in exis- 
tenc through the period. our corpu contain 120 newspap titles, give 
u an estim that the corpu cover approxim 14% of the region 
paper for the unit kingdom dure that time. 

data and associ metadata. 
digit process. the origin newspap be provid by the british 
librari to the findmypast newspap team a either microfilm or the orig- 
inal bound newspapers. origin bound newspap be scan use 
zeutschel A0 sheet-b scanners, creat high-qual digit copi of the 
newspap a tiff imag at 400 dot per inch (dpi) in 24-bit color befor 
be convert to jpeg2000 format imag for archiving. imag creat 
from digit the microfilm result in grayscal imag at 300 dpi. 

the raw imag creat dure digit be digit cropped, 
cleaned, and contrast enhanc befor be segment into classifi 
area correspond to the type of content, such a news articles, advertise- 
ments, and obituaries; structur information, such a page numbers, head- 
ers, and footers; and titl information, such a issu title, date of publica- 
tion, and price. 

the imag be then pass through an ocr process to identifi the text 
use in each section of the page, wherea the associ metadata for each 
issu be pass through a qualiti assur check to correct ani mistak 
in the structur extract step. 

data provid via the jisc collect be digit use a similar work- 
flow through an extern supplier (28). 
structur extraction. the raw imag from the scan of the origin bound 
newspap or the microfilm after cropping, cleaning, and contrast correc- 
tion be next process in a step to segment each page into classifi 
areas. thi process be perform by findmypast in two differ ways. 

the major of the corpu (78%) be manual segment into differ- 
ent classifi area relat to the content of the page, structur informa- 
tion, or titl information. It be found that thi manual process be pro- 
hibit expens after a certain point within the project, and therefore, 
the remain corpu be process use an autom method use the 
cc docwork softwar (29). 
ocr. ocr be perform on the digit imag within the cc docwork 
softwar (29) by the findmypast team. thi process output the recogn 
text in the imag along with associ inform (such a the locat 
and layout on the page) and percentag word accuraci for each word 
in the standard metadata object descript schema (mods), metadata 
encod and transmiss standard (mets), and analyz layout and text 
object (alto) format (30). 

the percentag word accuraci for ocr be calcul automat by the 
ocr softwar and use a a measur of how confid the softwar be that 
the charact make up the word be interpret correctly. each individ- 
ual charact in each word be assign a charact score between zero and 
nine (with nine be 100% confidence) for how confid the softwar 
be that the charact have be read correctly. the overal score for the word 
be then calcul by take the averag confid score for the letter 
that compos it. more widely, the word accuraci score be averag over a 

set of word to assign a qualiti score to how well the text in the imag have 
be recogn at the articl level. 

becaus error in ocr can be affect by a number of systemat fac- 
tors, includ but not limit to font, size, and physic condit of the 
origin paper copy, the error rate vari across titles; therefore, we aim 
to select those titl that have the best possibl ocr qualiti for inclus 
in our corpu so a not to detriment affect the analysi by introduc 
low-qual texts. Of course, certain typograph consider must also 
be consid when analyz the data, such a the common use of the 
long s, which can often be mistaken for an f. addit work can cer- 
tainli be do to account for these type of mistak and will improv in 
the future. 

overall, in the corpu select for analysis, the averag percentag word 
accuraci be estim to be 77.0%, with an SD of 5.78, take the averag 
score assign to each newspap outlet per year by cc docwork (29) 
weight by volum across all articl in the corpus. 
metadata. the process that be undertaken by the british librari and the 
findmypast newspap team to annot the data be again manag 
through the process manag pipelin base on cc docwork (29). 
metadata rel to each outlet be manual enter at the time of the 
digit base on the british librari newspap catalog. the locat 
assign to each outlet be identifi base on the locat of origin pub- 
lication. the date be extract from each newspap issu by human oper- 
ator and then, valid dure qualiti control checks. the page segmen- 
tation and headlin ocr for materi process earli in the project be 
manual correct by operators; late in the project, these step be per- 
form without human intervention. A human editor be use to run qual- 
iti control check on the structur data extract by the software, and the 
workflow softwar identifi systemat issu that be then manual cor- 
rect by operators. thi process includ verifi that the outlet name be 
correct, the date of the issu be correct, and the page have be segment 
into correctli identifi type along with ani other qualiti assur 
step taken. 

autom content analysis. after the digit process have be com- 
pleted, the findmypast team provid the bristol team with a collect 
of document contain the textual content from the newspap articl 
along with associ metadata relat to the titl of the article, the 
date of publication, the titl that publish the article, the locat for 
the publisher, and so forth. document be convert from the mets, 
mods, and alto format into javascript object notat (31) document 
and store with their associ metadata in a mongodb nosql collect 
(https://www.mongodb.com/). 

each document in the databas be then subject to an inform 
extract procedur (describ below), which aim to allow u to gener- 
ate time seri of ani n-gram, extract refer to entiti within the text 
and resolv the entities, and link the entiti to extern databas where 
possibl to enrich the inform contain within each document. 

n-grams. n-gram be extract from the main textual content of each 
document, begin with token the text, count the frequenc of 
each n-gram across the entir corpus, and then, filter the n-gram so a 
to onli keep those that occur a minimum number of time (in thi case, at 
least 10 times). 
generation. raw text data be store a a string of characters, with no 
explicit word information. token split the string of charact up 
into a string of words, also refer to a tokens, terms, or 1-grams, for 
which we can then comput the frequency. token be perform 
use the assumpt that contigu sequenc of alphabet charact 
form a singl 1-gram in the vocabulary, which be separ by whitespac 
characters. numer charact that form contigu sequenc be also 
consid a 1-gram, wherea special characters, such a punctuation, be 
treat in differ way depend on the specif character. for our pur- 
poses, the alphabet use be the unicod transform format 8 (utf-8) 
charact set. 

the token be implement use the word break rule from 
the unicod text segment algorithm follow the specif 
in the unicod standard annex 29 (unicode.org/reports/tr29/). n-gram 
be further process to remov possess (trail “’s” at the end 
of words), lowercased, and stem use the porter stemmer algorithm 
(32). token be perform use the lucen analyz librari avail- 
abl at https://lucene.apache.org/core/4 0 0/analyzers-common/overview- 
summary.html. 
frequenc of n-grams. We calcul the frequenc of each n-gram (up to 
a length of three) in the corpu by first count how often each n-gram 

lansdall-welfar et al. pna earli edit | 7 of 9 

https://www.mongodb.com/ 
http://unicode.org/reports/tr29/ 
https://lucene.apache.org/core/4_0_0/analyzers-common/overview-summary.html 
https://lucene.apache.org/core/4_0_0/analyzers-common/overview-summary.html 


occur within each document with a public date of the same year in 
the corpu and then, divid thi number by the total volum of term 
(1-grams) occur within the document publish in the same year. thi 
calcul give a rel import to each n-gram at the time of it use. 
thi calcul be comput within the hadoop map-reduc framework 
avail at hadoop.apache.org/, allow u to distribut the comput 
and work on the larg corpu use in thi study. 

when estim the rel frequenc of an n-gram for each year, 
we also calcul a confid interv for that estim use the yate’ 
score interv (33). the result confid bar be not discern when 
plotted, a they be veri small becaus of the veri larg size of the data 
use to calcul the time series. As an example, compar steam with elec- 
tricity, the size of the chang between 1800 and 1950 be at least two order 
of magnitud larg than the mean confid interv rel to those 
time points. 

entities. We use standard text engin tool to extract name enti- 
tie from the text, link them with extern sourc of inform where 
possible. entiti be extract use aida (https://github.com/yago-naga/ 
aida), a framework for entiti detect and disambigu (25) includ 
both person and locat types. additionally, we extract refer to 
people, includ those not necessarili present in ani extern databases, 
use the anni plugin of the gener architectur for text engin 
(https://sourceforge.net/projects/gate/) (20). 

although we note that both of these tool do not have 100% accuracy, 
in detect the entiti from the text or link it with the correct infor- 
mation from extern sources, it be import to also note that we miti- 
gate the risk by remov those entiti for which high confid could 
not be achiev a explain below. although perform of the tool 
cannot be assess on the histor corpu (for lack of a “ground truth”), 
each tool does, however, achiev high perform on benchmark tasks, 
with aida report a mean averag precis of 89.05% on the associ 
for comput linguistics’ special interest group on natur languag 
learn confer on comput natur languag learn (conll) 
2003 dataset (25), and our entiti extract tool base on the anni plugin 
for gate achiev an accuraci of 97.1% on news medium from the web (17). 
furthermore, for each of the tools, we develop qualiti control check and 
filter to ensur that we onli keep the predict for which we have a 
high level of confidence, becaus it should be note that these tool be not 
specif train on digit histor newspapers. 

for the entiti extract use aida (25), although onli more promin 
peopl or locat be identifi (becaus they must first appear in an exter- 
nal database, such a wikipedia), it be suffici for our purpos of iden- 
tifi differ person by their specif occup (e.g., scientists, 
writers, politicians, etc.). In do so, we be abl to replic the googl 
book studi (1) use all person that we extract from the corpu 
rather than limit ourselv to the top 25. overall, there be 263,813,326 
mention of 1,009,848 differ entiti mention in wikipedia. 

thi studi be perform by group all person by their occu- 
pation type in dbpedia (avail for download from wiki.dbpedia.org) 
(19) a extract by aida befor resolv hyponym to their hyper- 
nym occup type use the wordnet ontolog (34) (avail at 
https://wordnet.princeton.edu/wordnet/download/). person be fil- 
tere to remov spurious extract entities, where entiti be identifi 
a spuriou by first retriev the birth date for each entiti from dbpedia 
and then, remov those for which the major of their mention occur 
befor the entiti be born. In thi way, we reduc the number of person 
that have be erron link to a specif wikipedia entry. 

for studi gender balanc over the cours of histori within the cor- 
pus, we want to avoid ani systemat effect caus by our gender detec- 
tion procedure. A method base on link entiti to dbpedia (which be 
base on wikipedia) would like suffer from the same gender imbal 
discov in wikipedia (35). therefore, we use instead the anni plugin 
of gate to extract everi refer to a person within the corpu and classifi 
their gender into male, female, or unknown use contextu inform 
(such a titles, first names, pronouns, etc.). We consid onli those refer- 
enc for which we could obtain an unambigu gender, discard more 
ambigu entiti where we receiv more than one distinct gender label 
for the entity. In do so, we be abl to show the number of refer 
to male and femal over the cours of 150 year in unit kingdom news- 
papers. In total, there be 25,896,979 unambigu refer to males, 
10,198,490 unambigu refer to females, and onli 309,098 ambigu- 
ou refer (assign to both gender by the tool) found within the cor- 
pus, show that we can unambigu find the gender of an entiti for 
99.15% of the entiti in the histor newspap corpus. 

We addit compar our find with those come from the 
googl book n-gram corpu (1) along with our own result use the inde- 
pendent n-gram method. thi combin use of larg number of refer 
and the comparison with independ sourc of inform give u con- 
fidenc that we can separ the signal from the noise. 

locat be also extract use aida (25), disambigu each men- 
tion of a locat with it wikipedia page. geograph coordin be 
retriev from dbpedia for each locat or pars from the live wikipedia 
page when no coordin be resolv from dbpedia. 

geograph focu map of differ concepts, such a british or train 
a display in fig. 6, be gener by visual all locat that be 
present in ani articl contain the concept n-gram and that occur a min- 
imum of three time in ani articl contain the concept n-gram in the 
same year. thi threshold be use to both filter veri low-frequ loca- 
tion and obtain a more readabl map. locat marker be size accord- 
ing to a combin of the natur log of their total mention in the corpu 
(more mention locat be give great weight) and the probabl 
that, within a give year, a locat be mention in the same articl a the 
concept n-gram (the size of the intersect between a concept and a loca- 
tion with a year be a measur of how relat they be at that time). 

statist robust of methods. when work in a data-driven high- 
throughput way, which be the case in thi distant read project, it be neces- 
sari to autom most steps, and thi autom do creat the prob- 
lem that each step might introduc errors: ocr will corrupt some char- 
acters, name entiti recognit might fail to recogn a location, and 
disambigu step might link an entiti to the wrong entri in extern 
resources. however, the size of the dataset and care design can be use 
to mitig thi risk. 

our focu be on detect larg statist patterns, and therefore, we can 
toler less than perfect perform at each stage of the analysi and still 
extract a reliabl signal—if we care design the analysis. In thi way, we 
be not differ from previou culturom studi (1), and a nicholson (10) 
observed, “thi be the price one must pay to explor the ‘vast terra incognita’ 
of 19th centuri print culture.” 

saniti check perform at the end of the pipelin show that indeed— 
for all of the error that may be introduced—w can still reliabl detect 
histor events, such a coronations, war and epidemics. among the mani 
design choic involv in the study, we compar rel frequenc of a 
give word (e.g., train vs. horse) or rel chang in the ratio between 
male and femal entities, ensur that we be compar signal that be 
affect by the same type of noise. addit saniti checks, by compar 
time seri gener by words, such a he and she or men and women, with 
those gener by the overal mention of male and femal entities, show 
that ani nois found in the process pipelin do not cancel the signal. 

On the select of keyword and other signals. As point out by nicholson 
(10), one of the key design choic in these studi be the select of key- 
words. there be variou risk involv in thi step: a word might not repre- 
sent well the concept under investigation, perhap becaus it be ambiguous, 
or it might not be semant stabl dure the period under study; per- 
hap that word might not be robust under ocr noise. indeed, we might 
want to look at sever word to repres a concept (a we do for victo- 
rian values) or sometimes, entir lexic field (22). our approach have be 
to use judgment base on histor knowledg for the assess of the 
relev and stabil of each word, make use of care select list of 
word alreadi use in previou relev studies, ass keyword by close 
read some of the articl match them, and use autom mean to 
go beyond count word and therefore, bypass the risk associ with 
select keyword entirely. 

there be a second risk involv in the select of keywords: when min- 
ing vast corpora, there be alway the risk of find a spuriou signal (for 
example, a time seri that have accident resembl with some histor 
trend). the risk be high when use high-throughput method becaus of 
the statist phenomenon of “multipl testing”: even if each keyword have 
a veri low chanc of show accident correlations, when we can analyz 
ten of thousand of keywords, thi risk be multipli accordingly. the prob- 
lem be further increas by the inher ambigu of the task describ in 
thi study: the lexic field (22) rel to an event or cultur phenomenon 
be not well-defin a priori, and therefore, there be signific freedom for 
the analyst to—involuntarily—select word that confirm a hypothesis. 

these risk can be mitig by variou technic and statist 
approaches. for example, make use of precompil list of keyword from 
previou studies, such a the victorian values, be a standard statist method 
to account for multipl test by reduc the space of possibl test 

8 of 9 | www.pnas.org/cgi/doi/10.1073/pnas.1606380114 lansdall-welfar et al. 

http://hadoop.apache.org/ 
https://github.com/yago-naga/aida 
https://github.com/yago-naga/aida 
https://sourceforge.net/projects/gate/ 
http://wiki.dbpedia.org 
https://wordnet.princeton.edu/wordnet/download/ 
http://www.pnas.org/cgi/doi/10.1073/pnas.1606380114 


PN 
A 

S 
PL 

U 
S 

CO 
M 

PU 
TE 

R 
SC 

IE 
N 

CE 
S 

SO 
CI 

A 
L 

SC 
IE 

N 
CE 

S 

be conducted, wherea it should also be possibl to gener a list of key- 
word that relat to a specif concept by use techniqu from the field of 
automat queri expans (21), therefor approxim it lexic field. 
however, ultimately, it will be the job of the analyst to make care judg- 
ment and use the find with the necessari care. We have make everi 
effort to select nonambigu term and event to avoid the risk of gener- 
ate a spuriou signal, ensur that we gener the keyword for analysi 
in a way that be independ of their tempor behavior in the corpus. 

acknowledgments. We thank ilia flaouna for hi help in the initi 
stage of the studi and patrick fleme and the jisc for make their cor- 
pu available. part of the work be carri out use the comput 
facil of the advanc comput research center, univers of bris- 
tol. thi studi be make possibl by findmypast newspap archiv ltd 
(www.britishnewspaperarchive.co.uk), which share the data. most uni- 
versiti of bristol member of the team (t.l.-w., s.s., and n.c.) be sup- 
port by european research council advanc grant thinkbig award 
to n.c. 

1. michel jb, et al. (2011) quantit analysi of cultur use million of digit 
books. scienc 331(6014):176–182. 

2. reddi R, stclair G (2001) the million book digit librari project. (carnegi mellon 
university, piittsburgh). avail at www.rr.cs.cmu.edu/mbdl.htm. access decem- 
ber 19, 2016. 

3. gibb fw, cohen DJ (2011) A convers with data: prospect victorian word 
and ideas. vic stud 54(1):69–77. 

4. mauch M, maccallum rm, levi M, leroi AM (2015) the evolut of popular music: 
usa 1960–2010. R soc open sci 2 (5):150081. 

5. leetaru K (2011) culturom 2.0: forecast large-scal human behavior use 
global news medium tone in time and space. first monday 16(9). 

6. flaouna I, et al. (2013) research method in the age of digit journalism: massive- 
scale autom analysi of news-content—topics, style and gender. digit journal- 
ism 1(1):102–116. 

7. good P (2013) mass digit and the garbag dump: the conflict need of 
quantit and qualit methods. lit ling comput 28(3):425–431. 

8. morse-gagné EE (2011) culturomics: statist trap muddi the data. scienc 
332(6025):35. 

9. schwartz T (2011) culturomics: period gaug culture’ pulse. scienc 
332(6025):35–36. 

10. nicholson B (2012) count culture; or, how to read victorian newspap from a 
distance. J vic cult 17(2):238–246. 

11. moretti F (2013) distant read (verso books, london). 
12. borin L, et al. (2013) mine semant for culturomics: toward a knowledge-bas 

approach. proceed of the 2013 intern workshop on mine unstructur 
big data use natur languag processing, ed liu X, chen M, ding Y, song M 
(acm, new york), pp 3–10. 

13. suchanek fm, preda N (2014) semant culturomics. proc vldb endow 
7(12):1215–1218. 

14. lansdall-welfar T, sudhahar S, veltri ga, cristianini N (2014) On the coverag of 
scienc in the media: A big data studi on the impact of the fukushima disaster. pro- 
ceed of the 2014 ieee intern confer on big data (big data), ed lin J, 
pei J, lin TY (ieee, new york), pp 60–66. 

15. flaouna I, et al. (2010) the structur of the the EU mediasphere. plo one 
5(12):e14243. 

16. colleyl(2005)britons: forg the nation, 1707–1837 (yaleunivpress,newhaven,ct). 
17. jia S, lansdall-welfar T, sudhahar S, carter C, cristianini N (2016) women be see 

more than heard in onlin newspapers. plo one 11(2):e0148434. 
18. suchanek fm, kasneci G, weikum G (2007) yago: A core of semant knowledge. pro- 

ceed of the 16th intern confer on world wide web, ed williamson C, 
zurko me, patel-schneid P, shenoy P (acm, new york), pp 697–706. 

19. lehmann J, et al. (2015) dbpedia–a large-scale, multilingu knowledg base ex- 
tract from wikipedia. semant web, ed williamson C, zurko me, patel-schneid P, 
shenoy P 6(2):167–195. 

20. cunningham H, maynard D, bontcheva K, tablan V (2002) gate: A framework and 
graphic develop environ for robust nlp tool and applications. proceed- 
ing of the 40th annual meet of the associ for comput linguistics, ed 
isabel P (acl, stroudsburg, pa), pp 168–175. 

21. carpineto C, romano G (2012) A survey of automat queri expans in inform 
retrieval. acm comput surv 44(1):1–50. 

22. öhmann E, trier J (1931) der deutsch wortschatz im sinnbezirk de verstand 
(c. winter, heidelberg). 

23. weston J, ratl F, mobahi H, collobert R (2012) deep learn via semi-supervis 
embedding. neural networks: trick of the trade, ed montavon G, orr gb, mller k-r 
(springer, berlin), pp 639–655. 

24. findmypast newspap archiv limit (2016) about the british newspap archive. 
avail at www.britishnewspaperarchive.co.uk/help/about. access septemb 
26, 2016. 

25. hoffart J, et al. (2011) robust disambigu of name entiti in text. proceed 
of the confer on empir method in natur languag processing, ed merlo P, 
barzilay R, johnson M (associ for comput linguist stroudsburg, pa), 
pp 782–792. 

26. lansdall-welfar T, et al. (2016) findmypast yearli n-gram and entiti dataset. 
avail at data.bris.ac.uk/data/dataset/dobuvuu00mh51q773bo8ybkdz. access 
decemb 19, 2016. 

27. walker A (2006) the develop of the provinci press in england c. 1780–1914: An 
overview. journal stud 7(3):373–386. 

28. shaw J (2009) british librari newspap digitis report. avail 
at www.webarchive.org.uk/wayback/archive/20140614080134/www.jisc.ac.uk/media/ 
documents/programmes/digitisation/blfinal.pdf. access septemb 26, 2016. 

29. cc (2016) content convers specialist - digit services. avail at https:// 
content-conversion.com/#digitization-services. access septemb 26, 2016. 

30. impact centr of compet in digitis (2016) recommend on format 
and standard use in digitisation. avail at www.digitisation.eu/training/ 
recommendations-for-digitisation-projects/recommendations-formats-standards-rec- 
ommendations/. access septemb 26, 2016. 

31. bray T (2014) the javascript object notat (json) data interchang format (ietf, 
fremont, ca). 

32. porter MF (1980) An algorithm for suffix stripping. program 14(3):130–137. 
33. walli S (2013) binomi confid interv and conting tests: mathemat 

fundament and the evalu of altern methods. J quant linguist 20(3): 
178–208. 

34. miller ga, beckwith R, fellbaum C, gross D, miller KJ (1990) introduct to wordnet: 
An on-lin lexic database. int J lexicogr 3(4):235–244. 

35. wagner C, garcia D, jadidi M, strohmaier M (2015) it’ a man’ wikipedia? assess 
gender inequ in an onlin encyclopedia. proceed of the ninth intern 
confer on web and social media, icwsm 2015, ed quercia D, cha M, mascolo 
C, sandvig C (aaai press, palo alto, ca), pp 454–463. 

lansdall-welfar et al. pna earli edit | 9 of 9 

http://www.britishnewspaperarchive.co.uk 
https://www.rr.cs.cmu.edu/mbdl.htm 
http://www.britishnewspaperarchive.co.uk/help/about 
http://data.bris.ac.uk/data/dataset/dobuvuu00mh51q773bo8ybkdz 
http://www.webarchive.org.uk/wayback/archive/20140614080134/www.jisc.ac.uk/media/documents/programmes/digitisation/blfinal.pdf 
http://www.webarchive.org.uk/wayback/archive/20140614080134/www.jisc.ac.uk/media/documents/programmes/digitisation/blfinal.pdf 
https://content-conversion.com/#digitization-servic 
https://content-conversion.com/#digitization-servic 
http://www.digitisation.eu/training/recommendations-for-digitisation-projects/recommendations-formats-standards-recommendations/ 
http://www.digitisation.eu/training/recommendations-for-digitisation-projects/recommendations-formats-standards-recommendations/ 
http://www.digitisation.eu/training/recommendations-for-digitisation-projects/recommendations-formats-standards-recommendations/ 



