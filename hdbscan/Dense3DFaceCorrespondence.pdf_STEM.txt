




































untitl 


dens 3D face correspond 
sy zulqarnain gilani , ajmal mian, faisal shafait, and ian reid 

abstract—w present an algorithm that automat establish dens correspond between a larg number of 3D faces. 

start from automat detect spars correspond on the outer boundari of 3D faces, the algorithm triangul exist 

correspond and expand them iter by match point of distinct surfac curvatur along the triangl edges. after 

exhaust keypoint matches, further correspond be establish by gener evenli distribut point within triangl by 

evolv level set geodes curv from the centroid of larg triangles. A deform model (k3dm) be construct from the dens 

correspond face and an algorithm be propos for morph the k3dm to fit unseen faces. thi algorithm iter between rigid 

align of an unseen face follow by regular morph of the deform model. We have extens evalu the propos 

algorithm on synthet data and real 3D face from the frgcv2, bosphorus, bu3df and und ear databas use quantit and 

qualit benchmarks. our algorithm achiev dens correspond with a mean localis error of 1.28 mm on synthet face 

and detect 14 anthropometr landmark on unseen real face from the frgcv2 databas with 3 mm precision. furthermore, our 

deform model fit algorithm achiev 98.5 percent face recognit accuraci on the frgcv2 and 98.6 percent on bosphoru 

database. our dens model be also abl to gener to unseen datasets. 

index terms—dens correspondence, 3D face, morphing, keypoint detection, level sets, geodes curves, deform model 

Ç 

1 introduct 

one of the canon task in shape analysi be to find ameaning map between two or more shape [1]. 
the process, call shape correspondence, be a pre-requisit 
for mani comput vision, comput graphic and medic 
imag analysi applications. the requisit densiti of corre- 
spondenc be often dictat by the underli shape and tar- 
get application. sometimes, spars correspond be 
suffici to infer shape semant bymatch repres 
points, for exampl the four corner of a rectangl or emblem- 
atic point on key joint of a human body. however, spars 
correspond be often inadequ in case of articul 
shape [2], [3] where part of the shape can bend indepen- 
dentli or in the correspond of anatom shape which 
can deform in an elast manner [4]. In such circumstances, 
dens correspond be requir to guarante represent 
of global shape changes, for instanc in case of morph or 
attribut transfer. furthermore, veri subtl chang within a 
class of shape can be detect onli if the correspond 
between these shape be dens [6]. 

In thi paper we be concern with the task of find 
dens correspond between a veri larg number of simi- 
lar shapes; in our case 3D scan of human faces. We do so 

becaus thi further enabl u to gener highli accur 3D 
morphabl model that can be use for inform transfer 
between the train set and a test face or between two test 
face by morph the 3D model to fit the test face(s). for 
example, give the locat of anthropometr landmark [7] 
on the 3dmorphablemodel, these landmark can be automat- 
ical local on previous unseen test face [8]. further- 
more, dens correspond and morphabl model can be 
use for 3D face recognit [9], [10]. other applic 
includ facial morphometr measur such a gender 
score [5] and asymmetri for syndrom diagnosi [6], statis- 
tical shape model [11], [12], shape interpol [13], non- 
rigid shape registr [3], [14], [15], deform analy- 
si [16] and recognit [17], [18], [19]. 

while it be possibl to manual annot a small number 
(�30) of correspond for a few 3D faces, it be not feasibl 
to manual identifi dens correspond (�6,000) 
between hundr of 3D faces. the literatur also propos 
comput dens correspond by extend manual 
annot spars one [9], [20]. however, with the advent of 
huge 3D face databas like the facebas consortium [21] or 
rain dataset [22], [23], thi strategi too have becom impracti- 
cal and call for fulli automat algorithms. automat 
establish dens correspond between the 3D face of 
two differ person be an extrem challeng task 
becaus the facial shape vari significantli amongst individ- 
ual depend on their identity, gender, ethnic and age [7] 
a well a their facial express and pose. the problem of 
dens 3D point-to-point correspond can be formul 
a follows. given a set of N 3D faces, Fj ¼ ½xp; yp; zp�t ; 
j ¼ 1; . . . ;n; p ¼ 1; . . . ; pj, the aim be to establish a dens bijec- 
tive map f : Fi ! fjði 6¼ jÞ over k vertex where 
1 < < k < minðpi; pjþ. correspond should cover all 
region of the face for high fidel and should follow the 
same triangul for shape consistency. 

� s.z. gilani, A. mian, and F. shafait be with the school of comput sci- 
enc and softwar engineering, the univers of western australia, 35 
stirl highway, crawley, wa, 6009, australia. e-mail: syedzulqarnain. 
gilani@research.uwa.edu.au, {ajmal.mian, faisal.shafait}@uwa.edu.au. 

� I. reid be with the school of comput science, univers of adelaide, 
ingkarni wardli, north terrac campus, adelaide, SA 5005, australia. 
e-mail: ian.reid@adelaide.edu.au. 

manuscript receiv 15 june 2016; revis 2 may 2017; accept 3 juli 2017. 
date of public 10 juli 2017; date of current version 12 june 2018. 
(correspond author: sy zulqarnain gilani.) 
recommend for accept by R. yang. 
for inform on obtain reprint of thi article, pleas send e-mail to: 
reprints@ieee.org, and refer the digit object identifi below. 
digit object identifi no. 10.1109/tpami.2017.2725279 

1584 ieee transact ON pattern analysi and machin intelligence, vol. 40, no. 7, juli 2018 

0162-8828� 2017 ieee. person use be permitted, but republication/redistribut requir ieee permission. 
see http://www.ieee.org/publications_standards/publications/rights/index.html for more information. 

https://orcid.org/0000-0002-7448-2327 
https://orcid.org/0000-0002-7448-2327 
https://orcid.org/0000-0002-7448-2327 
https://orcid.org/0000-0002-7448-2327 
https://orcid.org/0000-0002-7448-2327 
mailto: 
mailto: 
mailto: 
mailto: 


exist dens correspond techniqu have one or 
more of the follow limitations: (1) they need manual 
annot landmark on 3D face for initialization. (2) they 
use imag textur match to find 3D shape correspon- 
dence. (3) they correspond all face to a singl refer face 
neglect the global proxim of the 3D faces. (4) they 
have not be test on complet benchmark databas such 
a the frgcv2 [24] or bosphoru [25] dataset for face recog- 
nition and landmark identification. (5) they have no explicit 
mechan of updat the dens correspondencemodel. 

In thi context, we propos a fulli automat algorithm 
for establish dens correspond simultan 
between a larg number of 3D faces. our algorithm do 
not requir ani manual intervent and reli sole on 3D 
shape match to encod accur facial morphology. We 
organ the 3D face into a minimum span tree base 
on bend energi requir to deform one shape into the 
other so that correspond can be propag in a reli- 
abl way. We propos a mechan for automat initializa- 
tion of a spars set of correspond on the outer 
boundari of the 3D faces. We form a triangul of these 
correspondences, and iter add to the set of point by 
match point of distinct surfac curvatur along (and 
close to) the triangul edges. after exhaust the possi- 
biliti for such matches, we further expand the set of 
match by gener point distribut evenli within tri- 
angl by evolv level set geodes curv from the cent- 
roid of larg triangles. the outcom of our algorithm be a 
keypoint-bas 3D deform model (k3dm). 

our second major contribut be a deform model fit- 
ting algorithm where k3dm be use to morph into unseen 
queri faces. start from the mean face, the fit algo- 
rithm iter between two steps. the queri face be trans- 
form rigidli to align with the model and the model be 
deform use regular least squar to fit the queri 
face. thi algorithm converg in a few iter and be 
robust to noise, outlier points, miss points, pose and 
express variations. 

our final contribut be an algorithm for augment the 
k3dm. given the k3dm and a new batch of M faces, we 
construct a minimum span tree use the near face 
to the k3dm a the root node. the k3dm be augment by 
add one face at a time, start with the root node, and 
each time updat the model and deform the updat 
model to good fit the next face in the span tree. 

evalu dens correspond techniqu be challeng- 
ing due to the inher difficulti of obtain ground-truth 
data. In the exist literature, evalu have mostli 
be perform on a spars set of anthropometr facial 
landmark [26], [27], [28] sinc these can be manual 
labelled. however, evalu on onli a few (� 20) anthro- 
pometr point do not show how well dens correspond- 
enc have gener to the whole face. thus, subject 
evalu be frequent perform [29] by visual 
inspect the qualiti of morph between face [4], [30]. 
In thi paper, we show how synthet 3D face (facegen 
modeller) can be use to quantit evalu dens cor- 
respond on a larg set of point (� 1; 000). use the 
present deform face model, we perform extens 
experi for landmark local (section 6.1) and 
face recognit (section 6.2) use real face from the 

frgcv2 [24] and bu3df [31] databases. result show 
that our algorithm outperform state-of-the-art application- 
specif algorithm in each of these areas. 

2 relat work 

exist 3D correspond techniqu can be group into 
descriptor based, model base and optim base [1]. 

descriptor base techniques. these techniqu match local 
3D point signatur deriv from the curvatures, shape 
index and normals. however, they be often highli sensit 
to surfac nois and sampl densiti [33] of the underli 
geometri [34]. more significantli for our purpose, the den- 
siti of correspond point be typic low result in cor- 
respond between a veri spars set of anthropometr 
landmarks. 

one of the earli works, in thi category, for establish 
dens correspond be propos by sun and abidi [30], 
[32] who project geodes contour around a 3D facial 
point onto their tangenti plane and use them a featur 
to match two surfaces. the approach, with minor modifica- 
tions, be employ by salazar et al. [35] to establish point 
correspond on 3D face in bu3df database. Lu and 
jain [36] present a multimod approach for facial featur 
extraction. use a face landmark model, the author 
detect seven correspond point on 3D face use 
shape index from rang imag and corner from inten- 
siti images. segundo et al. [37] combin surfac curvatur 
and depth relief curv for landmark detect in 3D face of 
the frgcv2 and bu3df databases. they extract featur 
from the mean and gaussian curvatur for detect five 
landmark in the nose and eye (high curvature) regions. 

creusot et al. [27] present a machin learn approach 
to detect 14 correspond landmark on 3D faces. they 
train multipl lda classifi on a set of 200 face and a 
landmark model use a myriad of local descriptors. each 
landmark detect be treat a a two class classif 
problem and the final result be fused. thi method work 
well for neutral express face of the frgcv2 and bospho- 
ru databases. peraki et al. [26] propos a method to detect 
landmark under larg pose variat use a statist 
facial landmark model (flm) for the full face and anoth 
two flm for profil view of the face. keypoint be 
detect use shape index and spin imag and then 
match on the basi ofminimumcombin normal pro- 
crust and spin imag similar distanc from all three 
flms. thismethodwa use to detect eight correspond 
in the frgcv2 and und ear databases. later, the author 
propos a techniqu [38] for fuse featur from 2D and 3D 
data to detect these landmarkswith good accuraci than [26]. 

some method have also be propos for gener 
spars correspond for 3D face recognit [44], [45], [46], 
[47]. however, these method be base on keypoint corre- 
spondenc that be repeat onli on the same identity. 

model base techniques. these approach creat a 
morphabl model use a spars set of correspond 
and then extend them to dens correspondences. 

employ a point distribut model coupl with 3D 
point signatur detection, nair and cavallaro [8] estim 
the locat of 49 correspond landmark on faces. they 
test their algorithm on 2,350 face of the bu3df [31] 

gilani etal.: dens 3D face correspond 1585 



databas and report a rather high mean landmark locali- 
zation error. 

blanz and vetter [29] propos a dens correspond 
algorithm use optic flow on the textur and the 3D cylin- 
drical coordin of the face point assum that the face 
be spatial aligned. they construct a 3D morphabl face 
model from 100 male and femal face each. An arbitrari 
face be chosen a a refer and the remain scan be 
regist to it by iter between optic flow base corre- 
spondenc and morphabl model fitting. one potenti pit- 
fall of the textur base dens correspond [29] be that 
facial textur be not alway consist with the underli 
3D facial morphology, e.g., the shape and locat of eye- 
brows. moreover, thi algorithm requir seven manual 
annot facial landmark for initialization. later, in [9], 
[39] the author use the 3dmorphablemodel for face recog- 
nition. experi be perform on onli 150 pair of 3D 
face [39] from frgcv2 database, although the total number 
of scan in the databas be 4,007. the semin work of blanz 
andvett [29]wa extend by paysan et al. [40] in the basel 
face model (bfm) which use an improv mesh registra- 
tion algorithm [41]. the author havemad their dens corre- 
spondenc model publicli avail which have enabl u to 
draw comparison with their model. 

passali et al. [42] propos an annot face model 
(afm) base on an averag facial 3D mesh. the model be 
creat by manual annot a spars set of anthropo- 
metric landmark [7] on 3D face scan and then segment 
it into differ annot areas. later, kakadiari et al. [43] 
propos elast registr use thi afm by shift the 
manual annot facial point accord to elast con- 
straint to match the correspond point of 3D target 
model in the gallery. face recognit be perform by 
compar the wavelet coeffici of the deform imag 
obtain from morphing. passali et al. [18] further 
improv the afm by incorpor facial symmetri to 
perform pose invari face recognition. however, the algo- 
rithm depend on detect of at least five facial landmark 
on a side pose scan. 

level set curv be evolv in [28] to automat 
extract seed point and correspond be establish 
by minim the bend energi between patch around 
seed point of differ faces. A morphabl model base on 
the dens correspond point be then fit to unseen 
queri face for transfer of correspondences. the accuraci of 
landmark local in thi method depend on the num- 
ber and accuraci of initi seed points. 

optim base techniques. these method optim 
an object function to find a map between fiduci 
points. non-rigid icp (nicp) be one such techniqu which 
formul deform registr a an optim prob- 
lem consist of a mesh smooth term and sever data 
fit term [41], [78]. these algorithm requir accur 
global initi point rang from 14 point [41] to 68 
point [77]. these point be either manual annot [29], 
[41] or detect automat use textur [77]. An exten- 
sion to thi method remov the need for fiduci point but 
assum a partial overlap of facial region [78], [79]. the 
align between two face be perform with a global 
rigid transform follow by per-vertex affin transfor- 
mation that bring the non-rigid shape into full alignment. 

such method be more suit for time vari deforma- 
tion of the same ident and often do not result in a bijec- 
tive (one-to-one) map of the vertices. booth et al. [77] 
construct a dens correspond model of sever face 
from a proprieti dataset by regist the scan to a tem- 
plate mesh use nicp algorithm [41] initi by 68 fidu- 
cial landmark detect use texture. bolkart et al. [80] 
present dens correspond a an optim prob- 
lem and use the minimum descript length (mdl) [11] 
a the object function. the author of method that be 
base on nicp [40], [41], [77], [78], [79] or other altern 
optim techniqu [80] have not report facial land- 
mark local results. hence, it be difficult to perform a 
direct object comparison with these methods. 

3 dens 3D face correspond 

the overal idea of our system for dens correspond 
between 3D face scans, be to begin with a set of automati- 
calli extract seed point that repres point match 
across all face in the dataset, and gradual densifi the set 
of matches. fig. 1 depict the overal flow of our system. 
here we give an overview of how thi proceeds, and then 
expand the detail in the section below. 

We first organ the face into a tree (section 3.1) base on 
similarity. We then seek a set of reliabl seed match 
(section 3.2) from which to begin an iter densif 
process. each iter of the densif process 
(section 3.3) begin by select the current best set of 
match (compris nq of the full set of nmatches) and form- 
ing a triangul of these points. take each edg of 
the result triangul in turn, we extract a narrow patch 

fig. 1. block diagram of the present dens 3D face correspond 
algorithm. 

1586 ieee transact ON pattern analysi and machin intelligence, vol. 40, no. 7, juli 2018 



center on the edg from a pair of face that be adjac 
in the tree. for each of these patch we find point of dis- 
tinctiv curvatur (section 3.4) - these will be new candi- 
date matches, or keypoint - and comput a 38-dimension 
descriptor of the local surfac around each keypoint. use 
constrain near neighbor we then determin point 
that match well between the pair of patch (i.e., their 
descriptor match and they be within a proxim thresh- 
old in the patch). We repeat thi process for all parent/ 
child pair throughout the tree, and elimin all keypoint 
that be not consist match throughout the tree. the 
remain keypoint that be success match across 
all face in the dataset be add to the current set of 
matches. At the end of one iteration, when we have cycl 
through all the triangul edges, we choos a new best 
set of nq match and repeat the process. 

onc the search for keypoint be exhausted, further corre- 
spondenc on facial area devoid of discrimin point 
be establish by first evolv level set curv and sam- 
pling equidist vertex (see section 3.6). featur vector 
of these vertex on the refer face be then match with 
the remain face to establish correspond a previ- 
ousli stated. 

the outcom of thi process be a set of dens corre- 
spond 3D face which we call the keypoint-bas 3D 
deform model (k3dm). 

3.1 preprocess and organ face 

the nose tip of a 3D face be detect automat follow 
mian et al. [67]. center a sphere at the nose tip , the face 
be cropped. the pose of the 3D face be iter correct to 
a canon form use the hotel transform [53]. next, 
hole be fill and nois be remov use the gridfit algo- 
rithm [76]. 

next,w pre-organis the face dataset into a graph (in fact, 
a tree) in which similar face be “close” to one another. let 
G ¼ ðvg; egþ be a direct graph where each node Vg be a 3D 
face F from the dataset and each edgeeg connect two node 
ðvi; vjþ of the graph. each edg of the graph hasweightw 

wðvi; vjþ ¼ 
bij þ bji 

2 
; (1) 

where bij be the amount of bend energi requir to 
deform face Fi to Fj and be measur use the 2D thin-plat 

spline model [48]. note that bij 6¼ bji and bii ¼ 0. since, the 
face be alreadi roughli aligned, their near neighbor 
point be take a approxim correspond for the 
purpos of calcul the bend energy. from G, we con- 
struct a minimum span tree P ¼ ðvt; etþ use 
kruskal’ algorithm. the node with the maximum number 
of child be take a the root node. 

the purpos of thi pre-organis be to increas the 
likelihood of find point match between pair of faces. 
A naiv approach would be to arbitrarili choos a singl (or 
average) face a refer and find it correspond to 
other in the dataset. but such an approach ignor the 
proxim between the face instanc and the global infor- 
mation underli the population. the process and a sam- 
ple graph be show in fig. 2. 

3.2 spars correspond initi 

We initi the correspond by first automat 
establish a spars set of seed points. We restrict these 
seed point to those that lie on the roughli ellipse-shap 
2D convex hull of the face, i.e., the 2d-hull when the 3D 
mesh be project into the x� y plane. We sampl these 
point at regular angular interv of d ¼ p=36 (see 
fig. 3), where the angl d be measur at the nose tip. 
there be of cours no guarante that in the finit resolu- 
tion mesh of the face there will be a point at an exact 
multipl of p=36, but for each face we choos the near 
point. thi yield a set of 72 3D seed point for each 3D 
face in the dataset which be use in the first iter of 
the triangul and densif process, a describ 
in the next section. 

3.3 triangul and geodes patch extract 

the main part of our algorithm be an iter that take the 
best set of match that have be establish to date, and 
grow the number of correspondences. for the first itera- 
tion, we use the spars set of correspond establish 
a in the previou section, while for subsequ iter 
we determin the best set of nq match from the full set of 
nmatch a describ in section 3.5. 

In each iteration, give nq correspond between N 
faces, we perform a 2D delaunay triangul of the mean 
x� y locat of the nq current best matches. thi triangu- 
lation be then use consist across all faces. We then 
pick a pair of parent/child node from the minimum span- 
ning tree P, Fj and fk. for both face in the pair, we extract 

fig. 2. the direct graphg ¼ ðvg; egþ (left) and the minimum span 
tree (mst)p ¼ ðvt; etþ (right) construct from five exampl imag of 
frgcv2. 

fig. 3. (a) vertic of the 2d-convex hull of the projection. (b) point 
sampl at angular interv of p=36. (c) initi spars correspond 
project on four ident of the frgcv2 dataset. 

gilani etal.: dens 3D face correspond 1587 



a narrow surfac patch S ¼ f½xi; yi; zi�t ; i ¼ 1; . . . ;mg � F, 
center on a geodes curv defin by each triangl 
edg (see fig. 4). for the sake of simplic we call thi a geo- 
desic patch. 

the (projected) length of the patch be the same a the 
length of the edge. the “narrow” width be set with refer 
to the scale of the origin face mesh resolution. more specif- 
ically, we set the width to be 5r where r be the averag 
mesh-edg length in the vicin of the endpoint of the edg 
(note that here the mesh-edg refer to the edg in the orig- 
inal dataset, not the edg of the triangul use for the 
densification). thi make the extract of the geodes 
patch scale invariant. the valu of r for real 3D face cap- 
ture with the minolta or the 3dmdface scanner typic 
rang from 1-3 mm. 

finally, we bring the patch sj;sk into approxim 
align use non-rigid registr [49], [50]. the pro- 
ce be show in fig. 4. 

3.4 keypoint detect on geodes patch 

our aim now be to establish accur correspond 
between a patch on one face Sj and it correspond patch 
on the other face sk. We do thi in a fairli standard manner 
by find distinct keypoints, gener a descriptor of 
the local surfac around each point, and establish 
match between point on each patch whose descriptor 
be suffici close. 

more specifically, to find keypoint we consid the sur- 
face distinct at each point in the patch. We do so by 
calcul the covari of all the point within a neigh- 
borhood of 5r of the current point, and mark a key- 
point ani point for which the ratio of the larg two 
eigenvalu of the covari exce a threshold. note that 
if the neighborhood be uniform these eigenvalu will be 
equal, and therefor the point be unsuit a a keypoint. 

fig. 5 show keypoint detect by our algorithm in the 
tenth iter on four differ ident of the frgcv2 
database. 

We use the keypoint detect on surfac patch Sj for 
featur extract and match onli if an adequ number 
of keypoint be detect (we use a minimum of three), oth- 
erwise, Sj be not consid to be suffici descript 
and the match be not sought within the patch. 

3.5 featur extract and match 

We denot by ccj ¼ ½xi; yi; zi�t ; i ¼ 1; . . . ; nC the set of key- 
point detect on the surfac sj, where nC be the number 
of keypoint (likewis for cck). for each keypoint we extract 
a featur vector x which describ the local surfac (within 
5r) use a set of 3D signatur and histogram base descrip- 
tors. these descriptor have be wide use in the litera- 
ture [27], [51], [52] for automat object recognit and for 
landmark detection. We use a combin of mani descrip- 
tor sinc the surfac patch be quit small and a singl 
descriptor may not captur suffici information. the list 
of descriptor be give below: 

� the spatial locat ½xi; yi; zi�t . 
� the surfac normal ½nx; ny; nz�t . 
� the seven invari moment [53] of the 3 3 histo- 

gram of thexy; YZ andxz planes. 
� the central moment mmn of order mþ n of the histo- 

gram matrixh 

mmn ¼ 
X’ 
i¼1 

X’ 
j¼1 

ði� �iþmðj� �jþnhði; jþ; (2) 

where ’ be the total number of point in H, 
�i ¼ p’i¼1 p’j¼1 ihði; jÞ and �j ¼ p’i¼1 p’j¼1 jhði; jþ. 

� the mean of the two principl curvatur �k1 and �k2 
calcul at each point on the extract local surfac 

� the gaussian curvaturek ¼ k1k2 
� the mean curvatur H ¼ k1þk22 
� the shape index. We use two variant of the shape 

index which vari from 0 to 1 and �1 to 1 
respectively, 
sa ¼ 12 � 1p arctan k1þk2k1�k2 ; 0 � sa � 1 and 
sb ¼ 2p arctan k1þk2k1�k2 ; �1 � sb � 1. 

� the curved c ¼ 
ffiffiffiffiffiffiffiffiffiffi 
k2 
1 
þk2 

2 
2 

q 
� the log-curved 

cl ¼ 2p log 
ffiffiffiffiffiffiffiffiffiffi 
k2 
1 
þk2 

2 
2 

q 
, 

� the willmor energi ew ¼ H2 �k, 
� the shape curved c ¼ sb:cl 
� the log differ mapml ¼ lnðk �H þ 1þ. 
use these descriptors, the dimension of the final 

featur vector x be 38. these featur be extract over a 
small enough local surfac center at the keypoint such 
that they be repeat across identities. In contrast, the fea- 
ture vector extract by mian et al. [44], [54] take the rang 
valu of a larg surfac (typic 20 mm radius) sur- 
round each keypoint. hence, their featur be repeat- 
abl onli over the same identity. one of the prerequisit of 
the techniqu that use depth valu a featur [44], [51], 

fig. 4. illustr of geodes patch extraction. (a) two 3D face with tri- 
angul over a few correspond point from the 2nd iteration. geo- 
desic surfac patch be extract between two sampl point show in 
red colour. (b) pointcloud of the geodes surfac patch befor and 
after registration. 

fig. 5. illustr of keypoint (not correspond points) detect along 
geodes patch in the tenth iter of our algorithm. notic the 
repeat of keypoint across the identities. 

1588 ieee transact ON pattern analysi and machin intelligence, vol. 40, no. 7, juli 2018 



[52], [54] be to defin a local refer frame for pose invari- 
ant matching. In our case, the featur be quasi pose invari- 
ant and henc do not requir a local refer frame. thi be 
becaus the pose of each train face have be iter 
correct to a canon form dure preprocess and the 
featur be extract from a veri small patch. 

next, we perform constrained-nn search between the 
featur vector xj from Sj and xk from sk, such that the cor- 
respond point lie within a proxim of 2r to each other, 
and their match score dðxj; xkþ - take to be euclidean 
distanc between their featur descriptor - be less than a 
threshold kq. the qualiti of correspond vari directli 
with kq. higher valu of kq will result in poor correspond- 
ing point with larg errors, wherea low valu of kq may 
reject valid correspond and henc advers effect the 
correspond density. fig. 6 show the effect of kq on the 
correspond found in our experi on the synthet 
dataset. As we increas the valu of kq, the mean localiza- 
tion error and it standard deviat (sd) increases. fig. 7 
show the outcom of thi step on two identities. 

thi process be repeat for all surfac patch in a pair 
of faces, and for all pair of face in the mst. onli point 
that be match throughout the mst in the pairwis 
scheme be retain and these be add to the set of cor- 
respond obtain for the previou iteration. We then 
select from the full set of correspond those which 
have the small match score dðxj; xkþ. We denot the 
number of select correspond by nq and use a valu 
of nq ¼ 80 in our experiments. In order to adequ cover 

the whole face for the subsequ iteration, we add 
the origin seed point to the nq points. next, we obtain 
a triangul of these point on the mean face of the 
dataset and extract geodes surfac patch a describ 
in section 3.3, repeat the process. 

3.6 densifi match in uniform region 

keypoints, by their veri definit concentr around 
region of high curvature/discrimination, such a the 
mouth, nose, and eyes. In thi section we describ how we 
establish correspond in more uniform region where 
keypoint cannot be found. A simpl approach to establish 
dens correspond in these area would be to sampl 
them uniformli within triangl of the delaunay triangula- 
tion. thi approach have be use in 2D by munsel 
et al. [55] who pre-organ the shape instanc base on a 
similar measur and then establish correspond 
between pair of shape by map the point from the 
sourc instanc to the target instanc after minim a 
bend energy. however, a uniform sampl in the trian- 
gle onli result in uniform sampl on the face in planar 
regions. instead, we adopt a sampl strategi that respect 
the underli surfac distanc (geodesics) on each face. 

after triangul of the final set of best qualiti corre- 
spond points, we select larg triangl with area great 
than ta. We set ta to be the mean area of all triangl in the 
connectivity, an effect and expediti choice. from the 
centroid of each triangle, we evolv a level-set curve, in 
which the front speed be set to be uniform along a (radial) 
geodesic. for conveni we refer to these curv a “level- 
set geodesics”. We follow the fast march method [56] 
and use the implement give by peyr [57]. We then 
sampl the point along the curv at regular interv to 
ensur equidist point (see fig. 8). becaus the evolut 

fig. 6. the effect of correspond qualiti threshold kq in the synthet dataset in the first iteration. (left) graph of kq versu the mean and SD of 
correspond local error. (middle) kq versu the number of correspond established. (right) kq versu the maximum local error. 
for all our experi we have set kq ¼ 2r show in the graph in a magenta circle. 

fig. 7. correspond establish in 1st, 4th, 13th and 18th iter of 
our algorithm on the first two ident of frgcv2. notic how well the 
point correspond across the identities. 

fig. 8. correspond establish on smooth surfaces. two face 
from an order pair with triangul over nq best qualiti correspond 
points. blue dot indic the centroid of larg triangles. level set base 
evolut of geodes curv for the two sampl triangles, magnifi on 
the right. 

gilani etal.: dens 3D face correspond 1589 



speed of the curv be uniform along geodesics, we obtain 
a uniform sampl on the surface; thi be in contrast to 
uniform sampl within the triangl which would not nec- 
essarili be uniform on the surfac itself. although these 
point be not keypoints, they be repeat on all 3D face 
across ident becaus they be extract from triangl 
whose vertex be correspond to each other across the 
dataset. furthermore, these point be extract at equal 
interv over a small regionwhich be smooth. 

given thi set of point sampl uniformli on the sur- 
face, we extract featur vector and perform pairwis 
match a before. point whose featur vector be close 
enough be retain a matches, with the rest discarded. 
thi be not an iter process and point be sampl onli 
onc from each triangl meet the threshold criterion. 
fig. 8 visual illustr the process. 

An altern method for densifi the match in the 
uniform region could be to regist the sourc and target 
face use the nicp algorithm [41], [78] initi by the 
correspond establish in the previou section. onc 
the target face have deform to the sourc face, densif 
of correspond be achiev by map the vertex in 
uniform region of the sourc face to that of the target face. 
thi approach requir tweak the nicp paramet and 
the iter optim process for non-rigid face defor- 
mation tend to be comput expensive. our result 
in section 6.1 also show that our featur match approach 
achiev high accuraci and therefore, we use thi 
approach for the remain part of the paper. 

4 k3dm fit and augment 

the output of the dens correspond algorithm be the set of 
N dens correspond 3D face efj. our object now be to 
develop a compact deform model base on these dens 
correspond faces. To do so we take a standard pca-bas 

approach, and we call the result our keypoint-bas 3D 

deform model. more formally, let �� ¼ ½ef1;ef2; . . . ; efn; �, 
where ef ¼ ½x1; . . . ; xp; y1; . . . ; yp; z1; . . . ; zp�t and p ¼ 1; . . . ; P . 
the rowmeanmm� of the k3dm be give by, 

mm� ¼ 
1 

N 

XN 
i¼1 

efi: (3) 
the row-norm model m ¼ �� mm� can be model 

by a multivari gaussian distribut and it eigenvalu 
decomposit be give by, 

usvt ¼ ��m; (4) 
where US be the princip compon (pcs), the column 
of V be their correspond loadings, and S be a diagon 
matrix of eigenvalues. We use onli the first n column of U 
which correspond to 98 percent of the energy. 

We propos to deform the statist model give in (4) 
into a queri face Q in a two step iter process, i.e., regis- 
tration and morphing. algorithm 1 give the detail of fit- 
ting the deform model to a queri face. note that we use 
Q and M for the point cloud of the queri face and model 
and use q and m for their vector version respectively. 
the queri face after vector can be parametr by 
the statist model such that mi ¼ uaai þ mm�, where the 

vector aai contain the paramet which be use to vari 
the shape of the model in the ith iter and mi be the vec- 
toriz form of the model repres the queri face. In 
the initi step aai be set to zero and the deform 
model Mi be character by the mean face of the k3dm. 
each iter begin with a registr step where the 
input face Q be regist to the model mi. thi step essen- 
tialli entail find an approxim correspond 
between the model and the queri face and a rigid transfor- 
mation. correspond be establish by search for the 
nearest neighbor (nn) of each point of Mi in Q use the 
k-d tree data structur [58]. let d repres the NN euclid- 
ean distanc between the correspond queri face and the 
model such that dj ¼ kfqji �mijk2. We defin outlier a 
point on eQ whose NN distanc with Mi be great than a 
threshold tc where tc ¼ dþ 3sd and exclud them from reg- 
istration. thi step ensur that the outlier do not affect the 
registr process. next, the queri face be translat to the 
mean of the model and be rotat to align with mi. We 
denot the correspond and regist queri face byqr. 

In the next step, the modelmi be deform to fit the regis- 
tere queri faceqr such that, 

âai ( min 
aai 

U 
aai þ mm� � qr 
�� �� 

2 
þ�kaai � aai�1k2; (5) 

andmi ¼ uâai þ mm�. the 
denot that onli those point (row 
ofu andmm�) be consideredwhich satisfi the threshold tc. the 
second term in (5) put a constraint on deform the model. 
the appli condit be intuit becaus we want to partial 
deform themodel in each iter such that themodel approx- 
imat the queri face in small steps. the iter procedur be 
termin when the residu error kmi � qrk2 � �f . In all of 
our experi � be set to 0.8 and �f ¼ 10�4. fig. 9 show 
the k3dmfit result on three datasets. 

algorithm 1. k3dm fit 

require: �m�m ¼ ½ef1;ef2; . . . ;efn � � mm� and queri face 
Q ¼ ½xp; yp; zp�t where p ¼ 1; . . . ; pq. 

initialization: 
1: iteration: i ¼ 0 and �0 ¼ 1 
2: usvt ¼ ��m 
3: aai ¼ 0 andmi ¼ uaai þ mm� 
4: while �i > �f do 
5: updat iteration: i ¼ iþ 1 
6: eQ ¼ q(mi (nn use k-d tree) 
7: eq0 ¼ feqkeqi �mik2 < dþ 3sdg 
8: Qr ¼ eq0rþ t (registr step) 
9: U 
( {uk row of U correspond to eq0} 
10: âai(minaai U 
aai þ mm� � qr 

�� �� 
2 
þ�kaai � aai�1k2 

11: mi ¼ uâai þ mm� 
12: �i ¼ kmi � qrk2 
13: end while 
14: return qr; âa;m 

from a practic perspective, there be usual a need to 
augment an exist dens correspond model with new 
3D faces. In the following, we present a k3dm augmenta- 
tion algorithm to achiev thi objective. given the k3dm 
and a batch of M new 3D faces, we comput the bend 
energi requir to deform the mean face of the k3dm to 

1590 ieee transact ON pattern analysi and machin intelligence, vol. 40, no. 7, juli 2018 



each of the new faces. thi inform be employ to orga- 
nize them face in a minimum span tree a outlin in 
section 3.1. travers from the root node (mean face), the 
k3dm be morph into each child node use the model fit- 
ting procedur give in algorithm 1. the result corre- 
spond 3D face of the input ident be add to the 
k3dm. algorithm 2 give the detail of our model augmen- 
tation technique. 

algorithm 2. k3dm augment 

require: �� ¼ ½ef1;ef2; . . . ;efn � and a batch of input 3D face 
FM ¼ ff1; f2; . . . ; fmg,m � 1. 

initialization: 
1: pre-organ the M face in a minimum span tree 

P ¼ ðvt; etþ 
2: for each 3D face fi in P do 
3: efi ¼ fit k3dmð��; fiþ 
4: �� ¼ ½ef1;ef2; . . . ;efn;efi� 
5: increment number of face in the model 
6: mm� ¼ 1N 

PN 
n¼1 n 

7: end for 
8: return �� ¼ ½ef1;ef2; . . . ;efnþm � 

5 experiment setup 

We have carri out extens experi on synthet and 
real data. below be the detail of the dataset used, evalua- 
tion criterion and the experi performed. 

5.1 dataset use 

our synthet dataset consist of 100 3D face gener 
from the facegen software.1 facegen have be use by sci- 
entist in the field of neurosci and social cognit to 
gener synthet face for replic human stimulu [59], 
[60]. the 100 face be in perfect correspond with each 
other and henc provid the ground truth. each face have 
3,727 vertex and 7,179 triangles. for experi on real 
3D faces, we use the frgcv2 [24], bosphoru [25], 
bu3df [31] and side pose scan of the und ear databas 
collect F [61] and G [62]. some sampl imag and 
detail of these dataset be give in fig. 10. the purpos of 
use such divers dataset be to evalu the perfor- 
manc of our propos techniqu for partial data, occlusion, 
express and pose invariance. 

5.2 evalu criteria 

fig. 11 show qualit result of our dens correspon- 
denc algorithm. the smooth transit between differ 
face be indic of accur correspond [4], [20]. We 
have includ a video of morph in the supplementari 

material, which can be found on the comput societi digi- 
tal librari at http://doi.ieeecomputersociety.org/10.1109/ 
tpami.2017.2725279. 

object evalu of dens correspond algorithm 
on real data be difficult due to the unavail of the 
ground-truth shape correspond [63]. one solut be to 
use synthet data where correspond be know a pri- 
ori. We use the synthet 3D face dataset a ground truth 
for our evaluations. To the best of our knowledge, thi be the 
first time synthet 3D face imag have be use to evalu- 
ate result of a dens correspond algorithm in term of 
mean local error of the correspondences. thi dataset 
and protocol be also use to evalu the efficaci of indi- 
vidual modul of our algorithm. 

In the case of real data, the accuraci of the dens corre- 
spondenc can be measur togeth with the deform 
model fit algorithm by measur the accuraci of land- 
mark local and face recognition. result be expect 
to be good when the underli model have accur 
dens correspondences. hence, we use our dens corre- 
spondenc model and fit algorithm in these applica- 
tion and evalu the results. In all tables, we have 
highlight the best and the second best result in that cate- 
gory. note that the main focu of thi paper be to propos a 
dens 3D face correspond algorithm. experi on 
landmark local and face recognit have be car- 
rie out to valid the accuraci of the correspondences. 

We creat separ dens correspond model from 
the frgcv2, bosphoru and bu3df dataset and denot 

fig. 9. k3dm fit result on three datasets. the first scan for each 
dataset be the raw input while the second scan be the fit model. the 60 
degre side pose scan have be rotat to highlight the partial data. 

fig. 10. sampl imag and detail of our four experiment datasets. 

fig. 11. qualit result of our dens correspond algorithm on 
the first three ident of frgcv2. the first face in each row be the 
sourc and the last face be the target.1. singular inversions, “facegen modeller”, www.facegen.com 

gilani etal.: dens 3D face correspond 1591 

http://doi.ieeecomputersociety.org/10.1109/tpami.2017.2725279 
http://doi.ieeecomputersociety.org/10.1109/tpami.2017.2725279 
www.facegen.com 


them with k3dmfr, k3dmbo and k3dmbu respectively. 
We compar our result to the basel face model (bfm) 
propos by paysan et al. [40]. We also establish dens cor- 
respond use our nicp variant for densifi the 
initi keypoint base featur match (see section 3.6). 
the algorithm be initi by the correspond found 
in section 3.5 and the variant be refer a k3dm-nicp. 

6 result and analysi 

6.1 landmark local 

synthet dataset. first, we present the evalu of our 
algorithm on synthet data. We establish dens correspon- 
denc on 100 synthet 3D face use our propos algo- 
rithm and report the mean and the standard deviat 
(sd) of the local error with respect to the ground 
truth. the origin synthet dataset contain 3,727 vertex 
for each 3D face. our propos method be success in 
establish dens correspond over 2,246 vertex (60 
percent of the original) with a mean local error of 
1:28 mm and SD �2:2 mm. correspond within 10 mm 
be establish on 99:33 percent vertices. fig. 12a show a 
plot of the cumul distribut of correspond 
within a give error distance. We also establish dens cor- 
respond over 2,341 vertex of the synthet dataset 
use our k3dm-nicp variant (see section 3.6). that 
method result in a mean local error of 1:30 mm 
with �2:3 mm standard deviation. 

To ascertain the contribut of differ components, we 
repeat our experi by remov differ compon 
(see fig. 1) from our algorithm. the result in tabl 1 show 
that the combin of all components/modul give the 
best results. 

frgcv2 dataset. We construct a dens correspond 
k3dm from the first neutral scan of the first 200 identi- 
tie (100 male and femal each) of thi dataset. the 

remain 1,956 scan of 266 ident be use a test 
data. next, we construct a k3dm from the neutral scan 
of the next 200 ident (100 male and femal each) and 
use the 2,051 scan correspond to the first train set 
for testing. thi way, we be abl to perform landmark 
detect on all 4,007 scan of frgcv2, each time ensur- 
ing that the ident use for make the k3dm be not 
present in the test data. 

We establish dens correspond between 9,309 verti- 
ce on the frgcv2 dataset (k3dmfr) and report the mean 
and SD of the landmark local error (�l) on 14 fidu- 
cial point consid to be biolog signific [65]. 
these anthropometr landmark be annot onli on the 
mean face and transfer to each dens correspond 
scan in the dataset. manual annot provid by 
szeptycki et al. [66] and creusot et al. [27] be use a 
ground truth for comparison. 

A comparison of the mean and SD of landmark localiza- 
tion error of our propos algorithm with the state-of-the- 
art in tabl 2 show that our result outperform them by a 
signific margin. k3dmbu be construct from 100 neu- 
tral express scan and 100 angri express level-1 
scans. k3dmbo be construct from the first neutral scan 
of 105 identities. the k3dmfr achiev the best perfor- 
manc and even the cross domain k3dm and the k3dm- 
nicp variant outperform exist state-of-the-art. cumula- 
tive local error plot use k3dmfr be show 
graphic in fig. 12b. 

bosphoru dataset. We construct two k3dmbo (100 face 
each) from the neutral scan of the bosphoru dataset [25] 
such that the model and test ident be mutual exclu- 
sive. note that there be 299 neutral express scan in the 
dataset. We manual annot 14 fiduci landmark on the 
mean face of k3dm and transfer the inform to other 
scan after model fitting. fig. 12c show the cumul 
detect rate of the 14 landmarks. tabl 3 detail landmark 
local result on the three categori of the bosphoru 
dataset. It be evid that our algorithm perform signifi- 
cantli good than the state-of-the-art under occlusions, 
rotat and express variation. creusot et al. [27] and 
sukno et al. [64] train their algorithm on 99 neutral 
scans. they do not report result on these 99 scan and 
the scan with yaw rotat of �90�. On the contrari we 
report the landmark result on all 4,666 scan of the 
databas includ the scan with larg yaw variation. 
landmark annot provid by [25], [27] be use a 
ground truth. for thi experiment, k3dmfr be creat 
from the neutral scan of first 100 male and femal (each) 

fig. 12. result of dens correspondence: (a-d) cumul local error distribut plot on the synthet (2,246 vertices), frgcv2 (14 land- 
marks), bosphoru (14 landmarks) and bu3df (12 landmarks) datasets. 

tabl 1 
modul wise mean and SD of local error 
(mm) on 2,246 vertic of the synthet dataset 

exclud module(s) mean � std 
organis face into a graph 2.16 � 2.8 
keypoint detect 3.06 � 5.1 
featur match 3.61 � 6.8 
keypoint detect and featur match 4.78 � 7.3 
select best match in each iter 2.61 � 3.4 
No modul exclud 1.28 � 2.2 

1592 ieee transact ON pattern analysi and machin intelligence, vol. 40, no. 7, juli 2018 



ident of frgcv2 while k3dmbu be the same a use 
in experi on frgcv2 dataset. 

bu3df dataset. We construct dens correspond 
model from the neutral a well a intens level-1 anger 
express scan of 100 ident of the bu3df data- 
set [31]. We ensur mutual exclus test and train 
ident while landmark local use a k3dmbu . 
compar result on 12 anthropometr landmark [7] on 
all 2,500 scan of the dataset be give in tabl 4. ground 
truth landmark locat be provid with the dataset [31]. 

fig. 12d show the commut error detect rate of the 
12 landmarks. k3dmfr be creat from the scan of the 
first 100 male and 100 femal ident of frgc. our result 
be good than the state-of-the-art for both the models. 

und ear dataset. To evalu the landmark local 
perform of our algorithm on side pose scan contain 
self occlusions, we perform experi on the und ear 
databas [61], [62]. We follow the exact protocol outlin 
by [18], [38] for a fair comparison. the dataset be divid into 
45 and 60 degre left and right pose scan name db45l, 

tabl 2 
compar result of the mean and SD (mm) of landmark local error on frgcv2 dataset 

author imag ex(l) ex( R ) en(l) en( R) N prn ac* ch* Ls Li Pg Sn mean 

Lu [36] 676 9.5 � 17.1 10.3 � 18.1 8.2 �17.2 8.3 � 17.2 - 8.3 � 19.4 - 6.1 � 17.4 - - - - 8.1 � 17.7 
segundo [37] 4007 - - 3.7 � 2.3 3.4 � 2.3 - 2.8 � 1.4 5.3 � 1.9 - - - - 4.1 � 1.9 
peraki [26] 975 5.6 � 3.1 5.8 � 3.4 4.2 � 2.2 4.4 � 2.5 - - 4.1 � 2.2 5.5 � 2.4 - - 4.9 � 3.7 - 5.0 � 2.7 
cruesot [27] 4007 5.9 � 3.1 6.0 � 3.0 4.3 � 2.4 4.3 � 2.0 4.2 � 2.0 3.4 � 2.0 4.8 � 3.6 5.5 � 3.5 4.2 � 3.2 5.5 � 3.9 7.3 � 7.4 3.7 � 3.1 5.0 � 3.3 
peraki [38] 975 4.7 5.4 4.0 4.1 3.7 4.3 - 4.1 - - 4.3 

sukno [64] 4007 4.7 � 2.7 4.6 � 2.7 3.5 � 1.7 3.6 � 1.7 2.5 � 1.6 2.3 � 1.7 2.6 � 1.4 3.9 � 2.8 3.3 � 1.8 4.6 � 3.4 4.9 � 3.5 2.7 � 1.1 3.5 � 2.4 
gilani [28] 4007 4.5 � 2.9 3.7 � 2.8 3.1 � 2.1 2.7 � 2.1 3.6 � 2.0 2.7 � 2.5 4.2 � 3.2 4.8 � 2.1 3.3 � 3.7 4.0 � 3.8 4.2 � 3.3 4.1 � 3.1 3.9 � 2.8 
bfm [40] 4007 2.2 � 2.5 2.7 � 1.8 2.5 � 2.1 2.9 � 2.2 3.2 � 2.2 2.3 � 2.0 8.3 � 2.9 2.6 � 2.9 2.6 � 2.2 3.8 � 3.7 4.2 � 3.8 3.8 � 3.6 3.7 � 2.7 
k3dm-nicp 4007 2.8 � 2.2 2.5 � 1.8 2.7 � 1.8 2.6 � 1.1 2.6 � 1.7 2.4 � 1.9 3.3 � 2.5 2.7 � 1.8 2.6 � 3.2 4.2 � 3.4 4.2 � 3.3 3.5 � 1.4 3.3 � 2.3 
k3dmfr 4007 2.6 � 2.1 2.4 � 1.7 2.4 � 1.6 2.4 � 0.9 2.5 � 1.5 2.2 � 1.8 3.0 � 2.4 2.5 � 1.8 2.4 � 3.1 4.1 � 3.3 4.1 � 3.3 3.4 � 1.1 2.9 � 2.1 
k3dmbu 4007 2.7 � 2.4 2.3 � 1.9 2.4 � 1.9 2.5 � 1.8 2.8 � 1.8 2.6 � 1.8 6.1 � 2.7 4.2 � 3.1 2.9 � 3.3 4.6 � 3.9 4.1 � 3.4 3.6 � 2.9 3.6 � 2.6 
k3dmbo 4007 2.6 � 2.2 2.4 � 1.9 2.8 � 2.0 2.9 � 2.0 3.2 � 2.2 2.3 � 2.1 8.3 � 3.4 3.1 � 2.7 2.5 � 2.4 3.5 � 3.7 4.1 � 3.9 3.8 � 3.6 3.8 � 2.7 

* result have be averag for left and right corner of nose and mouth. 
A ‘-’ denot that the author have not detect thi particular landmark. ex/en-outer/inn eye corner, n-nosebridg saddle, prn-nosetip, ac-nos curvature, ch- 
mouth corner, ls/li upper/low lip midpoint, pg-chintip, sn-nasal base. 

tabl 3 
comparison of landmark local result with the state-of-the-art on bosphoru dataset 

mean of local error (mm) 

author imag ex(l) ex( R ) en(l) en( R) N prn ac(l) Ac ( R) ch( L) ch( R) Ls Li Pg Sn mean 

E 
x 
p 
re 
s 
io 
n cruesot et al. [27] 2803 6.20 4.10 5.09 4.18 6.33 4.47 4.22 4.07 4.06 8.00 7.66 5.36 8.83 15.23 6.27 

sukno et al. [64] 2803 5.19 4.92 2.94 2.76 2.22 2.33 3.03 3.01 6.12 6.03 4.00 6.54 7.58 2.81 4.25 
bfm [40] 2920 3.58 3.62 2.77 2.65 2.17 2.90 3.80 4.63 5.86 6.01 3.99 6.77 8.12 3.59 4.32 
k3dmbo 2920 3.57 4.01 2.35 2.40 2.32 2.82 2.50 2.99 4.85 4.91 3.32 5.03 6.02 2.35 3.53 

R 
o 
ta 
ti 
o 
n 

cruesot et al. [27] 1155 5.42 4.12 5.18 3.65 5.17 4.89 3.52 3.43 4.05 4.29 3.84 3.81 4.68 9.47 4.68 
sukno et al. [64] 1155 4.48 4.95 2.97 3.23 3.40 4.36 3.36 3.37 3.76 3.75 3.47 5.01 7.77 4.19 4.15 

bfm [40] 1365 4.63 4.96 5.30 5.16 3.81 5.08 4.81 5.49 4.49 5.28 5.43 6.40 7.10 3.14 5.08 
k3dmbo 1365 4.84 5.09 3.31 3.85 2.68 3.19 2.73 3.20 4.53 4.91 4.13 5.84 6.22 3.80 4.14 

O 
cc 
lu 
si 
o 
n cruesot et al. [27] 381 8.13 5.45 5.60 4.99 7.78 4.72 5.34 4.85 4.10 5.62 4.81 4.30 5.44 11.05 5.87 

sukno et al. [64] 381 6.63 6.28 3.82 3.87 4.12 3.83 4.40 4.67 4.75 5.07 3.61 4.81 7.63 3.76 4.80 
bfm [40] 381 4.95 4.42 3.96 3.52 2.49 3.32 4.57 4.77 3.61 3.75 3.36 4.40 5.54 2.45 3.94 
k3dmbo 381 4.64 4.51 3.10 2.95 2.69 3.18 2.55 3.01 4.36 4.22 2.89 4.14 5.00 2.90 3.58 

all 

cruesot et al. [27] 4339 6.09 4.18 5.14 4.08 6.10 4.60 4.15 3.94 4.05 6.83 6.37 4.81 7.35 13.20 5.78 
sukno et al. [64] 4339 5.13 5.05 3.03 2.98 2.70 3.00 3.24 3.25 5.37 5.34 3.82 5.98 7.63 3.26 4.27 

bfm [40] 4666 3.93 4.03 3.41 3.34 2.68 3.57 4.07 4.86 5.34 5.65 4.37 6.50 7.64 3.38 4.48 
k3dmbo 4666 3.94 4.15 2.62 2.80 2.46 2.96 2.55 3.04 4.73 4.86 3.53 5.21 6.01 2.75 3.70 
k3dmbu 4666 4.04 4.25 3.21 3.12 2.50 3.27 3.65 4.34 5.16 5.45 4.25 6.25 7.26 3.16 4.27 
k3dmfr 4666 4.13 4.27 3.33 3.24 2.60 3.51 3.91 4.61 5.26 5.56 4.32 6.43 7.48 3.26 4.42 

standard deviat of local error (mm) 

imag ex(l) ex( R ) en(l) en( R) N prn ac(l) Ac ( R) ch( L) ch( R) Ls Li Pg Sn mean 

all 

cruesot et al. [27] 4339 5.02 3.79 4.43 3.49 5.22 4.61 3.45 3.11 2.95 5.35 5.17 3.95 8.36 10.37 4.95 
sukno et al. [64] 4339 4.01 3.86 2.15 2.33 2.27 2.56 2.37 2.42 5.06 4.75 3.51 6.86 7.16 2.37 3.69 

bfm [40] 4666 2.84 2.97 3.30 3.60 2.58 3.44 2.63 2.86 4.23 4.22 3.93 6.76 6.98 3.09 3.82 
k3dmbo 4666 2.69 2.82 2.06 2.23 1.63 1.61 1.45 1.59 3.13 3.03 2.99 4.23 4.28 2.23 2.57 
k3dmbu 4666 2.87 3.01 2.98 3.17 2.42 3.04 2.36 2.56 4.01 3.99 3.75 6.13 6.20 2.88 3.53 
k3dmfr 4666 2.93 3.07 3.10 3.30 2.52 3.26 2.54 2.72 4.10 4.07 3.80 6.31 6.39 2.97 3.65 

gilani etal.: dens 3D face correspond 1593 



db45r,db60l anddb60r. thi be a veri challeng dataset 
due to larg yaw rotations, noisi scan and self occlusions. 
the dens correspond model be creat from 200 neutral 
express scan of frgcv2. eight landmark includ the 
two inner and outer eye corners, nose tip, mouth corner and 
chin tip be annot on the mean face of k3dmfr. the 
mean and SD of landmark local error for all 8 point be 
comparedwith the state-of-the-art in tabl 5. 

6.2 face recognit 

imag of face be consid to be one of the most impor- 
tant biometr becaus it can be do passiv and be 
highli distinct between individuals. 3D face recognit 
have address mani shortcom of it counterpart in the 
2D domain [67]. We consid thi applic apt to test the 
qualiti of the present algorithms. note that our main aim 
be to evalu our propos correspond and model fit- 
ting algorithm a oppos to present a face recognit 
system per se. 

frgcv2 dataset. We follow the frgcv2 protocol [24] of 
face recognit and includ onli one scan of each individ- 
ual (466 in total) in the gallery. To demonstr the effective- 
ness of our k3dm augment algorithm, we construct a 
dens correspond model on the first avail neutral 
scan of the first 200 ident of frgcv2 dataset. the con- 
struct model be then augment with first avail neu- 
tral scan of the remain 266 ident of the databas 
use algorithm 2. the probe set consist of the remain 
(3,541) scan of all identities. note that there be onli one 
scan per ident for 56 individu in the dataset. all of 
these ident appear onli in the gallery. the complet 
dataset be further classifi into “neutral” and “non- 
neutral” express subclass follow the protocol out- 
line in [44] to evalu the effect of express on 
deform model fit and face recognition. 

We employ a holist and region base approach to 
model fit and face recognition. It be well know that 
the gener of a model can be increas by divid- 
ing face into independ subregion that be morph 

independ [29]. thi techniqu have be use exten- 
sive for face recognit [9], [67] and recent for match- 
ing offspr to their parent [68]. We also use thi 
approach and perform face recognit by morph the 
complet face a well a the eye and nose region We 
defin these region on the mean face which be suffici 
to transfer the inform to all the face in the dens 
correspond model. 

the full k3dmfr and the eye and nose model be sepa- 
rate morph and fit to each queri face in the probe to 
obtain model paramet (a-step 12 in algorithm 1). next, 
the paramet from the whole face and the region be 
concaten to form the featur vector for face recognition. 
We then perform featur select use the gef algo- 
rithm [69], [70] on the train data set of frgcv2 contain- 
ing 953 facial scans. note that these scan be not use in 
test the face recognit algorithm. the select featur 
of each queri face be match with those of the galleri 
face in the model. the queri face be assign the ident of 
the galleri face with which it have the small distanc 

df ¼ co �1 eaatmeaaqkeaat 
M 
k2keaaqk2, where eaam be the select featur of 

each face in k3dm and eaaq be the select featur of the 
queri face. 

fig. 14 show the process of model fit in pca space. 
the dens correspond model be iter fit on the 
queri face, which in the figur be an extrem express scan 
of the first identity. the model fit start from the mean 
face and in each iter the fit queri model travers 
closer to it galleri face in the pca space. face recognit be 
perform when the fit residu error �f be less than 10 

�5. 
figs. 13a and b show the result cmc and roc curves. 
rank-1 identif rate for neutral probe be 99.85 percent 
while 100 percent accuraci be achiev at rank-8. In the 
more difficult scenario of neutral versu non-neutral, the 
rank-1 identif rate be 96.3 percent. A similar trend be 
observ in the verif rate at 0.1 percent far. tabl 6 

tabl 4 
comparison of landmark local result (mean � sd) with the state-of-the-art on bu3df dataset 

author imag ex(l) en(l) N ex( R ) en( R) prn Ac Ch Ls Li mean 

nair et al. [8] 2350 - 12.1 - - 11.9 8.8 - - - - 10.9 
segundo et al. [37] 2500 - 6.3 � 4.8 - - 6.3 � 5.0 1.9 � 1.1 6.6 � 3.4 - - - 4.4� 3.5 
salazar et al. [35] 350 9.6 � 6.1 6.8 � 4.5 - 8.5 � 5.8 6.1 � 4.2 5.9 � 2.7 6.8 � 3.2 - - - 5.9� 4.3 
gilani et al. [28] 2500 4.4 � 2.7 4.8 � 2.6 4.5 � 2.7 4.4 � 2.7 3.3 � 2.7 2.9 � 2.0 4.3 � 2.7 5.7 � 3.7 4.2 � 2.7 6.9 � 6.3 3.7� 3.1 
k3dmbu 2500 3.8 � 2.2 2.2 � 1.5 2.9 � 2.1 3.3 � 2.2 2.4 � 1.6 2.5 � 1.7 2.3 � 1.6 4.6 � 3.3 3.6 � 2.3 6.4 � 6.1 2.8� 2.5 
k3dmfr 2500 4.0 � 2.4 2.8 � 1.6 4.3 � 2.6 3.6 � 2.4 2.7 � 1.7 2.6 � 1.8 2.9 � 1.8 5.4 � 3.5 3.8 � 2.4 7.0 � 6.6 3.1� 2.7 

tabl 5 
compar landmark localis result 

(mm) on und side pose scan 

databas db45l db45r db60l db60r 

yaw est [26] �45� � 9� 44� � 8� �59� � 8� 57� � 7� 
# scan 118 118 87 87 
passali et al. [18] 6.02 � 2.45 5.83 � 2.49 6.08 � 2.53 5.87 � 2.4 
peraki et al. [26] 4.75 � 1.91 5.03 �1.92 5.30 �2.49 4.95 � 1.80 
k3dmfr 4.04 � 1.77 4.31 � 1.90 4.36 � 2.25 4.24 � 1.28 

fig. 13. (left) roc curv for identif and (right) verif task 
on frgcv2 databas use our dens correspond model and fit 
algorithms. 

1594 ieee transact ON pattern analysi and machin intelligence, vol. 40, no. 7, juli 2018 



compar our algorithm with the state-of-the-art. In most 
cases, our result be good than the state-of-the-art depict 
the high qualiti of the dens correspondencemodel. 

bosphoru dataset. experi be perform on the 
more versatil bosphoru dataset to demonstr the 
expression, pose and occlus invari face recognit 
capabl of our propos model. k3dmbo be form 
from the first avail neutral scan of each ident in the 
dataset and a holist approach to face recognit be 
adopted. We follow the model fit and paramet match- 
ing techniqu a mention for frgcv2. compar 
result be give in tabl 7. our propos techniqu signifi- 
cantli outperform the state-of-the-art in pose invari 
face recognition, while at the same time it handl expres- 
sion and occlusions. 

und ear dataset. We perform face recognit experi- 
ment on thi dataset to demonstr the abil of k3dm to 
handl pose variat and self occlusions. the dataset be 
divid into three subset follow the protocol set by [18]. 
und00lr contain 466 subject of frgcv2 in the gallery. 

two 45 degre side scan each (left and right) for 39 sub- 
ject and two 60 degre side scan each (left and right) for 
32 subject make the probe set. these subject be common 
between frgcv2 and und ear databases. und45lr be 
compos of 45 degre side scan from 118 subjects. the 
k3dmfr make from 200 scan be fit on the left side scan 
to get the galleri paramet and then fit to the right 
side scan to get the probe parameters. A similar protocol be 
follow for und60lr which contain 60 degre side 
scan from 87 subjects. compar rank-1 recognit 
result be give in tabl 8. note that while smeet 
et al. [45] report > 98 percent face recognit result on 
the side pose scan of thi dataset, their perform on 
pose variat in the bosphoru dataset be significantli 
low at 84.2 percent. 

cross domain face recognition. To compar k3dm with 
the state-of-the-art basel face model(bfm) [40] we perform 
cross domain face recognit experi on frgcv2 and 
bosphoru dataset a they includ all the challeng of 
expressions, occlus and pose variation. for frgcv2 we 
use k3dmbo (creat from 105 neutral scan of bosphoru 
database) and k3dmbu (creat from 100 neutral and 100 
angri level-1 scans) while for bosphoru dataset we use 
k3dmfr and k3dmbu . all three model be fit to each 
scan in frgcv2 and bosphoru datasets. the model param- 
eter of the first neutral scan of each ident in each data- 
base be use a galleri features. tabl 9 detail the rank-1 
recognit result from thi experi which show that 
k3dm outperform the bfm. 

fig. 14. iter model fitting. the 466 frgcv2 ident be show a 
red star in the first three PC space. the model be morph iter 
into the queri face until the residu error be negligible. notic how the fit- 
ting process take the queri face through a non-linear path (inset image) 
and remov the extrem facial express to gener it equival 
neutral express model. 

tabl 6 
comparison of 3D face recognit result with the 
state-of-the-art in term of rank-1 identif rate 

(i-rate) and verif rate (v-rate) at 0.1 percent far 

author neutral non-neutr all 

i-rat v-rate i-rat v-rate i-rat v-rate 

mian et al. [44] 99.4% 99.9% 92.1% 96.6% 96.1% 98.6% 
kakadiari et al. [43] - 99.0% - 95.6% 97.0% 97.3% 
al-osaimi et al. [71] 97.6% 98.4% 95.2% 97.8% 96.5% 98.1% 
queirolo et al. [72] - 99.5% - 94.8% 98.4% 96.6% 
drira et al. [73] 99.2% - 96.8% - 97.7% 97.1% 
smeet et al. [45] - - - - 89.6% 79.0% 
Li et al. [47] - - - - 96.3% - 
k3dmfr 99.9% 99.9% 96.9% 96.6% 98.5% 98.7% 

tabl 7 
comparison of rank-1 recognit result (in percentage) with the state-of-the-art on bosphoru dataset 

author 

express pose occlus 

all 4,543au expr all yr< 90 yr90 PR CR all eye mouth glass hair all 

2,150 647 2,797 525 210 419 211 1,365 105 105 104 67 381 

alyz et al. [74] - - - - - - - - 93.6 93.6 97.8 89.6 93.6 - 
colombo et al. [75] - - - - - - - - 91.1 74.7 94.2 90.4 87.6 - 
drira et al. [73] - - - - - - - - 97.1 78.0 94.2 81.0 87.0 - 
berretti et al. [46] - - 95.7 81.6 45.7 98.3 93.4 88.6 - - - - 93.2 93.4 
smeetset al. [45] - - 97.7 - 24.3 - - 84.2 - - - - - 93.7 
Li et al. [47] 99.2 96.6 98.8 84.1 47.1 99.5 99.1 91.1 100.0 100.0 100.0 95.5 99.2 96.6 
k3dmbo 99.0 96.7 98.5 99.8 95.2 100.0 99.1 99.0 99.0 96.1 100.0 97.3 98.1 98.6 

au=act units; yr=yaw rotation; pr= pitch rotation; cr= cross rotation. 

gilani etal.: dens 3D face correspond 1595 



7 discuss and conclus 

We have propos an algorithm that simultan estab- 
lish dens correspond between a larg number of 3D 
faces. base on the dens correspondences, a deform 
face model be constructed. We also propos morphabl 
model fit and updat algorithm that be use for 
landmark identif and face recognition. thorough 
experi be perform on synthet and real 3D faces. 
comparison with exist state-of-the-art show that our 
algorithm consist achiev good or compar perfor- 
manc on both the task on all datasets. It be interest to 
note that while the face recognit algorithm propos by 
Li et al. [47] perform well on bosphoru database, it do 
not fare that well on frgcv2. similar trend can be observ 
in case of smeet et al. [45] for face recognit and 
sukno et al. [64] for landmark localization. To the best of our 
knowledg thi be the first paper that have report consist 
compar result on a varieti of applic on four 
public datasets. 

although the dens correspond model assum 
frontal and neutral pose scans, for landmark local 
and face recognit it demonstr robust to occlus 
a well a pose and express variat dure the fit 
process. henc the three propos algorithm present a uni- 
fie solut to a varieti of applic under expression, 
occlus and pose variation. the model can handl pose 
variat up to �90�. 

with regard to the comput complexity, it may be 
note that the model build process have to be do off- 
line. the algorithm iter over geodes patch between 
vertex for each image. build a dens correspond 
model on 105 ident of bosphoru databas in approxi- 
mate 30 iter take over 48 hour on a core–i7 
machin with 8 GB ram use matlab. however, the 
model fit process on an unseen face take less than 
seven seconds. 

acknowledg 

thi research be support by arc discoveri grant 
dp110102399 and dp160101458. I. reid grate acknowl- 
edg the financi support of the australian research 
council through grant ce140100016 and fl130100102. 

refer 
[1] O. van kaick , H. zhang, G. hamarneh, and D. cohen-or, “A 

survey on shape correspondence,” comput. graph. forum, vol. 30, 
no. 6, pp. 1681–1707, 2011. 

[2] V. jain, H. zhang, and O. van kaick, “non-rigid spectral corre- 
spondenc of triangl meshes,” int. J. shape model., vol. 13 no. 1, 
pp. 101–124, 2007. 

[3] W. chang and M. zwicker, “automat registr for articu- 
late shapes,” comput. graph. forum, vol. 27, no. 5, pp. 1459– 
1468, 2008. 

[4] H. zhang, A. sheffer, D. cohen, Q. zhou, O. van kaick, and 
A. tagliasacchi, “deformation-driven shape correspondence,” 
comput. graph. forum, vol. 27, no. 5, pp. 1431–1439, 2008. 

[5] S. Z. gilani, K. rooney, F. shafait, M. walters, and A. mian, 
“geometr facial gender scoring: object of perception,” plo 
one, vol. 9, no. 6, 2014, art. no. e99483. 

[6] P. hammond, “the use of 3D face shape model in dys- 
morphology,” archiv diseas childhood, vol. 92, no. 12, pp. 1120– 
1126, 2007. 

[7] L. farkas, “anthropometri of the head and face in clinic 
practice,” in anthropometri of the head and face, 2nd ed. ann 
arbor, mi, usa: univ. michigan, 1994, pp. 71–111. 

[8] P. nair and A. cavallaro, “3-d face detection, landmark localiza- 
tion, and registr use a point distribut model,” ieee 
trans. multimedia, vol. 11, no. 4, pp. 611–623, jun. 2009. 

[9] V. blanz and T. vetter, “face recognit base on fit a 3D 
morphabl model,” ieee trans. pattern anal. mach. intell., vol. 25, 
no. 9, pp. 1063–1074, sep. 2003. 

[10] S. Z. gilani, A. mian, and P. eastwood, “deep, dens and accu- 
rate 3D face correspond for gener popul specif 
deform models,” pattern recognit., vol. 69, pp. 238–250, 
2017. 

[11] R. H. davies, C. J. twining, T. F. cootes, J. C. waterton, and 
C. J. taylor, “3d statist shape model use direct optimis 
of descript length,” inproc. eur. conf. comput. vis., 2002, pp. 3–20. 

[12] T. heimann and h.-p. meinzer, “statist shape model for 3D 
medic imag segmentation: A review,”med. imag anal., vol. 13, 
no. 4, pp. 543–563, 2009. 

[13] M. alexa, “recent advanc in mesh morphing,” comput. graph. 
forum, vol. 21, no. 2, pp. 173–198, 2002. 

[14] D. aiger, N. mitra, and D. cohen, “4-point congruent set for 
robust pairwis surfac registration,” acm trans. graph., vol. 27, 
no. 3, 2008, art. no. 85. 

[15] B. brown and S. rusinkiewicz, “global non-rigid align of 3-d 
scans,” acm trans. graph., vol. 26, no. 3, 2007, art. no. 21. 

[16] h.mirzaalian, g.hamarneh, and T. lee, “A graph-bas approach 
to skin mole match incorpor template-norm coor- 
dinates,” in proc. ieee conf. comput. vis. pattern recognit., 2009, 
pp. 2152–2159. 

[17] T. funkhous and P. shilane, “partial match of 3D shape 
with priority-driven search,” in proc. eurograph symp. geometri 
process., 2006, vol. 256, pp. 131–142. 

[18] G. passalis, P. perakis, T. theoharis, and I. A. kakadiaris, “use 
facial symmetri to handl pose variat in real-world 3D face 
recognition,” ieee trans. pattern anal. mach. intell., vol. 33, no. 10, 
pp. 1938–1951, oct. 2011. 

[19] U. prabhu, J. heo, andm. savvides, “unconstrain pose-invari 
face recognit use 3D gener elast models,” ieee trans. 
pattern anal. mach. intell., vol. 33, no. 10, pp. 1952–1961, oct. 2011. 

[20] V. kraevoy and A. sheffer, “cross-parameter and compati- 
ble remesh of 3D models,” acm trans. graph., vol. 23, pp. 861– 
869, 2004. 

[21] H. hochheiser, et al., “the facebas consortium: A comprehens 
program to facilit craniofaci research,” develop. biology, 
vol. 355, no. 2, pp. 175–182, 2011. 

[22] A. J. whitehouse, et al., “prenat testosteron exposur be relat 
to sexual dimorph facial morpholog in adulthood,” proc. roy. 
soc. B, vol. 282, no. 1816, 2015, art. no. 7. 

tabl 8 
compar of rank-1 recognit result on 

partial face of und side pose scan 

databas und00lr und45lr und60lr 

# scan 608 236 174 
passali et al. [18] 76.8% 86.4% 81.6% 
smeet et al. [45] - 98.3% 100.0% 
k3dmfr 86.0% 95.8% 98.6% 

tabl 9 
comparison of rank-1 recognit on frgcv2 and 
bosphoru dataset use cross domain model 

frgcv2 

method neutral express pose occlus all 

bfm [40] 87.7% 65.6% - - 76.4% 
k3dmbu 92.7% 69.0% - - 80.5% 
k3dmbo 92.1% 62.9% - - 77.1% 

bosphoru 

bfm [40] - 81.1% 86.1% 86.6% 82.7% 
k3dmfr - 85.6% 86.5% 89.3% 85.8% 
k3dmbu - 90.3% 92.8% 90.7% 90.7% 

1596 ieee transact ON pattern analysi and machin intelligence, vol. 40, no. 7, juli 2018 



[23] S. Z. gilani, et al., “sexual dimorph facial featur vari accord- 
ing to level of autistic-lik trait in the gener population,” J. neu- 
rodevelopment disorders, vol. 7, no. 1, 2015, art. no. 14. 

[24] P. phillips, et al., “overview of the face recognit grand 
challenge,” in proc. ieee comput. soc. conf. comput. vis. pattern 
recognit., 2005, pp. 947–954. 

[25] A. savran, et al., “bosphoru databas for 3D face analysis,” in 
proc. eur. workshop biometr ident manage., 2008, pp. 47–56. 

[26] P. perakis, G. passalis, T. theoharis, and I. A. kakadiaris, “3d 
facial landmark detect under larg yaw and express var- 
iations,” ieee trans. pattern anal. mach. intell., vol. 35, no. 7, 
pp. 1552–1564, jul. 2013. 

[27] C. creusot, N. pears, and J. austin, “A machine-learn 
approach to keypoint detect and landmark on 3D meshes,” 
int. J. comput.vis., vol. 102, no. 1–3, pp. 146–179, 2013. 

[28] S. Z. gilani, F. shafait, and A. mian, “shape-bas automat 
detect of a larg number of 3D facial landmarks,” in proc. ieee 
conf. comput. vis. pattern recognit., 2015, pp. 4639–4648. 

[29] V. blanz and T. vetter, “A morphabl model for the synthesi of 
3D faces,” in proc. acm conf. comput. graph. interact techn., 
1999, pp. 187–194. 

[30] Y. sun, J. paik, A. koschan, D. page, and M. abidi, “point fin- 
gerprint: A new 3D object represent scheme,” ieee trans. 
syst. man cybern. part B: cybern., vol. 33, no. 4, pp. 712–717, 
aug. 2003. 

[31] L. yin, X. wei, Y. sun, J. wang, and M. J. rosato, “A 3D facial 
express databas for facial behavior research,” in proc. 7th int. 
conf. automat face gestur recognit., 2006, pp. 211–216. 

[32] Y. sun and M. A. abidi, “surfac match by 3D point’ finger- 
print,” in proc. 8th ieee int. conf. comput. vis., 2001, pp. 263–269. 

[33] S. wang, Y. wang, M. jin, X. D. gu, and D. samaras, “conform 
geometri and it applic on 3D shape matching, recognition, 
and stitching,” ieee trans. pattern anal. mach. intell., vol. 29, 
no. 7, pp. 1209–1220, jul. 2007. 

[34] J. novatnack and K. nishino, “scale-dependent/invari local 
3D shape descriptor for fulli automat registr of multipl 
set of rang images,” in proc. 10th eur. conf. comput. vis., 2008, 
pp. 440–453. 

[35] A. salazar, S. wuhrer, C. shu, and F. prieto, “fulli automat 
expression-invari face correspondence,” mach. vis. appl., 
vol. 25, no. 4, pp. 859–879, 2014. 

[36] X. Lu and A. K. jain, “automat featur extract for multiview 
3D face recognition,” in proc. 7th int. conf. automat face gestur 
recognit., 2006, pp. 585–590. 

[37] M. segundo, L. silva, P. bellon, and C. C. queirolo, “automat 
face segment and facial landmark detect in rang 
images,” ieee trans. syst. man cybern. part B: cybern., vol. 40, 
no. 5, pp. 1319–1330, oct. 2010. 

[38] P. perakis, T. theoharis, and I. A. kakadiaris, “featur fusion for 
facial landmark detection,” pattern recognit., vol. 47, no. 9, 
pp. 2783–2793, 2014. 

[39] V. blanz, K. scherbaum, and h.-p. seidel, “fit a morphabl 
model to 3D scan of faces,” in proc. 11th ieee int. conf. comput. 
vis., 2007, pp. 1–8. 

[40] P. paysan, R. knothe, B. amberg, S. romdhani, and T. vetter, 
“A 3D face model for pose and illumin invari face recog- 
nition,” in proc. int. conf. adv. video signal base surveillance, 2009, 
pp. 296–301. 

[41] B. amberg, S. romdhani, and T. vetter, “optim step nonrigid 
icp algorithm for surfac registration,” in proc. ieee conf. com- 
put. vis. pattern recognit., 2007, pp. 1–8. 

[42] G. passalis, I. kakadiaris, T. theoharis, G. toderici, and N. mur- 
tuza, “evalu of 3D face recognit in the presenc of facial 
expressions: An annot deform model approach,” in proc. 
ieee comput. soc. conf. comput. vis. pattern recognit. workshops, 
2005, pp. 171–171. 

[43] I. A. kakadiaris, et al., “three-dimension face recognit in the 
presenc of facial expressions: An annot deform model 
approach,” ieee trans. pattern anal. mach. intell., vol. 29, no. 4, 
pp. 640–649, apr. 2007. 

[44] A. mian, M. bennamoun, and R. owens, “keypoint detect and 
local featur match for textur 3D face recognition,” int. 
J. comput. vis., vol. 79, no. 1, pp. 1–12, 2008. 

[45] D. smeets, J. keustermans, D. vandermeulen, and P. suetens, 
“meshsift: local surfac featur for 3D face recognit under 
express variat and partial data,” comput. vis. imag under- 
standing, vol. 117, no. 2, pp. 158–169, 2013. 

[46] S. berretti, N. werghi, A. del bimbo , and P. pala, “match 3D 
face scan use interest point and local histogram descriptors,” 
comput. graph., vol. 37, no. 5, pp. 509–525, 2013. 

[47] H. li, D. huang, j.-m. morvan, Y. wang, and L. chen, “toward 
3D face recognit in the real: A registration-fre approach use 
fine-grain match of 3D keypoint descriptors,” int. J. comput. 
vis., vol. 113, no. 2, pp. 128–142, 2014. 

[48] F. L. bookstein, “princip warps: thin-plat spline and the 
decomposit of deformations,” ieee trans. pattern anal. mach. 
intell., vol. 11, no. 6, pp. 567–585, jun. 1989. 

[49] D. rueckert, L. sonoda, C. hayes, D. L. G. hill, M. O. leach, and 
D. J. hawkes, “nonrigid registr use free-form deforma- 
tions: applic to breast MR images,” ieee trans. med. imag., 
vol. 18, no. 8, pp. 712–721, aug. 1999. 

[50] d.-j. kroon, “finit iter closest point,” matlab central 
file exchange, 2009, https://au.mathworks.com/matlabcentral/ 
fileexchange/24301-finite-iterative-closest-point 

[51] Y. guo, F. sohel, M. bennamoun, M. lu, and J. wan, “rotat 
project statist for 3D local surfac descript and object rec- 
ognition,” int. J. comput. vis., vol. 105, no. 1, pp. 63–86, 2013. 

[52] F. tombari, S. salti, and L. Di stefano, “uniqu signatur of histo- 
gram for local surfac description,” in proc. 11th eur. conf. 
comput. vis., 2010, pp. 356–369. 

[53] R. C. gonzalez and R. E. woods, digit imag processing, 2nd ed. 
upper saddl river, NJ usa: prentic hall, 2002. 

[54] A. mian, M. bennamoun, and R. owens, “on the repeat and 
qualiti of keypoint for local feature-bas 3D object retriev 
from clutter scenes,” int. J. comput. vis., vol. 89, no. 2/3, 
pp. 348–361, 2010. 

[55] B. C. munsell, A. teml, and S. wang, “fast multipl shape corre- 
spondenc by pre-organ shape instances,” in proc. ieee conf. 
comput. vis. pattern recognit., 2009, pp. 840–847. 

[56] J. A. sethian, “evolution, implementation, and applic of level 
set and fast march method for advanc fronts,” J. comput. 
physics, vol. 169, no. 2, pp. 503–555, 2001. 

[57] G. peyr�e, “the numer tour of signal processing-advanc 
comput signal and imag processing,” ieee comput. sci. 
eng., vol. 13, no. 4, pp. 94–97, jul./aug. 2011. 

[58] J. L. bentley, “multidimension binari search tree use for asso- 
ciativ searching,” commun. acm, vol. 18, no. 9, 1975, art. no. 509. 

[59] A. todorov, S. baron, and N. oosterhof, “evalu face trust- 
worthiness: A model base approach,” social cognit affect. neu- 
roscience, vol. 3, no. 2, pp. 119–127, 2008. 

[60] N. N. oosterhof and A. todorov, “the function basi of face 
evaluation,” proc. nat. acadmey sci. unit state america, vol. 105, 
no. 32, pp. 11087–11092, 2008. 

[61] P. yan and K. bowyer, “empir evalu of advanc ear bio- 
metrics,” in proc. ieee comput. soc. conf. comput. vis. pattern rec- 
ognit. workshops, 2005, pp. 41–41. 

[62] P. yan and K. W. bowyer, “an automat 3D ear recognit sys- 
tem,” in proc. 3rd int. symp. 3D data process. vis. transmiss., 2006, 
vol. 6, pp. 326–333. 

[63] B. C. munsell, P. dalal, and S. wang, “evalu shape corre- 
spondenc for statist shape analysis: A benchmark study,” 
ieee trans. pattern anal. mach. intell., vol. 30, no. 11, pp. 2023– 
2039, nov. 2008. 

[64] F. M. sukno, J. L. waddington, and P. F. whelan, “3-d facial land- 
mark local with asymmetri pattern and shape regress 
from incomplet local features,” ieee trans. cybern., vol. 45, no. 9, 
pp. 1717–1730, sep. 2015. 

[65] S. Z. gilani, F. shafait, and A. mian, “biolog signific facial 
landmarks: how signific be they for gender classification?” in 
proc. int. conf. digit. imag comput.: techn. appl., 2013, pp. 1–8. 

[66] P. szeptycki, M. ardabilian, and L. chen, “A coarse-to-fin curva- 
ture analysis-bas rotat invari 3D face landmarking,” in 
proc. ieee 3rd int. conf. biometrics: theori appl. syst., 2009, pp. 1–6. 

[67] A. mian, M. bennamoun, and R. owens, “an effici multimod 
2d-3d hybrid approach to automat face recognition,” ieee 
trans. pattern anal. mach. intell., vol. 29, no. 11, pp. 1927–1943, 
nov. 2007. 

[68] A. dehghan, E. ortiz, R. villegas, and M. shah, “who do I look 
like? determin parent-offspr resembl via gate 
autoencoders,” in proc. ieee conf. comput. vis. pattern recognit. 
workshops, 2014, pp. 171–171. 

[69] S. Z. gilani and A. mian, “perceptu differ between men 
and women: A 3D facial morphometr perspective,” in proc. 22nd 
int. conf. pattern recognit., 2014, pp. 2413–2418. 

gilani etal.: dens 3D face correspond 1597 

https://au.mathworks.com/matlabcentral/fileexchange/24301-finite-iterative-closest-point 
https://au.mathworks.com/matlabcentral/fileexchange/24301-finite-iterative-closest-point 


[70] S. Z. gilani, F. shafait, and A. mian, “gradient base effici fea- 
ture selection,” in proc. ieee winter conf. appl. comput. vis., 2014, 
pp. 191–197. 

[71] F. al-osaimi, M. bennamoun, and A. mian, “an express defor- 
mation approach to non-rigid 3D face recognition,” int. J. comput. 
vis., vol. 81, no. 3, pp. 302–316, 2009. 

[72] C. queirolo, L. silva, O. bellon, andm. segundo, “3d face recogni- 
tion use simul anneal and the surfac interpenetr 
measure,” ieee trans. pattern anal. mach. intell., vol. 32, no. 2, 
pp. 206–219, feb. 2010. 

[73] H. drira, B. ben amor, A. srivastava, M. daoudi, and R. slama, 
“3d face recognit under expressions, occlusions, and pose var- 
iations,” ieee trans. pattern anal. mach. intell., vol. 35, no. 9, 
pp. 2270–2283, sep. 2013. 

[74] N. alyuz, B. gokberk, and L. akarun, “A 3D face recognit sys- 
tem for express and occlus invariance,” in proc. ieee 2nd 
int. conf. biometrics: theori appl. syst., 2008, pp. 1–7. 

[75] A. colombo, C. cusano, and R. schettini, “three-dimension 
occlus detect and restor of partial occlud faces,” 
J. math. imag. vis., vol. 40, no. 1, pp. 105–119, 2011. 

[76] J. D erico, “surfac fit use gridfit,” matlab central 
file exchange, 2008, https://au.mathworks.com/matlabcentral/ 
fileexchange/8998-surface-fitting-using-gridfit 

[77] J. booth, A. roussos, S. zafeiri and D. dunaway, “A 3D morph- 
abl model learnt from 10,000 faces,” in proc. ieee conf. comput. 
vis. pattern recognit., 2016, pp. 5543–5552. 

[78] H. li, R. W. sumner, and M. pauly, “global correspond opti- 
mizat for non-rigid registr of depth scans,” comput. 
graph. forum, vol. 27, no. 5, pp. 1421–1430, 2008, 

[79] H. li, B. adams, L. J. guibas, and M. pauly, “robust single-view 
geometri and motion reconstruction,” acm trans. graph., vol. 28, 
no. 5, 2009, art. no. 175. 

[80] T. bolkart and S. wuhrer, “A robust multilinear model learn 
framework for 3D faces,” in proc. ieee conf. comput. vis. pattern 
recognit., 2016, pp. 4911–4919. 

[81] V. G. kim, Y. lipman, and T. funkhouser, “blend intrins 
maps,” acm trans. graph., vol. 30, no. 4, 2011, art. no. 79. 

sy zulqarnain gilani receiv the MS degre 
in EE from the nation univers of scienc 
and technolog (nust), pakistan, in 2009 and 
secur the president’ gold medal. He receiv 
the phd degre from the univers of western 
australia. hi research interest includ 3D facial 
morphometr with applic to syndrom 
delin and machin learning. 

ajmal mian be an associ professor of com- 
puter scienc at the univers of western aus- 
tralia. He have receiv sever award includ 
the west australian earli career scientist of the 
year award, the vice-chancellor mid-car 
research award and the outstand young 
investig award. He have receiv two presti- 
giou fellowship and seven major grant from 
the australian research council and the nation 
health and medic research council with total 
fund of $3.0 million. hi research interest 

includ comput vision, machin learning, 3D face analysis, human 
action recognit and remot sensing. 

faisal shafait current work a an associ 
professor at school of electr engin 
and comput scienc (seecs), nust, paki- 
stan. He be also an adjunct senior lectur at 
the school of comput scienc at the univer- 
siti of western australia. formerly, he be a 
senior research at the german research 
center for artifici intellig (dfki), germani 
and a visit research at google, california. 
He receiv hi ph.d. in comput engin 
from kaiserslautern univers of technology, 

germani in 2008. hi research interest includ machin learn and 
pattern recognition. 

ian reid receiv the dphil degre from the uni- 
versiti of oxford, in 1991. He be a professor of 
comput scienc with the univers of adelaide. 
He have be employ in the robot research 
group, conduct research in comput vision, 
includ hold an epsrc advanc research 
fellowship (1997-2000), and he have be a uni- 
versiti lectur sinc 2000. In 2005, he be 
award the titl of reader and in 2010 the titl of 
professor. 

" for more inform on thi or ani other comput topic, 
pleas visit our digit librari at www.computer.org/publications/dlib. 

1598 ieee transact ON pattern analysi and machin intelligence, vol. 40, no. 7, juli 2018 

https://au.mathworks.com/matlabcentral/fileexchange/8998-surface-fitting-using-gridfit 
https://au.mathworks.com/matlabcentral/fileexchange/8998-surface-fitting-using-gridfit 















<< 
/ascii85encodepag fals 
/allowtranspar fals 
/autopositionepsfil true 
/autorotatepag /none 
/bind /left 
/calgrayprofil (gray gamma 2.2) 
/calrgbprofil (srgb iec61966-2.1) 
/calcmykprofil (u.s. web coat \050swop\051 v2) 
/srgbprofil (srgb iec61966-2.1) 
/cannotembedfontpolici /warn 
/compatibilitylevel 1.4 
/compressobject /off 
/compresspag true 
/convertimagestoindex true 
/passthroughjpegimag true 
/createjobticket fals 
/defaultrenderingint /default 
/detectblend true 
/detectcurv 0.0000 
/colorconversionstrategi /srgb 
/dothumbnail true 
/embedallfont true 
/embedopentyp fals 
/parseiccprofilesincom true 
/embedjobopt true 
/dscreportinglevel 0 
/emitdscwarn fals 
/endpag -1 
/imagememori 1048576 
/lockdistillerparam true 
/maxsubsetpct 100 
/optim true 
/opm 0 
/parsedsccom fals 
/parsedsccommentsfordocinfo true 
/preservecopypag true 
/preservedicmykvalu true 
/preserveepsinfo fals 
/preserveflat true 
/preservehalftoneinfo true 
/preserveopicom fals 
/preserveoverprintset true 
/startpag 1 
/subsetfont fals 
/transferfunctioninfo /remov 
/ucrandbginfo /preserv 
/useprologu fals 
/colorsettingsfil () 
/alwaysemb [ true 
/algerian 
/arial-black 
/arial-blackital 
/arial-bolditalicmt 
/arial-boldmt 
/arial-italicmt 
/arialmt 
/arialnarrow 
/arialnarrow-bold 
/arialnarrow-boldital 
/arialnarrow-ital 
/arialunicodem 
/baskoldfac 
/batang 
/bauhaus93 
/bellmt 
/bellmtbold 
/bellmtital 
/berlinsansfb-bold 
/berlinsansfbdemi-bold 
/berlinsansfb-reg 
/bernardmt-condens 
/bodonimtpostercompress 
/bookantiqua 
/bookantiqua-bold 
/bookantiqua-boldital 
/bookantiqua-ital 
/bookmanoldstyl 
/bookmanoldstyle-bold 
/bookmanoldstyle-boldital 
/bookmanoldstyle-ital 
/bookshelfsymbolseven 
/britannicbold 
/broadway 
/brushscriptmt 
/californianfb-bold 
/californianfb-ital 
/californianfb-reg 
/centaur 
/centuri 
/centurygoth 
/centurygothic-bold 
/centurygothic-boldital 
/centurygothic-ital 
/centuryschoolbook 
/centuryschoolbook-bold 
/centuryschoolbook-boldital 
/centuryschoolbook-ital 
/chiller-regular 
/colonnamt 
/comicsansm 
/comicsansms-bold 
/cooperblack 
/couriernewps-bolditalicmt 
/couriernewps-boldmt 
/couriernewps-italicmt 
/couriernewpsmt 
/estrangeloedessa 
/footlightmtlight 
/freestylescript-regular 
/garamond 
/garamond-bold 
/garamond-ital 
/georgia 
/georgia-bold 
/georgia-boldital 
/georgia-ital 
/haettenschweil 
/harlowsolid 
/harrington 
/hightowertext-ital 
/hightowertext-reg 
/impact 
/informalroman-regular 
/jokerman-regular 
/juiceitc-regular 
/kristenitc-regular 
/kuenstlerscript-black 
/kuenstlerscript-medium 
/kuenstlerscript-twobold 
/kunstlerscript 
/latinwid 
/lettergothicmt 
/lettergothicmt-bold 
/lettergothicmt-boldobliqu 
/lettergothicmt-obliqu 
/lucidabright 
/lucidabright-demi 
/lucidabright-demiital 
/lucidabright-ital 
/lucidacalligraphy-ital 
/lucidaconsol 
/lucidafax 
/lucidafax-demi 
/lucidafax-demiital 
/lucidafax-ital 
/lucidahandwriting-ital 
/lucidasansunicod 
/magneto-bold 
/maturamtscriptcapit 
/mediciscriptltstd 
/microsoftsansserif 
/mistral 
/modern-regular 
/monotypecorsiva 
/ms-mincho 
/msreferencesansserif 
/msreferencespecialti 
/niagaraengraved-reg 
/niagarasolid-reg 
/nuptialscript 
/oldenglishtextmt 
/onyx 
/palatinolinotype-bold 
/palatinolinotype-boldital 
/palatinolinotype-ital 
/palatinolinotype-roman 
/parchment-regular 
/playbil 
/pmingliu 
/poorrichard-regular 
/ravi 
/showcardgothic-reg 
/simsun 
/snapitc-regular 
/stencil 
/symbolmt 
/tahoma 
/tahoma-bold 
/tempussansitc 
/timesnewromanmt-extrabold 
/timesnewromanmtstd 
/timesnewromanmtstd-bold 
/timesnewromanmtstd-boldcond 
/timesnewromanmtstd-boldit 
/timesnewromanmtstd-cond 
/timesnewromanmtstd-condit 
/timesnewromanmtstd-ital 
/timesnewromanps-bolditalicmt 
/timesnewromanps-boldmt 
/timesnewromanps-italicmt 
/timesnewromanpsmt 
/times-roman 
/trebuchet-boldital 
/trebuchetm 
/trebuchetms-bold 
/trebuchetms-ital 
/verdana 
/verdana-bold 
/verdana-boldital 
/verdana-ital 
/vinerhanditc 
/vivaldii 
/vladimirscript 
/webd 
/wingdings2 
/wingdings3 
/wingdings-regular 
/zapfchancerystd-demi 
/zwadobef 
] 
/neveremb [ true 
] 
/antialiascolorimag fals 
/cropcolorimag true 
/colorimageminresolut 150 
/colorimageminresolutionpolici /ok 
/downsamplecolorimag true 
/colorimagedownsampletyp /bicub 
/colorimageresolut 150 
/colorimagedepth -1 
/colorimagemindownsampledepth 1 
/colorimagedownsamplethreshold 1.50000 
/encodecolorimag true 
/colorimagefilt /dctencod 
/autofiltercolorimag fals 
/colorimageautofilterstrategi /jpeg 
/coloracsimagedict << 
/qfactor 0.76 
/hsampl [2 1 1 2] /vsampl [2 1 1 2] 
>> 
/colorimagedict << 
/qfactor 0.40 
/hsampl [1 1 1 1] /vsampl [1 1 1 1] 
>> 
/jpeg2000coloracsimagedict << 
/tilewidth 256 
/tileheight 256 
/qualiti 15 
>> 
/jpeg2000colorimagedict << 
/tilewidth 256 
/tileheight 256 
/qualiti 15 
>> 
/antialiasgrayimag fals 
/cropgrayimag true 
/grayimageminresolut 150 
/grayimageminresolutionpolici /ok 
/downsamplegrayimag true 
/grayimagedownsampletyp /bicub 
/grayimageresolut 300 
/grayimagedepth -1 
/grayimagemindownsampledepth 2 
/grayimagedownsamplethreshold 1.50000 
/encodegrayimag true 
/grayimagefilt /dctencod 
/autofiltergrayimag fals 
/grayimageautofilterstrategi /jpeg 
/grayacsimagedict << 
/qfactor 0.76 
/hsampl [2 1 1 2] /vsampl [2 1 1 2] 
>> 
/grayimagedict << 
/qfactor 0.40 
/hsampl [1 1 1 1] /vsampl [1 1 1 1] 
>> 
/jpeg2000grayacsimagedict << 
/tilewidth 256 
/tileheight 256 
/qualiti 15 
>> 
/jpeg2000grayimagedict << 
/tilewidth 256 
/tileheight 256 
/qualiti 15 
>> 
/antialiasmonoimag fals 
/cropmonoimag true 
/monoimageminresolut 1200 
/monoimageminresolutionpolici /ok 
/downsamplemonoimag true 
/monoimagedownsampletyp /bicub 
/monoimageresolut 600 
/monoimagedepth -1 
/monoimagedownsamplethreshold 1.50000 
/encodemonoimag true 
/monoimagefilt /ccittfaxencod 
/monoimagedict << 
/K -1 
>> 
/allowpsxobject fals 
/checkcompli [ 
/none 
] 
/pdfx1acheck fals 
/pdfx3check fals 
/pdfxcompliantpdfonli fals 
/pdfxnotrimboxerror true 
/pdfxtrimboxtomediaboxoffset [ 
0.00000 
0.00000 
0.00000 
0.00000 
] 
/pdfxsetbleedboxtomediabox true 
/pdfxbleedboxtotrimboxoffset [ 
0.00000 
0.00000 
0.00000 
0.00000 
] 
/pdfxoutputintentprofil (none) 
/pdfxoutputconditionidentifi () 
/pdfxoutputcondit () 
/pdfxregistrynam () 
/pdfxtrap /fals 

/createjdffil fals 
/descript << 
/ch <feff4f7f75288fd94e9b8bbe5b9a521b5efa7684002000410064006f006200650020005000440046002065876863900275284e8e55464e1a65876863768467e5770b548c62535370300260a853ef4ee54f7f75280020004100630072006f0062006100740020548c002000410064006f00620065002000520065006100640065007200200035002e003000204ee553ca66f49ad87248672c676562535f00521b5efa768400200050004400460020658768633002> 
/cht <feff4f7f752890194e9b8a2d7f6e5efa7acb7684002000410064006f006200650020005000440046002065874ef69069752865bc666e901a554652d965874ef6768467e5770b548c52175370300260a853ef4ee54f7f75280020004100630072006f0062006100740020548c002000410064006f00620065002000520065006100640065007200200035002e003000204ee553ca66f49ad87248672c4f86958b555f5df25efa7acb76840020005000440046002065874ef63002> 
/dan <feff004200720075006700200069006e0064007300740069006c006c0069006e006700650072006e0065002000740069006c0020006100740020006f007000720065007400740065002000410064006f006200650020005000440046002d0064006f006b0075006d0065006e007400650072002c0020006400650072002000650067006e006500720020007300690067002000740069006c00200064006500740061006c006a006500720065007400200073006b00e60072006d007600690073006e0069006e00670020006f00670020007500640073006b007200690076006e0069006e006700200061006600200066006f0072007200650074006e0069006e006700730064006f006b0075006d0065006e007400650072002e0020004400650020006f007000720065007400740065006400650020005000440046002d0064006f006b0075006d0065006e0074006500720020006b0061006e002000e50062006e00650073002000690020004100630072006f00620061007400200065006c006c006500720020004100630072006f006200610074002000520065006100640065007200200035002e00300020006f00670020006e0079006500720065002e> 
/deu <feff00560065007200770065006e00640065006e0020005300690065002000640069006500730065002000450069006e007300740065006c006c0075006e00670065006e0020007a0075006d002000450072007300740065006c006c0065006e00200076006f006e002000410064006f006200650020005000440046002d0044006f006b0075006d0065006e00740065006e002c00200075006d002000650069006e00650020007a0075007600650072006c00e40073007300690067006500200041006e007a006500690067006500200075006e00640020004100750073006700610062006500200076006f006e00200047006500730063006800e40066007400730064006f006b0075006d0065006e00740065006e0020007a0075002000650072007a00690065006c0065006e002e00200044006900650020005000440046002d0044006f006b0075006d0065006e007400650020006b00f6006e006e0065006e0020006d006900740020004100630072006f00620061007400200075006e0064002000520065006100640065007200200035002e003000200075006e00640020006800f600680065007200200067006500f600660066006e00650074002000770065007200640065006e002e> 
/esp <feff005500740069006c0069006300650020006500730074006100200063006f006e0066006900670075007200610063006900f3006e0020007000610072006100200063007200650061007200200064006f00630075006d0065006e0074006f0073002000640065002000410064006f00620065002000500044004600200061006400650063007500610064006f007300200070006100720061002000760069007300750061006c0069007a00610063006900f3006e0020006500200069006d0070007200650073006900f3006e00200064006500200063006f006e006600690061006e007a006100200064006500200064006f00630075006d0065006e0074006f007300200063006f006d00650072006300690061006c00650073002e002000530065002000700075006500640065006e00200061006200720069007200200064006f00630075006d0065006e0074006f00730020005000440046002000630072006500610064006f007300200063006f006e0020004100630072006f006200610074002c002000410064006f00620065002000520065006100640065007200200035002e003000200079002000760065007200730069006f006e0065007300200070006f00730074006500720069006f007200650073002e> 
/fra <feff005500740069006c006900730065007a00200063006500730020006f007000740069006f006e00730020006100660069006e00200064006500200063007200e900650072002000640065007300200064006f00630075006d0065006e00740073002000410064006f006200650020005000440046002000700072006f00660065007300730069006f006e006e0065006c007300200066006900610062006c0065007300200070006f007500720020006c0061002000760069007300750061006c00690073006100740069006f006e0020006500740020006c00270069006d007000720065007300730069006f006e002e0020004c0065007300200064006f00630075006d0065006e00740073002000500044004600200063007200e900e90073002000700065007500760065006e0074002000ea0074007200650020006f007500760065007200740073002000640061006e00730020004100630072006f006200610074002c002000610069006e00730069002000710075002700410064006f00620065002000520065006100640065007200200035002e0030002000650074002000760065007200730069006f006e007300200075006c007400e90072006900650075007200650073002e> 
/ita (utilizzar quest impostazioni per crear documenti adob pdf adatti per visualizzar e stampar documenti aziendali in modo affidabile. I documenti pdf creati possono esser aperti con acrobat e adob reader 5.0 e versioni successive.) 
/jpn <feff30d330b830cd30b9658766f8306e8868793a304a3088307353705237306b90693057305f002000410064006f0062006500200050004400460020658766f8306e4f5c6210306b4f7f75283057307e305930023053306e8a2d5b9a30674f5c62103055308c305f0020005000440046002030d530a130a430eb306f3001004100630072006f0062006100740020304a30883073002000410064006f00620065002000520065006100640065007200200035002e003000204ee5964d3067958b304f30533068304c3067304d307e305930023053306e8a2d5b9a3067306f30d530a930f330c8306e57cb30818fbc307f3092884c3044307e30593002> 
/kor <feffc7740020c124c815c7440020c0acc6a9d558c5ec0020be44c988b2c8c2a40020bb38c11cb97c0020c548c815c801c73cb85c0020bcf4ace00020c778c1c4d558b2940020b3700020ac00c7a50020c801d569d55c002000410064006f0062006500200050004400460020bb38c11cb97c0020c791c131d569b2c8b2e4002e0020c774b807ac8c0020c791c131b41c00200050004400460020bb38c11cb2940020004100630072006f0062006100740020bc0f002000410064006f00620065002000520065006100640065007200200035002e00300020c774c0c1c5d0c11c0020c5f40020c2180020c788c2b5b2c8b2e4002e> 
/nld (gebruik deze instellingen om adob pdf-documenten te maken waarme zakelijk documenten betrouwbaar kunnen worden weergegeven en afgedrukt. De gemaakt pdf-documenten kunnen worden geopend met acrobat en adob reader 5.0 en hoger.) 
/nor <feff004200720075006b00200064006900730073006500200069006e006e007300740069006c006c0069006e00670065006e0065002000740069006c002000e50020006f0070007000720065007400740065002000410064006f006200650020005000440046002d0064006f006b0075006d0065006e00740065007200200073006f006d002000650072002000650067006e0065007400200066006f00720020007000e5006c006900740065006c006900670020007600690073006e0069006e00670020006f00670020007500740073006b007200690066007400200061007600200066006f0072007200650074006e0069006e006700730064006f006b0075006d0065006e007400650072002e0020005000440046002d0064006f006b0075006d0065006e00740065006e00650020006b0061006e002000e50070006e00650073002000690020004100630072006f00620061007400200065006c006c00650072002000410064006f00620065002000520065006100640065007200200035002e003000200065006c006c00650072002e> 
/ptb <feff005500740069006c0069007a006500200065007300730061007300200063006f006e00660069006700750072006100e700f50065007300200064006500200066006f0072006d00610020006100200063007200690061007200200064006f00630075006d0065006e0074006f0073002000410064006f00620065002000500044004600200061006400650071007500610064006f00730020007000610072006100200061002000760069007300750061006c0069007a006100e700e3006f002000650020006100200069006d0070007200650073007300e3006f00200063006f006e0066006900e1007600650069007300200064006500200064006f00630075006d0065006e0074006f007300200063006f006d0065007200630069006100690073002e0020004f007300200064006f00630075006d0065006e0074006f00730020005000440046002000630072006900610064006f007300200070006f00640065006d0020007300650072002000610062006500720074006f007300200063006f006d0020006f0020004100630072006f006200610074002000650020006f002000410064006f00620065002000520065006100640065007200200035002e0030002000650020007600650072007300f50065007300200070006f00730074006500720069006f007200650073002e> 
/suo <feff004b00e40079007400e40020006e00e40069007400e4002000610073006500740075006b007300690061002c0020006b0075006e0020006c0075006f0074002000410064006f0062006500200050004400460020002d0064006f006b0075006d0065006e007400740065006a0061002c0020006a006f0074006b006100200073006f0070006900760061007400200079007200690074007900730061007300690061006b00690072006a006f006a0065006e0020006c0075006f00740065007400740061007600610061006e0020006e00e400790074007400e4006d0069007300650065006e0020006a0061002000740075006c006f007300740061006d0069007300650065006e002e0020004c0075006f0064007500740020005000440046002d0064006f006b0075006d0065006e00740069007400200076006f0069006400610061006e0020006100760061007400610020004100630072006f0062006100740069006c006c00610020006a0061002000410064006f00620065002000520065006100640065007200200035002e0030003a006c006c00610020006a006100200075007500640065006d006d0069006c006c0061002e> 
/sve <feff0041006e007600e4006e00640020006400650020006800e4007200200069006e0073007400e4006c006c006e0069006e006700610072006e00610020006f006d002000640075002000760069006c006c00200073006b006100700061002000410064006f006200650020005000440046002d0064006f006b0075006d0065006e007400200073006f006d00200070006100730073006100720020006600f60072002000740069006c006c006600f60072006c00690074006c006900670020007600690073006e0069006e00670020006f006300680020007500740073006b007200690066007400650072002000610076002000610066006600e4007200730064006f006b0075006d0065006e0074002e002000200053006b006100700061006400650020005000440046002d0064006f006b0075006d0065006e00740020006b0061006e002000f600700070006e00610073002000690020004100630072006f0062006100740020006f00630068002000410064006f00620065002000520065006100640065007200200035002e00300020006f00630068002000730065006e006100720065002e> 
/enu (use these set to creat pdf that match the "suggested" set for pdf specif 4.0) 
>> 
>> setdistillerparam 
<< 
/hwresolut [600 600] 
/pages [612.000 792.000] 
>> setpagedevic 

