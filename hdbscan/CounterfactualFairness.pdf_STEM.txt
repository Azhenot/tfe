






































counterfactu fair - the alan ture institut 


counterfactu fair - the alan 
ture institut 

algorithm be increasingli assist in life-chang decisions, such a 
in parol hearings, loan applications, and univers admissions. 
however, if the data use to train an algorithm contain societ bia 
against certain races, genders, or other demograph groups, then the 
algorithm will too. use causal methods, research in thi project be 
aim to ensur algorithm fair by take into account differ 
social bia and compens for them effectively. 

jump to: project aim | applic | recent updat 
| disciplin & techniqu 

joshua loftus, assist professor of inform at nyu stern: 
“fair and causal infer be kind of dual problems. In causal 
inference, you tri and figur out the effect of a certain variable, when it 
might be confound with [i.e. both be affect by and affect] other 
things. In fairness, you’r tri to make a certain variabl not have ani 
effect, when it too might potenti be confound with other things.” 
it’ possibl to utilis thi idea to help good understand and mitig 
issu with algorithm decision-mak systems. 

imagin a car insur compani want to price insur for car 
owner by predict their accid rate with an algorithm. the 
compani assum that aggress drive be link both to driver be 
more like to have accid and a prefer for red cars. 

whilst it would seem that the compani could use red car prefer a a 
good way of predict who will caus accidents, there could be other 
variabl at play: for example, what if individu of a particular race be 
more like to drive red cars, but be no more like to drive aggress 
or have accidents? if, in an attempt to be fair, the compani remov or 
ignor race from the decision-mak process, they might onli have 
directli observ factors, like red car preference, from which to make 
a decision, therebi including, rather removing, hidden racial biases. 

what need to happen instead be that when an algorithm be be 
design to predict an outcom or make a decision, the variabl use 
to make the predict or decis need to be care assessed. ani 

counterfactu fair - the alan ture institut https://www.turing.ac.uk/research_projects/counterfactual-fairness/ 

1 sur 3 16-04-18 à 19:51 



differ in these variabl identifi a be caus by sensit 
factors, like race, then need to be cancel out. 

back to top 

ensur fair use causal method to produc ‘counterfactu 
fair’ algorithms, base on the idea a decis be fair toward an 
individu if the outcom be the same in realiti a it would be in a 
‘counterfactual’ world, in which the individu belong to a differ 
demographic. 

the project have involv produc a technic set of guidelin for 
practition to use when creat or refin decision-mak 
algorithms. these guidelin give practition an idea of how they 
should structur their problem, what be impli by their assumptions, 
and how they could evalu it all use a causal model. the framework 
also call for the need for decision-mak algorithm to be design 
with the input of expert knowledg about the situat the algorithm 
be be use in. 

the research team be current work and engag with policy- 
makers, lawyers, and investig journalists, whilst refin and 
improv their methods. 

back to top 

one exampl of the team’ work in action be with propublica, an 
american non-profit investig newsroom, which have collect a big 
dataset from the use of an algorithm call compas. the algorithm be 
use by judg and parol offic in the US for score crimin 
defendants’ likelihood of reoffending. the team have work with 
propublica to run their method on the dataset in order to confirm 
systematic, racial bia be preval in the algorithm. 

back to top 

the team present their work in decemb 2017 at the neural 
inform process system (nips) confer in california, one of 
the world’ premier machin learn conferences. 

In a year of record-break submiss for the conference, the team 
be invit to give an oral present of their research; one of onli 
40 of the 3,000 plu submit paper select for thi kind of 
presentation. 

simon dedeo, assist professor in social and decis scienc at 
carnegi mellon univers and previous a visit research at the 
turing, be present at the confer and said: “A crucial part of how 
we make moral judgement be by talk about causes. the 
counterfactu fair work be the first to show u how we might use 

counterfactu fair - the alan ture institut https://www.turing.ac.uk/research_projects/counterfactual-fairness/ 

2 sur 3 16-04-18 à 19:51 



thi to uncov injustic in algorithms”. 

back to top 

causal 

algorithm 

machin learn 

ethic 

back to top 

counterfactu fair - the alan ture institut https://www.turing.ac.uk/research_projects/counterfactual-fairness/ 

3 sur 3 16-04-18 à 19:51 


