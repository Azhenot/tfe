












































































gminer: A fast gpu-bas frequent itemset mine method for large-scal data 


inform scienc 439–440 (2018) 19–38 

content list avail at sciencedirect 

inform scienc 

journal homepage: www.elsevier.com/locate/in 

gminer: A fast gpu-bas frequent itemset mine method 

for large-scal data � 

kang-wook chon, sang-hyun hwang, min-soo kim ∗ 

dgist (daegu gyeongbuk institut of scienc and technology), daegu, republ of korea 

a r t i c l e i n f o 

articl history: 

receiv 19 march 2017 

revis 16 januari 2018 

accept 25 januari 2018 

avail onlin 31 januari 2018 

keywords: 

frequent itemset mine 

graphic process unit 

parallel algorithm 

workload skew 

a b s t r a c t 

frequent itemset mine be wide use a a fundament data mine technique. however, 

a the data size increases, the rel slow perform of the exist method hinder 

it applicability. although mani sequenti frequent itemset mine method have be 

proposed, there be a clear limit to the perform that can be achiev use a singl 

thread. To overcom thi limitation, variou parallel method use multi-cor cpu, multi- 

ple machine, or many-cor graphic process unit (gpu) approach have be proposed. 

however, these method still have drawbacks, includ rel slow performance, data 

size limitations, and poor scalabl due to workload skewness. In thi paper, we pro- 

pose a fast gpu-bas frequent itemset mine method call gminer for large-scal data. 
gminer achiev veri fast perform by fulli exploit the comput power of 
gpu and be suitabl for large-scal data. the method perform mine task in a coun- 

terintuit way: it mine the pattern from the first level of the enumer tree rather 

than store and util the pattern at the intermedi level of the tree. thi approach 

be quit effect in term of both perform and memori use in the gpu architecture. 

In addition, gminer solv the workload skew problem from which the exist par- 
allel method suffer; a a result, it perform increas almost linearli a the number 

of gpu increases. through extens experiments, we demonstr that gminer signifi- 
cantli outperform other repres sequenti and parallel method in most cases, by 

order of magnitud on the test benchmarks. 

© 2018 the authors. publish by elsevi inc. 

thi be an open access articl under the CC by-nc-nd license. 

( http://creativecommons.org/licenses/by-nc-nd/4.0/ ) 











1. introduct 

As a fundament data mine technique, frequent itemset mine be wide use in a wide rang of disciplin such a 

market basket analysis, web usag mining, social network analysis, intrus detection, bioinformatics, and recommend 

systems. however, the delug of data gener by autom system for diagnost or analysi purpos make it difficult 

or even imposs to appli mine techniqu in mani real-world applications. the exist method often fail to find 

frequent itemset in such big data within a reason amount of time. thus, in term of comput time, itemset 

mine be still a challeng problem that have not yet be complet solved. 
� fulli document templat be avail in the elsarticl packag on ctan. 
∗ correspond author. 

e-mail addresses: kw.chon@dgist.ac.kr (k.-w. chon), sanghyun@dgist.ac.kr (s.-h. hwang), mskim@dgist.ac.kr (m.-s. kim). 

https://doi.org/10.1016/j.ins.2018.01.046 

0020-0255/© 2018 the authors. publish by elsevi inc. thi be an open access articl under the CC by-nc-nd license. 

( http://creativecommons.org/licenses/by-nc-nd/4.0/ ) 

https://doi.org/10.1016/j.ins.2018.01.046 
http://www.sciencedirect.com 
http://www.elsevier.com/locate/in 
http://crossmark.crossref.org/dialog/?doi=10.1016/j.ins.2018.01.046&domain=pdf 
http://creativecommons.org/licenses/by-nc-nd/4.0/ 
mailto:kw.chon@dgist.ac.kr 
mailto:sanghyun@dgist.ac.kr 
mailto:mskim@dgist.ac.kr 
https://doi.org/10.1016/j.ins.2018.01.046 
http://creativecommons.org/licenses/by-nc-nd/4.0/ 


20 k.-w. chon et al. / inform scienc 439–440 (2018) 19–38 







































































































mani sequenti frequent itemset mine method such a apriori [2] , eclat [35] , fp-growth [14] , and lcm [30] use a sin- 

gle cpu thread. however, these single-thread applic all have a fundament mine perform limit becaus cpu 

clock speed be gener no longer increasing. To overcom the single-thread perform limit, multipl parallel frequent 

itemset mine method have be proposed. these method can be categor into three main groups: (1) (cpu-based) 

multi-thread methods, (2) distribut methods, and (3) graphic process unit (gpu)-bas methods. We omit the term 

”multi-thread” from the gpu-bas method becaus they be obvious multi-threaded. the first group focu on accel- 

erat the perform of the single-thread method by exploit multi-cor cpu [20,24,26,27,29] , while the second 

group tri to acceler the perform by exploit multipl machin [12,17,19] . detail about these method be avail- 

abl in recent survey studi [9,31] . 

the third group, namely, the gpu-bas methods, focu on acceler the perform by exploit many-cor gpu 

[7,15,18,28,37–39] . due to the high theoret comput perform of gpu for certain type of task compar with 

cpus, it have becom increasingli import to exploit the capabl of gpu in a wide rang of problems, includ fre- 

quent pattern mining. however, exist gpu-bas method all suffer from data size limit due to limit gpu mem- 

ory. gpu memori tend to be much small than main memory. most of the method can onli find frequent pattern in 

data load into gpu memory, which includ the input transact data and intermedi data gener at the interme- 

diat level of the pattern space. To the best of our knowledge, frontier expans [38] be the onli method in thi group 

that can handl larg input transact data than gpu memori while simultan exploit multipl gpus. however, it 

still cannot address the same data size a cpu-bas methods, becaus it cannot store suffici larg amount of data at 

intermedi level of the pattern space in gpu memory. 

most exist parallel method of the abov three group also suffer from the problem of workload skewness. workload 

skew be extrem common and significantli affect parallel comput performance. the exist parallel method usu- 

alli divid the search space of the pattern to be explor into multipl chunk (e.g., equival classes) and assign each 

chunk to a processor (or machine). each subtre of the enumer tree tend to have a differ workload size. As a result, 

these method be not particularli scalabl in term of the number of cpus, machines, or gpus. that is, their perform 

do not increas proport a the number of processor increases. 

In thi paper, we propos a fast gpu-bas frequent itemset mine method call gminer for large-scal data. our 
gminer method achiev high speed by fulli exploit the comput power of gpus. It can also address the same 
data size a cpu-bas methods-that is, it solv the main drawback of the exist gpu-bas methods. gminer achiev 
thi by mine the pattern from the first level of the enumer tree rather than store and util the pattern at 

intermedi level of the tree. thi strategi might look simple, but it be quit effect in term of perform and mem- 

ori usag for gpu-bas methods. We call thi strategi the travers from the first level (tfl) strategy. the tfl strategi 

do not store ani project databas or frequent itemset from the intermedi level of the enumer tree in gpu 

memory; instead, it find all the frequent itemset use onli the frequent itemset from the first level, denot a F 1 . thi 

strategi reduc the amount of gpu memori use and simultan and paradox improv the performance. thi 

result seem somewhat counterintuit but make sens in a gpu architecture, where the gap between processor speed 

and memori speed be quit large. In most cases, mine the frequent n -itemset by perform a larg amount of compu- 

tation base on a small F 1 set be faster than mine the same result by perform a small amount of comput base 

on a larg set of frequent (n-1)-itemset under the gpu architecture. use the tfl strategy, gminer improv the perfor- 
manc of the repres parallel methods, includ multi-threaded, distributed, and gpu-bas methods, by order of 

magnitude. In addit to the tfl strategy, we also propos a strategi call hop from the intermedi level (hil), to 

further improv the perform on dataset that contain long patterns. intuitively, the hil strategi reduc the requir 

comput by util more gpu memory, therebi improv the perform for long patterns. In addit to fast min- 

ing with effici memori usage, gminer solv the workload skew problem of the exist parallel methods. As a 
result, gminer ’s perform increas almost linearli a the number of gpu increases. To solv the workload skew 
problem, we propos the concept of a transact block and a rel memori address. the former be a fixed-s chunk 

of bitwis represent for transactions, while the latter be an array represent for candid itemsets. for parallel 

processing, gminer do not divid the search space of the enumer tree into sub-trees; instead, it divid an array of 
rel memori address into multipl subarrays, all of which have the same size. then, gminer store a subarray in each 
gpu and perform mine by stream transact block to all the gpu so that each gpu be assign almost the same 

workload. the main contribut of thi paper be a follows: 

• We propos a new, fast gpu-bas frequent itemset mine method name gminer that fulli exploit the gpu archi- 
tectur by perform a larg amount of comput on a small amount of data (i.e., frequent 1-itemsets). 

• We propos a strategi call hil that can further improv the perform on dataset that contain long pattern by 
perform a moder amount of comput base on a moder amount of data. 

• We propos a method to solv the workload skew problem by split an array of rel memori address for 
candid itemset among gpu and stream transact block to all gpus. 

• through experiments, we demonstr that gminer significantli outperform most of the state-of-the-art method that 
have be address in recent studi [4,9,25,31,33] on two kind of benchmarks. 

the sourc code for gminer be avail at https://infolab.dgist.ac.kr/gmin . the remaind of thi paper be organ 
a follows. section 2 discu the relat work. We propos the tfl strategi in section 3 , and in section 4 , we propos 

https://infolab.dgist.ac.kr/gmin 


k.-w. chon et al. / inform scienc 439–440 (2018) 19–38 21 

tabl 1 

categor of the exist frequent itemset mine methods. 

sequenti (cpu) parallel 

cpu gpu 

multi-thread distribut 

rel comput power low medium high high 

difficulti of workload balanc n/a medium high high 

network commun overhead X X O X 

processor memori limit X X X O 

repres method (use in 

experiment study) 

apriori (borgelt) [6] , 

eclat (borgelt) [6] , eclat 

(goethals) [10] , lcm 

[30] , fp-growth ∗ [11] 

fp-aray [20] , shafem 

[32] , mc-eclat [26] 

mllib [3] tbi [7] , gpapriori [37] , 

frontier expans [38] 































































the hil strategy. In section 5 we present a method that exploit multipl gpu and the cost model of gminer . section 6 
present the result of experiment evaluations, and section 7 summar and conclud thi paper. 

2. relat work 

the frequent itemset mine problem be usual defin a the problem of determin all itemset F that occur a a 
subset of at least a pre-defin fraction minsup of the transact in a give transact databas D = { t 1 , t 2 , . . . , t n } , where 
each transact t i be a subset of item from I [1,13] . In thi paper, we mainli use the number of occurrences, instead of a 
fraction, a the support of an itemset. mani sequenti and parallel frequent itemset mine method have be proposed. 

We categor the parallel method into three groups: (1) (cpu-based) multi-thread methods, (2) distribut methods, 

and (3) gpu-bas methods. their characterist and repres method be summar in tabl 1 and be explain 

in detail in section 2.1 –2.4 . 

2.1. sequenti method 

mani sequenti method have be propos for frequent pattern mining. the repres method includ apriori 

[2] , eclat [35] , lcm [30] , and fp-growth [14] . apriori be base on the anti-monoton property: if a k -itemset be not frequent, 

then it superset can never becom frequent. apriori repeatedli gener candid ( k +1)-itemset C k +1 from the frequent 
k -itemset F k (where k ≥ 1) and comput the support of C k +1 over the databas D for testing. borgelt [6] be a well-known 
implement of apriori that exploit a prefix tree to repres the transact databas and find frequent itemset di- 

rectli with the prefix tree to calcul support efficiently. eclat [35] us the equival class concept to partit the 

search space into multipl independ subspac (i.e., subproblems). it vertic data format make it possibl to perform 

support count effici by set intersection. goethal et al. [10] and borgelt [6] be well-known implement of eclat 

that optim it use the diffset [34] represent for candid itemset and transactions. the superior of both meth- 

od to other vertic method have be demonstr on the frequent itemset mine implement (fimi) competit 

(i.e., fimi03 and fimi04) [8] . lcm be a variat of eclat that combin variou techniqu such a a bitmap database, 

prefix tree, and the occurr deliv technique. As a result, lcm achiev the overal best perform among sequen- 

tial method in the fimi04 competition. fp-growth [14] build an fp-tree from the databas and recurs find frequent 

itemset by travers the fp-tree without explicit candid generation. It outperform the apriori-bas method in mani 

cases. fp-growth ∗ be a well-known implement of fp-growth that reduc the number of tree travers by exploit 
addit array data structures. fp-growth ∗’ superior be demonstr in the fimi03 competition. 

2.2. multi-thread method 

mani effort have be make to parallel sequenti method use multipl thread to improv the perform 

[20,26,32] . fp-array [20] , base on fp-growth, util a cache-consci fp-array built from a compact fp-tree and a lock- 

free tree construct algorithm. In an experiment study, fp-array improv the perform by up to six time on eight 

cpu cores. mc-eclat [26] be a parallel method base on eclat. mc-eclat util three parallel mine approaches, namely, in- 

dependent, shared, and hybrid mining, and it greatli improv the perform on rel small datasets. shafem [32] be 

a parallel method that dynam choos mine strategi base on dataset density. In detail, it switch between fp- 

growth and eclat base on dataset characteristics. In mani cases, multi-thread method greatli improv the perform 

compar to sequenti methods. however, they fail in pattern mine due to out-of-memori failur on some dataset that 

sequenti method handl success and tend to requir more memori than the sequenti method due to the larg 

amount of memori use by the independ threads. 



22 k.-w. chon et al. / inform scienc 439–440 (2018) 19–38 

























































































2.3. distribut method 

In theory, distribut method that exploit mani machin can address large-scal data. sever distribut method 

[3,19,22] have be proposed, all of which be base on a shared-noth framework such a hadoop or spark. lin et al. 

[19] propos parallel method base on hadoop for the apriori approach. moen et al. [22] propos dist-eclat and big- 

fim. dist-eclat be base on the eclat approach and bigfim be a hybrid approach between apriori and eclat. mllib of spark 

[3] includ a parallel version of fp-growth call pfp. pfp be an in-memori distribut method that run on a cluster of 

machines. It build independ fp-tree and then perform frequent itemset mine independ on each fp-tree in each 

machine. although the distribut method should be abl to handl larg data, or greatli improv the perform by 

add more machines, they do not show such result in mani case due to workload skewness. accord to the experi- 

mental result (which will be present in section 6 ), distribut method can result in even bad perform than do 

multi-thread method that use a singl machin due to the larg amount of network commun overhead. 

2.4. gpu-bas method 

modern gpu have mani comput core that allow multipl simultan execut of a kernel, which be a user- 

defin function. In addition, use gpu in a singl machin do not involv network commun overhead. gpu 

have radic differ characterist than cpus, includ the singl instruction, multipl thread (simt) model and the 

import of coalesc memori access. these differ make it difficult to appli most parallel method use complex 

data structur (e.g., fp-array) to gpu directli and efficiently. thus, most gpu-bas method have be propos base 

on apriori [7,15,18,28,31,37] . 

fang et al. [7] present two gpu-bas methods: pure bitmap implement (pbi) and trie-bas implement 

(tbi). these method repres a transact databas a an n × m binari matrix, where n be the number of itemset and 
m be the number of transactions, therebi make it suitabl for the gpu architecture. these method perform intersect 

oper on row of the binari matrix use a gpu to count support. pbi and tbi outperform the exist sequenti 

apriori methods, such a the apriori implement write by borgelt [6] , by factor of 2–10. however, accord to fang 

et al. [7] , these method be outperform by the exist parallel fp-growth method by factor of 4–16 on the parsec 

benchmark [5] . tbi be superior to pbi in term of the number of candid itemset that can be handl simultaneously; 

therefore, we compar tbi with our method in section 6 . 

zhang et al. [37] present gpapriori, which gener a so-cal static bitmap that repres all the distinct 1-itemset 

and their tidsets. similar to other gpu-bas apriori methods, gpapriori us a gpu onli to parallel the support count 

step. the candid gener step be perform use cpus. gpapriori adopt multipl optimizations, such a pre-load 

candid itemset into the share gpu memori and use hand-tun gpu block sizes. consequently, it show a speed- 

up of up to 80 time on a small dataset that can fit into gpu memori compar with some sequenti apriori method 

(e.g., that of borgelt [6] ). however, accord to zhang et al. [37] , gpapriori could not outperform state-of-the-art sequenti 

method such a fp-growth ∗ [11] , eclat [6] , and lcm [30] . 
In [28] , the author propos a parallel version of the dynam count itemset algorithm (dci) [23] , a variat of 

apriori in which two major dci operations, namely, intersect and computation, be parallel use a gpu. they pro- 

pose two strategies: a transaction-wis approach (call tw ) and a candidate-wis approach (call cw ). the tw strategi 

us all gpu core for the same candid simultaneously, and each thread overse a part of the data, while the cw strategi 

handl mani candid itemset simultaneously. We omit these method in tabl 1 and in our experiments, becaus the 

tw strategi be almost the same a tbi, and the cw strategi work for onli very-smal dataset [28] . 

the abov three apriori-bas methods, which use gpus, have a common seriou drawback: they cannot handl dataset 

larg than gpu memory. therefore, use them for real large-scal dataset be difficult becaus gpu memori be quit limit 

(e.g., to a few gb). In addition, the abov method do not outperform the repres sequenti method (e.g., lcm) a 

well a the repres multi-thread method (e.g., fp-array) [7,28,37] . 

accord to the recent survey paper on frequent itemset mine [9,31] , frontier expans [38] be the onli gpu-bas 

method that can handl dataset larg than gpu memory. frontier expans be base on eclat rather than apriori, and 

it util multipl gpus. the author show that it outperform the sequenti eclat and fp-growth method [38] , which 

be previous know to be the fast method in their categories. however, it fail to outperform some state-of-the- 

art multi-thread method such a fp-array (a show by our experiment result in section 6 ). We found that frontier 

expansion’ failur be due to three major drawbacks: (1) it store a larg amount of intermediate-level data in gpu memori 

(wast gpu clock cycles); (2) it have a larg data transfer overhead between main memori and gpu memory; and (3) it be 

not scalabl in term of the number of gpus. We will explain how the propos gminer method solv these drawback 
in section 3 –5 . 

3. tfl strategi 

for fast frequent itemset mining, even for large-scal data, gminer us the travers from the first level (tfl) strategi 
of mine the pattern from the first level, i.e., F , of the enumer tree. the tfl strategi do not store ani project 
1 



k.-w. chon et al. / inform scienc 439–440 (2018) 19–38 23 























































































databas or frequent itemset from the intermedi level of the enumer tree in gpu memory; instead, it find the en- 

tire frequent itemset use onli F 1 . thi approach significantli reduc gpu memori usage; thus, it can address large-scal 

data without encount out-of-memori problems. In addition, to elimin the data transfer overhead between main 

memori and gpu memory, gminer perform pattern mine while stream transact databas from main memori to 
gpu memory. here, gminer split the transact databas into block and stream them to gpus. thi block-bas stream- 
ing approach allow u to solv the workload skew problem, a explain in section 5 . section 3.1 and 3.2 explain the 

transact block and the block-bas stream approach, respectively. section 3.3 present the algorithm that implement 

the tfl strategy. 

3.1. transact block 

It be import that the data structur be simpl and use a regular memori access pattern to fulli exploit the com- 

putat power of gpu in term of workload balanc among thousand of gpu core and coalesc memori access. In 

general, compar with cpus, the arithmet and logic unit (alus) and memori scheme of gpu be not effici for han- 

dling complex or variable-s data structures, includ sets, lists, maps, and their combinations. furthermore, gpu have 

onli limit memory, which be a major obstacl for frequent itemset mine on large-scal and/or dens dataset use 

gpus. 

for comput efficiency, gminer adopt a vertic bitmap layout for data representation. the horizont layout and 
vertic tidset layout be too complex and irregular to maxim gpu comput efficiency. frequent itemset mine 

use the vertic bitmap layout reli heavili on bitwis and oper among large-scal bitmaps, where gpu have an 
overwhelm advantag over cpus. 

moreover, the vertic bitmap layout allow u to easili partit the input databas vertic into subdatabases, each of 

which can fit in main memori or gpu memory. hereafter, we denot an input databas D in the vertic bitmap layout a a 

transact bitmap . We defin the vertic partit of a transact bitmap in definit 1 . 

definit 1 (transact bitmap partition) . We vertic divid the transact bitmap TB into R non-overlap partit 

of the same width and denot them by TB 1: R , where TB k denot the k -th transact bitmap partit (1 ≤ k ≤ R ). 
As in other frequent itemset mine methods, gminer begin by mine the frequent 1-itemset | F 1 |; therefore, the size 

of TB be | F 1 | x | D | in bits, where | D | be the total number of transactions. when we denot the width of a singl partit of 

the transact bitmap a W , the size of TB k becom | F 1 | x W . If the number of transact of the last partit TB R be less 

than W , gminer pad the partit with 0 valu to guarante the width of W . 
the paramet W should be set to a suffici small valu to fit each TB k into gpu memory. for instance, we typic 

set W to 262,144 transact in our experiment evaluation, which equal to 262,144/8 = 32 KB for each 1-itemset. We 
consid each TB k of size | F 1 | x W a a transact block. the transact block be alloc consecut in main memori 

(or store a chunk in secondari storag similar to a disk page). 

A frequent 1-itemset x ( x ∈ F 1 ) have a bit vector of length | D | in TB , which be subdivid into R bit vector of length W . We 
denot a bit vector of x within TB k a TB k ( x ). As mention above, TB contain onli the bit vector for frequent 1-itemsets. 

thus, if x be a frequent n -itemset, x have n bit vector in TB k , i.e., { TB k ( i )| i ∈ x }. We defin a set of physic pointer to the bit 
vector for a frequent itemset x in the transact bitmap in definit 2 . 

definit 2 (rel memori address) . We defin a rel memori address of an item i , denot a RA ( i ), a the distanc 

in byte from the start memori address of TB k to that of TB k ( i ), for a transact block TB k . then, we defin a set of 

rel memori address of a frequent itemset x , denot a RA ( x ), a { RA ( i )| i ∈ x }. 
thi concept facilit the fast access to a memori locat of an itemset (or memori locat of itemsets) within a 

singl transact block in main memori or gpu memory. RA ( x ) be use a an identifi for an itemset x in gminer . We 
denot the number of item in x a | x | and the number of distinct memori address of RA ( x ) a | RA ( x )|. then, | x | = | RA (x ) | , 
becaus each item i ∈ x have it own uniqu memori address in TB k . We note that RA ( x ) for a frequent itemset x do not 
chang across all TB k (1 ≤ k ≤ R ); that is, it alway have the same rel memori address becaus the size of TB k be fixed. 

3.2. nested-loop stream 

gminer find frequent itemset use the candid gener and test approach with breadth-first search (bfs), a 
in apriori, which repeat two major steps, namely, candid gener and test (support counting), at each level of 

an itemset lattice. generally, the test step be more comput intens than the candid gener step. thus, 

gminer focu on acceler the test step by exploit gpus. the candid gener step be perform use cpus. 
gminer us bf travers rather than df travers (e.g., equival classes) to fulli exploit the massiv parallel 

of gpu and achiev good workload balance. when use bf traversal, the number of frequent itemset at a certain level 

could becom too larg to be store in the limit gpu memori and use for support count of the candid itemset of 

the next level. the increas in the number of transact make the problem more difficult. therefore, exist gpu-bas 

method for mine large-scal dataset (such a frontier expans [38] ) use a df approach that test onli the frequent 

and candid itemset of an equival class within gpu memory. however, the use of thi df approach on gpu could 



24 k.-w. chon et al. / inform scienc 439–440 (2018) 19–38 

































































































degrad the perform of itemset mine due to lack of parallel and workload skewness, which will be show in 

section 6 . 

our propos tfl strategi solv the issu of mine frequent itemset in large-scal dataset without degrad the per- 

formanc within limit gpu memory. We call an entir set of frequent 1-itemset the first level in the itemset lattic and 

call other level in the itemset lattic intermedi level . most of the exist frequent itemset mine method materi 

frequent itemset in intermedi level to reduc comput overhead, but thi approach greatli increas the space 

overhead. for example, aprioritid materi n -itemset when find n + 1-itemsets, and eclat materi the itemset 
that have the same prefix. however, thi approach can suffer from a lack of main memori due to the larg amount of in- 

termedi data. moreover, thi tendenc be more mark when exploit gpus, becaus gpu memori be limit compar 

to main memory. the propos tfl strategi test all the candid itemset of intermedi level use onli the first level, 

i.e., F 1 . thi featur be base on the observ that gpu have high comput power, especi for massiv bitwis 

operations, but rel small devic memory. our observ indic that, in the gpu architecture, test the candid 

n + 1-itemset use frequent 1-itemset tend to be much faster than test the candid n + 1-itemset use frequent 
n -itemset (i.e., F n ). thi speed differ occur becaus copi F n to gpu memori incur a much larg data transfer 

overhead than do copi onli F 1 , and simultaneously, access F n in gpu memori incur more non-coalesc memori 

access than do access F 1 . 

for mine large-scal databases, we also propos a new itemset mine techniqu on gpu call nested-loop stream . 

here, a singl seri of candid gener and test step constitut an iter . gminer perform nested-loop stream- 
ing at each iteration. thi techniqu copi the candid itemset to gpu a the outer operand. specifically, it copi onli 

the rel memori address of the itemset to the gpu rather than the itemset themselves. We denot the candid 

itemset at level L a C L . the propos techniqu copi RA ( C L ) = { RA ( x )| x ∈ C L } to the gpu (hereafter, when there be no 
ambiguity, we simpli denot RA ( C L ) a RA ). the techniqu also copi transact block of the first level (i.e., TB 1: R ) to 

gpu a the inner operand. We note that the outer operand, RA , or the inner operand, TB 1: R , or both, might not fit in gpu 

memory. thus, the propos techniqu partit the outer operand RA into RA 1: Q and copi each RA j to the gpu indi- 

vidual (1 ≤ j ≤ Q ). then, for each RA j , it stream each piec of the inner operand, i.e., transact block, TB k to the gpu 
(1 ≤ k ≤ R ). In most intermedi levels, the outer operand, RA , be much small than the inner operand, TB . In particular, 
when the entir RA can be kept in gpu memori (i.e., Q = 1), stream TB k to the gpu becom a major oper of thi 
technique. 

for each pair 〈 RA j , TB k 〉 , gminer calcul the partial support of x ∈ RA j within TB k . We denot the partial support for 
〈 RA j , TB k 〉 a PS j, k . We formal defin the partial support of itemset x in definit 3 . 
definit 3 (partial support) . We defin σ x ( TB k ) a the partial support of an itemset x within a give transact block TB k . 
the full support of x on the entir transact bitmap TB 1: R becom σ ( x ) = 

∑ R 
k =1 σx (T B k ) . 

To calcul the partial support σ x ( TB k ) for an itemset x = { i 1 , . . . , i n } , gminer simpli perform bitwis and oper 
n − 1 time among bit vector of { TB k ( i )| i ∈ x } and count the number of 1 in the result bit vector. gminer can effici 
access to the locat of the bit vector TB k ( x ) becaus RA ( x ) contain the rel memori address of x in TB k in gpu 

memory. We denot the function to appli a seri of n − 1 bitwis and oper for the itemset x a ⋂ { T B k (x ) } . We also 
denot the function that count the number of 1 in a give bit vector by count ( · ). then, σx (T B k ) = count( 

⋂ { T B k (x ) } ) . 
fig. 1 show the basic data flow of gminer with the nested-loop stream technique. In fig. 1 , the outer operand 

RA 1: Q and inner operand TB 1: R be store in main memori ( Q = 1 ). the buffer for RA j , call rabuf , and the buffer for TB k , 
call tbbuf , be store in gpu memory. here, we alloc rabuf and tbbuf to gpu global memory. gminer copi each 
TB k to tbbuf in a stream fashion via the pci-e bus, after copi RA j to rabuf . To store the partial support valu for all 

candid itemset in RA in each transact block TB k , gminer maintain a two-dimension array of size | RA | x R in main 
memory, denot a psarray , where | RA | be the number of candid itemsets. gminer also alloc the buffer for partial 
support in gpu global memory, denot a psbuf . the partial support valu calcul on the gpu core be first store in 

psbuf in gpu global memory, and then copi back to the psarray in main memory. 

3.3. tfl algorithm 

In thi section, we present the algorithm that implement the tfl strategy. We first explain the overal procedur of 

the algorithm use the exampl show in fig. 1 . the tfl strategi perform a total of seven steps. We denot the set of 

candid itemset at the current level in the itemset lattic a C L . In step 1, the tfl strategi convert C L to RA by map 

each itemset x in C L to it rel memori address RA ( x ) use dict . here, dict be a dictionari that map a frequent 1- 

itemset x ∈ F 1 to RA ( x ) within a transact block TB k . If the size of RA be larg than that of rabuf in gpu memory, then RA 
be logic divid into Q partitions, i.e., RA 1: Q , such that each partit can fit in rabuf . In step 2, it copi a partit RA j 
to rabuf in gpu memory. In step 3, it copi each transact block TB k to tbbuf in gpu memori in a stream fashion. 

In step 4-5, the gpu kernel function for the bitwis and operations, denot a K tfl , calcul the partial support of 
candid itemset in rabuf and store the valu in psbuf . In step 6, the tfl strategi copi the partial support in psbuf 

back to psarray in main memory. here, it copi the valu of TB k to the k -th column of psarray . In step 7, it aggreg 

the partial support of each itemset x in psarray to obtain σ ( x ). after step 7, gminer find the frequent L -itemset F for 
L 



k.-w. chon et al. / inform scienc 439–440 (2018) 19–38 25 

fig. 1. exampl of the tfl strategy. 































































which the support valu be great than or equal to a give threshold minsup , a in the exist frequent itemset mine 

methods. 

algorithm 1 show the pseudo code for the algorithm. dure initialization, the algorithm load a transact databas 

D into main memori (mm) and alloc psarray to mm. then, it alloc three buffers, namely, tbbuf, rabuf , and psbuf , 

to gpu global memori (dm) (line 1–3). next, it convert D to a set of transact block TB 1: R use F 1 such that each 

transact block can fit in tbbuf (line 4–5). after the dictionari dic t use to map x to RA ( x ) have be construct (line 6), 

it remain fix dure itemset mine becaus the tfl strategi us onli TB 1: R for F 1 a input data. the main loop consist 

of a gener step (line 10–11) and a test step (line 12–20), a in the apriori algorithm; however, compar to the 

apriori algorithm, our algorithm significantli improv the test step perform by stream the transact block 

of F 1 to overcom the limit impos by gpu memory, while simultan exploit gpu comput for fast and 

massiv parallel calcul of partial support (line 12–18). 

We note that the kernel function K tfl be usual call multipl time instead of a singl time (line 16). thi be due to a 

limit on the number of gpu blocks, which we can specifi when call K tfl . the K tfl function can calcul a partial support 

of a singl itemset use a singl gpu block. If we set the maximum number of gpu blocks, denot a maxblk , to 16 K, a 

singl call to K tfl can simultan calcul partial support for 16 K itemsets. thus, if | RA j | = 100 M, we must call the K tfl 
function � 100 M 16 K ≈ 6 , 250 times. that is, for the same transact block TB k in tbbuf , gminer execut the kernel function 
repeatedli while chang the affect portion of RA j . when copi data, RA be the outer operand, and TB be the inner 

operand. however, when call the kernel function, TB k be the inner operand, and RA j be the outer operand. 

next, we present the pseudo code for the gpu kernel function of gminer in algorithm 2 . thi function be use not onli 
in the tfl strategi but also in the hil strategi in section 4 . It take a pair of RA j and TB k , along with doneidx and maxthr , 

a inputs. here, doneidx be the index of the last candid that be process in RA j . thi valu be requir to identifi the 

portion of RA j that the current call of K tfl should process. for example, if | RA j | = 10,0 0 0 and maxblk = 10 0 0, doneidx in the 
second call of K tfl becom 10 0 0. the input maxthr be the maximum number of thread in a singl gpu block, which we can 

specifi when call K tfl , a with maxblk. bid and tid be the id of the current gpu block and gpu thread, respectively, 

which be automat determin system variables. becaus mani gpu block execut concurrently, some might have 

no correspond candid itemset to test. for instance, when | RA j | = 100 and maxblk = 20 0, 10 0 gpu block should not 
execut the kernel function becaus some block would have no itemsets. thus, when the current gpu block have no itemset, 

the kernel function return immedi (line 1–2). the kernel function prepar two frequently-access variables, namely, 

can and sup , in the share memori in gpu to improv performance. the variabl can contain the itemset for which the 

current gpu block bid will calcul the partial support, and the vector sup be initi to zero. 

the main loop of K tfl perform bitwis and oper simultan and repeatedli (line 5–8). under current gpu 
architectures, a singl gpu thread can effici perform bitwis and oper for single-precis width (i.e., 32 bits). 
that is, a singl gpu block can perform bitwis and oper up to maxthr × 32 bit simultaneously. however, the width 
of a transact block W might be consider larg than maxthr × 32 bits. 

fig. 2 show an exampl of K tfl , when maxt hr = 2 , and can = 0 , 1 , 3 . here, we assum that a gpu thread can perform 
bitwis and for 4 bit for simplicity. becaus the length of candid itemset be 3, thread 1 and 2 perform bitwis and 
oper twice over { TB (0), TB (1), TB (3)} and store the result bit in bitv . the kernel repeat thi process W 

maxt hr∗32 



26 k.-w. chon et al. / inform scienc 439–440 (2018) 19–38 













































times. the number of 1 in bitv can easili be count use the popcount function and store in the sup vector. In cuda, 

the popcount function be denot a popc (). the partial support valu be accumul in the sup vector W 
maxt hr∗32 times, a 

show in fig. 2 . finally, the kernel function aggreg the valu in sup into a singl partial support valu in TB k for the 

candid itemset can use a parallelreduct function (line 9). 

3.4. exploit gpu 

In thi section, we present the detail of the gminer implement that exploit gpus. first, we discu how to alloc 
and util the gpu memory. In particular, we consid a method to avoid the out-of-memori issu when handl large- 

scale data use gpus. second, we explain how to set gpu thread and improv the gpu kernel function performance. third, 

we explain the detail of the nested-loop streaming, process, includ both synchron and host-devic transfer. 

first, we alloc three type of buffer to gpu memori onli once; subsequ we use them repeatedli for the entir 

mine task. the out-of-memori issu of current gpu-bas method indic that the overal mine task fail due to 

increas data size that do not fit into gpu global memory. To avoid thi out-of-memori issue, we alloc the buffer 

(i.e., tbbuf, rabuf , and psbuf ) to gpu global memori onc while consid the gpu memori capacity, and then use them 

repeatedly. when the data (i.e., rel address and transact bitmap) be larg than the size of the correspond 

buffers, our method divid the data (i.e., rel address and transact bitmap) into multipl partitions, each of which 

then fit into the correspond buffer, and then copi each partit to the buffer individually. consequently, our method 

avoid the out-of-memori issu and simultan reduc the buffer alloc overhead in gpu memory. In contrast, 

other gpu-bas method repeatedli alloc the buffer to gpu memori dure the mine task. 

second, we exploit the share memori of gpus. each gpu follow the singl instruct multipl thread (simt) model 

and handl thread in a warp, which be a group of 32 threads. multipl warp form a gpu block, and thread in the same 

gpu block can quickli commun with one anoth use share memori and built-in primitives. frequent access 

gpu global memori to updat variabl be gener prohibit expensive. To avoid thi cost, our method us share 

memori to store the number of 1 in the bit vector correspond to the candid itemset x . after comput the partial 

support for the correspond transact block, our method store the partial support of x in the correspond locat of 

psbuf . As a result, our method improv perform by access the gpu global memori onli once. We also consid the 

number of gpu thread for the gpu kernel function. As discuss in section 3.3 , our gpu kernel function includ the par- 
algorithm 1: the tfl strategy. 

input : D ; /* transact databas */ 

input : minsup; /* minimum support */ 

output : F; /* frequent itemset */ 

1 load D into M M ; 

2 alloc P sarray on M M ; 

3 alloc { T bbu f , rabu f , P sbu f } on dm; 
4 F 1 ← find all frequent 1-itemsets; 
5 build T B 1: R use D and F 1 on M M ; 

6 dict ← dictionari map x to RA (x ) ( x ∈ F 1 ); 
7 L ← 1 ; 
8 while | F L | > 0 do 
9 L ← L + 1 ; 

/* gener candid use cpu */ 

10 C L ← gener candid itemset use F L −1 ; 
11 convert C L to RA 1: Q use dict; 

/* test use gpu */ 

12 for j ← 1 to Q do 
13 copi RA j into rabu f of dm; 

14 for k ← 1 to R do 
15 copi T B k into T bbu f of dm; 

16 call K T F L ( RA j , T B k ); /* � | RA j | maxblk time */ 
17 copi P sbu f into P sarray of M M ; 

18 thread synchron of GP Us ; 

19 σ (c) ← ∑ R k =1 P sarray [ c][ k ] , for ∀ c ∈ C L ; 
20 F L ← { c| c ∈ C L ∧ σ (c) ≥ minsup} ; 
21 F ← ⋃ F L ; 
22 return F; 



k.-w. chon et al. / inform scienc 439–440 (2018) 19–38 27 

algorithm 2: K tfl : kernel function for partial supports. 

input : RA j ; /* j-th partit of RA */ 

input : T B k ; /* k -th transact block */ 

input : d oneid x ; /*index of last candid do in RA j */ 

input : maxt hr; /*max number of thread in gpu block*/ 

variabl : can ; /* share variabl for a candid */ 

variabl : sup; /* share variabl for a partial support */ 

1 if d oneid x + bid ≥ | RA j | then 
2 return; 

3 can ← RA j [ d oneid x + bid ] ; 
4 sup[0 : maxt hr] ← 0 ; 
5 for i ← 0 ; i < W 

maxt hr∗32 ; i ← i + 1 do 
6 bitv ← ⋂ i ∈ can T B k [ i ][ w ∗ maxt hr + T ID ] ; 
7 sup[ T ID ] ← sup[ T ID ] + popcount (bit V ) ; 
8 syncthread () ; 

9 P sbu f [ d oneid x + bid ] ← paral l el reduct (sup[]) ; 

fig. 2. the gpu kernel function K tfl (a gpu block take an itemset{a,b,d}). 

fig. 3. multipl asynchron gpu stream of gminer . 













allelreduct function. however, thi function us multipl brand-and-bound operations, which degrad the perform 

when use gpus. thi perform degrad becom more mark a the number of gpu thread increases. therefore, 

by default, we set the number of gpu thread to 32, becaus they might be schedul togeth in the gpu architecture. 

third, we exploit multipl asynchron gpu streams. thi approach reduc the data transmiss overhead between 

main memori and gpu memory. fig. 3 show the timelin of the copi oper of the transact blocks. A cpu thread 

first transfer RA j to rabuf . then, it start multipl gpu streams, each of which perform the follow seri of oper 

repeatedly, while increment k : (1) copi TB to tbbuf , (2) execut the gpu kernel function, denot a K , to calcul 
k 



28 k.-w. chon et al. / inform scienc 439–440 (2018) 19–38 























































































PS j, k , and (3) copi PS j, k back to main memory. We denot the number of gpu stream a m . then, thi scheme requir 

the size of tbbuf to equal m transact block and the size of psbuf to be m x | RA j |, where | RA j | denot the number of 

candid itemset in RA j . In general, the abov three kind of operations, namely, copi to gpu memory, kernel execution, 

and copi to main memory, can overlap with one anoth in the current gpu architectur [16] ; thus, a larg portion of the 

copi time between gpu memori and main memori becom hidden. after process m streams, all the gpu thread 

be synchron by call the cudastreamsynchron function to comput the exact partial support for the correspond 

m transact blocks. here, the number of gpu stream m be specifi by the user; we use m = 4 a the default. 

4. hil strategi 

the tfl strategi in gminer can find all the frequent itemset for a large-scal databas use gpu that have onli a 
limit amount of gpu memory. although it show outstand perform in most cases, it perform might degrad if 

the length of the frequent itemset be to becom veri long. To solv thi issue, we propos the hop from intermedi 

level (hil) strategy, which increas the scalabl of the test step in term of the length of itemset by util more 

memory. We first present the data structur for store some frequent itemset at low intermedi levels, which be call 

fragment block , in section 4.1 , and then present the hil algorithm in section 4.2 . 

4.1. fragment block 

the hil strategi horizont partit each transact block TB k into disjoint fragment block . We defin the fragment 

size a the number of frequent 1-itemset that belong to a singl fragment block. the fragment size be fixed, and we denot 

it a H . thus, there be a total of S = � | F 1 | H fragment block in each transact block. 
the hil strategi materi all frequent itemset within each fragment block. here, materi of itemset x mean 

creat a bit vector for x in the correspond fragment block. becaus the fragment size be H , up to a maximum of 2 | H| − 1 
frequent itemset can be materi in each fragment block. thus, we set the height of a fragment block to 2 | H| − 1 , 
instead of H . 

the hil strategi vertic and horizont partit the transact bitmap TB into fragment blocks, each of which have 

the width W and height 2 | H| − 1 . A fragment block have it own ID within a transact block, denot a fid . each fragment 
block be alloc consecut in main memori (or store a a chunk in secondari storage, similar to a disk page). We 

denot the l -th fragment block of TB k a TB k, l . A fragment block TB k, l consist of 2 
| H| − 1 bit vectors, and we denot the set 

of itemset correspond to those bit vector a itemset ( TB k, l ). fig. 4 show an exampl of the hil strategi in which there 

be a total of R × 3 fragment block and H = 2 . the transact block TB 1 be partit into three fragment block { TB 1, 1 , 
TB 1, 2 , TB 1, 3 }, and each fragment block contain 2 

2 − 1 = 3 bit vectors. In fig. 4 , itemset ( TB 1, 2 ) becom {{ C }, { D }, { C, D }}. 
the bit vector of the n -itemset ( n > 1) in each fragment block be initi with 0 befor materialization. 

In term of space complexity, the hil strategi requir the space of O ( 
| F 1 | 
H × (2 H − 1) × | D | ) bit for the transact 

bitmap. compar with the full materi of frequent itemset at intermedi levels, the fragment block requir 

a much small amount of memory. for example, suppos that | D | = 10 M, and | F 1 | = 500 . then, full materi up to 
third level might requir up to ( 

( 
500 

1 

) 
+ 

( 
500 

2 

) 
+ 

( 
500 

3 

) 
) × 10,0 0 0,0 0 0 ≈ 23 tb. In contrast, the fragment block with H = 5 

requir onli 500 5 × (2 5 − 1) × 10,0 0 0,0 0 0 ≈ 3.6 gb. 
for materialization, the hil strategi perform frequent itemset mine from level 2 to H for each of R × S fragment 

blocks. In general, the number of fragment block increas a the size of databas increas and can becom veri large. 

for fast materi of mani blocks, we util the same nested-loop stream techniqu a be propos in section 3 . 

becaus the fragment block be not correlated, they can be materi independently. 

algorithm 3 present the algorithm to materi the fragment blocks. the algorithm take all the fragment block a 

input. It first calcul the maximum number of fragment block that can be materi simultan use rabuf on 

DM (line 1); we denot thi number a Q . then, it execut the main loop Q times. the algorithm stream the fragment 

block of fid between the start and end of all transact blocks, i.e., FB [1: R, begin : end ] . that is, a total of R × S Q fragment 
block be transfer to gpu memori in a stream fashion. To map the itemset in those block to their rel mem- 

ori addresses, we build the dict (line 5-6). then, the algorithm map onli the itemset for F H − F 1 becaus we do not 
need to materi F 1 (line 7). the algorithm execut the kernel function K hil simultan a it stream the fragment 

block (line 9-12). here, K hil be basic the same with K tfl , but it store bitv vector in the correspond posit in 

the fragment block in tbbuf , instead of calcul partial supports; thu we omit the pseudo code for K hil . after the call 

to K hil completes, the updat fragment block TB k , [ start : end ] be copi back to main memory. thi materi scheme, 

which us gpu computing, be veri fast; it elaps time be almost negligible, a show in section 6 . 

4.2. hil algorithm 

the hil strategi tri to reduc the number of bitwis and oper by util fragment blocks, which be a type 
of precomput results. differ from the tfl strategy, the hil strategi determin the set of fragment at each level 

dynam to reduc the amount of transact bitmap transfer to gpus. algorithm 4 present the pseudo code of the 



k.-w. chon et al. / inform scienc 439–440 (2018) 19–38 29 

fig. 4. exampl of the hil strategy. 

algorithm 3: materi fragment blocks. 

input : T B 1: R, 1: S ; /* fragment block */ 

1 Q ← integ valu satisfi S Q × (2 | H| − 1) < | rabu f | ; 
2 for j ← 1 to Q do 
3 start ← ( j − 1) × S Q + 1 ; 
4 end ← j × S Q ; 
5 F H ← 

⋃ l= end 
l= begin itemset (T B j,l ) ; 

6 dict ← dictionari map x to RA (x ) ( x ∈ F H ); 
7 convert F H − F 1 to RA j use dict; 
8 copi RA j into rabu f of dm; 

9 for k ← 1 to R do 
10 copi T B k, [ start: end] into T bbu f of dm; 

11 call K hil ( RA j , T B k, [ start: end] ); 

12 copi T B k, [ start: end] on DM back to M M ; 

13 thread synchron of GP Us ; 



















hil strategy. It first materi the fragment block use algorithm 3 (line 1-2). after gener the candid itemset 

C L , the algorithm find the minim set of fragments, denot a B , that contain all the itemset in C L (line 7). when the 

level, L , be low, most of fragment would be chosen a the set B . however, a level L increases, the number of fragment 

that contain C L decreases; thus, we can reduc the overhead involv in transfer fragment blocks. becaus the set of 

fragment chang at each level, the rel memori address of candid itemset in C L also change. thus, the algorithm 

build dict use onli the itemset in B at each level and convert C L to RA 1: Q (line 8-9). when stream the transact 

bitmap to the gpus, the algorithm copi onli the relev fragment block TB k, l ∈ B instead of the entir transact block 
TB k . 

In the hil strategi exampl show in fig. 4 , we assum that C L = {{ A, B, E} , { B, E, F }} . then, we can easili identifi the 
fragment B = { 1 , 3 } that contain all the itemset in C . the dictionari dict be built use the first and third fragments; thus, 
L 



30 k.-w. chon et al. / inform scienc 439–440 (2018) 19–38 

algorithm 4: hil algorithm. 

input : D ; /* transact databas */ 

input : minsup; /* minimum support */ 

input : H; /* fragment size */ 

output : F; /* frequent itemset */ 

/* line 1-4 in algorithm 1 */ 

1 build T B 1: R, 1: S use D , F 1 , and H on M M ; 

2 materi the fragment block of T B 1: R, 1: S ; 

3 L ← 1 ; 
4 while | F L | > 0 do 
5 L ← L + 1 ; 

/* gener candid use cpu */ 

6 C L ← gener candid itemset use F L −1 ; 
7 B ← set of fragment block contain C L ; 
8 dict ← dictionari map x ∈ itemset (B ) to RA (x ) ; 
9 convert C L to RA 1: Q use dict; 

/* test use gpu */ 

10 for j ← 1 to Q do 
11 copi RA j into rabu f of dm; 

12 for k ← 1 to R do 
13 copi T B k,l∈ B into T bbu f of dm; 
14 call K T F L ( RA j , T B k,l∈ B ); 
15 copi P sbu f into P sarray of M M ; 

/* line 18-20 in algorithm 1 */ 

16 F ← ⋃ F L ; 
17 return F; 

fig. 5. data flow of gminer use multipl gpus. 



















RA ({ E }) becom 3 instead of 6. when convert an itemset x ∈ C L to RA ( x ), RA ( x ) in the hil strategi be shorter than in the 
tfl strategy. that is, few bitwis and oper be requir to obtain the partial supports. for instance, the length of 
RA ({ A, B, E }) be two (i.e., {2, 3}), wherea it be three in the tfl strategy. As the fragment size H increases, the length of RA ( x ) 

tend to decrease. each RA j be copi to rabuf in gpu memory; then, the first set of fragment block { TB 1, 1 , TB 1, 3 } in B be 

stream to tbbuf in gpu memory. next, the second set of fragment block { TB 2, 1 , TB 2, 3 } be streamed. 

5. multipl gpu and cost model 

5.1. exploit multipl gpu 

gminer can be easili extend to exploit multipl gpu and further improv the performance. when exploit multipl 
gpus, gminer copi the differ portion of the outer operand to the differ gpu and copi the same transact (or 
fragment) block to all the gpus. We call thi scheme a the transact bitmap share scheme. thi scheme can be appli 

to both tfl and hil strategies. 

fig. 5 show the data flow of our scheme. when there be two gpus, the scheme copi RA 1 to gpu 1 and RA 2 to gpu 2 . 

then, it copi the same TB to both gpu and gpu . the kernel function on gpu calcul the partial support in RA , 
1 1 2 1 1 



k.-w. chon et al. / inform scienc 439–440 (2018) 19–38 31 

tabl 2 

statist of transact dataset use in the experiments. 

name webdoc quest-def quest-scale1 quest-scale2 

T avg 177.2 200 200 200 

M avg n/a 25 25 25 

|d| (m) 1.692 10 [1,5,10,15] 10 

|i| (k) 5268 10 10 [5,10,15,20] 

size (gb) 1.4 9 [0.9,4.6,9.1,14] [8.9,9.1,9.8,11] 



































































while that on gpu 2 calcul the partial support in RA 2 . note that becaus RA 1 and RA 2 have no common itemsets, the 

result of both kernel function can be copi back to psarray in main memori without conflicts. 

thi scheme be highli scalabl in term of the number of gpu use becaus RA j and RA k be independ task ( j 
= k ). In 
addition, it do not have the problem of workload imbalances, which be a typic issu in distribut and parallel comput 

methods. the comput be not skew when RA j and RA k be the same size, becaus the comput heavili reli on 

the number of bitwis and oper and do not use complex or irregular data structures. therefore, regardless of the 
characterist of the process datasets, the propos scheme achiev a stabl speed-up ratio when use multipl gpus. 

5.2. cost model 

In thi section, we present the cost model of gminer to understand it perform tendencies. In particular, we present 
the model for the tfl strategi and skip that of the hil strategi due to their similarity. here, we consid the factor that 

significantli affect the performance. the cost model of the tfl strategi be give by 

# iter ∑ 
L =1 

( | RA 1: Q | 
c1 × N + 

Q 

N 
× 

{ | T B 1: R | 
c2 

+ t call 
( 

R × � | RA j | 
maxblk 


) 

+ t kernel (T B R ) + 
| P S j,r | 

c2 

}) 
. (1) 

where, c 1 and c 2 respect repres the commun rate between main memori and gpu memori in chunk copi 

mode (approxim 12gb/sec in pci-e 3.0 x16 interface, in practice) and that in stream copi mode (approxim 

8gb/sec in pci-e 3.0 x16 interface, in practice), and N repres the number of gpus. the term 
| RA 1: Q | 
c1 ×N repres the total 

amount of time requir to copi the outer operands, i.e., RA 1: Q to gpu memory. It be divid by N becaus the data be trans- 

fer concurr to N gpus. the term in bracket repres the cost of stream the inner operand and comput 

partial supports. In detail, the term 
T B 1: R 

c2 repres the cost of stream the transact blocks. It cannot be reduc by 

use multipl gpu due to the characterist of the transact bitmap share scheme. here, t call ( n ) be the time overhead 

for call a kernel function n times. the tfl strategi call the kernel function R × � | RA j | 
maxblk 

time for each RA j . the term 
t kernel ( TB R ) indic the kernel execut time for the last singl transact block, which cannot be hidden by data stream- 

ing. likewise, the term 
| PS j,r | 

c2 indic the cost for copi the last partial support for RA j back to main memory, which 

also cannot be hidden by streaming. 

6. perform evalu 

In thi section, we present the experiment evalu of gminer compar with other repres method sum- 
mariz in tabl 1 . We present experiment result in three categories. first, we evalu the perform of gminer 
compar with the repres sequenti (i.e., single-threaded) methods, apriori by borgelt [6] , eclat by borgelt [6] , 

eclat by goethal [10] , fp-growth ∗ [11] , and lcm [30] . second, we evalu the perform of gminer compar with the 
repres parallel (i.e., multi-threaded, distributed, and gpu-based) methods. the consid multi-thread method 

be mc-eclat [26] , shafem [32] , and fp-array [20] ; the distribut method be the implement of fp-growth with mllib 

[3] of apach spark; and the gpu-bas method be tbi [7] , gpapriori [37] , and frontier expans [38] . third, we exam- 

ine the perform characterist of gminer while vari a wide rang of set and compar them with those of the 
tfl and hil strategies. 

6.1. experiment setup 

for experiments, we use both a real dataset and synthet datasets, a present in tabl 2 . As the real dataset, we use 

the larg dataset from fimi repositori [8] , call webdoc [21] , which have be wide use for the perform evalu- 

ation of frequent itemset mining. As synthet datasets, we use dataset gener by use ibm quest dataset gener 

[2] , which accept four major parameters: T avg , the averag number of item per transaction; M avg , the averag length of the 

maxim pattern; | D |, the number of transactions; and | I |, the number of distinct items. In tabl 2 , the valu of | D | be in 

million (m) and the valu of | I | be in thousand (k). We gener the default synthet dataset, which be call quest-def, 

and multipl variat by chang parameters. We note that webdoc be rel sparse, wherea quest-def be rel 

dense. 



32 k.-w. chon et al. / inform scienc 439–440 (2018) 19–38 

fig. 6. perform comparison with sequenti frequent itemset mine methods. 





















































To evalu lcm, fp-growth ∗, eclat (borgelt), eclat (goethals), apriori (borgelt), gpapriori, tbi, and frontier expansion, 
we download and compil their late sourc code. To evalu mc-eclat, shafem, and fp-array, we use the implement 

present in [36] and [5] . To evalu apach spark mllib’ fp-growth, we download and use the sourc code from [3] . all 

the method in experi be compil with the same optim option, name -o3, with gcc 4.9. We perform all 

experi on ubuntu 14.04.3 lt with the same gpu toolkit, namely, cuda 7.5. for the distribut methods, we use 

scala 2.11.7, spark 1.5.0, and hadoop 1.2.1. when measur the elaps time of gpu-bas method such a tbi, gpapriori, 

frontier expansion, and gminer , to perform a fair comparison, we includ all the time spent transfer data between gpu 
memori and main memory. We set the number of gpu stream for gminer to four a the default. 

We conduct all the experi on a machin with two intel 8-core cpu run at 2.90 ghz (a total of 16 cores), 

128 GB of main memory, and four nvidia gtx 1080 gpu with 2560 core run at 1.7 ghz, 8 GB of devic memory, 

and 96 KB of share memory. the nvidia gtx 1080 gpu follow the pascal gpu architectur and support cuda 8.0, which 

includ mani new features, such a improv compil performance. the cpu and gpu be connect via pci-e 3.0 x16 

interface. We conduct all the experi that involv distribut method on a cluster of eleven machines, one master and 

ten slaves, each of which be equip with an intel quad-cor cpu run at 3.40 ghz, 32 GB of main memory, and 4 TB 

hdds. that is, the cluster slave have a total of 40 cpu core and 320 GB main memory. 

We present the detail set use for the gpu-bas methods, namely, tbi [7] , gpapriori [37] , frontier expans [38] , 

and gminer . for both tbi and gpapriori, the experiment settings, such a the number of gpu thread and the number of 
gpu blocks, be not give in their papers. therefore, for both methods, we set the number of gpu thread and the number 

of gpu block to 32 and 16,384, respectively, which be the best paramet found through trial-and-error-bas tuning. 

for frontier expansion, 256 gpu thread and 2048 gpu block be use in the origin studi [38] . however, we found 

that these paramet do not yield the best perform in our experiment environments. therefore, we set the number 

of gpu thread and the number of gpu block to 32 and 4,096, respectively, which be the best paramet we found. for 

gminer , we set the number of gpu threads, the number of gpu blocks, and the number of gpu stream to 32, 16,384, and 
4, respectively. for gminer , we set the width of transact block to 8192 in four bytes. 

6.2. comparison with sequenti method 

fig. 6 (a) and (b) present the speed-up ratio of gminer over the repres sequenti methods, namely, fp-growth ∗, 
lcm, eclat (borgelt), eclat (goethals), and apriori (borgelt), on both the webdoc and quest-def dataset while vari 

minsup . the speed-up ratio on the y-axi be show in log-scale, and o.o.m. mean an out-of-memori error. We use the 

same X -axi rang a in [26] . In the figures, although the elaps time of all the method decreas a minsup increases, the 

gap in elaps time between gminer and all the other method increas slightly; thus, the speed-up ratio also increas 
slightly. 



k.-w. chon et al. / inform scienc 439–440 (2018) 19–38 33 

fig. 7. perform comparison with cpu-bas parallel frequent itemset mine methods. 













































for both the webdoc and quest-def datasets, gminer consist and significantli outperform all other methods. In 
fig. 6 (a), gminer outperform lcm, fp-growth ∗, eclat (borgelt), and apriori (borgelt) by factor of 7 − 100 , 23 − 494 , 13 − 
90 , and 124 − 3094 , respectively. among the exist methods, lcm show the overal best perform on both datasets. 
the larg perform gap between gminer and the exist method be mainli due to the tfl strategy, which fulli exploit 
fast and massiv bitwis comput use thousand of core and simultan reduc the memori access overhead 

by use rel memori address on the transact block of F 1 and nested-loop streaming, a explain in section 3 . 

In fig. 6 (b), lcm and eclat (borgelt) encount o.o.m. error becaus they tend to consum more memori when improv 

the perform than do the other exist methods. 

6.3. comparison with cpu-bas parallel method 

figs. 7 (a) and (b) present the speed-up ratio of gminer over the repres cpu-bas parallel methods, namely, 
mc-eclat, shafem, fp-array, and mllib, on both the webdoc and quest-def datasets. mc-eclat, shafem, and fp-array be 

cpu-bas parallel method that run on a singl machine, and mllib be a distribut method that run on spark. On both 

the webdoc and quest-def datasets, gminer still consist and significantli outperform all other methods, except for 
fp-array at minsup = . 06 on the webdoc dataset. In fig. 7 (a), gminer outperform mc-eclat and fp-array by factor of 
3 . 3 − 94 and 0 . 45 − 2 . 8 , respectively. 

among the exist three multi-thread methods, fp-array achiev the best overal perform on the webdoc 

dataset, while mc-eclat achiev the best overal perform on the quest-def dataset. fp-array usual result in o.o.m. 

error on the quest-def dataset, becaus it requir more memori than do mc-eclat and shafem. As state earlier, fp-array 

be a multi-thread version of fp-growth ∗; therefore, it requir consider more memori than do fp-growth ∗. however, 
fp-array be much faster than fp-growth ∗ on a give dataset and with the same minsup value. between the webdoc and 
quest-def datasets, quest-def usual requir more memori becaus it be denser. shafem result in the bad perform 

among multi-thread methods. We note that a distribut method, namely, mllib, achiev the bad perform among 

the exist parallel method or fail to find frequent itemsets, although it util a total of 40 cpu core and 320 GB of 

main memory. mllib be base on fp-growth, where each condit databas be process by the fp-growth method in each 

machine. In some cases, the degre of workload skew (i.e., imbalance) be extrem high; in such cases, a singl con- 

dition databas have almost the same size a the origin database. In addition, mllib’ fp-growth be implement on top 



34 k.-w. chon et al. / inform scienc 439–440 (2018) 19–38 

fig. 8. perform comparison with gpu-bas parallel frequent itemset mine methods. 









































of apach spark; thus, it tend to use more memori than do the origin fp-growth and incur addit overhead. these 

result suggest that improv the perform of frequent itemset mine use the sequenti method be non-trivial, and 

a parallel method must be devis care to achiev that goal. 

6.4. comparison with gpu-bas parallel method 

figs. 8 (a) and (b) present the speed-up ratio of gminer over the repres gpu-bas parallel methods, includ- 
ing frontier expansion, tbi, and gpapriori, on both the webdoc and quest-def datasets. note that the exist gpu-bas 

method outperform the cpu-bas methods, but onli when the size of data to be copi to gpu memori be quit small. 

In contrast, the perform of the gpu-bas method degrad compar with cpu-bas method a the data size in- 

creases. thi be becaus the data transmiss overhead between main memori and gpu memori can significantli affect 

the performance. gminer do not have the drawback of the exist gpu-bas methods. for instance, gminer reduc 
the overhead of data transmiss between the host and gpu devic by exploit multipl gpu streams, a explain in 

section 3 , while other method do not hide the overhead. As a result, gminer outperform the state-of-the-art cpu-bas 
methods, a show in figs. 6 and 7 . 

frontier expans achiev a perform similar to mc-eclat for webdocs, but be outperform by mc-eclat on quest- 

def. In mani cases, frontier expans fail to find frequent itemset due to o.o.m. error on quest-def. thi result occur 

becaus frontier expans tri to maintain frequent itemset at the intermedi level in gpu memori and quest-def be 

denser than webdocs; therefore, it must store consider more intermedi data in gpu memory. tbi outperform fron- 

tier expans at the minsup valu of 0.1-0.18 on webdocs, becaus tbi process more candid itemset simultaneously. 

however, tbi show o.o.m. error at the minsup valu of 0.06-0.08, while frontier expans success complet the 

pattern mine at the same minsup values. thi be becaus tbi tri to maintain a larg number of frequent intermediate- 

level itemset in gpu memori than do frontier expansion. gpapriori result in o.o.m. error in all case on both webdoc 

and quest-def; that is, the size of it static bitmap be larg than the capac of main memori (i.e., 128 gb). thi result 

occur becaus gpapriori gener a static bitmap for the whole input databas without prune the infrequ 1-itemset 

dure initialization. 



k.-w. chon et al. / inform scienc 439–440 (2018) 19–38 35 

fig. 9. scalabl test vari the number of transact and distinct items. 

fig. 10. speed-up ratio when use multipl gpu for gpu-bas methods. 

























6.5. scalabl test 

figs. 9 (a) and (b) present the speed-up ratio of gminer over the repres sequenti and parallel methods, namely, 
fp-growth ∗, lcm, eclat (borgelt), eclat (goethals), apriori (borgelt), mc-eclat, fp-array, and frontier expansion, on the 
quest-def dataset. In these experiments, we omit gpapriori, tbi, shafem, and mllib becaus they result in rel 

poor perform in the experi in section 6.2, 6.3 , and 6.4 . fig. 9 (a) show the result obtain while vari the 

number of transact (i.e., quest-scale1 in tabl 2 ). As the number of transact increases, the speed-up ratio also 

increase, i.e., gminer improv the perform more compar to the exist methods. fig. 9 (b) show the result ob- 
tain while vari the number of distinct itemset (i.e., quest-scale2 in tabl 2 ). As the number of distinct itemset (i.e., 

| I |) increases, the speed-up ratio remain approxim constant. gminer consist outperform the exist methods, 
regardless of the valu of | I |. 

figs. 10 (a) and (b) present the speed-up ratio obtain when use two gpu for the gpu-bas methods, namely, 

frontier expans and gminer. here, the theoret maximum speed-up ratio be two. On both the webdoc and quest-def 

datasets, gminer achiev ratio close to thi maximum valu in most cases. In contrast, frontier expans show much 
low speed-up ratio below one in most cases, which mean that use two gpu degrad it perform compar to 



36 k.-w. chon et al. / inform scienc 439–440 (2018) 19–38 

fig. 11. speed-up ratio of gminer when use multipl gpu and vari the characterist of datasets. 

fig. 12. find optim W and the number of gpu blocks. 

















































use a singl gpu. when the rang of minsup be within [0.1, 0.14] on webdocs, the speed-up ratio of gminer degrad 
slightli becaus the total elaps time be too short ( ≤ 1 sec .) and the time spent in support count use gpu be rel 
small. however, except when the workload be small, gminer achiev almost the maximum speed-up ratio becaus it share 
the transact bitmap among all the gpu and assign equal-s independ RA j to each gpu, a explain in section 5.1 . 

In contrast, frontier expans assign a subtre of the enumer tree (i.e., equival class) to each gpu. becaus it be 

like that those subtre have differ amount of workload (that is, a workload skew problem occurs), it scalabl 

can degrad greatly. In addition, frontier expans requir a larg overhead when exploit multipl gpu than do 

gminer becaus it divid the search space of pattern into equival classes. 
figs. 11 (a)-(b) present the speed-up ratio of gminer when use multipl gpus. We defin the speed-up ratio a T 1 T M , 

where T 1 and T M be the run time use a singl gpu and M gpus, respectively. fig. 11 (a) show the ratio obtain 

while vari the number of transact (i.e., | D |) among 1 M, 5 M, 10 M, and 15 M. fig. 11 (b) show the ratio obtain 

while vari the number of distinct item (i.e., | I |) among 5 K, 10 K, 15 K, and 20 K. the result show that regardless of the 

dataset characteristics, the speed-up ratio of gminer increas almost linearly. We note that there be a small gap between 
the number of gpu and the ideal speed-up ratio; thi gap occur mainli becaus of synchron overhead among the 

gpus. 

6.6. characterist of gminer 

fig. 12 present the elaps time obtain while vari the width of TB (i.e., W ) and the number of gpu blocks, on 

both datasets. As show in the figure, 8 K × 32 = 262,144 bit for the width of TB and 16 K gpu block yield the best 
overal performance; thus, we appli these valu a the default set for gminer . becaus gminer set the number of 
thread per gpu block to 64, the total number of thread use in gminer be 64 × 16 K = 1 million. 

fig. 13 present the variou characterist use in the hil strategi of gminer . fig. 13 (a) show the memori usag a a 
function of the fragment size ( H ), which increas almost exponenti a H increases. fig. 13 (b) show the elaps time 

for fragment materi (describ in algorithm 3 ) which increas in proport to the amount of memori usag in 

fig. 13 (a). We note that the materi time be veri short compar with the total run time in fig. 13 (d) and be 

almost negligible. fig. 13 (c) show the ratio of the number of fragment block copi to gpu memori for support count 

to the total number of fragment block in each iteration. when H = 1, i.e., use the tfl strategy, the transact block 
for F 1 be copi to gpu memori at everi iteration, so the usag ratio be 100%. however, when H > 1, i.e., use the hil 

strategy, onli a necessari subset of fragment block be copi to gpu memory, a describ in algorithm 4 result in a 



k.-w. chon et al. / inform scienc 439–440 (2018) 19–38 37 

fig. 13. characterist of the hil strategy. 

fig. 14. evalu of the hil strategi for databas contain long patterns. 































usag ratio of approxim 55%, regardless of fragment size. fig. 13 (d) show the total run time, which be minim 

when H = 5. 
We note that the support count step still take most of the run time even though gminer exploit gpu for 

support counting. base on these results, we set H = 5 a the default for the hil strategy. 
fig. 14 present the comparison result between the tfl and hil strategies. for thi experiment, we add a long pattern 

of length n to the quest-def dataset; a a result, the dataset contain mani long pattern of length n - 1, n - 2, and so on. 

fig. 14 (a) show the total mine time (a a multipl of 10 0 0 sec.) a a function of the length of n . the hil strategi outper- 

form the tfl strategi from n = 22; subsequently, the perform gap between two strategi increas a n increases, a 
explain in section 4 . the hil strategi reduc the number of bitwis and operations, while use more memory. fig. 14 (b) 
show the trade-off between run time and memori usag a a function of H in the hil strategy. In thi figure, H = 7 
yield slightli improv performance, but greatli increas the memori usage. thus, we suggest that H = 5 be a good set 
for databas that contain long patterns. 

7. summari 

In thi paper, we propos a fast gpu-bas frequent itemset mine method for large-scal dataset call gminer . In 
detail, we propos the tfl strategy, which fulli exploit the comput power of gpu by perform a larg amount of 

comput on a small amount of data, and the hil strategy, which can further improv the perform on dataset that 

contain long pattern by perform a moder amount of comput on a moder amount of data. gminer solv the 
workload skew problem the exist parallel method suffer from by split an array of rel memori address 

for candid itemset among the gpu and stream transact block to all the gpus. through extens experiments, 



38 k.-w. chon et al. / inform scienc 439–440 (2018) 19–38 











































we demonstr that gminer significantli outperform most of the state-of-the-art method that have be address in 
recent studi [4,9,25,31,33] on two kind of benchmarks, and it perform be scalabl in term of the number of gpus. 

acknowledg 

thi research be support by basic scienc research program through the nation research foundat of korea(nrf) 

fund by the ministri of science, ict and futur plan ( 2017r1e1a1a01077630 ) and samsung research fund center 

of samsung electron under project number srfc-it1502-10. 

refer 

[1] c.c. aggarw , J. han , frequent pattern mining, springer, 2014 . 

[2] R. agrawal, R. srikant, fast algorithm for mine associ rule in larg databases, in: proceed of vldb, 1994, pp. 4 87–4 99 . url http://www. 

vldb.org/conf/1994/p487.pdf . 
[3] apach spark mllib, http://spark.apache.org/mllib/ , 2017. 

[4] E. barali , T. cerquitelli , S. chiusano , A. grand , scalabl out-of-cor itemset mining, inf. sci. (ny) 293 (2015) 146–162 . 
[5] C. bienia , S. kumar , j.p. singh , K. Li , the parsec benchmark suite: character and architectur implications, in: proceed of pact, acm, 2008, 

pp. 72–81 . 
[6] C. borgelt , effici implement of apriori and eclat, in: proceed of fimi, 2003 . 

[7] W. fang , M. Lu , X. xiao , B. He , Q. luo , frequent itemset mine on graphic processors, in: proceed of damon, acm, 2009, pp. 34–42 . 

[8] fimi repository, http://fimi.ua.ac.b , 2005. 
[9] P. fournier-vig , j.c.-w. lin , B. Vo , t.t. chi , J. zhang , h.b. Le , A survey of itemset mining, interdisciplinari reviews: data mine and knowledg 

discovery, wiley, 2017 . 
[10] B. goethal , survey on frequent pattern mining, univers of helsinki, 2003 . 

[11] G. grahn , J. zhu , effici use prefix-tre in mine frequent itemsets., in: proceed of fimi, 90, 2003 . 
[12] F. gui, Y. ma, F. zhang, M. liu, F. li, W. shen, H. bai, A distribut frequent itemset mine algorithm base on spark, in: proceed of cscwd, 2015, 

pp. 271–275 . url https://doi.org/10.1109/cscwd.2015.7230970 . 

[13] J. han , J. pei , M. kamber , data mining: concept and techniques, elsevier, 2011 . 
[14] J. han , J. pei , Y. yin , mine frequent pattern without candid generation, in: acm sigmod record, 29, acm, 20 0 0, pp. 1–12 . 

[15] y.-s. huang , k.-m. Yu , l.-w. zhou , c.-h. hsu , s.-h. liu , acceler parallel frequent itemset mine on graphic processor with sorting, in: network 
and parallel computing, springer, 2013, pp. 245–256 . 

[16] m.-s. kim , K. An , H. park , H. seo , J. kim , gts: a fast and scalabl graph process method base on stream topolog to gpus, in: proceed of 
sigmod, acm, 2016, pp. 447–461 . 

[17] H. Li , Y. wang , D. zhang , M. zhang , e.y. chang , pfp: parallel fp-growth for queri recommendation, in: proceed of recsys, acm, 2008, pp. 107–114 . 

[18] C. lin, K. yu, W. ouyang, J. zhou, An opencl candid slice frequent pattern mine algorithm on graphic process units, in: proceed of smc, 
2011, pp. 2344–2349 . url https://doi.org/10.1109/icsmc.2011.6084028 . 

[19] m.-y. lin , p.-y. lee , s.-c. hsueh , apriori-bas frequent itemset mine algorithm on mapreduce, in: proceed of icuimc, acm, 2012, p. 76 . 
[20] L. liu , E. Li , Y. zhang , Z. tang , optim of frequent itemset mine on multiple-cor processor, in: proceed of pvldb, vldb endowment, 2007, 

pp. 1275–1285 . 
[21] C. lucches , S. orlando , R. perego , F. silvestri , webdocs: a real-lif huge transact dataset., in: proceed of fimi, 126, 2004 . 

[22] S. moen , E. aksehirli , B. goethal , frequent itemset mine for big data, in: big data, ieee, 2013, pp. 111–118 . 
[23] S. orlando , kdci: a multi-strategi algorithm for mine frequent sets, in: proceed of ieee icdm’03 workshop fimi’03, 2003 . 

[24] S. parthasarathi , m.j. zaki , M. ogihara , W. Li , parallel data mine for associ rule on shared-memori systems, knowl. inf. syst. 3 (1) (2001) 1–29 . 

[25] B. schlegel , frequent itemset mine on multiprocessor systems, technischen universität dresden, 2013 . dissert 
[26] B. schlegel , T. karnagel , T. kiefer , W. lehner , scalabl frequent itemset mine on many-cor processors, in: proceed of damon, acm, 2013, p. 3 . 

[27] B. schlegel , T. kiefer , T. kissing , W. lehner , pcapriori: scalabl apriori for multiprocessor systems, in: proceed of ssdbm, acm, 2013, p. 20 . 
[28] C. silvestri, S. orlando, gpudci: exploit gpu in frequent itemset mining, in: proceed of pdp, 2012, pp. 416–425 . url https://doi.org/10.1109/ 

pdp.2012.94 . 
[29] G. teodoro, N. mariano, W. M. jr., R. ferreira, tree projection-bas frequent itemset mine on multicor cpu and gpus, in: proceed of sbac-pad, 

2010, pp. 47–54 . url https://doi.org/10.1109/sbac-pad.2010.15 . 

[30] T. uno , M. kiyomi , H. arimura , lcm ver. 2: effici mine algorithm for frequent/closed/maxim itemsets, in: proceed of fimi, 126, 2004 . 
[31] r.l. Uy , m.t.c. suarez , survey on the current statu of serial and parallel algorithm of frequent itemset mining, manila J. sci. 9 (2016) 115–135 . 

[32] L. Vu , G. alaghband , novel parallel method for mine frequent pattern on multi-cor share memori systems, in: proceed of discs, acm, 2013, 
pp. 49–54 . 

[33] K. wang, Y. qi, j.j. fox, m.r. stan, K. skadron, associ rule mine with the micron automaton processor, in: proceed of ipdps, 2015, pp. 689–699 . 
url https://doi.org/10.1109/ipdps.2015.101 . 

[34] m.j. zaki , K. gouda , fast vertic mine use diffsets, in: proceed of sigkdd, acm, 2003, pp. 326–335 . 

[35] m.j. zaki , S. parthasarathi , M. ogihara , W. Li , et al. , new algorithm for fast discoveri of associ rules., in: proceed of kdd, 97, 1997, 
pp. 283–286 . 

[36] S. zalewski , mine frequent intra-and inter-transact itemset on multi-cor processors, ntnu, 2015 . (m thesis) 
[37] F. zhang, Y. zhang, j.d. bakos, gpapriori: gpu-acceler frequent itemset mining, in: proceed of cluster, 2011, pp. 590–594 . url https://doi. 

org/10.1109/cluster.2011.61 . 
[38] F. zhang, Y. zhang, j.d. bakos, acceler frequent itemset mine on graphic process units, J. supercomput. 66 (1) (2013) 94–117 . url https: 

//doi.org/10.1007/s11227- 013- 0887- x . 

[39] J. zhou, K. yu, B. wu, parallel frequent pattern mine algorithm on gpu, in: proceed of smc, 2010, pp. 435–440 . url https://doi.org/10.1109/ 
icsmc.2010.5641778 . 

https://doi.org/10.13039/501100003621 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0001 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0001 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0001 
http://www.vldb.org/conf/1994/p487.pdf 
http://spark.apache.org/mllib/ 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0003 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0003 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0003 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0003 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0003 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0004 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0004 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0004 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0004 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0004 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0005 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0005 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0006 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0006 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0006 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0006 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0006 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0006 
http://fimi.ua.ac.b 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0007 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0007 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0007 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0007 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0007 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0007 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0007 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0008 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0008 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0009 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0009 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0009 
https://doi.org/10.1109/cscwd.2015.7230970 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0011 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0011 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0011 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0011 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0012 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0012 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0012 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0012 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0013 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0013 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0013 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0013 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0013 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0013 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0014 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0014 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0014 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0014 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0014 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0014 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0015 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0015 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0015 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0015 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0015 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0015 
https://doi.org/10.1109/icsmc.2011.6084028 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0017 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0017 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0017 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0017 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0018 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0018 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0018 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0018 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0018 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0019 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0019 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0019 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0019 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0019 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0020 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0020 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0020 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0020 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0021 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0021 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0022 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0022 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0022 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0022 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0022 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0023 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0023 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0023 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0024 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0024 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0024 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0024 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0024 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0025 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0025 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0025 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0025 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0025 
https://doi.org/10.1109/pdp.2012.94 
https://doi.org/10.1109/sbac-pad.2010.15 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0028 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0028 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0028 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0028 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0029 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0029 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0029 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0030 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0030 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0030 
https://doi.org/10.1109/ipdps.2015.101 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0032 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0032 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0032 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0033 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0033 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0033 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0033 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0033 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0033 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0034 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0034 
http://refhub.elsevier.com/s0020-0255(18)30069-0/sbref0034 
https://doi.org/10.1109/cluster.2011.61 
https://doi.org/10.1007/s11227-013-0887-x 
https://doi.org/10.1109/icsmc.2010.5641778 

gminer: A fast gpu-bas frequent itemset mine method for large-scal data 
1 introduct 
2 relat work 
2.1 sequenti method 
2.2 multi-thread method 
2.3 distribut method 
2.4 gpu-bas method 

3 tfl strategi 
3.1 transact block 
3.2 nested-loop stream 
3.3 tfl algorithm 
3.4 exploit gpu 

4 hil strategi 
4.1 fragment block 
4.2 hil algorithm 

5 multipl gpu and cost model 
5.1 exploit multipl gpu 
5.2 cost model 

6 perform evalu 
6.1 experiment setup 
6.2 comparison with sequenti method 
6.3 comparison with cpu-bas parallel method 
6.4 comparison with gpu-bas parallel method 
6.5 scalabl test 
6.6 characterist of gminer 

7 summari 
acknowledg 
refer 


