






































whi (or rather, when) suffer in AI be incoherent. 


3rd decemb 2016 

[http://gunshowcomic.com/513] 
from gunshow by KC green 

i'v be argu for some month now [http://joanna-bryson.blogspot.com/2016/09/what-makes-person-five-reasons-not-to.html] 
in public talk that AI cannot be a legal person becaus suffer in well-design AI be incoherent. thi be not actual 
my own argument, but rather be due to S. M. solaiman from their brilliant recent articl legal person of robots, 
corporations, idol and chimpanzees: a quest for legitimaci [http://link.springer.com/article/10.1007/s10506-016-9192-3] . 

the great thing about solaiman' 
articl be that they make it clear whi 
corpor be legal person but AI 

and chimpanze aren't. basically, 
the notion of legal person have be 
develop to synchronis with our 
system of justice. justic among 

other thing requir mean of 
redress and coercion. A legal 
person most know and be abl to 
claim their rights–they must be abl 

to assert themselv a member of 
a society. thi be whi non-human 
anim (and some incapacit 
humans) be not legal persons. i'm 

happi with definit of "know" and 
"assert" that would mean that 
intellig artefact could do this, and 
inde organis of human can 

meet these criteria. however, legal 
person must also like ani person care about the kind of sanction that justic can use against them, so that justic can 
bind societi together. justic be part of the way a societi compos itself of individuals, it be part of the glue that turn a 
set of individu into a group. To date thi have not involv direct "joystick" manipulation, but rather sanction that 

individu find aversive, such a loss of time and/or social status. non-human anim can definit suffer, a I said, 
the onli thing that make them not legal person be their incapac to understand and argu their rights. but can AI 
suffer? solaiman conclud "not yet", but I would like to go further. 

pain, suffering, and concern for social statu be thing essenti to a social species, and a such they be integr to our 
intelligence. i'v read it argu that one of the characterist of a sociopath be miss thi part of what it be to be human, 
but i'm not an expert on clinic psycholog so don't know whether thi be ever truli possibl even in these extrem 
cases. but safe, well architect (designed) AI tend to be modular. I and my student build system of emot for AI 

[http://www.cs.bath.ac.uk/~jjb/web/ai.html#emot] , and i'm happi to have some variabl that repres an emot on which 
other behaviour depends. I don't have an issu with say a robot be excit or depress if it action express have 
be increas or inhibited, respectively. 

but I have an issu with say that a well-design robot be suffering, becaus suffer be defin to be someth 
suffici avers that you would avoid it. but anyth we insert into a well design AI we (or conceiv it) could 
extract and isolate. thi isn't the natur of suffering. 

I be not say I cannot conceiv of AI that could suffer. thi may not be like or even possible, but if we do actual 
construct AI by scan in a human or anim (really, it would have to be the whole thing, not just the brain – brain cell 
refer muscl cell and such like) then no doubt it could suffer. but that would not be well-design ai; rather, that 
would be a sort of clone [http://joanna-bryson.blogspot.com/2015/10/clones-should-not-be-slaves.html] . own human clone 

strike me a deepli uneth – exactli a uneth a own humans. build synthet clone of anim also more 
gener strike me a deepli inefficient; we would be good off work with the anim we have rather than 
construct clone of them from materi that aren't a well suit to purpos a their origin biology. 

whi (or rather, when) suffer in AI be incoherent. 

whi (or rather, when) suffer in AI be incoherent. https://joanna-bryson.blogspot.be/2016/12/why-or-rather-when-suffering-... 

1 sur 2 17-01-17 18:21 



So I find it extrem unlik we will ever have AI suffering, but even if we do, what I recommend (in keep with the 
british epsrc principl of robot [http://joanna-bryson.blogspot.com/2016/03/the-meaning-of-epsrc-principles-of.html] ) be 

that it should never be a legal product for manufactur and purchase. and therefor ani AI which would ever be bought 
or sell should not be consid a legal person. 

note that there be also other reason not to make AI a legal person, most importantli that tax robot allow the 

corpor who actual decid to use them rather than human off the hook [http://joanna-bryson.blogspot.com/2016/06 
/robots-are-owned-owners-are-taxed.html] for that decision, displac those corporations' liability, and also afford the 
opportun to hack up robot to minimis the amount of tax that will be paid. robot and AI be not human; they do not 
come in discret pre-defin units. they be artefacts, and a such, our own, author responsibility. [http://joanna- 

bryson.blogspot.com/2015/03/robots-are-more-like-novels-than.html] 

To get back to corporations, solaiman say these can suffer to the extent that the human in them suffer, and/or to the 
extent that lose their asset be equival to human suffering. the latter argument be weaker I think, but it have a lot of 

histor legal precedent. nevertheless, the fact that corpor don't realli suffer may well be whi we have a number 
of problem with corpor be treat a legal persons. confound these problem by declar AI or robot to 
be legal person would almost certainli not be wise. 

post 3rd decemb 2016 by joanna bryson 

labels: ai, ethics, polici 

view comment 

whi (or rather, when) suffer in AI be incoherent. https://joanna-bryson.blogspot.be/2016/12/why-or-rather-when-suffering-... 

2 sur 2 17-01-17 18:21 


