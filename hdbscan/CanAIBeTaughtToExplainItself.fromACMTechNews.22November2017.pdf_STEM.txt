






































can a.i. Be taught to explain itself? 


can a.i. Be taught to explain itself? 

cliff kuang 

In september, michal kosinski publish a studi that he fear 

might end hi career. the economist broke the news first, give it a 

self-consci anodyn title: “advanc in a.i. are use to spot sign 

of sexuality.” but the headlin quickli grow more alarmed. By the next 

day, the human right campaign and glaad, formerli know a the 

gay and lesbian allianc against defamation, have label kosinski’ 

work “dangerous” and “junk science.” (they claim it have not be 

peer reviewed, though it had.) In the next week, the tech-new site the 

verg have run an articl that, while care reported, be nonetheless 

top with a scorch headline: “the invent of a.i. ‘gaydar’ could 

Be the start of someth much worse.” 

kosinski have make a career of warn other about the us and 

potenti abus of data. four year ago, he be pursu a ph.d. in 

psychology, hop to creat good test for signatur person trait 

like introvers or open to change. but he and a collabor soon 

realiz that facebook might render person test superfluous: 

instead of ask if someon like poetry, you could just see if they 

“liked” poetri magazine. In 2014, they publish a studi show that if 

give 200 of a user’ likes, they could predict that person’ personality- 

test answer good than their own romant partner could. 

after get hi ph.d., kosinski land a teach posit at the 

stanford graduat school of busi and soon start look for new 

data set to investigate. one in particular stood out: faces. for decades, 

psychologist have be leeri about associ person trait with 

physic characteristics, becaus of the last taint of phrenolog and 

eugenics; studi face thi way was, in essence, a taboo. but to 

understand what that taboo might reveal when questioned, kosinski 

knew he couldn’t reli on a human judgment. 

kosinski first mine 200,000 publicli post date profiles, complet 

with pictur and inform rang from person to polit 

can a.i. Be taught to explain itself? https://www.nytimes.com/2017/11/21/magazine/can-ai-be-taught-to-expl... 

1 sur 13 30-11-17 à 18:55 



views. then he pour that data into an open-sourc facial-recognit 

algorithm — a so-cal deep neural network, built by research at 

oxford univers — and ask it to find correl between people’ 

face and the inform in their profiles. the algorithm fail to turn 

up much, until, on a lark, kosinski turn it attent to sexual 

orientation. the result almost defi belief. In previou research, the 

best ani human have do at guess sexual orient from a profil 

pictur be about 60 percent — slightli good than a coin flip. given 

five pictur of a man, the deep neural net could predict hi sexual 

with a much a 91 percent accuracy. for women, that figur be low 

but still remarkable: 83 percent. 

much like hi earli work, kosinski’ find rais question about 

privaci and the potenti for discrimin in the digit age, 

suggest scenario in which good program and data set might be 

abl to deduc anyth from polit lean to criminality. but there 

be anoth question at the heart of kosinski’ paper, a genuin 

mysteri that go almost ignor amid all the medium response: how 

be the comput do what it did? what be it see that human 

could not? 

photo illustr by derek brahney. sourc photo: howard sochurek/th 

life pictur collection/getti images. 

It be kosinski’ own research, but when he tri to answer that 

question, he be reduc to a painstak hunt for clues. At first, he 

tri cover up or exagger part of faces, tri to see how those 

can a.i. Be taught to explain itself? https://www.nytimes.com/2017/11/21/magazine/can-ai-be-taught-to-expl... 

2 sur 13 30-11-17 à 18:55 



chang would affect the machine’ predictions. result be 

inconclusive. but kosinski knew that women, in general, have big 

foreheads, thinner jaw and longer nose than men. So he have the 

comput spit out the 100 face it deem most like to be gay or 

straight and averag the proport of each. It turn out that the 

face of gay men exhibit slightli more “feminine” proportions, on 

average, and that the convers be true for women. If thi be accurate, 

it could support the idea that testosteron level — alreadi know to 

mold facial featur — help mold sexual a well. 

but it be imposs to say for sure. other evid seem to suggest 

that the algorithm might also be pick up on cultur driven traits, 

like straight men wear basebal hat more often. Or — crucial — 

they could have be pick up on element of the photo that human 

don’t even recognize. “human might have troubl detect these tini 

footprint that border on the infinitesimal,” kosinski says. “comput 

can do that veri easily.” 

It have becom commonplac to hear that machines, arm with 

machin learning, can outperform human at decidedli human tasks, 

from play Go to play “jeopardy!” We assum that be becaus 

comput simpli have more data-crunch power than our soggi 

three-pound brains. kosinski’ result suggest someth stranger: 

that artifici intellig often excel by develop whole new way of 

seeing, or even thinking, that be inscrut to us. it’ a more profound 

version of what’ often call the “black box” problem — the inabl to 

discern exactli what machin be do when they’r teach 

themselv novel skill — and it have becom a central concern in 

artificial-intellig research. In mani arenas, a.i. method have 

advanc with startl speed; deep neural network can now detect 

certain kind of cancer a accur a a human. but human doctor 

still have to make the decis — and they won’t trust an a.i. unless it 

can explain itself. 

thi isn’t mere a theoret concern. In 2018, the european union 

will begin enforc a law requir that ani decis make by a 

machin be readili explainable, on penalti of fine that could cost 

compani like googl and facebook billion of dollars. the law be 

write to be power and broad and fail to defin what constitut a 

can a.i. Be taught to explain itself? https://www.nytimes.com/2017/11/21/magazine/can-ai-be-taught-to-expl... 

3 sur 13 30-11-17 à 18:55 



satisfi explan or how exactli those explan be to be 

reached. It repres a rare case in which a law have manag to leap 

into a futur that academ and tech compani be just begin to 

devot concentr effort to understanding. As research at oxford 

dryli noted, the law “could requir a complet overhaul of standard and 

wide use algorithm techniques” — techniqu alreadi permeat 

our everyday lives. 

those techniqu can seem inescap alien to our own way of 

thinking. instead of certainti and cause, a.i. work off probabl and 

correlation. and yet a.i. must nonetheless conform to the societi we’v 

built — one in which decis requir explanations, whether in a court 

of law, in the way a busi be run or in the advic our doctor give us. 

the disconnect between how we make decis and how machin 

make them, and the fact that machin be make more and more 

decis for us, have birth a new push for transpar and a field of 

research call explain a.i., or x.a.i. it goal be to make machin 

abl to account for the thing they learn, in way that we can 

understand. but that goal, of course, rais the fundament question of 

whether the world a machin see can be make to match our own. 

“artifici intelligence” be a misnomer, an airi and evoc term 

that can be shade with whatev notion we might have about what 

“intelligence” be in the first place. research today prefer the term 

“machin learning,” which good describ what make such algorithm 

powerful. let’ say that a comput program be decid whether to give 

you a loan. It might start by compar the loan amount with your 

income; then it might look at your credit history, marit statu or age; 

then it might consid ani number of other data points. after 

exhaust thi “decis tree” of possibl variables, the comput will 

spit out a decision. If the program be built with onli a few exampl 

to reason from, it probabl wouldn’t be veri accurate. but give 

million of case to consider, along with their variou outcomes, a 

machine-learn algorithm could tweak itself — figur out when to, 

say, give more weight to age and less to incom — until it be abl to 

handl a rang of novel situat and reliabl predict how like each 

loan be to default. 

machin learn isn’t just one technique. It encompass entir 

can a.i. Be taught to explain itself? https://www.nytimes.com/2017/11/21/magazine/can-ai-be-taught-to-expl... 

4 sur 13 30-11-17 à 18:55 



famili of them, from “boost decis trees,” which allow an 

algorithm to chang the weight it give to each data point, to 

“random forests,” which averag togeth mani thousand of randomli 

gener decis trees. the sheer prolifer of differ techniques, 

none of them obvious good than the others, can leav research 

flummox over which one to choose. mani of the most power be 

bafflingli opaque; other evad understand becaus they involv an 

avalanch of statist probability. It can be almost imposs to peek 

insid the box and see what, exactly, be happening. 

rich caruana, an academ who work at microsoft research, have spent 

almost hi entir career in the shadow of thi problem. when he be 

earn hi ph.d at carnegi mellon univers in the 1990s, hi thesi 

advis ask him and a group of other to train a neural net — a 

forerunn of the deep neural net — to help evalu risk for patient 

with pneumonia. between 10 and 11 percent of case would be fatal; 

other would be less urgent, with some percentag of patient 

recov just fine without a great deal of medic attention. the 

problem be figur out which case be which — a high-stak 

question in, say, an emerg room, where doctor have to make quick 

decis about what kind of care to offer. Of all the machine-learn 

techniqu student appli to thi question, caruana’ neural net be 

the most effective. but when someon on the staff of the univers of 

pittsburgh medic center ask him if they should start use hi 

algorithm, “I say no,” caruana recalls. “I say we don’t understand 

what it do inside. I say I be afraid.” 

the problem be in the algorithm’ design. classic neural net focu 

onli on whether the predict they give be right or wrong, tweak 

and weigh and recombin all avail morsel of data into a 

tangl web of infer that seem to get the job done. but some of 

these infer could be terrif wrong. caruana be particularli 

concern by someth anoth graduat student notic about the 

data they be handling: It seem to show that asthmat with 

pneumonia fare good than the typic patient. thi correl be 

real, but the data mask it true cause. asthmat patient who 

contract pneumonia be immedi flag a danger cases; if they 

tend to fare better, it be becaus they get the best care the hospit 

can a.i. Be taught to explain itself? https://www.nytimes.com/2017/11/21/magazine/can-ai-be-taught-to-expl... 

5 sur 13 30-11-17 à 18:55 



could offer. A dumb algorithm, look at thi data, would have simpli 

assum asthma meant a patient be like to get good — and thu 

conclud that they be in less need of urgent care. 

“I knew I could probabl fix the program for asthmatics,” caruana says. 

“but what els do the neural net learn that be equal wrong? It 

couldn’t warn me about the unknown unknowns. that tension have 

bother me sinc the 1990s.” 

the stori of asthmat with pneumonia eventu becom a legendari 

allegori in the machine-learn community. today, caruana be one of 

perhap a few dozen research in the unit state dedic to 

find more transpar new approach to machin learning. for the 

last six years, he have be creat a new model that combin a 

number of machine-learn techniques. the result be a accur a hi 

origin neural network, and it can spit out chart that show how each 

individu variabl — from asthma to age — be predict of mortal 

risk, make it easi to see which one exhibit particularli unusu 

behavior. immediately, asthmat be reveal a a far outlier. other 

strang truth surface, too: for example, risk for peopl age 100 go 

down suddenly. “if you make it to thi round number of 100,” caruana 

says, “it seem a if the doctor be saying, ‘let’ tri to get you 

anoth year,’ which might not happen if you’r 93.” 

caruana may have brought clariti to hi own project, but hi solut 

onli underscor the fact the explain be a kaleidoscop problem. 

the explan a doctor need from a machin isn’t the same a the 

one a fighter pilot might need or the one an n.s.a. analyst sniff out a 

financi fraud might need. differ detail will matter, and differ 

technic mean will be need for find them. you couldn’t, for 

example, simpli use caruana’ techniqu on facial data, becaus they 

don’t appli to imag recognition. there may, in other words, eventu 

have to be a mani approach to explain a there be approach 

to machin learn itself. 

three year ago, david gunning, one of the most consequenti 

peopl in the emerg disciplin of x.a.i., attend a brainstorm 

session at a state univers in north carolina. the event have the titl 

“human-cent big data,” and it be sponsor by a government- 

fund think tank call the laboratori for analyt sciences. the idea 

can a.i. Be taught to explain itself? https://www.nytimes.com/2017/11/21/magazine/can-ai-be-taught-to-expl... 

6 sur 13 30-11-17 à 18:55 



be to connect lead a.i. research with expert in data 

visual and human-comput interact to see what new tool 

they might invent to find pattern in huge set of data. there to judg 

the ideas, and act a hypothet users, be analyst for the c.i.a., the 

n.s.a. and sundri other american intellig agencies. 

the research in gunning’ group step confid up to the white 

board, show off new, more power way to draw predict from a 

machin and then visual them. but the intellig analyst 

evalu their pitches, a woman who couldn’t tell anyon in the room 

what she do or what tool she be using, wave it all away. gun 

rememb her a plainli dressed, middle-aged, typic of the countless 

govern agent he have know who toil thanklessli in critic jobs. 

“none of thi solv my problem,” she said. “I don’t need to be abl to 

visual anoth recommendation. If i’m go to sign off on a 

decision, I need to be abl to justifi it.” she be issu what amount 

to a broadside. It wasn’t just that a clever graph indic the best 

choic wasn’t the same a explain whi that choic be correct. the 

analyst be point to a legal and ethic motiv for explainability: 

even if a machin make perfect decisions, a human would still have to 

take respons for them — and if the machine’ rational be 

beyond reckoning, that could never happen. 

gunning, a grandfatherli militari man whose buzz cut have surviv hi 

stint a a civilian, be a program manag at the defens advanc 

research project agency. He work in darpa’ shini new midris tower 

in downtown alexandria, va. — an offic indistinguish from the 

other nearby, except that the secur guard out front will take away 

your cellphon and warn you that turn on the wi-fi on your laptop 

will make secur personnel materi within 30 seconds. darpa 

manag like gun don’t have perman jobs; the expect be 

that they serv four-year “tours,” dedic to fund cutting-edg 

research along a singl line of inquiry. when he found himself at the 

brainstorm session, gun have recent complet hi second tour 

a a sort of johnni applese for a.i.: start in the 1990s, he have 

found hundr of projects, from the first applic of machine- 

learn techniqu to the internet, which presag the first search 

engines, to the project that eventu spun off a siri, apple’ voice- 

can a.i. Be taught to explain itself? https://www.nytimes.com/2017/11/21/magazine/can-ai-be-taught-to-expl... 

7 sur 13 30-11-17 à 18:55 



control assistant. “i’m proud to be a dinosaur,” he say with a smile. 

As of now, most of the military’ practic applic of such 

technolog involv perform enorm calcul beyond the reach 

of human patience, like predict how to rout supplies. but there be 

more ambiti applic on the horizon. one recent research 

program tri to use machin learn to sift through million of video 

clip and internet messag in yemen to detect cease-fir violations; if 

the machin do find something, it have to be abl to describ what’ 

worth pay attent to. anoth press need be for drone fli on 

self-direct mission to be abl to explain their limit so that the 

human command the drone know what the machin can — and 

cannot — be ask to do. explain have thu becom a hurdl for a 

wealth of possibl projects, and the depart of defens have begin 

to turn it eye to the problem. 

after that brainstorm session, gun take the analyst’ stori back 

to darpa and soon sign up for hi third tour. As he flew across the 

countri meet with comput scientist to help design an overal 

strategi for tackl the problem of x.a.i., what becom clear be that 

the field need to collabor more broadli and tackl grander 

problems. comput science, have leapt beyond the bound of 

consid pure technic problems, have to look further afield — to 

experts, like cognit scientists, who studi the way human and 

machin interact. 

thi repres a full circl for gunning, who begin hi career a a 

cognit psychologist work on how to design good autom 

system for fighter pilots. later, he begin work on what’ now call 

“old-fashion a.i.” — so-cal expert system in which machin be 

give volumin list of rules, then task with draw conclus by 

recombin those rules. none of those effort be particularli 

successful, becaus it be imposs to give the comput a set of rule 

long enough, or flexibl enough, to approxim the power of human 

reasoning. a.i.’ current blossom come onli when research begin 

invent new techniqu for let machin find their own pattern 

in the data. 

gunning’ x.a.i. initiative, which kick off thi year, provid $75 

million in fund to 12 new research programs; by the power of the 

can a.i. Be taught to explain itself? https://www.nytimes.com/2017/11/21/magazine/can-ai-be-taught-to-expl... 

8 sur 13 30-11-17 à 18:55 



purs strings, gun have refocu the energi of a signific part 

of the american a.i. research community. hi hope be that by make 

these new a.i. method account to the demand of human 

psychology, they will becom both more use and more powerful. “the 

real secret be find a way to put label on the concept insid a deep 

neural net,” he says. If the concept insid can be labeled, then they can 

be use for reason — just like those expert system be suppos to 

do in a.i.’ first wave. 

deep neural nets, which evolv from the kind of techniqu that 

rich caruana be experi with in the 1990s, be now the class of 

machin learn that seem most opaque. just like old-fashion 

neural nets, deep neural network seek to draw a link between an input 

on one end (say, a pictur from the internet) and an output on the other 

end (“thi be a pictur of a dog”). and just like those old neural nets, 

they consum all the exampl you might give them, form their own 

web of infer that can then be appli to pictur they’v never see 

before. deep neural net remain a hotb of research becaus they have 

produc some of the most breathtak technolog 

accomplish of the last decade, from learn how to translat 

word with better-than-human accuraci to learn how to drive. 

To creat a neural net that can reveal it inner workings, the research 

in gunning’ portfolio be pursu a number of differ paths. some 

of these be technic ingeni — for example, design new kind of 

deep neural network make up of smaller, more easili understood 

modules, which can fit togeth like lego to accomplish complex tasks. 

other involv psycholog insight: one team at rutger be design a 

deep neural network that, onc it make a decision, can then sift 

through it data set to find the exampl that best demonstr whi it 

make that decision. (the idea be partli inspir by psycholog studi 

of real-lif expert like firefighters, who don’t clock in for a shift 

thinking, these be the 12 rule for fight fires; when they see a fire 

befor them, they compar it with one they’v see befor and act 

accordingly.) perhap the most ambiti of the dozen differ project 

be those that seek to bolt new explanatori capabl onto exist 

deep neural networks. imagin give your pet dog the power of speech, 

so that it might final explain what’ so interest about squirrels. or, 

can a.i. Be taught to explain itself? https://www.nytimes.com/2017/11/21/magazine/can-ai-be-taught-to-expl... 

9 sur 13 30-11-17 à 18:55 



a trevor darrell, a lead investig on one of those teams, sum it up, 

“the solut to explain a.i. be more a.i.” 

five year ago, darrel and some colleagu have a novel idea for let 

an a.i. teach itself how to describ the content of a picture. first, they 

creat two deep neural networks: one dedic to imag recognit 

and anoth to translat languages. then they lash these two 

togeth and fed them thousand of imag that have caption attach 

to them. As the first network learn to recogn the object in a 

picture, the second simpli watch what be happen in the first, 

then learn to associ certain word with the activ it saw. work 

together, the two network could identifi the featur of each picture, 

then label them. soon after, darrel be present some differ work 

to a group of comput scientist when someon in the audienc rais 

a hand, complain that the techniqu he be describ would never 

be explainable. darrell, without a second thought, said, sure — but you 

could make it explain by onc again lash two deep neural 

network together, one to do the task and one to describ it. 

darrell’ previou work have piggyback on pictur that be alreadi 

captioned. what he be now propos be creat a new data set and 

use it in a novel way. let’ say you have thousand of video of basebal 

highlights. An image-recognit network could be train to spot the 

players, the ball and everyth happen on the field, but it wouldn’t 

have the word to label what they were. but you might then creat a new 

data set, in which volunt have write sentenc describ the 

content of everi video. onc combined, the two network should then 

be abl to answer queri like “show me all the doubl play involv 

the boston red sox” — and could potenti show you what cues, like 

the logo on uniforms, it use to figur out who the boston red sox are. 

call it the hamlet strategy: lend a deep neural network the power of 

intern monologue, so that it can narrat what’ go on inside. but do 

the concept that a network have taught itself align with the realiti that 

human be describing, when, for example, narrat a basebal 

highlight? Is the network recogn the boston red sox by their logo 

or by some other obscur signal, like “median facial-hair distribution,” 

that just happen to correl with the red sox? doe it actual have 

the concept of “boston red sox” or just some other strang thing that 

can a.i. Be taught to explain itself? https://www.nytimes.com/2017/11/21/magazine/can-ai-be-taught-to-expl... 

10 sur 13 30-11-17 à 18:55 



onli the comput understands? it’ an ontolog question: Is the 

deep neural network realli see a world that correspond to our own? 

We human be seem to be obsess with black boxes: the high 

compliment we give to technolog be that it feel like magic. when the 

work of a new technolog be too obvious, too easi to explain, it can 

feel banal and uninteresting. but when I ask david jensen — a 

professor at the univers of massachusett at amherst and one of the 

research be fund by gun — whi x.a.i. have suddenli 

becom a compel topic for research, he sound almost soulful: “we 

want peopl to make inform decis about whether to trust 

autonom systems,” he said. “if you don’t, you’r depriv peopl of 

the abil to be fulli independ human beings.” 

A decad in the making, the european union’ gener data 

protect regul final go into effect in may 2018. it’ a 

sprawling, many-tentacl piec of legisl whose open line 

declar that the protect of person data be a univers human right. 

among it hundr of provisions, two seem aim squar at where 

machin learn have alreadi be deploy and how it’ like to 

evolve. googl and facebook be most directli threaten by articl 21, 

which afford anyon the right to opt out of person tailor ads. the 

next articl then confront machin learn head on, limn a so- 

call right to explanation: e.u. citizen can contest “legal or similarli 

significant” decis make by algorithm and appeal for human 

intervention. taken together, articl 21 and 22 introduc the principl 

that peopl be owe agenc and understand when they’r face by 

machine-mad decisions. 

for many, thi law seem frustratingli vague. some legal scholar argu 

that it might be toothless in practice. other claim that it will requir 

the basic work of facebook and googl to change, l they face 

penalti of 4 percent of their revenue. It remain to be see whether 

compli with the law will mean a heap of fine print and an extra 

check box buri in a pop-up window, some new kind of warning-label 

system mark everi machine-mad decis or much more profound 

changes. 

If googl be one of the compani most endang by thi new scrutini 

on a.i., it’ also the compani with the great wherewith to lead the 

can a.i. Be taught to explain itself? https://www.nytimes.com/2017/11/21/magazine/can-ai-be-taught-to-expl... 

11 sur 13 30-11-17 à 18:55 



whole industri in solv the problem. even among the company’ 

astonish roster of a.i. talent, one particular star be chri olah, who 

hold the titl of research scientist — a titl share by google’ mani ex- 

professor and ph.d. — without ever have complet more than a 

year of college. olah have be work for the last coupl of year on 

creat new way to visual the inner work of a deep neural 

network. you might recal when googl creat a hallucinatori tool 

call deep dream, which produc psychedel distort when you 

fed it an imag and which go viral when peopl use it to creat 

hallucinatori mash-up like a doll cover in a pattern of doll eye and 

a portrait of vincent van gogh make up in place of bird beaks. olah 

be one of mani googl research on the team, lead by alex 

mordvintsev, that work on deep dream. It may have seem like a 

folly, but it be actual a technic steppingstone. 

olah speak faster and faster a he sink into an idea, and the word 

tumbl out of him almost too quickli to follow a he explain what he 

found so excit about the work he be doing. “the truth is, it’ realli 

beautiful. there’ some sens in which we don’t know what it mean to 

see. We don’t understand how human do it,” he told me, hand 

gestur furiously. “we want to understand someth not just about 

neural net but someth deeper about reality.” olah’ hope be that 

deep neural network reflect someth deeper about pars data — 

that insight glean from them might in turn shed light on how our 

brain work. 

olah show me a sampl of work he be prepar to publish with a 

set of collaborators, includ mordvintsev; it be make public thi 

month. the tool they have develop be basic an ingeni way of 

test a deep neural network. first, it fed the network a random imag 

of visual noise. then it tweak that imag over and over again, work 

to figur out what excit each layer in the network the most. 

eventually, that process would find the platon ideal that each layer of 

the network be search for. olah demonstr with a network 

train to classifi differ breed of dogs. you could pick out a neuron 

from the topmost layer while it be analyz a pictur of a golden 

retriever. you could see the ideal it be look for — in thi case, a 

hallucinatori mash-up of floppi ear and a forlorn expression. the 

can a.i. Be taught to explain itself? https://www.nytimes.com/2017/11/21/magazine/can-ai-be-taught-to-expl... 

12 sur 13 30-11-17 à 18:55 



network be inde home in on higher-level trait that we could 

understand. 

watch him use the tool, I realiz that it be exactli what the 

psychologist michal kosinski need — a key to unlock what hi deep 

neural network be see when it categor profil pictur a gay or 

straight. kosinski’ most optimist view of hi research be that it 

repres a new kind of scienc in which machin could access 

truth that lay beyond human intuition. the problem be reduc what 

a comput knew into a singl conclus that a human could grasp and 

consider. He have painstakingli test hi data set by hand and found 

evid that the comput might be discov hormon signal in 

facial structure. that evid be still fragmentary. but with the tool 

that olah show me, or one like it, kosinski might have be abl to 

pull back the curtain on how hi mysteri a.i. be working. It would 

be a obviou and intuit a a pictur the comput have drawn on it 

own. 

can a.i. Be taught to explain itself? https://www.nytimes.com/2017/11/21/magazine/can-ai-be-taught-to-expl... 

13 sur 13 30-11-17 à 18:55 


