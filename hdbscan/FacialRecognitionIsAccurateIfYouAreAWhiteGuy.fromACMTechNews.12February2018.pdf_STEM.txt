






































facial recognit Is accurate, if youâ•žr a white guy 


facial recognit Is accurate, if 
you’r a white guy 

steve lohr 

facial recognit technolog be improv by leap and bounds. some 

commerci softwar can now tell the gender of a person in a 

photograph. 

when the person in the photo be a white man, the softwar be right 99 

percent of the time. 

but the darker the skin, the more error aris — up to nearli 35 percent 

for imag of darker skin women, accord to a new studi that 

break fresh ground by measur how the technolog work on peopl 

of differ race and gender. 

these dispar results, calcul by joy buolamwini, a research at 

the m.i.t. media lab, show how some of the bia in the real world can 

seep into artifici intelligence, the comput system that inform facial 

recognition. 

color matter in comput vision 

facial recognit algorithm make by microsoft, ibm and face++ be more 

like to misidentifi the gender of black woman than white men. 

facial recognit Is accurate, if you’r a white guy https://www.nytimes.com/2018/02/09/technology/facial-recognition-race-... 

1 sur 13 12-02-18 à 19:25 



facial recognit Is accurate, if you’r a white guy https://www.nytimes.com/2018/02/09/technology/facial-recognition-race-... 

2 sur 13 12-02-18 à 19:25 



gender be misidentifi in up to 1 percent of lighter-skin 

male in a set of 385 photos. 

facial recognit Is accurate, if you’r a white guy https://www.nytimes.com/2018/02/09/technology/facial-recognition-race-... 

3 sur 13 12-02-18 à 19:25 



facial recognit Is accurate, if you’r a white guy https://www.nytimes.com/2018/02/09/technology/facial-recognition-race-... 

4 sur 13 12-02-18 à 19:25 



gender be misidentifi in up to 7 percent of lighter-skin 

femal in a set of 296 photos. 

facial recognit Is accurate, if you’r a white guy https://www.nytimes.com/2018/02/09/technology/facial-recognition-race-... 

5 sur 13 12-02-18 à 19:25 



facial recognit Is accurate, if you’r a white guy https://www.nytimes.com/2018/02/09/technology/facial-recognition-race-... 

6 sur 13 12-02-18 à 19:25 



gender be misidentifi in up to 12 percent of darker-skin 

male in a set of 318 photos. 

facial recognit Is accurate, if you’r a white guy https://www.nytimes.com/2018/02/09/technology/facial-recognition-race-... 

7 sur 13 12-02-18 à 19:25 



gender be misidentifi in 35 percent of darker-skin 

femal in a set of 271 photos. 

In modern artifici intelligence, data rules. a.i. softwar be onli a 

smart a the data use to train it. If there be mani more white men 

than black woman in the system, it will be bad at identifi the black 

women. 

one wide use facial-recognit data set be estim to be more 

than 75 percent male and more than 80 percent white, accord to 

anoth research study. 

the new studi also rais broader question of fair and 

account in artifici intellig at a time when invest in and 

adopt of the technolog be race ahead. 

facial recognit Is accurate, if you’r a white guy https://www.nytimes.com/2018/02/09/technology/facial-recognition-race-... 

8 sur 13 12-02-18 à 19:25 



today, facial recognit softwar be be deploy by compani in 

variou ways, includ to help target product pitch base on social 

medium profil pictures. but compani be also experi with face 

identif and other a.i. technolog a an ingredi in autom 

decis with high stake like hire and lending. 

research at the georgetown law school estim that 117 million 

american adult be in face recognit network use by law 

enforc — and that african american be most like to be 

singl out, becaus they be disproportion repres in mug- 

shot databases. 

facial recognit technolog be lightli regul so far. 

“thi be the right time to be address how these a.i. system work and 

where they fail — to make them social accountable,” say suresh 

venkatasubramanian, a professor of comput scienc at the univers 

of utah. 

until now, there be anecdot evid of comput vision miscues, 

and occasion in way that suggest discrimination. In 2015, for 

example, googl have to apolog after it image-recognit photo app 

initi label african american a “gorillas.” 

sorel friedler, a comput scientist at haverford colleg and a 

review editor on ms. buolamwini’ research paper, say expert have 

long suspect that facial recognit softwar perform differ on 

differ populations. 

“but thi be the first work i’m awar of that show that empirically,” ms. 

friedler said. 

ms. buolamwini, a young african-american comput scientist, 

experienc the bia of facial recognit firsthand. when she be an 

undergradu at the georgia institut of technology, program would 

work well on her white friends, she said, but not recogn her face at 

all. she figur it be a flaw that would sure be fix befor long. 

facial recognit Is accurate, if you’r a white guy https://www.nytimes.com/2018/02/09/technology/facial-recognition-race-... 

9 sur 13 12-02-18 à 19:25 



joy buolamwini, a research at the m.i.t. media lab, have emerg a an 

advoc in the new field of “algorithm accountability.” toni luong for the 

new york time 

but a few year later, after join the m.i.t. media lab, she ran into 

the missing-fac problem again. onli when she put on a white mask do 

the softwar recogn her a a face. 

By then, face recognit softwar be increasingli move out of the 

lab and into the mainstream. 

“o.k., thi be serious,” she recal decid then. “time to do 

something.” 

So she turn her attent to fight the bia built into digit 

technology. now 28 and a doctor student, after studi a a rhode 

scholar and a fulbright fellow, she be an advoc in the new field of 

“algorithm accountability,” which seek to make autom decis 

more transparent, explain and fair. 

facial recognit Is accurate, if you’r a white guy https://www.nytimes.com/2018/02/09/technology/facial-recognition-race-... 

10 sur 13 12-02-18 à 19:25 



her short ted talk on cod bia have be view more than 940,000 

times, and she found the algorithm justic league, a project to 

rais awar of the issue. 

In her newli publish paper, which will be present at a confer 

thi month, ms. buolamwini studi the perform of three lead 

face recognit system — by microsoft, ibm and megvii of china — by 

classifi how well they could guess the gender of peopl with differ 

skin tones. these compani be select becaus they offer gender 

classif featur in their facial analysi softwar — and their code 

be publicli avail for testing. 

she found them all wanting. 

To test the commerci systems, ms. buolamwini built a data set of 

1,270 faces, use face of lawmak from countri with a high 

percentag of woman in office. the sourc includ three african 

nation with predominantli dark-skin populations, and three 

nordic countri with mainli light-skin residents. 

the african and nordic face be score accord to a six-point 

label system use by dermatologist to classifi skin types. the 

medic classif be determin to be more object and 

precis than race. 

then, each company’ softwar be test on the curat data, craft 

for gender balanc and a rang of skin tones. the result vari 

somewhat. microsoft’ error rate for darker-skin woman be 21 

percent, while ibm’ and megvii’ rate be nearli 35 percent. they all 

have error rate below 1 percent for light-skin males. 

ms. buolamwini share the research result with each of the companies. 

ibm say in a statement to her that the compani have steadili improv 

it facial analysi softwar and be “deepli committed” to “unbiased” 

and “transparent” services. thi month, the compani said, it will roll 

out an improv servic with a nearli 10-fold increas in accuraci on 

darker-skin women. 

microsoft say that it have “alreadi take step to improv the accuraci 

of our facial recognit technology” and that it be invest in 

research “to recognize, understand and remov bias.” 

facial recognit Is accurate, if you’r a white guy https://www.nytimes.com/2018/02/09/technology/facial-recognition-race-... 

11 sur 13 12-02-18 à 19:25 



ms. buolamwini’ co-author on her paper be timnit gebru, who 

describ her role a an adviser. ms. gebru be a scientist at microsoft 

research, work on it fair account transpar and 

ethic in a.i. group. 

timnit gebru, a scientist at microsoft research, be a co-author of the paper 

that studi facial recognit software. codi o'loughlin for the new york 

time 

megvii, whose face++ softwar be wide use for identif in 

onlin payment and ride-shar servic in china, do not repli to 

sever request for comment, ms. buolamwini said. 

ms. buolamwini be releas her data set for other to build upon. she 

describ her research a “a start point, veri much a first step” 

toward solutions. 

ms. buolamwini be take further step in the technic commun and 

beyond. she be work with the institut of electr and electron 

engineers, a larg profession organ in computing, to set up a 

group to creat standard for account and transpar in facial 

analysi software. 

she meet regularli with other academics, public polici group and 

philanthropi that be concern about the impact of artifici 

intelligence. darren walker, presid of the ford foundation, say that 

facial recognit Is accurate, if you’r a white guy https://www.nytimes.com/2018/02/09/technology/facial-recognition-race-... 

12 sur 13 12-02-18 à 19:25 



the new technolog could be a “platform for opportunity,” but that it 

would not happen if it replic and amplifi bia and discrimin 

of the past. 

“there be a battl go on for fairness, inclus and justic in the 

digit world,” mr. walker said. 

part of the challenge, scientist say, be that there be so littl divers 

within the a.i. community. 

“we’d have a lot more introspect and account in the field of 

a.i. if we have more peopl like joy,” say cathi o’neil, a data scientist 

and author of “weapon of math destruction.” 

technology, ms. buolamwini said, should be more attun to the 

peopl who use it and the peopl it’ use on. 

“you can’t have ethic a.i. that’ not inclusive,” she said. “and whoever 

be creat the technolog be set the standards.” 

correction: februari 11, 2018 

becaus of an edit error, an earli version of the grid of photo 

misstat the number of photo in the data set for the first two rows. 

the top row, of lighter-skin males, be in a set of 385 photos, not 

296; the second row, lighter-skin females, be in a set of 296 

photos, not 385. 

facial recognit Is accurate, if you’r a white guy https://www.nytimes.com/2018/02/09/technology/facial-recognition-race-... 

13 sur 13 12-02-18 à 19:25 


