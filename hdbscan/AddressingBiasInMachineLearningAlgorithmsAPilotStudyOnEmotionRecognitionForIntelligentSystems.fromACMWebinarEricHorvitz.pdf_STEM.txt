



































address bia in machin learn algorithms: 
A pilot studi on emot recognit for 

intellig system 
ayanna howard1*, cha zhang2, eric horvitz2 
1school of electr and comput engin 

georgia institut of technolog 
atlanta, ga∗ 


2microsoft research 

redmond, WA 


abstract: recently, there have be an explos of cloud-bas servic that enabl develop to includ a spectrum of recognit 
services, such a emot recognition, in their applications. the recognit of emot be a challeng problem, and research have 
be do on build classifi to recogn emot in the open world. often, learn emot model be train on data set 
that may not suffici repres a target popul of interest. for example, mani of these on-lin servic have focu on 
train and test use a major represent of adult and thu be tune to the dynam of matur faces. for applic 
design to serv an old or young age demographic, use the output from these pre-defin model may result in low 
perform rate than when use a special classifier. similar challeng with bia in perform aris in other situat 
where dataset in these large-scal on-lin servic have a non-repres ratio of the desir class of interest. We consid the 
challeng of provid applic develop with the power to util pre-construct cloud-bas servic in their applic 
while still ensur satisfactori perform for their uniqu workload of cases. We focu on bia in emot recognit a a 
repres scenario to evalu an approach to improv recognit rate when an on-lin pre-train classifi be use for 
recognit of a class that may have a minor represent in the train set. We discu a hierarch classif approach 
to address thi challeng and show that the averag recognit rate associ with the most difficult emot for the minor class 
increas by 41.5% and the overal recognit rate for all class increas by 17.3% when use thi approach. 

i.! introduct 
poor represent of peopl of differ age and skin 

color in train data can lead to perform problem and 
bia for real-world classif task involv the visual 
attribut of people—such a detect facial express or 
pose. these perform problem and bia be directli 
correl with the problem of class-imbal in the dataset 
use to train these machin learn algorithms. there have 
be a number of effort that have tri to resolv thi issu 
with train on imbalanc dataset [1], includ use 
differ form of re-sampl [2], adjust the decis 
threshold [3], or a mixture-of-expert approach which 
combin the result of mani classifi [4]. the difficulti 
with imbal be recogn whi and when imbalanc data 
set be problematic. It can be difficult to distinguish between 
data associ with a low incid class and noisi data when 
train a classifier. thi be especi problemat when 
build model use cloud-bas servic that util 
train data drawn from readili avail sources, such a 
photo crawl from the web. tens-of-thousand of case 
might be download for such training, and the result 
dataset may be domin by high preval age and skin 
color categories. such broad scan of data lead to three 
challeng for applic developers, includ machin 
learn practition and roboticists. the first challeng be 


* research perform while visit research at microsoft research 

that, by use a cloud-bas service, applic develop 
typic cannot directli influenc it behavior sinc they do 
not have access to the services’ intern processes. the second 
challeng be that the categori which be deriv from a 
repres quantiti of major data (and thu have 
likelihood repres of real-world data streams) may 
lead to incorrect outcom when a person in a minor age 
and skin color categori us the system. In thi instance, the 
learn converg base on theoret accept 
outcom but it real-world outcom may not be social 
acceptable. the third challeng deal with the amplif of 
the problem when the data sourc be or be almost complet 
influenc by the domin class, which may not be 
repres of the world culture, thu lead to the 
perpetu of bia beliefs. although the deriv of 
these problem be different, these situat can bia the 
classif results, especi when design learn 
algorithm for emot recognit in intellig systems. 

emot recognit be a grow area of interest, from 
interpret mood for effect caregiv robot to 
recogn a child’ anxieti level for therapeut robots. 
emot recognit be the process of identifi human 
emotion, typic via facial expressions, linguistics, voice, or 
even bodi gestures. most machin learn algorithm for 
emot recognit use imag to track facial express in 



order to identifi basic emot such a happy, angry, fear, 
or surprise. In fact, in a review of onlin emot recognit 
api [5], over 50% of the intellig softwar packag 
avail use facial express to recogn emotions. 

gener of these algorithm for optim 
perform in the open world be typic achiev by 
train on larg set of unconstrain data collect ‘in the 
wild’. the term ‘in the wild’ mean imag have be 
captur under natur condit with vari paramet 
such a environ and scenes, divers illumin 
conditions, head pose and with occlusions. unfortunately, 
most of these imag sets, by the natur of their collect 
process, will have small collect of low incid classes, 
such a those associ with a young or old age 
demographic, or with an ethnic minority. for example, in the 
yearli emot recognit in the wild (emotiw) challeng 
[6], research be provid a dataset to benchmark the 
perform of their method on in-the-wild data. the dataset 
repres the typic express class of angry, disgust, 
fear, happiness, neutral, sad and surprise, but focu 
primarili on scene with adults. 

In thi paper, we examin the bia issu found in learn 
algorithm for intellig system by focu on the emot 
recognit problem. We first present baselin outcom for a 
cloud-bas emot recognit algorithm appli to imag 
associ with a minor class, in thi instance, children’ 
facial expressions. We then present a hierarch approach 
that combin output from the cloud-bas emot 
recognit algorithm with a special learner, and show 
that thi methodolog can increas overal recognit result 
by 17.3%. We also verifi that thi hierarch algorithm, 
when appli to an addit corpu of test data, show 
similar improv in the recognit rate. thi addit 
corpu be use to ass the perform of the hierarch 
approach in gener to new unseen images. We conclud 
by discuss futur work need to address the problem of 
bia stem from poor represent of peopl in a larg 
train set. 

ii.! relat work 
although there be a number of research effort focu 

on child that incorpor the recognit of emot to 
enabl their functionality, most have not do a systemat 
analysi of accuraci with respect to their emot recognit 
algorithms. for example, with socially-interact robots, a 
number of research robot such a darwin [7], the icub [8], 
avatar [9], and the grace robot [10], use emot to 
engag child in therapi or learning. their analysi though 
be base on overal perform on child engag and not 
on emot recognition. 

Of those research effort that have focu on emot 
recognit perform [11], veri few have focu on 
children. In [12], research use their own video data 
collect of child to develop method to analyz chang 
in facial express of 50 child age 3 to 9, with a focu on 
problem solv scenarios. their accuraci measur be not 
directli base on emot but rather center on facial 
action units, which, when blend together, can be use to 
repres emotions. In their application, they develop 

separ linear support vector machin to detect the presenc 
or absenc of one of 19 facial actions. the train set 
consist of 10000 imag frame and the test set consist 
of 200 randomli sampl frame from thi set, result in a 
recognit rate for the facial action unit that rang from 
61% to 100% depend on the unit. In [13], an approach for 
learn children’ affect state be present use three 
differ type of neural network structures, name a multi- 
stage radial basi function neural network, a probabilist 
neural network, and a multi-class classif support vector 
machin (svm). use the dartmouth databas of children 
face [14], they subdivid imag of child age 5 to 9 into 
a train set of 1040 imag and a test set of 242 images. 
the train set be cluster into three affect classes: 
posit (happy, pleased, surprised), neg (disgust, sad, 
angry) and neutral. they achiev a maximum overal 
recognit rate of 85% on the untrain facial test imag 
use the multi-class classif svm. In [15], a method 
be discuss for automat recognit of facial express 
for children. they valid their methodolog on the full 
dartmouth databas of children face of 1280 imag and 
their 8 emot classes. the full imag set be use for both 
train and test use a support vector machine, a c4.5 
decis tree, random forest and the multi-lay perceptron 
method. the svm achiev the maximum overal recognit 
rate of 79%. they then test on the nimh child emot 
face pictur set (nimh-chefs) databas [16] with 482 
imag to ass the gener accuraci of the classifi 
on new unseen imag and achiev a maximum overal 
recognit rate of 68.4% when use the svm that be 
train on the dartmouth dataset. 

these repres sever effort that have focu on the 
explicit evalu of emot recognit algorithm a 
appli to the domain of children’ emot cues. In the next 
section, we discu baselin result deriv from use a 
cloud-bas classifi on public avail dataset of 
children’ facial expressions. 

iii.! baselin result 
recently, sever cloud-bas servic have offer 

program librari that enabl develop to includ 
emot recognit capabl in their imag applic 
[17]. these include, among others, google’ vision api 
(https://cloud.google.com/vision) and the microsoft emot 
api (https://www.microsoft.com/cognitive-services), a 
compon of microsoft’ cognit services. these cloud- 
base emot recognit algorithm optim their 
perform in the open world by train on larg set of 
unconstrain data set collect ‘in the wild.’ To establish a 
baselin on the capabl of learn and infer for a 
minor class, we evalu the emot recognit result 
associ with children’ facial express use the 
microsoft emot api, a deep learn neural network [18]. 
the emot detect use the microsoft emot api be 
angry, contempt, disgust, fear, happy, neutral, sad, and 
surprise. 

We select four dataset of children’ face that be 
public avail for research purpos and with publish 




neutral contempt surpris 


sad disgust fear 


fear angri happi 

fig. 1.! exampl stimulu of child associ with the facial express 
databases: top: the radboud face database, middle: the dartmouth 
databas of children’ faces, bottom: nimh-chef databas 

human inter-rat reliabl measur associ with the 
emot labels. the four dataset be the nimh child 
emot face pictur set (nimh-chefs) [16], the 
dartmouth databas of children’ face [14], the radboud 
face databas [19], and the child emot pictur set 
(ceps) [20] (figur 1). the nimh child emot face 
pictur set (nimh-chefs) contain 534 imag of child 
rang in age from 10 to 17 year old with a mean age of 13.6 
year old. the pictur set includ 39 girl and 20 boy 
cover 5 emot (fear, angry, happy, sad and neutral). 
We select an inter-rat reliabl valu for inclus in our 
evalu at 75% of the rater correctli identifi the 
intend emotion, which exclud 52 pictur from the 
origin set leav a final set of 482 pictures. use inter-rat 
reliabl for inclus provid a way of quantifi the 
degre of agreement between two or more coders. We select 
75% a thi be the benchmark establish for have good 
agreement among rater when rate among 5-7 categories. 
the dartmouth databas of children’ face contain 1280 
imag of child rang in age from 5 to 16 year old with 
a mean age of 9.72 year old. the pictur set includ 40 girl 
and 40 boy cover 7 emot (neutral, happy, sad, 
angry, fear, surprise, and disgust). for evaluation, we 
select the inter-rat reliabl cut-off valu for inclus at 
75%, which exclud 370 pictur from the origin set 
leav a final set of 910 pictures. the radboud face 
databas (rafd) includ 240 imag cover 8 emot 
(neutral, angry, sad, fear, disgust, surprise, happy, and 
contempt). there be 4 boy and 6 girl in the dataset. base 
on a 75% inclus criteria, we exclud 57 pictur from the 
origin set leav a final set of 183 pictures. lastli be the 

child emot pictur set (ceps), which contain 273 
imag of children, rang in age from 6 to 11 year old with 
a mean age of 8.9 year old. the dataset includ 9 girl and 8 
boy cover 7 emot (happy, sad, angry, disgust, fear, 
surprise, and neutral). sinc we do not have access to the 
individu inter-rat reliabl valu associ with thi 
dataset, we use the researcher’ inclus critera, which 
result in a final set of 225 images. 

We seek to character the perform of exist 
machin learn algorithm on case from these distinct data 
set to develop an understand of how well the deep learn 
neural network (i.e. the microsoft emot api) perform on 
recogn children’ emot states. 

To evalu the perform of the deep learn 
algorithm, we pars each of the final imag set into the 
emot api and tabul the recognit results. tabl I 
show the perform for each of the datasets. 

tabl I. ! deep learn recognit rate across the 
differ stimuli set (in %): (fe)ar, (an)gry, (ha)ppy, (sa)d, 
(ne)utral, (su)rprised, (di)sgust, (co)ntempt 

Fe An Di Ha Ne Sa Su Co 

nimh-chef 13 43 100 100 48 

dartmouth 25 35 55 100 99 64 91 
radboud 33 54 100 100 100 95 100 50 

cep 5 50 10 95 92 52 81 



with respect to the overal recognit rates, which 

incorpor the variabl data dimens of the imag set 
(tabl ii), the overal emot recognit rate be 62% for 
the nimh-chef dataset, 81% for the dartmouth dataset, 
83% for the radboud dataset, and 61% for the cep dataset. 
If we compar these result with special learn 
algorithm that have be train specif on children’ 
facial imag and a discuss in the relat work section, we 
see that the deep learn algorithm, base on train in the 
wild, have result that be compar to the special result 
that use compar small train set but with an 
emphasi on a minor class (tabl iii). yet, if we look at the 
overal emot recognit rate for adults, the rate should 
be closer to 88% [30]. our goal therefor be to capit on 
the power of the cloud-bas emot recognit algorithm 
while improv the overal recognit rate. 

tabl ii. ! number OF imag associ with each stimuli 
set: (fe)ar, (an)gry, (ha)ppy, (sa)d, (ne)utral, (su)rprised, 

(di)sgust, (co)ntempt 

Fe An Di Ha Ne Sa Su Co 
nimh-chef 102 94 108 98 80 

dartmouth 20 83 101 302 145 135 124 
radboud 21 26 25 30 24 20 29 8 

cep 20 30 31 56 24 33 31 





tabl iii. ! deep learn ‘in the wild’ approach versu 
special learn methodolog 

dartmouth databas 
with emot group into positive, 
negative, and neutral affect state 

albu [13] 85% 
emot api 84% 
dartmouth databas nimh-chef 
khan [15] 79% 68% 
emot api 81% 62% 

iii.! methodolog and result 
when we examin the result from the deep learn 

neural network, we note that fear have a significantli low 
recognit rate than the other emot across all of the 
differ datasets. If we look at the confus matrix 
associ with fear (tabl iv), we also note that fear be most 
often confus with surprise. facial express of fear and 
disgust have repeatedli be found in the emot 
recognit literatur to be less well recogn than those of 
other basic emot [21]. In fact, it have be show that 
surpris be the most frequent error make when tri to 
recogn express of fear in child [22]. If we look at 
the basic facial action unit that make up these two 
expressions, it becom obviou whi thi confus occurs. 
facial action unit (aus) repres the 44 anatom 
distinct muscular activ that activ when chang occur 
in an individual’ facial appear (tabl v). base on 
comprehens compar human studies, ekman and 
friesen [23, 24] have label these muscl movement and 
identifi those believ to be associ with emot 
express (tabl vi) [25]. when examin the facial action 
unit associ with fear and surpris (tabl v), we confirm 
that surpris be actual a subset of fear (i.e. surpris ⊆ fear); 
and over 60% of the au in fear be also found in the set of 
surpris aus. As such, surpris becom easi to recogn 
than fear a a default sinc there be less distinct cue to 
identify. 

tabl iv. ! confus matrix associ with deep learn 
result 

surpris neutral happi sad fear 
fear 

nimh- 
chef 

74 
(83.7%) 

11 
(10.2%) 

0 3 13 
(6.1%) 

dartmouth 11 (55%) 
0 3 

(15%) 
1 

(5%) 
5 

(25%) 

radboud 13 (61.9%) 
0 0 1 

(4.8%) 
7 

(33.3%) 

cep 9 (45%) 
4 

(20%) 
3 

(15%) 
3 

(15%) 
1 

(5%) 
surpris 

dartmouth 113 (91.1%) 
3 

(2.4%) 
8 

(6.5%) 
0 0 

radboud 29 (100%) 
0 0 0 0 

cep 25 (80.6%) 
3 

(9.7%) 
3 

(9.7%) 
0 0 

tabl V. ! facial action unit involv IN emot stimuli 

emot au associ with emot 
angri 4, 5 and/or 7, 22, 23, 24 
fear 1, 2, 4, 5, 7, 20, 25 or 26 

surpris 1, 2, 5, 25 or 26 


tabl vi. ! facial action unit and facial featur imag 
from the children facial express dataset 

action 
unit descript 

facial featur 
imag 

1 inner brow raiser 

2 outer brow raiser 


4 brow lower 


5 upper lid raiser 


7 lid tighten 


20 lip stretcher 

22 lip funnel 


23 lip tighten 


24 lip pressor 


25 lip apart 

26 jaw drop 


thus, a a first step in illustr a process for improv 
the recognit rate of a gener machin learn 
algorithm, we focu on improv the overal recognit rate 
by improv recognit of the fear emotion. figur 2 
depict the overal algorithm flow of the approach. given a 
facial image, facial landmark be extract and use to 
comput a number of anthropometr features. the 
anthropometr featur be then fed into two support vector 
machin (svms) for binari classification, one to distinguish 
between fear and surpris with an explicit bia toward fear 
and one to distinguish between surpris and not-surpris 
with a balanc bias. the design of thi construct be to increas 
the bia toward the minor class (in the first svm) while 
ensur that the recognit of the major class be not 
drastic reduc (in the second svm). We train the svm 
on 50% of the data from three of the dataset of children’ 
face and evalu the result on all four datasets, includ 
the remain untrain dataset. 




fig. 2.! feature-bas learn approach for emot recognit of 
children’ facial express 

A. extract of anthropometr featur 
most method that focu on develop image-bas age 

classif method typic use featur associ with 
face anthropometri [26]. A face anthropometr model be 
base on measur of size and proport of the human 
face, i.e. human face ratios. although age classif be not 
our direct target application, it do provid some measur for 
distinguish between age group (i.e. child versu adults) 
base on facial features. We thu util variou human face 
ratio a the input into our special learn algorithm. In 
[27], it be show that four featur distanc be suffici to 
repres the mathemat relationship among all of the 
variou landmark for age classification. sinc we be 
interest in emot classification, we comput all princip 
ratios, namely: width of left eye, height of left eye, length 
of the nose bridge, distanc between the nose tip and chin, 
width of mouth, height of open mouth, and offset distanc 
between the inner and outer corner of the eyebrow. these 
anthropometr featur be comput base on extract face 
landmarks, a show in figur 3, and equat (1)-(7). 

"#$%ℎ'()*(%+,* = |+,*)*(%/00*12 − +,*)*(%45%*12| 
(1) 

6'7*81#$9*)*09%ℎ = |6'7*:''%:#9ℎ%2 − 
6'7*:''%)*(%2| (2) 

6'7*;#<%'=ℎ#0 = |=ℎ#0>'7#%#'0?@ − ?6'7*;#<@| (3) 

a*#9ℎ%'()*(%+,* = |+,*)*(%8'%%'b@ − +,*)*(%;'<@| 
(4) 


1 ! https://www.projectoxford.ai/fac 

"#$%ℎ'(c'5%ℎ = |c'5%ℎ:#9ℎ%2 − c'5%ℎ)*(%2| (5) 

a*#9ℎ%'(4<*0c'5%ℎ = |d<<*1)#<8'%%'b@ − 
d0$*1)#<;'<@| (6) 

+,*81'ea*#9ℎ%4((7*% = |+,*f1'e)*(%/00*1@ − 

??+,*f1'e)*(%45%*1@|?? (7) 

where x and y repres the pixel locat in (x,y) screen 
coordin and chinposit be estim a the pixel 
coordin associ with the bottom center of the face 
rectangl provid by the face api, which indic where 
in the imag a face be located. onc computed, all ratio be 
normal base on the calcul width and height of the 
face rectangle. 

















fig. 3.! face landmark extract use the face api develop by 
microsoft oxford project1 

onc computed, these featur be use to train two svm 
for emot classification. 

B. svm for classif of fear versu surpris 
given that there be a bia for surpris versu fear 

associ with children’ facial expressions, our first task 
be to develop a special classifi that bia the result 
toward the minor class, in thi case, the fear class. support 
vector machin (svms) be supervis learn model that 
can be use for classif of class associ with a set 
of train exampl [28]. for our application, we want to 
good differenti between the fear minor class and the 
surpris major class. thus, ani facial express that be 
classifi (correctli or incorrectly) a surpris by the deep 
learn algorithm, we want to re-evalu with a special 
learner. To enabl thi process, all emot label a 
surpris be fed to the first-level svm and reclassifi into 
one of two classes: fear or surprise. We thu design the first- 
level svm to learn the mapping: 

G ↦ I, where J ∊ :l, , ∊ ±1 , 0 = 7 (8) 

In thi case, x repres the vector contain 
anthropometr features, y=1 repres the surpris class, 
and y=-1 repres the fear class. 



for our application, we train the first-level svm on 
50% of the featur vector classifi a fear or surpris by the 
deep learn algorithm and extract from the radboud 
face database, the dartmouth databas of children’ face 
and the nimh-chef database. We do not train on the 
child emot pictur set a we wish to ass the 
capabl of the new algorithm when face with unseen 
facial characteristics. We then bia the class decis 
threshold of the first-level svm by select the minimum 
threshold valu that maxim the true posit rate 
associ with fear. this, by default, increas the fals 
posit rate of fear while potenti reduc the true 
posit rate associ with surprise. thus, after pars the 
imag through the first-level svm, the minor class have a 
significantli high recognit rate but the major class 
recognit rate, on average, be reduc a show in tabl vii. 
the high recognit rate for the minor class be valid 
even for the cep databas which contain data that be not 
in the train set of of the svm classifiers. all recognit 
rate incorpor the variabl data dimens of the imag 
set (tabl ii). 

tabl vii. ! emot recognit rate after training: ML – 
deep learn algorithm, svm – first-level support vector 

machin 

fear surpris chang in 
overal 

rec. rate ML ml+ svm ML 
ml+ 
svm 

nimh-chef 13% 47% 34% 
dartmouth 25% 91% 91% 79% -1.2% 
radboud 33% 77% 100% 100% 31.8% 

cep 5% 70% 81% 68% 17.6% 


the goal of the second-level svm be to increas the 
recognit rate of the major class to pre-bia level while 
still keep the recognit rate associ with the minor 
class high than it origin recognit rate. from tabl V, 
we note that angri and fear have more action unit in 
common than angri and surprise. thus, to reduc the effect 
of the action unit overlap between surpris and fear, we 
train the second-level svm on the recognit of two 
primari class – (fear ∨ angry) and surprise. We then 
associ the deriv anthropometr featur vector from 
each imag to one of two classes: surpris and not- 
surprised, where not-surpris repres the union of fear 
and angry. In thi case, for the mapping: G ↦ I, where J ∊ 
:l, , ∊ ±1 , 0 = 7, y=1 be associ with the surpris class, 
and y=-1 be associ with the fear or angri class. In 
practice, onli those featur vector that be classifi a fear 
by the first-level svm be process by the second-level 
svm. thi approach result in an averag increas in the 
recognit of fear by 41.5% and an increas in the overal 
recognit rate by 17.3%. As tabl viii shows, the overal 
recognit rate increas after pars through the second- 
level svm, even though the recognit rate for the minor 
class fall to a low valu than in the first-level svm. Of 
special interest, we note that, although recognit of fear have 
increas greatli for the dartmouth database, the recognit 

rate for surpris be slightli low than the origin surpris 
recognit rate, even after pars through the second-level 
svm. Of all the datasets, the dartmouth dataset have a larg 
imbal between surpris and fear, in fact thi dataset have 
6x more imag belong to surpris than fear (tabl ii). As 
such, thi result be not surpris a the balanc that we be 
tri to achiev in our approach be to ensur that the minor 
class have an increas in benefit with respect to recognit 
rates, while ensur that the reduct in benefit to the 
major class be not major. If the motiv is, instead, to 
ensur that the recognit rate for the minor class be 
maximized, the onli requir be to ignor the second-level 
svm and util onli the output result from pars 
through the first-level svm. 

In the next section, we make some interest observ 
about these result and provid discuss on way to 
gener thi approach to the broad class of gener 
learn algorithms. 

tabl viii. ! emot recognit rate after training: ML – 
deep learn algorithm, svm – second-level support vector 

machin 

fear surpris chang in 
overal 

rec. rate ML ml+ svm ML 
ml+ 
svm 

nimh-chef 13% 47% 34% 
dartmouth 25% 70% 91% 83% -0.6% 
radboud 33% 71% 100% 100% 32.8% 

cep 5% 55% 81% 81% 19.6% 


iv.! discuss 
We conclud thi paper with a discuss on the present 

result and highlight some area for futur effort that could 
address the limit associ with build classifi 
when there be imbalanc represent in their train sets. 

recently, there have be an upsurg of attent give to 
gener machin learn algorithm and the practic of 
inequ and discrimin that be potenti be built 
into them [29]. We know that imbal exist and thus, our 
goal in thi paper be to present an approach that enabl u to 
capit on the power of gener learn algorithms, 
while incorpor a process that allow u to tune those 
result for differ target demographics. bia in machin 
learn algorithm will occur anytim there be a larg 
major class coupl with other minor class have 
low incid rates, such a those associ with a young 
or old age demographic, or an ethnic minority. the 
challeng be to develop a process for ensur the overal 
posit result of the gener learn approach be 
maintained, while also increas the outcom associ 
with ani minor classes. In thi paper, we address thi issu 
by develop a hierarch approach that coupl the result 
from the gener learn algorithm with result from a 
special learner. although we focu on the issu of emot 
recognit for intellig systems, and address emot 



recognit associ with children’ facial expressions, thi 
concept can be appli to similar classif applications. 
the step involv be (1) identifi the set(s) of minor 
classes, (2) develop special learner that address the 
minor class via special focu on the class, and (3) 
develop a special learner that combin signal from 
both the minor and major class models. 

As show in the results, if at ani point, we determin that 
it be more import to have a maximum outcom rate 
associ with the minor class, regardless of the outcom 
rate associ with the major class, onli step (1) and (2) 
be necessary. that question on the inclus of a 
classifi touch on ethic of equiti in the perform of 
algorithms. 

although the present approach show valid in 
address the issu of bias, there be still a number of thread 
that need to be investigated. futur work in thi domain 
includ valid the approach with a focu on a differ 
minor class, valid the approach with a focu on a 
differ classif problem, and valid the approach 
with differ gener machin learn algorithms. We 
will also target improv the classif rate of both fear 
and disgust, sinc both of these express be hard to detect, 
and would provid further evid of the impact of thi 
methodology. We hope that thi work will contribut to 
rais the sensit to the potenti challeng in the 
perform and bia of classifi when make infer 
about peopl of differ age and skin colors. there be 
opportun for addit research to identifi and address 
these challenges. 

v.! refer 
[1]! kotsiantis, s., kanellopoulos, D. and pintelas, P. “handl 

imbalanc datasets: A review,” gest intern transact on 
comput scienc and engineering, vol. 30, pp. 25-36, 2006. 

[2]! chawla, n.v., hall, L. o., bowyer, K. W. and kegelmeyer, W. p., 
“smote: synthet minor oversampl technique,” journal of 
artifici intellig research, vol. 16, pp. 321–357, 2002. 

[3]! joshi, M. v., kumar, V. and agarwal, r.c. “evalu boost 
algorithm to classifi rare cases: comparison and improvements,” In 
first ieee intern confer on data mining, pp. 257-264, 
2001. 

[4]! provost, F. and fawcett, T. “robust classif for imprecis 
environments,” machin learning, vol. 42, pp. 203-231, 2001. 

[5]! doerrfeld, B. “20+ emot recognit api that will leav you 
impressed, and concerned,” http://nordicapis.com/20-emotion- 
recognition-apis-that-will-leave-you-impressed-and-concerned, 2015. 

[6]! dhall, a., ramana murthi o.v., goecke, r., joshi J. and gedeon, T. 
“video and imag base emot recognit challeng in the wild: 
emotiw 2015,” acm intern confer on multimod 
interact (icmi), 2015. 

[7]! brown, L. and howard A. “gestur behavior implement on a 
humanoid robot platform for effect social interaction,” ieee 
int. symp. on robot and human interact commun (ro- 
man), pp. 471 – 476, 2014. 

[8]! metta, g., sandini, g., vernon, D. natale, L. and nori, F. “the icub 
humanoid robot: an open platform for research in embodi cognition,” 
8th workshop on perform metric for intellig systems, pp. 50- 
56, 2008. 

[9]! cloutier, p., park, h.w., maccalla, J. and howard, A. “it’ all in the 
eyes: design facial express for an interact robot therapi 
coach for children,” 8th cambridg workshop on univers access 
and assist technology, cambridge, uk, 2016. 

[10]! simmon r., et al. “grace: An autonom robot for the aaai 
robot challenge,” AI magazine, vol. 24(2), pp. 51-72, 2003. 

[11]! sankur, b., ulukaya, S. and çeliktutan, O. “A compar studi of 
face landmark techniques,” eurasip J. imag and video 
processing, vol. 13, 2013. 

[12]! littleworth, g., bartlett, m.s., salamanca, l.p. and reilly, J. 
“autom measur of children’ facial express dure 
problem solv tasks,” ieee int. confer on automat face and 
gestur recognition, pp. 30–35, 2011. 

[13]! albu, f., hagiescu, d., vladutu, L. and puica, M. “neural network 
approach for children' emot recognit in intellig learn 
applications,” in proc. of edulearn 2015, barcelona, spain, pp. 
3229-3239, 2015. 

[14]! dalrymple, ka, gomez, J, and duchaine, B. “the dartmouth databas 
of children’ faces: acquisit and valid of a new face 
stimulu set,” urgesi C, ed.plo one. 2013. vol. 8(11), 2013. 

[15]! khan, r.a., meyer, A. and bouakaz, S. “automat affect analysis: 
from children to adults,” intern symposium on visual 
computing, isvc 2015, pp. 304-313, 2015. 

[16]! egger, h.l., pine, d.s., nelson, e., et al. “the nimh child emot 
face pictur set (nimh-chefs): A new set of children’ facial 
emot stimuli,” intern journal of method in psychiatr 
research, vol. 20(3), pp. 145-156, 2011. 

[17]! schmidt, A. “cloud-bas AI for pervas applications,” ieee 
pervas computing, vol. 15(1), pp. 14-18, 2016. 

[18]! barsoum, e., zhang, c., canton ferrer, C. and zhang, Z. “train 
deep network for facial express recognit with crowd- 
sourc label distribution,” acm intern confer on 
multimod interact (icmi), tokyo, japan, 2016. 

[19]! langner, o., dotsch, r., bijlstra, g., wigboldus, d.h.j., et. al. 
“present and valid of the radboud face 
database,” cognit & emotion, vol. 4(8), pp. 1377—1388, 2010. 

[20]! romani-sponchiado, a., sanvicente-vieira, b., mottin, c., hertzog- 
fonini, d., arteche, A. “child emot pictur set (ceps): 
develop of a databas of children’ emot expressions,” 
psycholog & neuroscience, vol. 8(4), pp. 467-478, 2015. 

[21]! gagnon, m., gosselin p., hudon-ven der buhs, i., larocque, k., 
milliard, K. “children’ recognit and discrimin of fear and 
disgust facial expressions,” journal of nonverb behavior, vol. 
34(1), pp. 27–42, 2010. 

[22]! gosselin, p., roberge, P. and lavalle´e, M. C. “the develop of 
the recognit of facial emot express compris in the human 
repertoire,” enfance, vol. 4, pp. 379–396, 1995. 

[23]! ekman, P. and friesen, W. facial action cod system: A techniqu 
for the measur of facial movement. palo alto, ca.: consult 
psychologist press, 1978. 

[24]! friesen, W. and ekman, P. emfacs-7: emot facial action 
code system. unpublish manual, univers of california, 
california, 1983. 

[25]! matsumoto, D. and ekman, P. “facial express analysis,” 
scholarpedia, vol. 3(5), pp. 4237, 2008. 

[26]! grd, P. “two-dimension face imag classif for distinguish 
child from adult base on anthropometry,” thesi submit to 
univers of zagreb, 2015. 

[27]! alom m.z., piao, m-l., islam m.s., kim, N. and park, j-h. 
“optim facial features-bas age classification,” world 
academi of science. engin and technolog conference, vol. 
6, pp. 319–324, 2012. 

[28]! joachims, T. “make large-scal svm learn practical. advanc 
in kernel method - support vector learning,” B. schölkopf and C. 
burg and A. smola (ed.), mit-press, 1999. 

[29]! crawford, K. “artifici intelligence’ white guy problem,” new 
york time – opinion, http://www.nytimes.com/2016/06/26/ 
opinion/sunday/artificial-intelligences-white-guy-problem.html, 2016. 

[30]! brodny, g., kołakowska, a., landowska, a., szwoch, m., szwoch, 
W. and wróbel, M. “comparison of select off-the-shelf solut for 
emot recognit base on facial expressions,” 9th int. conf. on 
human system interact (hsi), pp. 397-404, 2016. 


