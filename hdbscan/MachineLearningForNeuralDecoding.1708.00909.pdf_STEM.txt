









































microsoft word - decoding_arxiv.docx 


machin 
learn 
for 
neural 
decod 




joshua 
I. 
glaser1,2*, 
raeed 
H. 
chowdhury3,4, 
matthew 
G. 
perich3,4, 
lee 
E. 
miller2-­‐4, 
and 
konrad 
P. 

kording2-­‐7 




1. interdepartment 
neurosci 
program, 
northwestern 
university, 
chicago, 
il, 
usa 


2. depart 
of 
physic 
medicin 
and 
rehabilitation, 
northwestern 
univers 
and 
shirley 
ryan 
abil 
lab, 


chicago, 
il, 
usa 


3. depart 
of 
physiology, 
northwestern 
university, 
chicago, 
il, 
usa 

4. depart 
of 
biomed 
engineering, 
northwestern 
university, 
chicago, 
il, 
usa 

5. depart 
of 
appli 
mathematics, 
northwestern 
university, 
chicago, 
il, 
usa 

6. depart 
of 
neuroscience, 
univers 
of 
pennsylvania, 
philadelphia, 
il, 
usa 

7. depart 
of 
biomed 
engineering, 
univers 
of 
pennsylvania, 
philadelphia, 
il, 
usa 


* 
contact: 
j-­‐glaser@u.northwestern.edu 




abstract: 

while 
machin 
learn 
tool 
have 
be 
rapidli 
advancing, 
the 
major 
of 
neural 
decod 
approach 
still 

use 
last 
century’ 
methods. 
improv 
the 
perform 
of 
neural 
decod 
algorithm 
allow 
u 
to 
good 

understand 
what 
inform 
be 
contain 
in 
the 
brain, 
and 
can 
help 
advanc 
engin 
applic 
such 

a 
brain 
machin 
interfaces. 
here, 
we 
appli 
modern 
machin 
learn 
techniques, 
includ 
neural 
network 

and 
gradient 
boosting, 
to 
decod 
from 
spike 
activ 
in 
1) 
motor 
cortex, 
2) 
somatosensori 
cortex, 
and 
3) 

hippocampus. 
We 
compar 
the 
predict 
abil 
of 
these 
modern 
method 
with 
tradit 
decod 

method 
such 
a 
wiener 
and 
kalman 
filters. 
modern 
methods, 
in 
particular 
neural 
network 
and 
ensembles, 

significantli 
outperform 
the 
tradit 
approaches. 
for 
instance, 
for 
all 
of 
the 
three 
brain 
areas, 
an 
lstm 

decod 
explain 
over 
40% 
of 
the 
unexplain 
varianc 
from 
a 
wiener 
filter. 

these 
result 
suggest 
that 

modern 
machin 
learn 
techniqu 
should 
becom 
the 
standard 
methodolog 
for 
neural 
decoding. 
We 

provid 
code 
to 
facilit 
wider 
implement 
of 
these 
methods. 





introduction: 

decod 
be 
a 
critic 
tool 
for 
understand 
how 

neural 
signal 
relat 
to 
the 
outsid 
world. 
It 
can 
be 

use 
to 
determin 
how 
much 
inform 
the 
brain 

contain 
about 
an 
extern 
variabl 
(e.g. 
sensat 

or 
movement) 
[1-­‐3], 
and 
how 
thi 
inform 

differ 
across 
brain 
area 
[4-­‐6], 
experiment 

condit 
[7, 
8], 
diseas 
state 
[9], 
and 
more. 
It 
be 

also 
use 
in 
engin 
contexts, 
such 
a 
for 
brain 

machin 
interfac 
(bmis), 
where 
signal 
from 

motor 
cortex 
be 
use 
to 
control 
comput 
cursor 

[10], 
robot 
arm 
[11], 
and 
muscl 
[12]. 
decod 

be 
a 
central 
tool 
for 
neural 
data 
analysis. 



becaus 
decod 
be 
simpli 
a 
regress 
or 

classif 
problem, 
mani 
method 
can 
be 
use 

for 
neural 
decoding. 
despit 
the 
mani 
recent 

advanc 
in 
machin 
learn 
techniques, 
it 
be 
still 


veri 
common 
to 
use 
tradit 
method 
such 
a 

linear 
regression. 
use 
modern 
machin 
learn 

tool 
for 
neural 
decod 
would 
like 
significantli 

boost 
performance, 
and 
might 
allow 
deeper 
insight 

into 
neural 
function. 



here, 
we 
compar 
mani 
differ 
machin 
learn 

method 
to 
decod 
inform 
from 
neural 
spike 

activity. 

We 
predict 
movement 
veloc 
from 

macaqu 
motor 
cortex 
and 
sensorimotor 
cortex, 

and 
locat 
in 
space 
from 
rat 
hippocampus. 
In 
all 

brain 
regions, 
modern 
methods, 
in 
particular 
neural 

network 
and 
ensembles, 
lead 
to 
the 
high 

accuraci 
decoding, 
even 
for 
limit 
amount 
of 

data. 

We 
provid 
code 
so 
that 
other 
can 
easili 
use 

all 
the 
decod 
method 
we 
tested. 











methods: 



task 
and 
brain 
regions: 


decod 
movement 
veloc 
from 
the 
motor 

cortex 
and 
somatosensori 
cortex: 
In 
our 

“random-­‐target” 
experi 
[8], 
monkey 
move 
a 

planar 
manipulandum 
that 
control 
a 
cursor 
on 

the 
screen 
(fig. 
1a). 
the 
monkey 
continu 

reach 
to 
new 
target 
that 
be 
present 
with 
a 

brief 
hold 
period 
between 
reaches. 
after 
training, 

the 
monkey 
be 
surgic 
implant 
with 
96-­‐ 
channel 
utah 
electrod 
array 
(blackrock 

microsystems, 
salt 
lake 
city, 
ut) 
to 
record 
the 

extracellular 
activ 
of 
cortic 
neurons. 
In 
one 

experi 
[8], 
we 
record 
from 
both 
primari 

motor 
cortex 
(m1) 
and 
dorsal 
premotor 
cortex 

(pmd) 
and 
combin 
neuron 
from 
both 
areas. 
In 

anoth 
experi 
we 
record 
from 
area 
2 
of 

primari 
somatosensori 
cortex 
(s1) 
[13]. 
from 
both 

brain 
regions, 
we 
aim 
to 
predict 
the 
x 
and 
y 

compon 
of 
movement 
velocity. 
the 
record 

from 
motor 
cortex 
be 
21 
minutes, 
and 
contain 

164 
neurons. 
the 
mean 
and 
median 
fire 
rates, 

respectively, 
be 
6.7 
and 
3.4 
spike 
/ 
sec. 
the 

record 
from 
S1 
be 
51 
minutes, 
and 
contain 

52 
neurons. 
the 
mean 
and 
median 
fire 
rates, 

respectively, 
be 
9.3 
and 
6.3 
spike 
/ 
sec. 

decod 
posit 
from 
the 
hippocampus: 
We 

use 
a 
dataset 
from 
crcns, 
in 
which 
rat 
chase 

reward 
on 
a 
squar 
platform 
(fig. 
1b) 
[14, 
15]. 

extracellular 
record 
be 
make 
from 
layer 
ca1 

of 
dorsal 
hippocampu 
(hc). 
We 
aim 
to 
predict 

the 
x 
and 
y 
posit 
of 
the 
rat. 
the 
record 
from 

HC 
be 
93 
minutes, 
and 
contain 
58 
neurons. 
We 

exclud 
neuron 
with 
few 
than 
100 
spike 
over 

the 
durat 
of 
the 
experiment, 
result 
in 
46 

neurons. 
these 
neuron 
have 
mean 
and 
median 

fire 
rates, 
respectively, 
of 
1.7 
and 
0.2 
spike 
/ 
sec. 



gener 
decod 
methods: 


decod 
movement 
veloc 
from 
the 
motor 

cortex 
and 
somatosensori 
cortex: 
We 
predict 

the 
averag 
veloc 
(x 
and 
y 
components) 
in 
50 
m 

bins. 
neural 
spike 
train 
use 
for 
decod 
be 

also 
put 
into 
50 
m 
bins. 
In 
motor 
cortex, 
we 
use 

700 
m 
of 
neural 
activ 
(13 
bin 
befor 
and 
the 

concurr 
bin) 
to 
predict 
the 
current 
movement 

velocities, 
a 
the 
primari 
interest 
be 
in 
investig 

how 
motor 
cortex 
causal 
affect 
movement. 
In 

somatosensori 
cortex, 
we 
use 
650 
m 

surround 
the 
movement 
(6 
bin 
before, 
the 

concurr 
bin, 
and 
6 
bin 
after), 
a 
neural 
activ 


have 
be 
show 
both 
preced 
and 
follow 

movement 
[16]. 

decod 
posit 
from 
the 
hippocampus: 
We 

aim 
to 
predict 
the 
posit 
(x 
and 
y 
coordinates) 

of 
the 
rat 
in 
200 
m 
bins. 
neural 
spike 
train 
use 

for 
decod 
be 
also 
put 
into 
200 
m 
bins. 
We 

use 
2 
second 
of 
surround 
neural 
activ 
(4 

bin 
before, 
the 
concurr 
bin, 
and 
5 
bin 
after) 
to 

predict 
the 
current 
position. 


score 
metric: 
To 
determin 
the 
good 
of 
fit, 


we 
use 


!! 

R2 =1− 
ŷ 
i 
− y 

i( ) 
2 

i 
∑ 

y 
i 
− y( )2 

i 
∑ 

, 
where 
!!ŷi 
be 
the 


predict 
values, 
!yi 
be 
the 
true 
valu 
and 
!y 
be 

the 
mean 
value. 
thi 
formul 
of 
R2 
(which 
be 
the 

fraction 
of 
varianc 
account 
for, 
rather 
than 
the 

pearson’ 
correl 
coeffici 
squar 
[17]) 
can 

be 
neg 
on 
the 
test 
set 
due 
to 
overfit 
on 
the 

train 
set. 
the 
report 
R2 
valu 
be 
the 
averag 

across 
the 
x 
and 
y 
compon 
of 
veloc 
or 

position. 

cross-­‐validation: 
when 
determin 
the 
R2 
for 

everi 
method 
(fig. 
3), 
we 
use 
10 
fold 
cross-­‐ 
validation. 
for 
each 
fold, 
we 
split 
the 
data 
into 
a 

train 
set 
(80% 
of 
data), 
a 
contigu 
valid 

set 
(10% 
of 
data), 
and 
a 
contigu 
test 
set 

(10% 
of 
data). 
for 
each 
fold, 
decod 
be 
train 

to 
minim 
the 
mean 
squar 
error 
between 
the 

predict 
and 
true 
velocities/posit 
of 
the 

train 
data. 
We 
found 
the 
algorithm 

hyperparamet 
that 
lead 
to 
the 
high 
R2 
on 
the 

valid 
set 
use 
bayesian 
optim 
[18]. 

that 
is, 
we 
fit 
mani 
model 
on 
the 
train 
set 
with 

differ 
hyperparamet 
and 
calcul 
the 
R2 
on 

the 
valid 
set. 
then, 
use 
the 
hyperparamet 

that 
lead 
to 
the 
high 
valid 
set 
r2, 
we 

calcul 
the 
R2 
valu 
on 
the 
test 
set. 
error 
bar 

on 
the 
test 
set 
R2 
valu 
be 
comput 
across 

cross-­‐valid 
folds. 

bootstrapping: 
when 
determin 
how 

perform 
scale 
a 
function 
of 
data 
size 
(fig. 
5), 

we 
use 
a 
singl 
test 
set 
and 
valid 
set, 
and 

vari 
amount 
of 
train 
data 
that 
directli 

preced 
the 
valid 
set. 

the 
test 
and 
valid 

set 
be 
5 
minut 
long 
for 
motor 
and 

somatosensori 
cortices, 
and 
7.5 
minut 
for 

hippocampus. 
To 
get 
error 
bars, 
we 
resampl 
from 

the 
test 
set. 
becaus 
of 
the 
high 
correl 
between 

tempor 
adjac 
samples, 
we 
didn’t 
resampl 




randomli 
from 
all 
exampl 
(which 
would 
creat 

highli 
correl 
resamples). 
instead, 
we 
separ 

the 
test 
set 
into 
20 
tempor 
distinct 
subsets, 
s1-­‐ 
s20 
(i.e., 
S1 
be 
from 
t=1 
to 
t=t/20, 
S2 
be 
from 
t=t/20 

to 
t=2t/20, 
etc., 
where 
T 
be 
the 
end 
time), 
that 
be 

more 
nearli 
independ 
of 
each 
other. 
We 
then 

resampl 
combin 
of 
these 
20 
subset 
(e.g. 
s5, 

s13, 
… 
s2) 
1000 
time 
to 
get 
confid 
interv 
of 

R2 
values. 

preprocessing: 
the 
train 
input 
be 
normal 

(z-­‐scored). 
the 
train 
output 
be 
zero-­‐cent 

(mean 
subtracted), 
except 
in 
support 
vector 

regression, 
where 
the 
output 
be 
z-­‐scored. 
the 

validation/test 
input 
and 
output 
be 

preprocess 
use 
the 
preprocess 
paramet 

from 
the 
train 
set. 



specif 
decoders: 

kalman 
filter: 
In 
the 
kalman 
filter, 
the 
hidden 

state 
at 
time 
t 
be 
a 
linear 
function 
of 
the 
hidden 
state 

at 
time 
t-­‐1, 
plu 
a 
matrix 
character 
the 

uncertainty. 

the 
observ 
(measurement) 
at 

time 
t 
be 
a 
linear 
function 
of 
the 
hidden 
state 
at 
time 

t 
(plu 
noise). 
At 
everi 
time 
point, 
to 
updat 
the 

estim 
hidden 
state, 
the 
updat 
deriv 
from 

the 
current 
measur 
and 
the 
previou 
hidden 

state 
be 
combined. 
dure 
thi 
combination, 
the 

nois 
matrix 
give 
a 
high 
weight 
to 
the 
less 

uncertain 
information. 
We 
use 
a 
kalman 
filter 

similar 
to 
that 
implement 
in 
[19]. 
In 
the 
kalman 

filter, 
the 
measur 
be 
the 
neural 
spike 
trains, 

and 
the 
hidden 
state 
be 
the 
kinemat 
(x 
and 
y 

compon 
of 
position, 
velocity, 
and 
acceleration). 

We 
have 
one 
hyperparamet 
which 
differ 
from 

the 
implement 
in 
[19]. 
thi 
paramet 

determin 
the 
nois 
matrix 
associ 
with 
the 

transit 
in 
kinemat 
state 
(Q 
in 
[19]). 
We 

divid 
the 
empir 
nois 
matrix 
of 
train 
data 

(use 
in 
[19]) 
by 
the 
hyperparamet 
scalar 
C. 

the 

rational 
for 
thi 
addit 
be 
that 
neuron 
have 

tempor 
correlations, 
which 
make 
it 
desir 
to 

have 
a 
paramet 
that 
allow 
chang 
the 
weight 

of 
the 
new 
neural 
evidence. 

interestingly, 
the 

introduct 
of 
thi 
paramet 
make 
a 
big 

differ 
for 
the 
hippocampu 
dataset 
(fig. 
s1). 

We 
also 
allow 
for 
a 
lag 
between 
the 
neural 
data 

and 
predict 
kinematics. 
the 
lag 
and 

hyperparamet 
be 
determin 
base 
on 

valid 
set 
performance. 


wiener 
filter: 
the 
wiener 
filter 
us 
multipl 

linear 
regress 
to 
predict 
the 
output 
from 

multipl 
time 
bin 
of 
everi 
neurons’ 
spikes. 
that 
is, 

the 
output 
be 
assum 
to 
be 
a 
linear 
map 
of 
the 


number 
of 
spike 
in 
the 
relev 
time 
bin 
from 

everi 
neuron 
(fig. 
1c,d). 
here, 
separ 
model 

be 
use 
to 
predict 
the 
x 
and 
y 
compon 
of 
the 

kinematics. 

wiener 
cascade: 
the 
wiener 
cascad 
(also 
know 

a 
a 
linear 
nonlinear 
model) 
fit 
a 
linear 
regress 

(the 
wiener 
filter) 
follow 
by 
a 
fit 
static 

nonlinear 
(e.g. 
[20]). 
thi 
allow 
for 
a 
nonlinear 

relationship 
between 
the 
input 
and 
the 
output, 
and 

assum 
that 
thi 
nonlinear 
be 
pure 
a 
function 

of 
the 
linear 
output. 
here, 
a 
in 
the 
wiener 
filter, 

the 
input 
be 
neurons’ 
spike 
rate 
over 
relev 

time 
bins. 
the 
nonlinear 
compon 
be 
a 

polynomi 
with 
degre 
determin 
on 
the 

valid 
set. 
separ 
model 
be 
use 
to 

predict 
the 
x 
and 
y 
compon 
of 
the 
kinematics. 

support 
vector 
regression: 
In 
support 
vector 

machin 
regress 
(svr) 
[21], 
the 
input 
be 

project 
into 
a 
high 
dimension 
space 
use 
a 

nonlinear 
kernel, 
and 
then 
linearli 
map 
from 

thi 
space 
to 
the 
output 
to 
minim 
an 
object 

function 
[21]. 
here, 
we 
use 
standard 
support 

vector 
regress 
(svr) 
with 
a 
radial 
basi 
function 

kernel 
to 
predict 
the 
kinemat 
from 
the 
neurons’ 

spike 
rate 
in 
each 
bin. 
We 
set 
hyperparamet 
for 

the 
penalti 
of 
the 
error 
term 
and 
the 
maximum 

number 
of 
iterations. 
separ 
model 
be 
use 
to 

predict 
the 
x 
and 
y 
compon 
of 
the 
kinematics. 

xgboost: 
xgboost 
(extrem 
gradient 
boosting) 

[22] 
be 
an 
implement 
of 
gradient 
boost 
trees. 

for 
the 
regress 
problem, 
gradient 
boost 
fit 

mani 
regress 
trees. 
each 
subsequ 
regress 

tree 
be 
fit 
to 
the 
residu 
of 
the 
previou 
fit. 

regress 
tree 
creat 
nonlinear 
map 
from 

the 
input 
to 
output. 
here, 
we 
use 
the 
xgboost 
to 

predict 
the 
kinemat 
from 
the 
neurons’ 
spike 

rate 
in 
each 
bin. 
We 
set 
hyperparamet 
for 
the 

maximum 
depth 
of 
the 
tree, 
number 
of 
trees, 
and 

learn 
rate. 
separ 
model 
be 
use 
to 
predict 

the 
x 
and 
y 
compon 
of 
the 
kinematics. 

feedforward 
neural 
network: 
A 
feedforward 

neural 
net 
connect 
the 
input 
to 
sequenti 
layer 

of 
hidden 
unit 
via 
linear 
map 
follow 
by 

output 
nonlinearities. 
thi 
can 
allow 
for 
map 

complex 
nonlinear 
function 
from 
input 
to 
output. 

here, 
use 
the 
kera 
librari 
[23], 
we 
creat 
a 
fulli 

connect 
(dense) 
feedforward 
neural 
network 

with 
2 
hidden 
layer 
and 
rectifi 
linear 
unit 


activ 
after 
each 
hidden 
layer. 
We 
requir 
the 

number 
of 
hidden 
unit 
in 
each 
layer 
to 
be 
the 

same. 
We 
set 
hyperparamet 
for 
the 
number 
of 

hidden 
unit 
in 
the 
layers, 
amount 
of 
dropout 
[24], 

and 
number 
of 
train 
epochs. 
We 
use 
the 
adam 




algorithm 
[25] 
a 
the 
optim 
routine. 
thi 

neural 
network, 
and 
all 
neural 
network 
below 
have 

2 
output 
units. 
that 
is, 
the 
same 
network 
predict 

the 
x 
and 
y 
compon 
rather 
than 
there 
be 
2 

separ 
networks. 
the 
input 
be 
still 
the 
number 

of 
spike 
in 
each 
bin 
from 
everi 
neuron. 
note 
that 

we 
refer 
to 
feedforward 
neural 
network 
a 
a 

“modern” 
technique, 
despit 
their 
have 
be 

around 
for 
mani 
decades, 
due 
to 
their 
current 

resurg 
and 
the 
modern 
method 
for 
train 

the 
networks. 

simpl 
rnn: 
In 
a 
standard 
recurr 
neural 

network 
(rnn), 
the 
hidden 
state 
be 
a 
linear 

combin 
of 
the 
input 
and 
the 
previou 
hidden 

state. 
thi 
hidden 
state 
be 
then 
run 
through 
an 

output 
nonlinearity, 
and 
linearli 
map 
to 
the 

output. 
rnns, 
unlik 
feedforward 
neural 
networks, 

allow 
tempor 
chang 
in 
the 
system 
to 
be 

model 
explicitly. 
here, 
use 
the 
kera 
librari 

[23], 
we 
creat 
a 
neural 
network 
architectur 

where 
the 
spike 
input 
from 
all 
neuron 
be 
fed 

into 
a 
standard 
recurr 
neural 
network 
(fig. 
1e). 

the 
unit 
from 
thi 
recurr 
layer 
be 
fed 

through 
a 
rectifi 
linear 
unit 
nonlinearities, 
and 

fulli 
connect 
to 
an 
output 
layer 
with 
2 
unit 
(x 

and 
y 
veloc 
or 
posit 
components). 
We 
set 

hyperparamet 
for 
the 
number 
of 
units, 
amount 


of 
dropout, 
and 
number 
of 
train 
epochs. 
We 
use 

rmsprop 
[26] 
a 
the 
optim 
routine. 

gate 
recurr 
unit: 
gate 
recurr 
unit 

(grus) 
[27] 
be 
a 
more 
complex 
type 
of 
recurr 

neural 
network. 
It 
have 
gate 
units, 
which 
in 
practic 

allow 
for 
good 
learn 
of 
long-­‐term 
dependencies. 

for 
implementation, 
all 
method 
be 
the 
same 
a 

for 
the 
“simpl 
rnn”, 
except 
gate 
recurr 
unit 

be 
use 
rather 
than 
a 
tradit 
rnn. 


long 
short 
term 
memori 
network: 
like 
the 
gru, 

the 
long 
short 
term 
memori 
(lstm) 
network 
[28] 

be 
a 
more 
complex 
recurr 
neural 
network 
with 

gate 
unit 
that 
allow 
long-­‐term 
depend 
to 
be 

captur 
better. 
the 
lstm 
have 
more 
paramet 

than 
the 
gru. 
for 
implementation, 
all 
method 

be 
the 
same 
a 
for 
the 
“simpl 
rnn”, 
except 

lstm 
be 
used. 


ensemble: 
ensembl 
method 
combin 
the 

predict 
from 
sever 
other 
methods, 
and 
thu 

have 
the 
potenti 
to 
leverag 
the 
differ 
benefit 

of 
the 
method 
contain 
within 
the 
ensemble. 

here, 
use 
the 
predict 
from 
all 
decod 
except 

the 
kalman 
filter 
(which 
have 
a 
differ 
format) 
a 

inputs, 
we 
predict 
the 
output 
use 
the 

feedforward 
neural 
network 
describ 
above. 


code: 
python 
code 
for 
all 
method 
be 
avail 
at 

https://github.com/kordinglab/neural_decod 












figur 
1: 
task 
and 
decod 
schemat 

a) 
In 
the 
task 
for 
decod 
from 
motor 
and 
somatosensori 
cortices, 
monkey 
move 
a 
planar 
manipulandum 
that 

control 
a 
cursor 
on 
the 
screen. 
the 
monkey 
continu 
reach 
to 
new 
target 
that 
be 
presented, 
with 
a 
brief 

hold 
period 
between 
reach 
[8]. 
b) 
In 
the 
task 
for 
decod 
from 
hippocampus, 
rat 
chase 
reward 
on 
a 
squar 

platform. 
c) 
To 
decod 
(predict) 
the 
output 
in 
a 
give 
time 
bin, 
we 
use 
the 
fire 
rate 
of 
all 
N 
neuron 
in 
B 
time 
bins. 

In 
thi 
schematic, 
n=4 
and 
b=3 
(one 
bin 
preced 
the 
output, 
one 
concurr 
bin, 
and 
one 
follow 
bin). 
In 
our 
data, 

we 
predict 
two 
output 
from 
each 
brain 
region 
(x 
and 
y 
compon 
of 
veloc 
from 
motor 
and 
somatosensori 

cortex, 
and 
x 
and 
y 
compon 
of 
posit 
from 
hippocampus). 
for 
each 
region, 
the 
number 
of 
neuron 
and 
time 
bin 




use 
for 
decod 
be 
describ 
in 
methods. 
also, 
note 
that 
thi 
schemat 
do 
not 
appli 
for 
the 
kalman 
filter 
decoder. 


d) 
for 
the 
non-­‐recurr 
decod 
(wiener 
filter, 
wiener 
cascade, 
support 
vector 
regression, 
xgboost, 
and 

feedforward 
neural 
network), 
thi 
be 
a 
standard 
machin 
learn 
regress 
problem 
where 
N 
x 
B 
featur 
(the 
fire 

rate 
of 
each 
neuron 
in 
each 
relev 
time 
bin) 
be 
use 
to 
predict 
the 
output. 
e) 
for 
the 
recurr 
decod 
(simpl 

recurr 
neural 
network, 
grus, 
lstms), 
to 
predict 
an 
output, 
we 
use 
N 
features, 
with 
tempor 
connect 
across 
B 

bins. 
A 
schemat 
of 
a 
recurr 
neural 
network 
predict 
a 
singl 
output 
be 
on 
the 
right. 





result 



We 
investig 
how 
the 
choic 
of 
machin 
learn 

techniqu 
affect 
decod 
perform 
(fig. 
1) 

use 
a 
plethora 
of 
common 
machin 
learn 

methods. 
these 
rang 
from 
histor 
linear 

techniqu 
(e.g., 
the 
wiener 
filter) 
to 
modern 

machin 
learn 
techniqu 
(e.g., 
neural 
network 

and 
ensembl 
of 
techniques). 
We 
test 
the 

perform 
of 
all 
these 
techniqu 
across 
dataset 

from 
motor 
cortex, 
somatosensori 
cortex, 
and 

hippocampus. 



We 
aim 
to 
understand 
the 
perform 
of 
the 

method 
when 
fit 
to 
neural 
data. 
first, 
in 
order 
to 

get 
a 
qualit 
impress 
of 
the 
performance, 
we 

plot 
the 
output 
of 
each 
decod 
method 
for 

each 
of 
the 
three 
dataset 
(fig. 
2). 
In 
these 

examples, 
the 
modern 
methods, 
such 
a 
the 
lstm 

and 
ensemble, 
appear 
to 
outperform 
tradit 

methods, 
such 
a 
the 
wiener 
and 
kalman 
filters, 
a 

the 
predict 
be 
slightli 
closer 
to 
the 
true 

output. 
next, 
we 
quantit 
compar 
the 

methods. 
In 
all 
three 
brain 
areas, 
modern 
machin 

learn 
method 
outperform 
tradit 

decod 
method 
(fig. 
3). 
In 
particular, 
neural 

network 
and 
the 
ensembl 
lead 
to 
the 
best 

performance, 
while 
the 
wiener 
or 
kalman 
filter 
lead 

to 
the 
bad 
performance. 
In 
fact, 
the 
lstm 
decod 

explain 
over 
40% 
of 
the 
unexplain 
varianc 

from 
a 
wiener 
filter 
(r2’ 
of 
0.88, 
0.86, 
0.62 
vs. 
0.78, 

0.75, 
0.35). 
additionally, 
the 
feedforward 
neural 


network 
do 
almost 
a 
well 
a 
the 
lstm 
in 
all 
brain 

areas. 
across 
cases, 
the 
ensembl 
method 
add 
a 

reliable, 
but 
small 
increas 
to 
the 
explain 

variance. 
modern 
machin 
learn 
method 
lead 
to 

signific 
increas 
in 
predict 
power. 



while 
modern 
machin 
learn 
method 
yield 

the 
best 
perform 
on 
our 
full 
datasets, 
it 
be 

possible, 
becaus 
of 
their 
great 
complexity, 
that 

they 
would 
not 
work 
well 
with 
less 
data. 
thus, 
we 

test 
the 
feedforward 
neural 
network 
and 
lstm 

(two 
modern 
method 
that 
work 
particularli 

well), 
along 
with 
the 
wiener 
and 
kalman 
filters, 
on 

vari 
amount 
of 
data. 
even 
with 
limit 
data, 
the 

modern 
method 
work 
veri 
well. 
with 
onli 
2 

minut 
of 
train 
data 
for 
motor 
and 

somatosensori 
cortices, 
and 
15 
minut 
of 

hippocampu 
data, 
both 
modern 
method 

outperform 
both 
tradit 
method 
(fig. 
4,5). 


when 
decreas 
the 
amount 
of 
train 
data 

further, 
to 
onli 
1 
minut 
for 
motor 
and 

somatosensori 
cortex 
and 
7.5 
minut 
for 

hippocampu 
data, 
the 
kalman 
filter 
sometim 

perform 
compar 
to 
the 
modern 
methods. 

still, 
the 
modern 
method 
significantli 

outperform 
the 
wiener 
filter 
(fig. 
5). 
thus, 
even 

for 
limit 
data, 
modern 
machin 
learn 
method 

can 
yield 
signific 
gain 
in 
decod 
performance. 











figur 
2: 
exampl 
decod 
result 

exampl 
decod 
result 
from 
motor 
cortex 
(left), 
somatosensori 
cortex 
(middle), 
and 
hippocampu 
(right), 
for 
all 
ten 

method 
(top 
to 
bottom). 
ground 
truth 
trace 
be 
in 
black, 
while 
decod 
result 
be 
in 
variou 
colors. 













figur 
3: 
decod 
result 
summari 

R2 
valu 
be 
report 
for 
all 
decod 
(differ 
colors) 
for 
each 
brain 
area 
(top 
to 
bottom). 
error 
bar 
repres 
the 

mean 
+/-­‐ 
sem 
across 
cross-­‐valid 
folds. 
x’ 
repres 
the 
R2 
valu 
of 
each 
cross-­‐valid 
fold. 

note 
the 
differ 

y-­‐axi 
limit 
for 
the 
hippocampu 
dataset. 











figur 
4: 
exampl 
result 
with 
limit 
train 
data 

use 
onli 
2 
minut 
of 
train 
data 
for 
motor 
cortex 
and 
somatosensori 
cortex, 
and 
15 
minut 
of 
train 
data 
for 

hippocampus, 
we 
train 
two 
tradit 
method 
(wiener 
filter 
and 
kalman 
filter), 
and 
two 
modern 
method 

(feedforward 
neural 
network 
and 
lstm). 
exampl 
decod 
result 
be 
show 
from 
motor 
cortex 
(left), 
somatosensori 

cortex 
(middle), 
and 
hippocampu 
(right), 
for 
these 
method 
(top 
to 
bottom). 
ground 
truth 
trace 
be 
in 
black, 
while 

decod 
result 
be 
in 
the 
same 
color 
a 
previou 
figures. 










figur 
5: 
decod 
result 
with 
vari 
amount 
of 
train 
data 

use 
vari 
amount 
of 
train 
data, 
we 
train 
two 
tradit 
method 
(wiener 
filter 
and 
kalman 
filter), 
and 
two 

modern 
method 
(feedforward 
neural 
network 
and 
lstm). 
R2 
valu 
be 
report 
for 
these 
decod 
(differ 
colors) 

for 
each 
brain 
area 
(top 
to 
bottom). 
error 
bar 
be 
68% 
confid 
interv 
(meant 
to 
approxim 
the 
sem) 
produc 

via 
bootstrapping, 
a 
we 
use 
a 
singl 
test 
set. 
valu 
with 
neg 
r2 
be 
not 
shown. 
also 
note 
the 
differ 
y-­‐axi 

limit 
for 
the 
hippocampu 
dataset. 









discussion: 

here 
we 
test 
the 
perform 
of 
a 
larg 
number 

of 
decod 
techniqu 
on 
three 
differ 
neural 

decod 
problems. 
We 
found 
that, 
across 
datasets, 

neural 
network 
outperform 
tradit 
methods. 

An 
ensembl 
method 
provid 
onli 
minor 

addit 
predict 
power. 
the 
strong 

perform 
of 
neural 
network 
even 
persist 
for 

small 
dataset 
with 
a 
littl 
a 
one 
minut 
of 

train 
data. 




We 
find 
it 
particularli 
interest 
that 
the 
neural 

network 
method 
work 
so 
well 
with 
limit 
data, 

which 
be 
counter 
to 
the 
common 
perception. 
We 

believ 
the 
explan 
be 
simpli 
the 
size 
of 

networks. 
for 
instance, 
our 
network 
have 
on 
the 

order 
of 
100 
thousand 
parameters, 
while 
common 

network 
for 
imag 
classif 
(e.g. 
[29]) 
can 

have 
on 
the 
order 
of 
100 
million 
parameters. 
thus, 

the 
reason 
size 
of 
our 
network 
(hundr 
of 

hidden 
units) 
like 
allow 
for 
excel 
predict 

with 
limit 
data 
[30]. 



It 
be 
also 
intrigu 
that 
the 
feedforward 
neural 

network 
do 
almost 
a 
well 
a 
the 
lstm 
and 
good 

than 
the 
standard 
rnn, 
consid 
the 
recent 

attent 
to 
treat 
the 
brain 
a 
a 
dynam 

system 
[31]. 
for 
the 
motor 
and 
somatosensori 

cortex 
decoding, 
it 
be 
possibl 
that 
the 
highli 

train 
monkey 
yield 
a 
stereotyp 
tempor 

relationship 
between 
neural 
activ 
and 
movement 

that 
a 
feedforward 
neural 
network 
could 
effect 

capture. 
It 
would 
be 
interest 
to 
compar 
the 

perform 
of 
feedforward 
and 
recurr 
neural 

network 
on 
less 
constrain 
behavior. 




In 
order 
to 
find 
the 
best 
hyperparamet 
for 
the 

decod 
algorithms, 
we 
use 
a 
bayesian 

optim 
routin 
[18] 
to 
search 
the 

hyperparamet 
space 
(see 
methods). 
still, 
it 
be 

possibl 
that 
some 
of 
the 
decod 
algorithm 
do 

not 
use 
the 
optim 
hyperparameters, 
which 
could 

have 
lower 
overal 
accuracy. 
moreover, 
for 

sever 
method 
we 
do 
not 
fit 
all 
avail 

hyperparameters. 
We 
do 
thi 
in 
order 
to 
simplifi 

the 
use 
of 
these 
methods, 
in 
order 
to 
decreas 

comput 
runtim 
dure 
hyperparamet 

optimization, 
and 
becaus 
add 
addit 

hyperparamet 
do 
not 
appear 
to 
improv 

accuracy. 
for 
example, 
for 
the 
neural 
net 
we 
use 

dropout 
but 
not 
L1 
or 
L2 
regularization, 
and 
for 

xgboost 
we 
use 
less 
than 
half 
the 
avail 


hyperparamet 
for 
avoid 
overfitting. 
while 
our 

preliminari 
test 
with 
addit 

hyperparamet 
do 
not 
appear 
to 
significantli 

chang 
the 
results, 
it 
be 
possibl 
that 
we 
have 
not 

achiev 
optim 
perform 
of 
our 
methods. 



while 
we 
have 
test 
standard 
algorithm 
on 
three 

differ 
datasets, 
it 
be 
possibl 
that 
the 
rel 

perform 
of 
algorithm 
differ 
on 
other 
datasets. 

however, 
mani 
dataset 
in 
neurosci 
share 

basic 
properti 
with 
those 
we 
used. 
most 
be 

similar 
in 
length 
(ten 
of 
minut 
to 
a 
coupl 

hours), 
simpli 
becaus 
the 
length 
of 
a 
record 

session 
be 
usual 
limit 
by 
both 
the 
patienc 
of 
the 

anim 
and 
the 
experimentalist. 
moreover, 
most 

variabl 
of 
interest 
have 
similar 
relev 

timescales, 
where 
movement, 
speech, 
vision, 
and 

mani 
other 
phenomenon 
unfold 
on 
a 
timescal 
of 

hundr 
of 
millisecond 
to 
seconds. 
We 
thu 

expect 
that 
similar 
result 
would 
be 
obtain 
for 

other 
spike 
datasets. 



We 
have 
decod 
from 
spike 
data, 
but 
it 
be 

possibl 
that 
the 
problem 
of 
decod 
from 
other 

data 
modal 
be 
different. 
one 
main 
driver 
of 
a 

differ 
may 
be 
the 
distinct 
level 
of 
noise. 
for 

example, 
fmri 
signal 
have 
far 
high 
nois 
level 

than 
spikes. 
As 
the 
nois 
level 
go 
up, 
linear 

techniqu 
becom 
more 
appropriate, 
which 
may 

ultim 
lead 
to 
a 
situat 
where 
the 
tradit 

linear 
techniqu 
becom 
superior. 
appli 
the 

same 
analysi 
we 
do 
here 
across 
differ 
data 

modal 
be 
an 
import 
next 
step. 



all 
our 
decod 
be 
do 
“offline,” 
mean 
that 

the 
decod 
occur 
after 
the 
recording, 
and 
be 

not 
part 
of 
a 
control 
loop. 
thi 
type 
of 
decod 
be 

use 
for 
determin 
how 
inform 
in 
a 

particular 
brain 
area 
relat 
to 
an 
extern 
variable. 

however, 
for 
engin 
applic 
such 
a 
bmi 

[32, 
33], 
the 
goal 
be 
to 
decod 
inform 
(e.g., 

predict 
movements) 
in 
real 
time. 
our 
result 
here 

may 
not 
appli 
a 
directli 
to 
onlin 
decod 

situations, 
sinc 
the 
subject 
be 
ultim 
abl 
to 

adapt 
to 
imperfect 
in 
the 
decoder. 
In 
that 
case, 

even 
rel 
larg 
decod 
perform 

differ 
may 
be 
irrelevant. 
An 
addit 

challeng 
for 
onlin 
applic 
be 
comput 

runtime, 
which 
we 
have 
not 
address 
here. 
In 
the 

future, 
it 
would 
be 
valuabl 
to 
test 
modern 
machin 




learn 
techniqu 
for 
decod 
in 
onlin 

applic 
(a 
in 
[34]). 



while 
modern 
machin 
learn 
method 
provid 

an 
increas 
in 
decod 
accuracy, 
it 
be 
import 
to 

be 
care 
with 
the 
scientif 
interpret 
of 

decod 
results. 
decod 
can 
tell 
u 
how 
much 

inform 
a 
neural 
popul 
have 
about 
a 

variabl 
X. 
however, 
high 
decod 
accuraci 
do 

not 
mean 
that 
a 
brain 
area 
be 
directli 
involv 
in 

process 
X, 
or 
that 
X 
be 
the 
purpos 
of 
the 
brain 

area. 
for 
example, 
with 
a 
power 
decoder, 
it 
could 

be 
possibl 
to 
accur 
classifi 
imag 
base 
on 

record 
from 
the 
retina, 
sinc 
the 
retina 
have 

inform 
about 
all 
visual 
space. 
however, 
thi 

do 
not 
mean 
that 
the 
primari 
purpos 
of 
the 

retina 
be 
imag 
classification. 
moreover, 
even 
if 
the 

neural 
signal 
come 
befor 
the 
extern 
variable, 
it 

do 
not 
mean 
that 
it 
be 
causal 
involved. 
for 

example, 
inform 
could 
be 
in 
somatosensori 

cortex 
prior 
to 
movement 
due 
to 
an 
effer 
copi 

from 
m1. 
thus, 
research 
should 
constrain 

interpret 
to 
be 
about 
the 
inform 
in 

neural 
populations, 
and 
how 
it 
may 
vari 
across 

brain 
regions, 
experiment 
conditions, 
or 
time 

intervals. 



We 
decod 
continu 
valu 
variables. 
the 
same 

method 
can 
be 
use 
for 
classif 
tasks, 
which 

often 
use 
classic 
decod 
such 
a 
logist 

regress 
and 
support 
vector 
machines. 
while 


here 
we 
have 
not 
demonstr 
the 
benefit 
of 

modern 
machin 
learn 
method 
for 

classification, 
our 
avail 
code 
can 
easili 
be 

modifi 
to 
allow 
user 
to 
do 
classification. 



neural 
engin 
have 
a 
histori 
of 
develop 

special 
algorithm 
meant 
to 
increas 
the 

perform 
of 
decod 
[35-­‐37]. 
however, 
these 

algorithm 
be 
not 
typic 
test 
against 
state 
of 

the 
art 
machin 
learn 
algorithms. 
along 
with 
thi 

manuscript, 
we 
have 
releas 
a 
packag 
to 
do 

neural 
decod 
use 
all 
the 
describ 
methods, 

make 
it 
be 
easi 
to 
compar 
with 
ani 
new 

algorithm. 
our 
hunch 
be 
that 
it 
will 
be 
hard 
for 

special 
algorithm 
to 
compet 
with 
the 

standard 
algorithm 
develop 
by 
a 
massiv 

commun 
in 
machin 
learning. 





acknowledgements: 

We 
would 
like 
to 
thank 
pavan 
ramkumar 
for 
help 

with 
code 
development. 
for 
funding, 
JG 
would 
like 

to 
thank 
nih 
f31 
ey025532 
and 
nih 
t32 

hd057845. 
MP 
would 
like 
to 
thank 
nih 
f31 

ns092356 
and 
nih 
t32 
hd07418. 
RC 
would 
like 
to 

thank 
nih 
r01 
ns095251 
and 
dge-­‐1324585. 
LM 

would 
like 
to 
thank 
nih 
r01 
ns074044 
and 
nih 

r01 
ns095251. 
KK 
would 
like 
to 
thank 
nih 
r01 

ns074044, 
nih 
r01 
ns063399 
and 
nih 
r01 

ey021579. 













refer 




1. 
raposo 
D, 
kaufman 
mt, 
churchland 
ak. 
A 
category-­‐fre 
neural 
popul 
support 
evolv 
demand 
dure 

decision-­‐making. 
natur 
neuroscience. 
2014;17(12):1784-­‐92. 

2. 
rich 
el, 
walli 
jd. 
decod 
subject 
decis 
from 
orbitofront 
cortex. 
natur 
neuroscience. 

2016;19(7):973-­‐80. 

3. 
hung 
cp, 
kreiman 
G, 
poggio 
T, 
dicarlo 
jj. 
fast 
readout 
of 
object 
ident 
from 
macaqu 
inferior 
tempor 

cortex. 
science. 
2005;310(5749):863-­‐6. 

4. 
quiroga 
rq, 
snyder 
lh, 
batista 
ap, 
cui 
H, 
andersen 
ra. 
movement 
intent 
be 
good 
predict 
than 
attent 

in 
the 
posterior 
pariet 
cortex. 
J 
neurosci. 
2006;26(13):3615-­‐20. 

5. 
hernández 
A, 
nácher 
V, 
luna 
R, 
zaino 
A, 
lemu 
L, 
alvarez 
M, 
et 
al. 
decod 
a 
perceptu 
decis 
process 

across 
cortex. 
neuron. 
2010;66(2):300-­‐14. 

6. 
van 
der 
meer 
ma, 
johnson 
A, 
schmitzer-­‐torbert 
nc, 
redish 
ad. 
tripl 
dissoci 
of 
inform 
process 
in 

dorsal 
striatum, 
ventral 
striatum, 
and 
hippocampu 
on 
a 
learn 
spatial 
decis 
task. 
neuron. 
2010;67(1):25-­‐32. 

7. 
dekleva 
bm, 
ramkumar 
P, 
wanda 
pa, 
kord 
kp, 
miller 
le. 
uncertainti 
lead 
to 
persist 
effect 
on 
reach 

represent 
in 
dorsal 
premotor 
cortex. 
elife. 
2016;5:e14316. 
doi: 
10.7554/elife.14316. 

8. 
glaser 
ji, 
perich 
mg, 
ramkumar 
P, 
miller 
le, 
kord 
kp. 
popul 
code 
Of 
condit 
probabl 

distribut 
In 
dorsal 
premotor 
cortex. 
biorxiv. 
2017:137026. 

9. 
weygandt 
M, 
blecker 
cr, 
schäfer 
A, 
hackmack 
K, 
hayn 
j-­‐d, 
vaitl 
D, 
et 
al. 
fmri 
pattern 
recognit 
in 

obsessive–compuls 
disorder. 
neuroimage. 
2012;60(2):1186-­‐93. 

10. 
serruya 
md, 
hatsopoulo 
ng, 
paninski 
L, 
fellow 
mr, 
donoghu 
jp. 
brain-­‐machin 
interface: 
instant 
neural 

control 
of 
a 
movement 
signal. 
nature. 
2002;416(6877):141-­‐2. 

11. 
colling 
jl, 
wodling 
B, 
downey 
je, 
wang 
W, 
tyler-­‐kabara 
ec, 
weber 
dj, 
et 
al. 
high-­‐perform 

neuroprosthet 
control 
by 
an 
individu 
with 
tetraplegia. 
the 
lancet. 
2013;381(9866):557-­‐64. 

12. 
ethier 
C, 
obi 
er, 
bauman 
mj, 
miller 
le. 
restor 
of 
grasp 
follow 
paralysi 
through 
brain-­‐control 

stimul 
of 
muscles. 
nature. 
2012;485(7398):368-­‐71. 
doi: 
10.1038/nature10987. 
pubm 
pmid: 
22522928; 

pubm 
central 
pmcid: 
pmcpmc3358575. 

13. 
benjamin 
as, 
fernand 
hl, 
tomlinson 
T, 
ramkumar 
P, 
versteeg 
C, 
miller 
L, 
et 
al. 
modern 
machin 
learn 
far 

outperform 
glm 
at 
predict 
spikes. 
biorxiv. 
2017:111450. 

14. 
mizuseki 
K, 
sirota 
A, 
pastalkova 
E, 
buzsáki 
G. 
theta 
oscil 
provid 
tempor 
window 
for 
local 
circuit 

comput 
in 
the 
entorhinal-­‐hippocamp 
loop. 
neuron. 
2009;64(2):267-­‐80. 

15. 
mizuseki 
K, 
sirota 
A, 
pastalkova 
E, 
buzsáki 
G. 
multi-­‐unit 
record 
from 
the 
rat 
hippocampu 
make 
dure 

open 
field 
foraging. 
2009. 
doi: 
http://dx.doi.org/10.6080/k0z60kz9. 

16. 
london 
bm, 
miller 
le. 
respons 
of 
somatosensori 
area 
2 
neuron 
to 
activ 
and 
passiv 
gener 
limb 

movements. 
journal 
of 
neurophysiology. 
2013;109(6):1505-­‐13. 

17. 
fagg 
ah, 
ojakanga 
gw, 
miller 
le, 
hatsopoulo 
ng. 
kinet 
trajectori 
decod 
use 
motor 
cortic 
ensembles. 

ieee 
transact 
on 
neural 
system 
and 
rehabilit 
engineering. 
2009;17(5):487-­‐96. 

18. 
snoek 
J, 
larochel 
H, 
adam 
rp, 
editors. 
practic 
bayesian 
optim 
of 
machin 
learn 
algorithms. 

advanc 
in 
neural 
inform 
process 
systems; 
2012. 

19. 
Wu 
W, 
black 
mj, 
gao 
Y, 
serruya 
M, 
shaikhouni 
A, 
donoghu 
J, 
et 
al., 
editors. 
neural 
decod 
of 
cursor 
motion 

use 
a 
kalman 
filter. 
advanc 
in 
neural 
inform 
process 
systems; 
2003. 

20. 
pohlmey 
ea, 
solla 
sa, 
perreault 
ej, 
miller 
le. 
predict 
of 
upper 
limb 
muscl 
activ 
from 
motor 
cortic 

discharg 
dure 
reaching. 
journal 
of 
neural 
engineering. 
2007;4(4):369. 

21. 
chang 
c-­‐c, 
lin 
c-­‐j. 
libsvm: 
a 
librari 
for 
support 
vector 
machines. 
acm 
transact 
on 
intellig 
system 
and 

technolog 
(tist). 
2011;2(3):27. 

22. 
chen 
T, 
guestrin 
C, 
editors. 
xgboost: 
A 
scalabl 
tree 
boost 
system. 
proceed 
of 
the 
22nd 
acm 
sigkdd 

intern 
confer 
on 
knowledg 
discoveri 
and 
data 
mining; 
2016: 
acm. 

23. 
chollet 
F. 
keras. 
2015. 

24. 
srivastava 
N, 
hinton 
ge, 
krizhevski 
A, 
sutskev 
I, 
salakhutdinov 
R. 
dropout: 
a 
simpl 
way 
to 
prevent 
neural 

network 
from 
overfitting. 
journal 
of 
machin 
learn 
research. 
2014;15(1):1929-­‐58. 

25. 
kingma 
D, 
Ba 
J. 
adam: 
A 
method 
for 
stochast 
optimization. 
arxiv 
preprint 
arxiv:14126980. 
2014. 

26. 
tieleman 
T, 
hinton 
G. 
lectur 
6.5-­‐rmsprop: 
divid 
the 
gradient 
by 
a 
run 
averag 
of 
it 
recent 
magnitude. 

coursera: 
neural 
network 
for 
machin 
learning. 
2012. 

27. 
cho 
K, 
van 
merriënbo 
B, 
gulcehr 
C, 
bahdanau 
D, 
bougar 
F, 
schwenk 
H, 
et 
al. 
learn 
phrase 

represent 
use 
rnn 
encoder-­‐decod 
for 
statist 
machin 
translation. 
arxiv 
preprint 
arxiv:14061078. 
2014. 

28. 
hochreit 
S, 
schmidhub 
J. 
long 
short-­‐term 
memory. 
neural 
computation. 
1997;9(8):1735-­‐80. 

29. 
krizhevski 
A, 
sutskev 
I, 
hinton 
ge, 
editors. 
imagenet 
classif 
with 
deep 
convolut 
neural 
networks. 

advanc 
in 
neural 
inform 
process 
systems; 
2012. 




30. 
zhang 
C, 
bengio 
S, 
hardt 
M, 
recht 
B, 
vinyal 
O. 
understand 
deep 
learn 
requir 
rethink 

generalization. 
arxiv 
preprint 
arxiv:161103530. 
2016. 

31. 
shenoy 
kv, 
sahani 
M, 
churchland 
mm. 
cortic 
control 
of 
arm 
movements: 
a 
dynam 
system 
perspective. 

annu 
rev 
neurosci. 
2013;36:337-­‐59. 
doi: 
10.1146/annurev-­‐neuro-­‐062111-­‐150509. 
pubm 
pmid: 
23725001. 

32. 
kao 
jc, 
staviski 
sd, 
sussillo 
D, 
nuyujukian 
P, 
shenoy 
kv. 
inform 
system 
opportun 
in 
brain–machin 

interfac 
decoders. 
proceed 
of 
the 
ieee. 
2014;102(5):666-­‐82. 

33. 
nicolas-­‐alonso 
lf, 
gomez-­‐gil 
J. 
brain 
comput 
interfaces, 
a 
review. 
sensors. 
2012;12(2):1211-­‐79. 

34. 
sussillo 
D, 
nuyujukian 
P, 
fan 
jm, 
kao 
jc, 
staviski 
sd, 
ryu 
S, 
et 
al. 
A 
recurr 
neural 
network 
for 
closed-­‐loop 

intracort 
brain–machin 
interfac 
decoders. 
journal 
of 
neural 
engineering. 
2012;9(2):026027. 

35. 
kao 
jc, 
nuyujukian 
P, 
ryu 
si, 
churchland 
mm, 
cunningham 
jp, 
shenoy 
kv. 
single-­‐tri 
dynam 
of 
motor 
cortex 

and 
their 
applic 
to 
brain-­‐machin 
interfaces. 
natur 
communications. 
2015;6. 

36. 
corbett 
E, 
perreault 
E, 
koerd 
K, 
editors. 
mixtur 
of 
time-­‐warp 
trajectori 
model 
for 
movement 
decoding. 

advanc 
in 
neural 
inform 
process 
systems; 
2010. 

37. 
kao 
jc, 
nuyujukian 
P, 
ryu 
si, 
shenoy 
kv. 
A 
high-­‐perform 
neural 
prosthesi 
incorpor 
discret 
state 

select 
with 
hidden 
markov 
models. 
ieee 
transact 
on 
biomed 
engineering. 
2017;64(4):935-­‐45. 














supplement 
figur 
1. 
kalman 
filter 
version 

R2 
valu 
be 
report 
for 
differ 
version 
of 
the 
kalman 
filter 
for 
each 
brain 
area 
(top 
to 
bottom). 
On 
the 
left 
(in 

more 
transpar 
cyan), 
the 
kalman 
filter 
be 
implement 
a 
in 
[19]. 
On 
the 
right 
(in 
more 
opaqu 
cyan), 
the 
kalman 

filter 
be 
implement 
with 
an 
extra 
paramet 
that 
scale 
the 
nois 
matrix 
associ 
with 
the 
transit 
in 
kinemat 

state 
(see 
methods). 
thi 
version 
with 
the 
extra 
paramet 
be 
the 
one 
use 
in 
the 
main 
text. 
error 
bar 
repres 
the 

mean 
+/-­‐ 
sem 
across 
cross-­‐valid 
folds. 
x’ 
repres 
the 
R2 
valu 
of 
each 
cross-­‐valid 
fold. 

note 
the 
differ 

y-­‐axi 
limit 
for 
the 
hippocampu 
dataset. 





