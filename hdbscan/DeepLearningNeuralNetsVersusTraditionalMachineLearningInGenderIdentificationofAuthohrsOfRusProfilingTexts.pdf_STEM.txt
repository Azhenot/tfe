


























































































deep learn neural net versu tradit machin learn in gender identif of author of rusprofil text 


sciencedirect 

avail onlin at www.sciencedirect.com 

procedia comput scienc 123 (2018) 424–431 

1877-0509 © 2018 the authors. publish by elsevi ltd. thi be an open access articl under the CC by-nc-nd licens 
(http://creativecommons.org/licenses/by-nc-nd/3.0/). 
peer-review under respons of the scientif committe of the 8th annual intern confer on biolog inspir 
cognit architectur 
10.1016/j.procs.2018.01.065 

8th annual intern confer on biolog inspir cognit architectures, bica 2017 

10.1016/j.procs.2018.01.065 1877-0509 

© 2018 the authors. publish by elsevi ltd. thi be an open access articl under the CC by-nc-nd licens 
(http://creativecommons.org/licenses/by-nc-nd/3.0/). 
peer-review under respons of the scientif committe of the 8th annual intern confer on 
biolog inspir cognit architectur 

thi space be reserv for the procedia header, do not use it 

deep learn neural net versu tradit machin 

learn in gender identif of author of rusprofil 

text 

alexand sboev1,2, ivan moloshnikov1, dmitri gudovskikh1, anton 
selivanov1, roman rybka1, and tatiana litvinova1,3 

1 nation research centr ’kurchatov institute’, moscow, russian feder 
2 mephi nation research nuclear university, moscow, russian feder 

3 voronezh state pedagog university, voronezh, russian feder 
sag111@mail.ru, ivan-rus@yandex.ru, dvgudovskikh@gmail.com, 

aaselivanov.10.03@gmail.com, rybkarb@gmail.com, centr ru yaz@mail.ru 

abstract 
In thi paper we compar accuraci of solv the task of gender identif of ruspro- 

file text without gender decept on base of two type of data-driven model approaches: 
on the one hand, well-known convent machin learn algorithms, such a support vec- 
tor machine, gradient boosting; and, on the other hand, the set of deep learn neuronets, 
such a neuronet topolog with convolution, fully-connected, and long short-term memori 
layers, etc. the depend of effect of these model on the featur select and on 
their represent be investigated. the obtain f1-score of 88% establish the state of the 
art in the gender identif task with the rusprofil corpus. 

keywords: gender identification, neural networks, natur languag processing, data-driven model 

1 introduct 

In the current practic there be two class of data-driven model applic to the gender iden- 
tific task: convent machin learn algorithm like support vector machin (svm) 
,gradient boost and the set of deep learn neuronet with the convolution, the long 
shortterm memori layer (lstm), etc. the contemporari level of accuracies, reach on the 
task be differ for differ languages. result of the pan 2017 competit [1] give the 
main mileston in the question what be the state of the art for such languag a arabic, en- 
glish,portuguese, spanish. one of the pan 2017 task be the gender identif of twitter 
texts. the competit corpu consist of 500 tweet of 100 authors. the dataset be divid 
into 60% (300 texts) for train and 40% (200 texts) for testing. the best result for english 
and spanishwer obtain use the linear support vector machine, see [2]. input text be 

1 

thi space be reserv for the procedia header, do not use it 

deep learn neural net versu tradit machin 

learn in gender identif of author of rusprofil 

text 

alexand sboev1,2, ivan moloshnikov1, dmitri gudovskikh1, anton 
selivanov1, roman rybka1, and tatiana litvinova1,3 

1 nation research centr ’kurchatov institute’, moscow, russian feder 
2 mephi nation research nuclear university, moscow, russian feder 

3 voronezh state pedagog university, voronezh, russian feder 
sag111@mail.ru, ivan-rus@yandex.ru, dvgudovskikh@gmail.com, 

aaselivanov.10.03@gmail.com, rybkarb@gmail.com, centr ru yaz@mail.ru 

abstract 
In thi paper we compar accuraci of solv the task of gender identif of ruspro- 

file text without gender decept on base of two type of data-driven model approaches: 
on the one hand, well-known convent machin learn algorithms, such a support vec- 
tor machine, gradient boosting; and, on the other hand, the set of deep learn neuronets, 
such a neuronet topolog with convolution, fully-connected, and long short-term memori 
layers, etc. the depend of effect of these model on the featur select and on 
their represent be investigated. the obtain f1-score of 88% establish the state of the 
art in the gender identif task with the rusprofil corpus. 

keywords: gender identification, neural networks, natur languag processing, data-driven model 

1 introduct 

In the current practic there be two class of data-driven model applic to the gender iden- 
tific task: convent machin learn algorithm like support vector machin (svm) 
,gradient boost and the set of deep learn neuronet with the convolution, the long 
shortterm memori layer (lstm), etc. the contemporari level of accuracies, reach on the 
task be differ for differ languages. result of the pan 2017 competit [1] give the 
main mileston in the question what be the state of the art for such languag a arabic, en- 
glish,portuguese, spanish. one of the pan 2017 task be the gender identif of twitter 
texts. the competit corpu consist of 500 tweet of 100 authors. the dataset be divid 
into 60% (300 texts) for train and 40% (200 texts) for testing. the best result for english 
and spanishwer obtain use the linear support vector machine, see [2]. input text be 

1 

thi space be reserv for the procedia header, do not use it 

deep learn neural net versu tradit machin 

learn in gender identif of author of rusprofil 

text 

alexand sboev1,2, ivan moloshnikov1, dmitri gudovskikh1, anton 
selivanov1, roman rybka1, and tatiana litvinova1,3 

1 nation research centr ’kurchatov institute’, moscow, russian feder 
2 mephi nation research nuclear university, moscow, russian feder 

3 voronezh state pedagog university, voronezh, russian feder 
sag111@mail.ru, ivan-rus@yandex.ru, dvgudovskikh@gmail.com, 

aaselivanov.10.03@gmail.com, rybkarb@gmail.com, centr ru yaz@mail.ru 

abstract 
In thi paper we compar accuraci of solv the task of gender identif of ruspro- 

file text without gender decept on base of two type of data-driven model approaches: 
on the one hand, well-known convent machin learn algorithms, such a support vec- 
tor machine, gradient boosting; and, on the other hand, the set of deep learn neuronets, 
such a neuronet topolog with convolution, fully-connected, and long short-term memori 
layers, etc. the depend of effect of these model on the featur select and on 
their represent be investigated. the obtain f1-score of 88% establish the state of the 
art in the gender identif task with the rusprofil corpus. 

keywords: gender identification, neural networks, natur languag processing, data-driven model 

1 introduct 

In the current practic there be two class of data-driven model applic to the gender iden- 
tific task: convent machin learn algorithm like support vector machin (svm) 
,gradient boost and the set of deep learn neuronet with the convolution, the long 
shortterm memori layer (lstm), etc. the contemporari level of accuracies, reach on the 
task be differ for differ languages. result of the pan 2017 competit [1] give the 
main mileston in the question what be the state of the art for such languag a arabic, en- 
glish,portuguese, spanish. one of the pan 2017 task be the gender identif of twitter 
texts. the competit corpu consist of 500 tweet of 100 authors. the dataset be divid 
into 60% (300 texts) for train and 40% (200 texts) for testing. the best result for english 
and spanishwer obtain use the linear support vector machine, see [2]. input text be 

1 

thi space be reserv for the procedia header, do not use it 

deep learn neural net versu tradit machin 

learn in gender identif of author of rusprofil 

text 

alexand sboev1,2, ivan moloshnikov1, dmitri gudovskikh1, anton 
selivanov1, roman rybka1, and tatiana litvinova1,3 

1 nation research centr ’kurchatov institute’, moscow, russian feder 
2 mephi nation research nuclear university, moscow, russian feder 

3 voronezh state pedagog university, voronezh, russian feder 
sag111@mail.ru, ivan-rus@yandex.ru, dvgudovskikh@gmail.com, 

aaselivanov.10.03@gmail.com, rybkarb@gmail.com, centr ru yaz@mail.ru 

abstract 
In thi paper we compar accuraci of solv the task of gender identif of ruspro- 

file text without gender decept on base of two type of data-driven model approaches: 
on the one hand, well-known convent machin learn algorithms, such a support vec- 
tor machine, gradient boosting; and, on the other hand, the set of deep learn neuronets, 
such a neuronet topolog with convolution, fully-connected, and long short-term memori 
layers, etc. the depend of effect of these model on the featur select and on 
their represent be investigated. the obtain f1-score of 88% establish the state of the 
art in the gender identif task with the rusprofil corpus. 

keywords: gender identification, neural networks, natur languag processing, data-driven model 

1 introduct 

In the current practic there be two class of data-driven model applic to the gender iden- 
tific task: convent machin learn algorithm like support vector machin (svm) 
,gradient boost and the set of deep learn neuronet with the convolution, the long 
shortterm memori layer (lstm), etc. the contemporari level of accuracies, reach on the 
task be differ for differ languages. result of the pan 2017 competit [1] give the 
main mileston in the question what be the state of the art for such languag a arabic, en- 
glish,portuguese, spanish. one of the pan 2017 task be the gender identif of twitter 
texts. the competit corpu consist of 500 tweet of 100 authors. the dataset be divid 
into 60% (300 texts) for train and 40% (200 texts) for testing. the best result for english 
and spanishwer obtain use the linear support vector machine, see [2]. input text be 

1 

thi space be reserv for the procedia header, do not use it 

deep learn neural net versu tradit machin 

learn in gender identif of author of rusprofil 

text 

alexand sboev1,2, ivan moloshnikov1, dmitri gudovskikh1, anton 
selivanov1, roman rybka1, and tatiana litvinova1,3 

1 nation research centr ’kurchatov institute’, moscow, russian feder 
2 mephi nation research nuclear university, moscow, russian feder 

3 voronezh state pedagog university, voronezh, russian feder 
sag111@mail.ru, ivan-rus@yandex.ru, dvgudovskikh@gmail.com, 

aaselivanov.10.03@gmail.com, rybkarb@gmail.com, centr ru yaz@mail.ru 

abstract 
In thi paper we compar accuraci of solv the task of gender identif of ruspro- 

file text without gender decept on base of two type of data-driven model approaches: 
on the one hand, well-known convent machin learn algorithms, such a support vec- 
tor machine, gradient boosting; and, on the other hand, the set of deep learn neuronets, 
such a neuronet topolog with convolution, fully-connected, and long short-term memori 
layers, etc. the depend of effect of these model on the featur select and on 
their represent be investigated. the obtain f1-score of 88% establish the state of the 
art in the gender identif task with the rusprofil corpus. 

keywords: gender identification, neural networks, natur languag processing, data-driven model 

1 introduct 

In the current practic there be two class of data-driven model applic to the gender iden- 
tific task: convent machin learn algorithm like support vector machin (svm) 
,gradient boost and the set of deep learn neuronet with the convolution, the long 
shortterm memori layer (lstm), etc. the contemporari level of accuracies, reach on the 
task be differ for differ languages. result of the pan 2017 competit [1] give the 
main mileston in the question what be the state of the art for such languag a arabic, en- 
glish,portuguese, spanish. one of the pan 2017 task be the gender identif of twitter 
texts. the competit corpu consist of 500 tweet of 100 authors. the dataset be divid 
into 60% (300 texts) for train and 40% (200 texts) for testing. the best result for english 
and spanishwer obtain use the linear support vector machine, see [2]. input text be 

1 

deep learn neuronet model versu tradit machin learn . . . sboev et al. 

repres a frequenc vector of charact 2,3,4-gram and word forms, such a bigram 
and trigrams.then the frequenc be replac by the measur 1 + log(term − frequency), 
which show the best result. for the arab language, the best model [3] be base on a 
represent of text a a vector contain combin of character, word and po n-gram 
with emojis, charact flooding, sentiment words. logist regress be use for train the 
classifier. deep learn approach in [4] show the best result on the portugues language. 
the author appli recurr neural network (rnn) for word and convolut neural 
network (cnn) for characters. thereby, two represent of differ level for a singl mes- 
sage be obtained. they be combin and classifi by gender, use attent mechanism, 
max-pool layer, and fully-connect layer. the word embed layer be preliminarili 
train with the skip-gram. for charact emb layer, weight be randomli initi 
with a uniform distribution. 

so, accord to the result of the competit [3], tradit method of ML show the 
best result for english, spanish, and arab languages, while deep learn be the winner for 
portuguese. the aim of thi paper be to find out which approach would be good for russian. 
We use differ corpora, describ in detail in section 2, with differ set of input featur 
describ in section 3.1. among the corpu creat with offlin respondents, there be one 
collect by crowdsourc on the web, and anoth goal of the paper be to compar the result 
obtain on differ corpu and to ass the possibl of further use of crowdsourcing. the 
algorithm we use, tradit machin learn one and deep learn topologies, be present 
in section 3.2. result of calcul and their discuss be in section 4 and 5. 

part name total men women avg. 
length(m) 

avg. 
length(w) 

male 
author 

femal 
author 

gi(or) 394 125 269 123.38 107.82 47 92 
gi(bal) 250 125 125 123.38 111.19 47 74 

tabl 1: statist of the gender imit text corpus. 

part name total men women avg. 
length(m) 

avg. 
length(w) 

male 
author 

femal 
author 

GI cs(or) 3204 1161 2043 75.16 77.21 280 438 
GI cs(bal) 2322 1161 1161 75.16 78.89 280 265 
GI c A b(or) 2134 772 1362 75.35 77.21 279 438 
GI c A b(bal) 1544 772 772 75.35 78.91 279 264 

tabl 2: statist of the gender imit crowdsourc text corpus. 

part name total men women avg. 
length(m) 

avg. 
length(w) 

male 
author 

femal 
author 

origin 1033 641 392 60.42 66.49 641 392 
balanc 784 392 392 58.61 66.49 392 392 

tabl 3: statist of the rusper text corpus. 

2 

http://crossmark.crossref.org/dialog/?doi=10.1016/j.procs.2018.01.065&domain=pdf 


alexand sboev et al. / procedia comput scienc 123 (2018) 424–431 425 

© 2018 the authors. publish by elsevi ltd. thi be an open access articl under the CC by-nc-nd licens 
(http://creativecommons.org/licenses/by-nc-nd/3.0/). 
peer-review under respons of the scientif committe of the 8th annual intern confer on 
biolog inspir cognit architectur 

thi space be reserv for the procedia header, do not use it 

deep learn neural net versu tradit machin 

learn in gender identif of author of rusprofil 

text 

alexand sboev1,2, ivan moloshnikov1, dmitri gudovskikh1, anton 
selivanov1, roman rybka1, and tatiana litvinova1,3 

1 nation research centr ’kurchatov institute’, moscow, russian feder 
2 mephi nation research nuclear university, moscow, russian feder 

3 voronezh state pedagog university, voronezh, russian feder 
sag111@mail.ru, ivan-rus@yandex.ru, dvgudovskikh@gmail.com, 

aaselivanov.10.03@gmail.com, rybkarb@gmail.com, centr ru yaz@mail.ru 

abstract 
In thi paper we compar accuraci of solv the task of gender identif of ruspro- 

file text without gender decept on base of two type of data-driven model approaches: 
on the one hand, well-known convent machin learn algorithms, such a support vec- 
tor machine, gradient boosting; and, on the other hand, the set of deep learn neuronets, 
such a neuronet topolog with convolution, fully-connected, and long short-term memori 
layers, etc. the depend of effect of these model on the featur select and on 
their represent be investigated. the obtain f1-score of 88% establish the state of the 
art in the gender identif task with the rusprofil corpus. 

keywords: gender identification, neural networks, natur languag processing, data-driven model 

1 introduct 

In the current practic there be two class of data-driven model applic to the gender iden- 
tific task: convent machin learn algorithm like support vector machin (svm) 
,gradient boost and the set of deep learn neuronet with the convolution, the long 
shortterm memori layer (lstm), etc. the contemporari level of accuracies, reach on the 
task be differ for differ languages. result of the pan 2017 competit [1] give the 
main mileston in the question what be the state of the art for such languag a arabic, en- 
glish,portuguese, spanish. one of the pan 2017 task be the gender identif of twitter 
texts. the competit corpu consist of 500 tweet of 100 authors. the dataset be divid 
into 60% (300 texts) for train and 40% (200 texts) for testing. the best result for english 
and spanishwer obtain use the linear support vector machine, see [2]. input text be 

1 

thi space be reserv for the procedia header, do not use it 

deep learn neural net versu tradit machin 

learn in gender identif of author of rusprofil 

text 

alexand sboev1,2, ivan moloshnikov1, dmitri gudovskikh1, anton 
selivanov1, roman rybka1, and tatiana litvinova1,3 

1 nation research centr ’kurchatov institute’, moscow, russian feder 
2 mephi nation research nuclear university, moscow, russian feder 

3 voronezh state pedagog university, voronezh, russian feder 
sag111@mail.ru, ivan-rus@yandex.ru, dvgudovskikh@gmail.com, 

aaselivanov.10.03@gmail.com, rybkarb@gmail.com, centr ru yaz@mail.ru 

abstract 
In thi paper we compar accuraci of solv the task of gender identif of ruspro- 

file text without gender decept on base of two type of data-driven model approaches: 
on the one hand, well-known convent machin learn algorithms, such a support vec- 
tor machine, gradient boosting; and, on the other hand, the set of deep learn neuronets, 
such a neuronet topolog with convolution, fully-connected, and long short-term memori 
layers, etc. the depend of effect of these model on the featur select and on 
their represent be investigated. the obtain f1-score of 88% establish the state of the 
art in the gender identif task with the rusprofil corpus. 

keywords: gender identification, neural networks, natur languag processing, data-driven model 

1 introduct 

In the current practic there be two class of data-driven model applic to the gender iden- 
tific task: convent machin learn algorithm like support vector machin (svm) 
,gradient boost and the set of deep learn neuronet with the convolution, the long 
shortterm memori layer (lstm), etc. the contemporari level of accuracies, reach on the 
task be differ for differ languages. result of the pan 2017 competit [1] give the 
main mileston in the question what be the state of the art for such languag a arabic, en- 
glish,portuguese, spanish. one of the pan 2017 task be the gender identif of twitter 
texts. the competit corpu consist of 500 tweet of 100 authors. the dataset be divid 
into 60% (300 texts) for train and 40% (200 texts) for testing. the best result for english 
and spanishwer obtain use the linear support vector machine, see [2]. input text be 

1 

thi space be reserv for the procedia header, do not use it 

deep learn neural net versu tradit machin 

learn in gender identif of author of rusprofil 

text 

alexand sboev1,2, ivan moloshnikov1, dmitri gudovskikh1, anton 
selivanov1, roman rybka1, and tatiana litvinova1,3 

1 nation research centr ’kurchatov institute’, moscow, russian feder 
2 mephi nation research nuclear university, moscow, russian feder 

3 voronezh state pedagog university, voronezh, russian feder 
sag111@mail.ru, ivan-rus@yandex.ru, dvgudovskikh@gmail.com, 

aaselivanov.10.03@gmail.com, rybkarb@gmail.com, centr ru yaz@mail.ru 

abstract 
In thi paper we compar accuraci of solv the task of gender identif of ruspro- 

file text without gender decept on base of two type of data-driven model approaches: 
on the one hand, well-known convent machin learn algorithms, such a support vec- 
tor machine, gradient boosting; and, on the other hand, the set of deep learn neuronets, 
such a neuronet topolog with convolution, fully-connected, and long short-term memori 
layers, etc. the depend of effect of these model on the featur select and on 
their represent be investigated. the obtain f1-score of 88% establish the state of the 
art in the gender identif task with the rusprofil corpus. 

keywords: gender identification, neural networks, natur languag processing, data-driven model 

1 introduct 

In the current practic there be two class of data-driven model applic to the gender iden- 
tific task: convent machin learn algorithm like support vector machin (svm) 
,gradient boost and the set of deep learn neuronet with the convolution, the long 
shortterm memori layer (lstm), etc. the contemporari level of accuracies, reach on the 
task be differ for differ languages. result of the pan 2017 competit [1] give the 
main mileston in the question what be the state of the art for such languag a arabic, en- 
glish,portuguese, spanish. one of the pan 2017 task be the gender identif of twitter 
texts. the competit corpu consist of 500 tweet of 100 authors. the dataset be divid 
into 60% (300 texts) for train and 40% (200 texts) for testing. the best result for english 
and spanishwer obtain use the linear support vector machine, see [2]. input text be 

1 

thi space be reserv for the procedia header, do not use it 

deep learn neural net versu tradit machin 

learn in gender identif of author of rusprofil 

text 

alexand sboev1,2, ivan moloshnikov1, dmitri gudovskikh1, anton 
selivanov1, roman rybka1, and tatiana litvinova1,3 

1 nation research centr ’kurchatov institute’, moscow, russian feder 
2 mephi nation research nuclear university, moscow, russian feder 

3 voronezh state pedagog university, voronezh, russian feder 
sag111@mail.ru, ivan-rus@yandex.ru, dvgudovskikh@gmail.com, 

aaselivanov.10.03@gmail.com, rybkarb@gmail.com, centr ru yaz@mail.ru 

abstract 
In thi paper we compar accuraci of solv the task of gender identif of ruspro- 

file text without gender decept on base of two type of data-driven model approaches: 
on the one hand, well-known convent machin learn algorithms, such a support vec- 
tor machine, gradient boosting; and, on the other hand, the set of deep learn neuronets, 
such a neuronet topolog with convolution, fully-connected, and long short-term memori 
layers, etc. the depend of effect of these model on the featur select and on 
their represent be investigated. the obtain f1-score of 88% establish the state of the 
art in the gender identif task with the rusprofil corpus. 

keywords: gender identification, neural networks, natur languag processing, data-driven model 

1 introduct 

In the current practic there be two class of data-driven model applic to the gender iden- 
tific task: convent machin learn algorithm like support vector machin (svm) 
,gradient boost and the set of deep learn neuronet with the convolution, the long 
shortterm memori layer (lstm), etc. the contemporari level of accuracies, reach on the 
task be differ for differ languages. result of the pan 2017 competit [1] give the 
main mileston in the question what be the state of the art for such languag a arabic, en- 
glish,portuguese, spanish. one of the pan 2017 task be the gender identif of twitter 
texts. the competit corpu consist of 500 tweet of 100 authors. the dataset be divid 
into 60% (300 texts) for train and 40% (200 texts) for testing. the best result for english 
and spanishwer obtain use the linear support vector machine, see [2]. input text be 

1 

thi space be reserv for the procedia header, do not use it 

deep learn neural net versu tradit machin 

learn in gender identif of author of rusprofil 

text 

alexand sboev1,2, ivan moloshnikov1, dmitri gudovskikh1, anton 
selivanov1, roman rybka1, and tatiana litvinova1,3 

1 nation research centr ’kurchatov institute’, moscow, russian feder 
2 mephi nation research nuclear university, moscow, russian feder 

3 voronezh state pedagog university, voronezh, russian feder 
sag111@mail.ru, ivan-rus@yandex.ru, dvgudovskikh@gmail.com, 

aaselivanov.10.03@gmail.com, rybkarb@gmail.com, centr ru yaz@mail.ru 

abstract 
In thi paper we compar accuraci of solv the task of gender identif of ruspro- 

file text without gender decept on base of two type of data-driven model approaches: 
on the one hand, well-known convent machin learn algorithms, such a support vec- 
tor machine, gradient boosting; and, on the other hand, the set of deep learn neuronets, 
such a neuronet topolog with convolution, fully-connected, and long short-term memori 
layers, etc. the depend of effect of these model on the featur select and on 
their represent be investigated. the obtain f1-score of 88% establish the state of the 
art in the gender identif task with the rusprofil corpus. 

keywords: gender identification, neural networks, natur languag processing, data-driven model 

1 introduct 

In the current practic there be two class of data-driven model applic to the gender iden- 
tific task: convent machin learn algorithm like support vector machin (svm) 
,gradient boost and the set of deep learn neuronet with the convolution, the long 
shortterm memori layer (lstm), etc. the contemporari level of accuracies, reach on the 
task be differ for differ languages. result of the pan 2017 competit [1] give the 
main mileston in the question what be the state of the art for such languag a arabic, en- 
glish,portuguese, spanish. one of the pan 2017 task be the gender identif of twitter 
texts. the competit corpu consist of 500 tweet of 100 authors. the dataset be divid 
into 60% (300 texts) for train and 40% (200 texts) for testing. the best result for english 
and spanishwer obtain use the linear support vector machine, see [2]. input text be 

1 

deep learn neuronet model versu tradit machin learn . . . sboev et al. 

repres a frequenc vector of charact 2,3,4-gram and word forms, such a bigram 
and trigrams.then the frequenc be replac by the measur 1 + log(term − frequency), 
which show the best result. for the arab language, the best model [3] be base on a 
represent of text a a vector contain combin of character, word and po n-gram 
with emojis, charact flooding, sentiment words. logist regress be use for train the 
classifier. deep learn approach in [4] show the best result on the portugues language. 
the author appli recurr neural network (rnn) for word and convolut neural 
network (cnn) for characters. thereby, two represent of differ level for a singl mes- 
sage be obtained. they be combin and classifi by gender, use attent mechanism, 
max-pool layer, and fully-connect layer. the word embed layer be preliminarili 
train with the skip-gram. for charact emb layer, weight be randomli initi 
with a uniform distribution. 

so, accord to the result of the competit [3], tradit method of ML show the 
best result for english, spanish, and arab languages, while deep learn be the winner for 
portuguese. the aim of thi paper be to find out which approach would be good for russian. 
We use differ corpora, describ in detail in section 2, with differ set of input featur 
describ in section 3.1. among the corpu creat with offlin respondents, there be one 
collect by crowdsourc on the web, and anoth goal of the paper be to compar the result 
obtain on differ corpu and to ass the possibl of further use of crowdsourcing. the 
algorithm we use, tradit machin learn one and deep learn topologies, be present 
in section 3.2. result of calcul and their discuss be in section 4 and 5. 

part name total men women avg. 
length(m) 

avg. 
length(w) 

male 
author 

femal 
author 

gi(or) 394 125 269 123.38 107.82 47 92 
gi(bal) 250 125 125 123.38 111.19 47 74 

tabl 1: statist of the gender imit text corpus. 

part name total men women avg. 
length(m) 

avg. 
length(w) 

male 
author 

femal 
author 

GI cs(or) 3204 1161 2043 75.16 77.21 280 438 
GI cs(bal) 2322 1161 1161 75.16 78.89 280 265 
GI c A b(or) 2134 772 1362 75.35 77.21 279 438 
GI c A b(bal) 1544 772 772 75.35 78.91 279 264 

tabl 2: statist of the gender imit crowdsourc text corpus. 

part name total men women avg. 
length(m) 

avg. 
length(w) 

male 
author 

femal 
author 

origin 1033 641 392 60.42 66.49 641 392 
balanc 784 392 392 58.61 66.49 392 392 

tabl 3: statist of the rusper text corpus. 

2 



426 alexand sboev et al. / procedia comput scienc 123 (2018) 424–431deep learn neuronet model versu tradit machin learn . . . sboev et al. 

part name total men women avg. 
length(m) 

avg. 
length(w) 

male 
author 

femal 
author 

reviews(or) 1033 641 392 60.42 66.49 641 392 
reviews(bal) 784 392 392 58.61 66.49 392 392 
fb(or) 250 136 114 1381.87 1395.82 136 114 
fb(bal) 228 114 114 1382.58 1395.82 114 114 
FB split(or) 1617 868 749 197.36 195.19 
FB split(bal) 1498 749 749 200.86 195.19 
tw(or) 1541 998 543 1721.91 1638.18 998 543 
tw(bal) 1086 543 543 1746.76 1638.18 543 543 
Tw split(or) 7512 5062 2450 298.37 315.13 - - 
Tw split(bal) 4900 2450 2450 298.45 315.13 - - 
lj(or) 11 6 5 52812.5 63049.8 6 5 
lj(bal) 10 5 5 50463 63049.8 5 5 
LJ split(or) 3256 1632 1624 193.91 193.74 - - 
LJ split(bal) 3248 1624 1624 164.27 163.74 - - 

tabl 4: statist of the rusprofil text corpus. 

2 use corpu 

We use sever corpora, have differ number of authors, texts, and text length. for thi 
reason the origin corpu be balanc by the number of text by woman and men. the 
statist of the use datasets, origin and balanced, be present in tabl 1-4. the russian 
gender imit (gi) (tabl 1) corpu consist of special write author texts[5]. each 
author chose a topic from a list of four: a letter to a friend, a self-descript for a date site, 
a complaint about the bo or about a tour, and then be instruct to write three text on 
the same topic: text A - in the author’ natur style, text B - a someon of the opposit sex, 
text C - a someon els of the same sex. GI crowdsourc (gi cs) (tabl 2) contain text 
collect by crowdsourc platform to extend the GI corpus. It be collect the same way 
and have the same subset a gi. We singl out the subcorpu of texts: GI c a b denot 
the part of GI c without the C text (similar to GI type c). rusper (rusper)(t 3) 
be a russian-languag corpu [6] of write text label with data on their authors. each 
text have a metadata like gender, age, personalities, educ level, neuropsycholog test 
data, etc. thi paper us a part of the corpus, consist of text on two topics: letter to a 
friend and pictur descriptions. rusprofil (rusprof)(t 4) corpu [7] contain text 
collect from differ social medium platform a twitter, facebook and livejournal, along with 
review - the set of review collect manually. thi data set be divid into subsamples, 
which allow to studi how the featur of the corpu influenc the qualiti of the model and 
to evalu the possibl of cross-genr classification. some subsampl of rusprof be 
divid into two sets. In the first set all messag be merg into one text for each author: 
twitter(tw) - 1000 twitter messag for each user, LJ - the set of blog text from livejournal, 
FB - messag from facebook walls. In the second set, after combin each user messag into 
one text, it be separ into document of 15 sentences. these subsampl be denot a 
Tw split, LJ split, and FB split. We also conduct an evalu of the model with the 
corpu preliminarili balanc by the author’ gender. these result be note ‘origin (or)’ 
or ‘balanced(bal)’ respect next to the name of the corpu in the tabl further. 

3 

deep learn neuronet model versu tradit machin learn . . . sboev et al. 

3 method 

3.1 featur 

the follow set of featur be use in our work in combin with differ models: 

tf-idf for n-grams(tf-idf): the vector of n-gram frequencies, character a docu- 
ment d, be obtain by appli by the tf-idf formula tf − idf(t, d) = tf(t, d) × idf(t) 
to each n-gram t of the collect D. here t be a charact n-gram from 3 to 8 charact 
long, tf(t, d) be the number of time t occur in d; idf(t) = log 1+nd1+df(d,t) +1. here nd be the 

total number of texts, and df(d, t) be the number of text that contain t. onli n-gram 
that exist in more than 100 text be used. We use differ valu of minim df(d, t) in 
the rang from 1 to 10. 

char n-grams(char). To repres a document a a vector, the frequenc of encount 
symbol n-gram rang from 1 to 8 be calculated. 

grm-1: each word be encod by a 49-dimension binari vector of morpholog properties. 
the size of a document be fix at 300 words: longer text be clipped, and shorter text 
be extend with null vectors. 

grm-2: each word be again encod by a 49-dimension morpholog properti vector, but 
then all the vector of a text be concatenated, form a vector of the length 14700. 

word2vec. thi be an alreadi exist model that be preliminarili train on a collect 
of random russian web page crawl in decemb 2014, contain 9 million document 
in total. corpu size be 660, 628, 738 tokens. model be train use the continu 
skip-gram algorithm. vector dimension be set to 500, window size 2. lemma 
occur less than 30 time be ignor [8]. 

sequenc featur (seq. feat): text be repres a sequenc of word with a full set of 
morpholog tag (person, gender, part of speech, etc.) along with the type of syntact 
relat with a parent, all one-hot encoded. 

3.2 model 

3.2.1 convent machin learn method 

support vector machin (svm). We use the classifi base on a support vector machin 
with linear kernel. the follow hyperparamet be used: regular paramet C = 1, 
l2−norm use in the penal and squar hinge-loss function. gradient boosting(gb) 
classifi be train with the follow parameters: learn rate be 0.05, the number of 
boost stage to perform be 300, the minimum number of sampl to split an intern node be 
19, the maximum depth of the tree be 12. 

3.2.2 neural network topolog 

model 1 be base on convolut and fulli connect layers: convolut neural net- 
work (cnn): 128 neurons, window size = 2, activ function = relu;maxpool 
layer: window = 4, step = 4; cnn: 128 neurons, window = 2, activ function = 
relu; maxpool layer: window = 4, step = 4; cnn: 128 neurons, window = 2, 
activ function = relu; maxpool layer: window = 4, step = 4; cnn: 128 

4 



alexand sboev et al. / procedia comput scienc 123 (2018) 424–431 427deep learn neuronet model versu tradit machin learn . . . sboev et al. 

part name total men women avg. 
length(m) 

avg. 
length(w) 

male 
author 

femal 
author 

reviews(or) 1033 641 392 60.42 66.49 641 392 
reviews(bal) 784 392 392 58.61 66.49 392 392 
fb(or) 250 136 114 1381.87 1395.82 136 114 
fb(bal) 228 114 114 1382.58 1395.82 114 114 
FB split(or) 1617 868 749 197.36 195.19 
FB split(bal) 1498 749 749 200.86 195.19 
tw(or) 1541 998 543 1721.91 1638.18 998 543 
tw(bal) 1086 543 543 1746.76 1638.18 543 543 
Tw split(or) 7512 5062 2450 298.37 315.13 - - 
Tw split(bal) 4900 2450 2450 298.45 315.13 - - 
lj(or) 11 6 5 52812.5 63049.8 6 5 
lj(bal) 10 5 5 50463 63049.8 5 5 
LJ split(or) 3256 1632 1624 193.91 193.74 - - 
LJ split(bal) 3248 1624 1624 164.27 163.74 - - 

tabl 4: statist of the rusprofil text corpus. 

2 use corpu 

We use sever corpora, have differ number of authors, texts, and text length. for thi 
reason the origin corpu be balanc by the number of text by woman and men. the 
statist of the use datasets, origin and balanced, be present in tabl 1-4. the russian 
gender imit (gi) (tabl 1) corpu consist of special write author texts[5]. each 
author chose a topic from a list of four: a letter to a friend, a self-descript for a date site, 
a complaint about the bo or about a tour, and then be instruct to write three text on 
the same topic: text A - in the author’ natur style, text B - a someon of the opposit sex, 
text C - a someon els of the same sex. GI crowdsourc (gi cs) (tabl 2) contain text 
collect by crowdsourc platform to extend the GI corpus. It be collect the same way 
and have the same subset a gi. We singl out the subcorpu of texts: GI c a b denot 
the part of GI c without the C text (similar to GI type c). rusper (rusper)(t 3) 
be a russian-languag corpu [6] of write text label with data on their authors. each 
text have a metadata like gender, age, personalities, educ level, neuropsycholog test 
data, etc. thi paper us a part of the corpus, consist of text on two topics: letter to a 
friend and pictur descriptions. rusprofil (rusprof)(t 4) corpu [7] contain text 
collect from differ social medium platform a twitter, facebook and livejournal, along with 
review - the set of review collect manually. thi data set be divid into subsamples, 
which allow to studi how the featur of the corpu influenc the qualiti of the model and 
to evalu the possibl of cross-genr classification. some subsampl of rusprof be 
divid into two sets. In the first set all messag be merg into one text for each author: 
twitter(tw) - 1000 twitter messag for each user, LJ - the set of blog text from livejournal, 
FB - messag from facebook walls. In the second set, after combin each user messag into 
one text, it be separ into document of 15 sentences. these subsampl be denot a 
Tw split, LJ split, and FB split. We also conduct an evalu of the model with the 
corpu preliminarili balanc by the author’ gender. these result be note ‘origin (or)’ 
or ‘balanced(bal)’ respect next to the name of the corpu in the tabl further. 

3 

deep learn neuronet model versu tradit machin learn . . . sboev et al. 

3 method 

3.1 featur 

the follow set of featur be use in our work in combin with differ models: 

tf-idf for n-grams(tf-idf): the vector of n-gram frequencies, character a docu- 
ment d, be obtain by appli by the tf-idf formula tf − idf(t, d) = tf(t, d) × idf(t) 
to each n-gram t of the collect D. here t be a charact n-gram from 3 to 8 charact 
long, tf(t, d) be the number of time t occur in d; idf(t) = log 1+nd1+df(d,t) +1. here nd be the 

total number of texts, and df(d, t) be the number of text that contain t. onli n-gram 
that exist in more than 100 text be used. We use differ valu of minim df(d, t) in 
the rang from 1 to 10. 

char n-grams(char). To repres a document a a vector, the frequenc of encount 
symbol n-gram rang from 1 to 8 be calculated. 

grm-1: each word be encod by a 49-dimension binari vector of morpholog properties. 
the size of a document be fix at 300 words: longer text be clipped, and shorter text 
be extend with null vectors. 

grm-2: each word be again encod by a 49-dimension morpholog properti vector, but 
then all the vector of a text be concatenated, form a vector of the length 14700. 

word2vec. thi be an alreadi exist model that be preliminarili train on a collect 
of random russian web page crawl in decemb 2014, contain 9 million document 
in total. corpu size be 660, 628, 738 tokens. model be train use the continu 
skip-gram algorithm. vector dimension be set to 500, window size 2. lemma 
occur less than 30 time be ignor [8]. 

sequenc featur (seq. feat): text be repres a sequenc of word with a full set of 
morpholog tag (person, gender, part of speech, etc.) along with the type of syntact 
relat with a parent, all one-hot encoded. 

3.2 model 

3.2.1 convent machin learn method 

support vector machin (svm). We use the classifi base on a support vector machin 
with linear kernel. the follow hyperparamet be used: regular paramet C = 1, 
l2−norm use in the penal and squar hinge-loss function. gradient boosting(gb) 
classifi be train with the follow parameters: learn rate be 0.05, the number of 
boost stage to perform be 300, the minimum number of sampl to split an intern node be 
19, the maximum depth of the tree be 12. 

3.2.2 neural network topolog 

model 1 be base on convolut and fulli connect layers: convolut neural net- 
work (cnn): 128 neurons, window size = 2, activ function = relu;maxpool 
layer: window = 4, step = 4; cnn: 128 neurons, window = 2, activ function = 
relu; maxpool layer: window = 4, step = 4; cnn: 128 neurons, window = 2, 
activ function = relu; maxpool layer: window = 4, step = 4; cnn: 128 

4 



428 alexand sboev et al. / procedia comput scienc 123 (2018) 424–431deep learn neuronet model versu tradit machin learn . . . sboev et al. 

neurons, window = 2, activ function = relu; globalmaxpooling; dropout 0.5; 
fully-connect mlp layer: 128 neurons, activ function = relu; dropout 0.5; 
output layer - mlp: activ function = softmax. 

model 2 . the concept of stack bidirect lstm neural network architectur be in- 
spire by [9], who show the possibl of use such an architectur for charact 
prediction, machin translat and imag classif tasks. the peculiar of thi 
network worth note be that the first branch on lstm return sequenc that be 
further concatenated. It consist of the follow layers: cnn: 30 neurons, window 
size = 3, activ function = relu. the input be pad so that the output have the 
same length a the origin input (futher denot a pad = ’same’); maxpool 
layer: window = 2; cnn: 30 neurons, window size = 3, activ function = relu, 
pad = ’same’; maxpool layer: window = 2; cnn: 30 neurons, window size 
= 3, activ function = relu, pad = ’same’; maxpool layer: window = 2; 
leftlstm: 30 neurons, and the last output in the full sequenc be return (further de- 
note by ’return sequence’) and in parallel rightlstm: 30 neurons, the input sequenc 
be process backward and the revers full sequenc be return (further denot a 
’go backwards’); concatenate: leftlstm and rightlstm; leftlstm 2: 30 neuron 
and in parallel rightlstm 2: 30 neurons, ”go backwards”; concatenate: leftlstm 2 
and rightlstm 2; dropout 0.5; dense: 10 neurons, activ function = ”tanh”; 
dropout 0.5; output layer - dense: 2 neurons, activ function = ’softmax’. 

model 3 . the architectur of thi neural network have be adapt from the work [10]. net- 
work topology: cnn: 30 neurons, window size = 3, activ function = relu. the 
input be pad so that the output have the same length a the origin input (futher 
denot a pad = ”same”); maxpool layer: window = 2; cnn: 30 neurons, 
window size = 3, activ function = relu, pad = “same’; maxpool layer: 
window = 2; cnn: 30 neurons, window size = 3, activ function = relu, pad = 
’same’;maxpool layer: window = 2; leftlstm: 30 neuron and in parallel rightl- 
stm: 30 neurons, ”go backwards”; concatenate: leftlstm and rightlstm; dropout 
0.5, dense: 5 neurons, activ function = ’tanh’; dropout 0.5; output layer - 
dense: 2 neurons, activ function = ’softmax’. 

network train be perform with earli stop (if the error on the valid set grow 
dure 15 epochs, then stop). after train the weight from the best model be loaded. We 
use the rmsprop algorithm [11] and learn rate of 0.001. 

4 experi 

evalu of F1 score (f1 mean) and mean deviat (f1 std) be obtained. In case of 
convent machin learn alghoritm all the train data have be use to fit models. 
F1 std be calcul on base of 10 differ cycl of train and test of singl configu- 
ration. the train dataset be split 5 time into 80% to train and 20% to validate. the 
F1 mean and the F1 std be calcul on the base of these split data sets. the baselin be 
calcul accord to the size of classes, and be f1-score=0.59 for the original, unbalanc 
test dataset and f1-score=0.5 for the balanc test dataset. result obtain with train 
on ’a’ and ’b’ GI subset be of especi interest, in spite of their low accuracy. By exclud- 
ing the ’c’ subset we balanc the train set by the number of actual-gend sampl and 
opposite-gender-mimick samples. the reason be that, when actual-gend sampl (’a’ and 

5 

deep learn neuronet model versu tradit machin learn . . . sboev et al. 

# train dataset model featur F1 F1 std delta 
(bl 
0.59) 

1 rusper; GI a,b,c model 2 grm-1 0.73 0.04 0.14 
2 rusper; GI a,b,c model 3 grm-1 0.76 0.07 0.17 
3 rusper; GI a,b model 2 grm-1 0.65 0.1 0.06 
4 GI cs; GI a,b,c svm char 0.74 0.04 0.15 
5 GI cs; GI A GB grm-2 0.76 0.19 0.17 
6 rusper model 3 grm-1 0.78 0.04 0.19 
7 GI c a GB tf-idf 0.74 0.03 0.15 
16 GI cs; rusper; re- 

views; Tw split; LJ split; 
FB split 

model 1 seq. feat 0.86 0.03 0.27 

17 rusper; reviews; 
Tw split; LJ split; 
FB split 

model 1 seq. feat 0.82 0.03 0.23 

18 GI c model 1 seq. feat 0.85 0.03 0.26 
19 Tw split, LJ split, 

FB split 
model 1 seq. feat 0.81 0.03 0.22 

20 GI cs; rusper; review model 1 seq. feat 0.87 0.03 0.28 
21 rusper; review model 1 seq. feat 0.79 0.02 0.2 
22 GI c a b model 1 seq. feat 0.84 0.03 0.25 

tabl 5: result of experi on imbalanc datasets. 

’c’ subsets) domin over opposite-gender-mimick sampl (’b’ subset), the network learn 
the straightforward gender-ind morpholog featur (like genu in russian). and, vice 
versa, if gender-decept sampl domin over actual-gend ones, the network still reli on 
the straightforward morpholog features, just revert them. so, by balanc the train 
set by the number of actual-gend and gender-decept samples, we aim to make the network 
ignor the straightforward gender-ind featur and infer the deeper, non-trivi ones. 

5 result 

tabl 5, 6 demonstr the F1 score of achiev models, train on differ set of imbalanc 
and balanc train dataset respectively. the model 1 give the best result of 88% ± 3%, 
that be about 30% more than the bl. the best model base on the convent gradient 
boost algorithm give the result of 70% ± 7%, which be 20% abov bl. the effici of 
svm model learn directli depend on the train set size be show in fig 1. the gain in 
F1 while the set size variat from 10% to 100% be about 12%. 

6 conclus 

the present approach base on deep neural network with cnn layer prove to be well- 
found for solv the problem of identifi the gender of a text author. In our previou 
works, a neural network be present on the basi of a combin of cnn and lstm [12], 

6 



alexand sboev et al. / procedia comput scienc 123 (2018) 424–431 429deep learn neuronet model versu tradit machin learn . . . sboev et al. 

neurons, window = 2, activ function = relu; globalmaxpooling; dropout 0.5; 
fully-connect mlp layer: 128 neurons, activ function = relu; dropout 0.5; 
output layer - mlp: activ function = softmax. 

model 2 . the concept of stack bidirect lstm neural network architectur be in- 
spire by [9], who show the possibl of use such an architectur for charact 
prediction, machin translat and imag classif tasks. the peculiar of thi 
network worth note be that the first branch on lstm return sequenc that be 
further concatenated. It consist of the follow layers: cnn: 30 neurons, window 
size = 3, activ function = relu. the input be pad so that the output have the 
same length a the origin input (futher denot a pad = ’same’); maxpool 
layer: window = 2; cnn: 30 neurons, window size = 3, activ function = relu, 
pad = ’same’; maxpool layer: window = 2; cnn: 30 neurons, window size 
= 3, activ function = relu, pad = ’same’; maxpool layer: window = 2; 
leftlstm: 30 neurons, and the last output in the full sequenc be return (further de- 
note by ’return sequence’) and in parallel rightlstm: 30 neurons, the input sequenc 
be process backward and the revers full sequenc be return (further denot a 
’go backwards’); concatenate: leftlstm and rightlstm; leftlstm 2: 30 neuron 
and in parallel rightlstm 2: 30 neurons, ”go backwards”; concatenate: leftlstm 2 
and rightlstm 2; dropout 0.5; dense: 10 neurons, activ function = ”tanh”; 
dropout 0.5; output layer - dense: 2 neurons, activ function = ’softmax’. 

model 3 . the architectur of thi neural network have be adapt from the work [10]. net- 
work topology: cnn: 30 neurons, window size = 3, activ function = relu. the 
input be pad so that the output have the same length a the origin input (futher 
denot a pad = ”same”); maxpool layer: window = 2; cnn: 30 neurons, 
window size = 3, activ function = relu, pad = “same’; maxpool layer: 
window = 2; cnn: 30 neurons, window size = 3, activ function = relu, pad = 
’same’;maxpool layer: window = 2; leftlstm: 30 neuron and in parallel rightl- 
stm: 30 neurons, ”go backwards”; concatenate: leftlstm and rightlstm; dropout 
0.5, dense: 5 neurons, activ function = ’tanh’; dropout 0.5; output layer - 
dense: 2 neurons, activ function = ’softmax’. 

network train be perform with earli stop (if the error on the valid set grow 
dure 15 epochs, then stop). after train the weight from the best model be loaded. We 
use the rmsprop algorithm [11] and learn rate of 0.001. 

4 experi 

evalu of F1 score (f1 mean) and mean deviat (f1 std) be obtained. In case of 
convent machin learn alghoritm all the train data have be use to fit models. 
F1 std be calcul on base of 10 differ cycl of train and test of singl configu- 
ration. the train dataset be split 5 time into 80% to train and 20% to validate. the 
F1 mean and the F1 std be calcul on the base of these split data sets. the baselin be 
calcul accord to the size of classes, and be f1-score=0.59 for the original, unbalanc 
test dataset and f1-score=0.5 for the balanc test dataset. result obtain with train 
on ’a’ and ’b’ GI subset be of especi interest, in spite of their low accuracy. By exclud- 
ing the ’c’ subset we balanc the train set by the number of actual-gend sampl and 
opposite-gender-mimick samples. the reason be that, when actual-gend sampl (’a’ and 

5 

deep learn neuronet model versu tradit machin learn . . . sboev et al. 

# train dataset model featur F1 F1 std delta 
(bl 
0.59) 

1 rusper; GI a,b,c model 2 grm-1 0.73 0.04 0.14 
2 rusper; GI a,b,c model 3 grm-1 0.76 0.07 0.17 
3 rusper; GI a,b model 2 grm-1 0.65 0.1 0.06 
4 GI cs; GI a,b,c svm char 0.74 0.04 0.15 
5 GI cs; GI A GB grm-2 0.76 0.19 0.17 
6 rusper model 3 grm-1 0.78 0.04 0.19 
7 GI c a GB tf-idf 0.74 0.03 0.15 
16 GI cs; rusper; re- 

views; Tw split; LJ split; 
FB split 

model 1 seq. feat 0.86 0.03 0.27 

17 rusper; reviews; 
Tw split; LJ split; 
FB split 

model 1 seq. feat 0.82 0.03 0.23 

18 GI c model 1 seq. feat 0.85 0.03 0.26 
19 Tw split, LJ split, 

FB split 
model 1 seq. feat 0.81 0.03 0.22 

20 GI cs; rusper; review model 1 seq. feat 0.87 0.03 0.28 
21 rusper; review model 1 seq. feat 0.79 0.02 0.2 
22 GI c a b model 1 seq. feat 0.84 0.03 0.25 

tabl 5: result of experi on imbalanc datasets. 

’c’ subsets) domin over opposite-gender-mimick sampl (’b’ subset), the network learn 
the straightforward gender-ind morpholog featur (like genu in russian). and, vice 
versa, if gender-decept sampl domin over actual-gend ones, the network still reli on 
the straightforward morpholog features, just revert them. so, by balanc the train 
set by the number of actual-gend and gender-decept samples, we aim to make the network 
ignor the straightforward gender-ind featur and infer the deeper, non-trivi ones. 

5 result 

tabl 5, 6 demonstr the F1 score of achiev models, train on differ set of imbalanc 
and balanc train dataset respectively. the model 1 give the best result of 88% ± 3%, 
that be about 30% more than the bl. the best model base on the convent gradient 
boost algorithm give the result of 70% ± 7%, which be 20% abov bl. the effici of 
svm model learn directli depend on the train set size be show in fig 1. the gain in 
F1 while the set size variat from 10% to 100% be about 12%. 

6 conclus 

the present approach base on deep neural network with cnn layer prove to be well- 
found for solv the problem of identifi the gender of a text author. In our previou 
works, a neural network be present on the basi of a combin of cnn and lstm [12], 

6 



430 alexand sboev et al. / procedia comput scienc 123 (2018) 424–431deep learn neuronet model versu tradit machin learn . . . sboev et al. 

# train dataset model featur F1 F1 std delta 
(bl 0.5) 

1 GI c a b GB tf-idf 0.65 0.03 0.06 
2 GI c a GB tf-idf 0.78 0.02 0.19 
3 GI c a svm tf-idf 0.73 0.02 0.14 
4 GI cs; rusper; re- 

views; Tw split; LJ split; 
FB split. 

model 1 seq. feat 0.88 0.03 0.38 

5 rusper; reviews; 
Tw split; LJ split; 
FB split; 

model 1 seq. feat 0.84 0.02 0.34 

6 GI c model 1 seq. feat 0.87 0.03 0.37 
7 Tw split; LJ split; 

FB split; 
model 1 featur 0.82 0.02 0.32 

8 tw; lj; FB model 1 seq. feat 0.77 0.04 0.27 
9 GI cs; rusper; review model 1 seq. feat 0.88 0.03 0.38 
10 rusper; review model 1 seq. feat 0.79 0.03 0.29 
11 GI c a b model 1 seq. feat 0.86 0.03 0.36 
12 GI c a GB tf-idf 0.79 0.02 0.29 

tabl 6: result of experi on balanc datasets. 

0.45 

0.5 

0.55 

0.6 

0.65 

0.7 

0.75 

0.8 

0.2 0.4 0.6 0.8 1 

F 
1- 
sc 
or 
e 

train dataset size, % 

svm 
baselin 

figur 1: depend of estim of svm from the size of train set. 

in which the achiev f1-score of 86% and the increas in comparison with bl of 23% correspond 
to the result obtain in thi work. so, our result show that the state of the art in gender 
identif task with the rusprof corpu be about 88% with the superior of deep learn 
model (convolut neural network - model 1). anoth consequ of the work be that the 
use of the collect corpu GI c allow to increas the accuraci of the task of identifi gender 
of non-decept russian texts. thi be prove by train on the crowdsours corpu with 
test on the GI corpus. so, thi allow to exploit the same approach for text with gender 
decepton in the future. 

7 

deep learn neuronet model versu tradit machin learn . . . sboev et al. 

acknowledg 

thi research be support by the russian scienc foundation, project No 16-18-10050. thi 
work have be carri out use comput resourc of the feder collect usag center 
complex for simul and data process for mega-sci facil at nrc ’kurchatov 
institute’, http://ckp.nrcki.ru/ 

refer 

[1] francisco rangel, paolo rosso, martin potthast, and benno stein. overview of the 5th author 
profil task at pan 2017: gender and languag varieti identif in twitter. work note 
paper of the clef, 2017. 

[2] angelo basile, gareth dwyer, maria medvedeva, josin rawee, hessel haagsma, and malvina 
nissim. n-gram: new groningen author-profil model. arxiv preprint arxiv:1707.03764, 2017. 

[3] matej martinc, iza škrjanec, katja zupan, and senja pollak. pan 2017: author profiling-gend 
and languag varieti prediction. cappellato et al.[13], 2017. 

[4] yasuhid miura, tomoki taniguchi, motoki taniguchi, and tomoko ohkuma. author profil 
with word+ charact neural attent network. cappellato et al.[13]. 

[5] tatiana litvinova, pavel seredin, olga litvinova, and olga zagorovskaya. differ in type– 
token ratio and part-of-speech frequenc in male and femal russian write texts. In proceed 
of the workshop on stylist variation, page 69–73, 2017. 

[6] tatiana litvinova, olga litvinlova, olga zagorovskaya, pavel seredin, aleksandr sboev, and olga 
romanchenko. ”ruspersonality”: A russian corpu for authorship profil and decept detection. 
In intelligence, social media and web (ismw fruct), 2016 intern fruct confer 
on, page 1–7. ieee, 2016. 

[7] rusprofil lab. rusprofil corpu of russian texts. [online], 2017. http://rusprofilinglab. 
ru/rusprofiling-at-pan/corpus/. 

[8] andrey kutuzov and elizaveta kuzmenko. build web-interfac for vector semant model 
with the webvector toolkit. eacl 2017, page 99, 2017. 

[9] nal kalchbrenner, ivo danihelka, and alex graves. grid long short-term memory. arxiv preprint 
arxiv:1507.01526, 2015. 

[10] eliyahu kiperwass and yoav goldberg. simpl and accur depend pars use bidirec- 
tional lstm featur representations. arxiv preprint arxiv:1603.04351, 2016. 

[11] lin wu, chunhua shen, and anton van den hengel. personnet: person re-identif with deep 
convolut neural networks. arxiv preprint arxiv:1601.07255, 2016. 

[12] aleksandr sboev, tatiana litvinova, irina voronina, dmitri gudovskikh, and roman rybka. 
deep learn network model to categor text accord to author’ gender and to identifi text 
sentiment. In comput scienc and comput intellig (csci), 2016 intern 
confer on, page 1101–1106. ieee, 2016. 

8 



alexand sboev et al. / procedia comput scienc 123 (2018) 424–431 431deep learn neuronet model versu tradit machin learn . . . sboev et al. 

# train dataset model featur F1 F1 std delta 
(bl 0.5) 

1 GI c a b GB tf-idf 0.65 0.03 0.06 
2 GI c a GB tf-idf 0.78 0.02 0.19 
3 GI c a svm tf-idf 0.73 0.02 0.14 
4 GI cs; rusper; re- 

views; Tw split; LJ split; 
FB split. 

model 1 seq. feat 0.88 0.03 0.38 

5 rusper; reviews; 
Tw split; LJ split; 
FB split; 

model 1 seq. feat 0.84 0.02 0.34 

6 GI c model 1 seq. feat 0.87 0.03 0.37 
7 Tw split; LJ split; 

FB split; 
model 1 featur 0.82 0.02 0.32 

8 tw; lj; FB model 1 seq. feat 0.77 0.04 0.27 
9 GI cs; rusper; review model 1 seq. feat 0.88 0.03 0.38 
10 rusper; review model 1 seq. feat 0.79 0.03 0.29 
11 GI c a b model 1 seq. feat 0.86 0.03 0.36 
12 GI c a GB tf-idf 0.79 0.02 0.29 

tabl 6: result of experi on balanc datasets. 

0.45 

0.5 

0.55 

0.6 

0.65 

0.7 

0.75 

0.8 

0.2 0.4 0.6 0.8 1 

F 
1- 
sc 
or 
e 

train dataset size, % 

svm 
baselin 

figur 1: depend of estim of svm from the size of train set. 

in which the achiev f1-score of 86% and the increas in comparison with bl of 23% correspond 
to the result obtain in thi work. so, our result show that the state of the art in gender 
identif task with the rusprof corpu be about 88% with the superior of deep learn 
model (convolut neural network - model 1). anoth consequ of the work be that the 
use of the collect corpu GI c allow to increas the accuraci of the task of identifi gender 
of non-decept russian texts. thi be prove by train on the crowdsours corpu with 
test on the GI corpus. so, thi allow to exploit the same approach for text with gender 
decepton in the future. 

7 

deep learn neuronet model versu tradit machin learn . . . sboev et al. 

acknowledg 

thi research be support by the russian scienc foundation, project No 16-18-10050. thi 
work have be carri out use comput resourc of the feder collect usag center 
complex for simul and data process for mega-sci facil at nrc ’kurchatov 
institute’, http://ckp.nrcki.ru/ 

refer 

[1] francisco rangel, paolo rosso, martin potthast, and benno stein. overview of the 5th author 
profil task at pan 2017: gender and languag varieti identif in twitter. work note 
paper of the clef, 2017. 

[2] angelo basile, gareth dwyer, maria medvedeva, josin rawee, hessel haagsma, and malvina 
nissim. n-gram: new groningen author-profil model. arxiv preprint arxiv:1707.03764, 2017. 

[3] matej martinc, iza škrjanec, katja zupan, and senja pollak. pan 2017: author profiling-gend 
and languag varieti prediction. cappellato et al.[13], 2017. 

[4] yasuhid miura, tomoki taniguchi, motoki taniguchi, and tomoko ohkuma. author profil 
with word+ charact neural attent network. cappellato et al.[13]. 

[5] tatiana litvinova, pavel seredin, olga litvinova, and olga zagorovskaya. differ in type– 
token ratio and part-of-speech frequenc in male and femal russian write texts. In proceed 
of the workshop on stylist variation, page 69–73, 2017. 

[6] tatiana litvinova, olga litvinlova, olga zagorovskaya, pavel seredin, aleksandr sboev, and olga 
romanchenko. ”ruspersonality”: A russian corpu for authorship profil and decept detection. 
In intelligence, social media and web (ismw fruct), 2016 intern fruct confer 
on, page 1–7. ieee, 2016. 

[7] rusprofil lab. rusprofil corpu of russian texts. [online], 2017. http://rusprofilinglab. 
ru/rusprofiling-at-pan/corpus/. 

[8] andrey kutuzov and elizaveta kuzmenko. build web-interfac for vector semant model 
with the webvector toolkit. eacl 2017, page 99, 2017. 

[9] nal kalchbrenner, ivo danihelka, and alex graves. grid long short-term memory. arxiv preprint 
arxiv:1507.01526, 2015. 

[10] eliyahu kiperwass and yoav goldberg. simpl and accur depend pars use bidirec- 
tional lstm featur representations. arxiv preprint arxiv:1603.04351, 2016. 

[11] lin wu, chunhua shen, and anton van den hengel. personnet: person re-identif with deep 
convolut neural networks. arxiv preprint arxiv:1601.07255, 2016. 

[12] aleksandr sboev, tatiana litvinova, irina voronina, dmitri gudovskikh, and roman rybka. 
deep learn network model to categor text accord to author’ gender and to identifi text 
sentiment. In comput scienc and comput intellig (csci), 2016 intern 
confer on, page 1101–1106. ieee, 2016. 

8 


