




















































adapt machin learn for credit card fraud detect 


université libr de bruxel 
comput scienc depart 

machin learn group 

adapt machin learn for 
credit card fraud detect 

A thesi submit in fulfil of the requir 
for the ph.d. degre in comput scienc 

author: 
andrea dal pozzolo 

supervisor: 
prof. gianluca bontempi 

decemb 2015 



declar of authorship 

I, andrea dal pozzolo, declar that thi thesi titl “adapt machin learn for 

credit card fraud detection” have be compos by myself and contain origin work 

of my own execution. some of the report work have be do in collabor with a 

number of co-author whose contribut be acknowledg in the relev sections. 

thi thesi have be write under the supervis of prof. gianluca bontempi. 

the member of the juri are: 

• prof. bart baesen (katholiek universiteit leuven, belgium) 

• prof. cesar alippi (politecnico di milano, italy) 

• prof. gianluca bontempi (université libr de bruxelles, belgium) 

• prof. tom lenaert (université libr de bruxelles, belgium) 

• prof. yve De smet (université libr de bruxelles, belgium) 

• dr. olivi caelen (worldlin s.a., belgium) 

ii 



“the cure for boredom be curiosity. there be no cure for curiosity.” 

dorothi parker 



université libr DE bruxel 

comput scienc depart 

machin learn group 

abstract 
adapt machin learn for 

credit card fraud detect 

by andrea dal pozzolo 

billion of dollar of loss be caus everi year by fraudul credit card transactions. 

the design of effici fraud detect algorithm be key for reduc these losses, and 

more and more algorithm reli on advanc machin learn techniqu to assist fraud 

investigators. the design of fraud detect algorithm be howev particularli challeng- 

ing due to the non-stationari distribut of the data, the highli unbalanc class 

distribut and the avail of few transact label by fraud investigators. At 

the same time public data be scarc avail for confidenti issues, leav unan- 

swere mani question about what be the best strategy. In thi thesi we aim to provid 

some answer by focu on crucial issu such as: i) whi and how undersampl be 

use in the presenc of class imbal (i.e. fraud be a small percentag of the trans- 

actions), ii) how to deal with unbalanc and evolv data stream (non-stationar 

due to fraud evolut and chang of spend behavior), iii) how to ass perform 

in a way which be relev for detect and iv) how to use feedback provid by in- 

vestig on the fraud alert generated. finally, we design and ass a prototyp of a 

fraud detect system abl to meet real-world work condit and that be abl to 

integr investigators’ feedback to gener accur alerts. 



université libr DE bruxel 

département d’informatiqu 

machin learn group 

résumé 
adapt machin learn for 

credit card fraud detect 

par andrea dal pozzolo 

de milliard de dollar de pert sont réalisé chaqu anné en raison de transact 

frauduleus sur le cart de crédit. La clé pour réduir ce pert est le développe- 

ment d’algorithm de détection de fraud efficaces. De plu en plu d’algorithm se 

basent sur de techniqu de machin learn avancé pour assist le détecteur de 

fraude. La concept d’algorithm de détection de la fraud est toutefoi particulière- 

ment difficil en raison de la distribut non-stationnair de données, de la distribut 

tré déséquilibré de class et la disponibilité de seulement quelqu transact cata- 

logué par le détecteur de fraude. dan le même temps, de donné publiqu ne sont 

guèr dispon pour de raison de confidentialité, laissant de nombreus question 

san répons à propo de ce qui est la meilleur stratégi pour traiter avec eux. dan 

cett thèse, nou proposon quelqu répons en se concentr sur de question cru- 

cial tell que: i) pourquoi et comment undersampl est util en présenc de class 

déséquilibré (c-à-d le fraud sont un petit pourcentag de transactions), ii) com- 

ment traiter l’évolut du flux de donné non-balancé (non-stationnair en raison de 

l’évolut et le changement de comport de dépens fraude), iii) le évaluat de 

la perform qui sont pertinent pour la détection et iv) l’utilis de évaluat 

fourni par le détecteur sur le alert de fraud générées. enfin, nou concevon un 

systèm de détection de la fraud en mesur de satisfair le condit de travail dan 

le mond réel et qui est capabl d’intégrer le détecteur avec rétroaction pour générer 

de alert de fraud précises. 



acknowledg 

foremost, I would like to express my deep and sincer gratitud to my supervisor prof. 

gianluca bontempi for hi inspiration, patienc and encouragement. He introduc me 

to the field of machin learn and provid lot of good idea and advice. I would 

have never complet thi thesi without hi help. besid gianluca, I be deepli grate 

to dr. olivi caelen for hi suggest and guidanc throughout my phd study. hi 

great idea and unfail support be essenti to finish thi thesis. 

I would like to thank also prof. giacomo boracchi and prof. cesar alippi for their 

supervis and fruit discuss on the problem of learn in non-stationari envi- 

ronment dure my research visit at politecnico di milano. A great thank also to 

prof. nitesh V. chawla and dr. reid A. johnson for share their preciou knowledg 

and expertis on the topic of unbalanc classif dure my research visit at notr 

dame university. My sincer thank also go to the phd committe member and the 

examin of thi thesi for the insight comment and hard question throughout my 

phd study. 

A well-known quot say that behind everi great man there’ a great woman. while 

i’m not a great man, there’ a great woman behind me and her name be katia. all my 

achiev also depend on her, so thank you my love for have alway support me 

dure these four years. 

If I be abl to arriv to the phd studi it be becaus I have two great parents, francesco 

and francesca, that alway believ in what I be doing. I wish to convey special thank 

to my famili for their endless support and understanding. 

last but not least, I would like to thank my friend (from itali and belgium) and 

colleagu both from the comput scienc depart of ulb and worldlin s.a. 

(former and current) for their continu encourag in these 4 years. A big thank 

also to serg waterschoot (fraud risk manag at worldlin s.a.) that make possibl 

thi phd and innoviris1 (brussel region) that fund the doctiri project. 

1innoviri be the brussel institut for the encourag of scientif research and innovation. 

vi 



content 

declar of authorship ii 

abstract iv 

résumé v 

acknowledg vi 

list of figur xi 

list of tabl xiii 

list of acronym xv 

I overview 1 

1 introduct 3 
1.1 the problem of fraud detect . . . . . . . . . . . . . . . . . . . . . . . 3 
1.2 the impact of fraud . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 
1.3 credit card fraud detect . . . . . . . . . . . . . . . . . . . . . . . . . 7 
1.4 challeng in data driven fraud detect system . . . . . . . . . . . . 8 
1.5 contribut . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9 

1.5.1 understand sampl method . . . . . . . . . . . . . . . . . . . 10 
1.5.2 learn from evolv and unbalanc data stream . . . . . . . . 11 
1.5.3 formal of a real-world fraud detect system . . . . . . . 11 
1.5.4 softwar and credit card fraud detect dataset . . . . . . . . . 12 

1.6 public and research activ . . . . . . . . . . . . . . . . . . . . . . 12 
1.7 financi support and project object . . . . . . . . . . . . . . . . . . . 14 
1.8 outlin . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14 
1.9 notat . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 

2 preliminari 17 
2.1 machin learn . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17 

2.1.1 formal of supervis learn . . . . . . . . . . . . . . . . . 18 
2.1.2 the problem of classif . . . . . . . . . . . . . . . . . . . . . 21 
2.1.3 bias-vari decomposit . . . . . . . . . . . . . . . . . . . . . . 23 

vii 



content viii 

2.1.4 evalu of a classif problem . . . . . . . . . . . . . . . . . 24 
2.2 credit card fraud detect . . . . . . . . . . . . . . . . . . . . . . . . . 27 

2.2.1 fraud detect system work condit . . . . . . . . . . . . . 27 
2.2.1.1 fd layers: . . . . . . . . . . . . . . . . . . . . . . . . . 28 
2.2.1.2 supervis inform . . . . . . . . . . . . . . . . . . . 29 
2.2.1.3 system updat . . . . . . . . . . . . . . . . . . . . . . . . 29 

2.2.2 featur augment . . . . . . . . . . . . . . . . . . . . . . . . . 30 
2.2.3 accuraci measur of a fraud detect system . . . . . . . . . . . 31 

3 state-of-the-art 35 
3.1 techniqu for unbalanc classif task . . . . . . . . . . . . . . . . 35 

3.1.1 data level method . . . . . . . . . . . . . . . . . . . . . . . . . . . 36 
3.1.2 algorithm level method . . . . . . . . . . . . . . . . . . . . . . . . 39 

3.2 learn with non-stationar . . . . . . . . . . . . . . . . . . . . . . . . 41 
3.2.1 sampl select bia . . . . . . . . . . . . . . . . . . . . . . . . . 42 
3.2.2 time evolv data . . . . . . . . . . . . . . . . . . . . . . . . . . . 44 

3.3 learn with evolv and unbalanc data stream . . . . . . . . . . . . 46 
3.4 algorithm solut for fraud detect . . . . . . . . . . . . . . . . . . 47 

3.4.1 supervis approach . . . . . . . . . . . . . . . . . . . . . . . . . 48 
3.4.2 unsupervis approach . . . . . . . . . . . . . . . . . . . . . . . 51 

II contribut 55 

4 techniqu for unbalanc classif task 57 
4.1 when be undersampl effect in unbalanc classif tasks? . . . . 58 

4.1.1 the warp effect of undersampl on the posterior probabl . 59 
4.1.2 warp and class separ . . . . . . . . . . . . . . . . . . . . 62 
4.1.3 the interact between warp and varianc of the estim . . 63 
4.1.4 experiment valid . . . . . . . . . . . . . . . . . . . . . . . . 67 
4.1.5 discuss . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72 

4.2 use calibr probabl with undersampl . . . . . . . . . . . . . . 73 
4.2.1 adjust posterior probabl to new prior . . . . . . . . . . . . 73 
4.2.2 warp correct and classif threshold adjust . . . . 76 
4.2.3 experiment result . . . . . . . . . . . . . . . . . . . . . . . . . . 77 
4.2.4 discuss . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80 

4.3 race for sampl method select . . . . . . . . . . . . . . . . . . . . 81 
4.3.1 race for strategi select . . . . . . . . . . . . . . . . . . . . . . 82 
4.3.2 experiment result . . . . . . . . . . . . . . . . . . . . . . . . . . 83 
4.3.3 discuss . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85 

4.4 conclus . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87 

5 learn from evolv data stream with skew distribut 89 
5.1 learn strategi in credit card fraud detect . . . . . . . . . . . . . . 91 

5.1.1 formal of the learn problem . . . . . . . . . . . . . . . . 91 
5.1.2 strategi for learn with unbalanc and evolv data stream 91 
5.1.3 experiment assess . . . . . . . . . . . . . . . . . . . . . . . . 95 
5.1.4 discuss . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105 



content ix 

5.2 use hddt to avoid instanc propag . . . . . . . . . . . . . . . . . 107 
5.2.1 helling distanc decis tree . . . . . . . . . . . . . . . . . . . 108 
5.2.2 helling distanc a weight ensembl strategi . . . . . . . . . . 109 
5.2.3 experiment assess . . . . . . . . . . . . . . . . . . . . . . . . 110 
5.2.4 discuss . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114 

5.3 conclus . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115 

6 A real-world fraud detect systems: concept drift adapt with 
alert-feedback interact 117 
6.1 realist work condit . . . . . . . . . . . . . . . . . . . . . . . . . . 118 
6.2 fraud detect with alert-feedback interact . . . . . . . . . . . . . . 119 
6.3 learn strategi . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120 

6.3.1 convent classif approach in fd . . . . . . . . . . . 121 
6.3.2 separ delay supervis sampl from feedback . . . . . . 121 
6.3.3 two specif fdss base on random forest . . . . . . . . . . . . . 123 

6.4 select bia and alert-feedback interact . . . . . . . . . . . . . . . . 124 
6.5 experi . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125 

6.5.1 separ feedback from delay supervis sampl . . . . . . . 127 
6.5.2 artifici dataset with concept drift . . . . . . . . . . . . . . . . . 128 
6.5.3 improv the perform of the feedback classifi . . . . . . . . 130 
6.5.4 standard accuraci measur and classifi ignor afi . . . . . . 132 
6.5.5 adapt aggreg . . . . . . . . . . . . . . . . . . . . . . . . . . 133 
6.5.6 final strategi select and classif model analysi . . . . . . 136 

6.6 discuss . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 138 
6.7 conclus . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141 

7 conclus and futur perspect 143 
7.1 summari of contribut . . . . . . . . . . . . . . . . . . . . . . . . . . . 143 
7.2 learn lesson . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144 
7.3 open issu . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 145 
7.4 the future: go toward big data solut . . . . . . . . . . . . . . . . 146 
7.5 ad valu for the compani . . . . . . . . . . . . . . . . . . . . . . . . . 149 
7.6 conclud remark . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149 

A the unbalanc packag 151 
a.1 method for unbalanc classif . . . . . . . . . . . . . . . . . . . . . 151 
a.2 race for strategi select . . . . . . . . . . . . . . . . . . . . . . . . . . 154 
a.3 summari . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 156 

B fd softwar modul 157 
b.1 model train . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 157 
b.2 score . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 158 
b.3 review . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 158 

C bia and varianc of an estim 159 



content x 

bibliographi 161 



list of figur 

1.1 the credit card fraud detect process. . . . . . . . . . . . . . . . . . . 5 
1.2 fraudul and genuin distribut in septemb 2013. . . . . . . . . . . 10 
1.3 partner of the doctiri project. . . . . . . . . . . . . . . . . . . . . . . . . 14 

2.1 the player of supervis learning. . . . . . . . . . . . . . . . . . . . . . . 19 
2.2 the receiv oper characterist (roc) curv . . . . . . . . . . . . 26 
2.3 the layer of a fraud detect system . . . . . . . . . . . . . . . . . . . 27 

3.1 resampl method for unbalanc classification. . . . . . . . . . . . . . 37 
3.2 differ type of concept drift. . . . . . . . . . . . . . . . . . . . . . . . 45 

4.1 how undersampl work . . . . . . . . . . . . . . . . . . . . . . . . . . . 59 
4.2 p and p at differ β . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61 
4.3 synthet dataset with differ class overlap. . . . . . . . . . . . . . . . . 62 
4.4 p a a function of β for two univari binari classif tasks. . . . . . 62 
4.5 p − p a a function of δ, where δ = ω+ − ω−. . . . . . . . . . . . . . . . . 63 
4.6 dpsdp a a function of p and β. . . . . . . . . . . . . . . . . . . . . . . . . . . 66 
4.7 term of inequ 4.20 for a classif task with non separ classes. 67 
4.8 term of inequ 4.20 for a classif task with separ classes. . . 67 
4.9 plot of dpsdp percentil and 

√ 
νs 
ν for the synthet dataset 1. . . . . . . . . 68 

4.10 region where undersampl should work in synthet dataset 1. . . . . . 69 
4.11 plot of dpsdp percentil and 

√ 
νs 
ν for the synthet dataset 2. . . . . . . . . 70 

4.12 differ between the kendal rank correl of p̂ and p̂ with p in uci 
datasets. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71 

4.13 ratio between the number of sampl satisfi condit (4.20) and all 
the instanc avail in each dataset averag over all the βs. . . . . . . 72 

4.14 learn framework for compar model with and without undersam- 
pling use cross valid (cv). . . . . . . . . . . . . . . . . . . . . . . 78 

4.15 boxplot of auc for differ valu of β in the credit-card dataset. . . . . 80 
4.16 boxplot of BS for differ valu of β in the credit-card dataset. . . . . . 80 
4.17 the race algorithm. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83 
4.18 comparison of strategi for unbalanc data with differ classifi over 

all dataset of tabl 4.3 in term of g-mean (the high the better). . . . 84 
4.19 comparison of strategi for unbalanc data with differ classifi on 

cam and ecoli dataset in term of g-mean (the high the better). . . . . 84 

5.1 the static approach. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 92 
5.2 the updat approach. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93 
5.3 the propag and forget approach. . . . . . . . . . . . . . . . . . . . . . 94 

xi 



list of figur xii 

5.4 weight α′j for variabl term_mcc. . . . . . . . . . . . . . . . . . . . . . 97 
5.5 comparison of static strategi use sum of rank in all batches. . . . . . 99 
5.6 comparison of updat strategi use sum of rank in all batches. . . . . 101 
5.7 comparison of forget strategi use sum of rank in all batches. . . . 103 
5.8 comparison of differ balanc techniqu and strategi use sum of 

rank in all batches. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104 
5.9 comparison of differ balanc techniqu and strategi in term of 

averag predict time (in seconds) over all batches. . . . . . . . . . . . . 105 
5.10 comparison of all strategi use sum of rank in all batches. . . . . . . . 106 
5.11 batch averag result in term of area under the roc curv (auc) 

(higher be better) use differ sampl strategi and batch-ensembl 
weight method with c4.5 and hddt over all uci datasets. . . . . . . 112 

5.12 batch averag result in term of comput time (lower be better) 
use differ sampl strategi and batch-ensembl weight method 
with c4.5 and hddt over all uci datasets. . . . . . . . . . . . . . . . . . 113 

5.13 batch averag result in term of comput auc (higher be better) 
use differ sampl strategi and batch-ensembl weight method 
with c4.5 and hddt over all drift moa datasets. . . . . . . . . . . . 113 

5.14 batch averag result in term of auc (higher be better) use differ 
sampl strategi and batch-ensembl weight method with c4.5 and 
hddt over the credit card dataset. . . . . . . . . . . . . . . . . . . . . . 114 

5.15 comparison of differ strategi use the sum of rank in all batch 
for the creditcard dataset in term of auc. . . . . . . . . . . . . . . . . . 114 

6.1 the supervis sampl available. . . . . . . . . . . . . . . . . . . . . . . . 120 
6.2 learn strategi for feedback and delay transact occur in 

the two day (M = 2) befor the feedback (δ = 7). . . . . . . . . . . . . . 122 
6.3 number of daili fraud for dataset in tabl 6.2. . . . . . . . . . . . . . . 126 
6.4 averag Pk per day for classifi on dataset 2013. . . . . . . . . . . . . . 128 
6.5 comparison of classif strategi use sum of rank in all batch 

and pair t-test base upon on the rank of each batch. . . . . . . . . . . 129 
6.6 averag Pk per day for classifi on dataset with artifici concept drift. 130 
6.7 A classifi Rt train on all recent transact occur between t and 

t− δ. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 132 
6.8 detect accuraci measur use differ perform measur on the 

2013 dataset. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 134 
6.9 feedback request by awt and it compon Ft and wdt . . . . . . . . 135 
6.10 posterior probabl pft(+|x) and pwdt (+|x) for differ days. . . . . . 137 
6.11 train set size and time to train a RF for the feedback and delay 

classifi in the 2013 dataset . . . . . . . . . . . . . . . . . . . . . . . . . 138 
6.12 averag featur import measur by the mean decreas in accuraci 

calcul with the gini index in the brf model of wdt in the 2013 
dataset. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 139 

b.1 softwar modul of the fd prototyp present in chapter 6. . . . . . . 157 



list of tabl 

1.1 probabl notat . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16 
1.2 learn theori notat . . . . . . . . . . . . . . . . . . . . . . . . . . . 16 
1.3 fraud detect notation. . . . . . . . . . . . . . . . . . . . . . . . . . . . 16 

2.1 confus matrix. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24 
2.2 confus matrix of a classifi with tpr=99% and tnr=99%. . . . . . 25 

4.1 rank correl between p̂ (p̂s) and p for differ valu of β in the 
classif task of figur 4.9. . . . . . . . . . . . . . . . . . . . . . . . . 69 

4.2 rank correl between p̂ (p̂s) and p for differ valu of β in the 
classif task of figur 4.11. . . . . . . . . . . . . . . . . . . . . . . . 70 

4.3 select dataset from the uci repositori [1] . . . . . . . . . . . . . . . . 71 
4.4 differ level of undersampl in a dataset with 1,000 posit in 10,000 

observations. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74 
4.5 sum of rank and p-valu of the pair t-test between the rank of p̂ and 

p̂′ and between p̂ and p̂ for differ metrics. . . . . . . . . . . . . . . . . 79 
4.6 comparison of CV and f-race result in term of g-mean for random 

forest (rf) classifier. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85 
4.7 comparison of CV and f-race result in term of g-mean for support 

vector machin (svm) classifier. . . . . . . . . . . . . . . . . . . . . . . . 86 

5.1 strength and weak of the differ learn approaches. . . . . . . . 95 
5.2 fraudul dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95 
5.3 dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112 

6.1 classifi use in the chapter. . . . . . . . . . . . . . . . . . . . . . . . . 123 
6.2 dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125 
6.3 averag Pk for the slide and ensembl strategi . . . . . . . . . . . . . 127 
6.4 dataset with artifici introduc CD . . . . . . . . . . . . . . . . . . . 129 
6.5 averag Pk in the month befor and after CD for the slide window . . . 129 
6.6 averag Pk in the month befor and after CD for the ensembl . . . . . . 130 
6.7 averag Pk for the slide and ensembl approach when δ = 15. . . . . . . 131 
6.8 averag Pk of Ft with method for ssb correction. . . . . . . . . . . . . . 131 
6.9 averag Pk for the slide approach with more than 100 feedback per day. 132 
6.10 averag ap, auc and Pk for the slide approach . . . . . . . . . . . . . 133 
6.11 averag Pk of awt with adapt αt . . . . . . . . . . . . . . . . . . . . . . 136 

xiii 





list of acronym 

afi alert-feedback interact . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29 

AP averag precis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32 

auc area under the roc curv . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xii 

ber balanc error rate . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25 

brf balanc random forest. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .123 

CD concept drift. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .44 

cnn condens nearest neighbor . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38 

CV cross valid . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xi 

edr expert driven rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27 

ddm data driven model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .8 

enn edit nearest neighbor . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39 

FD fraud detect . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14 

fd fraud detect system . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 

FN fals neg . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8 

fnr fals neg rate . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25 

FP fals posit . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8 

fpr fals posit rate . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25 

HD helling distanc . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39 

hddt helling distanc decis tree . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11 

xv 



list of tabl xvi 

IG inform gain . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39 

iid independ and ident distribut . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18 

LB logit boost . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77 

ML machin learn . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 

mme mean misclassif error . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24 

nnet neural network . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83 

ncl neighborhood clean rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39 

oss one side selection. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .38 

knn k-nearest neighbor. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .39 

RF random forest. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .xiii 

roc receiv oper characterist . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xi 

ssb sampl select bia . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .41 

svm support vector machin . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xiii 

tnr true neg rate . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25 

TP true posit . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119 

tpr true posit rate . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25 



To my futur wife katia 

xvii 





part I 

overview 

1 





chapter 1 

introduct 

1.1 the problem of fraud detect 

fraud be a old a human itself and can take an unlimit varieti of differ forms. 

moreover, the develop of new technolog provid addit way in which crim- 

inal may commit fraud [2], for instanc in e-commerc the inform about the card 

be suffici to perpetr a fraud. the use of credit card be preval in modern day 

societi and credit card fraud have kept on grow in recent years. financi loss due 

to fraud affect not onli merchant and bank (e.g. reimbursements), but also individu 

clients. If the bank lose money, custom eventu pay a well through high interest 

rates, high membership fees, etc. fraud may also affect the reput and imag of a 

merchant caus non-financi loss that, though difficult to quantifi in the short term, 

may becom visibl in the long period. for example, if a cardhold be victim of fraud 

with a certain company, he may no longer trust their busi and choos a competitor. 

the action take against fraud can be divid into fraud prevention, which attempt 

to block fraudul transact at source, and fraud detection, where success fraud 

transact be identifi a posteriori. technolog that have be use in order to 

prevent fraud be address verif system (avs), card verif method (cvm) 

and person identif number (pin). av involv verif of the address with 

zip code of the custom while cvm and pin involv check of the numer code that 

be key in by the customer. for prevent purposes, financi institut challeng all 

transact with rule base filter and data mine method a neural network [3]. 

fraud detect is, give a set of credit card transactions, the process of identifi if 

a new author transact belong to the class of fraudul or genuin transact 

[4]. A fraud detect system (fds) should not onli detect fraud case efficiently, 

3 



chapter 1. introduct 4 

but also be cost-effect in the sens that the cost invest in transact screen 

should not be high than the loss due to fraud [5]. bhatla [6] show that screen 

onli 2% of transact can result in reduc fraud loss account for 1% of the total 

valu of transactions. however, a review of 30% of transact could reduc the fraud 

loss drastic to 0.06%, but increas the cost exorbitantly. In order to minim 

cost of detect it be import to use expert rule and statist base model (e.g. 

machin learning) to make a first screen between genuin and potenti fraud and ask 

the investig to review onli the case with high risk. 

typically, transact be first filter by check some essenti condit (e.g. suf- 

ficient balance) and then score by a predict model (see figur 1.1). the predict 

model score each transact with high or low risk of fraud and those with high risk 

gener alerts. investig check these alert and provid a feedback for each alert, 

i.e. true posit (fraud) or fals posit (genuine). these feedback can then be use 

to improv the model. A predict model can be built upon experts’ rules, i.e. rule 

base on knowledg from fraud experts, but these requir manual tune and human 

supervision. alternatively, with machin learn (ml) techniqu [7] we can effici 

discov fraudul pattern and predict transact that be most like to be fraud- 

ulent. ML techniqu consist in infer a predict model on the basi of a set of 

examples. the model be in most case a parametr function, which allow predict the 

likelihood of a transact to be fraud, give a set of featur describ the transaction. 

In the domain of fraud detection, the use of learn techniqu be attract for a num- 

ber of reasons. first, they allow to discoveri pattern in high dimension data streams, 

i.e. transact arriv a a continu stream and each transact be defin by mani 

variables. second, fraudul transact be often correl both over time and space. 

for examples, fraudster typic tri to commit fraud in the same shop with differ 

card within a short time period. third, learn techniqu can be use to detect and 

model exist fraudul strategi a well a identifi new strategi associ to un- 

usual behavior of the cardholders. predict model base on ML techniqu be also 

abl to automat integr investigators’ feedback to improv the accuraci of the 

detection, while in the case of expert system, includ investig feedback requir 

rule revis that can be tediou and time consuming. 

when a fraud cannot be prevented, it be desir to detect it a rapidli a possible. In 

both cases, prevent and detection, the problem be magnifi by a number of domain 

constraint and characteristics. first, care must be take not to prevent too mani 

legitim transact or incorrectli block genuin cards. custom irrit be to be 

avoided. second, most bank process vast number of transactions, of which onli a 

small fraction be fraudulent, often less than 0.1% [3]. third, onli a limit number of 

transact can be check by fraud investigators, i.e. we cannot ask a human person 



chapter 1. introduct 5 

predic;ve&model& 

rejected& 

terminal&check& 
correct'pin?'' 

sufficient'balance'?'' 
blocked'card?' 

feedback& 

inves;gators& 
fraud&score& 

figur 1.1: the credit card fraud detect process. credit card payment need 
to pa a first termin check and then if not reject be score by a predict model 
that rais alert for the most suspici transactions. investig provid feedback 
on the alert (transact label a fraud or genuine) that can be use to improv the 

accuraci of the predict model. 

to check all transact one by one if it be fraudul or not. In other word compani 

and public institut need automat system abl to support fraud detect [8]. 

credit card fraud may occur in variou way [9]: just to mention some, we can have 

steal card fraud, cardholder-not-pres fraud and applic fraud: 

• stolen card fraud be the most common type of fraud where the fraudster usual 
tri to spend a much a possibl and a quickli a possible. the detect of 

such a fraud typic reli on the discoveri of an unexpect usag pattern of 

the credit card (gener unexpectedli important) with respect to the common 

practice. 

• cardholder-not-pres fraud be often observ in e-business. here the fraudster 
need the inform about a credit card but not the card itself. thi fraud 

demand a prompt detect since, unlik the previou case, the offici card owner 

be not awar that hi own data have be stolen. 

• applic fraud correspond to the applic for a credit card with fals per- 
sonal information. thi kind of fraud occur more rare sinc it could be detect 

dure the applic by check the inform of the applier, contrari to other 

fraud that can not be anticipated. 



chapter 1. introduct 6 

the previou classif howev be not exhaustive, sinc fraud be continu evolv- 

ing. for a more gener discuss of differ fraud type we refer the reader to [10]. 

whenev a fraud method be detected, crimin adapt their strategi and tri others. 

At the same time, everyday there be new crimin take part in the game and tri 

new and old strategies. In thi set it be import to updat the detect tools, but 

keep old one a well [2]. exchang of idea for detect tool be difficult a fraud- 

ster could benefit from it by test their strategies. for the same reason dataset be 

typic not publicli avail to the research community. 

1.2 the impact of fraud 

with thi extens use of credit cards, fraud appear a a major issu in the credit card 

business. It be hard to have some figur on the impact of fraud, sinc compani and 

bank do not like to disclos the amount of loss due to frauds. anoth problem in 

credit-card fraud loss estim be that we can measur the loss of onli those fraud that 

have be detected, and it be not possibl to ass the size of unreported/undetect 

frauds. other fraud be report long after the crimin have complet the crime [11]. 

however, the associ for payment clear servic (apacs) have estim that 

total loss through credit card fraud in the unit kingdom have be grow rapidli 

from £122 million in 1997 to £440.3 million in 2010 [8]. accord to the nilson re- 

port [12], global credit, debit, and prepaid card fraud loss reach $11.27 billion 

in 2012 - Up 14.6% over 2011. gross fraud loss account for 5.22% total volume, 

up from 5.07% in 2011. In 2012, onli in the usa fraud loss reach $5.33 billion. 

accord to the lexi nexi [13], in 2014 fraudul card transact worldwid have 

reach around $11 billion a year, and the usa may account for about half of that. 

the european central bank (ecb) report [14] that, in 2012, e 1 in everi e 2’635 

spent on credit and debit card issu within sepa (the european union, iceland, 

liechtenstein, monaco, norway and switzerland) be lose to fraud. the total valu of 

fraud be estim reach e 1.33 billion in 2012, regist an increas of 14.8% 

compar with 2011. In particular 60% of these fraud come from card-not-pres 

(cnp) payment (i.e. payment via post, telephon or the internet), 23% from point-of- 

sale (pos) termin and 17% from atms. the introduct of emv secur standard 

(chip on cards) have reduc fraud share (0.048% in 2008 and 0.038% in 2012) on the 

total number of transactions.1 however, from 2011 to 2012, cnp fraud have increas 

by 21%, follow the grow of cnp payments, which rise by around 15% to 20% a 

year between 2008 and 2012, while all the other transact rise by 4%. the ecb report 
1with emv card the cardhold be ask to enter a pin. 



chapter 1. introduct 7 

show also that credit card be more affect by fraud than debit card, estim that 

for everi e 1000 we have e 1 of loss due to fraud in credit while e 1 for everi e 5’400 

in debit card. anoth interest fact be that cnp fraud be usual more frequent in 

matur card markets, wherea po fraud be more common in less develop markets. 

the 2015 cybersourc report [15] show that busi be reluct toward the adop- 

tion of 3-d secur method [16] (onlin authent base on a three-domain model: 

acquirer, issuer and interoperability), becaus it may caus poor custom experi 

and the risk of custom abandon their purchases. 

1.3 credit card fraud detect 

credit card fraud detect reli on the analysi of record transactions. transact 

data be mainli compos of a number of attribut (e.g. credit card identifier, transac- 

tion date, recipient, amount of the transaction). automat system be essenti sinc 

it be not alway possibl or easi for a human analyst to detect fraudul pattern in 

transact datasets, often character by a larg number of samples, mani dimen- 

sion and onlin updates. also, the cardhold be not reliabl in report the theft, loss 

or fraudul use of a card [17]. In the follow we will now discu advantag and 

disadvantag of expert driven and data driven approach to fraud detection. 

the expert driven approach us domain knowledg from fraud investig to defin 

rule that be use to predict the probabl of a new transact to be fraudulent. let u 

imagin that the investig know from experi that a transact do on a bet 

websit with an amount great than $10000 be almost certain to be fraudulent. then 

we can automat the detect by mean of a rule a “if transact amount > $10000 

& bet websit then fraud probabl = 0.99”. In the same spirit we can defin a 

set of rule for differ scenarios. typically, expert rule can be distinguish between 

score rule and block rules. the former assign a score to a transact base on the 

risk the investig associ to a certain pattern; the latter can block the transact 

becaus the risk of fraud be too high. the advantag of expert rule are: i) they be easi 

to develop and to understand, ii) they explain whi an alert be gener and iii) they 

exploit domain expert knowledge. however, they have a number of drawbacks: i) they be 

subject (if you ask 7 expert you may get 7 differ opinions), ii) they detect onli easi 

correl between variabl and fraud (it be hard for a human analyst to think in more 

the three dimens and explor all possibl pattern combinations), iii) they be abl to 

detect onli know fraudul strategies, iv) they requir human monitoring/supervis 

(updat in case of perform drop) and v) they can becom obsolet soon due to fraud 

evolution. 



chapter 1. introduct 8 

A differ way to automat the detect be by mean of data driven methods, i.e. 

set up a fd base on machin learn abl to learn from data in a supervis or 

unsupervis manner which pattern be the most probabl relat to a fraudul be- 

havior. with machin learn we let the comput to discov fraudul pattern in 

the data. data driven approach have also advantag and disadvantages, for instanc 

with machin learn algorithm we can: i) learn complex fraudul configur 

(use all featur available), ii) ingest larg volum of data, iii) model complex distribu- 

tions, iv) predict new type of fraud (anomali from genuin patterns) and v) adapt 

to chang distribut in the case of fraud evolution. however, they have also some 

drawbacks: i) they need enough samples, ii) some model be black box, i.e. they be 

not easili interpret by investig and they do not provid an understand of the 

reason whi an alert be generated. 

data driven and expert driven method usual work in parallel and their combin 

be often the best solution. typically, real-world fdss like the one of our project partner 

(worldlin s.a. from brussels, belgium) use data driven method to obtain precis 

alert (reduc fals posit (fp)), while expert driven one be mostli use to make 

sure that all the fraud be detect (reduc fals neg (fn)) at the cost of have 

few fals alerts.2 data driven solut should not be see a a tool to replac expert- 

base system, but rather a a support to obtain a more accur detection. A detail 

descript of how these two type of method work and how they be combin will be 

provid in section 2.2.1. 

thi thesi will concern automat data driven method base on machin learn 

techniques. the design of a fd base on data driven model (ddms) be not an 

easi task, it requir the practition to decid which featur to use, strategi (e.g. 

supervis or unsupervised), algorithm (e.g. decis trees, neural network, support 

vector machine), frequenc of updat of the model (onc a year, monthli or everi time 

new data be available), etc. We hope that, by the end of the thesis, the reader will have 

a good understand of how to design and implement an effect data driven fraud 

detect solution. 

1.4 challeng in data driven fraud detect system 

the design of a fdss employ ddm base on machin learn algorithm be par- 

ticularli challeng for the follow reasons: 
2from person commun with the project collabor it have emerg that expert driven 

method be more recal oriented, while data driven one be optim for precision, i.e. the first aim 
to reduc miss fraud and the second to reduc fals alerts. 



chapter 1. introduct 9 

1. fraud repres a small fraction of all the daili transact [18]. 

2. fraud distribut evolv over time becaus of season and new attack strate- 

gy [19]. 

3. the true natur (class) of the major of transact be typic know onli 

sever day after the transact take place, sinc onli few transact be time 

check by investig [20]. 

the first challeng be also know a the unbalanc problem [21], sinc the distribut 

of the transact be skew toward the genuin class. the distribut of genuin 

and fraud sampl be not onli unbalanced, but also overlap (see the plot over the 

first two princip compon in figur 1.2). most machin learn algorithm be 

not design to cope with a both unbalanc and overlap class distribut [22]. 

the chang in fraudul activ and costum behavior be the main respons of 

non-stationar in the stream of transactions. thi situat be typic refer to 

a concept drift [23] and be of extrem relev for fdss which have to be constantli 

updat either by exploit the most recent supervis sampl or by forget outdat 

inform that might be no more use wherea not misleading. fd strategi that 

be not updat or revisit frequent be often lose their predict accuraci in the 

long term [18]. 

the third challeng be relat to the fact that, in a real-world setting, it be imposs 

to check all transactions. the cost of human labour serious constrain the number of 

alerts, return by the fds, which can be valid by investigators. investig check 

fd alert by call the cardholders, and then provid the fd with feedback indic 

whether the alert be relat to fraudul or genuin transactions. these feedbacks, 

which refer to a tini fraction of the daili transact amount, be the onli real-tim 

inform that can be provid to train or updat classifiers. the class (fraudul / 

non-fraudulent) of the rest of transact be know onli sever day later. class can 

be automat assign when a certain time period have passed, e.g. by assum a 

certain reaction time for custom to discov and then report frauds. standard fdss 

ignor feedback from investig often provid less accur alert than fdss abl 

to use effici both feedback and the other supervis sampl avail [20]. 

1.5 contribut 

the contribut of the thesi address the challeng discuss in the previou section. 



chapter 1. introduct 10 

(a) 08/09/2013 (b) 09/09/2013 

(c) 10/09/2013 (d) 11/09/2013 

(e) 12/09/2013 (f) 13/09/2013 

figur 1.2: plot of genuin and fraudul transact between the 8th and 13th of 
septemb 2013 over the first two princip components. fraud repres a small part 
of all observ available. the distribut of fraud and genuin sampl be highli 

overlap and chang over the time. 

1.5.1 understand sampl method 

the first main contribut of thi thesi be the formal of sampl method 

adopt in unbalanc classif tasks. In particular we focu on undersampl 

which be a standard techniqu for balanc skew distributions. despit it popular 

in the machin learn community, there be no detail analysi about the impact of 

undersampl on the accuraci of the final classifier. chapter 4 reveal the condit un- 

der which undersampl will improv the rank of the posterior probabl return 

by a classifier. then we propos a method to calibr the posterior probabl of a clas- 

sifier appli after undersampling. however, there be no guarante that undersampl 



chapter 1. introduct 11 

be the best method to adopt for a give classifi and dataset, so we propos to use a 

race algorithm to adapt select the best unbalanc strategy. 

1.5.2 learn from evolv and unbalanc data stream 

the second main contribut be relat to the non-stationari natur of transact 

distribut in credit cards. the continu evolut in the way fraudster attempt 

and commit illeg activ requir a continu adapt of the learn algorithm 

use to detect frauds. At the same time the distribut be highli skew toward the 

genuin class, make standard techniqu for evolv data stream not suitable. In 

chapter 5 we investig multipl solut for unbalanc data stream with the goal of 

show in practic which strategi be the best to adopt for fraud detection. We show 

that retain histor transact be useful, but it be also import to forget outdat 

sampl for the model to be precise. also, propag of fraudul instanc along the 

stream be anoth effect techniqu to deal with such unbalanc data streams. when 

propag of old transact in the stream be not desir (e.g. for comput 

reason), we suggest to use an ensembl of helling distanc decis tree (hddt) a 

they show good perform than approach base on instanc propagations. 

1.5.3 formal of a real-world fraud detect system 

In chapter 6 we present a prototyp of a fd abl to meet real-world work condi- 

tions, which be the third main contribut of the thesis. most fdss monitor stream of 

credit card transact by mean of classifi return alert for the riskiest payments. 

fraud detect differ from convent classif task because, in a first phase, 

onli a small set of supervis sampl be provid by human investigators. label of the 

vast major of transact be make avail onli sever day later, when custom 

have possibl report unauthor transactions. the delay in obtain accur la- 

bel and the interact between alert and supervis inform have to be care 

take into consider when learn in a concept-drift environment. We show that 

investigator’ feedback and delay label have to be handl separ and requir 

differ classif strategies. finally, base on our results, we argu that the best 

detect solut consist in train two separ classifi (on feedback and delay 

labels, respectively), and then aggreg the outcomes. 



chapter 1. introduct 12 

1.5.4 softwar and credit card fraud detect dataset 

besid these main contributions, dure thi thesi we also develop a softwar packag 

call unbalanc [24] avail for the R languag [25]. thi packag be present in 

appendix A, it implement some of most well-known techniqu for unbalanc classi- 

ficat and propos a race algorithm [26] to select adapt the most appropri 

strategi for a give unbalanc task [27]. 

anoth contribut of thi thesi be the releas to the public of a dataset contain 

inform about credit card transact with exampl of fraudul samples. the 

dataset be first use in the experi of our paper [28] and then make avail 

at: http://www.ulb.ac.be/di/map/adalpozz/data/creditcard.rdata. It contain 31 

numer input variables. featur “time” denot the second elaps between each 

transact and the first transact in the dataset. the featur “amount” be the trans- 

action amount, which can be use for example-depend cost-sensit learning. featur 

“class” be the respons variabl and it take valu 1 in case of fraud and 0 otherwise. 

the dataset be highli unbalanced; fraud repres 0.172% of all transact (492 fraud 

out of 284807 transactions). for confidenti reason, the mean of most variabl be 

not reveal and the featur have be transform by mean of princip components. 

the cardhold identifi be also not avail so each transact can be consid in- 

depend from the others. thi be one of the rare dataset on fraud detect avail 

to the community. 

1.6 public and research activ 

the list of work publish dure thi thesi be summar below, by categori and 

chronolog order. 

peer review intern journal articl 

• andrea dal pozzolo, giacomo boracchi, olivi caelen, cesar alippi, and gi- 
anluca bontempi. credit card fraud detect with alert-feedback interaction. 

submit to ieee transact on neural network and learn systems. 

• andrea dal pozzolo, olivi caelen, yann-ael Le borgne, serg waterschoot, and 
gianluca bontempi. learn lesson in credit card fraud detect from a practi- 

tioner perspective. expert system with applications, 41(10):4915-4928, 2014. 

http://www.ulb.ac.be/di/map/adalpozz/data/creditcard.rdata 


chapter 1. introduct 13 

peer review intern confer paper 

• andrea dal pozzolo, olivi caelen, and gianluca bontempi. when be under- 
sampl effect in unbalanc classif tasks?. In european confer on 

machin learning. ecml-kdd, 2015. 

• andrea dal pozzolo, olivi caelen, reid A. johnson and gianluca bontempi. 
calibr probabl with undersampl for unbalanc classification. In sym- 

posium on comput intellig and data mine (cidm), ieee, 2015. 

• andrea dal pozzolo, giacomo boracchi, olivi caelen, cesar alippi, and gian- 
luca bontempi. credit card fraud detect and concept-drift adapt with 

delay supervis information. In neural network (ijcnn), the 2015 interna- 

tional joint confer on. ieee, 2015. 

• andrea dal pozzolo, reid A. johnson, olivi caelen, serg waterschoot, nitesh 
V chawla, and gianluca bontempi. use hddt to avoid instanc propag 

in unbalanc and evolv data streams. In neural network (ijcnn), the 2014 

intern joint confer on. ieee, 2014. 

• andrea dal pozzolo, olivi caelen, serg waterschoot, gianluca bontempi, rac- 
ing for unbalanc method selection. proceed of the 14th intern con- 

ferenc on intellig data engin and autom learn (ideal), ieee, 

2013 

peer review intern confer poster 

• andrea dal pozzolo, olivi caelen, and gianluca bontempi. comparison of bal- 
anc techniqu for unbalanc datasets. phd student forum of the intern 

confer on data mine (icdm), ieee, 2012. 

research visit and grant 

dure my phd i’v visit the follow research groups: 

• data, infer analytics, and learn (dial) lab at the univers of notr 
dame, indiana, usa in novemb 2013 and may 2014 (host by prof. nitesh V 

chawla) 



chapter 1. introduct 14 

• dipartimento di elettronica, informazion e bioingegneria (deib) at politecnico 
di milano, itali in novemb 2014 and from april to may 2015 (host by prof. 

giacomo boracchi) 

the first visit at dial lead to the confer paper at ijcnn 2014 [19] and the visit at 

deib to the paper at ijcnn 2015 [20]. At the begin of the phd studies, I take also 

part to the organ of the intern confer in data mine (icdm) 2012. 

In the last year of the phd I receiv two travel grants: i) ulb ccci travel grant for 

the second research visit at deib (e 1500) and ii) inn travel grant for the ijcnn 2015 

confer ($800). 

1.7 financi support and project object 

the work present in thi thesi be fund by the doctiri project titl “adapt 

real time machin learn for credit card fraud detection”, support by innoviri which 

be the brussel institut for the encourag of scientif research and innovation. the 

object of the 4 year project be to design, ass and valid a machin learn 

framework abl to calibr in an automatic, real-tim and adapt manner the fraud 

detect strategi of the industri partner. the academ partner be the machin learn- 

ing group, from the comput scienc depart of the université libr de bruxelles. 

the busi partner be worldlin s.a., which be a compani base in brussel and leader 

in e-pay services. 

figur 1.3: partner of the doctiri project “adapt real time machin learn for 
credit card fraud detection”. 

1.8 outlin 

the thesi be organ a follows: chapter 2 introduc the notion and tool that 

will be consid in the thesis. the chapter be divid in two main parts, the first 

(section 2.1) provid the reader preliminari knowledg about machin learn and 

the problem of classification. the second (section 2.2) be devot to the problem of 

fraud detect (fd) and describ the main layer of a fds. 



chapter 1. introduct 15 

chapter 3 review the differ approach which have be investig in the litera- 

ture to address the challeng introduc in section 1.4. each section present relev 

work that have be propos in the literatur for solv differ problem typic of 

fraud detection. section 3.1 be dedic to method for unbalanc classif task 

and section 3.2 present solut to the problem of learn in non-stationari environ- 

ments. section 3.3 review work on unbalanc data stream and section 3.4 introduc 

algorithm solut that have be propos for fraud detection. 

chapter 4, 5 and 6 repres the main contribut of the thesis. In chapter 4 we tackl 

the problem of learn in the presenc of unbalanc class distribut with a focu on 

undersampling, how it works, how it can improv the perform of a classifi and 

to choos the best strategi for a give dataset. then chapter 5 provid the reader 

with an experiment comparison of sever method for unbalanc data streams. the 

first part (section 5.1) investig which solut work best on a credit card data 

stream, while the second (section 5.2) illustr an algorithm for avoid propag 

of instanc along the stream. chapter 6 present a prototyp of a realist fds, where 

the interact between the classifi gener the alert and investig provid 

feedback be model and exploit to improv the detection. 

finally, chapter 7 provid a summari of the result present in the thesi and propos 

futur research directions. the remaind of the present chapter provid the notat 

that will be use throughout the follow chapters. 

1.9 notat 

throughout the thesis, random variabl be write with boldfac letter (y), their 

realiz be in normal font (y) and estim wear a hat (ŷ). p(y) denot the 
probabl distribut of the random variabl y. uppercas letter (y) be use for 

set and uppercas calligraph font (l) for learn algorithms. 



chapter 1. introduct 16 

tabl 1.1: probabl notat 

p(y) probabl that the discret random variabl y take the valu y, i.e., p(i = y) 
p(y) probabl mass distribut of the random variabl y 
p(y|x) the condit probabl that y = y know that x = x 
p(y|x) the condit distribut function of the target y know that x = x 
e[y] expect valu of y. 
V ar[y] varianc of y. 
h(y) entropi of y 
h(y|x) condit entropi of y give x 
i(y;x) mutual inform of y and x 
|x| the number of element of the set X 
ŷ statist estim of y 
p̂(y|x) estim of p(y|x) 

tabl 1.2: learn theori notat 

L learn algorithm 
y ∈ Y unidimension discret random variabl repres the output of L 
Y ⊂ R the domain of the random variabl y 
y a realiz of the random variabl y 
x ∈ X a multidimension discret random variabl repres the input of L 
X ⊂ Rn the domain of the random variabl x 
n dimens of the input space X 
x a realiz of x 
TN the train set, compos of N realiz (xi, yi), i ∈ {1, 2, ..., N} 
N number of sampl in the train set 
xi the ith realiz of the variabl x in TN 
Λ ⊂ Rd model paramet space. 
θ ∈ Λ model paramet vector. 
Λθ class of model with paramet θ. 
h(x, θ) ∈ Λθ predict model with input x and paramet θ. 
l(y, h(x, θ)) loss function. 
remp(θ) empir risk. 
GN gener error. 

tabl 1.3: fraud detect notation. 

k number of alert that investig be abl to valid everyday. 
At alert rais at day t, where |at| = k. 
pk(t) precis on at. 
dt−δ delay supervis coupl avail at day t and occur at t− δ. 
Ft feedback at t: recent supervis coupl avail at day t. 
Bt batch of transact avail at day t. 
δ number of day for which feedback be provided. 
M number of day for which delay sampl be provided. 



chapter 2 

preliminari 

machin learn play an import role in data driven fraud detect system, so 

in thi chapter we will first introduc the reader to the problem of learn from data 

befor move to the specif applic domain. In particular we will focu on the 

problem of learn with supervis data, a.k.a. supervis learning, where the learn 

algorithm be train on label examples. section 2.1 introduc the basic of learn 

from annot data that we will late build upon in futur chapters. section 2.2 be 

devot to the specif of the fraud detect application. 

2.1 machin learn 

machin learn play a key role in mani scientif disciplin and it applic be 

part of our daili life. It be use for exampl to filter spam email, for weather predic- 

tion, in medic diagnosis, product recommendation, face detection, fraud detection, etc. 

machin learn (ml) studi the problem of learning, which can be defin a the 

problem of acquir knowledg through experience. thi process typic involv ob- 

serv a phenomenon and construct a hypothesi on that phenomenon that will allow 

one to make predict or, more in general, to take ration actions. for computers, the 

experi or the phenomenon to learn be give by the data, henc we can defin ML a 

the process of extract knowledg from data [29]. 

machin learn be close relat to the field of statistics, pattern recognit and 

data mine [7]. At the same time, it emerg a a subfield of comput scienc and 

give special attent to the algorithm part of the knowledg extract process. In 

summary, the focu of ML be on algorithm that be abl to learn automat the 

pattern hidden in the data. 

17 



chapter 2. preliminari 18 

thi thesi be about supervis learning, where ML algorithm be train on some 

annot data (the train set) to build predict models, or learners, which will enabl 

u to predict the output of new unseen observations. It be call supervis becaus the 

learn process be do under the supervis of an output variable, in contrast with 

unsupervis learn where the respons variabl be not available. 

supervis learn assum the avail of label samples, i.e. observ anno- 

tat with their output, which can be use to train a learner. In the train set we can 

distinguish between input featur and an output variabl that be assum to be depen- 

dent on the inputs. the output, or respons variable, defin the class of observ 

and the input featur be the set of variabl that have some influenc on the output 

and be use to predict the valu of the respons variable. depend on the type of 

output variabl we can distinguish between two type of supervis task: i) classif 

and ii) regression. the first assum a categor output, while the latter a continu 

one. fraud detect belong to the first type sinc observ be transact that 

can be either genuin or fraudulent, while in other problem such a stock price predic- 

tion the respons be a continu variable. On the other hand, in both classif and 

regress tasks, input featur can includ both quantit and qualit variables. 

In thi thesi we will also refer to qualit variabl a categorical, discret and factor 

variables. 

2.1.1 formal of supervis learn 

let x be the realiz of a input random vector x defin in the input domain X, and 

y denot the output valu of the respons variabl y, take it valu in the output 

domain Y. In supervis learn we have four main player [30]: 

• G, the gener of input vector x ∈ X ⊂ Rn from an unknown probabl 
distribut fx(x). 

• S, the supervisor which assign to everi input x an output valu y ∈ Y ⊂ R 
accord to the condit probabl fy(y|x). 

• T, the train sampl which be independ and ident distribut (iid) 
sampl (x, y) drawn from the joint distribut fx,y(x, y). 

• lm, the learn machin that, give some train sampl T, return a class of 
parametr function (or hypothesis) h(x, θ), θ ∈ Λ, estim S for an input x and 
defin a map between the input and output domains, where Λ defin the 

domain for the paramet θ. 



chapter 2. preliminari 19 

supervisor* yx 

ŷ 

generator* 

training*samples* 

FX (x) FY (y | x) 

fxi (x, y) 

h(x,θ ) 

learning*machine* 

figur 2.1: the player of supervis learning. A gener return an input vector 
x accord to fx(x) and a supervisor associ an output valu y to x on the basi 
of fy(y|x). A collect of input and output valu defin a train set accord 
to fx,y(x, y). the learn machin produc an hypothesi h(x, θ) on the basi of a 

train set and predict the output ŷ for a new observation. 

the relationship that link the input x to the output y, denot a fy(y|x), be defin 
by S and it can be express a a function of the inputs, name f(x) and know a 

target operator, where y = f(x) + � with � be some noise. In gener fx(x), fy(y|x) 
and fx,y(x, y) be unknown, but some train sampl T be avail for lm. On the 

basi of T it be possibl to learn a LM that approxim fy(y|x). A model or learner L 
be defin a one of the mani hypothesi h(x, θ) in the paramet space Λ ⊂ rd. It be 
gener by lm, and associ to each input vector x an output valu or predict 

ŷ = h(x, θ), with ŷ ∈ Y. when Y ∈ R we have a regress task, while for classif 
Y be a set of class or categories. In particular, thi thesi will be concern with binari 

classif task in which Y ∈ {+,−}, where the posit output will be also cod 
a 1 and the neg a 0. with respect to fraud detection, posit observ will 

denot fraudul transact and neg genuin (legitimate) ones. 

LM explor multipl nest class of hypothesi Λ1 ⊂ Λ2 . . . ⊂ Λq ⊂ Λ for a give T 
and gener differ hypothesi by set distinct paramet θ in h(x, θ). In order 

to find the optim hypothesi h(x, θ∗) we have first to defin a loss function l(y, ŷ) that 

measur the discrep between ŷ and y, where ŷ = h(x, θ). given a loss function 

we can then defin a risk function r(θ) that measur how well a hypothesi h(x, θ) 

approxim f(x) over the x×i domain. 

r(θ) = 

∫ 
x,i 

l(y, ŷ)dfy(y|x)dfx(x) (2.1) 



chapter 2. preliminari 20 

the optim model h(x, θ∗) be defin a the hypothesi have the paramet θ∗ mini- 

mize r(θ): 

θ∗ = arg min 
θ∈λ 

r(θ) (2.2) 

the map f∗ : X→ Y defin by h(x, θ∗) be also know a target function. A train 
set TN = {(xi, yi), i = 1, . . . , N} be defin a a collect of N sampl from T. for a 
give train set TN we can comput onli what be call the empir risk (remp) and 

the hypothesi minim thi quantiti may be differ from h(x, θ∗). In the empir 

risk minim procedur [30] the paramet θ̂ be identifi by minim remp(θ): 

remp(θ) = 
1 

N 

N∑ 
i=1 

l(yi, h(xi, θ)) (2.3) 

θ̂ = arg min 
θ∈λ 

remp(θ) (2.4) 

It be import to stress that the same hypothesi h(x, θ̂) achiev differ remp(θ̂) when 

the train set chang (θ̂ depend on TN ), and the train set itself can be see a a 

realiz of a random variabl TN . for thi reason the accuraci of a learn algorithm 

be often measur use the gener error (gn ), which be the mean of remp(θ̂) over 

all possibl train sets: 

GN = etn [remp(θ̂)] (2.5) 

the choic of class of hypothesi have a great impact on the error GN that a learn 

algorithm L be abl to achieve. when the model be too simpl h(x, θ̂) could poorli 
approxim the target oper f(x) on the train set (high remp(θ̂)), but be 

gener enough to fit well multipl datasets, while a too complex model could fit perfectli 

the train set (low remp(θ̂)), but have poor gener on new datasets. thi 

interact can lead to the problem of underfit or overfit and it be often refer 

to a the bias-vari trade-off of a model [31]. 

the bia of a model be the error from erron assumpt in the learn algorithm, and 

the varianc be the error from sensit to small fluctuat in the train set (formal 

definit of bia and varianc avail in appendix c). section 2.1.3 will illustr how 

GN have both a bia and a varianc component. It be commonli say that a hypothesi 

underfit the data when it have larg bia but low variance, while it overfit the data 

when it have low bia but larg variance. In both cases, the hypothesi give a poor 

represent of the target and a reason trade-off need to be found. On the basi 

of the avail train set, the goal of the practition be then to search for the optim 

trade-off between the varianc and the bia terms. 



chapter 2. preliminari 21 

typically, the supervis learn procedur minim the error GN by mean of a two- 

step nest search process [32]. the inner process be know a parametr identification, 

and the outer a structur identification. the parametr identif step consid a 

singl class of hypothesi Λj , with j = 1, . . . , q, and select a hypothesi h(·, θjn ) with 
θjn ∈ Λj by mean of a learn algorithm L. the role of the learn algorithm be to 
find the model that minim the empir error on a give train set. then h(·, θjn ) 
be select a the one minim an estim of the gener error ĝjn by mean 

of a valid techniqu (e.g. cross valid or bootstrap).1 

θ̂jn = arg min 
θ̂n∈λj 

ĝjn (2.6) 

the structur identif step rang over differ class of hypothesi Λj , 1 ≤ j ≤ q 
and call for each of them the parametr routin which return the vector θ̂jn . the final 

model to be use for predict be select in the set {θ̂jn , j = 1, . . . , q}, a the one have 
the small gener error across all the class of hypotheses. thi last process be 

call model selection. 

2.1.2 the problem of classif 

A classif task can be explain a the problem of defin the associ between a 

categor depend variabl and independ variabl that can take either continu 

or discret values. As mention in the previou section, the depend variabl y ∈ Y 
be allow to take valu among a small set of K possibl class Y = {c1, . . . , ck} and 
the input/output valu of a sampl (x, y) be drawn from the joint distribut fx,y. A 

classifi K be a hypothesi h(x, θ) that return ŷ = ĉ ∈ Y. 

In gener we can identifi three altern approach to solv the classif problem: 

• estim the posterior probabl p(i = ck|x = x), and then subsequ use 
decis theori to assign a class ŷ to an input valu x. 

• estim the class-condit probabl p(x = x|i = ck) and prior probabl 
p(i = ck) separ and comput posterior probabl use bayes’ theorem: 

p(i = ck|x = x) = 
p(x = x|i = ck)p(i = ck)∑k 
k=1 p(x = x|i = ck)p(i = ck) 

then use decis theori to assign each new x to one of the classes. 
1note that we can comput onli an estim of GN , becaus typic we have access onli to a 

sampl of all possibl dataset of size N . 



chapter 2. preliminari 22 

• find a function g(x), know a discrimin function [7], which map each input 
x directli onto a class label ŷ (no probabl estim needed). 

approach that model the posterior probabl directli be call discrimin mod- 

els, while a gener approach model the class-condit and prior probabl for 

each class, and then calcul posterior probabl use bayes’ theorem. 

In the case of binari classif K = 2 and a popular loss function be the zero-on loss 

l0/1 which assign loss equal to one in case of wrong predict and zero otherwise: 

l0/1 : y×i → {0, 1} 

y, ŷ 7→ 
{ 

0 if y 6= ŷ 
1 if y = ŷ 

(2.7) 

however, in mani applic the cost of misclassif be class dependent. for ex- 

ampl in cancer treatment, the cost of not predict correctli a sick patient (a fals 

negative) be much high than make a wrong predict when the patient be healthi 

(a fals positive). assum Y = {1, 0}, where 1 denot posit instanc and 0 nega- 
tive ones. let li,j be the loss (cost) incur in decid i when the true class be j and 

p = p(i = 1|x = x). We can defin the risk of predict an instanc a posit or 
neg a follows: 

r+ = (1− p)l1,0 + pl1,1 

r− = (1− p)l0,0 + pl0,1 

standard decision-mak process base on decis theori [7, 33, 34] defin the optim 

class of a sampl a the one minim the risk (expect valu of the loss function). 

bay decis rule for minim the risk can be state a follows: assign the posit 

class to sampl with r+ ≤ r−, and the neg class otherwise. 

ŷ = 

{ 
1 if r+ ≤ r− 

0 if r+ > r− 
(2.8) 

As show by elkan [35], (2.8) be equival to predict a sampl a posit when p > τ 

and the threshold τ is: 

τ = 
l1,0 − l0,0 

l1,0 − l0,0 + l0,1 − l1,1 
(2.9) 

typically, the cost of a correct predict be zero, henc l0,0 = 0 and l1,1 = 0. If we set 

l1,0 = l0,1 = 1 we obtain l0/1 and τ = 0.5. 



chapter 2. preliminari 23 

2.1.3 bias-vari decomposit 

As show in the previou section, a binari classif problem can be solv by esti- 

mate the posterior probabl and then use a threshold τ to defin the class. sinc 

the posterior probabl be a continu value, the probabl estim problem can 

be treat a a regress problem. In regression, the unknown condit distribut 

fy(y|x) be typic estim use the condit expect e[y|x] [30]. In the case 
of binari classif with Y = {1, 0} we can write: 

e[y|x] = 1 · p(i = 1|x) + 0 · p(i = 0|x) = p(i = 1|x) 

In thi way, the classif problem can be see a a regress problem where the 

output take valu in {0, 1}. let p = p(i = 1|x = x) and p̂ it approxim give 
by the estim p̂. A common choic of loss function in regress be the quadrat loss 

give by l(p, p̂) = (p − p̂)2. In the case of the quadrat loss function, it can be show 
that the gener error GN can be decompos into a bia and a varianc term [36]. 

GN = etn [(p− p̂)2] = bias[p̂]2 + V ar[p̂] (2.10) 

where bias[p̂] = etn [p̂]− p and V ar[p̂] = etn [(p̂−etn [p̂])2] (deriv avail in 
appendix c). the first term bias[p̂]2 measur the “bias” of the model, it give an idea 

of how far the averag of our estim p̂ be from the true valu p. the “variance” term 

(V ar[p̂]) quantifi how much p̂ vari around it mean for differ train set TN . It 

therefor quantifi the sensit of the model predict for a give train set. the 

varianc be independ of the true probabl p, and be null for the classifi that have 

the same predict across all train datasets. domingo [37] provid a more gener 

bias-vari decomposit that work also for the l0/1. 

typically, complex model have high varianc and a low bia while simpl model have 

low varianc and a high bias. thi be becaus complex model can approxim well the 

target function (low bias), but be highli affect by the variabl of the train set 

(lead to high variance). the opposit occur with simpl models. simpl learner can 

show good perform than more complex one (e.g., [38, 39]). thi be becaus both 

bia and varianc influenc the predict error. the optim trade-off between bia and 

varianc be often domain or applic specific. sever work have found that ensembl 

of model veri often outperform a singl model (e.g., [40]), becaus averag multipl 

model often (though not always) reduc the varianc of singl models. 

well-known ensembl method be bag [41] and boost [42]. In bag multipl 

hypothesi be construct by use differ bootstrap sampl of the origin data 

set. the result model be then combin into an ensembl to make predictions. 



chapter 2. preliminari 24 

breiman [41] show that bag allow one to transform an unbias classifi into 

a nearli optim one by reduc the varianc term of (2.10). In the case of boosting, 

weak learner be combin to obtain accur predict [42] and the improv in 

the gener error over a singl classifi can also be relat to the bias-vari 

decomposit by introduc the notion of a margin [37], which measur the confid 

in the predict of the ensemble. 

A power ensembl algorithm base on bag be random forest [43]. random 

forest (rf) be an ensembl of decis trees, where each tree be train on differ 

bootstrap sampl of the origin train set and us a random subset of all the featur 

available. thi return a forest of decis tree that be veri differ from each other. 

divers in the model gener an ensembl be a key factor for varianc reduct [44]. 

2.1.4 evalu of a classif problem 

In a classif problem an algorithm be assess on it overal accuraci to predict 

the correct class of new unseen observ and usual ĝn be assess in term of 

mean misclassif error (mme). let Y1 be the set of posit instances, Y0 the 

set of neg instances, ŷ1 the set of instanc predict a posit and ŷ0 the one 

predict a negative. for a binari classif problem it be convent to defin a 

confus matrix (tabl 2.1). 

Y1 Y0 
ŷ1 TP FP 
ŷ0 FN TN 

tabl 2.1: confus matrix. 

In the case of zero-on loss we can then defin mme = |fp∧fn|n , where oper |·| defin 
the cardin of a set and N the size of the dataset. In the follow we will write FP 

to denot |fp| and similarli for all the other entri of the confus matrix. from mme 
we can then defin the accuraci of a model a 1 - mme. however, in some situations, the 

accuraci be not a good measur of performance, especi in unbalanc classif 

problem where one class be much more frequent than the other [45, 46]. for exampl 

consid the case where we have N = 10000 transact and onli 1% be fraudul 

(100 positives). predict all transact a genuin (negative) would return to an 

accuraci of 0.99, but we would miss to detect all fraudul cases. 

other classif measur base on the confus matrix be [47, 48]: 



chapter 2. preliminari 25 

• precision: tptp+fp 

• recall: tptp+fn , also call true posit rate (tpr), sensit or hit rate 

• true neg rate (tnr): tnfp+tn , also call specif 

• fals posit rate (fpr): fpfp+tn 

• fals neg rate (fnr): fntp+fn 

• balanc error rate (ber): 0.5( fptn+fp + fnfn+tp ) 

• g-mean: √sensitivity× specif 

• f-measure: 2precision×recallprecision+recal , also call f-score or f1. 

In an unbalanc classif problem, it be also well know that quantiti like tpr 

and tnr be mislead assess measur [49]. imagin a classifi with tpr=99% 

and tnr=99% (tabl 2.2), if we have 1% of posit samples, then precis be onli 0.5. 

even worse, if we have onli 0.1% of positives, then precis be 0.09. 

(a) class percentag 

Y1 Y0 
ŷ1 99% 1% 
ŷ0 1% 99% 

(b) frequenc 

Y1 Y0 
ŷ1 99 99 
ŷ0 1 9801 

100 9900 

tabl 2.2: confus matrix of a classifi with tpr=99% and tnr=99% when we 
have 100 posit instanc in 10000 observations. 

ber may be inappropri too becaus of differ cost of misclassif fals nega- 

tive and fals positives. precis and recal have opposit behavior, have high pre- 

cision mean bad recal and vice versa. f-measur give equal import to precis 

and recal into a metric rang between 0 and 1 (the high the better). f-measur and 

g-mean be often consid to be relev measur in unbalanc problem [21, 50–52]. 

In gener these measur can be comput onli onc a confus matrix be available, 

which mean that their valu depend on the threshold use for classif defin 

by (2.9). chang the threshold correspond to use differ misclassif costs. 

the receiv oper characterist (roc) curv [53, 54] be a well-know assess 

techniqu that allow evalu the perform of a classifi over a rang of differ 

thresholds. It be obtain by plot tpr against fpr (see figur 2.2), where each 

point of the curv correspond to a differ classif threshold. A classifi K be say 
to be more accur than a classifi W in the roc space onli if the curv of K alway 
domin the curv of W. the best classifi correspond to the point (0,1) in the roc 



chapter 2. preliminari 26 

fpr 

T 
P 

R 
0. 

0 
0. 

2 
0. 

4 
0. 

6 
0. 

8 
1. 

0 

0.0 0.2 0.4 0.6 0.8 1.0 

K 
W 

figur 2.2: the receiv oper characterist (roc) curv for two classifi 
K and W. the gray line repres the perform of a random model. 

space (no fals neg and no fals positives), while a classifi predict at random 

would have perform along the diagon connect the bottom left corner to the 

top right. when there be not a clear winner (e.g. classifi K domin W onli in one 
part of the roc space), the comparison be usual do by calcul the area under 

the roc curv (auc). auc be also a well-accept measur for unbalanc dataset 

and it have becom the de facto standard in classif [19, 51, 55–57]. 

however, auc be insensit to class prior sinc both tpr and fpr do not chang 

with a differ class ratio. precision-recal (pr) curv be instead sensit to chang 

in the class distribution, but there be there a strong connect between roc and PR 

curves. A curv domin in roc space if and onli if it domin in PR space, and 

algorithm that optim the area under PR curv be guarante to optim the area 

under roc curv [58]. 

when evalu the output of a classifi it be also import to ass the qualiti of the 

estim probabl [59]. A well-known measur of qualiti be brier score (bs) [60]. 

BS be a measur of averag squar loss between the estim probabl and the 

actual class value. It allow evalu how well probabl be calibrated, the low 

the BS the more accur be the probabilist predict of a model. let p̂(yi|xi) be 
the probabl estim of sampl xi to have class yi ∈ {1, 0}, BS be defin as: 

BS = 
1 

N 

N∑ 
i=1 

[yi − p̂(yi|xi)]2 (2.11) 



chapter 2. preliminari 27 

2.2 credit card fraud detect 

2.2.1 fraud detect system work condit 

In thi section we describ the work condit of a real-world fraud detect sys- 

tem (fds). figur 2.3 describ the hierarchi of layer in a fds, each control 

whether the transact be genuin or should be rather report a a fraud: i) terminal, 

ii) transact block rules, iii) score rules, iv) data driven model, v) investiga- 

tors. the first four element of the fd be fulli automatized, while the last one requir 

human intervent and it be the onli non-automat and offlin part of the fds. auto- 

matic tool have to decid whether the transact request (or the transact attempt) 

have to be approv in real time (i.e., decis have to be take immediately) or in near 

real time (i.e. decis can be take in a short time). block and score rule be 

expert driven rule (edr), i.e. rule design by investig base upon their expe- 

rience. On the contrary, the ddm us annot transact a sourc of inform 

to extract knowledg about fraudul and genuin patterns. In the follow we will 

explain the role play by each compon of the fds. 
transact request 

transact attem 
pt 

real time 

transact deni 

correct pin? 
suf!cient balance? 

activ account? 

investigatorstermin block 
rule 

data driven 
model 

score 
rule 

transact deni 

near real time of"in 

automat tool 

author transact 

alert 

feedback 

human supervis 

fd part we modelexpert driven data driven 

transact 

figur 2.3: the layer of a fds. In thi thesi we focu onli on the data driven part. 



chapter 2. preliminari 28 

2.2.1.1 fd layers: 

the termin repres the first layer of convent secur check in a fds. At thi 

stage secur check such a correct pin code, number of attempts, statu of the card 

(activ or blocked), suffici balanc and expenditur limit provid a first filter of the 

transact that can get through [61]. these condit be evalu in real time and 

if ani of them be not satisfied, the transact be denied. all transact pass thi 

first filter rais a transact request to the second layer control by the block rules. 

transact block rule be design by experienc investig and they can block 

a transact request befor it be authorized. these rule oper in real time, and be 

veri precise, they deni a transact request onli if it clearli repres a fraud attempt.2 

block rule be if-then (-else) rule that associ the class fraud or genuin to a 

transact when specif condit be met. An exampl can be the following: “if a 

pin-bas transact be do in europ and in asia within 5 min from the same 

cardhold then deni the transaction”, sinc the custom cannot physic be in 

europ and asia over a short time interval.3 transact request pass block 

rule be author and becom transact (the payment be executed). befor each 

author transact be sent to the success secur layer of fd it be enrich with 

aggreg inform (e.g. averag expenditure, number of transact in the same 

day of the same cardholder, etc.). the result featur vector describ the transact 

be then analyz by both score rule and ddms. these control be perform in near 

real time (typic less than 6 [61]) sinc there be no need to provid an immedi 

respons give that the transact have be alreadi authorized. 

score rule be edr defin by investig base upon their experi that act like 

a rule-bas classifier. they assign a score to each author transaction: the larg the 

score, the more like the transact be to be a fraud. In practic score rule contain 

simple, human-understand condit (e.g. IF internet transact in fiscal paradis 

and amount > 1000$, then fraud score = 0.9) and a such can be easili design by 

investig or other experts. these rule be easi to understand and fast to deploy, but 

requir manual revis when their perform drops. As a consequence, these rule 

can be expens to maintain. 

data driven model (ddm) layer reli on a predict model to assign a fraud score to 

each transaction. usual thi phase us ML algorithm that return for each transac- 

tion an estim of the probabl to be a fraud. these algorithm can learn complex 

correl in the data use larg volum of data with high dimensionality. they be 
2card should be block onli if there be a high risk of frauds, becaus it prevent the cardhold to 

make ani futur payments. 
3note that thi be just an illustr example, block rule be confidenti information. 



chapter 2. preliminari 29 

usual more robust than edr, but most of them be black box, i.e. it be not possibl 

to convert them into rule that be easi to interpret. ddm be abl to consid all 

the inform associ to a transaction, while edr return condit base on few 

featur of the transactions. 

investig be fraud expert that check fraud alerts, i.e. transact that have re- 

ceiv a high fraud score by either edr or ddm. these suspici transact be 

display in a case manag tool (cmt) where investig can see the associ 

fraud score, check where they come from (edr or ddm) and annot them a genuin 

or fraud after verification. In a realist scenario onli few alert can be check give 

a limit number of investig [62]. for thi reason, they typic investig onli 

transact with the high fraud score. the role of investig be to contact the 

cardholder, check if the transact be fraudul or not and annot it with it correct 

label. thi process can be long, tedious, and at the same time the number of transact 

to check be usual veri large, so it be import to minim fals alerts. the label 

process gener annot transact that be use by the ddm. In the follow 

we use the term feedback to refer to these label transactions. 

2.2.1.2 supervis inform 

investigators’ feedback be the most recent supervis inform avail to the fd 

and they repres a tini part of all transact process everyday [20]. addit 

label transact be provid by cardhold report unauthor transact [20, 

61]. however, the number of custom report fraud not detect by the fd be 

usual small and hard to model, sinc cardhold have differ habit when it come 

to check the transcript of credit card transact give by the bank. We do not know 

the class of all the other transact that have not be checked, they can be either 

genuin or fraud miss by the fd and ignor by the cardholders. however, after 

a certain time period when no further miss fraud be reported, we can assum that 

uncheck transact be genuine. these transact can then be use to train a new 

ddm. 

2.2.1.3 system updat 

expert driven system be updat manually, while the data-driven compon be up- 

date automatically. alert gener today defin the feedback that will be use to 

train an algorithm that detect the fraud of tomorrow. thi mean that alert-feedback 

interact (afi) govern the type of inform avail to the algorithm that regu- 

late the data driven phase. 



chapter 2. preliminari 30 

typically, ddm requir a larg set of sampl to train an accur model, so the ML 

algorithm use in the data driven layer be train at the end of the day, when a 

suffici batch of feedback be available. feedback of alert transact be give 

by investig dure the day, but onli at the end of the day we have all the feedback 

for the alert gener by the fds. therefore, the ddm be usual updat everyday 

at midnight and the detect model be then appli to all the transact occur in 

the next days. 

the focu of the thesi be to improv the ddm part of the fd and to model the 

interact between data driven method base on ML and investigators. In particular, 

we will consid a scenario where the ddm be the onli element of the fd respons for 

the alert give to fraud expert and the algorithm be abl to learn from the feedback 

provided. In the remaind of the thesi we will use the term fd to indic onli the 

fd layer we model: ddm and investigators. 

2.2.2 featur augment 

when a transact be authorized, it be enter in a databas contain few variabl 

such a cardhold ID (card_id), amount, datetime, merchant, etc. start from 

these featur it be possibl to comput new variabl that can describ the cardhold 

behaviour. thi process be call featur augmentation, becaus the ultim goal be to 

add to the origin featur new inform features. standard featur augment 

consist into comput variabl such a averag expenditur of the cardhold in the 

last week/month, number of transact in the same shop, number of daili transactions, 

etc. [18, 62–65]. van vlassela et al. [61] use also network featur to consid the role 

of the cardhold in the network of transactions. 

these new featur be also call aggreg featur a they provid an aggreg 

view of the cardhold behaviour over a certain time period. It be import to includ 

aggreg featur for the ddm to learn the behavior of the custom over time and 

detect anomal transact w.r.t. typic custom usag of the credit card. trans- 

action aggreg be comput expensive; therefor aggreg featur be often 

comput for each cardhold offlin use histor transact (e.g. transact of 

the same cardhold in the previou month). onc aggreg variabl be avail they 

be merg with the origin featur to defin a featur vector describ the transact 

that be then use to train the ddm. after transact author and featur aug- 

mentation, each featur vector be score by both ddm and score rule which oper 

in near-real time. 



chapter 2. preliminari 31 

In a test environment, we should remov card_id from the featur vector. A model 

that receiv a input the variabl card_id may have perform too optimist on 

futur fraud from the same cardhold if not remov from the dataset. On the contrary, 

in a real work environment, a card be block after the first fraud be found, so we cannot 

see futur transact from the same card. To replic the real set we could remov 

all the transact of the compromis card, but thi would reduc the number of fraud 

avail for test our algorithm, worsen the class unbal problem in our dataset. 

anoth option be to remov the card_id variabl from the featur vector. In thi 

case, each fraud can be treat independ and the fd cannot leverag card_id 

for detect frauds. note that card_id be use to comput aggreg variables, so 

we can safe remov card_id onli onc the new variabl be includ in the featur 

vectors. these new featur contain inform about the cardholder, so there be not 

loss of inform in remov card_id after featur augmentation. 

2.2.3 accuraci measur of a fraud detect system 

choos a good perform measur be not a trivial task in the case of fraud detection. 

among others, fraud detect must deal with the follow challenges: i) unbalanc 

class sizes, ii) cost structur of the problem (the cost of a fraud be not easi to define), 

iii) time to detect (a card should be block a soon a it be found victim of fraud, 

quick reaction to the appear of the first can prevent other frauds), iv) error in class 

label (quantifi unreport frauds), v) reputation’ cost for the company, etc. 

As alreadi mention in section 2.1.4, standard classif measur such a mme, 

ber, tpr and tnr be mislead assess measur in unbalanc class prob- 

lem [49]. A well-accept measur for unbalanc classif be the area under the 

roc curv (auc) [56]. thi metric give a measur of how much the roc curv be 

close to the point of perfect classification. hand [66] consid standard calcul of 

the auc a inappropriate, sinc thi translat into make an averag of differ mis- 

classif cost for the two classes. An altern way of estim auc be base on 

the use of the mann–whitney statist and consist in rank the transact accord 

to the posterior probabl to be fraudul and measur the likelihood that a fraud 

rank high than a genuin transact [67]. By adopt the rank-bas formul of 

auc we can avoid the problem rais by hand of use differ probabl thresholds. 

In mani fd (e.g. [68–70]), cost-bas measur be defin to quantifi the monetari 

loss due to fraud [71] by mean of a cost-matrix that associ a cost to each entri of 

the confus matrix. elkan [35] claim that it be safer to ass cost-sensit problem 

in term of benefit (invers of cost), sinc there be the risk of use differ baselin 



chapter 2. preliminari 32 

when use a cost-matrix to measur overal cost. To avoid thi problem, normal 

cost or save [70] be use to ass the perform w.r.t. the maximum loss. when 

defin a cost measure, one could consid the cost of a FN fix or depend on the 

transact amount. In the first case each fraud be equal costly, while in the latter the 

cost be exampl dependent. An argument for use fix cost be to give equal import 

to small and larg fraud (fraudster usual test a card with small amounts), while 

transaction-depend cost allow one to quantifi the real loss that a compani have to 

face. 

In the transaction-depend case, the cost of a miss fraud (fn) be often assum 

to be equal to the transact amount [35, 71], becaus it have to be reimburs to the 

customer. cost of correct or fals alert be consid to be equival to the cost of a 

phone call, becaus the investig make a phone call to the cardhold to verifi if it be 

the case of a fals alert or a real fraud. the cost of a phone call be neglig compar to 

the loss that occur in case of a fraud. however, when the number of fals alert be too 

larg or the card be block by error, the imposs to make transact can translat 

into big loss for the customer. 

the cost should also includ the time take by the detect system to react. the 

shorter be the reaction time, the larg be the number of fraud that it be possibl to 

prevent. typically, onc fraudster success perpetu a fraud, then they tri to 

spend all the money avail on the card. As a consequence, when evalu a fd 

we should also consid the spend limit of each card: i.e. detect a fraud on a 

card have a larg spend limit (e.g. corpor cards) result in high save than 

detect a fraud on a card have a small spend limit [72]. for all these reasons, 

defin a cost measur be a challeng problem in credit card detect and there be not 

agreement on which be the right way to measur the cost of frauds. 

the perform of a detect task (like fraud detection) be not necessarili well de- 

scribe in term of classif [73]. In a detect problem what matter most be 

whether the algorithm can rank the few use item (e.g. frauds) ahead of the rest. 

In a scenario with limit resources, fraud investig cannot revis all transact 

mark a fraudul from a classif algorithm. they have to put their effort into 

investig transact with the high risk of fraud, which mean that the detect 

system be ask to return the transact rank by their posterior fraud probability. 

the goal then be not to predict accur each class, but to return a correct rank of the 

minor classes. 

In thi context a good detect algorithm should be abl to give a high rank to relev 

item (frauds) and low score to non-relevant. A well-known detect measur be averag 

precis (ap) [73]. let N+ be the number of posit (fraud) case in the origin dataset 



chapter 2. preliminari 33 

and tpk be the number of true posit in the first k rank transact (tpk ≤ k). 
let u denot precis and recal at k a Pk = tpkk and Rk = 

tpk 
N+ 

. We can then defin 

averag precis as: 

AP = 
N∑ 
k=1 

pk(rk − rk−1) (2.12) 

where N be the total number of observ in the dataset. the good the rank, the 

great the AP and the optim algorithm that rank all the fraud ahead of the legiti- 

mate have AP = 1. note that AP be also an estim of the area under the precision-recal 

curv [74]. 

As explain in section 2.2.1, each time a fraud alert be gener by the detect system, 

it have to be check by investig befor proceed with action (e.g. custom 

contact or card stop). given the limit number of investigators, it be crucial to have the 

best rank within the maximum number k of alert that they can investigate. In thi 

set it be import to have the high precis within the first k alerts, name pk. 

note that, while auc and AP give a measur of the qualiti of the rank on the whole 

datasets, Pk focu onli on a subset of k transactions. precis at k (pk) be also call 

alert precis and it have emerg a a standard accuraci measur of fdss [18, 20, 64]. 

assess of two fdss (e.g. exist versu new version) can hide undesir bias. 

when evalu between choos an exist fd and a new solution, hand [75] warn 

against the bia that favor the old fds. the data use to train a new fd depend on 

the alert and detect give by the fd in place at the moment of training, i.e. we can 

train a new fd onli on the fraud discov by the old fd and the undetect one 

cannot be use for train / evaluation. therefore, there be a select bia in the data 

collect process that be due to the perform of the previou fds, a a result the 

evalu be bia in favor of the exist system. thi issu be similar to the problem 

of evalu classifi in the presenc of alert-feedback interact (see chapter 6), 

where we know the feedback onli of the learner request the labels. the perform 

evalu make sens onli condit on the learner gener the alerts, so it be 

incorrect to compar two altern algorithm when onli one of the two request the 

feedbacks. 





chapter 3 

state-of-the-art 

thi chapter present a review of the approach that have be adopt for deal 

with the challeng of a data driven fd present in section 1.4. section 3.1 provid 

an overview of state-of-the-art method for unbalanc classif and section 3.2 

review the princip adapt techniqu propos for the problem of learn in non- 

stationari distribution. then in section 3.3 we present method that address the problem 

of class unbal in evolv data streams. finally, section 3.4 present state-of-the-art 

algorithm solut propos for credit card fraud detection. 

3.1 techniqu for unbalanc classif task 

learn from unbalanc dataset be a difficult task sinc most learn algorithm be 

not design to cope with a larg differ between the number of case belong to 

differ class [22]. there be sever method that deal with thi problem and we can 

distinguish between method that oper at the data and algorithm level [76]. At 

the data level, the unbalanc strategi be use a a pre-process step to rebal 

the dataset or to remov the nois between the two classes, befor ani algorithm be 

applied. At the algorithm level, algorithm be themselv adjust to deal with the 

minor class detection. data level method can be group into five main categories: 

sampling, ensemble, cost-based, distance-bas and hybrid. within algorithm method 

instead we can distinguish between: i) classifi that be specif design to deal 

with unbalanc distribut and ii) classifi that minim overal classif cost. 

the latter be know in the literatur a cost-sensit classifi [35]. both data and 

algorithm level method that be cost-sensit target the unbalanc problem by use 

differ misclassif cost for the minor and major class. At the data level, 

cost-bas method sampl the data to reproduc the differ cost associ to each 

35 



chapter 3. state-of-the-art 36 

class (see translat theorem [77]). cost-sensit classifi instead directli minim 

the cost by use cost specif loss function. alternatively, wrapper method can be 

use to convert a cost-insensit (or cost-blind) classifi into a cost-sensit one (e.g. 

metacost [78]). 

all the method present in the follow section will discu the unbalanc problem 

a refer to between class imbalance, i.e. imbal in class frequency. however, 

class imbal can exist also within the class [79, 80] (due to small cluster within one 

class), and thi problem be often link to the presenc of rare case [81]. within-class 

imbal and rare case be close relat to the problem of small disjuncts, which 

hinder classif perform [80, 82–84]. small disjunct be rule that cover a small 

cluster of exampl result from concept that be underrepres [46, 85, 86]. for an 

in-depth analysi of other issu relat to unbalanc classif we invit the reader 

to have a look at [87]. 

3.1.1 data level method 

sampl method 

typically, sampl method be use to rebal the datasets, becaus studi have 

show that standard classifi have good perform when train on a balanc 

train set [88–90]. sampl techniqu do not take into consider ani class in- 

format in remov or add observations, yet they be easi to implement and to 

understand. 

undersampl [91] consist in downsiz the major class by remov observ 

at random. In an unbalanc problem it be realist to assum that mani observ 

of the major class be redund and that by remov some of them at random the 

result distribut should not chang much. however, the risk of remov relev 

observ from the dataset be still present, sinc the remov be do in an unsupervis 

manner. In practice, thi techniqu be often adopt sinc it be simpl and speed up the 

learn phase. 

oversampl [91] consist in up-siz the small class at random decreas the level 

of class imbalance. By replic the minor class until the two class have equal 

frequency, oversampl increas the risk of overfit [91] by bias the model toward 

the minor class. other drawback of thi approach be that it do not add ani new 

inform minor exampl and that it increas the train time. thi can be 

particularli ineffect when the origin dataset be fairli large. 



chapter 3. state-of-the-art 37 

smote [92] oversampl the minor class by gener synthet exampl in the 

neighborhood of observ ones. the idea be to form new minor exampl by interpo- 

late between sampl of the same class. thi have the effect of creat cluster around 

each minor observation. By creat synthet observ the classifi build larg 

decis region that contain nearbi instanc from the minor class. smote have 

show to improv the perform of a base classifi in mani applic [92], but 

it have also some drawbacks. synthet observ be gener without consid 

neighbor examples, lead to an increas of overlap between the two class [93]. 

borderline-smot [94] and adasyn [95] have be propos to overcom thi prob- 

lem. 

undersampling- oversampling- smote- 

figur 3.1: resampl method for unbalanc classification. the neg and pos- 
itiv symbol denot major and minor class instances. In red the new observ 

creat with oversampl methods. 

cost-bas method 

cost proport sampl [35] consist into sampl train instanc from the ma- 

joriti and minor class by take into consider the ratio of the misclassif 

costs. let li,j denot the misclassif cost of class j predict a i, so that the cost of 

a FP and a FN be write a l1,0 and l0,1. when we want to keep all minor examples, 

then the number of major instanc should be multipli by l1,0l0,1 . If we assum that 

the cost of a FP be lower, i.e. l1,0 < l0,1, thi boil down to undersampl the major 



chapter 3. state-of-the-art 38 

class. alternatively, cost proport sampl can be achiev by replic observa- 

tion from the minor class l0,1l1,0 time (oversampling). As in the case of oversampling, 

replic sampl from the minor class may induc overfit [77]. 

cost [77] adopt “reject sampling” to select the instanc in the final dataset. each 

instanc in the origin train set be drawn once, and accept into the sampl with the 

accept probabl lj,iz where Z be an arbitrari constant such that Z ≥ max lj,i. when 
Z = max lj,i, thi be equival to keep all exampl of the rare class, and sampl 

the major class without replac accord to l1,0l0,1 . 

distance-bas method 

the follow method make use of distanc measur between input point either to 

undersampl or to remov noisi and borderlin exampl of each class. these method 

be veri time consum sinc they requir comput distanc between observations. 

tomek link [96] remov observ from the neg class that be close to the posit 

region in order to return a dataset that present a good separ between the two 

classes. let u consid two input exampl xi and xj belong to differ classes, 

and let d(xi, xj) be their distance. A (xi, xj) pair be call a tomek link if there be no 

exampl xk, such that d(xi, xk) < d(xi, xj) or d(xj , xk) < d(xi, xj). If two exampl 

form a tomek link, then one of these exampl be noisi or both be borderline. neg 

instanc that be tomek link be then remov reduc the major class. thi 

method be particularli use in noisi dataset a it remov those sampl for which 

nois can lead to a misclassif [97]. 

condens nearest neighbor (cnn) [98] be use to select a subset S from the origin 

unbalanc set T which be consist with T in the sens that S classifi T correctli 

with the one-nearest neighbor rule (1-nn). the idea behind thi implement of a 

consist subset be to elimin the exampl from the major class that be distant 

from the decis border, sinc these sort of exampl might be consid less relev 

for learning. sinc noisi sampl be like to be misclassified, mani of them will be 

add to the S set which mean cnn rule be extrem sensit to nois [99]. moreover, 

noisi train data will misclassifi sever of the subsequ test examples. 

one side select (oss) [100] be an undersampl method result from the combi- 

nation of tomek link follow by the applic of cnn. tomek link be use a an 

undersampl method and remov noisi and borderlin major class examples. bor- 

derlin exampl can be consid unsaf sinc a small amount of nois can make them 

fall on the wrong side of the decis border [97]. cnn aim to remov exampl from 



chapter 3. state-of-the-art 39 

the major class that be distant from the decis border. the remain examples, 

i.e. safe major class instanc and all minor class examples, be use for learning. 

edit nearest neighbor (enn) [101] remov ani exampl whose class label differ from 

the class of at least two of it three near neighbors. In thi way major exampl 

that fall in the minor region be remov and likewis isol minor exampl be 

removed. To avoid the risk of lose relev minor exampl enn be edit to remov 

onli neg exampl that be misclassifi by their 3 near neighbors. 

neighborhood clean rule (ncl) [89] modifi the enn method by increas the 

role of data cleaning. firstly, ncl remov neg exampl that be misclassifi by 

their 3-nearest neighbors. secondly, the neighbor of each posit exampl be found 

and the one belong to the major class be removed. sinc thi algorithm remov 

noisi instances, a well a close-bord points, the decis boundari becom smoother 

with a consequ reduct of the risk of overfit [97]. 

other hybrid strategi can be easili creat by combin sampling, ensembl or distance- 

base techniqu [27]. 

3.1.2 algorithm level method 

algorithm orient method be essenti a modif (or extension) of exist clas- 

sific algorithm for unbalanc tasks. depend on their applic we distin- 

guish between imbalanc learn and cost-sensit learning. In first case, the goal be 

to improv accuraci of the minor class, while in the second case the object be to 

minim the cost associ to the classif task. 

imbal learn 

standard decis tree such a c4.5 [102] use inform gain (ig) a split criterion 

in each node of the tree. however, thi split criterion return rule that be bia 

toward the major class. liu et al. [57] use the class confid proport (ccp) 

metric for split in presenc of class imbalance, while cieslak and chawla [103] suggest 

split with helling distanc (hd). they show that HD be skew-insensit and the 

propos hddt have good perform compar to standard c4.5. other studi 

have also report the neg effect of skew class distribut not onli on decis 

tree [21, 82], but also for neural network [82, 104], k-nearest neighbor (knn) [100, 

105, 106] and svm [107, 108]. 



chapter 3. state-of-the-art 40 

A svm optim in term of f-measur be present by callut and dupont [109], while 

Li et al. [110] use svm with rbf kernel a base classifi for adaboost. In the famili of 

lazi learn classifiers, liu and chawla [111] propos a knn weight strategi design 

for handl the problem of class unbalance. the algorithm, call ccw-knn (class 

confid weight knn), be abl to correct the inher bia toward the major class 

in exist knn classifiers. 

associ rule mine with class unbal be often achiev by specifi multipl 

support level for each class to account for the differ in class frequenc [112]. within 

the famili of rule-bas classifiers, verhein and chawla [113] develop a classifi call 

sparccc that be specif design for unbalanc classification. In all these algo- 

rithm the gener idea be to modifi the origin classifi in order to learn good pattern 

from the minor class. weiss [114] argu that these algorithm solut should be pre- 

fer to data level method caus they be abl to deal with the class unbal directli 

without bias the classifi toward one class. 

follow the great success of ensembl learn in machin learning, lot of ensembl 

strategi have be propos for imbalanc learning, with bag [41] and boost- 

ing [115] be the most popular method to aggreg classifiers. usually, ensembl 

method combin an unbalanc strategi with a classifi to explor the major and 

minor class distribution. balancecascad [116] be a supervis strategi to under sam- 

ple the major class. thi method iter remov the major class instanc that 

be correctli classifi by a boost algorithm. the idea be that observ of the 

major class that be easi to classifi be redund and that by remov them the 

algorithm can concentr on the hard cases. the drawback be that a classif algo- 

rithm have to be appli sever time to reduc the major class lead to an increas 

in comput needs. 

easyensembl [116] and underbag [117] combin differ model that learn distinct 

aspect of the origin major class. thi be do by creat differ balanc train 

set by undersampling, learn a model for each dataset and then combin all predic- 

tion a in bagging. In the case of easyensemble, boost be use a classifi so that the 

method be abl to integr the advantag of boost and bagging. In the same spirit, 

sever studi have integr oversampling/undersampl in ensembl of svm [118– 

121]. smoteboost [122] combin boost with smote. similarly, databoost-im [45] 

gener synthet sampl a well within the boost framework to improv the predic- 

tive accuraci of both the major and minor classes. rareboost [123] modifi the 

boost algorithm to increas accuraci on the rare class by emphas the differ 



chapter 3. state-of-the-art 41 

of TN from fn, and TP from FP at each iter of boosting. jous-boost [124] gener- 

ate duplic of the minor class with oversampling, but also introduc perturb 

(“jittering”) by add iid nois to minor examples. 

cost-sensit learn 

In unbalanc classif tasks, it be usual more import to correctli predict pos- 

itiv (minority) instanc than neg (majority) instances. thi be often achiev by 

associ differ cost to erron predict of each class. cost-bas method 

oper at the algorithm level be abl to consid misclassif cost in the learn- 

ing phase without the need of sampl the two classes. exampl of these classifi be 

cost-sensit boost [125, 126], svm [127] and neural network [128]. 

In the famili of decis tree classifiers, cost-bas split criterion be use to minim 

cost [129]; or cost inform determin whether a subtre should be prune [130]. In 

general, prune allow improv the gener of a tree classifi sinc it remov 

leaf with few sampl on which we expect poor probabl estimates. although, when 

the classif task be unbalanced, leaf contain few sampl be often the one 

associ to the minor class and the first remov with pruning. 

with metacost [78] domingo propos a gener framework that allow transform 

ani non cost-sensit classifi into a cost-sensit one. similarly, threshold [131] 

allow use cost-insensit algorithm for cost minim via differ classif 

thresholds. these last method be also call cost-sensit meta-learners, sinc they be 

wrapper that minim misclassif cost use standard classif algorithm. 

In mani applications, however, cost be not explicitli avail or easi to estimate, 

complic the use of cost-sensit algorithm [132]. 

3.2 learn with non-stationar 

A standard assumpt in machin learn be that the train and test set be 

drawn from the same underli distribution. let ptr(x, y) and pts(x, y) denot joint 
probabl of a sampl (x, y) accord to train and test distribution. In a non- 

stationari environ we have ptr(x, y) 6= pts(x, y). when there be a distribut 
mismatch between the test and train data, the model fit use the train data 

will be sub-optim for the test scenario. typically, thi mismatch be gener by the 

follow two causes: i) sampl select bia (ssb) or ii) time evolv data. 



chapter 3. state-of-the-art 42 

In the first case the select process of the train sampl be respons for a bia 

train set and depend on the bia differ solut exist to correct thi bias. the 

second caus of non-stationar be link to stream data where the data distribut 

evolv with time. 

3.2.1 sampl select bia 

sampl select bia (ssb) occur when the train set avail be bia becaus 

it have be select in a way that be not repres of the whole population. for 

example, consid the problem where a bank want to predict whether someon who be 

appli for a credit card will be abl to repay the credit at the end of the month. the 

bank have data avail on custom whose applic have be approved, but have 

no inform on reject customers. thi mean that the data avail to the bank be 

a bia sampl of the whole population. the bia in thi case be intrins to the dataset 

collect by the bank. 

We formal the sampl bia by mean of a random variabl s ∈ {0, 1} where sampl 
includ in the bia train set have s = 1, and s = 0 otherwise. then the joint 

distribut of a sampl (x, y) in the bia train set be p(x, y| = 1) and p(x, y) 
be the distribut in the case when the train set be unbiased. ssb requir what 

be know a the support condit [133]: the support of the probabl measur of the 

train data have to be a subset of the support of the probabl measur of the test data. 

under thi condit ptr(y, x) = p(y, x| = 1) and pts(y, x) = p(y, x). the select 
bia can be of differ types: class prior bias, featur bia (also call covari shift) 

and complet bias. 

class prior bias, also call prior probabl shift, be essenti a chang in class priors: 

p(y| = 1) 6= p(y). It correspond to the case when the select be independ of 
the featur x give the class y: p( = 1|x, y) = p( = 1|y). As a consequ of 
prior change, class-condit probabl be differ (p(y|x, s = 1) 6= p(y|x)), while 
within-class distribut remain unchang (p(x|y, s = 1) = p(x|y)). thi type of 
bia can be introduc voluntarili for unbalanc classif task a in the case of 

undersampl and oversampl techniqu present in section 3.1.1. As a result of 

class prior bias, classifi have probabl estim that be poorli calibr [28]. 

well-know method for correct the prior bia be give by saeren et al. [134] and 

elkan [35]. 

featur bia refer to chang in the distribut of the input variabl without affect 

the condit probabl p(y|x). the select be independ of the class label y give 
the featur x (miss at random): p( = 1|x, y) = p( = 1|x). thi condit impli 



chapter 3. state-of-the-art 43 

p(y|x, s = 1) = p(y|x). featur bia appear to be most studi type of bia [135–138] 
and a standard solut consist into re-weight train instanc [139]. 

finally, complet bia be the most gener case where the select depend on both 

y and x (miss not at random). the most famou method for correct complet 

bia be the one of heckman [140] that give him the nobel prize. heckman defin two 

linear models, one for estim s and one for y, which use differ subset of features. 

the two-step procedur for bia correct consist into model s with ordinari least 

squar and then use the output a an addit featur in the model use to estim 

y. If the same featur be use to estim both linear model estim s and y, then 

the addit variabl may end up highli correl with the bia estim of y and 

the heckman procedur be not effect in correct the bia [141]. follow the same 

idea zadrozni and elkan [142] use a classifi to predict p( = 1|x) and then incorpor 
thi probabl estim a input featur in a new classifi use to predict p(y|x), but 
there be no theoret guarante that thi method should correct ssb. for a recent 

survey on ssb we refer to [141]. 

the machin learn commun have extens investig the ssb problem [35, 

77, 142–145]. A standard remedi to ssb be import weight which consist of 

re-weight the cost of train sampl error to more close reflect that of the test 

distribut [77, 143, 144]. use the bay formula we can write p(x, y) in term of 
p(x, y| = 1): 

p(x, y) = p(x, y| = 1)p( = 1)p( = 1|x, y) = 
p( = 1) 
p( = 1|x, y)p(x, y| = 1) (3.1) 

hence, we can correct ssb use a weight-sensit algorithm, where a train instanc 

(x, y) receiv a weight p(s=1)p(s=1|x,y) . the probabl p( = 1) can easili be estim 
know the proport of sampl examples, howev comput p( = 1|x, y) be not 
straightforward. In the case of featur bia we can rewrit (3.1) as: 

p(x, y) = p( = 1)p( = 1|x)p(x, y, s = 1) (3.2) 

now we can estim term p( = 1|x) use a classifi that distinguish between sampl 
point and instanc not includ in the train set. however, cort et al. [133] argu 

that the re-weight approach be abl to remov the bia a long a the weight be 

estim correctly. with a poor estim of the weight we be not guarante to be 

abl to remov the bias. In estim p( = 1|x) we might have some valu equal 
to zero, so it may be safer to assum complet bia [146]. ssb be close relat to the 

problem of learn under time evolv data streams, where import weight be 

use to correct the concept drift due to covari shift [147]. 



chapter 3. state-of-the-art 44 

3.2.2 time evolv data 

most of the times, the main caus of differ between train and test set in data 

stream be due to a chang in the data gener process. use bay rule we can write 

the joint distribut of a sampl (x, y) as: 

p(x, y) = p(y|x)p(x) = p(x|y)p(y) (3.3) 

usually, in classif we be interest in a estim of p(y|x), from (3.3) we have: 

p(y|x) = p(x|y)p(y)p(x) (3.4) 

use (3.4), a chang between the distribut of the data stream at time t and t + 

1, pt(x, y) 6= pt+1(x, y), can come from [135]: i) p(y|x), ii)p(x|y), iii) p(y) and iv) 
combin of the previous. note that a chang in p(x) do not affect y and can 
thu be ignor [148]. most often, regardless of type of term varying, a chang in the 

distribut be refer in literatur a concept drift [23] or dataset shift [149]. 

chang in the probabl prior (pt(y) 6= pt+1(y)) can caus well-calibr classifi 
to becom miscalibr [28]. concept drift due to pt(x|y) 6= pt+1(x|y) affect the 
distribut of the observ within the class, but leaf the class boundari unchang 

(pt(y|x) = pt+1(y|x)). thi type of drift be often call covari shift [141]. when 
pt(y|x) 6= pt+1(y|x), there be a chang in the class boundari that make ani previous 
learn classifi biased. the latter be the bad type of drift, becaus it directli affect 

the perform of a classifier, a the distribut of the features, with respect to the 

class, have chang [148] (see figur 3.2). In gener it be hard to say where the chang 

come from, becaus we have access to onli estim of the previou probabl and 

we have no knowledg (or control) of the data gener process. 

learn algorithm oper in non-stationari environ typic reli onli on the 

supervis inform that be up-to-d (thu relevant), and remov obsolet train 

sampl [150]. however, concept learn in the past may re-occur in the future, there- 

fore when remov obsolet train samples, we could remov inform that be still 

relevant. thi be know a the stability-plast dilemma [151]. 

concept drift (cd) adapt approach can be group into two families: i) activ and 

ii) passiv adapt [150]. the former [152–155], react to CD when a chang be detect 

(e.g. by mean of a chang detect test). activ approach be mostli adopt for 

data distribut that chang abruptly, becaus chang detect with gradual drift 

be typic more difficult [156]. when a chang be identifi the classifi be updat 

or remov and replac by a new one train on the most recent sampl available. 



chapter 3. state-of-the-art 45 

t +1 

t 

class%priors%change% within%class%change% class%boundary%change% 

figur 3.2: illustr exampl of differ type of concept drift. chang in class 
prior be due to pt(y) 6= pt+1(y), while within class chang (covari shift) occur when 
pt(x|y) 6= pt+1(x|y). class boundari chang happen when pt(y|x) 6= pt+1(y|x). 

the chang detector can work by: a) check featur distribut or b) analyz 

misclassif errors. In first case featur be inspect to detect possibl evolv 

distributions, wherea misclassif error be use to identifi chang in the class 

boundary. CD detect be particularli challeng in the presenc of class unbalanced, 

becaus we might have to wait a while befor have enough sampl from the minor 

class [148]. 

In the case of passiv approach the classifi be continu updat a soon a new 

supervis sampl becom avail (no trigger mechan involved) [18, 157, 158]. 

generally, these approach be use in the presenc of gradual drift and recur 

concept [158]. passiv approach typic reli on ensembl of classifiers, where CD 

adapt be obtain by weight the ensembl member and creating/remov the 

classifi compos the ensemble. By integr sever classifiers, the ensembl com- 

bine what be learn from new observ and the knowledg acquir befor [159–161]. 

the weight of each member in the ensembl be comput to reflect how well a classi- 

fier be still relev for the current concepts. If the weight of a classifi drop below a 

certain threshold, then the classifi be usual replaced, see for exampl sea [160] and 

dwm [162]. other ensembl techniqu [159–161] use ensembl of classifi in order to 

combin what be learn from new observ and the knowledg acquir before. 

alternatively, passiv CD adapt be achiev by train a classifi over a slide 

window of the recent supervis sampl (e.g. stagger [163] and flora [164]). 



chapter 3. state-of-the-art 46 

It becom critic then to set the rate of forgetting, defin by the window size, in 

order to match the rate of chang in the distribut [165]. the simplest strategi us a 

constant forget rate, which boil down to consid a fix window of recent observ 

to retrain the model. flora approach [164] us a variabl forget rate where the 

window be shrunk if a chang be detect and expand otherwise. 

for a recent and in-deep review on CD adapt we refer the reader to [156]. thi 

thesi we will focu on passiv approaches, where the data stream be receiv in batch 

of daili transactions. In the case of fraud detection, the data stream present not onli 

non-stationari distributions, but also unbalanc classes. the problem of learn in 

the case of unbalanc data have be wide explor in the static learn set 

[82, 91, 92, 116]. learn from non-stationari data stream with skew class distribut 

be howev a rel recent domain and will be treat in the next section. 

3.3 learn with evolv and unbalanc data stream 

In mani applic (e.g. network traffic monitor and web access data) the data be 

receiv over time with high frequenc and it be not possibl to store all histor samples. 

the data have to be process in real time and it may not be feasibl to revisit previou 

transactions. thi restrict be know in the literatur a one-pass constraint [166]. 

one popular algorithm for mine data stream be veri fast decis tree (vfdt) by 

domingo and hulten [167]. vfdt learn increment from each new observ 

without store ani examples, i.e. use constant memori and constant time per exam- 

ple, and us hoeffd bound to determin the convers of a tree leaf to a tree node. 

sinc the semin paper of domingos, sever similar algorithm have be proposed, e.g. 

cvfdt [168] us a slide window for concept drift adaptation, vfdtc [169] extend 

vfdt for continu data and CD use a naiv bay classifi in the leaves. 

when the data stream be unbalanced, a certain time have to elaps in order to ac- 

cumul enough sampl from the minor class. sinc a classifi requir a larg 

set of sampl to learn an accur model, typic the train be do batch wise, 

i.e. when a suffici number of sampl from both class be available. despit the 

larg literatur on data stream studies, few work have tri to address the problem 

of learn with non-stationari data stream with unbalanc class distribution. In 

these work the class unbal problem be typic address my adopt one of the 

resampl method present in section 3.1.1 to rebal the batch of the data 

stream [19, 170–173]. for example, ditzler and polikar propos learn++.ni [172] 



chapter 3. state-of-the-art 47 

where they extend learn++.ns [174] for unbalanc data stream by train clas- 

sifier on multipl balanc batch obtain with undersampling. follow the same 

idea, learn++.cd [173] rebal the train set of each classifi in the ensembl 

use smote [92]. 

rebalanc a batch with few posit (minority) sampl could mean remov mani 

neg sampl (in the case of undersampling) or signific replic of the minor 

class (oversampling) with a high risk of overfitting. A differ way to compens 

the class imbal within the batch be to propag minor class sampl along 

the stream. for exampl gao et al. [170, 171] combin minor class propag and 

undersampl of the major class. the posit exampl be accumul along the 

stream until they repres 40% of the observations. when thi happens, the old 

posit exampl be replac by the new observ from the minor class. thi 

propag method ignor the similar of the minor class instanc to the current 

concept, reli onli on it similar in time. 

lichtenwalt and chawla [175] suggest propag not onli minor samples, but also 

observ from the major class that have be previous misclassifi to increas 

the boundari definit between the two classes. chen and He propos rea [176] where 

they recommend propag onli exampl from the minor class select use a knn 

algorithm. similarly, sera [177] propag to the last batch onli minor class that 

belong to the same concept use mahalanobi distance. hoen and chawla [148] use 

instead an instanc propag mechan base on a naïv bay classifier. In thi 

case, naïv bay be use to select old posit instanc which be relev to the current 

minor class context. thi method reli on find instanc that be similar to the 

current minor class context. 

wang, minku and yao [178] propos sampling-bas onlin bag (sob) to deal 

with unbalanc data streams. their algorithm, be essenti a modif of onlin 

bag [179], in which the sampl rate of the instanc belong to one class be deter- 

mine adapt base on the current imbal statu and classif performance. 

the problem with thi approach be that it be not design to handl CD a it aim to 

maxim g-mean greedili over all receiv exampl [178]. 

3.4 algorithm solut for fraud detect 

In the literature, both supervis [64, 180, 181] and unsupervis [11, 182] ML algo- 

rithm have be propos for credit card fraud detection. As explain in section 2.1, 



chapter 3. state-of-the-art 48 

supervis techniqu assum the avail of annot datasets, i.e. transact la- 

bele a genuin or fraudulent. In thi case a model be train under the supervis 

of the class inform to discov pattern associ to the fraudul and genuin 

class. On the contrary, unsupervis method work with dataset that contain unlabel 

samples. these method consist in outlier detect or anomali detect techniqu 

that associ fraudul behaviour to ani transact that do not conform to the 

majority, without knowledg on transact class [11]. unsupervis techniqu usual 

gener too mani fals alert so it be often a good idea to combin both supervis and 

unsupervis method a in [62]. 

the detect problem can be see from the transact and card level. At the card 

level be possibl to group transact from the same card and learn behavior model 

of individu cards. behavior model be typic unsupervis method that aim to 

character the genuin behavior of each individu card over the time. these model 

onli consid the previou histori of each card but do not attempt to identifi global 

pattern of fraudul behaviors; they onli tri to detect chang in behavior. exampl 

of these be give by fawcett and provost [183], bolton [11] and weston [184]. the 

problem with thi approach be that a chang in behavior may not be due to fraud. for 

example, the chang in spend behavior dure holiday season may be not necessari 

link to fraudul activities. 

model that oper at the transact level tri to differenti legitim transac- 

tion from fraudul one without know the behavior of a card. these customer- 

independ model can serv a a second line of defense, the first be customer- 

depend model (behavior models). thi strategi consid onli transact in 

isol from each other. neither the previou histori of the associ account, nor 

other transact be take into consideration. alternatively, it be possibl to work at 

the transact level and includ custom behavior in the model by use aggreg 

variabl of the cardhold a present in section 2.2.2. 

3.4.1 supervis approach 

In supervis algorithm fraudul and non-fraudul exampl be use to predict the 

class of a new observation. supervis techniqu develop for fraud detect can be 

group into: i) supervis profiling, ii) classification, iii) cost-sensit and iv) network 

methods. 



chapter 3. state-of-the-art 49 

supervis profil 

when label transact be available, it be possibl to profil the distribut of rel- 

evant variabl for genuin and fraudul card [185]. thi mean that it be possibl 

to creat differ profil for each class. At thi point everi new transact can be 

compar to see which profil be more similar. for example, siddiqi [186] propos to 

use weight Of evid (woe) a similar measur between two profil in credit 

risk. the same metric can be use to compar the genuin and fraudul profil [185]. 

profil can also be creat use rule-bas methods. 

rule can come from human expert or from statist model and they have the advan- 

tage of be easi to understand and to implement. A set of rule be defin for each 

profil and if a new transact match these rule it be assum to have the same pro- 

file. chan [181] for instanc us rule to filter out safe transactions. An adapt user 

profil method be propos by fawcett and provost [187] but for telecommun 

frauds. cort [188] defin an account signatur for profil account in data streams. 

As the crimin activ and legitim user-behavior evolves, fraudul profil have to 

be updat a well. thi mean that statistical-bas rule have to be updat periodi- 

cally. altern a weight ensembl approach can be use to includ new rule while 

maintain old rule [189]. profil must be updat to reflect the dynam pattern of 

crimin activ a well a chang in legitim user behavior. thi present a chal- 

leng for static rule-bas method that be learn off-line, a they must be frequent 

valid and retrained. 

classif 

classif appear to be the standard way to approach fraud detect [190] and 

sever classif algorithm have be used, e.g. neural network [180, 191–193], 

logist regress [65], associ rule [194], support vector machin [63], fisher 

discrimin analysi [69], and decis tree [19, 68, 70]. 

decis tree have found mani applic in fraud detection, for both credit card 

fraud detect [126] and credit risk score [195]. neural network a well have be 

extens appli in detect system such a falcon [196], minerva (dorronsoro [193]), 

fd [191], cardwatch [192] and visa [197]. dorronsoro [193] show that a three-lay net 

be capabl of deal with the highli skew class distributions. however, a explain in 

section 3.1, supervis method in gener suffer from the problem of unbalanc class 

sizes: the legitim transact gener far outnumb the fraudul ones. 



chapter 3. state-of-the-art 50 

neural network be abl to learn difficult class boundaries, but they be black-box a 

it be not possibl for a human be to understand how they behave. rule extract 

and decis tree be wide use in fraud detect becaus unlik black-box techniqu 

allow a good grasp of the classification. thi be import because, often, the analyst 

be not machin learn specialist and need to understand classif mechan 

in order to trust and use them. these approach be often base on the extract 

of conjunct and disjunct of rule that be represent of the choic of the 

classif and directli understandable. 

probabilist graphic model be use a well in fraud detect such a bayesian 

belief network [185]. card’ activ can be model use a hidden markov models. 

sudjianto [185] show that be possibl to use hmm to monitor transact of a card 

defin differ statu of a card. finally, between all the algorithm propos in the 

literature, we recommend use random forest, becaus sever studi have show that 

it achiev the best result among differ classifi [18, 20, 61, 63, 64, 71]. 

cost-sensit method 

sinc busi be interest in reduc the monetari loss due to fraudul activities, 

there be a larg bodi of work on cost-sensit classifiers. these method be also call 

cost-sensit algorithms, becaus they be abl to take into account the differ cost in 

misclassifi a transact a fraud or legitimate. As show in section 3.1.2, cost-sensit 

learn [78], [35] be an altern way to deal with the unbalanc problem that consist 

into assign larg cost to error make on the minor class. mani cost-sensit algo- 

rithm avail in the literatur be base on boosting; see for exampl asymboost [198], 

adacost [126], csb [199], databoost [45], adauboost [200] and smoteboost [122]. 

tradit cost-sensit learn such a adacost [126] assum that the cost be 

fix and class-dependent, howev in fraud detect the cost be proport to the 

transact amount. the larg the amount, the great the potenti loss in case of 

fraud. In these set the cost of miss a fraud (a fals negative) be not fixed, 

but proport to the transact amount. exampl of cost-sensit classifi us- 

ing transaction-depend cost be [68–70]. mahmoudi and duman [69] use modifi 

fisher discrimin analysi to consid example-depend cost for each transact 

to maxim total profit. similarli bahnsen et al. [70] and sahin et al.[68] use example- 

depend cost-sensit decis tree for maxim the savings. cost-bas method 

be use when the primari goal be to minim some cost / maxim the benefit of the 

detect or save sinc the loss function take into account the financi loss occur 

in each prediction. 



chapter 3. state-of-the-art 51 

given the high cost of misclassifi a fraud than a genuin transaction, cost-bas 

algorithm could in principl prefer to produc a fals alert rather than take the risk to 

predict a transact a legitim when it be not. As a consequence, these algorithm 

can gener mani fals posit and be of no practic use for investig who requir 

precis alert (see section 2.2.1). 

detect of fraud network 

the detect of link between data can also lead to fraud discovering. for example, in 

the telecommun domain, expert have notic that a fraudul account be often 

connect to anoth by some call give between fraudsters. By analyz these links, 

they discov fraud networks. such approach seem complementari to individu fraud 

detect [201]. 

when the fraudul activ be spread over mani transact and card, illeg activ 

can be uncov by analyz pattern of relat transactions. In particular link analysi 

and graph mine method may be abl to detect these group of fraudul transact 

[185]. recent van vlassela et al. [61] have propos apate, a framework for credit 

card fraud detect that allow includ network inform a addit featur to 

the origin featur vector describ a transaction. they show that featur includ 

network inform be abl to improv significantli the perform of a standard 

supervis algorithm. 

3.4.2 unsupervis approach 

unsupervis method be use when there be no prior set of legitim and fraudul 

observations. sinc they be not base on exampl of fraud or genuin transactions, 

unsupervis strategi have the advantag of be independ of their selection, and 

be able, in theory, to discov fraud still unobserved, that have not be detect by 

an expert. yet they be not affect by the problem of mislabel dataset and class 

imbalance. howev unsupervis credit card fraud detect have not receiv a lot of 

attent in the literatur [11]. 

techniqu employ in fraud detect be usual a combin of profil and outlier 

detect methods. they model a baselin distribut that repres normal behavior 

and then attempt to detect observ that show the great departur from thi norm 

[202]. one of these method be peer group analysi [184] which cluster custom into 

differ profil and identifi fraud a transact depart from the custom profil 



chapter 3. state-of-the-art 52 

(see also the recent survey by phua [203]). other model cardhold behavior by mean 

of self-organ map [5, 204, 205]. 

In order to detect outlier or anomali it be import first to defin when an exampl 

be an outlier. grubb [206] give the follow definition: “an outli observation, or 

outlier, be one that appear to deviat markedli from other member of the sampl in 

which it occurs”. for barnett & lewi [207] an outlier is: “an observ (or subset of 

observations) which appear to be inconsist with the remaind of that set of data”. 

when it be possibl to defin a region or distribut of the data repres the normal 

behavior then all observ fall outsid can be flag a outlier. thi approach 

howev come with sever challenges: i) defin a normal region which encompass 

everi possibl normal behavior be veri difficult, ii) normal behavior keep evolv and 

an exist notion of normal behavior might not be suffici repres in the 

future, iii) the boundari between normal and outli behavior be often fuzzy, iv) fraud 

adapt themselv to make the outli observ appear like normal, therebi make 

the task of defin normal behavior more difficult and v) data contain nois which be 

similar to the actual outliers. 

In gener we can distinguish between two form of outliers: local and global outliers. A 

global outlier be an observ anomal to the entir data set. In the case of fraud 

detection, an exampl of global outlier can be a transact of e 10000 when all the other 

transact in the dataset have small amount. A local outlier be an observ that 

look anomal when compar to subgroup of the data. when a card be mostli use 

in a restrict geograph area, a purchas make by the same card in foreign countri be 

a local outlier within it transactions, but be not anomal with respect to all possibl 

transactions. depend on the type of outlier that we want to detect we can use local 

and global approaches. 

local approach 

In [209], the author aim to detect outlier by analyz local inform of the space. 

To achiev this, they introduc the notion of rough membership function that comput 

the degre of devianc of data, depend on the densiti of it local neighborhood. 

In [11], bolton et al. have base their work on the hypothesi that a fraud differ 

accord to the consid data, similarli to what be propos in [187, 210]. the idea of 

peer group analysi [11] be that time seri that be in some sens similar be group 

togeth to form a peer group. transact that deviat strongli from their peer group 

be flag a potenti fraudulent. the behaviour of the peer group be summar 



chapter 3. state-of-the-art 53 

at each subsequ time point and the behaviour of a time seri compar with the 

summari of it peer group. the author present their analysi more a a way to alert 

investig of anomal data than a a fraud classifier. In the paper, the author 

consid time seri of data that be cluster on the basi a distanc function in group 

of defin size. they next propos to resum each group by a model and then comput 

their deviance. they final present result in a graph style that allow visual 

breakpoints. thi approach be interest becaus it be understand and it be not 

base on an annot set. It be then, a-priori, capabl to detect ani kind of fraud. 

global approach 

the work present in [211] address high dimension spaces. In thi kind of spaces, 

ani observ can be consid a an outlier becaus of the sparsiti of the data. the 

author propos to project data in few dimens space to avoid these phenomenon 

and studi the densiti of distribut to detect frauds. they split the origin space into k 

subspac of same depth on each dimens and then tri to combin these space to form 

hypercub of dimens n (n littl enough) that be of a particularli weak density. To 

combin dimens the best, they use an evolutionari approach that combin randomli 

dimens to extract the best candidates. experiment result show a qualiti close to 

systemat approach and a good qualiti of detection. anoth benefit of thi approach 

is, by project data, it be capabl to deal with data have miss attributes. it 

drawback be again it rendering, even if the select dimens can partial explain the 

analysis. 

In [212], the question be to detect outlier in data have categor attributes. the 

author formal the problem thi way: “find a small subset of a target dataset such 

that the degre of disord of the result dataset after the remov of thi subset be 

minimized”. thi degre of “disorder” be measur with the entropi of the dataset. their 

techniqu aim to detect the k most deviant outlier in the dataset. they estim that 

thi paramet be not hard to defin because, accord to them, the problem be give thi 

way in concret case (find for exampl the 5% of fraudsters). they develop an iter 

algorithm that tri to optim the set by minim the entropy. thi approach, which 

could appear expensive, be in fact estim experiment a almost linear w.r.t. the 

size of the dataset and the number of outlier to extract (k). result be interest 

though the author make the strong assumpt that attribut be independent. 





part II 

contribut 

55 





chapter 4 

techniqu for unbalanc 

classif task 

result present in thi chapter have be publish in the follow papers: 

• andrea dal pozzolo, olivi caelen, and gianluca bontempi. when be under- 
sampl effect in unbalanc classif tasks?. In european confer on 

machin learning. ecml-kdd, 2015. 

• andrea dal pozzolo, olivi caelen, reid A. johnson and gianluca bontempi. 
calibr probabl with undersampl for unbalanc classification. In sym- 

posium on comput intellig and data mine (cidm). ieee, 2015. 

• andrea dal pozzolo, olivi caelen, serg waterschoot, gianluca bontempi, rac- 
ing for unbalanc method selection. proceed of the 14th intern con- 

ferenc on intellig data engin and autom learn (ideal), ieee, 

2013 

the chapter be divid into three main parts. the first part of the chapter (section 4.1) 

be base on [213] and it analysi a well-known techniqu call undersampl (see sec- 

tion 3.1.1), which consist into rebalanc (typic by resampling) of the class befor 

proceed with the learn of the classifier. though thi seem to work for the major 

of cases, no detail analysi exist about the impact of undersampl on the accuraci 

of the final classifier. In particular we will propos a theoret analysi specifi under 

which condit undersampl be recommend and expect to be effective. 

In the second part of the chapter (section 4.2), which be base on [28], we show how 

sampl data use to train a model induc an artifici bia into the comput poste- 

rior probabilities, for which we show a correct method. although thi bia do not 

57 



chapter 4. techniqu for unabalanc classif task 58 

affect the rank order return by the posterior probability, it significantli impact the 

classif accuraci and probabl calibration. We use bay minimum risk theori 

to find the correct classif threshold and show how to adjust it after undersampling. 

finally, the third part of the chapter (section 4.3) be base on [27]. In thi section, we 

propos to use a race algorithm to select adapt the most appropri strategi for 

a give unbalanc task. race allow one to test rapidli a larg set of altern and 

we use it to compar undersampl against a larg set of techniqu for unbalanc 

classification. however, a confirm by our experiment comparison, no techniqu 

appear to work consist good in all conditions. the result show that race be 

abl to adapt the choic of the strategi to the specif natur of the unbalanc problem 

and to select rapidli the most appropri strategi without compromis the accuracy. 

4.1 when be undersampl effect in unbalanc classifi- 

cation tasks? 

when the data be unbalanced, standard machin learn algorithm that maxim over- 

all accuraci tend to classifi all observ a major class instances. thi translat 

into poor accuraci on the minor class (low recall), which be typic the class of inter- 

est. degrad of classif perform be not onli relat to a small number of 

exampl in the minor class in comparison to the number of exampl in the major 

class (express by the class imbal ratio), but also to the minor class decompo- 

sition into small sub-clust [214] (also know in the literatur a small disjunct [80]) 

and to the overlap between the two class [84, 215–217]. In these studi it emerg 

that perform degrad be strongli caus by the presenc of both unbalanc 

class distribut and a high degre of class overlap. additionally, in unbalanc clas- 

sific tasks, the perform of a classifi be also affect by the presenc of noisi 

exampl [218, 219]. 

one possibl way to deal with thi issu be to adjust the algorithm themselv [77, 78, 82]. 

here we will consid instead a data-level strategi know a undersampl [21]. In an 

unbalanc problem, it be often realist to assum that mani observ of the major 

class be redund and that by remov some of them at random the data distribut 

will not chang significantly. nevertheless, the risk of remov relev observ 

from the dataset be still present, sinc the remov be perform in an unsupervis 

manner. In practice, sampl method be often use to balanc dataset with skew 

class distribut becaus sever classifi have empir show good perform 

when train on balanc dataset [88, 90]. however, these studi do not impli that 



chapter 4. techniqu for unabalanc classif task 59 

undersampling-- 

unbalanced- balanced- 

figur 4.1: undersampling: remov major class observ until we have the 
same number of instanc in the two classes. 

classifi cannot learn from unbalanc datasets. for instance, other studi have also 

show that some classifi do not improv their perform when the train dataset 

be balanc use sampl techniqu [82, 106]. As a result, for the moment the onli 

way to know if sampl help the learn process be to run some simulations. despit 

the popular of undersampling, we have to remark that there be not yet a theoret 

framework explain how it can affect the accuraci of the learn process. 

In thi chapter we aim to analyz the role of the two side effect of undersampl on 

the final accuracy. the first side effect be that, by remov major class instances, 

we perturb the a priori probabl of the train set and we induc a warp in the 

posterior distribut [35, 134]. the second be that the number of sampl avail for 

train be reduc with an evid consequ in term of accuraci of the result 

classifier. We studi the interact between these two effect of undersampl and we 

analyz their impact on the final rank of posterior probabilities. In particular we show 

under which condit an undersampl strategi be recommend and expect to be 

effect in term of final classif accuracy. 

4.1.1 the warp effect of undersampl on the posterior probabl 

let u consid a binari classif task f : Rn → {0, 1}, where X ∈ Rn be the 
input and Y ∈ {0, 1} be the output. In the follow we will also use the label neg 
(resp. positive) to denot the label 0 (resp. 1). suppos that the train set TN = 

{(x1, y1), . . . , (xn , yN )} of size N be unbalanc (i.e. the number N+ of posit case be 
small compar to the number N− of neg ones) and that rebalanc be perform 

by undersampling, i.e. the result dataset contain a subset of the negatives. let u 

introduc a random binari select variabl s associ to each sampl in TN , which 

take the valu 1 if the point be sampl and 0 otherwise. We now deriv how the 

posterior probabl of a model learn on a balanc subset relat to the one learn 

on the origin unbalanc dataset, on the basi of [149]. let u assum that the select 



chapter 4. techniqu for unabalanc classif task 60 

variabl s be independ of the input x give the class y (class-depend selection): 

p(s|y, x) = p(s|y) (4.1) 

where p( = 1|y, x) be the probabl that a sampl (x, y) be includ in the balanc 
train sample. thi assumpt impli p(x|y, s) = p(x|y), i.e. by remov observa- 
tion at random in the major class we do not chang within-class distributions. with 

undersampl there be a chang in the prior probabl (p(y| = 1) 6= p(y)) and a 
a consequ the class-condit probabl be differ a well, p(y|x, s = 1) 6= 
p(y|x). let the sign + denot y = 1 and − denot y = 0, e.g. p(+|x) = p(i = 1|x) 
and p(−|x) = p(i = 0|x). from bayes’ rule we can write: 

p(+|x, s = 1) = p( = 1|+, x)p(+|x)p( = 1|+, x)p(+|x) + p( = 1|−, x)p(−|x) (4.2) 

use condit (4.1) in (4.2) we obtain: 

p(+|x, s = 1) = p( = 1|+)p(+|x)p( = 1|+)p(+|x) + p( = 1|−)p(−|x) (4.3) 

with undersampl we keep all posit and a subset of neg (see figur 4.1), 

therefor we have: 

p( = 1|+) = 1 (4.4) 

and 
p(+) 
p(−) ≤ p( = 1|−) < 1 (4.5) 

note that if we set p( = 1|−) = p(+)p(−) , we obtain a balanc dataset where the number of 
posit and neg instanc be the same. At the same time, if we set p( = 1|−) = 1, 
no neg instanc be remov and no undersampl take place. use (4.4), we 

can rewrit (4.3) a 

p(+|x, s = 1) = p(+|x)p(+|x) + p( = 1|−)p(−|x) (4.6) 

let u denot β = p( = 1|−) a the probabl of select a neg instanc with 
undersampling, p = p(+|x) a the true posterior probabl of class + on the origi- 
nal dataset, and p = p(+|x, s = 1) a the true posterior probabl of class + after 
sampling. We can rewrit equat (4.6) as: 

p = 
p 

p+ β(1− p) (4.7) 



chapter 4. techniqu for unabalanc classif task 61 

equat (4.7) quantifi the amount of warp of the posterior probabl due to 

undersampling.1 from it, we can deriv p a a function of ps: 

p = 
βp 

βp − p + 1 
(4.8) 

the relat between p and p (parametr in β) be illustr in figur 4.2. the top 

figur 4.2: p and p at differ β. when β be low, undersampl be strong, which 
mean it be remov a lot of negatives, while for high valu the remov be less strong. 

low valu of β lead to a more balanc problem. 

curv of figur 4.2 refer to the complet balanc which correspond to β = p(+)p(−) ≈ N 
+ 

N− , 

assum that N 
+ 

N− provid an accur estim of the ratio of the prior probabilities. 

figur 4.4 illustr the warp effect for two univari (n = 1) classif task 

(see figur 4.3). In both task the two class be normal distribut (x− ∼ N (0, σ) 
and X+ ∼ N (µ, σ)), σ = 3 and p(+) = 0.1 but the degre of separ be differ (on 
the left larg overlap for µ = 3 and on the right small overlap for µ = 15). It be easi to 

remark that the warp effect be larg in the low separ case. 

As a final remark, consid that when β = N 
+ 

N− , the warp due to undersampl map 

two close and low valu of p into two valu p with a larg distance. the opposit 

occur for high valu of p. In section 4.1.3 we will show how thi have an impact on the 

rank return by estim of p and ps. 
1in the case of oversampl it can be show that p = αpαp+1−p , where α denot the number of 

time a posit instanc be replicated. the larg the class imbalanced, the larg α have to be in order 
to obtain a balanc distribution. 



chapter 4. techniqu for unabalanc classif task 62 

3 15 

0 

500 

1000 

1500 

−10 0 10 20 −10 0 10 20 
x 

C 
ou 

nt class 
0 
1 

figur 4.3: synthet dataset with posit and neg observ sampl from 
two differ normal distributions. posit account for 10% of the 10,000 random 
values. On the left we have a difficult problem with overlap class (µ = 3), on the 

right an easi problem where the class be well-separ (µ = 15). 

figur 4.4: posterior probabl p a a function of β for two univari binari 
classif task with norm class condit densiti X− ∼ N (0, σ) and X+ ∼ 
N (µ, σ) (on the left µ = 3 and on the right µ = 15, in both exampl σ = 3). note 

that the origin probabl p correspond to p when β = 1. 

4.1.2 warp and class separ 

In thi section we be go to show how the impact of warp depend on the sepa- 

rabil natur of the classif task. let ω+ and ω− denot the class condit 

probabl p(x|+) and p(x|−), and π+ (π+ ) the class prior befor (after) under- 
sampling. It be possibl to deriv the relat between the warp and the differ 

δ = ω+−ω− between the class condit distributions. from bayes’ theorem we have: 

p = 
ω+π+ 

ω+π+ + ω−π− 
(4.9) 

suppos δ = ω+ − ω−, we can write (4.9) as: 

p = 
ω+π+ 

ω+π+ + (ω+ − δ)π− = 
ω+π+ 

ω+(π+ + π−)− δπ− = 
ω+π+ 

ω+ − δπ− (4.10) 



chapter 4. techniqu for unabalanc classif task 63 

figur 4.5: ps−p a a function of δ, where δ = ω+−ω− for valu of ω+ ∈ {0.01, 0.1} 
when π+ = 0.5 and π+ = 0.1. note that δ be upper bound to guarante 0 ≤ p ≤ 1 

and 0 ≤ p ≤ 1. 

sinc π+ + π− = 1. similarly, sinc ω+ do not chang with undersampling: 

p = 
ω+π+ 

ω+ − δπ− 
(4.11) 

now we can write p − p as: 

p − p = 
ω+π+ 

ω+ − δπ− 
− ω 

+π+ 

ω+ − δπ− (4.12) 

sinc p ≥ p becaus of (4.7), 0 ≤ p ≤ 1 and 0 ≤ p ≤ 1 we have: 0 ≤ p − p ≤ 1. In 
figur 4.5 we plot p − p a a function of δ when π+ = 0.5 and π+ = 0.1. for small 
valu of the class condit densiti it appear that the differ have the high 

valu for δ valu close to zero. thi mean that the warp be high for similar class 

condit probabl (i.e. low separ configurations). 

4.1.3 the interact between warp and varianc of the estim 

section 4.1.1 discuss the first consequ of undersampling, i.e. the transform of 

the origin condit distribut p into a warp condit distribut p accord 

to equat (4.7). the second consequ of undersampl be the reduct of the 

train set size, which inevit lead to an increas of the varianc of the classifier. 

thi section discu how these two effect interact and their impact on the final accuraci 

of the classifier, by focu in particular on the accuraci of the rank of the minor 

class (typic the class of interest). 

undersampl transform the origin classif task (i.e. estim the condit 

distribut p) into a new classif task (i.e. estim the condit distribut 

ps). In what follow we aim to ass whether and when undersampl have a benefici 

effect by chang the target of the estim problem. 



chapter 4. techniqu for unabalanc classif task 64 

let u denot by p̂ (resp. p̂s) the estim of the condit probabl p (resp. ps). 

assum we have two distinct test point have probabl p1 < p2 where ∆p = p2−p1 
with ∆p > 0. A correct classif aim to rank the most probabl posit sampl 

should rank p2 befor p1, sinc the second test sampl have an high probabl of 

belong to the posit class. unfortun the valu p1 and p2 be not know and 

the rank should reli on the estim valu p̂1 and p̂2. for the sake of simplic we 

will assum here that the estim of the condit probabl have the same bia and 

varianc in the two test points. thi impli p̂1 = p1 + �1 and p̂2 = p2 + �2, where �1 and 

�2 be two realiz of the random variabl ε ∼ N (b, ν) where b and ν be the bia 
and the varianc of the estim of p. note that the estim error �1 and �2 may 

induc a wrong rank if p̂1 > p̂2. 

what happen if instead of estim p we decid to estim ps, a in undersampling? 

note that becaus of the monoton transform (4.7), p1 < p2 ⇒ ps,1 < ps,2. Is the 
rank base on the estim of ps,1 and ps,2 more accur than the one base on 

the estim of p1 and p2? 

In order to answer thi question let u suppos that also the estim of p be bia but 

that it varianc be larg give the small number of samples.2 then p̂s,1 = ps,1 + η1 
and p̂s,2 = ps,2 + η2, where η ∼ N (bs, νs), νs > ν and ∆p = ps,2 − ps,1. let u now 
comput the deriv of p w.r.t. p. from (4.7) we have: 

dp 
dp 

= 
β 

(p+ β(1− p))2 (4.13) 

correspond to a concav function. In particular for p = 0 we have dp = 1βdp, while 

for p = 1 it hold dp = βdp. We will now show that dpsdp be bound in the rang [β, 
1 
β ]. 

let λ be the valu of p for which dpsdp = 1: 

λ = 

√ 
β − β 

1− β 

from (4.13) we have 

1 < 
dp 
dp 

< 
1 

β 
, when 0 < p < λ 

and 

β < 
dp 
dp 

< 1 when λ < p < 1. 

It follow that: 

β ≤ dp 
dp 
≤ 1 
β 

(4.14) 

2it be well-known that train a classifi on a reduc dataset lead to probabl estim with 
larg varianc [220]. 



chapter 4. techniqu for unabalanc classif task 65 

let u now suppos that the quantiti ∆p be small enough to have an accur approxi- 

mation ∆ps∆p ≈ 
dp 
dp . We can defin the probabl of obtain a wrong rank of p̂1 and 

p̂2 as: 

p(p̂2 < p̂1) = p(p2 + �2 < p1 + �1) 
= p(�2 − �1 < p1 − p2) = p(�1 − �2 > ∆p) 

where �2 − �1 ∼ N (0, 2ν).3 By make a hypothesi of normal we have 

p(�1 − �2 > ∆p) = 1− Φ 
( 

∆p√ 
2ν 

) 
(4.15) 

where Φ be the cumul distribut function of the standard normal distribution. 

similarly, the probabl of a rank error with undersampl is: 

p(p̂s,2 < p̂s,1) = p(η1 − η2 > ∆ps) 

and 

p(η1 − η2 > ∆ps) = 1− Φ 
( 

∆ps√ 
2ν 

) 
(4.16) 

We can now say that a classifi learn after undersampl have good rank w.r.t. a 

classifi learn with unbalanc distribut when 

p(�1 − �2 > ∆p) > p(η1 − η2 > ∆ps) (4.17) 

or equival from (4.15) and (4.16) when 

1− Φ 
( 

∆p√ 
2ν 

) 
> 1− Φ 

( 
∆ps√ 

2ν 

) 
⇐⇒ Φ 

( 
∆p√ 

2ν 

) 
< Φ 

( 
∆ps√ 

2ν 

) 
which boil down to 

∆p√ 
2ν 

< 
∆ps√ 

2ν 
⇐⇒ ∆p 

∆p 
> 

√ 
νs 
ν 
> 1 (4.18) 

sinc Φ be monoton non decreas and we have assum that νs > ν. then from (4.18), 

it follow that undersampl be use in term of more accur rank if: 

dp 
dp 

> 

√ 
νs 
ν 

(4.19) 

or, use (4.13), when: 
β 

(p+ β(1− p))2 > 
√ 
νs 
ν 

(4.20) 

3we assum that the bia of p̂1 and p̂2 be similar: e[�2 − �1] = b2 − b1 = 0. 



chapter 4. techniqu for unabalanc classif task 66 

(a) (b) 

figur 4.6: left: dpsdp a a function of p. right: 
dp 
dp a a function of β 

the valu of thi inequ depend on sever terms: the rate of undersampl β, the 

ratio of the varianc of the two classifi and the posteriori probabl p of the test 

point. also the nonlinear of the first left-hand term suggest a complex interact 

between the involv terms. for instanc if we plot the left-hand term of (4.20) a a 

function of the posteriori probabl p (figur 4.6(a)) and of the valu β (figur 4.6(b)), 

it appear that the most favor configur for undersampl occur for the low 

valu of the posteriori probabl (e.g. non separ or badli separ configurations) 

and intermedi β (neither too unbalanc nor too balanced). howev if we modifi 

β, thi have an impact on the size of the train set and consequ on the right-hand 

term (i.e. varianc ratio) too. also, though the design can control the β term, the 

other two term vari over the input space. thi mean that the condit (4.20) do 

not necessarili hold for all the test points. 

In order to illustr the complex of the interaction, let u consid two univari 

(n = 1) classif task where the minor class be normal distribut around zero 

and the major class be distribut a a mixtur of two gaussians. figur 4.7 and 4.8 

show the non separ and separ case, respectively: on the left side we plot the 

class condit distribut (thin lines) and the posterior distribut of the minor 

class (thicker line), while on the right side we show the left and the right term of the 

inequ (4.20) (solid: left-hand term, dotted: right-hand term). what emerg form 

the figur be that the least separ region (i.e. the region where the posteriori of the 

minor class be low) be also the region where undersampl help more. however, 

the impact of undersampl on the overal accuraci be difficult to be predict sinc 

the region where undersampl be benefici chang with the characterist of the 

classif task and the rate β of undersampling. 



chapter 4. techniqu for unabalanc classif task 67 

−2 −1 0 1 2 

0. 
0 

0. 
2 

0. 
4 

0. 
6 

0. 
8 

1. 
0 

1. 
2 

x 

Po 
st 

er 
io 

r p 
ro 

ba 
bi 

lit 
y 

(a) class condit distribut (thin lines) and 
the posterior distribut of the minor class 
(thicker line). 

(b) dp 
dp 

(solid lines), 
√ 

νs 
ν 

(dot lines). 

figur 4.7: non separ case. On the right we plot both term of inequ 4.20 
(solid: left-hand, dotted: right-hand term) for β = 0.1 and β = 0.4 

−2 −1 0 1 2 

0. 
0 

0. 
2 

0. 
4 

0. 
6 

0. 
8 

1. 
0 

1. 
2 

x 

Po 
st 

er 
io 

r p 
ro 

ba 
bi 

lit 
y 

(a) class condit distribut (thin lines) and 
the posterior distribut of the minor class 
(thicker line). 

(b) dp 
dp 

(solid lines), 
√ 

νs 
ν 

(dot lines). 

figur 4.8: separ case. On the right we plot both term of inequ 4.20 (solid: 
left-hand, dotted: right-hand term) for β = 0.1 and β = 0.4 

4.1.4 experiment valid 

In thi section we ass the valid of the condit (4.20) by perform a number of 

test on synthet and real datasets. We first simul two unbalanc synthet task 

(5% and 25% of posit samples) with overlap class and gener a test set 

and sever train set from the same distribution. figur 4.9(a) and figur 4.11(a) 

show the distribut of the test set for the two tasks. 

In order to comput the varianc of p̂ and p̂ in each test point, we gener 1000 time 

a train set and we estim the condit probabl on the basi of sampl mean 

and covariance. 



chapter 4. techniqu for unabalanc classif task 68 

In figur 4.9(b) (first task) we plot 
√ 

νs 
ν (dot line) and three percentil (0.25, 0.5, 0.75) 

of dpsdp vs. the rate of undersampl β. It appear that for at least 75% of the test 

points, the term dpsdp be high than 
√ 

νs 
ν . In figur 4.10(a) the point surround with 

a triangl be those one for which dpsdp > 
√ 

νs 
ν hold when β = 0.053 (balanc dataset). 

for such sampl we expect that rank return by undersampl (i.e. base on p̂ ) 

be good than the one base on the origin data (i.e. base on p̂). the plot show that 

undersampl be benefici in the region where the major class be situated, which be 

also the area where we expect to have low valu of p. figur 4.10(b) show also that 

thi region move toward the minor class when we do undersampl with β = 0.323 

(90% negatives, 10% posit after undersampling). 

● 

● 

●● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● ● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 
● 

● 

● 

● 

● ● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● ● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 

● 

● 
● 

● 
● 

● 

● 

● 
● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

●● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● ● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 
● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● ● 

● 

● 

● 

● 

● 

● ● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● ● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● ● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● ● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● ● 

● 

● 

● 

● 

●● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 
● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● ● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● ● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

0 

5 

10 

15 

20 

0 5 10 15 

X1 

X 
2 

class 

● 

● 

0 

1 

(a) synthet dataset 1 (b) 
√ 

νs 
ν 

and dp 
dp 

for differ β 

figur 4.9: left: distribut of the test set where posit account for 5% of the 
total. right: plot of dpsdp percentil (25 

th, 50th and 75th) and of 
√ 

νs 
ν (black dashed). 

In order to measur the qualiti of the rank base on p̂ and p̂ we comput the kendal 

rank correl of the two estim with p, which be the true posterior probabl of 

the test set that defin the correct ordering. In tabl 4.1 we show the rank 

correl of p̂ (and p̂) with p for the sampl where the condit (4.20) (first five 

rows) hold and where it do not (last five rows). the result indic that point for 

which condit (4.20) be satisfi have inde good rank with p̂ than p̂. 

We repeat the experi for the second task have a larg proport of posit 

(25%) (dataset 2 in figur 4.11(a)). from the figur 4.11(b), plot dpsdp and 
√ 

νs 
ν a 

a function of β, it appear that onli the first two percentil be over 
√ 

νs 
ν . thi mean 

that less point of the test set satisfi the condit (4.20). thi be confirm from 

the result in tabl 4.2 where it appear that the benefit due to undersampl be less 

signific than for the first task. 



chapter 4. techniqu for unabalanc classif task 69 

(a) undersampl with β = 0.053 (b) undersampl with β = 0.323 

figur 4.10: region where undersampl should work. triangl indic the test 
sampl where the condit (4.20) hold for the dataset in figur 4.9. 

tabl 4.1: classif task in figur 4.9: rank correl between the poste- 
rior probabl p̂ (p̂s) and p for differ valu of β. the valu K (ks) denot the 
kendal rank correl without (with) undersampling. the first (last) five line refer 

to sampl for which the condit (4.20) be (not) satisfied. 

β K Ks Ks −K %point satisfi (4.20) 
0.053 0.298 0.749 0.451 88.8 
0.076 0.303 0.682 0.379 89.7 
0.112 0.315 0.619 0.304 91.2 
0.176 0.323 0.555 0.232 92.1 
0.323 0.341 0.467 0.126 93.7 
0.053 0.749 0.776 0.027 88.8 
0.076 0.755 0.773 0.018 89.7 
0.112 0.762 0.764 0.001 91.2 
0.176 0.767 0.761 -0.007 92.1 
0.323 0.768 0.748 -0.020 93.7 

now we ass the valid of the condit (4.20) on a number of real unbalanc binari 

classif task obtain by transform some dataset from the uci repositori [1] 

(tabl 4.3)4. 

given the unavail of the condit posterior probabl function, we first ap- 

proxim p by fit a random forest over the entir dataset in order to comput the 

left-hand term of (4.20). then we use a bootstrap procedur to estim p̂ and appli 
4 transform dataset be avail at http://www.ulb.ac.be/di/map/adalpozz/ 

imbalanced-datasets.zip 

http://www.ulb.ac.be/di/map/adalpozz/imbalanced-datasets.zip 
http://www.ulb.ac.be/di/map/adalpozz/imbalanced-datasets.zip 


chapter 4. techniqu for unabalanc classif task 70 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 
● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● ● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● ● 

● 

● 

● 

●● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

●● 

● 
● 

● 

● ● 

● 

● 

● 

● 

● 

● 

●● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 

● 

● 

● 

● 

● 

● 
● 

● ● 

● 

● 

● 

● ● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● ● 

● 

● 

● 
● 

● 

● 

● ● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

●● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● ● 

● 

● 

● 

● 

● ● 
● 

● 

● 

● 
● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● ● 

● ● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

−5 

0 

5 

10 

15 

0 10 20 

X1 

X 
2 

class 

● 

● 

0 

1 

(a) synthet dataset 2 (b) 
√ 

νs 
ν 

and dp 
dp 

for differ β 

figur 4.11: left: distribut of the test set where posit account for 25% 
of the total. right: plot of dpsdp percentil (25 

th, 50th and 75th) and of 
√ 

νs 
ν (black 

dashed). 

tabl 4.2: classif task in figur 4.11: rank correl between the pos- 
terior probabl p̂ (p̂s) and p for differ valu of β. the valu K (ks) denot the 
kendal rank correl without (with) undersampling. the first (last) five line refer 

to sampl for which the condit (4.20) be (not) satisfied. 

β K Ks Ks −K % point satisfi (4.20) 
0.333 0.586 0.789 0.202 66.4 
0.407 0.588 0.761 0.172 66.6 
0.500 0.605 0.738 0.133 68.1 
0.619 0.628 0.715 0.087 70.3 
0.778 0.653 0.693 0.040 73 
0.333 0.900 0.869 -0.030 66.4 
0.407 0.899 0.875 -0.024 66.6 
0.500 0.894 0.874 -0.020 68.1 
0.619 0.885 0.869 -0.016 70.3 
0.778 0.870 0.856 -0.014 73 

undersampl to the origin dataset to estim p̂s. We repeat bootstrap and under- 

sampl 100 time to comput the right hand term 
√ 

νs 
ν . thi allow u to defin the 

subset of point for which the condit (4.20) holds. 

figur 4.12 report the differ between kendal rank correl of p̂ and p̂, av- 

erag over differ level of undersampl (proport of major vs. minority: 

90/10, 80/20, 60/40, 50/50). higher differ mean that p̂ return a good order 

than p̂ (assum that the rank provid by p be correct). the plot distinguish 

between sampl for which condit (4.20) be satisfi and not. In gener we see that 

point with a posit differ correspond to those have the condit satisfi and 



chapter 4. techniqu for unabalanc classif task 71 

tabl 4.3: select dataset from the uci repositori [1] 

dataset N N+ N− n+/n 
ecoli 336 35 301 0.10 
glass 214 17 197 0.08 
letter-a 20000 789 19211 0.04 
letter-vowel 20000 3878 16122 0.19 
ism 11180 260 10920 0.02 
letter 20000 789 19211 0.04 
oil 937 41 896 0.04 
page 5473 560 4913 0.10 
pendigit 10992 1142 9850 0.10 
phoss 11411 613 10798 0.05 
satimag 6430 625 5805 0.10 
segment 2310 330 1980 0.14 
boundari 3505 123 3382 0.04 
estat 5322 636 4686 0.12 
cam 18916 942 17974 0.05 
compustat 13657 520 13137 0.04 
covtyp 38500 2747 35753 0.07 

the opposit for neg differences. these result seem to confirm the experi with 

synthet data, where a good order be give by p̂ when the condit (4.20) holds. 

figur 4.12: differ between the kendal rank correl of p̂ and p̂ with p, 
name Ks and K, for point have the condit (4.20) satisfi and not. Ks and K 

be calcul a the mean of the correl over all βs. 

In figur 4.13 we show the ratio of sampl in each dataset satisfi condit (4.20) 

averag over all the βs. the proport of point in which undersampl be use 

chang heavili with the dataset considered. for example, in the dataset vehicle, yeast, 

german and pima, underdamp return a good order for more than 80% of the 

samples, while the proport drop to less than 50% in the page dataset. 

thi seem to confirm our intuit that the right amount of undersampl depend on 

the classif task (e.g. degre of non separability), the learn algorithm and the 

target test set. It follow that there be no reason to believ that undersampl until 

the two class be perfectli balanc be the default strategi to adopt. 



chapter 4. techniqu for unabalanc classif task 72 

It be also worth to remark that the check of the condit (4.20) be not easi to be done, 

sinc it involv the estim of 
√ 

νs 
ν (ratio of the varianc of the classifi befor and 

after undersampling) and of dpsdp , which demand the knowledg of the true posterior 

probabl p. In practic sinc p be unknown in real datasets, we can onli reli on a data 

driven approxim of dpsdp . also the estim of 
√ 

νs 
ν be a hard statist problem, 

a know in the statist literatur on ratio estim [221]. 

figur 4.13: ratio between the number of sampl satisfi condit (4.20) and all 
the instanc avail in each dataset averag over all the βs. 

4.1.5 discuss 

undersampl have becom the de facto strategi to deal with skew distributions, but, 

though easi to be justified, it conceal two major effects: i) it increas the varianc 

of the classifi and ii) it produc warp posterior probabilities. the first effect be 

typic address by the use of averag strategi (e.g. underbag [117]) to reduc 

the variabl while the second requir the calibr of the probabl to the new 

prior of the test set [134]. despit the popular of undersampl for unbalanc 

classif tasks, it be not clear how these two effect interact and when undersampl 

lead to good accuraci in the classif task. 

In thi first part of the chapter, we aim to analyz the interact between undersam- 

pling and the rank error of the posterior probability. We deriv the condit (4.20) 

under which undersampl can improv the rank and we show that when it be satis- 

fied, the posterior probabl obtain after sampl return a more accur order of 

test instances. To valid our claim we use first synthet and then real datasets, and 

in both case we regist a good rank with undersampl when condit (4.20) 

be met. It be import to remark how thi condit show that the benefici impact 

of undersampl be strongli depend on the natur of the classif task (degre 

of imbal and non separability), on the varianc of the classifi and a a consequ 

be extrem depend on the specif test point. We think that thi result shed light 



chapter 4. techniqu for unabalanc classif task 73 

on the reason whi sever discord result have be obtain in the literatur about 

the effect of undersampl in unbalanc tasks. 

however, the practic use of thi condit be not straightforward sinc it requir the 

knowledg of the posteriori probabl and of the ratio of varianc befor and after 

undersampling. It follow that thi result should be use mainli a a warn against a 

naiv use of undersampl in unbalanc task and should suggest instead the adopt 

of specif adapt select techniqu (e.g. race [27], see section 4.3) to perform a 

case-by-cas use (and calibration) of undersampling. 

4.2 use calibr probabl with undersampl 

In the previou section we show with equat (4.7) that undersampl induc an 

artifici bia (warping) into the posterior probabl return by a model. We now 

demonstr how to correct for thi bia use the equat deriv in section 4.1.1. 

although thi method do not affect the rank order return by the posterior proba- 

bility, it significantli impact the classif accuraci and probabl calibration. We 

use bay minimum risk theori [30] to find the correct classif threshold and show 

how to adjust it after undersampling. experi on sever real-world unbalanc 

dataset valid our results. 

4.2.1 adjust posterior probabl to new prior 

the first part of the chapter show that undersampl be respons for a drift in pos- 

terior probabl and induc warp probabl estim (see section 4.1). however, 

the first and most direct effect of undersampl be the chang in the class priors. To 

show thi effect, let u use an illustr example. 

let’ suppos we have an unbalanc problem where the posit account for 10% of 

10,000 observ (i.e., we have 1,000 posit and 9,000 negatives). suppos we want 

to have a balanc dataset β = N 
+ 

N− ≈ 0.11, where ≈ 88.9% (8000/9000) of the neg 
instanc be discharged. tabl 4.4 show how, by reduc β, the origin unbalanc 

dataset becom more balanc and small a neg instanc be removed. after 

undersampling, the number of neg be n− = βn−, while the number of posit 

stay the same n+ = n+. the percentag of neg (perc−) in the dataset decreas 

a n− → n+. 

after a classif model be learn on a balanc train set, it be normal use to 

predict a test set, which be like to have an unbalanc distribut similar to the 



chapter 4. techniqu for unabalanc classif task 74 

tabl 4.4: undersampl a dataset with 1,000 posit in 10,000 observations. Ns 
defin the size of the dataset after undersampl and n− (n+ ) the number of neg 
(positive) instanc for a give β. when β = 0.11 the neg sampl repres 50% 

of the observ in the dataset. 

Ns N 
− 
s N 

+ 
s β perc 

− 

2,000 1,000 1,000 0.11 50.00 
2,800 1,800 1,000 0.20 64.29 
3,700 2,700 1,000 0.30 72.97 
4,600 3,600 1,000 0.40 78.26 
5,500 4,500 1,000 0.50 81.82 
6,400 5,400 1,000 0.60 84.38 
7,300 6,300 1,000 0.70 86.30 
8,200 7,200 1,000 0.80 87.80 
9,100 8,100 1,000 0.90 89.01 
10,000 9,000 1,000 1.00 90.00 

origin train set. thi mean that the posterior probabl of a model learn on the 

balanc train set should be adjust for the chang in prior between the train 

and test sets. In thi section we propos to use equat (4.8) to correct the posterior 

probabl estim after undersampling. let u call p′ the bias-correct probabl 

obtain from p use (4.8): 

p′ = 
βp 

βp − p + 1 
(4.21) 

equat (4.21) can be see a a special case of the framework propos by saeren et 

al. [134] and elkan [35] for correct the posterior probabl in the case of test and 

train set share the same priors. 

let pt = p(yt = +|xt) be the posterior probabl for a test instanc (xt, yt), where 
the test set have priors: π−t = 

n−t 
Nt 

and π+t = 
n+t 
Nt 

. In the unbalanc train set 

we have π− = N 
− 

N , π 
+ = N 

+ 

N and after undersampl the train set π 
− 
s = 

βn− 

n++βn− , 

π+ = 
N+ 

n++βn− . If we assum that the class condit distribut p(x|+) and p(x|−) 
remain the same between the train and test sets, saeren et al. [134] show that, 

give differ prior between the train and test sets, the posterior probabl can 

be correct with the follow equation: 

pt = 

π+t 
π+ 
p 

π+t 
π+ 
p + 

π−t 
π− 

(1− ps) 
(4.22) 

let u assum that the train and test set share the same priors: π+t = π+ and 

π−t = π 
−: 

pt = 

π+ 

π+ 
p 

π+ 

π+ 
p + 

π− 

π− 
(1− ps) 



chapter 4. techniqu for unabalanc classif task 75 

then, sinc 
π+ 

π+ 
= 

N+ 

n++n− 

N+ 

n++βn− 

= 
N+ + βn− 

N+ +n− 
(4.23) 

π− 

π− 
= 

N− 

n++n− 

βn− 

n++βn− 

= 
N+ + βn− 

β(n+ +n−) 
(4.24) 

we can write 

pt = 

n++βn− 

n++n− p 
n++βn− 

n++n− p + 
n++βn− 

β(n++n−)(1− ps) 

pt = 
p 

p + 
(1−ps) 
β 

= 
βp 

βp − p + 1 

hence, the transform propos by saeren et al. [134] be essenti equival 

to (4.21). similarly, elkan [35] propos to adjust the posterior probabl after un- 

dersampl with the follow equation: 

pt = π 
+ 
t 

p − π+ p 
π+ − π+ p + π+t p − π+t π+ 

(4.25) 

pt = 
(1− π+ )p 

π+ 
π+t 

(1− ps) + p − π+ 

use equat (4.23) and the assumpt that π+t = π+ and π 
− 
t = π 

−: 

pt = 

βn− 

n++βn− p 
n++n− 

n++βn− (1− ps) + p − N 
+ 

n++βn− 

pt = 
βn−p 

(n+ +n−)(1− ps) + (n+ + βn−)p −n+ 

pt = 
βn−p 

N− −n−p + βn−p 
= 

βp 
βp − p + 1 

equat (4.25) be equival to (4.21) and therefor to the one propos by saeren et 

al. [134]. 

In summary, when we know the prior in the test set we can correct the probabl 

with elkan’ and saerens’ equations. however, these probabl be usual unknown 

and must be estimated. If we make the assumpt that train and test have the 

same prior we can use (4.21) for calibr ps. note that the abov transform will 

not affect the rank produc by ps. equat (4.21) defin a monoton transforma- 

tion, henc the rank of p will be the same a p′. while p be estim use all the 

sampl in the unbalanc dataset, p and p′ be comput consid a subset of the 

origin sampl and therefor their estim be subject to high varianc [213]. 



chapter 4. techniqu for unabalanc classif task 76 

4.2.2 warp correct and classif threshold adjust 

As previous describ in section 2.1.2, a classifi typic defin the optim class 

of a sampl a the one minim the risk. In practice, thi translat into calcul 

the posterior probabl and predict an instanc a posit or neg when the 

probabl be abov a certain threshold. If we assum that there be no cost in case of 

correct prediction, then from (2.9) the threshold minim the risk is: 

τ = 
l1,0 

l1,0 + l0,1 

where li,j be the cost occur in decid i when the true class be j. In an unbalanc 

problem, the cost of miss a posit instanc (fals negative) be usual high than 

the cost of miss a neg (fals positive). If the cost of a fals neg and fals 

posit be unknown, a natur solut be to set these cost use the prior (π− and 

π+). let l1,0 = π+ and l0,1 = π−. then, sinc π− > π+ we have l0,1 > l1,0 a desired. 

We can then write 

τ = 
l1,0 

l1,0 + l0,1 
= 

π+ 

π+ + π− 
= π+ (4.26) 

sinc π+ + π− = 1. thi be also the optim threshold in a cost-sensit applic 

where the goal be to minim overal cost and the misclassif cost be defin 

use the prior [35]. 

even if undersampl produc warp probabl estimates, it be often use to balanc 

dataset with skew class distribut becaus sever classifi have empir show 

good perform when train on a balanc dataset [88, 90]. let τs denot the 

threshold use to classifi an observ after undersampling, from (4.26) we have τs = 

π+ , where π+ be the posit class prior after undersampling. In the case of undersampl 

with β = N 
+ 

N− (balanc train set) we have τs = 0.5. 

when correct p with (4.21), we must also correct the probabl threshold to main- 

tain the predict accuraci defin by τs (thi be need otherwis we would use differ 

misclassif cost for p′). let τ ′ be the threshold for the unbias probabl p′. 

from elkan [35]: 
τ ′ 

1− τ ′ 
1− τs 
τs 

= β (4.27) 

τ ′ = 
βτ 

(β − 1)τ + 1 
(4.28) 

use τs = π+ , (4.28) becomes: 

τ ′ = 
βπ+ 

(β − 1)π+ + 1 



chapter 4. techniqu for unabalanc classif task 77 

τ ′ = 
β N 

+ 

n++βn− 

(β − 1) N+ 
n++βn− + 1 

= 
N+ 

N+ +n− 
= π+ 

the optim threshold to use with p′ be equal to the one for p. As an altern to 

classifi observ with p and τs, we can obtain equival result with p′ and 

τ ′. In summary, a a result of undersampling, a high number of observ be 

predict a positive, but the posterior probabl be bia due to a chang in the 

priors. equat (4.28) allow u find the threshold that guarante equal accuraci after 

the posterior probabl correction. therefore, in order to classifi observ with 

unbias probabl after undersampling, we have to first obtain p′ from p with (4.21) 

and then use τ ′ a a classif threshold. 

4.2.3 experiment result 

the ration of the follow experi be to compar the probabl estim of two 

models, one learn in the presenc and the other in the absenc of undersampling, and 

test the benefit of probabl calibr after undersampling. We use g-mean a a 

measur of classif accuracy, auc to ass the qualiti of the rank produc by 

the probabl and brier score (bs) a a measur of probabl calibr (see section 

2.1.4). In our experi we use the same dataset of section 4.1.4 (tabl 4.3). for 

each dataset we use 10-fold CV to test our model and we repeat the CV 10 times. 

In particular, we use a stratifi cv, where the class proport in the dataset be 

kept the same over all the folds. As the origin dataset be unbalanced, the result 

fold be unbalanc a well. for each fold of CV we learn two models: one use 

all the observ and the other with the one remain after undersampling. then 

both model be test on the same test set (figur 4.14). We use sever supervis 

classif algorithm avail in R [25] with default parameters: RF [222], svm [223] 

and logit boost (lb) [224]. 

We denot a p̂ and p̂ the posterior probabl estim obtain with and without 

undersampl and a p̂′ the bias-correct probabl obtain from p̂ with equa- 

tion (4.21). let τ , τs and τ ′ be the probabl threshold use for p̂, p̂ and p̂′ re- 

spectively, where τ = π+, τs = π+ and τ ′ = π+. the goal of these experi be to 

compar which probabl estim return the high rank (auc), calibr (bs) 

and classif accuraci (g-mean) when coupl with the threshold defin before. 

In undersampling, the amount of sampl defin by β be usual set to be equal to N 
+ 

N− , 

lead to a balanc dataset where π+ = π− = 0.5. however, there be no reason to 

believ that thi be the optim sampl rate. often, the optim rate can be found onli 

a posteriori after tri differ valu of β. for thi reason we replic the CV with 



chapter 4. techniqu for unabalanc classif task 78 

test%set% train%set% 

undersampling%unbalanced%model% 

balanced%model%p̂ 

ˆ!p 

τ 

τ ' 

τ s 

fold%1% fold%2% fold%3% fold%4% fold%10% 

unbalanced%dataset% 

.%.%.%.% 

p̂ 

figur 4.14: learn framework for compar model with and without undersam- 
pling use cv. We use one fold of the CV a test set and the other for training, 

and iter the framework to use all the fold onc for testing. 

differ β such that {n+n− ≤ β ≤ 1} and for each CV the accuraci be comput a the 
averag g-mean (or auc) over all the folds. 

In tabl 4.5 we report the result over all the datasets. for each dataset, we rank the 

probabl estim p̂s, p̂ and p̂′ from the bad to the best perform for differ 

valu of β. We then sum the rank over all the valu of β and over all datasets. more 

formally, let ri,k,b ∈ {1, 2, 3} be the rank of probabl i on dataset k when β = b. 
the probabl with the high accuraci in k when β = b have ri,k,b = 3 and the one 

with the low have ri,k,b = 1. then the sum of rank for the probabl i be defin as∑ 
k 

∑ 
bri,k,b. the high the sum, the high the number of time that one probabl 

have high accuraci than the others. 

for auc, a high rank sum mean a high auc and henc a good rank return 

by the probability. similarly, with g-mean, a high rank sum correspond to high 

predict accuracy. however, in the case of bs, a high rank sum mean poorer prob- 

abil calibr (larger bias). tabl 4.5 have in bold the probabl with the best 

rank sum accord to the differ metrics. for each metric and classifi it report the 

p-valu of the pair t-test base on the rank between p̂ and p̂′ and between p̂ and p̂s. 

In term of auc, we see that p̂ and p̂′ have good perform than p̂ for LB and 

svm. the rank sum be the same for p̂ and p̂′ sinc the two probabl be link by 

a monoton transform (equat (4.21)). If we look at g-mean, p̂ and p̂′ return 

good accuraci than p̂ two time out of three. In thi case, the rank sum of p̂ and p̂′ 

be the same sinc we use τs and τ ′ a the classif threshold, where τ ′ be obtain 



chapter 4. techniqu for unabalanc classif task 79 

from τs use (4.28). If we look at the p-values, we can strongli reject the null hypothesi 

that the accuraci of p̂ and p̂ be from the same distribution. for all classifiers, p̂ be the 

probabl estim with the best calibr (lower rank sum with bs), follow by p̂′ 

and p̂s. the rank sum of p̂′ be alway low than the one of p̂s, indic that p̂′ have 

low bia than p̂s. thi result confirm our claim that equat (4.21) allow one to 

reduc the bia introduc by undersampling. 

In summari from thi experi we can conclud that undersampl do not alway 

improv the rank or classif accuraci of an algorithm, but when it be the case 

we should use p̂′ instead of p̂ becaus the first have alway good calibration. 

tabl 4.5: sum of rank and p-valu of the pair t-test between the rank of p̂ and 
p̂′ and between p̂ and p̂ for differ metrics. In bold the probabl with the best 

rank sum (higher for auc and g-mean, low for bs). 

metric algo 
∑ 
rp̂ 

∑ 
rp̂ 

∑ 
rp̂′ ρ(rp̂, rp̂s) ρ(rp̂, rp̂′) 

auc LB 22,516 23,572 23,572 0.322 0.322 
auc RF 24,422 22,619 22,619 0.168 0.168 
auc svm 19,595 19,902.5 19,902.5 0.873 0.873 

g-mean LB 23,281 23,189.5 23,189.5 0.944 0.944 
g-mean RF 22,986 23,337 23,337 0.770 0.770 
g-mean svm 19,550 19,925 19,925 0.794 0.794 

BS LB 19809.5 29448.5 20402 0.000 0.510 
BS RF 18336 28747 22577 0.000 0.062 
BS svm 17139 23161 19100 0.001 0.156 

We now consid a real-world dataset, compos of credit card transact from septem- 

ber 2013 make avail by our industri partner.5 It contain a subset of onlin trans- 

action that occur in two days, where we have 492 fraud out of 284,807 transactions. 

the dataset be highli unbalanced, where the posit class (frauds) account for 0.172% 

of all transactions, and the minimum valu of β be ≈ 0.00173. In figur 4.15 we have the 
auc for differ valu of β. the boxplot of p̂ and p̂′ be ident becaus of (4.21), 

they increas with β → N+ 
N− and have high median than the one of p̂. thi exampl 

show how in case of extrem class imbalance, undersampl can improv predict 

accuraci of sever classif algorithms. 

In figur 4.16 we have the BS for differ valu of β. the boxplot of p̂′ show in 

gener small calibr error (lower bs) than those of p̂ and the latter have high 

BS especi for small valu of β. thi support our previou results, which found that 

the loss in probabl calibr for p̂ be great the strong the undersampling. 
5the dataset be avail at http://www.ulb.ac.be/di/map/adalpozz/data/creditcard.rdata 

http://www.ulb.ac.be/di/map/adalpozz/data/creditcard.rdata 


chapter 4. techniqu for unabalanc classif task 80 

LB RF svm 

●●●●●●●●●● ●●●●●●●●●● 
●●●●●●●●●● ●●●●●●●●●● 

●●●●●●●●●●●●●●●●●●●● ●●●●●●●●●●●●●●●●●●●● 

●●●●●● ●●●●●● 

●●●●●● ●●●●●● 

●●●●●● ●●●●●● 

●●●●●●●● ●●●●●●●● 

●●●●●●●● ●●●●●●●● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

0.900 

0.925 

0.950 

0.975 

1.000 

0. 
1 
0. 

2 
0. 

3 
0. 

4 
0. 

5 
0. 

6 
0. 

7 
0. 

8 
0. 

9 1 
0. 

1 
0. 

2 
0. 

3 
0. 

4 
0. 

5 
0. 

6 
0. 

7 
0. 

8 
0. 

9 1 
0. 

1 
0. 

2 
0. 

3 
0. 

4 
0. 

5 
0. 

6 
0. 

7 
0. 

8 
0. 

9 1 

beta 

A 
U 

C 

probabl 
p 
p' 
p 

credit−card 

figur 4.15: boxplot of auc for differ valu of β in the credit-card dataset. 

LB RF svm 
● 
● 
● 
● 
● 
● 
● 
● 
● 
● 
● 
● 
● 
● 
● 
● 
● 
● 
● 
● 

●●●●●●●●●● 

●●●●●●●●●● 

●●●●●● 

●●●●●● 

● 
● 
● 
● 
● 
● 
● 
● 
● 
● 
● 
● 

●●●●●● 

●●●●●● 

●●●●●●●● ●●●●●●●● 

3e−04 

6e−04 

9e−04 

0. 
1 
0. 

2 
0. 

3 
0. 

4 
0. 

5 
0. 

6 
0. 

7 
0. 

8 
0. 

9 1 
0. 

1 
0. 

2 
0. 

3 
0. 

4 
0. 

5 
0. 

6 
0. 

7 
0. 

8 
0. 

9 1 
0. 

1 
0. 

2 
0. 

3 
0. 

4 
0. 

5 
0. 

6 
0. 

7 
0. 

8 
0. 

9 1 

beta 

B 
S 

probabl 
p 
p' 
p 

credit−card 

figur 4.16: boxplot of BS for differ valu of β in the credit-card dataset. 

4.2.4 discuss 

the warp due to the instanc select procedur in undersampl be essenti 

equival to the bia that occur with a chang in the prior when class-within distribu- 

tion remain stable. with undersampling, we creat a differ train set, where the 

class be less unbalanced. however, if we make the assumpt that the train and 

test set come from the same distribution, it follow that the probabl estim 

obtain after undersampl be biased. As a result of undersampling, the posterior 

probabl p̂ be shift away from the true distribution, and the optim separ 

boundari move toward the major class so that more case be classifi into the 

minor class. 



chapter 4. techniqu for unabalanc classif task 81 

By make the assumpt that prior probabl do not chang from train and 

testing, i.e. they both come form the same data gener process, we propos the 

transform give in equat (4.21), which allow u to remov the drift in p̂ due to 

undersampling. 

the bia on p̂ regist by BS get larg for small valu of β, which mean strong un- 

dersampl produc probabl with poorer calibr (larger loss). with synthetic, 

uci and credit-card datasets, the drift-correct probabl (p̂′) have significantli good 

calibr than p̂ (lower brier score). 

even if undersampl produc poorli calibr probabl estim p̂s, sever stud- 

y have show that it often provid good predict accuraci than p̂ [88, 90]. To 

improv the calibr of p̂ we propos to use p̂′ sinc thi transform do not af- 

fect the ranking. In order to maintain the accuraci obtain with p̂ and the probabl 

threshold τs, we propos to use p̂′ togeth with τ ′ to account for the chang in priors. 

By chang the undersampl rate β we give differ cost to fals posit and fals 

negatives, combin p̂′ with τ ′ allow one to maintain the same misclassif cost 

of a classif strategi with p̂ and τs for ani valu of β. 

finally, we consid a highli unbalanc dataset (credit-card), where the minor 

class account for onli 0.172% of all observations. In thi dataset, the larg improv 

in accuraci obtain with undersampl be coupl with poor calibr probabl 

(larg bs). By correct the posterior probabl and chang the threshold we be 

abl to improv calibr without lose predict accuracy. 

4.3 race for sampl method select 

As alreadi see in section 4.1, the degre of imbal be not the onli factor that 

determin the difficulti of a classification/detect task. anoth influenti factor 

be the amount of overlap of the class of interest [86]. prati [84] show that class 

unbalance, by itself, do not seem to be a problem. most studi [78, 82, 84, 106] 

propos one method that seem to work well under certain conditions, howev there be 

no empir evid than one techniqu be superior to all the others. In gener the best 

method do not exits, howev in some case some techniqu be good than others, 

thi be know in the literatur a no-free-lunch theorem [225, 226]. 

all these support the idea that under differ conditions, such a distinct datasets, al- 

gorithms, metrics, the best method may change. sinc in real larg task it be hard to 

know a priori the natur of the unbalanc tasks, the user be recommend to test all 



chapter 4. techniqu for unabalanc classif task 82 

techniqu with a consequ comput overhead. We make an exhaust compar- 

ison of these method on a real credit-card fraud dataset and nine public benchmark 

datasets. the result show that there be no balanc techniqu which be consist 

the best one and that the best method depend on the algorithm appli a well a the 

dataset used. for thi reason, we propos the adopt of a race strategi [227] to 

automat select the most adequ techniqu for a give dataset. the rational of 

the race strategi consist in test multipl balanc strategi on a subset of the 

dataset and to remov progress the altern that be significantli worse. our re- 

sult show that by adopt a race strategi we be abl to select in an effici manner 

either the best balanc method or a method that be not significantli differ from the 

best one. moreover, race be abl to reduc consist the comput need befor 

find the right method for the dataset. 

4.3.1 race for strategi select 

the varieti of approach discuss in section 3.1 suggest that in a real situat where 

we have no prior inform about the data distribution, it be difficult to decid which 

unbalanc strategi to use. In thi case test all altern be not an option either 

becaus of the associ comput cost. 

A possibl solut come form the adopt of the race approach which be propos 

in [227] to perform effici model select in a learn task. the principl of race 

consist in test in parallel a set of altern and use a statist test to determin 

if an altern be significantli bad than the others. In that case such altern be 

discard from the competition, and the comput effort be devot to differenti 

the remain ones. histor the first exampl of race method be call hoeffd 

race sinc it reli on the hoeffd theorem to decid when a model be significantli bad 

than the others. the f-race version be propos in [26] and combin the friedman test 

with hoeffd race [227] to elimin inferior candid a soon a enough statist 

evid aris against them. In f-race, the friedman test be use to check whether there 

be evid that at least one of the candid be significantli differ from other and 

post-test be appli to elimin those candid that be significantli bad than the 

best one. 

here we adopt f-race to search effici for the best strategi for unbalanc data. 

the candid be assess on differ subset of data and, each time a new assess 

be made, the friedman test be use to dismiss significantli inferior candidates. We use a 

10 fold CV to provid the assess measur to the race. If a candid be significantli 

good than all the other then the race be termin without the need of use the whole 



chapter 4. techniqu for unabalanc classif task 83 

dataset. In case there be no evid of worse/bett methods, the race termin when 

the entir dataset be explor and the best candid be the one with the best averag 

result. 

candidate(1 candidate(2 candidate(3 
subset(1( 0.50 0.47 0.48 
subset(2 0.51 0.48 0.30 
subset(3 0.51 0.47 
subset(4 0.49 0.46 
subset(5 0.48 0.46 
subset(6 0.60 0.45 
subset(7 0.59 
subset(8 
subset(9 
subset(10 

original(dataset 

tim 
e 

figur 4.17: illustr exampl of racing: test in parallel a set of candid use 
a subset of the dataset and remov from the race those that be significantli bad than 
the best. the race continu with the remain candid until onli one be selected. 

4.3.2 experiment result 

In these experi we test some of the techniqu for unbalanc classif 

discuss in section 3.1.1 on the dataset of tabl 4.3 and the credit card data use 

in [28]. In particular, we consid the follow techniques: undersampling, oversam- 

pling, smote, cnn, enn, ncl, oss and tomek link. 

We start by perform a CV for each techniqu with differ classif algo- 

rithms: RF [222], neural network (nnet) [228], svm [228], LB [224] and decis 

tree [229]. figur 4.18 display the result of the CV for all the algorithm and datasets. 

for each dataset we comput the averag g-mean in the CV and then calcul the 

averag accuraci over all the datasets. We also includ the perform in the case of 

unbalanc dataset a benchmark. In thi study, we see that the combin of RF 

and undersampl appear to return the larg accuracy. 

however, the result be highli depend on the dataset and classifi considered. In 

figur 4.19 we show the accuraci on two datasets. In the case of the cam dataset under- 

sampl be the best techniqu for all the classif algorithm used. On the contrary, 

we see that for ecoli dataset, there be not a singl techniqu that clearli outperform the 

others. 



chapter 4. techniqu for unabalanc classif task 84 

0.0 

0.2 

0.4 

0.6 

0.8 

Un 
ba 

l 
Ov 

er 

Un 
de 

r 

SM 
OT 

E 
OS 

S 
CN 

N 
EN 

N 
NC 

L 

To 
m 

ek 

G 
− 

m 
ea 

n 

algo 
LB 
nnet 
RF 
svm 
tree 

figur 4.18: comparison of strategi for unbalanc data with differ classifi 
over all dataset of tabl 4.3 in term of g-mean (the high the better). 

cam ecoli 

0.00 

0.25 

0.50 

0.75 

Un 
ba 

l 
Ov 

er 

Un 
de 

r 

SM 
OT 

E 
OS 

S 
CN 

N 
EN 

N 
NC 

L 

To 
m 

ek 

Un 
ba 

l 
Ov 

er 

Un 
de 

r 

SM 
OT 

E 
OS 

S 
CN 

N 
EN 

N 
NC 

L 

To 
m 

ek 

G 
− 

m 
ea 

n 

algo 
LB 
nnet 
RF 
svm 
tree 

figur 4.19: comparison of strategi for unbalanc data with differ classifi 
on cam and ecoli dataset in term of g-mean (the high the better). 

In these experi the classif accuraci be measur in term of g-mean, but we 

could have differ outcom when use anoth metric [27]. In gener there be no singl 

strategi that be coher superior to all the other in all condit (i.e. algorithm and 

dataset). even if sometim it be possibl to find a strategi that be statist good 

than other it be comput demand test all strategi on sever dataset 

and algorithms. for thi reason in [27] we propos to adopt the f-race algorithm to 

automat the way to select the best strategi for unbalanc data. the algorithm be 

avail in the companion unbalanc packag [24] avail for the R languag (see 

appendix a). tabl 4.6 and 4.7 show the result of the f-race. 

the first thing we notic be that for almost all dataset f-race be abl to return the best 



chapter 4. techniqu for unabalanc classif task 85 

dataset explor method ntest % gain mean Sd 

ecoli race under 46 49 0.836 0.04cv smote 90 - 0.754 0.112 

letter-a race under 34 62 0.952 0.008cv smote 90 - 0.949 0.01 

letter-vowel race under 34 62 0.884 0.011cv under 90 - 0.887 0.009 

letter race smote 37 59 0.951 0.009cv under 90 - 0.951 0.01 

oil race under 41 54 0.629 0.074cv smote 90 - 0.597 0.076 

page race smote 45 50 0.919 0.01cv smote 90 - 0.92 0.008 

pendigit race under 39 57 0.978 0.011cv under 90 - 0.981 0.006 

phoss race under 19 79 0.598 0.01cv under 90 - 0.608 0.016 

satimag race under 34 62 0.843 0.008cv under 90 - 0.841 0.011 

segment race smote 90 0 0.978 0.01cv smote 90 - 0.978 0.01 

estat race under 27 70 0.553 0.023cv under 90 - 0.563 0.021 

covtyp race under 42 53 0.924 0.007cv smote 90 - 0.921 0.008 

cam race under 34 62 0.68 0.007cv under 90 - 0.674 0.015 

compustat race under 37 59 0.738 0.021cv under 90 - 0.745 0.017 

creditcard race under 43 52 0.927 0.008cv smote 90 - 0.924 0.006 

tabl 4.6: comparison of CV and f-race result in term of g-mean for RF classifier. 

method accord to cv. In the case where there be no agreement between f-race and CV 

on the best method, the differ in perform be howev not significant. the main 

advantag of race be that bad method be not test on the whole dataset reduc 

the comput needed. take into consider the 8 method and the unbalanc 

case, in a 10 fold CV we have 90 test to make (10 fold x 9 methods). In the case of 

f-race the number of total test depend upon how mani fold be need befor f-race 

find the best method. the gain column of tabl 4.6 and 4.7 show the comput 

gain (in percentag of the CV tests) obtain by use f-race. In the case of the segment 

dataset and RF classifi the gain be 0, mean that the race do not find signific 

bad candidates. In all the other case f-race allow a signific comput save 

with no loss in performance. 

4.3.3 discuss 

recent literatur in data mine and machin learn have plenti of research work 

on strategi to deal with unbalanc data. however, a definit answer on the best 



chapter 4. techniqu for unabalanc classif task 86 

dataset explor method ntest % gain mean Sd 

ecoli race smote 55 39 0.83 0.068cv oss 90 - 0.613 0.361 

letter-a race smote 31 66 0.96 0.009cv smote 90 - 0.961 0.008 

letter-vowel race smote 31 66 0.878 0.007cv smote 90 - 0.876 0.005 

letter race smote 31 66 0.96 0.007cv smote 90 - 0.96 0.007 

oil race over 90 0 0.356 0.155cv tomek 90 - 0.311 0.272 

page race smote 31 66 0.91 0.015cv smote 90 - 0.905 0.012 

pendigit race smote 63 30 0.992 0.003cv smote 90 - 0.992 0.003 

phoss race under 31 66 0.571 0.008cv under 90 - 0.509 0.112 

satimag race under 41 54 0.842 0.011cv smote 90 - 0.837 0.012 

segment race smote 84 7 0.971 0.021cv cnn 90 - 0.972 0.014 

boundari race under 34 62 0.401 0.051cv under 90 - 0.423 0.079 

estat race under 31 66 0.56 0.068cv under 90 - 0.593 0.016 

covtyp race smote 34 62 0.927 0.007cv smote 90 - 0.924 0.006 

cam race under 31 66 0.684 0.026cv under 90 - 0.686 0.017 

compustat race under 27 70 0.742 0.012cv under 90 - 0.741 0.013 

creditcard race smote 42 53 0.919 0.011cv under 90 - 0.916 0.008 

tabl 4.7: comparison of CV and f-race result in term of g-mean for svm classifier. 

strategi to adopt be yet to come. our experiment result support the idea that the 

final perform be extrem depend on the data natur and distribution. 

thi consider have lead u to adopt the f-race strategi where differ candid 

(unbalanc methods) be test simultaneously. We have show that thi algorithm be 

abl to select few candid that perform good than other without explor the whole 

dataset. f-race be abl to get result similar to the cross valid for most of the 

datasets. 

In gener we saw that undersampl and smote togeth with RF be often the meth- 

od return the larg accuracy. As far a the fraud dataset be concerned, we prefer 

undersampl over smote becaus it reduc the dataset set allow faster train of 

the classifier. however, a the fraud evolv over the time the same method could becom 

sub-optim in the future. In thi context the f-race contribut to the select of the 

best strategi be crucial in order to have a detect system that quickli adapt to the 

new data distribution. within the uci dataset we notic that some task be much 

easi (high accuracy) than the other and they may not have an unbalanc method 



chapter 4. techniqu for unabalanc classif task 87 

that perform significantli good than the others. 

4.4 conclus 

A standard approach to deal with unbalanc classif task be to rebal the 

dataset befor train a learn algorithm. one of the most straightforward way to 

achiev a balanc distribut be to use undersampling, i.e. remov observ from 

the major class. despit the popular of thi technique, no detail analysi about 

the impact of undersampl on the accuraci of the final classifi be avail yet. 

thi chapter aim to fill thi gap by propos an integr analysi of the two element 

which have the larg impact on the effect of an undersampl strategy: the 

increas of the varianc due to the reduct of the number of sampl and the warp 

of the posterior distribut due to the chang of priori probabilities. 

We propos a theoret analysi specifi under which condit undersampl be 

recommend and expect to be effective. It emerg that undersampl be not al- 

way the best solut and sever factor affect it power (e.g. varianc of the classifier, 

the degre of imbalance, class separ and the valu of the posterior probability.) 

however, when it appear to improv predict accuraci we show that it be import 

to re-calibr the posterior probabl of a classifi to account for the chang in class 

priors. finally, we propos to use a race algorithm to choos between multipl strate- 

gy for unbalanc classif in order to avoid test all possibl techniqu and 

configurations. 





chapter 5 

learn from evolv data 

stream with skew distribut 

result present in thi chapter have be publish in the follow papers: 

• andrea dal pozzolo, olivi caelen, yann-ael Le borgne, serg waterschoot, and 
gianluca bontempi. learn lesson in credit card fraud detect from a practi- 

tioner perspective. expert system with applications, 41(10):4915-4928, 2014. 

• andrea dal pozzolo, reid A. johnson, olivi caelen, serg waterschoot, nitesh 
V chawla, and gianluca bontempi. use hddt to avoid instanc propag 

in unbalanc and evolv data streams. In neural network (ijcnn), the 2014 

intern joint confer on. ieee, 2014. 

fraud detect problem be typic address in two differ ways. In the static 

learn setting, a detect model be period retrain from scratch (e.g. onc a 

year or month). In the onlin learn setting, the detect model be updat a soon a 

new data arrives. though thi strategi be the most adequ to deal with issu of non- 

stationarity, littl attent have be devot in the literatur to the unbalanc problem 

in a chang environment. anoth problemat issu in credit card fraud detect be 

the scarciti of avail data due to confidenti issu that give littl chanc to the 

commun to share real dataset and ass exist techniques. 

the first part of the chapter (section 5.1) be base on [18] and it aim at make an 

experiment comparison of sever state-of-the-art algorithm and model techniqu 

on one real dataset, focu in particular on some open question like: which machin 

learn algorithm should be used? Is it enough to learn a model onc a month or it be 

necessari to updat the model everyday? how mani transact be suffici to train 

89 



chapter 5. learn from evolv data stream with skew distribut 90 

the model? should the data be analyz in their origin unbalanc form? If not, which 

be the best way to rebal them? which perform measur be the most adequ to 

ass results? 

We address these question with the aim of assess their import on real data and 

from a practition perspective. these be just some of potenti question that could 

rise dure the design of a detect system. We do not claim to be abl to give a definit 

answer to the problem, but we aim to give some guidelin to other peopl in the field. 

our goal be to show what work and what do not in a real case study. 

section 5.1 start by formal the credit card fraud detect task and present a way 

to creat new featur in the dataset that can trace the cardhold spend habits. 

then, we propos and compar three approach for onlin learn in order to identifi 

what be import to retain or to forget in a chang and non-stationari environment. 

We show the impact of the rebalanc techniqu on the final perform when the 

class distribut be skewed. In do thi we merg techniqu develop for unbalanc 

static dataset with onlin learn strategies. our experiment analysi show that to 

adapt to chang environments, it be imper to updat the learn algorithm. A 

static approach that never updat the learn algorithm often fail to maintain good 

predict performances. 

the second part of the chapter (section 5.2) build upon thi result and propos an 

algorithm solut for unbalanc data stream base on helling distanc decis tree 

(hddt) [19], which remov the need of sampl techniqu or instanc propagation. 

hddt [230] have be previous use for static dataset with skew distribut and it 

have show good perform than standard decis trees. In unbalanc data streams, 

state-of-the-art techniqu use instanc propag and decis tree (e.g. c4.5 [102]) 

to cope with the unbalanc problem. however, it be not alway possibl to either revisit 

or store old instanc of a data stream. use hddt allow u to: i) remov instanc 

propag between batch and ii) use all inform avail in a batch without 

need to rebal the class befor train a classifier. thi have sever benefits, for 

example: i) improv predict accuracy, ii) speed, and iii) single-pass through the 

data. We also use a helling weight ensembl of hddt to combat concept drift and 

increas the accuraci of singl classifiers. We test our framework on sever stream 

dataset with unbalanc class and concept drift. 



chapter 5. learn from evolv data stream with skew distribut 91 

5.1 learn strategi in credit card fraud detect 

5.1.1 formal of the learn problem 

In thi section, we formal the credit card fraud detect task a a statist learn 

problem. each transact be describ by a featur vector x contain basic inform 

such a amount of the expenditure, the shop where it be performed, the currency, 

etc. however, these variabl do not provid ani inform about the normal card 

usage. the normal behavior of a cardhold can be measur by use a set of histor 

transact from the same card. for example, a previous explain in section 2.2.2, 

we can get an idea of the cardhold spend habit by look at the averag amount 

spent in differ merchant categori (e.g. restaurant, onlin shopping, ga station, etc.) 

in the last 3 month preced the transaction. 

let xij be the transact number j of a card number i and dt(xij) be the correspond 

transact date-time. We assum that the transact be order in time such that 

if xiv occur befor xiw then dt(xiv) < dt(xiw). let xiλ be a new incom transact 

and ∆t denot the time-fram of a set of histor transact for the same card. hiλ 
be then the set of the histor transact occur in the time-fram ∆t befor xiλ 
such that hiλ = {xij}, where dt(xiλ) > dt(xij) ≥ dt(xiλ) − ∆t. for instance, with 
∆t = 90 days, hiλ be the set of transact for the same card occur in the 3 month 

preced dt(xiλ). the card behavior can be summar use classic aggreg 

method (e.g. mean, max, min or count) on the set hiλ. thi mean that it be possibl 

to creat new aggreg variabl that can be add to the origin variabl in x to 

includ inform of the card. In thi way we have includ inform about the user 

behavior at the transact level. As a consequence, transact from cardhold with 

similar spend habit will share analog aggreg variables. let x̄k indic the 

featur vector associ to a transact xij obtain by add aggreg features. 

At day t, a classifi Kt be train on a batch of supervis transactions, denot a 
Bt = {(x̄k, yk), k = 1, . . . , n}, to predict p(+|x̄λ), the probabl of a new incom 
transact x̄λ to be fraudulent. note that in thi formul we ignor the statu of 

the card. We also assum to know the true class of all transactions, i.e. no mislabel 

sampl due to undetect fraud nor fraud report with a delay by the cardholders. 

5.1.2 strategi for learn with unbalanc and evolv data stream 

the most convent way to deal with sequenti fraud data be to adopt a static ap- 

proach (see figur 5.1 and algorithm 1), which creat onc in a while a classif 

model and us it a a predictor dure a long horizon. though thi approach reduc the 



chapter 5. learn from evolv data stream with skew distribut 92 

time%sta)c%approach% 

fraudulent%transac)ons% 
genuine%transac)ons% 

bt�2 bt�1 Bt bt+1 bt+2 bt+3 bt+4 

Mt 

figur 5.1: static approach: a model Mt be train on K = 3 batch and use to 
predict futur batches. 

algorithm 1 static approach 
require: K: number of batch use for training, B: total number of batch avail (B > k), K: 
classif algorithms, sampling: sampl method. 
T ← empti set of transactions. 
for t ∈ {1, . . . ,k} do 

Bt ← tth batch of transactions. 
T← merg Bt with T. 

M← buildmodel(t, K, sampling) 
for t ∈ {K + 1, . . . , B} do 

p̂← usem to predict p(+, x̄) for transact in bt. 
acct ← predict accuraci of p̂ . measur by auc, ap, pk. 

return average(acc) 

learn effort, it main problem resid in the lack of adapt that make it insensit 

to ani chang of distribut in the upcom batches. 

On the basi of the state-of-the-work describ in section 3.3, it be possibl to conceiv 

two altern strategi to address both the increment and the unbalanc natur of 

the fraud detect problem. the first approach, denot a the updat approach and 

illustr in figur 5.2 and algorithm 2, be inspir by wang et al. [189]. It us a set 

of M model and a number K of batch to train each model. note that for M > 1 

and K > 1 the train set of the M model be overlapping. thi approach adapt 

to chang environ by forget batch at a constant rate. the classifi use to 

make predict be an ensembl of last M models. 

the second approach denot a the propag and forget approach and illustr in 

figur 5.3 and algorithm 3 be inspir by gao et all’ work [170]. In order to mitig 

the unbalanc effects, each time a new batch be available, a model be learn on the 

genuin transact of the previou kgen batch and all past fraudul transactions. 



chapter 5. learn from evolv data stream with skew distribut 93 

time%update%approach% 

bt�2 bt�1 Bt bt+1 

mt�2 mt�1 mtmt�3 

Et 

bt�5 bt�4 bt�3 

fraudulent%transac)ons% 
genuine%transac)ons% 

figur 5.2: updat approach for K = 3 and M = 4. for each new batch a model be 
train on the K late batches. singl model be use to predict the follow batch 

or can be combin into an ensembl et. 

algorithm 2 updat approach 
require: K: number of batch use for training, B: total number of batch avail (B > k), M : 
number of model in the ensemble, K: classif algorithms, sampling: sampl method. 
T ← empti set of transactions. 
Et ← empti array of models. 
k ← 0 
m← 0 
for t ∈ {1, . . . , B} do 

Bt ← tth batch of transactions. 
k ← k + 1. 
T← merg Bt with T. 
if k ≥ K then 

remov bt−k from T 
k ← k − 1. 

m← m+ 1. 
Mt ← buildmodel(t, K, sampling) 
Et ← addmt to et. 
if m ≥M then 

removemt−m from Et 
m← m− 1. 

p̂← use Et to predict p(+, x̄) for transact in bt+1. 
acct+1 ← predict accuraci of p̂ . measur by auc, ap, pk. 

return average(acc) 

sinc thi approach lead to train set which grow in size over the time, a maximum 

train size be set to avoid overloading. onc thi size be reached, old observ 

be remov in favor of the more recent ones. An ensembl of model be obtain by 

combin the last M model a in the updat approach. 

note that in all these approach (includ the static one), a balanc techniqu (e.g. 

undersampling, smote) can be introduc to reduc the skew of the train set. 



chapter 5. learn from evolv data stream with skew distribut 94 

time% 
propagate%and%forget%approach% 

bt�2 bt�1 Bt bt+1bt�3 

mt�2 mt�1 mtmt�3 

Et 
fraudulent%transac)ons% 
genuine%transac)ons% 

figur 5.3: propag and forget approach: for each new batch a model be creat 
by keep all previou fraudul transact and a small set of genuin transact 
from the last 2 batch (kgen = 2). singl model be use to predict the follow 

batch or can be combin into an ensembl (M = 4). 

algorithm 3 propag and forget approach 
require: kgen: number of batch from which to retain genuin transactions, B: total number of 
batch avail (B > k), M : number of model in the ensemble, N : max size of the train set, 
K: classif algorithms, sampling: sampl method. 
T ← empti set of transactions. 
Et ← empti array of models. 
k ← 0 
m← 0 
for t ∈ {1, . . . , B} do 

Bt ← tth batch of transactions. 
k ← k + 1. 
T← merg Bt with T. 
if k ≥ kgen then 

remov genuin transact of bt−kgen from T 
k ← k − 1. 

if |t| > N then 
remov old fraudul transact from T until |t| = N 

m← m+ 1. 
Mt ← buildmodel(t, K, sampling) 
Et ← addmt to et. 
if m ≥M then 

removemt−m from Et 
m← m− 1. 

p̂← use Et to predict p(+, x̄) for transact in bt+1. 
acct+1 ← predict accuraci of p̂ . measur by auc, ap, pk. 

return average(acc) 

In tabl 5.1 we have summar the strength and weak of these approaches. the 

static strategi have the advantag of be fast a the train of the model be do onli 

once, but thi do not return a model that follow the chang in the distribut of the 



chapter 5. learn from evolv data stream with skew distribut 95 

tabl 5.1: strength and weak of the differ learn approaches. 

approach strength weak 

static • speed • No CD adapt 
updat • No instanc propag • need sever batch 

• CD adapt for the minor class 
propag and forget • accumul minor • propag lead to 

instanc faster larg train time 
• CD adapt 

data. the other two approach on the contrari can adapt to concept drift (cd). they 

differ essenti in the way the minor class be accumul in the train batches. the 

propag and forget strategi propag instanc between batch lead to big 

train set and comput burden. 

5.1.3 experiment assess 

In thi section we perform an extens experiment assess on the basi of real data 

in order to address common issu that the practition have to solv when face larg 

credit card fraud datasets. 

dataset and featur transform 

the credit card fraud dataset contain a subset of the transact from the first of 

februari 2012 to the twentieth of may 2013 (detail in tabl 5.2). the dataset be 

divid in daili batch and contain e-commerc fraudul transactions. 

tabl 5.2: fraudul dataset 

# day # featur # transact period 
422 45 2’202’228 1feb12 - 20may13 

thi dataset be strongli unbalanc (the percentag of fraudul transact be low 

than 0.4%) and have a total of 422 batch contain daili transact with an averag 

of 5218 transact per batch. 

the origin variabl avail in the dataset includ the transact amount, point 

of sale, currency, countri of the transaction, merchant type and mani others. however, 

these variabl do not explain cardhold behavior, so aggreg featur be add to 

the origin one in order to profil the user behavior (see section 5.1.1). for example, 

the transact amount and the card_id be use to comput the averag expenditur 



chapter 5. learn from evolv data stream with skew distribut 96 

per week and per month of one card, the differ between the current and previou 

transact and mani others. for each transact and card we take 3 month (∆t = 

90 days) to comput the aggreg variables. 

A great number of the variabl in the origin dataset be discret featur take sev- 

eral values. however, some classifi such a nnet be not abl to handl discret 

variable, so these featur have to be transform into numer features. In the R envi- 

ronment [25], discret variabl be also know a factor and their valu a levels. one 

straightforward way to transform factor into numer featur be to comput the risk 

of have a fraudul transact for each level of a factor. let’ consid for exampl 

a factor variabl f . We can comput the probabl of the jth level of factor f to be 

fraudulent, denot a βj , a follows: βj = 
n+f=j 
nf=j 

, where n+f=j be the number of fraudul 

transact and nf=j the total number of transact for factor f with level j. 

As first option we could use βj to associ to each level a fraud score, but thi would 

lead to the follow issues: i) with few fraudul transactions, mani level be go 

to have βj = 0 make the distribut of the new featur skew toward zero, and ii) 

βj could be the same for level with big and small frequency. for exampl if we have a 

level with 1 fraudul transact out of 10 we have βj = 0.1 a for a level with 100 

fraudul transact out of 1000. In the first exampl howev we comput βj use 

onli 10 observ wherea in the second we can use 1000 observations, therefor in 

the second scenario we be more confid about the probabl calculation. 

In our work we use a score function which combin some a-priori fraud probabl 

with βj . the idea be that when there’ not much inform (level with few transac- 

tions) we should use what we call the averag fraud probabl (afp) that be the 

mean probabl of have a fraud in a day. On the other hand, when we have enough 

inform we want to consid the fraud probabl come from the factor level (de- 

fin by βj). We use a weight averag of afp and βj where the weight αj give 

to βj be defin by the proport of transact for that level to all the transactions: 

αj = 
nf=j 
N . As a result a factor can be transform into a numer featur by associ- 

ate to each level a fraud score Sj a follow: 

Sj = αjβj + (1− αj)afp (5.1) 

In thi score function however, even with the maximum valu of αj (which be alway 

less than 1) we still have the influenc of the a-priori part give by (1 − αj)afp. To 
avoid thi problem, we can transform the previou function to bind the weight to be in 

the rang [0, 1] use a new weight α′j = 
αj−minαj 

maxαj−minαj . We can now rewrit (5.1) as: 

Sj = α 
′ 
jβj + (1− α′j)afp (5.2) 



chapter 5. learn from evolv data stream with skew distribut 97 

A new problem with thi new type of score function emerg when there be a factor 

that do not have a uniform distribut of the transact over it levels. for exampl 

the factor variabl term_mcc (termin merchant categori code) have few frequent 

level and mani rare levels. with thi factor we would end up with few level have a 

big weight αj and mani level with small αj (figur 5.4(a)). In thi kind of situat 

we can appli the log function to have a smoother α′j (figur 5.4(b)). 


! 

(a) α′j = 
αj−minαj 

maxαj−minαj 

! 

(b) α′j = 
log (αj−minαj) 

log (maxαj−minαi) 

figur 5.4: weight α′j for variabl term_mcc. 

solv the factor problem, the dataset now contain onli numer variables, where the 

origin discret variabl have be transform into numer featur rang from 0 

(low risk) to 1 (high risk). 

result 

our experiment analysi allow one to compar sever strategi for credit card fraud 

detection. base on the approach present in section 5.1.2, our experiment find 

aim to give guidelin to practition work on credit card fraud detection. To evalu 

our results, we measur the perform of the detect in term of auc, AP and Pk 
(see section 2.2.3). 

influenc of algorithm and train set size in a static approach 

the static approach (describ in section 5.1.2) be one of the most commonli use by 

practition becaus of it simplic and rapidity. however, open question remain 

about which learn algorithm should be use and the consequ sensit of the 

accuraci to the train size. We test three differ supervis algorithms: rf, 



chapter 5. learn from evolv data stream with skew distribut 98 

nnet and svm provid by the R softwar [25]. We use R version 3.0.1 with packag 

randomforest [222], e1071 [228], unbalanc [24] and mass [231]1. 

In order to ass the impact of the train set size (in term of days/batches) we carri 

out the predict with differ window (K = 30, 60 and 90). all train set be 

rebalanc use undersampl and all experi be replic five time to reduc 

the varianc caus by the sampl implicit in unbalanc techniques. figur 5.5 show 

the sum of the rank from the friedman test [232] for each strategi in term of ap, auc 

and pk. for each batch, we rank the strategi from the least to the best performing. 

then we sum the rank over all batches. more formally, let rs,b ∈ {1, ..., S} be the rank 
of strategi s on batch b and S be the number of strategi to compare. the strategi with 

the high accuraci in b have rs,b = S and the one with the low have rs,b = 1. then 

the sum of rank for the strategi s be defin a 
∑B 

b=1 rs,b, where B be the total number 

of batches. the high the sum, the high be the number of time that one strategi be 

superior to the others. the white bar denot model which be significantli bad than 

the best (pair t-test base on the rank of each batch). 

the strategi name follow a structur built on the follow options: 

• algorithm use (rf, svm, nnet) 

• sampl method (under, smote, easyensemble) 

• model updat frequenc (one, daily, 15days, weekly) 

• number of model in the ensembl (m) 

• learn approach (static, update, propag and forget) 

• learn paramet (k, kgen) 

then the strategi option be concaten use the dot a separ point (e.g. 

rf.under.daily.10m.update.60k). In both datasets, random forest clearli outper- 

form it competitor and, a expected, accuraci be improv by increas the train 

size (figur 5.5). becaus of the signif superior of random forest with re- 

spect to the other algorithms, in what follow we will limit to consid onli thi learn 

algorithm. 

advantag of updat model 

here we ass the advantag of adopt the updat approach describ in section 5.1.2. 

figur 5.6 report the result for differ valu of K and M . the strategi be call 
1for each classifi we use the default set provid by the package. 



chapter 5. learn from evolv data stream with skew distribut 99 

nnet.under.one.1m.static.60k 

svm.under.one.1m.static.60k 

nnet.under.one.1m.static.90k 

svm.under.one.1m.static.90k 

rf.under.one.1m.static.30k 

rf.under.one.1m.static.60k 

rf.under.one.1m.static.90k 

0 500 1000 1500 

sum of the rank 

best signific 
fals 
true 

metric: AP 

(a) metric: AP 

svm.under.one.1m.static.60k 

svm.under.one.1m.static.90k 

nnet.under.one.1m.static.60k 

nnet.under.one.1m.static.90k 

rf.under.one.1m.static.30k 

rf.under.one.1m.static.60k 

rf.under.one.1m.static.90k 

0 500 1000 1500 

sum of the rank 

best signific 
fals 
true 

metric: auc 

(b) metric: auc 

nnet.under.one.1m.static.60k 

svm.under.one.1m.static.60k 

nnet.under.one.1m.static.90k 

svm.under.one.1m.static.90k 

rf.under.one.1m.static.30k 

rf.under.one.1m.static.60k 

rf.under.one.1m.static.90k 

0 500 1000 1500 

sum of the rank 

best signific 
fals 
true 

metric: precisionrank 

(c) metric: Pk 

figur 5.5: comparison of static strategi use sum of rank in all batches. 



chapter 5. learn from evolv data stream with skew distribut 100 

daili if a model be built everi day, weekli if onc a week or 15day if everi 15 days. 

We compar ensembl strategi (M > 1) with model built on singl batch (K = 1) 

against singl model strategi (M = 1) use sever batch in the train (K > 1). 

for all metrics, the best strategi be rf.under.daily.5m.update.90k. It creat a new 

model at each batch use previou 90 day (K = 90) for train and keep the last 5 

model creat (M = 5) for predictions. In the case of AP howev thi strategi be not 

statist good than the ensembl approach rank a second. 

for all metrics, the strategi that use onli the current batch to build a model (K = 1) 

be coher the worst. thi confirm the result of previou analysi show that a 

too short window of data (and consequ a veri small fraction of frauds) be insuffici 

to learn a reliabl model. when compar the updat frequenc of the model use 

the same number of batch for train (K = 90), daili updat be rank alway good 

than weekli and 15days. thi confirm the intuit that the fraud distribut be alway 

evolv and therefor it be good to updat the model a soon a possible. 

benefit of propag old fraud 

thi section ass the accuraci of the propag and forget approach describ in 

section 5.1.2 whose rational be to avoid discard old fraudul observations. 

accumul old fraud lead to less unbalanc batches. In order to avoid have 

batch where the accumul fraud outnumb the genuin transactions, two option 

be available: i) forget some of the old fraud ii) accumul old genuin trans- 

action a well. In the first case when the accumul fraud repres 40% of the 

transactions, new fraud replac old fraud a in gao [171]. In the second case we accu- 

mulat genuin transact from previou kgen batches, where kgen defin the number 

of batch use (see figur 5.3). 

figur 5.7 show the sum of rank for differ strategi where the genuin transact 

be take from a differ number of day (kgen). the best strategi accord to AP 

and Pk us an ensembl of 5 model for each batch (M = 5) and 30 day for genuin 

transact (kgen = 30). the same strategi rank third in term of auc and be 

significantli bad than the best. To creat ensembl we use a time-bas array of 

model of fix sizem , which mean that when the number of model avail be great 

than M , the most recent in time model replac the M th model in the array remov 

the old model in the ensemble. 

In gener we see good perform when kgen increas from 0 to 30 and onli in few 

case kgen > 30 lead to significantli good accuracy. note that in all our strategi 



chapter 5. learn from evolv data stream with skew distribut 101 

rf.under.daily.90m.update.1k 
rf.under.daily.60m.update.1k 
rf.under.daily.15m.update.1k 
rf.under.daily.30m.update.1k 
rf.under.daily.1m.update.30k 

rf.under.15days.1m.update.90k 
rf.under.weekly.1m.update.90k 

rf.under.daily.1m.update.60k 
rf.under.daily.1m.update.90k 

rf.under.daily.30m.update.90k 
rf.under.daily.15m.update.90k 
rf.under.daily.5m.update.90k 

0 1000 2000 

sum of the rank 

best signific 
fals 
true 

metric: AP 

(a) metric: AP 

rf.under.daily.90m.update.1k 
rf.under.daily.60m.update.1k 
rf.under.daily.15m.update.1k 
rf.under.daily.30m.update.1k 
rf.under.daily.1m.update.30k 

rf.under.15days.1m.update.90k 
rf.under.daily.1m.update.60k 

rf.under.weekly.1m.update.90k 
rf.under.daily.1m.update.90k 

rf.under.daily.30m.update.90k 
rf.under.daily.15m.update.90k 
rf.under.daily.5m.update.90k 

0 1000 2000 

sum of the rank 

best signific 
fals 
true 

metric: auc 

(b) metric: auc 

rf.under.daily.90m.update.1k 
rf.under.daily.60m.update.1k 
rf.under.daily.15m.update.1k 
rf.under.daily.30m.update.1k 
rf.under.daily.1m.update.30k 

rf.under.15days.1m.update.90k 
rf.under.daily.1m.update.60k 

rf.under.weekly.1m.update.90k 
rf.under.daily.1m.update.90k 

rf.under.daily.30m.update.90k 
rf.under.daily.15m.update.90k 
rf.under.daily.5m.update.90k 

0 500 1000 1500 2000 2500 

sum of the rank 

best signific 
fals 
true 

metric: precisionrank 

(c) metric: Pk 

figur 5.6: comparison of updat strategi use sum of rank in all batches. 



chapter 5. learn from evolv data stream with skew distribut 102 

after select the observ to includ in the train set we use undersampl to 

make sure we have the two class equal represented. 

impact of balanc techniqu on detect accuraci 

So far we consid exclus undersampl a balanc techniqu in our experi- 

ments. In thi section we ass the impact of use altern method like smote 

and easyensemble. experiment result (figur 5.8) show that they both over-perform 

undersampling. 

In our datasets, the number of fraud be on averag 0.4% of all transact in the batch. 

undersampl randomli select a number of genuin transact equal to the num- 

ber of frauds, which mean remov about 99.6% of the genuin transact in the 

batch. easyensembl be abl to reduc the varianc of undersampl by use sever 

sub-model for each batch, while smote creat new artifici fraudul transactions. 

In our experi we use 5 sub-model in easyensemble. for all balanc tech- 

niques, between the three approach present in section 5.1.2, the static approach be 

consist the worse. 

In figur 5.9 we compar the previou strategi in term of averag predict time over 

all batches. smote be comput heavi sinc it consist in oversampling, lead 

to big batch sizes. easyensembl replic undersampl and learn from sever 

sub-batches. thi give high comput time than undersampling. between the 

differ increment approaches, static have the low time a the model be learn onc 

and not retrained. propag and forget strategi have the high predict time over 

all balanc methods. thi be expect sinc it retain old transact to deal with 

unbalanc batches. 

analysi of the best overal strategi 

the larg number of possibl altern (in term of learn classifier, balanc tech- 

niqu and increment learn strategy) requir a joint assess of sever combina- 

tion in order to come up with a recommend approach. figur 5.10 summari the 

best strategi in term of differ metrics. the combin of easyensembl with 

propag and forget emerg a best for all metrics. smote with updat be not signifi- 

cantli bad of the best for AP and pk, but it be not rank well in term of auc. the 

fact that within the best strategi we see differ balanc techniqu confirm that 

in unbalanc data streams, the adopt balanc strategi may play a major role. As 

expect the static approach rank low in figur 5.10 a it be not abl to adapt to the 



chapter 5. learn from evolv data stream with skew distribut 103 

rf.under.daily.1m.forget.0kgen 

rf.under.daily.30m.forget.30kgen 

rf.under.daily.1m.forget.90kgen 

rf.under.daily.1m.forget.60kgen 

rf.under.daily.1m.forget.30kgen 

rf.under.daily.1m.forget.15kgen 

rf.under.daily.15m.forget.30kgen 

rf.under.daily.10m.forget.30kgen 

rf.under.daily.5m.forget.30kgen 

0 1000 2000 3000 

sum of the rank 

best signific 
fals 
true 

metric: AP 

(a) metric: AP 

rf.under.daily.1m.forget.0kgen 

rf.under.daily.1m.forget.15kgen 

rf.under.daily.30m.forget.30kgen 

rf.under.daily.1m.forget.30kgen 

rf.under.daily.15m.forget.30kgen 

rf.under.daily.10m.forget.30kgen 

rf.under.daily.5m.forget.30kgen 

rf.under.daily.1m.forget.60kgen 

rf.under.daily.1m.forget.90kgen 

0 1000 2000 3000 

sum of the rank 

best signific 
fals 
true 

metric: auc 

(b) metric: auc 

rf.under.daily.1m.forget.0kgen 

rf.under.daily.30m.forget.30kgen 

rf.under.daily.1m.forget.15kgen 

rf.under.daily.15m.forget.30kgen 

rf.under.daily.1m.forget.30kgen 

rf.under.daily.10m.forget.30kgen 

rf.under.daily.1m.forget.90kgen 

rf.under.daily.1m.forget.60kgen 

rf.under.daily.5m.forget.30kgen 

0 1000 2000 

sum of the rank 

best signific 
fals 
true 

metric: precisionrank 

(c) metric: Pk 

figur 5.7: comparison of forget strategi use sum of rank in all batches. 



chapter 5. learn from evolv data stream with skew distribut 104 

rf.under.one.1m.static.90k 

rf.smote.one.1m.static.90k 

rf.easyensemble.one.1m.static.90k 

rf.under.daily.1m.update.90k 

rf.under.daily.1m.forget.90kgen 

rf.easyensemble.daily.1m.update.90k 

rf.smote.daily.1m.forget.90kgen 

rf.easyensemble.daily.1m.forget.90kgen 

rf.smote.daily.1m.update.90k 

0 500 1000 1500 

sum of the rank 

best signific 
fals 
true 

metric: AP 

(a) metric: AP 

rf.smote.one.1m.static.90k 

rf.under.one.1m.static.90k 

rf.easyensemble.one.1m.static.90k 

rf.under.daily.1m.update.90k 

rf.smote.daily.1m.forget.90kgen 

rf.under.daily.1m.forget.90kgen 

rf.smote.daily.1m.update.90k 

rf.easyensemble.daily.1m.update.90k 

rf.easyensemble.daily.1m.forget.90kgen 

0 500 1000 1500 

sum of the rank 

best signific 
fals 
true 

metric: auc 

(b) metric: auc 

rf.under.one.1m.static.90k 

rf.smote.one.1m.static.90k 

rf.easyensemble.one.1m.static.90k 

rf.under.daily.1m.update.90k 

rf.under.daily.1m.forget.90kgen 

rf.smote.daily.1m.forget.90kgen 

rf.easyensemble.daily.1m.update.90k 

rf.easyensemble.daily.1m.forget.90kgen 

rf.smote.daily.1m.update.90k 

0 500 1000 1500 

sum of the rank 

best signific 
fals 
true 

metric: precisionrank 

(c) metric: Pk 

figur 5.8: comparison of differ balanc techniqu and strategi use sum of 
rank in all batches. 



chapter 5. learn from evolv data stream with skew distribut 105 

easyensembl smote under 

0 

200 

400 

Da 
ili 

.1 
M 

.F 
or 

ge 
t.9 

0K 
ge 

n 
Da 

ili 
.1 

M 
.U 

pd 
at 

e.9 
0K 

On 
e.1 

M 
.S 

ta 
tic 

.9 
0K 

Da 
ili 

.1 
M 

.F 
or 

ge 
t.9 

0K 
ge 

n 
Da 

ili 
.1 

M 
.U 

pd 
at 

e.9 
0K 

On 
e.1 

M 
.S 

ta 
tic 

.9 
0K 

Da 
ili 

.1 
M 

.F 
or 

ge 
t.9 

0K 
ge 

n 
Da 

ili 
.1 

M 
.U 

pd 
at 

e.9 
0K 

On 
e.1 

M 
.S 

ta 
tic 

.9 
0K 

strategi 

C 
om 

pu 
ta 

tio 
na 

l t 
im 

e 

algo 
RF 

figur 5.9: comparison of differ balanc techniqu and strategi in term 
of averag predict time (in seconds) over all batches. experi run on a HP 
proliant bl465c G5 blade with 2x amd opteron 2.4 ghz, 4 core each and 32 GB 

ddr3 ram. 

chang distribution. the propag and forget approach be significantli good than 

updat for easyensemble, while smote give good rank with update. 

It be worth to note that strategi which combin more than one model (M > 1) to- 

gether with undersampl be not superior to the predict with a singl model and 

easyensemble. easyensembl learn from differ sampl of the major class, which 

mean that for each batch differ concept of the major class be learned. 

5.1.4 discuss 

the need to detect fraudul pattern in huge amount of data demand the adopt of 

automat methods. the scarciti of public avail dataset in credit card transact 

give littl chanc to the commun to test and ass the impact of exist techniqu 

on real data. the goal of thi first part of the chapter be to give some guidelin to 

practition on how to tackl the detect problem. 

credit card fraud detect reli on the analysi of record transactions. however, sin- 

gle transact inform be not consid suffici to detect a fraud occurr [11] 

and the analysi have to take into consider the cardhold behavior. To thi purpos 

we includ cardhold inform into the transact by comput aggreg vari- 

abl on histor transact of the same card. As new credit-card transact keep 

arriving, the detect system have to process them a soon a they arriv and avoid re- 

tain in memori too mani old transactions. We compar three altern approach 



chapter 5. learn from evolv data stream with skew distribut 106 

nnet.under.one.1m.static.60k 
svm.under.one.1m.static.60k 

nnet.under.one.1m.static.90k 
nnet.under.one.1m.static.120k 

svm.under.one.1m.static.90k 
svm.under.one.1m.static.120k 

rf.under.one.1m.static.30k 
rf.under.one.1m.static.60k 

rf.smote.one.1m.static.90k 
rf.under.one.1m.static.90k 

rf.easyensemble.one.1m.static.90k 
rf.under.one.1m.static.120k 

rf.under.15days.1m.update.90k 
rf.under.weekly.1m.update.90k 

rf.under.daily.1m.update.90k 
rf.under.daily.1m.forget.90kgen 

rf.under.daily.30m.forget.30kgen 
rf.under.daily.30m.update.90k 
rf.under.daily.15m.update.90k 

rf.under.daily.5m.update.90k 
rf.under.daily.15m.forget.30kgen 
rf.under.daily.10m.forget.30kgen 

rf.easyensemble.daily.1m.update.90k 
rf.smote.daily.1m.forget.90kgen 

rf.under.daily.5m.forget.30kgen 
rf.smote.daily.1m.update.90k 

rf.easyensemble.daily.1m.forget.90kgen 

0 1000 2000 3000 4000 

sum of the rank 

best signific 
fals 
true 

metric: AP 

(a) metric: AP 

svm.under.one.1m.static.60k 
svm.under.one.1m.static.120k 
svm.under.one.1m.static.90k 

nnet.under.one.1m.static.60k 
nnet.under.one.1m.static.90k 

nnet.under.one.1m.static.120k 
rf.under.one.1m.static.30k 
rf.under.one.1m.static.60k 

rf.smote.one.1m.static.90k 
rf.under.one.1m.static.90k 

rf.easyensemble.one.1m.static.90k 
rf.under.daily.30m.forget.30kgen 

rf.under.one.1m.static.120k 
rf.under.daily.15m.forget.30kgen 

rf.under.15days.1m.update.90k 
rf.under.daily.10m.forget.30kgen 
rf.under.daily.5m.forget.30kgen 
rf.under.weekly.1m.update.90k 

rf.smote.daily.1m.forget.90kgen 
rf.under.daily.1m.update.90k 

rf.under.daily.30m.update.90k 
rf.under.daily.1m.forget.90kgen 
rf.smote.daily.1m.update.90k 
rf.under.daily.15m.update.90k 

rf.under.daily.5m.update.90k 
rf.easyensemble.daily.1m.update.90k 

rf.easyensemble.daily.1m.forget.90kgen 

0 1000 2000 3000 4000 

sum of the rank 

best signific 
fals 
true 

metric: auc 

(b) metric: auc 

nnet.under.one.1m.static.60k 
svm.under.one.1m.static.60k 

nnet.under.one.1m.static.90k 
svm.under.one.1m.static.90k 

nnet.under.one.1m.static.120k 
svm.under.one.1m.static.120k 

rf.under.one.1m.static.30k 
rf.under.one.1m.static.60k 

rf.smote.one.1m.static.90k 
rf.under.one.1m.static.90k 

rf.easyensemble.one.1m.static.90k 
rf.under.one.1m.static.120k 

rf.under.15days.1m.update.90k 
rf.under.daily.30m.forget.30kgen 

rf.under.weekly.1m.update.90k 
rf.under.daily.15m.forget.30kgen 
rf.under.daily.10m.forget.30kgen 

rf.under.daily.1m.update.90k 
rf.under.daily.30m.update.90k 

rf.smote.daily.1m.forget.90kgen 
rf.under.daily.5m.forget.30kgen 
rf.under.daily.1m.forget.90kgen 

rf.under.daily.15m.update.90k 
rf.under.daily.5m.update.90k 

rf.easyensemble.daily.1m.update.90k 
rf.smote.daily.1m.update.90k 

rf.easyensemble.daily.1m.forget.90kgen 

0 1000 2000 3000 4000 

sum of the rank 

best signific 
fals 
true 

metric: precisionrank 

(c) metric: Pk 

figur 5.10: comparison of all strategi use sum of rank in all batches. 



chapter 5. learn from evolv data stream with skew distribut 107 

(static, updat and propag and forget) to studi which approach be good to adopt 

in unbalanc and non-stationari credit card data streams. 

In the static learn set a wide rang of techniqu have be propos to deal 

with unbalanc datasets. however, in online/increment learn few attempt have 

tri to deal with unbalanc data stream [52, 148, 170]. In these works, the most 

common balanc techniqu consist in undersampl the major class in order to 

reduc class imbalance. In our work we adopt two altern to undersampling: 

smote and easyensemble. In particular we show that they be both abl to return 

high accuracies. our framework can be easili extend to includ other data-level 

balanc techniques. 

the experiment part have show that in data streams, with standard classif 

algorithms, when the distribut be skew toward one class it be import maintain 

previou minor exampl in order to learn a good separ of two classes. instanc 

propag from previou batch have the effect of increas the minor class in the 

current batch, but it be of limit impact give the small number of frauds. We test 

sever ensembl and singl model strategi use differ number of batch for 

training. In gener we see that model train on multipl batch have good accuraci 

than singl batch models. multi-batch model learn on overlap train sets, when 

thi happen singl model strategi can beat ensembles. 

our framework address the problem of non-stationar in data stream by creat a 

new model everi time a new batch be available. thi approach have show good result 

than updat the model at a low frequenc (weekli or everi 15days). updat the 

model be crucial in a non-stationari environment, thi intuit be confirm by the bad 

result of the static approach. In our dataset, overal we saw random forest beat 

neural network and support vector machine. the final best strategi implement the 

propag and forget approach togeth with easyensembl and daili update. 

5.2 use hddt to avoid instanc propag 

the result from the previou section have show that, in fraud detection, it be import 

to updat the model a soon a new data arriv in order to adapt to possibl chang 

in the data distributions. In thi second part of the chapter we aim to improv the 

updat approach present in section 5.1.2 by propos helling distanc decis 

tree (hddt) [103] a a base learner for data streams. 

sever state-of-the-art techniqu for unbalanc data stream have address the imbal- 

anc problem by propag minor observ between batches, with c4.5 decis 



chapter 5. learn from evolv data stream with skew distribut 108 

tree be the most common algorithm use [148, 171, 175, 176]. these techniqu re- 

tain previou minor class instanc in order to provid the algorithm balanc batches, 

sinc the classifi be not abl to learn from skew distributions. however, when data 

arriv a a continu stream of transactions, it can becom imposs to store or prop- 

agat previou observations. therefore, there be the need of tool that be abl to process 

stream of data a soon a they arrive, without revis old observations. 

thi section be base on our previou work [19], where we use hddt [103] a a base 

classifi for data stream in order to avoid instanc propag between subsequ 

batch of data. We show that hddt be abl to produc superior perform than 

standard c4.5 decis tree in term of predict accuracy, comput time and 

resourc needed. 

In order to combat concept drift we have use a batch-ensembl model combin 

base on helling distanc and inform gain a in [175]. thi choic have prove to 

be benefici in the presenc of chang distribut in the data. We have test our 

framework with differ type of datasets: unbalanc dataset without know concept 

drift, artifici dataset with know concept drift and a highli unbalanc credit card 

fraud dataset with concept drift. 

5.2.1 helling distanc decis tree 

origin introduc to quantifi the similar between two probabl distribut [233], 

the helling distanc (hd) have be recent propos a a split criterion in decis 

tree to improv the accuraci in unbalanc problem [103, 230]. In the context of data 

streams, it have produc excel result in detect classifi perform degrad 

due to concept drift [175, 234]. let P1 and P2 be two discret probabl distribut 

take valu φ ∈ Φ, helling distanc be defin as: 

hd(p1, p2) = 

√∑ 
φ∈φ 

(√ 
p1(φ)− 

√ 
p2(φ) 

)2 
(5.3) 

helling distanc have sever properties: 

• hd(p1, p2) = hd(p2, p1) (symmetric) 

• hd(p1, p2) >= 0 (non-negative) 

• hd(p1, p2) ∈ [0, 
√ 

2] 

start from (5.3), cieslak and chawla [103] deriv a new decis tree split criterion 

base on helling distanc that be skew insensitive. they start from the assumpt 



chapter 5. learn from evolv data stream with skew distribut 109 

that all numer featur be partit into q bins, so that the result dataset be 

make of onli categor variables. then for each featur f , they comput the distanc 

between the class over all the feature’ partitions. In the case of a binari classif 

problem where f+ denot the instanc of the posit class and f− the negatives, the 

helling distanc between f+ and f− is: 

hd(f+, f−) = 

√√√√√ q∑ 
j=1 

√ |f+j | 
|f+| − 

√ 
|f−j | 
|f−| 

2 (5.4) 
where j defin the jth bin of featur f and |f+j | be the number of posit instanc of 
featur f in the jth bin. At each node of the tree, hd(f+, f−) be comput for each 

featur and then the featur with the maximum distanc be use to split. the author 

of [55, 103, 235] recommend to leav the tree unprun and to use laplac smooth 

for obtain posterior probabilities.2 note that the class prior do not appear explicitli 

in equat (5.4), which mean that class imbal ratio do not influenc the distanc 

calculation. 

5.2.2 helling distanc a weight ensembl strategi 

In evolv data stream it be import to understand how similar two consecut data 

batch be in order to decid whether a model learn on a previou batch be still valid. 

lichtenwalt and chawla [175] propos to employ HD a a measur of the distanc 

between two separ batches. let u defin a Bt the batch at time t use for train 

and bt+1 a the subsequ test batch. first numer featur be discret into 

equal-width bins, then helling distanc between Bt and bt+1 for a give featur f be 

calcul as: 

hd(bft ,B 
f 
t+1) = 

√√√√√∑ 
v∈f 

√ |bf=vt | 
|bt| 

− 

√ 
|bf=vt+1 | 
|bt+1| 

2 (5.5) 
where |bf=vt | be the number of instanc of featur f take valu v in the batch at time 
t, while |bt| be the total number of instanc in the same batch. 

equat (5.5) do not account for differ in featur relevance. In general, featur 

distanc should have a high weight when the featur be relevant, while a small weight 

should be assign to a weak feature. make the assumpt that featur relev 

remain stabl over time, lichtenwalt and chawla [175] suggest use the inform 

gain to weight the distances. for a give featur f of a batch B, the inform gain 
2when the class distribut be unbalanced, prune would remov those leaf with few sampl 

which be also the one more like to be associ with the minor class. 



chapter 5. learn from evolv data stream with skew distribut 110 

be defin a the decreas in entropi H of a class c: 

ig(b, f) = h(bc)−h(bc|bf ) (5.6) 

where Bc defin the class of the observ in batch B and Bf the observ of 

featur f . for the test batch we cannot comput ig(b, f), a the label be not 

provided, therefor the featur relev be calcul on the train batch. We can now 

defin a new distanc function that combin inform gain and helling distanc 

as: 

hdig(bt,bt+1, f) = hd(b 
f 
t ,B 

f 
t+1) ∗ (1 + ig(bt, f)) (5.7) 

hdig(bt,bt+1, f) provid a relevance-weight distanc for each singl feature. the 

final distanc between two batch be then comput by take the averag over all the 

features. 

ahdig(bt,bt+1) = 

∑ 
f∈bt hdig(bt,bt+1, f) 

|f ∈ bt| 
(5.8) 

We learn a new model a soon a a new batch be avail and combin learn model into 

an ensembl where the weight of the model be invers proport to the batches’ 

distances. the low the distanc between two batch the more similar be the concept 

between them. In a stream environ with concept drift we should expect good 

perform on the current batch from model learn on similar concepts. with thi 

reason in mind, the ensembl weight should be high for small distances. We use 

the same transform of [175], where the weight wt of a classifi train on Bt and 

that predict on bt+1 be defin a follows: 

wt = ahdig(bt,bt+1)−m (5.9) 

where M repres the ensembl size. 

5.2.3 experiment assess 

mani of the data stream framework for concept drift and unbalanc data use 

c4.5 [102] decis tree a the base learner [148, 171, 175, 236]. In our experi 

we compar the result of c4.5 to the helling distanc decis tree (hddt) with 

the paramet suggest in [103] (unprun and with laplac smoothing). the com- 

parison be do use differ propagation/sampl method and model combin 

(ensembl vs. singl models). 

In an unbalanc data stream, for each batch/chunk, the posit class exampl repre- 

sent the minor of the observations. each batch can be consid a a small unbalanc 

dataset, permit all the techniqu alreadi develop for static unbalanc dataset 



chapter 5. learn from evolv data stream with skew distribut 111 

to be implemented. In a stream environment, however, it be possibl to collect minor- 

iti observ from previou batch to combat class imbalance. for our experi 

we consid instanc propag method that assum no sub-concept within the 

minor class. In particular we use gao’ [171] and lichtenwalter’ [175] propag 

method present in section 3.3 and two other benchmark method (under and bl): 

• SE (gao’ [171] propag of rare class instanc and undersampl at 40%) 

• BD (lichtenwalter’ boundari definit [175]: propag rare-class instanc 
and instanc in the neg class that the current model misclassifies.) 

• under (undersampling: no propag between batches, undersampl at 40%) 

• BL (baseline: no propagation, no sampling) 

the first two method can be consid a oversampl method sinc the minor 

proport in the batch be augmented. from now on, for simplic we will call all the 

previous discuss instanc propag method sampl strategies. 

for each of the previou sampl strategi we tested: i) hdig: ensembl with weight 

from (5.9) and ii) No ensemble: singl classifier. In the first case, an ensembl be built 

combin all model learn with weight give by (5.9). In the second case, we use the 

model learn in the current batch to predict the incom batch. thi option have the 

advantag of be faster a no model be store dure the learn phase. 

In all our experi we report the result in term of auc. the framework be 

write in java and we use the weka [237] implement of c4.5 and hddt. We 

use uci dataset [1] to first studi the unbalanc problem without worri about 

concept drift. these dataset be not inher sequenti and exhibit no concept drift; 

we render them a data stream by random the order of instanc and process 

them in batch a in [175]. then we use the moa [238] framework to gener some 

artifici dataset with drift featur to test the behavior of the algorithm under 

concept drift. final we use a real-world credit card dataset which be highli unbalanc 

and whose fraud be chang in type and distribution. thi dataset contain credit 

card transact from onlin payment between the 5th of septemb 2013 and the 25th 

of septemb 2013, where onli 0.15% of the transact be fraudulent. 

We first test the differ sampl strategi use hddt and c4.5. On the left 

side of figur 5.11 we see the result where hdig distanc (discuss in section 5.2.2) 

be use to weight the model from differ batch accord to (5.9). On the right 

be the result where onli the model of the current batch be use for prediction. the 

column indic the batch mean auc for each strategi averag over all uci datasets. 



chapter 5. learn from evolv data stream with skew distribut 112 

tabl 5.3: dataset 

dataset sourc # instanc # featur imbal ratio 
adult uci 48,842 14 3.2:1 
can uci 443,872 9 52.1:1 

compustat uci 13,657 20 27.5:1 
covtyp uci 38,500 10 13.0:1 
footbal uci 4,288 13 1.7:1 
ozone-8h uci 2,534 72 14.8:1 
wrd uci 99,200 41 1.0:1 
text uci 11,162 11465 14.7:1 

driftedl moa 1,000,000 25 9.0:1 
driftedrbf moa 1,000,000 11 1.02:1 
driftedwav moa 1,000,000 41 2.02:1 
creditcard fraud 3,143,423 36 658.8:1 

thi mean that for each dataset we comput the mean auc over all batch and then 

averag the result between all datasets. In gener we notic that hddt be abl to 

hdig No ensembl 

0.00 

0.25 

0.50 

0.75 

BD BL SE under BD BL SE under 

sampl 

AU 
RO 

C algorithm 
c4.5 
hddt 

figur 5.11: batch averag result in term of auc (higher be better) use differ 
sampl strategi and batch-ensembl weight method with c4.5 and hddt over 

all uci datasets. 

outperform c4.5. for each sampl method we see that the ensembl counterpart of 

the singl model have high accuracy. 

In figur 5.12 we display the averag comput time. As expected, when a singl 

classifi be use the framework be much faster, but it come at the cost of low accuraci 

(see figur 5.11). when undersampl be use in the framework we have the small 

comput time, a it us a subset of the observ in each batch and no instanc 

be propag between batches. 

figur 5.13 show the result for the dataset with concept drift gener use the 

moa framework. hdig-bas ensembl return good result than a singl classifi 

and hddt again give good accuraci than c4.5. 



chapter 5. learn from evolv data stream with skew distribut 113 

hdig No ensembl 

0 

1000 

2000 

3000 

4000 

BD BL SE under BD BL SE under 

sampl 

TI 
M 

E algorithm 
c4.5 
hddt 

figur 5.12: batch averag result in term of comput time (lower be better) 
use differ sampl strategi and batch-ensembl weight method with c4.5 

and hddt over all uci datasets. 

hdig No ensembl 

0.0 

0.2 

0.4 

0.6 

0.8 

BD BL SE under BD BL SE under 

sampl 

AU 
RO 

C algorithm 
c4.5 
hddt 

figur 5.13: batch averag result in term of comput auc (higher be better) 
use differ sampl strategi and batch-ensembl weight method with c4.5 

and hddt over all drift moa datasets. 

figur 5.14 display the result on the creditcard dataset. thi dataset be a good exampl 

of an unbalanc data stream with concept drift. onc again hddt be alway good than 

c4.5, howev the increas in perform give by the ensembl be less import than 

the one regist with the uci datasets. from figur 5.14, it be hard to discrimin 

the best strategy, a mani of them have compar results. 

figur 5.15 show the sum of the rank for each strategi over all the batches. As explain 

in section 5.1.3, for each batch, we assign the high rank to the most accur strategi 

and then sum the rank over all batches. the high the sum, the high the number of 

time one strategi be superior to the others. 

the strategi with the high sum of rank (bl_hdig_hddt ) combin BL with 

hdig ensembl of hddts. BL method leaf the batch unbalanced, which mean 

that the best strategi be actual the one avoid instanc propagation/sampling. A 



chapter 5. learn from evolv data stream with skew distribut 114 

hdig No ensembl 

0.00 

0.25 

0.50 

0.75 

1.00 

BD BL SE under BD BL SE under 

sampl 

AU 
RO 

C algorithm 
c4.5 
hddt 

figur 5.14: batch averag result in term of auc (higher be better) use differ 
sampl strategi and batch-ensembl weight method with c4.5 and hddt over 

the credit card dataset. 

pair t-test on the rank be then use to compar each strategi with the best. base 

on thi test, we saw that the strategi with the second-highest sum of rank (un- 

der_hdig_hddt ) be not significantli bad than the first. compar to the first, 

thi strategi implement undersampl at each batch instead of bl. figur 5.15 con- 

firm that hddt be good than c4.5. the c4.5 implement of the win strategi 

(bl_hdig_c4.5 ) be significantli bad than the best (bl_hdig_hddt ). the same 

happen for the second best rank strategi (under_hdig_hddt rank high 

than under_hdig_c4.5 ). 

bl_c4.5 
se_c4.5 
bd_c4.5 

under_c4.5 
bl_hdig_c4.5 

se_hddt 
se_hdig_c4.5 
under_hddt 

bl_hddt 
bd_hdig_c4.5 

bd_hddt 
bd_hdig_hddt 

under_hdig_c4.5 
se_hdig_hddt 

under_hdig_hddt 
bl_hdig_hddt 

0 100 200 

sum of the rank 

best signific 
fals 
true 

auroc 

figur 5.15: comparison of differ strategi use the sum of rank in all batch 
for the credit card dataset in term of auc. In gray be the strategi that be not 

significantli bad than the best have the high sum of ranks. 

5.2.4 discuss 

To our knowledge, our work be the first to evalu the use of the hddt tree algorithm 

for stream data. mani of the state-of-the-art techniqu use the c4.5 algorithm 



chapter 5. learn from evolv data stream with skew distribut 115 

combin with sampl or instanc propag to balanc the batch befor training. 

We have show that when use in data streams, hddt without sampl typic lead 

to good result than c4.5 with sampling. thus, hddt can offer good perform 

than c4.5, while actual remov sampl from the process. 

the remov of the propagation/sampl step in the learn process have sever benefits: 

• It allow a single-pass approach (the observ be process a soon a they 
arrive, avoid sever pass throughout the batch for instanc propagation). 

• It reduc the comput cost/resourc need (thi be import sinc with 
massiv amount of data it may no longer be possibl to store/retriev old in- 

stances). 

• It avoid the problem of find previou minor instanc from the same concept 
(in the case of a new concept in the minor class, it may not be possibl to find 

previou observ to propagate). 

We have use artifici dataset to test how differ strategi work under concept drift. 

the use of hdig a an ensembl weight strategi have increas the perform of 

the singl classifiers, not onli in artifici dataset with know drift (moa datasets), but 

even in dataset whose distribut be assum to be more or less stabl (uci datasets). 

finally, we test our framework on a proprietari dataset contain credit card trans- 

action from onlin payment. thi be a particularli interest dataset, a it be extrem 

unbalanc and exhibit concept drift within the minor class. hddt perform veri 

well when combin with BL (no sampling) and undersampling. An import featur of 

these basic sampl strategi be the fact that framework implement them be much 

faster (see figur 5.12) sinc no observ be store from previou batches. when 

these two sampl strategi give compar results, the practition could prefer un- 

dersampl a it be more memori effici sinc it us a reduc part of the batch for 

training. By use undersampling, however, a lot of instanc from the major class 

be not considered. 

5.3 conclus 

In the first part of the chapter (section 5.1) we have first formal the problem of fraud 

detect and then present three differ approach for unbalanc data streams. We 

have compar a static approach against two dynam way to learn in the presenc of 

non-stationar and unbalanc distribution. from our experiment assess the 



chapter 5. learn from evolv data stream with skew distribut 116 

static approach be consist the bad in term of predict accuracy, a strong signal 

that the data stream be evolv and updat the detect strategi be beneficial. from 

the experi it emerg also that it be import to use strategi to rebal the 

batch of the stream befor train a classif algorithm, either by resampl (e.g. 

undersampling, smote) or by propag instanc from the minor class along the 

stream. 

however, it be not alway possibl to store or revisit previou transact in high fre- 

quenci data streams. for thi reason, in the second part of the chapter (section 5.2) 

we have present a classif algorithm (hddt) optim for unbalanc dataset 

and use it in a data stream environ in order to avoid the propag of instanc 

between batches. hddt show good perform without the need of rebalanc the 

two class (e.g. no undersampl required) and prove to perform good than standard 

decis tree (e.g. c4.5). 



chapter 6 

A real-world fraud detect 

systems: concept drift adapt 

with alert-feedback interact 

part of the result present in thi chapter have be publish in the follow paper: 

• andrea dal pozzolo, giacomo boracchi, olivi caelen, cesar alippi, and gian- 
luca bontempi. credit card fraud detect and concept-drift adapt with 

delay supervis information. In neural network (ijcnn), the 2015 interna- 

tional joint confer on. ieee, 2015. 

most fdss monitor stream of credit card transact by mean of classifi return 

alert for the riskiest payments. fraud detect differ from convent classif 

because, in a first phase, human investig who have time to ass onli a reduc 

number of alert provid a small set of supervis sampl denot a feedbacks. label 

of the vast major of transact be make avail onli sever day later, when 

custom have possibl report unauthor transactions. these transact defin 

an addit set of supervis sampl call delay samples. the delay in obtain 

accur label and the interact between alert and supervis inform have to be 

care take into consider when learn in a concept-drift environment. 

In thi chapter we address a realist fraud detect set and we show that feedback 

and delay sampl have to be handl separately. We design two prototyp of fd 

on the basi of an ensembl and a sliding-window approach (section 6.3.1) and we show 

that the win strategi consist in train two separ classifi (on feedback and 

delay samples, respectively), and then aggreg the outcomes. experi on larg 

117 



chapter 6. concept-drift adapt with alert-feedback interact 118 

dataset show that the alert precision, which be the primari concern of investigators, can 

substanti be improv by the propos approach. 

In order to obtain precis alerts, feedback sampl have to receiv larg weight than 

non-alert transact and method that diminish their role in the learn process 

lead to loss of predict accuracy. 

6.1 realist work condit 

As discuss in section 3.4, fdss typic relay on classif algorithm to iden- 

tifi transact at risk of fraud that gener alerts, but be not abl to integr the 

feedback that investig provid on the alert rais by the fds. As a consequence, 

most fdss avail in the literatur (e.g. [11, 180, 181]) ignor alert-feedback interac- 

tion (afi), make the unrealist assumpt that all transact be correctli label 

by a supervisor. 

with a limit number of investig onli a restrict quantiti of alert can be checked, 

which mean a small set of label transact return a feedback. non-alert trans- 

action be a larg set of unsupervis sampl that can be either fraud or genuine. 

addit label observ be obtain by mean of cardhold that report unau- 

thoriz transact [20, 61]. the number of custom report fraud not detect by 

the fd be usual small and hard to model sinc cardhold have differ habit when 

it come to check the transcript of credit card transact give by the bank. then, 

everi day in addict to investigators’ feedback, we have histor supervis sampl 

for which the label can safe assum to be correct after some time. In summary, 

we can distinguish between two type of supervis samples: i) feedback provid by 

investig and ii) histor transact whose label be receiv with a larg delay. 

We will call the latter delay sampl to stress the fact that their label be avail onli 

after a while. 

In thi formul we assum that the fd be updat everyday at midnight and the 

detect model be then appli to all the transact occur the follow day. feed- 

back of alert transact be give by investig dure the day and by the end of 

the day we have all the feedback for the alert gener by the fds. In these settings, 

the ML algorithm learn from the batch of feedback avail at the end of the day 

and be not train from each transact incrementally, i.e. the algorithm be train onli 

when a suffici batch of supervis sampl be provided. 



chapter 6. concept-drift adapt with alert-feedback interact 119 

6.2 fraud detect with alert-feedback interact 

As in section 5.1.1, we formul the fraud detect problem a a binari classif 

task where each transact be associ to a featur vector x and a label y. featur 

in x could be the transact amount, the shop id, the card id, the timestamp or the 

country, a well a featur extract from the custom profile. becaus of the time- 

vari natur of the transactions’ stream, typically, fdss train (or update) a classifi 

Kt everi day (t). In general, fdss receiv a continu stream of transact and they 
have to score each transact onlin (i.e. in few milliseconds), however, the classifi 

be updat onc a day, to gather a suffici amount of supervis transactions. the 

set of transact arriv at day t, denot a bt, be process by the classifi kt−1 
train in the previou day (t − 1). the k riskiest transact of Bt be report to 
the investigators, where k > 0 repres the number of alert the investig be abl 

to validate. the report alert At be determin by rank the transact of Bt 
accord to the posterior probabl p̂kt−1(+|x), which be the estimate, return by 
kt−1, of the probabl for x to be a fraud. more formally, At be defin as: 

At = {x ∈ Bt s.t. r(x) ≤ k} (6.1) 

where r(x) ∈ {1, . . . , |bt|} be the rank of the transact x accord to pkt−1(+|x). In 
other terms, the transact with the high probabl rank first (r(x) = 1) and the 

one with the low probabl rank last (r(x) = |bt|). 

onc the alert At be generated, investig provid feedback ft, defin a set of k 

supervis couples: Ft = {(x, y), x ∈ at}, which repres the most recent inform 
that the fd receives. At day t, we also receiv the label of all the transact process 

at day t− δ, provid a set of delay supervis coupl dt−δ = {(x, y), x ∈ bt−δ}, see 
figur 6.1. though investig have not person check these transactions, they be 

by default assum to be genuin after δ days, a far a custom do not report frauds.1 

As a result, the label of all the transact old than δ day be provid at day t. 

the problem of receiv delay label be also refer to a verif latenc [239]. 

feedback Ft can either refer to fraud (correct alerts) or genuin transact (fals 

alerts): correct alert be then true posit (tps), while fals alert be fps. similarly, 

dt−δ contain both fraud (fals negative) and genuin transact (true negatives), 

although the vast major of transact belong to the genuin class. 

the goal of a fd be to return accur alerts: when too mani fp be reported, in- 

vestig might decid to ignor forthcom alerts. thus, what actual matter be 
1 investig typic assum that fraud miss by the fd be report by custom themselv 

(e.g. after have check their credit card balance), within a maximum time-interv of δ days. 



chapter 6. concept-drift adapt with alert-feedback interact 120 

t −1 t t +1 

feedbacks)delayed)samples) 

t −δ 

all)fraudulent)transac6ons)of)a)day) 

all)genuine)transac6ons)of)a)day) 

fraudulent)transac6ons)in)the)feedback) 
genuine)transac6ons)in)the)feedback) 

ftft�1ft�3ft�4ft�5ft�6 ft�2dt�7dt�8 bt+1 

figur 6.1: the supervis sampl avail at day t include: i) feedback of the 
first δ day and ii) delay coupl occur befor the δth day. In thi figur we set 

δ = 7. 

to achiev the high precis in at. As show in section 2.2.3, thi precis can be 

measur by the quantiti 

pk(t) = 
|tpk(t)| 

k 
(6.2) 

where tpk(t) = {(x, y) ∈ At s.t. y = +}.2 pk(t) be then the proport of fraud in the 
top k transact with the high estim likelihood of be fraud [64]. 

6.3 learn strategi 

the fraud detect scenario describ in section 6.2 suggest that learn from feed- 

back Ft be a differ problem than learn from delay sampl in dt−δ. the first 

differ be evident: Ft provid recent, up-to-date, inform while dt−δ might be 

alreadi obsolet onc it be available. the second differ concern the percentag of 

fraud in Ft and dt−δ. while it be clear that the class distribut in dt−δ be alway 

skew toward the genuin class, the number of fraud in Ft actual depend on the 

perform of classifi kt−1: when pk(t) = 0.5 we have feedback Ft with a balanc 
distribution, while for pk(t) > 0.5 we have more fraud than genuin transact in 

ft. the third, and probabl the most subtle, differ be that supervis coupl in Ft 
be not independ drawn, but be instead select by kt−1 among those transact 
that be more like to be frauds. As such, a classifi train on Ft learn how to label 

transact that be most like to be fraudulent, and might be in principl not precis 

on the vast major of genuin transactions. therefore, besid the fact that Ft and dt−δ 
might requir differ resampl methods, Ft and dt−δ be also repres of two 

2note that in thi formul |ft| = |at| and |at| = k. 



chapter 6. concept-drift adapt with alert-feedback interact 121 

differ classif problem and, a such, they have to be separ handled. In 

the following, two tradit fraud detect approach be present (section 6.3.1), 

and further develop to handl separ feedback and delay supervis coupl 

(section 6.3.2). experi in section 6.5 show that thi be a valuabl strategy, which 

substanti improv the alert precision. 

6.3.1 convent classif approach in fd 

dure the fd operation, both feedback Ft and delay supervis sampl dt−δ can be 

exploit for train or updat the classifi kt. In particular, we train the fd con- 
sider the feedback from the last δ day (i.e. {ft,ft−1, . . . ,ft−(δ−1)}) and the delay 
supervis pair from the lastm day befor the feedbacks, i.e. {dt−δ, . . . ,dt−(δ+m−1)}. 

In the follow we present two convent solut for concept-drift adapt [171, 

182] built upon a classif algorithm prove an estim of the probabl p(+|x). 

• wt: a slide window classifi that be daili updat over the supervis sampl 
receiv in the last δ +M days, i.e. {ft, . . . ,ft−(δ−1),dt−δ, . . . ,dt−(δ+m−1)} (see 

figur 6.2(a)). 

• et: an ensembl of classifi {m1,m2, . . . ,mm ,F }, where Mi be train on 
dt−(δ+i−1) and Ft be train on all the feedback of the last δ day {ft, . . . ,ft−(δ−1)} 
(see figur 6.2(b)). the posterior probabl pet(+|x) be estim by averag 
the posterior probabl of the individu classifiers, pmi(+|x), i = 1, . . . ,M and 
pft(+|x). note that we use a singl classifi to learn from the set of feedback 
sinc their size be typic small. everyday, Ft be re-train consid the new 
feedbacks, while a new classifi be train on the new delay supervis coupl 

provid (dt−δ) and includ in the ensemble. At the same time, the most obsolet 

classifi be remov from the ensemble. 

these solut implement two basic approach for handl concept drift that can be 

further improv by adopt dynam slide window or adapt ensembl size [240]. 

6.3.2 separ delay supervis sampl from feedback 

As explain in section 6.3, our intuit be that feedback and delay transact 

have to be treat separately. therefore, at day t we train a specif classifi Ft on 
the feedback of the last δ day {ft, . . . ,ft−(δ−1)} and denot by pft(+|x) it posterior 
probability. We then train a second classifi on the delay sampl by mean either of 



chapter 6. concept-drift adapt with alert-feedback interact 122 

ftft�1ft�3ft�4ft�5ft�6 ft�2dt�7dt�8 

Wt 

ftwdt 

awt 
(a) slide window strategi 

ftft�1ft�3ft�4ft�5ft�6 ft�2dt�7dt�8 

ftm1m2 

edt aet 

Et 

m1m2 Ft 

(b) ensembl strategi 

figur 6.2: learn strategi for feedback and delay transact occur in 
the two day (M = 2) befor the feedback (δ = 7). 

a sliding-window or an ensembl mechan (see figur 6.2): let u denot by wdt the 
classifi train on a slide window of delay sampl {dt−δ, . . . ,dt−(δ+m−1)} and 
by pwdt (+|x) it posterior probabilities, while E 

D 
t denot the ensembl of M classi- 

fier {m1,m2, . . . ,mm} where each individu classifi Mi be train on dt−δ−i, i = 
1, . . . ,M . then, the posterior probabl pedt (+|x) be obtain by averag the poste- 
rior probabl of the individu classifiers. 

both “delayed” classifi wdt and edt have to be aggreg with Ft to exploit informa- 
tion provid by feedbacks. however, to rais alerts, we be not interest in aggreg 

method at the label level but rather at the posterior probabl level. for the sake of 

simplic we adopt the most straightforward approach base on a linear combin of 

the posterior probabl of the two classifi (ft and one among wdt and edt ). let u 
denot by aet the aggreg of Ft and edt where paet (+|x) be defin as: 

paet (+|x) = αtpft(+|x) + (1− αt)pedt (+|x) (6.3) 

A similar definit hold for awt , the aggreg of Ft and wdt : 

pawt (+|x) = αtpft(+|x) + (1− αt)pwdt (+|x) (6.4) 



chapter 6. concept-drift adapt with alert-feedback interact 123 

note that Ft andwdt jointli use the train set ofwt and, similarly, the two classifi 
Ft and edt jointli use the same train sampl of Et (see figur 6.2). 

feedback repres a small portion of the supervis sampl use for train classifi 

wt, henc they have littl influenc on pwt(+|x). similarly, Ft repres one of the 
classifi of the ensembl et, henc feedback influenc pet(+|x) onli for 1m+1 , while 
delay sampl for mm+1 . By aggreg accord to (6.3) and (6.4) we be abl to 

give a larg weight to feedback via the paramet αt, e.g. a larg αt give great 

influenc to Ft in the aggreg posteriori probabl pawt and paet . 

experi in section 6.5 show that handl feedback separ from delay su- 

pervis sampl provid much more precis alerts, and by aggreg with αt = 0.5 

we be abl to outperform standard fdss train on feedback and delay supervis 

sampl pool togeth (like Wt and et).3 

tabl 6.1 summar the classifi use in thi chapter. 

tabl 6.1: classifi use in the chapter. 

Ft A feedback classifi daili updat use feedback from t to t− δ. 
Wt A slide window classifi daili updat use δ +M days. 
wdt A delay slide window classifi daili updat use M days. 
awt An aggreg of wdt and Ft accord to (6.3). 
Et An ensembl of classifi daili updat use δ +M days. 
edt A delay ensembl of classifi daili updat use M days. 
Mi ith member of an ensembl of classifiers. 
aet An aggreg of edt and Ft accord to (6.4). 
αt weight assign to Ft in aggreg aet and awt . 

6.3.3 two specif fdss base on random forest 

the fdss present in the previou section have be implement use a random for- 

est [43] with 100 trees. In particular, forwdt ,wt and for allmi, i = 1, . . . ,M , we use a 
balanc random forest (brf) [50] where each tree be train on a balanc bootstrap 

sample, obtain by randomli undersampl the major class while preserv all the 

minor class sampl in the correspond train set. each tree of brf receiv a 

differ random sampl of the genuin transact and the same sampl from the fraud 

class in the train set, yield a balanc train set. thi undersampl strategi 

allow one to learn tree with balanc distribut and to exploit mani subset of the 

major class. At the same time, thi resampl method reduc train time. A 
3in the specif case of the ensembl approach and αt = 0.5, the aggreg of Ft and edt (aet ) 

correspond to assign a larg weight to Ft in et. 



chapter 6. concept-drift adapt with alert-feedback interact 124 

drawback of undersampl be that we be potenti remov relev train sam- 

ple form the dataset, howev thi problem be mitig by the fact that we learn 100 

differ trees. use undersampl allow u to rebal the batch without propa- 

gate minor class observ along the stream a in [171]. In contrast, for Ft that 
be train on feedback we adopt a standard RF where no resampl be performed. 

6.4 select bia and alert-feedback interact 

In thi section we discu the problem of train a classifi on feedback samples. A 

convent assumpt in ML be that the learn algorithm receiv train and test 

sampl drawn accord to the same distribution. however, thi assumpt do not 

hold in our case, sinc alert-feedback interact (afi) provid a recent bia subset of 

supervis transact (ft), which be not repres of all the transact occur 

in a day (bt). As a consequence, classifi Ft learn under a select bia govern by 
afi. 

let u defin a random select variabl s that associ to each sampl in Bt valu 1 if 

the transact be in Ft and 0 otherwise. when train a classifi Ft on Ft instead of Bt 
we get an estim of pft(+|x, s = 1) rather than pft(+|x). As show in section 3.2.1 
(see (3.1)), a standard solut to ssb consist into train a weight-sensit algorithm, 

where a train sampl (x, y) receiv a weight w: 

w = 
p( = 1) 
p( = 1|x, y) (6.5) 

alternatively, if the learn algorithm be not abl to accept weight train samples, 

it suffic to resampl the train set with replac and probabl equal to the 

weight [133]. 

In equat (6.5), p( = 1) can be easili estim by calcul the proport of 
feedback in a day. however, p( = 1|x, y) be not easi to estim sinc we know the 
label of onli few feedback samples. An assumpt often make in literatur [135–138] be 

that the select variabl s be independ of the class y give the input x (covari 

shift): p(s|y, x) = p(s|x). then equat (6.5) becomes: 

w = 
p( = 1) 
p( = 1|x) (6.6) 

We can get an estim of p( = 1|x) by build a classifi that predict s a the class 
label, which be a classifi that learn to discrimin feedback and non-feedback sampl 

between t and t− δ. 



chapter 6. concept-drift adapt with alert-feedback interact 125 

the problem with all these correct be that, sinc feedback be select accord 

to p(+|x), we have that p( = 1|x) and p(+|x) be highli correlated. moreover, we 
expect p( = 1|x) and p( = 1|x, y) to be larg for feedback samples, lead to 
small weight in (6.5) and (6.6). thi mean that import weight techniqu 

be expect to low the influenc of feedback in the learn process. As show in 

our previou work [20], strategi reduc the weight of feedback sampl be often 

return less precis alert (lower pk). for thi reason, re-weight be not expect 

to bring improv with afi. additionally, the covari shift assumpt be hard 

to defend, becaus the percentag of fraud in the feedback be much high than the one 

regist in typic day, i.e. the probabl of select a feedback cannot be say to be 

independ of the class of the transact (p(s|y, x) 6= p(s|x)). 

6.5 experi 

In thi work we use three larg dataset contain credit card transact make by 

european cardhold via on-lin websites. the first, refer to a 2013, have transac- 

tion from septemb 2013 to januari 2014, the second one, refer to a 2014, have 

transact from august to decemb 2014 and the third, refer to a 2015, from 

januari 2015 to end of may 2015. In tabl 6.2 we have report addit inform 

about the data. the dataset contain both origin and aggreg featur calcul a 

show in section 5.1.3. It be easi to notic that these dataset be highli unbalanced, i.e. 

fraud account for about 0.2% of all transactions. the number of fraud be also vari 

significantli over the year (see figur 6.3). 

tabl 6.2: dataset 

Id start day end day # day # transact # featur % fraud 
2013 2013-09-05 2014-01-18 136 21’830’330 51 0.19% 
2014 2014-08-05 2014-12-31 148 27’113’187 51 0.22% 
2015 2015-01-05 2015-05-31 146 27’651’197 51 0.26% 

In the first experi we process all dataset to ass the import of separ 

feedback from delay supervis samples. though we expect these stream to be 

affect by concept drift (cd), sinc they span a quit long time range, we do not have 

ani ground truth to investig the reaction to CD of the propos fds. To thi purpose, 

we design the second experi where we juxtapos batch of transact acquir in 

differ time of the year to artifici introduc CD in a specif day in the transact 

stream. 

In both experi we test fdss built on random forest a present in section 6.3.3. 

We consid both the slide window and ensembl approach and compar the 



chapter 6. concept-drift adapt with alert-feedback interact 126 

2013 2014 2015 

● 

● 
●●● 

● 
● 

● 

●● 
● 
● 

● 

●● 
● 

● 

● 

● 

●●● 

● 

● 

●● 

● 

● 

● 

●●● 

● 

● 

● 

● 

● 

● 
●● 
● 
●●● 

●● 
● 

● 

● 

● 

● 
● 

● 

● 

● 

● 
● 

● 
● 

● 
● 

● 

● 
● 

● 
● 

● 

● 
● 

● 
● 
● 

● 

● 

● 

● 

● 

● 
● 
● 

● 

●●● 
● 
● 

● 

●● 
● 

● 
● 

● 
● 
●● 

● 
● 

● 

● 

● 

● 

● 
●●● 

● 
● 
● 
● 
●● 
●● 
●●● 

● 
●● 
●● 
●●● 

● 
● 
● 

● 

● 

● 
● 
●●● 

● 

● 

● 

●● 
● 
● 

●● 

● 
● 

● 

● 

● 

● 

●● 

● 

● 

● 
● 

● 

● 

● 
● 

● 

● 

● 
●● 

●● 

●● 

● 
● 

● 

● 

● 
● 
● 

● 

●● 

● 

● 
●●●● 

●● 
● 

● 
● 

● 
● 

● 

●● 
● 
● 

●● 

● 

● 

● 
●●● 

●● 

● 
● 
● 

● 

● 
●● 
●● 
●● 
● 
●●●● 

● 

● 

● 

● 

● 

● 
● 

● 
● 
● 

● 

● 

● 

● 
● 

● 

● 
● 

● 

● 

● 

●● 
●● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

●●● 

●● 
● 

● 

● 
● 

● 

● 
● 

●●● 
● 
● 

●● 
●● 
●●● 

●● 

● 
● 

● 
● 
● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 
● 

● 
● 
●●● 

● 

●● 

●● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

●●● 
● 

● 

● 

● 
● 
●● 
● 
● 
● 

● 

● 
● 

● 

● 
● 

● 

● 
● 
● 

● 

● 

● 

● 
● 

● 

● 

● 

●● 

● 

●● 

● 

● 

● 
● 

● 

●● 
●●● 

● 

● 
● 

● 
● 
● 
● 

● 

● 

● 
●● 

● 

● 
●● 

●● 

● 

● 

● 

● 
● 

● 

● 

●● 
●●● 

● 
● 
● 

● 

● 

● 
● 

●● 
● 

● 

● 

● 

● 

● 

●● 

● 
● 
● 

● 

● 

● 
● 
● 

● 

●●● 
● 

● 

0 

500 

1000 

1500 

2000 

2500 

sep oct nov dec jan aug sep oct nov dec janjan feb mar apr may jun 

day 

N 
um 

be 
r 

of 
fr 

au 
d 



figur 6.3: number of daili fraud for dataset in tabl 6.2. 

accuraci of pool feedback and delay supervis sampl togeth (wt and et) 
against learn separ classifi (ft, wdt and edt ) that be then aggreg (awt 
and aet ). let u recal that each test classifi rais alert differently. thi mean 
that also the feedback return to the classifi might be different. thi have to be 

consid when compar sever classifiers, for instance, when compar Wt and 
wdt , the supervis inform provid be not the same because, in the first case alert 
be rais by Wt while in the second by wdt . 

At first we assum that after δ = 7 day all the transact label be provid (delay 

supervis information) and that we have a budget of k = 100 alert that can be check 

by the investigators: thus, Ft be train on a window of 700 feedbacks. then in the 
experi of section 6.5.3 we use δ = 15 and we allow Ft to be train on a larg 
number of feedback per day (|ft| ≥ 100) to see how these paramet influenc the 
perform of the detection. In the same section we test some ssb correct techniqu 

to see whether they can actual improv the perform of ft. 

experi from section 6.5.4 compar the propos classifiers’ aggregationawt against 
a classifi Rt train on all recent transact that make the unrealist assumpt 
that all daili transact can be check by investigators. thi experi aim to com- 

pare a classifi Rt ignor afi with the aggreg propos use differ accuraci 
measures, pk, auc and ap. 

In section 6.5.5 we run experi to studi whether adapt the weight αt give to 

Ft in (6.3) and (6.4) have an impact on the perform of awt and aet . It emerg that 
combin classifi with a standard mean (αt = 0.5 for all the data stream) be often 

competit to more complic weight strategies. 



chapter 6. concept-drift adapt with alert-feedback interact 127 

for all experiments, we set M = 16 so that wdt be train on a window of 16 day 
and edt (resp. et) be an ensembl of 16 (resp. 17) classifiers.4 each experi be 
repeat 10 time to reduc the results’ variabl due to bootstrap of the train 

set in the random forests. the fd perform be assess by mean of the averag Pk 
over all the batch (the high the better) and use a pair t-test to ass whether the 

perform gap between each pair of test classifi be signific or not. We comput 

the pair t-test on the rank result from the friedman test [232] a recommend by 

demsar [241] (see section 5.1.3). 

6.5.1 separ feedback from delay supervis sampl 

In order to evalu the benefit of learn on feedback and delay sampl separately, 

we first compar the perform of classifi Wt against ft, wdt and the aggreg 
awt . the aggreg awt and aet be comput use αt = 0.5 over all the data 
stream. In addit to the classifi present in section 6.3, we consid also a static 

classifi call St that be train onc on the first M day and never updated. In absenc 
of concept drift we expect St to perform similarli to wdt (wdt be just St updat everi 
day). tabl 6.3(a) show the averag Pk over all the batch for the three dataset 

separately. 

tabl 6.3: averag Pk for the slide and ensembl strategi (δ = 7, M = 16 and 
αt = 0.5). 

(a) slide approach 

dataset classifi mean sd 
2013 F 0.62 0.25 
2013 WD 0.54 0.22 
2013 W 0.57 0.23 
2013 S 0.48 0.25 
2013 AW 0.70 0.21 
2014 F 0.59 0.29 
2014 WD 0.58 0.26 
2014 W 0.60 0.26 
2014 S 0.54 0.24 
2014 AW 0.69 0.24 
2015 F 0.67 0.25 
2015 WD 0.66 0.21 
2015 W 0.68 0.21 
2015 S 0.58 0.23 
2015 AW 0.75 0.20 

(b) ensembl approach 

dataset classifi mean sd 
2013 F 0.62 0.25 
2013 ED 0.50 0.24 
2013 E 0.58 0.24 
2013 S 0.47 0.24 
2013 AE 0.69 0.21 
2014 F 0.60 0.30 
2014 ED 0.49 0.28 
2014 E 0.56 0.27 
2014 S 0.53 0.25 
2014 AE 0.68 0.26 
2015 F 0.66 0.25 
2015 ED 0.61 0.19 
2015 E 0.67 0.20 
2015 S 0.58 0.23 
2015 AE 0.74 0.20 

In all datasets, awt outperform the other fdss in term of pk. the barplot of figur 
6.5 show the sum of rank for each classifi and the result of the pair t-tests. figur 

6.5 indic that in all dataset (figur 6.5(a), 6.5(b) and 6.5(c)) awt be significantli 
4we ran sever experi with M = 1, 8, 16, 24 and found M = 16 a a good trade-off between 

performance, comput load, and the number of day that can be use for test in each stream. 



chapter 6. concept-drift adapt with alert-feedback interact 128 

good than all the other classifiers. Ft achiev high averag Pk and high sum of 
rank than wdt and wt: thi confirm that feedback be veri import to increas pk. 

figur 6.4(a) display the valu of Pk for awt and Wt in each day, averag in a neigh- 
borhood of 15 days. after decemb there be a substanti perform drop, which can 

be see a a CD due to a chang in cardhold behaviour in the period befor and after 

christmas. however, awt domin Wt along the whole 2013 dataset, which confirm 
that a classifi awt that learn on feedback and delay transact separ outper- 
form a classifierwt train on all the supervis inform pool togeth (feedback 
and delay transactions). 

tabl 6.3(b) and figur 6.5(d), 6.5(e) and 6.5(f) confirm thi claim also when the 

fd implement an ensembl of classifiers.5 In particular, figur 6.4(b) display the 

smooth averag Pk of classifi aet and et. for the whole dataset aet have good Pk 
than et. 

W 
AW 

(a) slide window strategi 

AE 
E 

(b) ensembl strategi 

figur 6.4: averag Pk per day (the high the better) for classifi on dataset 2013 
smooth use move averag of 15 days. In the slide window approach classifi 
awt have high Pk than wt, and in the ensembl approach aet be superior than et. 

6.5.2 artifici dataset with concept drift 

the rational of thi experi be to test the reaction of the propos fd to abrupt 

cd. To thi purpose, in thi section we artifici introduc an abrupt CD in specif 

day by juxtapos transact acquir in differ time of the year. tabl 6.4 report 

the three dataset that have be gener by concaten batch of the dataset 2013 

with batch from 2014. the number of day after CD be set such that the fd have the 

time to forget the inform from the previou concept. 

tabl 6.5(a) show the valu of Pk averag over all the batch in the month befor the 

chang for the slide window approach, while tabl 6.5(b) show Pk in the month after 

the cd. awt report the high Pk befor and after cd. similar result be obtain with 
5pleas note that classifi Ft return differ result between 6.3(a) and 6.3(b) becaus of the 

stochast natur of rf. 



chapter 6. concept-drift adapt with alert-feedback interact 129 

swdwfaw 

(a) slide window strate- 
gy on dataset 2013 

swdfwaw 

(b) slide window strate- 
gy on dataset 2014 

swdfwaw 

(c) slide window strate- 
gy on dataset 2015 

edsefa 

(d) ensembl strategi on 
dataset 2013 

edsefa 

(e) ensembl strategi on 
dataset 2014 

SE edfa 

(f) ensembl strategi on 
dataset 2015 

figur 6.5: comparison of classif strategi use sum of rank in all batch 
and pair t-test base upon on the rank of each batch (classifi have the same 
label on their bar be not significantli differ with a confid level of 0.95). In all 
dataset (2013, 2014 and 2015), classifi aggreg awt and aet be significantli 

good that the others. 

tabl 6.4: dataset with artifici introduc CD 

Id start 2013 end 2013 start 2014 end 2014 
cd1 2013-09-05 2013-09-30 2014-08-05 2014-08-31 
cd2 2013-10-01 2013-10-31 2014-09-01 2014-09-30 
cd3 2013-11-01 2013-11-30 2014-08-05 2014-08-31 

tabl 6.5: averag Pk in the month befor and after CD for the slide window 

(a) befor CD 
cd1 cd2 cd3 

classifi mean sd mean sd mean sd 
F 0.411 0.142 0.754 0.270 0.690 0.252 
WD 0.291 0.129 0.757 0.265 0.622 0.228 
W 0.332 0.215 0.758 0.261 0.640 0.227 
AW 0.598 0.192 0.788 0.261 0.768 0.221 

(b) after CD 
cd1 cd2 cd3 

classifi mean sd mean sd mean sd 
F 0.635 0.279 0.511 0.224 0.599 0.271 
WD 0.536 0.335 0.374 0.218 0.515 0.331 
W 0.570 0.309 0.391 0.213 0.546 0.319 
AW 0.714 0.250 0.594 0.210 0.675 0.244 

the ensembl approach (tabl 6.6(a), 6.6(b)). In all these experiments, aet be also faster 
than standard classifi Et and Wt to react in the presenc of a CD (see figur 6.6). 
the larg variat of Pk over the time reflect the non-stationar of the data stream. 

expect for dataset cd1, we have on averag low Pk after concept drift. 



chapter 6. concept-drift adapt with alert-feedback interact 130 

tabl 6.6: averag Pk in the month befor and after CD for the ensembl 

(a) befor CD 
cd1 cd2 cd3 

classifi mean sd mean sd mean sd 
F 0.585 0.183 0.731 0.267 0.706 0.245 
ED 0.555 0.318 0.563 0.217 0.562 0.223 
E 0.618 0.313 0.696 0.276 0.648 0.245 
AE 0.666 0.222 0.772 0.272 0.751 0.221 

(b) after CD 
cd1 cd2 cd3 

classifi mean sd mean sd mean sd 
F 0.696 0.270 0.477 0.235 0.610 0.270 
ED 0.551 0.298 0.286 0.182 0.486 0.265 
E 0.654 0.266 0.373 0.235 0.581 0.268 
AE 0.740 0.232 0.575 0.227 0.659 0.245 

AW 
W 

(a) slide window strategi on dataset cd1 

AW 
W 

(b) slide window strategi on dataset cd2 

W 
AW 

(c) slide window strategi on dataset cd3 

AE 
E 

(d) ensembl strategi on dataset cd3 

figur 6.6: averag Pk per day (the high the better) for classifi on dataset with 
artifici concept drift (cd1, cd2 and cd3) smooth use move averag of 15 
days. In all dataset awt have high Pk than wt. for the ensembl approach we show 
onli dataset cd3, where aet domin Et for the whole dataset (similar result be 
obtain on cd1 and cd2, but they be not includ for compactness). the vertic 

bar denot the date of the concept drift. 

6.5.3 improv the perform of the feedback classifi 

the goal of these experi be to see how the perform of Ft be influenc by: 
i) the number of day of feedback avail (defin by δ), ii) method correct the 

select bias, and iii) the number of feedback avail everyday. To thi purpos we 

first test strategi with Ft train on 15 day (δ = 15). In tabl 6.7 we see that, with 
δ = 15, Ft have high Pk than when it be train with δ = 7 (see tabl 6.3). the 
aggreg awt and aet also improv their perform with δ = 15. 

the rational of the second experi be to see where or not the method for ssb 

would improv the perform of the feedback classifi ft. In tabl 6.8 we test two 
type of method for correct the select bias: import weight with weight 



chapter 6. concept-drift adapt with alert-feedback interact 131 

tabl 6.7: averag Pk for the slide and ensembl approach when δ = 15. 

(a) slide approach 

dataset classifi mean sd 
2013 F 0.67 0.24 
2013 WD 0.54 0.22 
2013 AW 0.72 0.20 
2014 F 0.67 0.27 
2014 WD 0.56 0.27 
2014 AW 0.71 0.25 
2015 F 0.71 0.21 
2015 WD 0.62 0.21 
2015 AW 0.76 0.19 

(b) ensembl approach 

dataset classifi mean sd 
2013 F 0.67 0.23 
2013 ED 0.48 0.23 
2013 AE 0.72 0.21 
2014 F 0.67 0.28 
2014 ED 0.49 0.27 
2014 AE 0.70 0.25 
2015 F 0.71 0.22 
2015 ED 0.56 0.18 
2015 AE 0.75 0.20 

provid by (6.5) and joint probabl averag [242]. In the first case we use a 

weight-sensit algorithm an implement of the random forest base on condit 

infer tree [243] avail in the parti packag [244]. In the second case we use 

the semi-supervis version (sja) of the algorithm propos by fan et al. [242] for 

ssb correction. these result be obtain with the slide approach when δ = 15, 

but equival one can be obtain with the ensembl sinc Ft be the same for both 
approaches. If we compar the result of tabl 6.8 with the one of Ft in tabl 6.7 we see 
that techniqu for ssb do not improv the perform of ft, and weight techniqu 
can actual deterior it performance. 

tabl 6.8: averag Pk of Ft with method for ssb correct when δ = 15. 

dataset ssb correct mean sd 
2013 sja 0.66 0.24 
2013 weigth 0.64 0.25 
2014 sja 0.66 0.27 
2014 weigth 0.65 0.28 
2015 sja 0.71 0.22 
2015 weigth 0.68 0.23 

In the remaind of the section we investig how request a larg number of feedback 

(i.e. gener a larg number of alerts) influenc the perform of Ft and it 
aggregation. If have more feedbacks, lead to good performances, then the compani 

should hire more investigators. In tabl 6.9 we allow Ft to be train on a larg 
number of feedback (|ft| ≥ 100) and evalu the perform with Pk use k = 100 
for all experiments. It emerg that, the compani would obtain a good detect by 

increas the number of investigators. however, the increas in accuraci should be 

evalu against the cost of hire more investigators, perhap good accuraci be not 

suffici to justifi the high cost of investigation. 



chapter 6. concept-drift adapt with alert-feedback interact 132 

tabl 6.9: averag Pk for the slide approach with more than 100 feedback per day 
when δ = 15 and k = 100. 

(a) dataset 2013 
|ft| classifi mean sd 
100 F 0.68 0.23 
100 AW 0.72 0.20 
300 F 0.74 0.22 
300 AW 0.78 0.19 
500 F 0.76 0.20 
500 AW 0.79 0.18 

(b) dataset 2014 
|ft| classifi mean sd 
100 F 0.68 0.27 
100 AW 0.71 0.24 
300 F 0.73 0.25 
300 AW 0.76 0.22 
500 F 0.75 0.23 
500 AW 0.78 0.21 

(c) dataset 2015 
|ft| classifi mean sd 
100 F 0.71 0.21 
100 AW 0.76 0.19 
300 F 0.80 0.18 
300 AW 0.82 0.17 
500 F 0.82 0.17 
500 AW 0.83 0.17 

6.5.4 standard accuraci measur and classifi ignor afi 

In thi section we compar the perform of the feedback classifi Ft and it aggre- 
gation awt against a classifi Rt that be train on all recent transact occur 
between t and t − δ (feedback and non-alert transactions, see figur 6.7). In thi 
experi we want to see how a classifi Rt ignor alert-feedback interact com- 
pare to Ft (train onli on feedbacks).6 It be import to remark than Rt and Ft be 
train on the same number of day (defin by δ), while wdt be train on a window 
of delay samples. We ass the result use Pk and two other detect measur 

present in section 2.2.3, name auc and ap. note that these last figur of merit 

can be consid a global rank measures, becaus they ass the rank qualiti 

over all the instances, not onli in the top k a Pk does. As explain in section 6.1, 

most work in fraud detect use auc a perform measur and train a classifi 

use all avail inform like Rt without consid investigators’ feedback. 

ftft�1ft�3ft�4ft�5ft�6 ft�2dt�7dt�8 

ftwdt 

awt 

Rt 

figur 6.7: A classifi Rt train on all recent transact occur between t and 
t − δ make the unrealist assumpt that all these transact have be check 

and label by investigators. In thi figur we use δ = 7 and M = 2. 

tabl 6.10 report the result for the three datasets. We notic that, when use global 

rank measur such a auc and ap, Rt alway outperform Ft and the latter be 
6note that in a real scenario we cannot comput rt, sinc label be avail onli for feedback 

sampl between t and t− δ. 



chapter 6. concept-drift adapt with alert-feedback interact 133 

often the bad between all classifi considered. On the contrary, when the accuraci 

be evalu in term of pk, then Ft be a good altern to rt. these result can 
be interpret in the follow way: when the object be to get accur rank of 

the most suspici transact (maxim pk) we should use a classifi train on 

transact that be a riski a the one we want to predict, henc Ft should be favor 
becaus it contain onli riski sampl (feedbacks). On the contrary, a classifi train 

on all daili transact (which be mostli genuine), like rt, will be a good choic if 
we want to obtain a good rank on all sampl (e.g. maxim auc). 

from tabl 6.10 and figur 6.8 we see also that Rt have in gener good accuraci than 
wdt , which confirm the presenc of a non-stationari environ and train on more 
recent transact allow one to react faster to cd. the aggreg of Ft and wdt in 
awt return high Pk than rt, but it be beaten by Rt in term of auc. In a nutshell, to 
have good predict on the k transact with the larg fraud risk it be good to train 

a specif classifi on the feedback (previou riski transactions). when the object be 

instead to obtain good overal accuraci (not onli on the top k) we should perhap use a 

standard classifi that use all inform available. 

tabl 6.10: averag ap, auc and Pk for the slide approach (δ = 15, M = 16 and 
αt = 0.5). 

(a) dataset 2013 
metric classifi mean sd 
AP F 0.31 0.13 
AP WD 0.28 0.15 
AP R 0.33 0.15 
AP AW 0.40 0.14 
auc F 0.83 0.06 
auc WD 0.94 0.03 
auc R 0.96 0.01 
auc AW 0.94 0.03 
Pk F 0.67 0.24 
Pk WD 0.54 0.22 
Pk R 0.60 0.22 
Pk AW 0.72 0.20 

(b) dataset 2014 
metric classifi mean sd 
AP F 0.30 0.15 
AP WD 0.29 0.17 
AP R 0.35 0.19 
AP AW 0.39 0.16 
auc F 0.81 0.08 
auc WD 0.94 0.03 
auc R 0.96 0.02 
auc AW 0.93 0.03 
Pk F 0.67 0.27 
Pk WD 0.56 0.27 
Pk R 0.63 0.25 
Pk AW 0.71 0.25 

(c) dataset 2015 
metric classifi mean sd 
AP F 0.27 0.11 
AP WD 0.30 0.13 
AP R 0.39 0.16 
AP AW 0.37 0.12 
auc F 0.81 0.07 
auc WD 0.95 0.02 
auc R 0.97 0.01 
auc AW 0.94 0.02 
Pk F 0.71 0.21 
Pk WD 0.62 0.21 
Pk R 0.68 0.20 
Pk AW 0.76 0.19 

6.5.5 adapt aggreg 

the ration of follow experi be to investig how to adapt the aggreg awt 
and aet in the presenc of non-stationari environments. let u recal that the posterior 
probabl of awt be defin a follow: pawt (+|x) = αtpft + (1 − αt)pwdt , where 
we have introduc the compact notat pft , pwdt to denot pft(+|x), pwdt (+|x). 
similar definit hold for aet (aggreg of Ft and edt , see (6.4)). perhap the most 
straightforward adapt strategi be to set the weight at day t + 1 (αt+1) depend 

on the perform of Ft and wdt (or edt ). oper with differ valu of αt 



chapter 6. concept-drift adapt with alert-feedback interact 134 

(a) rank measur in term of AP (b) rank measur in term of auc 

(c) rank measur in term of Pk 

figur 6.8: detect accuraci of awt , ft, wdt and Rt measur use differ 
perform measur on the 2013 dataset. auc and AP be measur of global rank 
while Pk be a measur of rank in the top k transact with the larg probabl 

of be fraudulent. 

correspond to cut the plane (pft ,pwdt ) use straight line have differ angular 
coeffici (see figur 6.10). 

In our aggreg we would like to give a larg weight to the probabl that be more 

accurate, so if pft be more accur than pwdt (or pedt ), at day t+1 we want αt+1 > 0.5. 
In order to defin the weight αt+1 we have first to decid how to measur the accuraci 

of Ft when the classifi gener the alert (and request feedbacks) be awt .7 

let fawt be the feedback request by A 
W 
t and fft be the feedback request by 

Ft (see figur 6.9). let y+t (resp. y−t ) be the subset of fraudul (resp. genuine) 
transact in day t, we defin the follow sets: corrft = fawt ∩fft∩i 

+ 
t , errft = 

fawt ∩ fft ∩ Y 
− 
t , and missft = fawt ∩ {bt \ fft} ∩ Y 

+ 
t . In the exampl of figur 6.9 

we have |corrft | = 4, |errft | = 2 and |missft | = 3. We can now comput some 
accuraci measur of Ft in the feedback request by awt :8 

• accft = 1− 
|errft | 

k 

• accmissft = 1− 
|errft |+|missft | 

k 

• precisionft = 
|corrft | 

k 

7we cannot comput Pk of Ft and wdt becaus feedback be request by awt . 
8these accuraci measur be inspir by standard classif metric present in section 2.1.4 



chapter 6. concept-drift adapt with alert-feedback interact 135 

• recallft = 
|corrft | 
|fawt 

∩y+t | 

• aucft = probabl that fraudul feedback rank high than genuin feedback 
in fawt accord to pft . 

• probdifft = differ between the mean of pft calcul on the fraud and the 
mean on the genuin in fawt . 

fawt 
fft 

fwdt 

Bt 

figur 6.9: feedback request by awt (fawt ) be a subset of all the transact of 
day t (bt). fft ( fwdt ) denot the feedback request by Ft (W 

D 
t ). the symbol + 

be use for fraud and − for genuin transactions. 

similarly, we can comput the accuraci of classifi wdt (or edt ) in the feedback re- 
quest by awt . for example, in figur 6.9 we have |corrwdt | = 3, |errwdt | = 5 and 
|misswdt | = 4. By choos one of the previou accuraci measur we obtain differ 
way to combin the probabl and adapt to CD at the aggreg level. let’ imag- 

ine we choos aucft a metric for Ft and similarli aucwdt for W 
D 
t , then we comput 

αt+1 a follows: 

αt+1 = 
aucft 

aucft + aucwdt 
(6.7) 

use (6.7) ensur that αt+1 ∈ [0, 1]. In tabl 6.11 we present the averag Pk of classifi 
awt when δ = 15 with adapt αt, i.e. αt chang everyday accord to one of the 
accuraci measur present before. 

We have also consid the ideal case in which we could use everyday the valu of αt 
return the best results, by test differ valu αt ∈ {0.1, . . . , 0.9} and select α∗t 
a the one allow the aggreg to have the high pk. note that in a real scenario it 

be not possibl to comput α∗t sinc we cannot ask feedback for more than one classifi 

and all the feedback be avail onli at the end of the day. tabl 6.11 report result 

obtain with α∗t under the name best for α adaptation. In general, the perform 

increas with α∗t be margin w.r.t. all the other strategi considered. also, it appear 

that adapt the weight be not significantli good than keep everyday αt = 0.5. 



chapter 6. concept-drift adapt with alert-feedback interact 136 

tabl 6.11: averag Pk of awt with adapt αt (δ = 15). 

(a) dataset 2013 
α adapt mean sd 
best(α∗t ) 0.73 0.21 
probdif 0.70 0.22 
acc 0.72 0.21 
accmiss 0.72 0.21 
precis 0.72 0.21 
recal 0.71 0.21 
auc 0.72 0.21 
none(αt = 0.5) 0.72 0.20 

(b) dataset 2014 
α adapt mean sd 
best(α∗t ) 0.72 0.24 
probdif 0.68 0.26 
acc 0.71 0.24 
accmiss 0.70 0.24 
precis 0.71 0.24 
recal 0.70 0.25 
auc 0.71 0.24 
none(αt = 0.5) 0.71 0.24 

(c) dataset 2015 
α adapt mean sd 
best(α∗t ) 0.76 0.19 
probdif 0.73 0.21 
acc 0.76 0.19 
accmiss 0.75 0.19 
precis 0.75 0.19 
recal 0.74 0.20 
auc 0.75 0.19 
none(αt = 0.5) 0.76 0.19 

6.5.6 final strategi select and classif model analysi 

the aim of thi section be to select the final strategi for the fds, make an analysi 

of the time complex of the propos solut and understand which featur of the 

dataset be the most informative. In the previou experi we saw that aggreg a 

feedback classifi (ft) with a delay classifi (wdt or edt ) use (6.3) or (6.4) be often 
the best solution. overal we found the best perform use the configur of 

tabl 6.7: δ = 15,m = 16 and αt = 0.5. If we have to choos between the slide window 

or ensembl approach we would recommend the second. As show in figur 6.11(b), the 

ensembl edt have low train time than the slide window, becaus the first train 
everyday a modelmt use onli transact from dt−d. On the contrary, in the slide 
window a modelwdt be built use transact from {dt−δ, . . . ,dt−(δ+m−1)}, hencewdt 
be a train on a much larg train set. 

despit the larg differ in the train set size between the ensembl and slide 

window for the delay classifi (see figur 6.11(a)), the differ in the train time 

be small (see figur 6.11(b)), becaus in wdt and edt each tree of the random forest 
us a balanc bootstrap sampl of the origin train set (see section 6.3.3). the 

train time of Ft be neglig sinc it be train on few feedback samples. As a 
consequence, the train time of aggreg awt and aet be essenti equival to 
the one of the delay classifi wdt and edt . 

the RF algorithm can be easili parallel by distribut the train of each decis 

tree on multipl cores/machines. In thi way it be possibl to drastic reduc the 

comput time request for train the fds. In the ideal case of no overhead due to 

parallelization, the theoret speedup be equival to the number of cores/machin 

use for train the rf. 

loupp [245] deriv three bound for the time complex of RF train procedure: i) 

best o(qmnb log2nb), ii) bad o(qmn2b lognb) and iii) averag o(qmnb log 
2nb), where 

Nb be the number of boostrap sampl in each tree, m the number of tree in the forest 



chapter 6. concept-drift adapt with alert-feedback interact 137 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

●● ● 
● 

●● 

● 

● 

● 

● 
● ● 

●●● 

● 

●●●●● 
● 

● 

●●●●●●●●●●●● 

● 

●●● 

● 

● 

● 

● 

●● 
●● 
● 
●●● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 

● 
● 

● 

● 

● 

● 

●● 
● 
● 

●● 
● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

●● 

● ● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

●●● 

● 

● 

● 

● 

● 

●● 
● 

● 

● 
●● 

●●●● 

● 

● 

● 

● 

●●●●●● 
● 
●●●●● 

● 

●● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 

●●● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

●●● 

● 

●●●●●●●●●● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

●●●●●● 

● 

● 

●●●●●● 

● 

● 

●●●●●●●● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● ● 

● 

● 

● ● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

●● 
● 

●● 

● 

● 

● 

● 

● 
● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● ● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● ● 

●● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 

● 

● 

● 

● 

● ● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● ●● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● ● 

● 

● 

● ● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 

●● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 
● 

● 

● 

● 
● 

● 

● 

● 

●● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 
● 

● 
● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● ●● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● ● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 
● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● ● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● ●●● 

●● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● ● 

● 
● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● ● 

● 
● 

● 

● 

● 

●● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 
●● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● ● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
●● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● ● 

● 

● 

●● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

●● 
● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 
● 

● 

● ● ● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
●● ● 

● 

● 

● 

● 

● 

● 

● ● 

0.00 

0.25 

0.50 

0.75 

1.00 

0.00 0.25 0.50 0.75 1.00 
pf(+|x) 

P 
W 

D 
(+ 

|x 
) class 

● 

● 

+ 
− 

alert 
● fals 

true 

pk: 0.91 alpha: 0.599 

(a) 6th of octob 2013 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

●● 
●● 

●● 
● 

● 

● 

● 

● 

● 
● 

●●● 
● 

● 

●●●● 

● 

●●●●●●● 

● 

●● 

● 

● 

●●●●●●●●●●●●●●●●● 

● 

●● 

● 

●●●●●●●● 

● 

●●●●●● 

● 

●● 
● 

● 

● 

● 

●● 

● 

●● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

●● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 
● 

●● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● ● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
●●● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

●●● 
● 

● 

● 

●● 

● 

●● 

● 

● 

● 

● 
●●● ● ● ● 

●●● 

●●●● 

● 

●●●●● 

● 

●● 
● 

●● ●●● 

● 

● 

● 

●● 

●●●●●●●●●●●●●●●●●●●●●●● 

● 

● 

● 

● 

● 

● 

●●● 

● 

● 

●●● 

● 

●●●●●●●●●●●●● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● ● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● ● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

●● 

● 

● 

● 

● 
● 

● 
● 

● ● 
● 

● 

● 
● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 

● 

● 

● 

● 
● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

●● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 

● 

● 

●● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 
● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● ●● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● ● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● ● 

● 

● 

● 

● ●● 
● 

● 

● 

● 

● ● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● ● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● ● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● ● 
● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

●● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 

● 

● 
● 

● 

● 

● ● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

●● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

0.00 

0.25 

0.50 

0.75 

1.00 

0.00 0.25 0.50 0.75 1.00 
pf(+|x) 

P 
W 

D 
(+ 

|x 
) class 

● 

● 

+ 
− 

alert 
● fals 

true 

pk: 0.99 alpha: 0.789 

(b) 7th of octob 2013 

● 

● 

● 

● ● 

● 

● 

● 

● 

● 

● 

●● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● ● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● ● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 
● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

●● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● ● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● ● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● ● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● ● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 
● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● ● 

● 
● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● ● 

● 

●● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● ● 

● 

● 
● 

● 

● 

● 

● 
●● 

● 

● 

● ● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 
● 

● ● 
● 

● 
● 

● 

● 
● 

● 

● ● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

●● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● ● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● ● 

● 

● 

● 

● 

● ● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● ● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● ● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 

● 
● 

●● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● ● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● ● 

● 

● 
● 

● 

● 

● 

● 
● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● ● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

●● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● ● 
● 

● 

● 

● 

● 

● 

●● 

● 

●● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● ● 

● 

● 

● 

● ● 

● 

● 

● 

● 

● 

● ● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● ● 

● 
● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 
● 

● 

● 
● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 
● ● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

●● 

● 

● 
● 

● ● 

● 

● 

● 

● 
● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● ● 

● 

●●● 

● 

● 

●● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● ● ●● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● ● 

● 

● 

● 

● 

●● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 

● 

● 

●● 

● 

● ● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

0.00 

0.25 

0.50 

0.75 

1.00 

0.00 0.25 0.50 0.75 1.00 
pf(+|x) 

P 
W 

D 
(+ 

|x 
) class 

● 

● 

+ 
− 

alert 
● fals 

true 

pk: 0.6 alpha: 0.192 

(c) 8th of octob 2013 

● 
● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● ● 

● ● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 

● 

●●● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 
● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● ● 

● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 
● 

● 

● 
● 
● 

● ● 

● 

● 

● 

● ● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

●● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

●● 
● 

● 

● 

● ● 
● 

● 

● 

● ● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
●● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 

● 

● 

● 

● 

● 

● 

● 

●● 

● ● 

● 
● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 
● 

● 
● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 
● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

●● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 
● ● 

● 

● 
● 

● 

● 

● 

● 

● 

●● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 
● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

●● 

● 

●● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

●● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

●● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 

● 

● 

● 

● ● 

● 

● 

●● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● ● 
● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 
●● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

●● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 
● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● ● 

● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● ●● 

● 

● 

● 

● 

● 

● 

●● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● ● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

●● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● ● 

● 

● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 

●● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● ● 
● 

● ● 

● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● ● 

● 

● 

● 

● 

●● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 
● 

● 

● 
● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 
● 

● 

● ● 

● 

0.00 

0.25 

0.50 

0.75 

1.00 

0.00 0.25 0.50 0.75 1.00 
pf(+|x) 

P 
W 

D 
(+ 

|x 
) class 

● 

● 

+ 
− 

alert 
● fals 

true 

pk: 0.86 alpha: 0.554 

(d) 9th of octob 2013 

figur 6.10: posterior probabl pft(+|x) and pwdt (+|x) for differ days. feed- 
back transact be denot with triangl and red color be use for frauds. In thi 
example, feeback be request by awt with αt comput a in (6.7). oper with 
differ valu of αt correspond to cut the plane (pft ,pwdt ) use straight line 

have a angular coeffici −αt(1−αt) . 

and q the number of featur use to split each tree of the RF (q ≤ n). the best case 
correspond to the case when sampl be alway partit at the tree node into two 

balanc subset of N2 samples. the bad correspond to the case of split that creat 

a subset with onli one sampl and the other subset with the remain N − 1 instances. 
the averag correspond to the averag time complexity. In all our experi onli the 

term Nb be chang between the differ classifiers, while m = 100 and q = 7.9 In the 
9in the randomforest packag [222], the default valu of q be obtain a q = 

√ 
n. 



chapter 6. concept-drift adapt with alert-feedback interact 138 

●●● 

●●●●●●●●●●●●● ●●●●●●●●●●●●●●●0e+00 

1e+06 

2e+06 

3e+06 

delay feedback 

classifi 

T 
ra 

in 
in 

g 
se 

t s 
iz 

e 

adapt 
slide 
ensembl 

(a) train set size 

●● 
● 
● 

● ●●0 

100 

200 

300 

400 

delay feedback 

classifi 

T 
ra 

in 
in 

g 
tim 

e 

adapt 
slide 
ensembl 

(b) train time 

figur 6.11: train set size and time (in seconds) to train a RF for the feedback 
(ft) and delay classifi (wdt and edt ) in the 2013 dataset. all the simul be 
run use a singl core in order to minim the comput resourc request to the 

univers cluster a in section 5.1.3. 

case of brf, Nb = 2n+ where N+ be the number of fraud avail for train (see 

section 6.3.3). 

finally, in figur 6.12 we plot a measur of featur relev extract from the brf 

model of wdt . the most inform featur be risk_term_miduid which mea- 
sure the risk associ to a termin identifi (miduid). within the top 10 most 

inform featur we see variabl measur the amount of the transact (e.g. 

sum_amt_his) and featur measur the risk associ to the countri and con- 

tinent of the termin (e.g. risk_term_country). all variabl with the name 

start with risk be featur that be origin provid a categor variabl 

and that have be convert into numer one by mean of the transform present 

in section 5.1.3. 

6.6 discuss 

let u now discu the accuraci improv achiev by classifi awt and aet pro- 
pose in section 6.3.2. first of all, we notic that the classifi learn on recent feedback 

be more accur that those train on delay samples. thi be make explicit by ta- 

ble 6.3 show that Ft often outperform wdt (and edt ), and Wt (and et). We deem 
that Ft outperform wdt (resp. edt ) sinc wdt (resp. edt ) be train on less recent 
supervis couples. As far a the improv with respect towt (and et) be concerned, 
our interpret be that thi be due to the fact thatwt (and et) be train on the entir 
supervis dataset, then weaken the specif contribut of feedbacks. 

our result instead show that aggreg prevent the larg amount of delay super- 

vise sampl to domin the small set of immedi feedbacks. thi boil down to 

assign larg weight to the most recent than to the old samples, which be a golden rule 



chapter 6. concept-drift adapt with alert-feedback interact 139 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

tx_accept 
had_refus 

nb_refused_hi 
tx_intl 

had_trx_same_shop 
tx_3d_secur 

is_night 
had_lot_nb_tx 

risk_gend 
nb_trx_same_shop_hi 

risk_card_brand 
risk_d_ag 

risk_languag 
had_test 

risk_d_amt 
risk_term_mcc_group 

tx_hour 
risk_brok 

risk_term_mccg 
risk_last_country_hi 

age 
risk_d_sum_amt 

risk_term_region 
risk_term_mcc 

nb_trx_hi 
risk_term_countri 

amount 
risk_term_contin 

min_amt_hi 
sum_amt_hi 

risk_last_miduid_hi 
risk_term_miduid 

0 20 40 60 

featur import 

RF model day 20130906 

figur 6.12: averag featur import measur by the mean decreas in accuraci 
calcul with the gini index in the RF model of wdt in the 2013 dataset. the 
randomforest packag [222] avail in R use the gini index a split criterion. 
As state in the packag documentation: “the mean decreas in accuraci measur be 
comput from permut the out Of bag (oob) data: for each tree, the error rate on 
the oob portion of the data be recorded. then the same be do after permut each 
predictor variable. the differ between the two be then averag over all trees, and 

normal by the standard deviat of the differences”. 

when learn in non-stationari environments. the aggreg awt with αt = 0.5 be 
inde an effect way to attribut high import to the inform includ in 

the feedbacks. At the same time aet with αt = 0.5 be a way to balanc the contribut 
of Ft and the remain M model of et. 

anoth motiv of the accuraci improv with the aggreg be that classifi 

train on feedback and delay sampl address two differ classif task (see 

section 6.3). In particular Ft learn to discrimin those sampl that have high risk 
of be frauds, i.e. those transact yield a larg valu of the posterior probabl 

of the classifi use to gener alerts. On the contrary, classifi train on delay 

sampl reli on heterogen sampl that be not select depend on the posterior 

of the classifier, and includ both fraud and genuin transact that be not consid 

risky. for thi reason too, it be not conveni to pool the two type of supervis 

sampl together. finally, we notic that a constant and equal weight (αt = 0.5) in the 

aggreg awt and aet be often perform a well a adapt weight strategi 
present in section 6.5.5. 



chapter 6. concept-drift adapt with alert-feedback interact 140 

the interact between the fdss (rais alerts) and the investig (provid true 

labels) recal solut where the classifi interact with an oracl for addit label 

typic of activ learn [246]. the goal of activ learn be to minim the request of 

label data ask to oracles, by determin which be the most inform instanc 

to query. unfortunately, in a fds, we have a small budget devot to fraud alert 

investigation, i.e. the money that compani dedic to fraud investig be limited. 

the few investig avail have to focu on the most suspici transact with 

the goal of detect the larg number of frauds. We cannot demand the investig 

to check genuin transact for the sake of obtain inform patterns. valid 

of transact with low risk would come at the cost of not control highli riski 

transact with a consequ impact on the detect accuracy. In the ideal case of 

perfect detect all transact label by investig should be of class fraud. 

In our formul (section 6.2) we select transact to alert use the probabl of the 

sampl to be fraudulent. alternatively, baesen et al. [10] recommend gener alert 

for transact with expect fraud loss (fraud probability× transact amount) great 
than a certain threshold. similarly, fan et al. [126] suggest to alert onli transact 

have the expect fraud loss high than the overhead (cost of review an alert, 

i.e. cost of investigation). In thi work we defin the alert without consid the 

transact amount, becaus we want to give equal import to fraud of small and 

larg amount. If we detect fraud of small amounts, we can block the card and prevent 

larg one befor they occur, becaus fraudster typic tri to steal money with small 

amount first and then, if successful, with larg ones. 

It be worth to remark that the formul propos in section 6.2 be still a simplifi 

descript of the process regul compani analyz credit card transactions. 

for instance, it be typic not possibl to extract the alert At by rank the whole 

set bt, sinc transact have to be immedi pass to investigators; similarly, de- 

lay supervis coupl dt−δ do not come all at once, but be provid over time. 

notwithstanding, we deem that the most import aspect of the problem (i.e. the 

alert-feedback interact and the time-vari natur of the stream) be alreadi con- 

tain in our formul and that further detail would unnecessarili make the problem 

set complex. 

A limit of the current studi be that we report a feedback onli those transact 

gener an alert. however, when the investig call a cardholder, they typic 

check the statu of also previou transact make by the same card. thi mean that 

one alert can gener multipl supervis transact (|ft| ≥ |at|). In thi setting, 
it be more interest measur alert precis at the card level instead of the transac- 

tion level, i.e. measur how mani fraudul card be detect in the k card that 



chapter 6. concept-drift adapt with alert-feedback interact 141 

investig be abl to check. preliminari results, not includ in thi chapter, seem 

to confirm that, also in term of alert precis measur at the card level, the best 

perform be obtain by aggreg two classifi one train on feedback and 

the other on delay samples. 

6.7 conclus 

In thi chapter we formal a framework that reproduc the work condit of 

real-world fdss. In a real-world fraud-detect scenario, the onli recent supervised- 

inform be provid on the basi of the alert gener by the fd and feedback 

provid by investigators, i.e. alert-feedback interact (afi). all the other supervis 

sampl be avail with a much larg delay. 

our intuit be that: i) afi have to be explicitli consid in order to improv alert 

precis and ii) feedback and delay sampl have to be separ handl when 

train a realist fds. To thi purpose, we have consid two gener approach for 

fraud detection: a slide window and an ensembl of classifiers. We have then compar 

fdss that separ learn on feedback and delay sampl against fdss that pool all 

the avail supervis inform together. experi run on real-world stream of 

transact show that the former strategi provid much more precis alert than the 

latter, and that it also adapt more promptli in concept-drift environments. 

the major of the work present in the literatur (e.g. [18, 61]) assum that we have 

the label all transact (ignor afi) and use auc a accuraci measure. We claim 

that in a real world scenario, the main goal of a fd be to return accur alerts, i.e. high 

Pk (precis within the k transact that we report a alert to the investigators). In 

thi chapter we have show that in order to get precis alert (high pk) it be mandatori 

to give larg import to feedback samples. strategi lower their influenc in 

the learn process (e.g. ssb correct techniqu and Wt or Et classifiers) be often 
return less precis alert (lower pk). 

the feedback classifi Ft provid accur rank of the most suspici transact 
(high pk), but it be not the best option when the goal be to achiev a good rank of all 

transact (low auc). classifi train on everyday transact (e.g. wdt , edt , rt) 
have low pk, but return a good global rank (higher auc). By increas δ, the 

number of day in which we receiv feedbacks, Ft have good perform in term of 
pk. when Ft have high Pk also it aggreg awt and aet have high accuracy. 

adapt techniqu be import in the presenc of cd, thi be make clear by the 

poor perform of the static classifi St which use the same model along the stream. 



chapter 6. concept-drift adapt with alert-feedback interact 142 

aggreg Ft and wdt (or edt ) with awt (or aet ) be often the best solut to achiev 
high Pk even in the presenc of abrupt CD (see result from section 6.5.2). We have 

also test sever method to comput the weight αt use in the aggregations, but it 

appear that a simpl averag (αt = 0.5) be often the best solution. In the futur work 

we want to studi non-linear aggreg of classifi use in awt and aet , perhap 
good perform can be achiev by use a rank algorithm receiv a input the 

posterior probabl and the class of the transaction. 

currently, unsupervis (non-feedback) transact between t and t− δ be not use in 
the learn process. We think that be worth test semi-supervis learn algorithm 

to exploit both supervis (feedbacks) and unsupervis sampl occur between t 

and t − δ. anoth direct worth investig be to use more than k transact for 
train Ft if the rank be accur (when Pk ≈ 1). when Ft have high Pk we expect 
that the rank produc by the posterior probabl pft be accur not onli in the 
top k transactions, but also let’ say in the top k+γ. In thi case we could train Ft use 
k+ γ samples, where transact rank between k and k+ γ be label a fraudulent. 

finally, we can say that the result present in thi chapter be in line with the per- 

formanc of our industri partner (sometim even better). however, for confidenti 

reason, we be not allow to disclos figur regard the perform of our partner. 

appendix B present the softwar modul of the propos fds. 



chapter 7 

conclus and futur perspect 

fraud detect be a particularli challeng and complex task. fraudul activ 

be rare event that be hard to model and in constant evolution. the larg volum of 

transact happen everyday demand automat tool to support investigation, and 

the human resourc devot to investig have to concentr on the most suspici 

cases. thi thesi investig how machin learn algorithm could be use to address 

some of these issues. In particular, we focu on the design of a framework that be abl 

to report the riskiest transact to investig by mean of algorithm that can deal 

with unbalanc and evolv data streams. thi chapter summar the main result 

of the thesis, discu open issu and present futur research directions. 

7.1 summari of contribut 

A standard solut to deal with classif problem have unbalanc class dis- 

tribut (like fraud detection) be to rebal the class befor train a model. A 

popular rebalanc techniqu in the machin learn commun be undersampling. In 

chapter 4 we show the condit under which undersampl be expect to improv 

the rank of fraudul and genuin transact give by the posterior probabl of 

a classifier. We also studi the effect of class-separ on probabl calibr and 

how to set a threshold to make predictions. It emerg that, without control on the data 

distribution, it be not possibl to know beforehand whether undersampl be beneficial. 

for thi reason in section 4.3 we propos a race algorithm to select rapidli the best 

sampl techniqu when multipl solut be available. the race algorithm be 

make avail open sourc a a softwar packag for the R languag [25] (see packag 

unbalanc [24] present in appendix a). 

143 



chapter 7. conclus and futur perspect 144 

In order to deal with the non-stationar distribut of credit card transactions, chap- 

ter 5 investig multipl strategi for concept drift adapt in the presenc of skew 

distribution. We notic that updat regularli the fd be a much good altern 

than use the same model over all the year. when choos the sampl to train a 

classifi it be import to retain histor transact a well a forget outdat sam- 

ple for the model to be precise. also, resampl method (notabl undersampling) 

significantli improv the perform of a fds. propag of fraudul transact 

along the stream be anoth effect way to rebal the class distribution. however, 

the latter solut lead to comput overhead and it can be avoid without loss 

of accuraci by adopt a fd base on helling distanc decis tree. 

typically, fraud alert gener by a fd be check by human investig that 

annot alert transact a genuin or fraudulent. feedback from investig 

provid recent supervis sampl that be highli informative. In chapter 6 we present 

a prototyp of a fd that be abl to includ investigators’ feedback in the learn 

process. We show that, for the fd to produc accur alerts, feedback have to receiv 

larg weight than the other supervis sampl available. combin two classifiers, 

one train on feedback and one train on delay samples, be often the best way to 

provid accur alert in the presenc of concept drift. 

with thi thesi we also make avail to the machin learn commun a dataset 

contain observ of credit card transactions. thi dataset have be use in [28] 

and it includ exampl of fraudul samples, inform that be rare available.1 

7.2 learn lesson 

In the follow we summar what we have learn dure thi phd project with the 

intent of provid the reader and practition with some take home messages: 

• As show in chapter 4, rebalanc a train set with undersampl be not guar- 
ante to improv performances, sever factor influenc the final effect 

of undersampl and most of them cannot be control (e.g. the varianc of a 

classifi and the sampl where the condit (4.20) be satisfied). 

• the optim degre of sampl depend on the dataset considered. In section 4.1 
we show that the right amount of sampl with undersampl (defin by β) be 

dataset specific. when sampl be too aggress we have less point for which 

undersampl be beneficial. characterist of the classif task, such a class 
1dataset avail at http://www.ulb.ac.be/di/map/adalpozz/data/creditcard.rdata. 

http://www.ulb.ac.be/di/map/adalpozz/data/creditcard.rdata 


chapter 7. conclus and futur perspect 145 

separ and imbal ratio, also influenc the perform of the classifi 

and the effect of sampl methods. 

• the best techniqu for unbalanc classif do not exist and the best for 
a give dataset can vari with the algorithm and accuraci measur adopt (see 

section 4.3). adapt select strategi (e.g. f-race [26]) can be effect to 

rapidli provid an answer on which techniqu to use. 

• the data stream defin by credit card transact have non-stationari distri- 
butions, i.e. chang in fraudul and genuin behavior sever affect the perfor- 

manc of a fds. thi be make clear by the poor perform of static approach 

a show in section 5.1.3. updat the fd be often a good idea and retain 

histor transact can improv predict accuracy. 

• for a real-world fd it be mandatori to produc precis alerts, i.e. provid an 
accur rank of transact with the high risk of be fraudulent. As 

explain in section 6.2, investig trust and follow the alert of a data driven 

model a long a it do not gener too mani fals alerts. poor alert precis 

(low pk) mean also few recent fraudul transact and the fd have to relay 

onli on old fraudul pattern for the detection. 

• the best learn algorithm for a fd depend on the accuraci measur that we 
want to maximize. As show in chapter 6, a classifi train onli on feedback 

sampl (ft) can provid more precis alert (higher pk) than one train on all 
recent transact (rt). however, the latter becom a much good choic when 
use standard classif measur such a auc. 

7.3 open issu 

In thi section we want to discu some open issu in fraud detect that we believ 

be worth investigating, such as: i) defin a good perform measure, ii) model 

alert-feedback interact and iii) use the supervis and unsupervis inform 

avail with afi. 

despit everybodi agre on the fact that miss a fraud be much bad than generat- 

ing a fals alert, there be no agreement on which be the best way to measur fraud detect 

performance. indeed, the machin learn commun have propos sever cost mea- 

sures, some be transaction-depend [35, 70, 71], other be class-depend [2, 247]. 

other work avoid use cost-bas accuraci measur by make the implicit assumpt 

that it be more import to provid correct predict [18, 64]. 



chapter 7. conclus and futur perspect 146 

We think that there be not a correct and wrong way to measur detect performances, 

compani have differ idea about what be the best figur of merit. however, if a 

cost-bas measur be prefer then we recommend use normal cost [63] instead of 

save [70], becaus the second can be neg which be counter intuitive.2 altern 

one should use a benefit matrix a propos by elkan [35]. when use standard clas- 

sific metrics, we suggest auc estim base on the mann-whitney (wilcoxon) 

statist [18] (see section 2.2.3). In thi thesi we deem that, from an investig per- 

spective, the most relev measur be the alert precision, denot a pk, i.e. precis 

within the k most riski transact [20]. 

chapter 6 have propos a framework that be abl to exploit investigators’ feedback to 

improv detect performance. In our formulation, feedback be avail at the end 

of the day altogether, while in reality, the feedback mechan be much more complex. 

feedback be provid dure the day a soon a investig call the cardholder. more- 

over, investig check all previou transact of one card onc it be found to be victim 

of fraud. thi mean that we could have more the one feedback transact per alert 

gener and the model train on feedback should learn online, i.e. a soon a feed- 

back be received. additionally, feedback can be provid with a delay of more than 24 

hour and histor transact could receiv their label after months. despit these 

practic constraint we deem that the framework propos in chapter 6 be abl to meet 

essenti work condit of a real-world fd present in section 2.2.1. 

improv of the fd present in chapter 6 could come from use all avail 

transactions, not onli supervis samples. for example, semi-supervis strategi could 

exploit also unlabel data (non-feedback transact in the first δ days) to improv the 

detection. alternatively, even if investig requir the fd to provid accur alerts, 

we could use few alert (e.g. 5%) to queri unrisky, but interest sampl for the sake 

of obtain more precis alerts. thi last option would allow explor a small part of 

unsupervis sampl a in activ learning. 

7.4 the future: go toward big data solut 

In thi section we will discu futur research direct that in the meantim lead to the 

definit of a new research project call brufenc sponsor by innoviris.3 brufenc 

be a three year joint project between three research group of two univers and three 

compani base in brussels, belgium. the partner of the project are: machin learn 
2in some cases, give the small number of frauds, the cost of predict all transact a genuin 

can be low than the cost regist by a classif algorithm, lead to neg savings. 
3innoviri be the brussel institut for the encourag of scientif research and innovation. 



chapter 7. conclus and futur perspect 147 

group from université libr de bruxelles, machin learn group from université 

catholiqu de louvain, qualsec from université libr de bruxelles, worldlin s.a., 

steria and nviso. 

the goal of the project be the design of mechan base on machin learn and 

big data mine techniqu that allow to automat detect attack and fraudul 

behavior in larg amount of transactions. brufenc aim at develop a real-tim 

framework that be abl to compar in parallel a larg number of altern model 

in term of natur (expert-bas or data driven), featur (e.g. histori or custom 

related), data (e.g. supervis or unsupervised), predict method (e.g. decis trees, 

neural networks), scalabl (e.g. convent versu map/reduc implementation) 

and qualiti criterion (e.g. readabl vs. accuracy). the framework be expect to be 

scalabl with respect to the amount of data and resourc available. the project will also 

investig the exploit of network data (social networks, commun networks, 

etc.) for fraud, privaci and secur purposes. the use of network data be current a 

highli studi field, subject of much recent work in variou area of scienc [10]. 

current the IT infrastructur use for the fd be base on classic data warehous 

architectures. these architectur be well design for busi report but not for 

appli analyt to big volum of data. In thi context, it be infeas to do analyt- 

ic directli on the whole histor data set with standard machin learn algorithms. 

though an easi solut consist in use onli a portion of data for train the algo- 

rithms, thi have detriment effect on the result predict accuracy. 

compani that want to stay at the cut edg of secur technolog (like the sponsor 

of thi project) be more and more interest to enter the big data paradigm. however, 

though the introduct of big data technolog (e.g. hadoop4, spark5) in the everyday 

busi process be claim to be straightforward by mani vendors, in practic it de- 

mand a major redesign of exist functionalities. thi be particularli true for analyt 

and busi intellig applications, where the number of off-the-shelf solut be still 

limit and the requir data process be not trivial. A major goal of the project will 

be to adapt and, when necessary, rewrit machin learn and adapt function 

to make them scalabl for huge amount of transact and log data. In particular 

we will target problem character by larg amount of noise, larg dimensionality, 

non-stationar and demand a rapid and accur identif of threaten or 

fraudul configurations. 

As show by van vlassela et al. [61], network data be a power sourc of inform 

in order to improv the detect of fraudul behaviors. the rational be that network 
4http://hadoop.apache.org/ 
5http://spark.apache.org/ 

http://hadoop.apache.org/ 
http://spark.apache.org/ 


chapter 7. conclus and futur perspect 148 

connect provid inform that can improv the accuraci of the predict model. 

for example, it be well know that fraudul activ be link to each other. know 

that a merchant be target by mani fraudster may provid use inform on the 

likelihood that a transact on the same shop be fraudulent. the project will investigate, 

develop, and compar differ predict model in order to determin to which extent 

predict accuraci can be improv by use intern and extern network data. the 

project will also investig and compar differ predict model (graph-bas semi- 

supervis classif [248]) for privat inform discoveri (inform not publicli 

available), in order to determin to which extent, hidden inform can be infer from 

the network (e.g. age and sex of the cardhold if not available). eventually, we will 

develop new measur identifi the most critic or vulner connect node whose 

remov result in split the network. thi can be do with traffic inform or 

without traffic data. 

credit card fraud detect have tradit focu on look for factor such a trans- 

action amount, point of sales, location, etc. avail insid the organization. As show 

in section 2.2.2, from these basic variabl it be possibl to comput new aggreg fea- 

ture to model the behavior of the cardholder. typically, compani use a small sampl 

of histor transact for each cardhold to build account-level variables. becaus 

it be comput demand to comput aggregates, these featur be usual cal- 

culat offlin and then add to the featur vector repres the transact when 

it be authorized. use a small part of the inform avail may translat into a 

loss of predict accuracy. the introduct of big data technolog allow overcom 

these issues, i.e. comput aggreg in real time and use a larg set of histor 

transactions. 

the big data solut that we envisag will be abl to process massiv amount of 

structur and unstructur data from a hybrid of sourc a well. thi will enabl the 

exploit of both exist in-hous and public data (i.e. social media, websites, blogs). 

model and algorithm will take advantag of these richer sourc to build more accur 

detect models. for example, social medium can use to check whether a cardhold be 

travel and valid a transact from an unusu location. 

the project will deliv an onlin learn framework that be abl to process the data 

stream where the account-level inform and the network of transact be con- 

sidered. the learn process will have to handl the unbalanc natur of the data 

in real time without have to store/recal previou transact a in dal pozzolo et 

al. [19]. the algorithm will be implement use scalabl architectur that will allow 

the integr of exist and extern sourc of information. 



chapter 7. conclus and futur perspect 149 

7.5 ad valu for the compani 

In thi section we want to discu how the result of doctiri project (present in 

section 1.7) could be valor by the industri partner worldlin s.a. 

the fd in product at worldlin be current adopt a static approach (see section 

5.1.2), i.e. a classif model updat once/twic a year. the result of chapter 5 

show to the compani that there be a clear perform gain when the model be updat 

more frequently, e.g. onc a week or everi 15 days. the work do in chapter 5 allow 

worldlin to ass the perform of sever learn strategi in the presenc of CD 

and to test differ CD adapt methods. 

We also use differ classif algorithm not yet explor by worldline. In par- 

ticular, random forest have emerg a the best algorithm in mani simul and now 

the compani have it in production. dure the project we also investig new way to 

creat aggreg featur in order to includ user behavior at the transact level (see 

the transform propos in section 5.1.3). 

the unbalanc problem have never be theoret studi befor in worldline. the 

result of chapter 4 show that, in case of fraud detection, the perform of a clas- 

sifier can be significantli improv when sampl method be use to rebal the 

two classes. given the larg imbal ratio and number of transactions, undersam- 

pling should perhap be favor w.r.t. oversampl techniques. At the same time 

it be import to calibr the probabl in order to provid an accur rank of 

the transact after sampl the dataset (see section 4.2). additionally, the race 

strategi propos in section 4.3 give worldlin a new tool for select effici the 

unbalanc method that best fit the data. 

finally, in chapter 6 we provid evid that alert transact can be veri infor- 

mativ for obtain accur fds. currently, the fd in product at worldlin be 

not abl to trace if an histor transact have be check in a fraud investig or 

not. In thi setting, it be not possibl to distinguish between feedback and non-feedback 

samples. As show in section 6.5, high perform can be achiev by combin 

classifi separ train on feedback and delay transactions. 

7.6 conclud remark 

the doctiri phd project be an uniqu opportun to work on real-world fraud detec- 

tion data that, becaus of it high sensitivity, be scarc available. moreover, thi type of 

data be veri interest becaus it combin sever challeng such a class overlap, class 



chapter 7. conclus and futur perspect 150 

imbal and mislabel sampl among others. the collabor with the industri 

partner be particularli fruit becaus in the compani we have a supervisor, dr. olivi 

caelen, who care guid our work. 

As show in chapter 6, in real work condit we have constraint that defin new 

challenges. for example, the limit number of transact verifi by investig 

allow onli few recent supervis samples, while in the literatur most work assum 

to know the label of all transactions. also, the figur of merit that be interest for a 

compani may differ from standard accuraci measures. 

typically, compani be interest in more practic than theoret results, e.g. “a 

long a the algorithm work well there be no need to question it design or implementa- 

tion”. On the contrary, the academ world be sometim address complex problem 

that have few practic applications. We believ that both worlds, industri and univer- 

sity, should look at each other and exchang idea in order to have a much larg impact 

on society. for all these reasons, we hope that the doctiri initi will be follow 

by mani other and will pave the way of more collabor between compani and 

univers in the brussel region. 



appendix A 

the unbalanc packag 

thi appendix present a new softwar packag call unbalanc [24] avail for 

the R languag [25]. It implement some techniqu for unbalanc classif task 

present in section 3.1.1 and provid a race strategi [227] to adapt select the 

best method for a give dataset, classif algorithm and accuraci measur adopted. 

a.1 method for unbalanc classif 

the unbalanc packag includ some of the most well-known sampl and distance- 

base method for unbalanc classif task. within the famili of sampl meth- 

ods, we have function for random undersampl (ubunder) and oversampl (ubover) 

[91]. the packag contain also a function call ubsmot that implement smote [92]. 

other distance-bas method avail in unbalanc be oss [100] (uboss ), cnn [98] 

(ubcnn ), enn [101] (ubenn ), ncl [89] (ubncl) and tomek link [96] (ubtomek). all 

these method can be call by a wrapper function ubbal that allow test all these 

strategi by simpl chang the argument type. 

the packag includ the ubionospher datasets, which be a modif of the ionospher 

dataset contain in mlbench package. It have onli numer input variables, i.e. the first 

two variabl be removed. the class variable, origin take valu bad and good, have 

be transform into a factor where 1 denot the minor (bad) and 0 the major 

class (good). thi variabl be our target and it be in the last column of the dataset. In the 

follow we will also call the minor class a posit and the major a negative. 

for example, let’ appli oversampl to the ionospher dataset to have a balanc 

dataset. 

151 



appendix A. the unbalanc packag 152 

library(unbalanced) 

data(ubionosphere) 

n <- ncol(ubionosphere) 

output <- ubionosphere[ ,n] 

input <- ubionosphere[ ,-n] 

set.seed(1234) 

# 1-option use ubov function 

data <- ubover(x=input, y=output, k=0) 

# 2-option use ubbal function 

#data <- ubbalance(x=input, y=output, type="ubover", k=0) 

#oversampl dataset 

overdata <- data.frame(data$x, class=data$y) 

#check the frequenc of the target variabl after oversampl 

summary(overdata$class) 

## 0 1 

## 225 225 

In thi case we replic the minor class until we have a mani posit a neg 

instances. alternativelly, we can balanc the dataset use undersampl (i.e. remov 

observ from the major class): 

# use ubund function 

data <- ubunder(x=input, y=output, perc=50, method="percpos") 

#undersampl dataset 

underdata <- data.frame(data$x, class=data$y) 

#check the frequenc of the target variabl after oversampl 

summary(underdata$class) 

## 0 1 

## 126 126 

anoth well-know method for unbalanc distribut be smote, which oversampl the 

minor class by creat new synthet observations. let’ compar the perform 



appendix A. the unbalanc packag 153 

of two randomforest classifiers, one train on the origin unbalanc dataset and a 

second train on a dataset obtain after appli smote. 

set.seed(1234) 

#keep half for train and half for test 

N <- nrow(ubionosphere) 

n.tr <- floor(0.5*n) 

x.tr <- input[1:n.tr, ] 

y.tr <- output[1:n.tr] 

x.t <- input[(n.tr+1):n, ] 

y.t <- output[(n.tr+1):n] 

#use the origin unbalanc train set to build a model 

unbaltrain <- data.frame(x.tr, class=y.tr) 

library(randomforest) 

model1 <- randomforest(class ~ ., unbaltrain) 

#predict on the test set 

pred <- predict(model1, x.ts, type="class") 

confusionmatrix1 <- table(prediction=preds, actual=y.ts) 

print(confusionmatrix1) 

## actual 

## predict 0 1 

## 0 131 2 

## 1 6 37 

#rebal the train set befor build a model 

#balanc <- ubbalance(x=x.tr, y=y.tr, type="ubover", k=0) 

balanc <- ubbalance(x=x.tr, y=y.tr, type="ubsmote", percover=250) 

baltrain <- data.frame(balanced$x, class=balanced$y) 

#use the balanc train set 

model2 <- randomforest(class ~ ., baltrain) 

#predict on the test set 

pred <- predict(model2, x.ts, type="class") 

confusionmatrix2 <- table(prediction=preds, actual=y.ts) 

print(confusionmatrix2) 



appendix A. the unbalanc packag 154 

## actual 

## predict 0 1 

## 0 128 0 

## 1 9 39 

#we can now correctli classifi more minor class instanc 

use smote we alter the origin class distribut and we be abl to increas the 

number of minor instanc correctli classified. after smote the dataset we have no 

fals negatives, but a larg number of fals positives. In unbalanc classification, it 

often desir to correctli classifi all minor instanc (reduc the number of fals 

negatives), becaus the cost of miss a posit instanc (a fals negative) be much 

high than the cost of miss a neg instanc (a fals positive). 

a.2 race for strategi select 

the varieti of approach avail in the unbalanc packag allow the user to test 

multipl unbalanc methods. In a real situat where we have no prior inform 

about the data distribution, it be difficult to decid which unbalanc strategi to use. 

In thi case test all altern be not an option either becaus of the associ 

comput cost. 

As show in section 4.3, a possibl solut come from the adopt of the race 

algorithm. race be avail in unbalanc with the ubrac function and it im- 

plement be a modif of the race function avail in the race package. the 

function ubrac compar the 8 unbalanc method (ubunder, ubover, ubsmote, 

uboss, ubcnn, ubenn, ubncl, ubtomek) against the unbalanc distribution, so we 

have 9 candid start the race. In the follow we will use a highli unbalanc 

dataset contain credit card transact use in [28]. 

set.seed(1234) 

# load the dataset 

load(url("http://www.ulb.ac.be/di/map/adalpozz/data/creditcard.rdata")) 

#configur of the sampl method use in the race 

ubconf <- list(type="ubunder", percover=200, percunder=200, 

k=2, perc=50, method="percpos", w=null) 



appendix A. the unbalanc packag 155 

# race with 10 tree in the random forest to speed up result 

result <- ubracing(class ~., creditcard, "randomforest", positive=1, 

metric="auc", ubconf=ubconf, ntree=10) 

## race for unbalanc method select in 10 fold CV 

## number of candidates...........................................9 

## max number of fold in the cv.................................10 

## max number of experiments....................................100 

## statist test...................................friedman test 

## 

## markers: 

## x No test be performed. 

## - the test be perform and 

## some candid be discarded. 

## = the test be perform but 

## no candid be discarded. 

## 

## +-+-----------+-----------+-----------+-----------+-----------+ 

## | | fold| alive| best| mean best| exp so far| 

## +-+-----------+-----------+-----------+-----------+-----------+ 

## |x| 1| 9| 4| 0.9541| 9| 

## |=| 2| 9| 4| 0.954| 18| 

## |-| 3| 2| 4| 0.9591| 27| 

## |=| 4| 2| 4| 0.963| 29| 

## |=| 5| 2| 4| 0.9651| 31| 

## |-| 6| 1| 4| 0.9646| 33| 

## +-+-----------+-----------+-----------+-----------+-----------+ 

## select candidate: ubsmot metric: auc mean value: 0.9646 

the best method accord to the f-race be smote. pleas note that it be possibl 

to chang the type of statist test use to remov candid in the race with the 

argument stat.test. when we set stat.test = "no", no statist test be perform and 

the race termin when all the fold of the cross valid be explored. 



appendix A. the unbalanc packag 156 

a.3 summari 

with the unbalanc packag we have make avail some of the most well-known 

method for unbalanc distribution. all these method can be call from ubbal 

that be a wrapper to the method-specif functions. depend on the type of dataset, 

classif algorithm and accuraci measur adopted, we may have differ strategi 

that return the best accuracy. 

thi consider have lead u to adopt the race strategi where differ candid 

(unbalanc methods) be test simultaneously. thi algorithm be implement in the 

ubrac function which select the best candid without have to explor the whole 

dataset. 



appendix B 

fd softwar modul 

thi appendix present the softwar modul of the fd prototyp present in chap- 

ter 6. the softwar be divid in three main modul (see figur b.1): i) model training, 

ii) score and iii) review. the follow section present the role of each module. these 

modul be all implement in the R languag [25]. 

train_model, 

transac'ons) 
stream) 

predic/on, fraud)score) cmt) 

inves'gators)feedbacks) 

delayed) 
transac'ons) 

model)training) scoring) 

review) 

figur b.1: softwar modul of the fd prototyp present in chapter 6. 

b.1 model train 

thi modul be use to train predict model that be capabl of estim the prob- 

abil of a transact to be fraudulent. In particular, everyday it learn two models, 

one on delay transact dt−δ and one on feedback Ft (see section 6.3.2). the mod- 

ule implement two standard CD adapt techniqu (see section 6.3.1): i) a slide 

window classifi and ii) an ensembl of classifiers. regardless of the CD adapt 

strategi adopted, the modul run at midnight so that the result predict model 

(ft and wdt or edt ) be use to score transact occur the next day (t + 1). the 
main function of thi modul be train_model which receiv in input some supervis 

157 



appendix B. fd softwar modul 158 

transact (feedback or delay samples) and return a predict model built use 

the randomforest [222] packag a explain in section 6.3.3. 

b.2 score 

In the score modul all transact arriv at day t+ 1 be score by the predict 

function. In the predict function, each transact be first score by both the feedback 

classifi (with pft(+|x)) and the delay classifi (with pwdt (+|x) or pedt (+|x)). then, 
the final fraud score be comput use (6.3) or (6.4) depend on the CD adapt 

strategi use in modul b.1. thi modul be the most critic becaus transact arriv 

a a continu stream and have to be score in near real time (see section 2.2.1), i.e. 

the predict function receiv in input transact that have be author and have 

to score them within a littl time span. note that the featur vector of transact 

enter thi modul contain alreadi the aggreg featur present in section 2.2.2. 

aggreg featur be comput offlin in a distinct module. 

b.3 review 

In thi module, transact be make avail to the investig in a dashboard 

call case manag tool (cmt), where for each transact they can see the fraud 

score return by the predict function, and the featur vector contain the origin 

variabl such a card_id, the shop, currency, and also the aggreg variable. In 

the cmt transact be sort accord to their fraud score so that investig can 

review the most suspici one at the time they access the cmt. after verif a 

transact be flag a check and it becom a feedback. transact that be not 

review by the investig remain unlabel for δ day and then, if not report a 

fraudul by the cardholders, be label a genuine. alter δ days, transact that 

have not be check be use a delay supervis sampl in modul b.1. 



appendix C 

bia and varianc of an estim 

thi appendix present two measur to ass the qualiti of an estimator, name bia 

and variance. then we show a bias–vari decomposit for the mean squar error. 

definit 1 (bia of an estimator). An estim θ̂ of θ have bia 

bias[θ̂] = e[θ̂]− θ 

In particular, θ̂ be say to be unbias if e[θ̂] = θ and bia otherwise. 

definit 2 (varianc of an estimator). the varianc of an estim θ̂ be the varianc 

of it sampl distribut 

V ar[θ̂] = e[(θ̂ − e[θ̂])2] 

for ani random variabl x we can write 

V ar[x] = e[x2]− e[x]2 ⇐⇒ e[x2] = V ar[x] + e[x]2 (c.1) 

sinc θ be determinist e[θ] = θ and V ar[θ] = 0. therefore, use (c.1) we can decom- 

pose the mean squar error (mse) in term of bia and varianc of θ̂: 

mse = E 
[ 
(θ − θ̂)2 

] 
= e[θ2 + θ̂ 

2 − 2θθ̂] (c.2) 
= e[θ2] + e[θ̂ 

2 
]− e[2θθ̂] (c.3) 

= V ar[θ] + e[θ]2 + V ar[θ̂] + e[θ̂]2 − 2θe[θ̂] (c.4) 
= 0 + V ar[θ̂] + (θ − e[θ̂])2 (c.5) 
= V ar[θ̂] + e[θ − θ̂]2 (c.6) 
= V ar[θ̂] +bias[θ̂]2 (c.7) 

159 





bibliographi 

[1] d.j. newman A. asuncion. uci machin learn repository, 2007. url http: 

//archive.ics.uci.edu/ml/. 

[2] r.j. bolton and d.j. hand. statist fraud detection: A review. statist 

science, page 235–249, 2002. 

[3] piotr juszczak, niall M adams, david J hand, christoph whitrow, and david J 

weston. off-the-peg and bespok classifi for fraud detection. comput 

statist & data analysis, 52(9):4521–4532, 2008. 

[4] sam maes, karl tuyls, bram vanschoenwinkel, and bernard manderick. credit 

card fraud detect use bayesian and neural networks. In proceed of the 1st 

intern naiso congress on neuro fuzzi technologies, 2002. 

[5] jon TS quah and M sriganesh. real-tim credit card fraud detect use com- 

putat intelligence. expert system with applications, 35(4):1721–1732, 2008. 

[6] tej paul bhatla, vikram prabhu, and amit dua. understand credit card frauds. 

card busi review, 1(6), 2003. 

[7] christoph M bishop et al. pattern recognit and machin learning, volum 4. 

springer new york, 2006. 

[8] linda delamaire, hah abdou, and john pointon. credit card fraud and detect 

techniques: a review. bank and bank systems, 4(2):57–68, 2009. 

[9] raymond anderson. the credit score toolkit: theori and practic for retail 

credit risk manag and decis automation. oxford univers press, 2007. 

[10] bart baesens, veroniqu van vlasselaer, and wouter verbeke. fraud analyt 

use descriptive, predictive, and social network techniques: A guid to data 

scienc for fraud detection. john wiley & sons, 2015. 

[11] richard J bolton and david J hand. unsupervis profil method for fraud 

detection. credit score and credit control vii, page 235–255, 2001. 

161 

http://archive.ics.uci.edu/ml/ 
http://archive.ics.uci.edu/ml/ 


bibliographi 162 

[12] the nilson report, august 2013. url http://www.nilsonreport.com/. [issu 

1023 | aug 2013]. 

[13] lexi nexis. true cost of fraud 2014 study. url http://www.lexisnexis.com/ 

risk/insights/true-cost-fraud.aspx. 

[14] european central bank. report on card fraud available: https://www.ecb. 

europa.eu/press/pr/date/2014/html/pr140225.en.html. 

[15] cybersource. 2015 uk fraud report series: part 2, 2015. url http://www. 

cybersource.com/. [online; access july-2015]. 

[16] wikipedia. 3-d secure, 2015. url http://en.wikipedia.org/wiki/3-d_secure. 

[online; access july-2015]. 

[17] jose M pavía, ernesto J veres-ferrer, and gabriel foix-escura. credit card inci- 

dent and control systems. intern journal of inform management, 32 

(6):501–503, 2012. 

[18] andrea dal pozzolo, olivi caelen, yann-ael Le borgne, serg waterschoot, and 

gianluca bontempi. learn lesson in credit card fraud detect from a practi- 

tioner perspective. expert system with applications, 41(10):4915–4928, 2014. 

[19] andrea dal pozzolo, reid A. johnson, olivi caelen, serg waterschoot, nitesh V 

chawla, and gianluca bontempi. use hddt to avoid instanc propag in 

unbalanc and evolv data streams. In neural network (ijcnn), 2014 inter- 

nation joint confer on, page 588–594. ieee, 2014. 

[20] andrea dal pozzolo, giacomo boracchi, olivi caelen, cesar alippi, and gi- 

anluca bontempi. credit card fraud detect and concept-drift adapt with 

delay supervis information. In neural network (ijcnn), 2015 intern 

joint confer on. ieee, 2015. 

[21] haibo He and edwardo A garcia. learn from imbalanc data. knowledg and 

data engineering, ieee transact on, 21(9):1263–1284, 2009. 

[22] G. batista, A. carvalho, and M. monard. appli one-sid select to unbal- 

anc datasets. micai 2000: advanc in artifici intelligence, page 315–325, 

2000. 

[23] joão gama, indrė žliobaitė, albert bifet, mykola pechenizkiy, and abdelhamid 

bouchachia. A survey on concept drift adaptation. acm comput survey 

(csur), 46(4):44, 2014. 

http://www.nilsonreport.com/ 
http://www.lexisnexis.com/risk/insights/true-cost-fraud.aspx 
http://www.lexisnexis.com/risk/insights/true-cost-fraud.aspx 
https://www.ecb.europa.eu/press/pr/date/2014/html/pr140225.en.html 
https://www.ecb.europa.eu/press/pr/date/2014/html/pr140225.en.html 
http://www.cybersource.com/ 
http://www.cybersource.com/ 
http://en.wikipedia.org/wiki/3-d_secur 


bibliographi 163 

[24] andrea dal pozzolo, olivi caelen, and gianluca bontempi. unbalanced: race 

for unbalanc method selection., 2015. url http://cran.r-project.org/ 

package=unbalanced. R packag version 2.0. 

[25] R develop core team. R: A languag and environ for statist com- 

puting. R foundat for statist computing, vienna, austria, 2011. url 

http://www.r-project.org/. isbn 3-900051-07-0. 

[26] M. birattari, T. stützle, L. paquete, and K. varrentrapp. A race algorithm for 

configur metaheuristics. In proceed of the genet and evolutionari compu- 

tation conference, page 11–18, 2002. 

[27] andrea dal pozzolo, olivi caelen, serg waterschoot, and gianluca bontempi. 

race for unbalanc method selection. In proceed of the 14th intern 

confer on intellig data engin and autom learning. ideal, 

2013. 

[28] andrea dal pozzolo, olivi caelen, reid A. johnson, and gianluca bontempi. 

calibr probabl with undersampl for unbalanc classification. In 2015 

ieee symposium on comput intellig and data mining. ieee, 2015. 

[29] tom M mitchell. machin learning. 1997. burr ridge, il: mcgraw hill, 45, 1997. 

[30] vladimir naumovich vapnik and vlamimir vapnik. statist learn theory, 

volum 1. wiley new york, 1998. 

[31] trevor hastie, robert tibshirani, jerom friedman, T hastie, J friedman, and 

R tibshirani. the element of statist learning, volum 2. springer, 2009. 

[32] lennart ljung. system identification: theori for the user. ptr prentic hall 

inform and system scienc series, 198, 1987. 

[33] andrew R webb. statist pattern recognition. john wiley & sons, 2003. 

[34] richard O duda, peter E hart, and david G stork. pattern classification. john 

wiley & sons, 2012. 

[35] C. elkan. the foundat of cost-sensit learning. In intern joint con- 

ferenc on artifici intelligence, volum 17, page 973–978, 2001. 

[36] trevor. hastie, robert. tibshirani, and J jerom H friedman. the element of 

statist learning, volum 1. springer new york, 2001. 

[37] pedro domingos. A unifi bias-vari decomposit for zero-on and squar 

loss. aaai/iaai, 2000:564–569, 2000. 

http://cran.r-project.org/package=unbalanc 
http://cran.r-project.org/package=unbalanc 
http://www.r-project.org/ 


bibliographi 164 

[38] robert C holte. veri simpl classif rule perform well on most commonli 

use datasets. machin learning, 11(1):63–90, 1993. 

[39] pedro domingo and michael pazzani. On the optim of the simpl bayesian 

classifi under zero-on loss. machin learning, 29(2-3):103–130, 1997. 

[40] eric bauer and ron kohavi. An empir comparison of vote classif 

algorithms: bagging, boosting, and variants. machin learning, 36(1-2):105–139, 

1999. 

[41] leo breiman. bag predictors. machin learning, 24(2):123–140, 1996. 

[42] robert E schapire, yoav freund, peter bartlett, and wee sun lee. boost the 

margin: A new explan for the effect of vote methods. annal of 

statistics, page 1651–1686, 1998. 

[43] leo breiman. random forests. machin learning, 45(1):5–32, 2001. 

[44] ander krogh, jesper vedelsby, et al. neural network ensembles, cross validation, 

and activ learning. advanc in neural inform process systems, 7:231–238, 

1995. 

[45] hongyu guo and herna L viktor. learn from imbalanc data set with boost- 

ing and data generation: the databoost-im approach. acm sigkdd explor 

newsletter, 6(1):30–39, 2004. 

[46] gari M weiss. mine with rarity: a unifi framework. acm sigkdd explo- 

ration newsletter, 6(1):7–19, 2004. 

[47] david L olson and dursun delen. advanc data mine techniques. springer 

scienc & busi media, 2008. 

[48] i.h. witten and E. frank. data mining: practic machin learn tool and 

techniques. morgan kaufmann, 2005. 

[49] foster provost. machin learn from imbalanc data set 101. In proceed 

of the aaai’2000 workshop on imbalanc data sets, 2000. 

[50] chao chen, andi liaw, and leo breiman. use random forest to learn imbalanc 

data. univers of california, berkeley, 2004. 

[51] nitesh V chawla, david A cieslak, lawrenc O hall, and ajay joshi. automati- 

calli counter imbal and it empir relationship to cost. data mine and 

knowledg discovery, 17(2):225–252, 2008. 



bibliographi 165 

[52] gregori ditzler, robi polikar, and nitesh chawla. An increment learn algo- 

rithm for non-stationari environ and class imbalance. In pattern recognit 

(icpr), 2010 20th intern confer on, page 2997–3000. ieee, 2010. 

[53] tom fawcett. roc graphs: note and practic consider for researchers. 

machin learning, 31:1–38, 2004. 

[54] tom fawcett. An introduct to roc analysis. pattern recognit letters, 27(8): 

861–874, 2006. 

[55] nitesh V chawla. c4.5 and imbalanc data sets: investig the effect of sam- 

pling method, probabilist estimate, and decis tree structure. In proceed of 

the icml, volum 3, 2003. 

[56] nitesh V chawla. data mine for imbalanc datasets: An overview. In data 

mine and knowledg discoveri handbook, page 853–867. springer, 2005. 

[57] wei liu, sanjay chawla, david A cieslak, and nitesh V chawla. A robust decis 

tree algorithm for imbalanc data sets. In sdm, volum 10, page 766–777. siam, 

2010. 

[58] jess davi and mark goadrich. the relationship between precision-recal and roc 

curves. In proceed of the 23rd intern confer on machin learning, 

page 233–240. acm, 2006. 

[59] ira cohen and mois goldszmidt. properti and benefit of calibr classifiers. 

In knowledg discoveri in databases: pkdd 2004, page 125–136. springer, 2004. 

[60] glenn W brier. verif of forecast express in term of probability. monthli 

weather review, 78(1):1–3, 1950. 

[61] véroniqu van vlasselaer, cristian bravo, olivi caelen, tina eliassi-rad, le- 

man akoglu, moniqu snoeck, and bart baesens. apate: A novel approach for 

autom credit card transact fraud detect use network-bas extensions. 

decis support systems, 2015. 

[62] M krivko. A hybrid model for plastic card fraud detect systems. expert system 

with applications, 37(8):6070–6076, 2010. 

[63] christoph whitrow, david J hand, piotr juszczak, D weston, and niall M 

adams. transact aggreg a a strategi for credit card fraud detection. 

data mine and knowledg discovery, 18(1):30–55, 2009. 

[64] siddhartha bhattacharyya, sanjeev jha, kurian tharakunnel, and J christoph 

westland. data mine for credit card fraud: A compar study. decis 

support systems, 50(3):602–613, 2011. 



bibliographi 166 

[65] sanjeev jha, montserrat guillen, and J christoph westland. employ trans- 

action aggreg strategi to detect credit card fraud. expert system with appli- 

cations, 39(16):12650–12657, 2012. 

[66] d.j. hand. measur classifi performance: a coher altern to the area 

under the roc curve. machin learning, 77(1):103–123, 2009. 

[67] donald bamber. the area abov the ordin domin graph and the area below 

the receiv oper characterist graph. journal of mathemat psychology, 

12(4):387–415, 1975. 

[68] yusuf sahin, serol bulkan, and ekrem duman. A cost-sensit decis tree 

approach for fraud detection. expert system with applications, 40(15):5916–5923, 

2013. 

[69] nader mahmoudi and ekrem duman. detect credit card fraud by modifi 

fisher discrimin analysis. expert system with applications, 42(5):2510–2516, 

2015. 

[70] alejandro correa bahnsen, djamila aouada, and björn ottersten. example- 

depend cost-sensit decis trees. expert system with applications, 2015. 

[71] alejandro correa bahnsen, aleksandar stojanovic, djamila aouada, and bjorn 

ottersten. cost sensit credit card fraud detect use bay minimum risk. In 

machin learn and applic (icmla), 2013 12th intern confer 

on, volum 1, page 333–338. ieee, 2013. 

[72] ekrem duman and M hamdi ozcelik. detect credit card fraud by genet 

algorithm and scatter search. expert system with applications, 38(10):13057– 

13063, 2011. 

[73] G. fan and M. zhu. detect of rare item with target. statist and it interface, 

4:11–17, 2011. 

[74] Mu zhu. recall, precis and averag precision. depart of statist and 

actuari science, univers of waterloo, waterloo, 2, 2004. 

[75] david J hand and martin J crowder. overcom select bia in evalu 

new fraud detect system for revolv credit operations. intern journal 

of forecasting, 28(1):216–223, 2012. 

[76] nitesh V chawla, nathali japkowicz, and aleksand kotcz. editorial: special 

issu on learn from imbalanc data sets. acm sigkdd explor newslet- 

ter, 6(1):1–6, 2004. 



bibliographi 167 

[77] B. zadrozny, J. langford, and N. abe. cost-sensit learn by cost- 

proportion exampl weighting. In data mining, icdm, page 435–442. ieee, 

2003. 

[78] P. domingos. metacost: a gener method for make classifi cost-sensitive. 

In proceed of the fifth acm sigkdd intern confer on knowledg 

discoveri and data mining, page 155–164. acm, 1999. 

[79] nathali japkowicz. concept-learn in the presenc of between-class and within- 

class imbalances. In advanc in artifici intelligence, page 67–77. springer, 

2001. 

[80] taeho Jo and nathali japkowicz. class imbal versu small disjuncts. acm 

sigkdd explor newsletter, 6(1):40–49, 2004. 

[81] gari M weiss. learn with rare case and small disjuncts. In icml, page 

558–565, 1995. 

[82] nathali japkowicz and shaju stephen. the class imbal problem: A systemat 

study. intellig data analysis, 6(5):429–449, 2002. 

[83] nathali japkowicz. class imbalances: be we focu on the right issue. In 

workshop on learn from imbalanc data set ii, volum 1723, page 63, 2003. 

[84] ronaldo C prati, gustavo eapa batista, and maria carolina monard. class 

imbal versu class overlapping: an analysi of a learn system behavior. In 

micai 2004: advanc in artifici intelligence, page 312–321. springer, 2004. 

[85] J. ross quinlan. induct of decis trees. machin learning, 1(1):81–106, 1986. 

[86] robert C holte, lian E acker, and bruce W porter. concept learn and the 

problem of small disjuncts. In proceed of the eleventh intern joint 

confer on artifici intelligence, volum 1, 1989. 

[87] haibo He and yunqian ma. imbalanc learning: foundations, algorithms, and 

applications. john wiley & sons, 2013. 

[88] gari M weiss and foster provost. the effect of class distribut on classifi 

learning: an empir study. rutger univ, 2001. 

[89] J. laurikkala. improv identif of difficult small class by balanc class 

distribution. artifici intellig in medicine, page 63–66, 2001. 

[90] andrew estabrooks, taeho jo, and nathali japkowicz. A multipl resampl 

method for learn from imbalanc data sets. comput intelligence, 20(1): 

18–36, 2004. 



bibliographi 168 

[91] C. drummond and r.c. holte. c4.5, class imbalance, and cost sensitivity: whi 

under-sampl beat over-sampling. In workshop on learn from imbalanc 

dataset ii, 2003. 

[92] NV chawla, KW bowyer, lawrenc O. hall, and W. philip kegelmeyer. smote: 

synthet minor over-sampl technique. journal of artifici intellig re- 

search (jair), 16:321–357, 2002. 

[93] BX wang and N japkowicz. imbalanc data set learn with synthet samples. 

In proc. iri machin learn workshop, page 19, 2004. 

[94] hui han, wen-yuan wang, and bing-huan mao. borderline-smote: a new over- 

sampl method in imbalanc data set learning. In advanc in intellig 

computing, page 878–887. springer, 2005. 

[95] haibo he, yang bai, edwardo garcia, shutao li, et al. adasyn: adapt synthet 

sampl approach for imbalanc learning. In neural networks, 2008. ijcnn 

2008.(ieee world congress on comput intelligence). ieee intern 

joint confer on, page 1322–1328. ieee, 2008. 

[96] I. tomek. two modif of cnn. ieee trans. syst. man cybern., 6:769–772, 

1976. 

[97] S. suman, K. laddhad, and U. deshmukh. method for handl highli skew 

datasets. part i-october, 3, 2005. 

[98] P. E. hart. the condens near neighbor rule. ieee transact on informa- 

tion theory, 1968. 

[99] d.r. wilson and t.r. martinez. reduct techniqu for instance-bas learn 

algorithms. machin learning, 38(3):257–286, 2000. 

[100] miroslav kubat, stan matwin, et al. address the curs of imbalanc train 

sets: one-sid selection. In icml, volum 97, page 179–186. nashville, usa, 

1997. 

[101] d.l. wilson. asymptot properti of near neighbor rule use edit data. 

systems, man and cybernetics, (3):408–421, 1972. 

[102] j.r. quinlan. c4.5: program for machin learning, volum 1. morgan kaufmann, 

1993. 

[103] david A cieslak and nitesh V chawla. learn decis tree for unbalanc 

data. In machin learn and knowledg discoveri in databases, page 241–256. 

springer, 2008. 



bibliographi 169 

[104] sofia visa and anca ralescu. issu in mine imbalanc data sets-a review 

paper. In proceed of the sixteen midwest artifici intellig and cognit 

scienc conference, page 67–73. sn, 2005. 

[105] inderjeet mani and I zhang. knn approach to unbalanc data distributions: a case 

studi involv inform extraction. In proceed of workshop on learn 

from imbalanc datasets, 2003. 

[106] gustavo eapa batista, ronaldo C prati, and maria carolina monard. A studi 

of the behavior of sever method for balanc machin learn train data. 

acm sigkdd explor newsletter, 6(1):20–29, 2004. 

[107] rong yan, yan liu, rong jin, and alex hauptmann. On predict rare class 

with svm ensembl in scene classification. In acoustics, speech, and signal pro- 

cessing, 2003. proceedings.(icassp’03). 2003 ieee intern confer on, 

volum 3, page iii–21. ieee, 2003. 

[108] gang Wu and edward Y chang. class-boundari align for imbalanc dataset 

learning. In icml 2003 workshop on learn from imbalanc data set ii, wash- 

ington, dc, page 49–56, 2003. 

[109] jérôme callut and pierr dupont. F β support vector machines. In neural net- 

works, 2005. ijcnn’05. proceedings. 2005 ieee intern joint confer 

on, volum 3, page 1443–1448. ieee, 2005. 

[110] xuchun li, lei wang, and eric sung. adaboost with svm-base compon clas- 

sifiers. engin applic of artifici intelligence, 21(5):785–795, 2008. 

[111] wei liu and sanjay chawla. class confid weight knn algorithm for im- 

balanc data sets. In advanc in knowledg discoveri and data mining, page 

345–356. springer, 2011. 

[112] bing liu, wynn hsu, and yime ma. mine associ rule with multipl min- 

imum supports. In proceed of the fifth acm sigkdd intern confer 

on knowledg discoveri and data mining, page 337–341. acm, 1999. 

[113] florian verhein and sanjay chawla. use significant, posit associ and 

rel class correl rule for associ classif of imbalanc datasets. 

In data mining, 2007. icdm 2007. seventh ieee intern confer on, 

page 679–684. ieee, 2007. 

[114] gari M weiss. foundat of imbalanc learning. H. he, & Y. ma, imbalanc 

learning: foundations, algorithms, and applications, page 13–41, 2013. 



bibliographi 170 

[115] yoav freund, robert E schapire, et al. experi with a new boost algorithm. 

In icml, volum 96, page 148–156, 1996. 

[116] x.y. liu, J. wu, and z.h. zhou. exploratori undersampl for class-imbal 

learning. systems, man, and cybernetics, part B: cybernetics, 39(2):539–550, 

2009. 

[117] shuo wang, Ke tang, and xin yao. divers explor and neg correla- 

tion learn on imbalanc data sets. In neural networks, 2009. ijcnn 2009. 

intern joint confer on, page 3259–3266. ieee, 2009. 

[118] fernando vilariño, panagiota spyridonos, jordi vitrià, and petia radeva. experi- 

ment with svm and stratifi sampl with an imbalanc problem: detect of 

intestin contractions. In pattern recognit and imag analysis, page 783–791. 

springer, 2005. 

[119] pilsung kang and sungzoon cho. eu svms: ensembl of under-sampl svm 

for data imbal problems. In neural inform processing, page 837–846. 

springer, 2006. 

[120] yang liu, aijun an, and xiangji huang. boost predict accuraci on imbal- 

anc dataset with svm ensembles. In advanc in knowledg discoveri and data 

mining, page 107–118. springer, 2006. 

[121] benjamin X wang and nathali japkowicz. boost support vector machin for 

imbalanc data sets. knowledg and inform systems, 25(1):1–20, 2010. 

[122] N. chawla, A. lazarevic, L. hall, and K. bowyer. smoteboost: improv predic- 

tion of the minor class in boosting. knowledg discoveri in databases: pkdd 

2003, page 107–119, 2003. 

[123] mahesh V joshi, vipin kumar, and ramesh C agarwal. evalu boost 

algorithm to classifi rare classes: comparison and improvements. In data mining, 

2001. icdm 2001, proceed ieee intern confer on, page 257–264. 

ieee, 2001. 

[124] david mease, abraham J wyner, and andrea buja. boost classif tree 

and class probability/quantil estimation. the journal of machin learn re- 

search, 8:409–439, 2007. 

[125] yanmin sun, moham S kamel, andrew KC wong, and yang wang. cost- 

sensit boost for classif of imbalanc data. pattern recognition, 40 

(12):3358–3378, 2007. 



bibliographi 171 

[126] wei fan, salvator J stolfo, junxin zhang, and philip K chan. adacost: misclas- 

sific cost-sensit boosting. In icml, page 97–105, 1999. 

[127] hame masnadi-shirazi and nuno vasconcelos. risk minimization, probabl 

elicitation, and cost-sensit svms. In icml, page 759–766, 2010. 

[128] matjaz kukar, igor kononenko, et al. cost-sensit learn with neural networks. 

In ecai, page 445–449, 1998. 

[129] charl X ling, qiang yang, jian wang, and shichao zhang. decis tree 

with minim costs. In proceed of the twenty-first intern confer on 

machin learning, page 69. acm, 2004. 

[130] jeffrey P bradford, clayton kunz, ron kohavi, cliff brunk, and carla E brodley. 

prune decis tree with misclassif costs. In machin learning: ecml- 

98, page 131–136. springer, 1998. 

[131] c.x. ling and v.s. sheng. cost-sensit learn and the class imbal problem. 

encyclopedia of machin learning, 2008. 

[132] marcu A maloof, pat langley, stephani sage, and T binford. learn to detect 

rooftop in aerial images. 1997. 

[133] corinna cortes, mehryar mohri, michael riley, and afshin rostamizadeh. sam- 

ple select bia correct theory. In algorithm learn theory, page 38–53. 

springer, 2008. 

[134] marco saerens, patric latinne, and christin decaestecker. adjust the output 

of a classifi to new a priori probabilities: a simpl procedure. neural computation, 

14(1):21–41, 2002. 

[135] mark G kelly, david J hand, and niall M adams. the impact of chang pop- 

ulat on classifi performance. In proceed of the fifth acm sigkdd in- 

ternat confer on knowledg discoveri and data mining, page 367–371. 

acm, 1999. 

[136] hidetoshi shimodaira. improv predict infer under covari shift by 

weight the log-likelihood function. journal of statist plan and inference, 

90(2):227–244, 2000. 

[137] david J hand et al. classifi technolog and the illus of progress. statist 

science, 21(1):1–14, 2006. 

[138] keisuk yamazaki, motoaki kawanabe, sumio watanabe, masashi sugiyama, and 

klaus-robert müller. asymptot bayesian gener error when train and 



bibliographi 172 

test distribut be different. In proceed of the 24th intern confer 

on machin learning, page 1079–1086. acm, 2007. 

[139] masashi sugiyama, matthia krauledat, and klaus-robert müller. covari shift 

adapt by import weight cross validation. the journal of machin 

learn research, 8:985–1005, 2007. 

[140] jame J heckman. sampl select bia a a specif error. econometrica: 

journal of the econometr society, page 153–161, 1979. 

[141] jose G moreno-torres, troy raeder, rocío alaiz-rodríguez, nitesh V chawla, 

and francisco herrera. A unifi view on dataset shift in classification. pattern 

recognition, 45(1):521–530, 2012. 

[142] bianca zadrozni and charl elkan. learn and make decis when cost 

and probabl be both unknown. In proceed of the seventh acm sigkdd 

intern confer on knowledg discoveri and data mining, page 204–213. 

acm, 2001. 

[143] bianca zadrozny. learn and evalu classifi under sampl select bias. 

In proceed of the twenty-first intern confer on machin learning, 

page 114. acm, 2004. 

[144] wei fan, ian davidson, bianca zadrozny, and philip S yu. An improv catego- 

rizat of classifier’ sensit on sampl select bias. In data mining, fifth 

ieee intern confer on, page 4–pp. ieee, 2005. 

[145] miroslav dudík, steven J phillips, and robert E schapire. correct sampl 

select bia in maximum entropi densiti estimation. In advanc in neural 

inform process systems, page 323–330, 2005. 

[146] nitesh V chawla and grigori I karakoulas. learn from label and unla- 

bele data: An empir studi across techniqu and domains. J. artif. intell. 

res.(jair), 23:331–366, 2005. 

[147] masashi sugiyama. learn under non-stationarity: covari shift adapt 

by import weighting. In handbook of comput statistics, page 927–952. 

springer, 2012. 

[148] T ryan hoens, robi polikar, and nitesh V chawla. learn from stream data 

with concept drift and imbalance: an overview. progress in artifici intelligence, 

1(1):89–101, 2012. 

[149] joaquin quionero-candela, masashi sugiyama, anton schwaighofer, and neil D 

lawrence. dataset shift in machin learning. the mit press, 2009. 



bibliographi 173 

[150] C. alippi, G. boracchi, and M. roveri. just-in-tim classifi for recurr con- 

cepts. neural network and learn systems, ieee transact on, 24(4):620– 

634, april. issn 2162-237x. doi: 10.1109/tnnls.2013.2239309. 

[151] stephen grossberg. nonlinear neural networks: principles, mechanisms, and ar- 

chitectures. neural networks, 1(1):17–61, 1988. 

[152] joao gama, pedro medas, gladi castillo, and pedro rodrigues. learn with 

drift detection. In advanc in artifici intelligence–sbia 2004, page 286–295. 

springer, 2004. 

[153] kyosuk nishida and koichiro yamauchi. detect concept drift use statist 

testing. In discoveri science, page 264–269. springer, 2007. 

[154] albert bifet and ricard gavalda. learn from time-chang data with adapt 

windowing. In sdm, volum 7, page 2007. siam, 2007. 

[155] cesar alippi, giacomo boracchi, and manuel roveri. A just-in-tim adapt 

classif system base on the intersect of confid interv rule. neural 

networks, 24(8):791–800, 2011. 

[156] gregori ditzler, manuel roveri, cesar alippi, and robi polikar. learn in non- 

stationari environments: A survey. comput intellig magazine, ieee, 

10(4):12–25, 2015. 

[157] indrė žliobaitė. learn under concept drift: an overview. arxiv preprint 

arxiv:1010.4784, 2010. 

[158] ryan elwel and robi polikar. increment learn of concept drift in nonsta- 

tionari environments. neural networks, ieee transact on, 22(10):1517–1531, 

2011. 

[159] robi polikar, L upda, SS upda, and vasant honavar. learn++: An increment 

learn algorithm for supervis neural networks. systems, man, and cybernetics, 

part C: applic and reviews, 31(4):497–508, 2001. 

[160] W nick street and yongseog kim. A stream ensembl algorithm (sea) for large- 

scale classification. In proceed of the seventh acm sigkdd intern 

confer on knowledg discoveri and data mining, page 377–382. acm, 2001. 

[161] sheng chen, haibo he, kang li, and sachi desai. musera: multipl select 

recurs approach toward imbalanc stream data mining. In neural network 

(ijcnn), the 2010 intern joint confer on, page 1–8. ieee, 2010. 



bibliographi 174 

[162] J zico kolter and marcu A maloof. dynam weight majority: An ensembl 

method for drift concepts. the journal of machin learn research, 8:2755– 

2790, 2007. 

[163] jeffrey C schlimmer and richard H granger jr. increment learn from noisi 

data. machin learning, 1(3):317–354, 1986. 

[164] gerhard widmer and miroslav kubat. learn in the presenc of concept drift 

and hidden contexts. machin learning, 23(1):69–101, 1996. 

[165] ludmila I kuncheva. classifi ensembl for chang environments. In multipl 

classifi systems, page 1–15. springer, 2004. 

[166] charu C aggarwal. data streams: model and algorithms, volum 31. springer 

scienc & busi media, 2007. 

[167] pedro domingo and geoff hulten. mine high-spe data streams. In proceed 

of the sixth acm sigkdd intern confer on knowledg discoveri and 

data mining, page 71–80. acm, 2000. 

[168] geoff hulten, lauri spencer, and pedro domingos. mine time-chang data 

streams. In proceed of the seventh acm sigkdd intern confer on 

knowledg discoveri and data mining, page 97–106. acm, 2001. 

[169] joão gama, ricardo fernandes, and ricardo rocha. decis tree for mine 

data streams. intellig data analysis, 10(1):23–45, 2006. 

[170] jing gao, wei fan, jiawei han, and S Yu philip. A gener framework for mine 

concept-drift data stream with skew distributions. In sdm, 2007. 

[171] jing gao, bolin ding, wei fan, jiawei han, and philip S yu. classifi data 

stream with skew class distribut and concept drifts. internet computing, 

12(6):37–49, 2008. 

[172] gregori ditzler and robi polikar. An ensembl base increment learn frame- 

work for concept drift and class imbalance. In neural network (ijcnn), the 

2010 intern joint confer on, page 1–8. ieee, 2010. 

[173] gregori ditzler and robi polikar. increment learn of concept drift from 

stream imbalanc data. knowledg and data engineering, ieee transact 

on, 25(10):2283–2301, 2013. 

[174] ryan elwel and robi polikar. increment learn of variabl rate concept drift. 

In multipl classifi systems, page 142–151. springer, 2009. 



bibliographi 175 

[175] ryan N lichtenwalt and nitesh V chawla. adapt method for classif 

in arbitrarili imbalanc and drift data streams. In new frontier in appli 

data mining, page 53–75. springer, 2010. 

[176] sheng chen and haibo he. toward increment learn of nonstationari imbal- 

anc data stream: a multipl select recurs approach. evolv systems, 2 

(1):35–50, 2011. 

[177] sheng chen and haibo he. sera: select recurs approach toward nonsta- 

tionari imbalanc stream data mining. In neural networks, 2009. ijcnn 2009. 

intern joint confer on, page 522–529. ieee, 2009. 

[178] shuowang, leandro L minku, and xin yao. onlin class imbal learn and it 

applic in fault detection. intern journal of comput intellig 

and applications, 12(04), 2013. 

[179] nikunj C oza. onlin bag and boosting. In systems, man and cybernetics, 

volum 3, page 2340–2345. ieee, 2005. 

[180] R. brause, T. langsdorf, and M. hepp. neural data mine for credit card fraud 

detection. In tool with artifici intelligence, proceedings, page 103–106. ieee, 

1999. 

[181] p.k. chan, W. fan, a.l. prodromidis, and s.j. stolfo. distribut data mine 

in credit card fraud detection. intellig system and their applications, 14(6): 

67–74, 1999. 

[182] dimitri K tasoulis, niall M adams, and david J hand. unsupervis cluster 

in stream data. In icdm workshops, page 638–642, 2006. 

[183] F. provost, T. fawcett, et al. analysi and visual of classifi performance: 

comparison under imprecis class and cost distributions. In proceed of the 

third intern confer on knowledg discoveri and data mining, page 43– 

48. amer assn for artificial, 1997. 

[184] d.j. weston, d.j. hand, n.m. adams, C. whitrow, and P. juszczak. plastic 

card fraud detect use peer group analysis. advanc in data analysi and 

classification, 2(1):45–62, 2008. 

[185] agu sudjianto, sheela nair, ming yuan, aijun zhang, daniel kern, and fernando 

cela-díaz. statist method for fight financi crimes. technometrics, 52(1), 

2010. 

[186] naeem siddiqi. credit risk scorecards: develop and implement intellig 

credit scoring, volum 3. wiley. com, 2005. 



bibliographi 176 

[187] tom fawcett and foster provost. adapt fraud detection. data mine and 

knowledg discovery, 1(3):291–316, 1997. 

[188] corinna cort and daryl pregibon. signature-bas method for data streams. 

data mine and knowledg discovery, 5(3):167–182, 2001. 

[189] haixun wang, wei fan, philip S yu, and jiawei han. mine concept-drift 

data stream use ensembl classifiers. In proceed of the ninth acm sigkdd 

intern confer on knowledg discoveri and data mining, page 226–235. 

acm, 2003. 

[190] ewt ngai, yong hu, YH wong, yijun chen, and xin sun. the applic of 

data mine techniqu in financi fraud detection: A classif framework and 

an academ review of literature. decis support systems, 50(3):559–569, 2011. 

[191] sushmito ghosh and dougla L reilly. credit card fraud detect with a neural- 

network. In system sciences, 1994. proceed of the twenty-seventh hawaii 

intern confer on, volum 3, page 621–630. ieee, 1994. 

[192] emin aleskerov, bernd freisleben, and bharat rao. cardwatch: A neural network 

base databas mine system for credit card fraud detection. In comput 

intellig for financi engin (cifer), 1997., proceed of the ieee/i- 

afe 1997, page 220–226. ieee, 1997. 

[193] j.r. dorronsoro, F. ginel, C. sgnchez, and CS cruz. neural fraud detect in 

credit card operations. neural networks, 8(4):827–834, 1997. 

[194] D. sánchez, MA vila, L. cerda, and JM serrano. associ rule appli to 

credit card fraud detection. expert system with applications, 36(2):3630–3640, 

2009. 

[195] tian-shyug lee, chih-chou chiu, yu-chao chou, and chi-ji lu. mine the 

custom credit use classif and regress tree and multivari adapt 

regress splines. comput statist & data analysis, 50(4):1113–1130, 

2006. 

[196] krishna M gopinathan, loui S biafore, william M ferguson, michael A lazarus, 

anu K pathria, and allen jost. fraud detect use predict modeling, octo- 

ber 6 1998. US patent 5,819,226. 

[197] B fryer. visa crack down on fraud. informationweek, 594:87, 1996. 

[198] P. viola and M. jones. fast and robust classif use asymmetr adaboost 

and a detector cascade. advanc in neural inform process system, 14, 

2001. 



bibliographi 177 

[199] K. ting. An empir studi of metacost use boost algorithms. machin 

learning: ecml 2000, page 413–425, 2000. 

[200] g.k.j. shawe-taylor. optim classifi for imbalanc train sets. advanc 

in neural inform process system 11, 11:253, 1999. 

[201] andrew fast, lisa friedland, marc maier, brian taylor, david jensen, henri G 

goldberg, and john komoroske. relat data pre-process techniqu for 

improv secur fraud detection. In proceed of the 13th acm sigkdd 

intern confer on knowledg discoveri and data mining, page 941–949. 

acm, 2007. 

[202] yufeng kou, chang-tien lu, sirirat sirwongwattana, and yo-p huang. survey 

of fraud detect techniques. In networking, sens and control, 2004 ieee 

intern confer on, volum 2, page 749–754. ieee, 2004. 

[203] clifton phua, vincent lee, kate smith, and ross gayler. A comprehens survey 

of data mining-bas fraud detect research. arxiv preprint arxiv:1009.6119, 

2010. 

[204] vladimir zaslavski and anna strizhak. credit card fraud detect use self- 

organ maps. inform and security, 18:48, 2006. 

[205] dominik olszewski. fraud detect use self-organ map visual the user 

profiles. knowledge-bas systems, 70:324–334, 2014. 

[206] f.e. grubbs. procedur for detect outli observ in samples. techno- 

metrics, 11(1):1–21, 1969. 

[207] V. barnett and T. lewis. outlier in statist data. wiley seri in probabl 

and mathemat statistics. appli probabl and statistics, chichester: wiley, 

1984, 2nd ed., 1, 1984. 

[208] longin jan latecki, aleksandar lazarevic, and dragoljub pokrajac. outlier de- 

tection with kernel densiti functions. In machin learn and data mine in 

pattern recognition, page 61–75. springer, 2007. 

[209] feng jiang, yuefei sui, and cungen cao. outlier detect base on rough mem- 

bership function. In rough set and current trend in computing, page 388–397. 

springer, 2006. 

[210] michael H cahill, dian lambert, jost C pinheiro, and don X sun. detect 

fraud in the real world. comput reviews, 45(7):447, 2004. 



bibliographi 178 

[211] charu C aggarw and philip S yu. outlier detect for high dimension data. 

In acm sigmod record, volum 30, page 37–46. acm, 2001. 

[212] zengyou he, shengchun deng, and xiaofei xu. An optim model for outlier 

detect in categor data. In advanc in intellig computing, page 400–409. 

springer, 2005. 

[213] andrea dal pozzolo, olivi caelen, and gianluca bontempi. when be under- 

sampl effect in unbalanc classif tasks? In machin learn and 

knowledg discoveri in databases. springer, 2015. 

[214] jerzi stefanowski. overlapping, rare exampl and class decomposit in learn 

classifi from imbalanc data. In emerg paradigm in machin learning, 

page 277–306. springer, 2013. 

[215] gustavo eapa batista, ronaldo C prati, and maria C monard. balanc strate- 

gy and class overlapping. In advanc in intellig data analysi vi, page 

24–35. springer, 2005. 

[216] vicent garcía, jose sánchez, and ramon mollineda. An empir studi of the 

behavior of classifi on imbalanc and overlap data sets. In progress in 

pattern recognition, imag analysi and applications, page 397–406. springer, 

2007. 

[217] vicent garcía, ramón alberto mollineda, and josé salvador sánchez. On the 

k-nn perform in a challeng scenario of imbal and overlapping. pattern 

analysi and applications, 11(3-4):269–280, 2008. 

[218] jason van huls and taghi khoshgoftaar. knowledg discoveri from imbalanc 

and noisi data. data & knowledg engineering, 68(12):1513–1542, 2009. 

[219] D anyfantis, M karagiannopoulos, S kotsiantis, and P pintelas. robust 

of learn techniqu in handl class nois in imbalanc datasets. In artifi- 

cial intellig and innov 2007: from theori to applications, page 21–28. 

springer, 2007. 

[220] damien brain and geoffrey I webb. the need for low bia algorithm in classifi- 

cation learn from larg data sets. In principl of data mine and knowledg 

discovery, page 62–73. springer, 2002. 

[221] HO hartley and A ross. unbias ratio estimators. 1954. 

[222] andi liaw and matthew wiener. classif and regress by randomforest. 

R news, 2(3):18–22, 2002. url http://cran.r-project.org/doc/rnews/. 

http://cran.r-project.org/doc/rnews/ 


bibliographi 179 

[223] alexandro karatzoglou, alex smola, kurt hornik, and achim zeileis. kernlab-an 

s4 packag for kernel method in r. 2004. 

[224] jarek tuszynski. catools: tools: move window statistics, gif, base64, roc 

auc, etc., 2013. url http://cran.r-project.org/package=catools. R pack- 

age version 1.16. 

[225] david H wolpert. the lack of a priori distinct between learn algorithms. 

neural computation, 8(7):1341–1390, 1996. 

[226] david H wolpert and william G macready. No free lunch theorem for optimiza- 

tion. evolutionari computation, ieee transact on, 1(1):67–82, 1997. 

[227] O. maron and a.w. moore. hoeffd races: acceler model select search 

for classif and function approximation. robot institute, page 263, 1993. 

[228] david meyer, evgenia dimitriadou, kurt hornik, andrea weingessel, and 

friedrich leisch. e1071: misc function of the depart of statist (e1071), 

TU wien, 2012. url http://cran.r-project.org/package=e1071. R packag 

version 1.6-1. 

[229] terri therneau, beth atkinson, and brian ripley. rpart: recurs partit 

and regress trees, 2014. url http://cran.r-project.org/package=rpart. 

R packag version 4.1-5. 

[230] david A cieslak, T ryan hoens, nitesh V chawla, and W philip kegelmeyer. 

helling distanc decis tree be robust and skew-insensitive. data mine and 

knowledg discovery, 24(1):136–158, 2012. 

[231] W. N. venabl and B. D. ripley. modern appli statist with S. springer, new 

york, fourth edition, 2002. url http://www.stats.ox.ac.uk/pub/mass4. isbn 

0-387-95457-0. 

[232] milton friedman. the use of rank to avoid the assumpt of normal implicit 

in the analysi of variance. journal of the american statist association, 32 

(200):675–701, 1937. 

[233] C radhakrishna rao. A review of canon coordin and an altern to 

correspond analysi use helling distance. questiió: quadern d’estadística, 

sistemes, informatica i investigació operativa, 19(1):23–63, 1995. 

[234] david A cieslak and nitesh V chawla. detect fractur in classifi perfor- 

mance. In data mining, 2007. icdm 2007. seventh ieee intern confer- 

enc on, page 123–132. ieee, 2007. 

http://cran.r-project.org/package=catool 
http://cran.r-project.org/package=e1071 
http://cran.r-project.org/package=rpart 
http://www.stats.ox.ac.uk/pub/mass4 


bibliographi 180 

[235] foster provost and pedro domingos. tree induct for probability-bas ranking. 

machin learning, 52(3):199–215, 2003. 

[236] T ryan hoens, nitesh V chawla, and robi polikar. heurist updat weight 

random subspac for non-stationari environments. In data mine (icdm), 2011 

ieee 11th intern confer on, page 241–250. ieee, 2011. 

[237] mark hall, eib frank, geoffrey holmes, bernhard pfahringer, peter reutemann, 

and ian H witten. the weka data mine software: an update. acm sigkdd 

explor newsletter, 11(1):10–18, 2009. 

[238] albert bifet, geoff holmes, richard kirkby, and bernhard pfahringer. moa: mas- 

sive onlin analysis. the journal of machin learn research, 99:1601–1604, 

2010. 

[239] georg krempl and vera hofer. classif in presenc of drift and latency. In 

data mine workshop (icdmw), 2011 ieee 11th intern confer on, 

page 596–603. ieee, 2011. 

[240] wei fan. systemat data select to mine concept-drift data streams. In 

proceed of the tenth acm sigkdd intern confer on knowledg 

discoveri and data mining, page 128–137. acm, 2004. 

[241] janez demšar. statist comparison of classifi over multipl data sets. the 

journal of machin learn research, 7:1–30, 2006. 

[242] wei fan and ian davidson. On sampl select bia and it effici correct via 

model averag and unlabel examples. In sdm, page 320–331. siam, 2007. 

[243] torsten hothorn, peter bühlmann, sandrin dudoit, annett molinaro, and 

mark J van der laan. surviv ensembles. biostatistics, 7(3):355–373, 2006. 

[244] hothorn torsten, hornik kurt, and achim zeilei carolin, strobl and. party: A 

laboratori for recurs partytioning., 2015. url http://cran.r-project.org/ 

package=party. R packag version 1.0-13. 

[245] gill louppe. understand random forests: from theori to practice. arxiv 

preprint arxiv:1407.7502, 2014. 

[246] burr settles. activ learn literatur survey. univers of wisconsin, madison, 

52:55–66, 2010. 

[247] DJ hand, C whitrow, NM adams, P juszczak, and D weston. perform 

criterion for plastic card fraud detect tools. journal of the oper research 

society, 59(7):956–962, 2008. 

http://cran.r-project.org/package=parti 
http://cran.r-project.org/package=parti 


bibliographi 181 

[248] bertrand lebichot, ilkka kivimaki, kevin françoisse, and marco saerens. semisu- 

pervis classif through the bag-of-path group betweenness. neural net- 

work and learn systems, ieee transact on, 25(6):1173–1186, 2014. 


declar of authorship 
abstract 
résumé 
acknowledg 
list of figur 
list of tabl 
list of acronym 
I overview 
1 introduct 
1.1 the problem of fraud detect 
1.2 the impact of fraud 
1.3 credit card fraud detect 
1.4 challeng in data driven fraud detect system 
1.5 contribut 
1.5.1 understand sampl method 
1.5.2 learn from evolv and unbalanc data stream 
1.5.3 formal of a real-world fraud detect system 
1.5.4 softwar and credit card fraud detect dataset 

1.6 public and research activ 
1.7 financi support and project object 
1.8 outlin 
1.9 notat 

2 preliminari 
2.1 machin learn 
2.1.1 formal of supervis learn 
2.1.2 the problem of classif 
2.1.3 bias-vari decomposit 
2.1.4 evalu of a classif problem 

2.2 credit card fraud detect 
2.2.1 fraud detect system work condit 
2.2.1.1 fd layers: 
2.2.1.2 supervis inform 
2.2.1.3 system updat 

2.2.2 featur augment 
2.2.3 accuraci measur of a fraud detect system 


3 state-of-the-art 
3.1 techniqu for unbalanc classif task 
3.1.1 data level method 
3.1.2 algorithm level method 

3.2 learn with non-stationar 
3.2.1 sampl select bia 
3.2.2 time evolv data 

3.3 learn with evolv and unbalanc data stream 
3.4 algorithm solut for fraud detect 
3.4.1 supervis approach 
3.4.2 unsupervis approach 



II contribut 
4 techniqu for unbalanc classif task 
4.1 when be undersampl effect in unbalanc classif tasks? 
4.1.1 the warp effect of undersampl on the posterior probabl 
4.1.2 warp and class separ 
4.1.3 the interact between warp and varianc of the estim 
4.1.4 experiment valid 
4.1.5 discuss 

4.2 use calibr probabl with undersampl 
4.2.1 adjust posterior probabl to new prior 
4.2.2 warp correct and classif threshold adjust 
4.2.3 experiment result 
4.2.4 discuss 

4.3 race for sampl method select 
4.3.1 race for strategi select 
4.3.2 experiment result 
4.3.3 discuss 

4.4 conclus 

5 learn from evolv data stream with skew distribut 
5.1 learn strategi in credit card fraud detect 
5.1.1 formal of the learn problem 
5.1.2 strategi for learn with unbalanc and evolv data stream 
5.1.3 experiment assess 
5.1.4 discuss 

5.2 use hddt to avoid instanc propag 
5.2.1 helling distanc decis tree 
5.2.2 helling distanc a weight ensembl strategi 
5.2.3 experiment assess 
5.2.4 discuss 

5.3 conclus 

6 A real-world fraud detect systems: concept drift adapt with alert-feedback interact 
6.1 realist work condit 
6.2 fraud detect with alert-feedback interact 
6.3 learn strategi 
6.3.1 convent classif approach in fd 
6.3.2 separ delay supervis sampl from feedback 
6.3.3 two specif fdss base on random forest 

6.4 select bia and alert-feedback interact 
6.5 experi 
6.5.1 separ feedback from delay supervis sampl 
6.5.2 artifici dataset with concept drift 
6.5.3 improv the perform of the feedback classifi 
6.5.4 standard accuraci measur and classifi ignor afi 
6.5.5 adapt aggreg 
6.5.6 final strategi select and classif model analysi 

6.6 discuss 
6.7 conclus 

7 conclus and futur perspect 
7.1 summari of contribut 
7.2 learn lesson 
7.3 open issu 
7.4 the future: go toward big data solut 
7.5 ad valu for the compani 
7.6 conclud remark 

A the unbalanc packag 
a.1 method for unbalanc classif 
a.2 race for strategi select 
a.3 summari 

B fd softwar modul 
b.1 model train 
b.2 score 
b.3 review 

C bia and varianc of an estim 
bibliographi 


