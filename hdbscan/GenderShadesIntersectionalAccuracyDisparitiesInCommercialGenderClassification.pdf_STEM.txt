


















































proceed of machin learn research 81:1–15, 2018 confer on fairness, accountability, and transpar 

gender shades: intersect accuraci dispar in 
commerci gender classification∗ 

joy buolamwini joyab@mit.edu 
mit media lab 75 amherst st. cambridge, MA 02139 

timnit gebru timnit.gebru@microsoft.com 
microsoft research 641 avenu of the americas, new york, NY 10011 

editors: sorel A. friedler and christo wilson 

abstract 
recent studi demonstr that machin 
learn algorithm can discrimin base 
on class like race and gender. In thi 
work, we present an approach to evalu 
bia present in autom facial analysi al- 
gorithm and dataset with respect to phe- 
notyp subgroups. use the dermatolo- 
gist approv fitzpatrick skin type clas- 
sific system, we character the gen- 
der and skin type distribut of two facial 
analysi benchmarks, ijb-a and adience. 
We find that these dataset be overwhelm- 
ingli compos of lighter-skin subject 
(79.6% for ijb-a and 86.2% for adience) 
and introduc a new facial analysi dataset 
which be balanc by gender and skin type. 
We evalu 3 commerci gender clas- 
sific system use our dataset and 
show that darker-skin femal be the 
most misclassifi group (with error rate 
of up to 34.7%). the maximum error rate 
for lighter-skin male be 0.8%. the 
substanti dispar in the accuraci of 
classifi darker females, lighter females, 
darker males, and lighter male in gender 
classif system requir urgent atten- 
tion if commerci compani be to build 
genuin fair, transpar and account 
facial analysi algorithms. 

keywords: comput vision, algorith- 
mic audit, gender classif 

1. introduct 

artifici intellig (ai) be rapidli infiltr 
everi aspect of society. from help determin 

∗ download our gender and skin type balanc ppb 
dataset at gendershades.org 

who be hired, fired, grant a loan, or how long 
an individu spend in prison, decis that 
have tradit be perform by human be 
rapidli make by algorithm (o’neil, 2017; citron 
and pasquale, 2014). even ai-bas technolog 
that be not specif train to perform high- 
stake task (such a determin how long some- 
one spend in prison) can be use in a pipelin 
that perform such tasks. for example, while 
face recognit softwar by itself should not be 
train to determin the fate of an individu in 
the crimin justic system, it be veri like that 
such softwar be use to identifi suspects. thus, 
an error in the output of a face recognit algo- 
rithm use a input for other task can have se- 
riou consequences. for example, someon could 
be wrong accus of a crime base on erro- 
neou but confid misidentif of the per- 
petrat from secur video footag analysis. 

mani AI systems, e.g. face recognit tools, 
reli on machin learn algorithm that be 
train with label data. It have recent 
be show that algorithm train with bia 
data have result in algorithm discrimin 
(bolukbasi et al., 2016; caliskan et al., 2017). 
bolukbasi et al. even show that the popular 
word emb space, word2vec, encod soci- 
etal gender biases. the author use word2vec 
to train an analog gener that fill in miss- 
ing word in analogies. the analog man be to 
comput programm a woman be to “x” be 
complet with “homemaker”, conform to the 
stereotyp that program be associ with 
men and homemak with women. the bia 
in word2vec be thu like to be propag 
throughout ani system that us thi embedding. 

c© 2018 J. buolamwini & T. gebru. 

gendershades.org 


gender shade 

although mani work have studi how to 
creat fairer algorithms, and benchmark dis- 
crimin in variou context (kilbertu et al., 
2017; hardt et al., 2016b,a), onli a hand of 
work have do thi analysi for comput vi- 
sion. however, comput vision system with 
inferior perform across demograph can 
have seriou implications. esteva et al. show 
that simpl convolut neural network can be 
train to detect melanoma from images, with ac- 
curaci a high a expert (esteva et al., 2017). 
however, without a dataset that have label for 
variou skin characterist such a color, thick- 
ness, and the amount of hair, one cannot measur 
the accuraci of such autom skin cancer de- 
tection system for individu with differ skin 
types. similar to the well document detrimen- 
tal effect of bia clinic trial (popejoy and 
fullerton, 2016; melloni et al., 2010), bia sam- 
ple in AI for health care can result in treatment 
that do not work well for mani segment of the 
population. 

In other contexts, a demograph group that 
be underrepres in benchmark dataset can 
nonetheless be subject to frequent targeting. 
the use of autom face recognit by law 
enforc provid such an example. At least 
117 million american be includ in law en- 
forcement face recognit networks. A year- 
long research investig across 100 polic de- 
partment reveal that african-american indi- 
vidual be more like to be stop by law 
enforc and be subject to face recogni- 
tion search than individu of other ethnici- 
tie (garvi et al., 2016). fals posit and un- 
warrant search pose a threat to civil liberties. 
some face recognit system have be show 
to misidentifi peopl of color, women, and young 
peopl at high rate (klare et al., 2012). moni- 
tore phenotyp and demograph accuraci of 
these system a well a their use be necessari to 
protect citizens’ right and keep vendor and law 
enforc account to the public. 

We take a step in thi direct by make two 
contributions. first, our work advanc gender 
classif benchmark by introduc a new 
face dataset compos of 1270 uniqu individu- 
al that be more phenotyp balanc on the 
basi of skin type than exist benchmarks. To 
our knowledg thi be the first gender classifica- 
tion benchmark label by the fitzpatrick (tb, 

1988) six-point skin type scale, allow u to 
benchmark the perform of gender classifica- 
tion algorithm by skin type. second, thi work 
introduc the first intersect demograph 
and phenotyp evalu of face-bas gender 
classif accuracy. instead of evalu ac- 
curaci by gender or skin type alone, accuraci 
be also examin on 4 intersect subgroups: 
darker females, darker males, lighter females, and 
lighter males. the 3 evalu commerci gen- 
der classifi have the low accuraci on darker 
females. sinc comput vision technolog be be- 
ing util in high-stak sector such a health- 
care and law enforcement, more work need to 
be do in benchmark vision algorithm for 
variou demograph and phenotyp groups. 

2. relat work 

autom facial analysis. autom fa- 
cial imag analysi describ a rang of face per- 
ception task including, but not limit to, face 
detect (zafeiri et al., 2015; mathia et al., 
2014; bai and ghanem, 2017), face classifica- 
tion (reid et al., 2013; levi and hassner, 2015a; 
roth et al., 2016) and face recognit (parkhi 
et al., 2015; wen et al., 2016; ranjan et al., 2017). 
face recognit softwar be now built into most 
smart phone and compani such a google, 
ibm, microsoft and face++ have releas com- 
mercial softwar that perform autom facial 
analysi (ibm; microsoft; face++; google). 

A number of work have go further than 
sole perform task like face detection, recog- 
nition and classif that be easi for human 
to perform. for example, compani such a af- 
fectiva (affectiva) and research in academia 
attempt to identifi emot from imag of peo- 
ple’ face (dehghan et al., 2017; srinivasan et al., 
2016; fabian benitez-quiroz et al., 2016). some 
work have also use autom facial analysi 
to understand and help those with autism (leo 
et al., 2015; palestra et al., 2016). controversi 
paper such a (kosinski and wang, 2017) claim 
to determin the sexual of caucasian male 
whose profil pictur be on facebook or date 
sites. and other such a (wu and zhang, 2016) 
and isra base compani facept (faception) 
have develop softwar that purport to deter- 
mine an individual’ characterist (e.g. propen- 
siti toward crime, iq, terrorism) sole from 

2 



gender shade 

their faces. the client of such softwar includ 
governments. An articl by (aguera Y arca et 
al., 2017) detail the danger and error propa- 
gate by some of these aforement works. 

face detect and classif algorithm 
be also use by us-bas law enforc for 
surveil and crime prevent purposes. In 
“the perpetu lineup”, garvi and colleagu 
provid an in-depth analysi of the unregul 
polic use of face recognit and call for rigor 
standard of autom facial analysis, racial ac- 
curaci testing, and regularli inform the pub- 
lic about the use of such technolog (garvi 
et al., 2016). past research have also show that 
the accuraci of face recognit system use 
by us-bas law enforc be systemat 
low for peopl label female, black, or be- 
tween the age of 18—30 than for other demo- 
graphic cohort (klare et al., 2012). the late 
gender classif report from the nation in- 
stitut for standard and technolog (nist) also 
show that algorithm nist evalu perform 
bad for female-label face than male-label 
face (ngan et al., 2015). 

the lack of dataset that be label by eth- 
niciti limit the generaliz of research ex- 
plore the impact of ethnic on gender classi- 
ficat accuracy. while the nist gender report 
explor the impact of ethnic on gender classi- 
ficat through the use of an ethnic proxi (coun- 
tri of origin), none of the 10 locat use in 
the studi be in africa or the caribbean where 
there be signific black populations. On the 
other hand, farinella and dugelay claim that 
ethnic have no effect on gender classification, 
but they use a binari ethnic categor 
scheme: caucasian and non-caucasian (farinella 
and dugelay, 2012). To address the underrepre- 
sentat of peopl of african-desc in previ- 
ou studies, our work explor gender classifica- 
tion on african face to further scholarship on 
the impact of phenotyp on gender classification. 

benchmarks. most large-scal attempt to 
collect visual face dataset reli on face de- 
tection algorithm to first detect face (huang 
et al., 2007; kemelmacher-shlizerman et al., 
2016). megaface, which to date be the larg 
publicli avail set of facial images, be com- 
pose util head hunter (mathia et al., 
2014) to select one million imag from the yahoo 
flicker 100m imag dataset (thome et al., 2015; 

kemelmacher-shlizerman et al., 2016). ani sys- 
temat error found in face detector will in- 
evit affect the composit of the bench- 
mark. some dataset collect in thi manner 
have alreadi be document to contain signif- 
icant demograph bias. for example, lfw, a 
dataset compos of celebr face which have 
serv a a gold standard benchmark for face 
recognition, be estim to be 77.5% male and 
83.5% white (han and jain, 2014). although 
(taigman et al., 2014)’ face recognit system 
recent report 97.35% accuraci on the lfw 
dataset, it perform be not broken down by 
race or gender. given these skew in the lfw 
dataset, it be not clear that the high report ac- 
curaci be applic to peopl who be not well 
repres in the lfw benchmark. In respons 
to these limitations, intellig advanc re- 
search project activ (iarpa) releas the 
ijb-a dataset a the most geograph divers 
set of collect face (klare et al., 2015). In 
order to limit bias, no face detector be use 
to select imag contain faces. In compari- 
son to face recognition, less work have be do 
to benchmark perform on gender classifica- 
tion. In 2015, the adienc gender and age classi- 
ficat benchmark be releas (levi and has- 
sner, 2015b). As of 2017, the nation insti- 
tute of standard and technolog be start an- 
other challeng to spur improv in face gen- 
der classif by expand on the 2014-15 
study. 

3. intersect benchmark 

An evalu of gender classif perfor- 
manc current requir reduc the construct 
of gender into defin classes. In thi work we use 
the sex label of “male” and “female” to defin 
gender class sinc the evalu benchmark 
and classif system use these binari labels. 
An intersect evalu further requir a 
dataset repres the defin gender with a 
rang of phenotyp that enabl subgroup accu- 
raci analysis. To ass the suitabl of exist- 
ing dataset for intersect benchmarking, we 
provid skin type annot for uniqu sub- 
ject within two select datasets, and compar 
the distribut of darker females, darker males, 
lighter females, and lighter males. due to phe- 
notyp imbal in exist benchmarks, we 

3 



gender shade 

figur 1: exampl imag and averag face from the new pilot parliament benchmark (ppb). As 
the exampl show, the imag be constrain with rel littl variat in pose. the 
subject be compos of male and femal parliamentarian from 6 countries. On average, 
senegales subject be the darkest skin while those from finland and iceland be the 
light skinned. 

creat a new dataset with more balanc skin 
type and gender representations. 

3.1. rational for phenotyp label 

though demograph label for protect class 
like race and ethnic have be use for per- 
form algorithm audit (friedler et al., 2016; 
angwin et al., 2016) and assess dataset diver- 
siti (han and jain, 2014), phenotyp label be 
seldom use for these purposes. while race la- 
bel be suitabl for assess potenti algorith- 
mic discrimin in some form of data (e.g. 
those use to predict crimin recidiv rates), 
they face two key limit when use on visual 
images. first, subjects’ phenotyp featur can 
vari wide within a racial or ethnic category. 
for example, the skin type of individu iden- 
tifi a black in the US can repres mani 
hues. thus, facial analysi benchmark consist- 
ing of lighter-skin black individu would not 
adequ repres darker-skin ones. sec- 
ond, racial and ethnic categori be not consis- 

tent across geographies: even within countri 
these categori chang over time. 

sinc race and ethnic label be unstable, we 
decid to use skin type a a more visual pre- 
cise label to measur dataset diversity. skin type 
be one phenotyp attribut that can be use to 
more object character dataset along with 
eye and nose shapes. furthermore, skin type be 
chosen a a phenotyp factor of interest becaus 
default camera set be calibr to expos 
lighter-skin individu (roth, 2009). poorli 
expos imag that result from sensor optimiza- 
tion for lighter-skin subject or poor illumi- 
nation can prove challeng for autom facial 
analysis. By label face with skin type, we 
can increas our understand of perform 
on thi import phenotyp attribute. 

3.2. exist benchmark select 
rational 

ijb-a be a US govern benchmark releas 
by the nation institut of standard and tech- 

4 



gender shade 

lightestdarkest 

180o 120o 60o 0o 60o 120o 180o 

60o 

0o 

30o 

60o 

30o 

figur 2: the global distribut of skin color. most african have darker skin while those from 
nordic countri be lighter-skinned. imag from (encyclopedia britannica) c©copyright 
2012 encyclopedia britannica. 

nolog (nist) in 2015. We chose to evalu thi 
dataset give the government’ involv and 
the explicit develop of the benchmark to be 
geograph divers (a mention in sec. 2). 
At the time of assess in april and may of 
2017, the dataset consist of 500 uniqu sub- 
ject who be public figures. one imag of each 
uniqu subject be manual label with one of 
six fitzpatrick skin type (tb, 1988). 

adienc be a gender classif benchmark 
releas in 2014 and be select due to it re- 
cenci and unconstrain nature. the adienc 
benchmark contain 2, 284 uniqu individu sub- 
jects. 2, 194 of those subject have refer im- 
age that be discern enough to be label 
by skin type and gender. like the ijb-a dataset, 
onli one imag of each subject be label for 
skin type. 

3.3. creation of pilot parliament 
benchmark 

preliminari analysi of the ijb-a and adi- 
enc benchmark reveal overrepresent of 
lighter males, underrepresent of darker fe- 
males, and underrepresent of darker indi- 
vidual in general. We develop the pilot par- 
liament benchmark (ppb) to achiev good in- 
tersect represent on the basi of gender 
and skin type. ppb consist of 1270 individu 

from three african countri (rwanda, senegal, 
south africa) and three european countri (ice- 
land, finland, sweden) select for gender pariti 
in the nation parliaments. 

properti ppb ijb-a adienc 

releas year 2017 2015 2014 
#subject 1270 500 2284 
avg. ipd 63 pixel - - 
bbox size 141 (avg) ≥36 - 
IM width 160-590 - 816 
IM height 213-886 - 816 

tabl 1: variou imag characterist of the pi- 
lot parliament benchmark compar 
with prior datasets. #subject denot 
the number of uniqu subjects, the aver- 
age bound box size be give in pixels, 
and IM stand for image. 

figur 1 show exampl imag from ppb a 
well a averag face of male and femal in 
each countri repres in the datasets. We 
decid to use imag of parliamentarian sinc 
they be public figur with know ident and 
photo avail under non-restrict licens 
post on govern websites. To add skin 

5 



gender shade 

type divers to the dataset, we chose parlia- 
mentarian from african and european coun- 
tries. fig. 2 show an approxim distribu- 
tion of averag skin type around the world. As 
see in the map, african countri typic have 
darker-skin individu wherea nordic coun- 
tri tend to have lighter-skin citizens. col- 
oniz and migrat pattern nonetheless in- 
fluenc the phenotyp distribut of skin type 
and not all african be darker-skinned. simi- 
larly, not all citizen of nordic countri can be 
classifi a lighter-skinned. 

the specif african and european countri 
be select base on their rank for gen- 
der pariti a assess by the inter parliamen- 
tari union (inter parliamentari union rank- 
ing). Of all the countri in the world, rwanda 
have the high proport of woman in parlia- 
ment. nordic countri be also well repres 
in the top 10 nations. given the gender pariti 
and preval of lighter skin in the region, ice- 
land, finland, and sweden be chosen. To bal- 
anc for darker skin, the next two highest-rank 
african nations, seneg and south africa, be 
also added. 

tabl 1 compar imag characterist of ppb 
with ijb-a and adience. ppb be highli con- 
strain sinc it be compos of offici profil 
photo of parliamentarians. these profil photo 
be take under condit with cooper sub- 
ject where pose be rel fixed, illumin be 
constant, and express be neutral or smiling. 
conversely, the imag in the ijb-a and adi- 
enc benchmark be unconstrain and subject 
pose, illumination, and express by construc- 
tion have more variation. 

3.4. intersect label methodolog 

skin type labels. We chose the fitzpatrick 
six-point label system to determin skin type 
label give it scientif origins. dermatologist 
use thi scale a the gold standard for skin classi- 
ficat and determin risk for skin cancer (tb, 
1988). 

the six-point fitzpatrick classif system 
which label skin a type I to type VI be skew 
toward lighter skin and have three categori that 
can be appli to peopl perceiv a white (fig- 
ure 2). yet when it come to fulli repres 
the sepia spectrum that character the rest of 

ppb 

ijb-a 

adienc 

0% 25% 50% 75% 100% 

30.323.325.021.3 

4.4 16.0 20.2 59.4 

7.4 6.4 44.6 41.6 %darker femal 

%darker male 

%lighter femal 

%ligher male 

figur 3: the percentag of darker female, 
lighter female, darker male, and lighter 
male subject in ppb, ijb-a and adi- 
ence. onli 4.4% of subject in adienc 
be darker-skin and femal in com- 
parison to 21.3% in ppb. 

the world, the categor be fairli coarse. 
nonetheless, the scale provid a scientif 
base start point for audit algorithm and 
dataset by skin type. 

gender labels. all evalu compani 
provid a “gender classification” featur that 
us the binari sex label of femal and male. 
thi reductionist view of gender do not ade- 
quat captur the complex of gender or ad- 
dress transgend identities. the compani pro- 
vide no document to clarifi if their gender 
classif system which provid sex label be 
classifi gender ident or biolog sex. To 
label the ppb data, we use femal and male la- 
bel to indic subject perceiv a woman or 
men respectively. 

label process. for exist benchmarks, 
one author label each imag with one of six 
fitzpatrick skin type and provid gender an- 
notat for the ijb-a dataset. the adienc 
benchmark be alreadi annot for gender. 
these preliminari skin type annot on ex- 
ist dataset be use to determin if a new 
benchmark be needed. 

more annot resourc be use to label 
ppb. for the new parliamentarian benchmark, 
3 annot includ the author provid gen- 
der and fitzpatrick labels. A board-certifi sur- 
gical dermatologist provid the definit label 
for the fitzpatrick skin type. gender label be 
determin base on the name of the parliamen- 
tarian, gender title, prefix such a Mr or ms, 
and the appear of the photo. 

6 



gender shade 

set n F M darker lighter DF DM LF LM 

all subject 1270 44.6% 55.4% 46.4% 53.6% 21.3% 25.0% 23.3% 30.3% 

africa 661 43.9% 56.1% 86.2% 13.8% 39.8% 46.4% 4.1% 9.7% 

south africa 437 41.4% 58.6% 79.2% 20.8% 35.2% 43.9% 6.2% 14.6% 
seneg 149 43.0% 57.0% 100.0% 0.0% 43.0% 57.0% 0.0% 0.0% 
rwanda 75 60.0% 40.0% 100.0% 0.0% 60.0% 40.0% 0.0% 0.0% 

europ 609 45.5% 54.5% 3.1% 96.9% 1.3% 1.8% 44.2% 52.7% 

sweden 349 46.7% 53.3% 4.9% 95.1% 2.0% 2.9% 44.7% 50.4% 
finland 197 42.6% 57.4% 1.0% 99.0% 0.5% 0.5% 42.1% 56.9% 
iceland 63 47.6% 52.4% 0.0% 100.0% 0.0% 0.0% 47.6% 52.4% 

tabl 2: pilot parliament benchmark decomposit by the total number of femal subject de- 
note a F, total number of male subject (m), total number of darker and lighter subjects, 
a well a femal darker/light (df/lf) and male darker/light subject (dm/lm). the 
group composit be show for all uniqu subjects, africa, europ and the countri in 
our dataset locat in each of these continents. 

dataset lighter (i,ii,iii) darker (iv, V, vi) total 

ppb 53.6% 681 46.4% 589 1270 
ijb-a 79.6% 398 20.4% 102 500 
adienc 86.2% 1892 13.8% 302 2194 

tabl 3: the distribut of lighter and darker-skin subject (accord to the fitzpatrick clas- 
sific system) in ppb, ijb-a, and adienc datasets. adienc have the most skew 
distribut with 86.2% of the subject consist of lighter-skin individu wherea 
ppb be more evenli distribut between lighter (53.6%) and darker (46.4%) subjects. 

3.5. fitzpatrick skin type comparison 

for the purpos of our analysis, lighter subject 
will refer to face with a fitzpatrick skin type 
of i,ii, or iii. darker subject will refer to face 
label with a fitzpatrick skin type of iv,v, or 
vi. We intent choos countri with ma- 
joriti popul at opposit end of the skin 
type scale to make the lighter/dark dichotomi 
more distinct. the skin type be aggreg to 
account for potenti off-by-on error sinc the 
skin type be estim use imag instead of em- 
ploy a standard spectrophotomet and fitz- 
patrick questionnaire. 

tabl 2 present the gender, skin type, and in- 
tersect gender by skin type composit of 
ppb. and figur 3 compar the percentag of 
imag from darker female, darker male, lighter 

femal and lighter male subject from adience, 
ijb-a, and pbb. ppb provid the most bal- 
anc represent of all four group wherea 
ijb-a have the least balanc distribution. 

darker femal be the least repres in 
ijb-a (4.4%) and darker male be the least rep- 
resent in adienc (6.4%). lighter male be the 
most repres uniqu subject in all datasets. 
ijb-a be compos of 59.4% uniqu lighter male 
wherea thi percentag be reduc to 41.6% in 
adienc and 30.3% in ppb. As see in tabl 3, 
adienc have the most skew distribut by skin 
type. 

while all the dataset have more lighter- 
skin uniqu individuals, ppb be around half 
light at 53.6% wherea the proport of lighter- 
skin uniqu subject in ijb-a and adienc 

7 



gender shade 

be 79.6% and 86.2% respectively. ppb provid 
substanti more darker-skin uniqu sub- 
ject than ijb-a and adience. even though adi- 
enc have 2194 label uniqu subjects, which be 
nearli twice that of the 1270 subject in ppb, 
it have 302 darker subjects, nearli half the 589 
darker subject in ppb. overall, ppb have a more 
balanc represent of lighter and darker 
subject a compar to the ijb-a and adienc 
datasets. 

4. commerci gender 
classif audit 

We evalu 3 commerci gender classifiers. 
overall, male subject be more accur clas- 
sifi than femal subject replic previou 
find (ngan et al., 2015), and lighter subject 
be more accur classifi than darker in- 
dividuals. An intersect breakdown reveal 
that all classifi perform bad on darker fe- 
male subjects. 

4.1. key find on evalu 
classifi 

• all classifi perform good on male face 
than femal face (8.1% − 20.6% differ 
in error rate) 

• all classifi perform good on lighter face 
than darker face (11.8% − 19.2% differ 
in error rate) 

• all classifi perform bad on darker femal 
face (20.8% − 34.7% error rate) 

• microsoft and ibm classifi perform best 
on lighter male face (error rate of 0.0% and 
0.3% respectively) 

• face++ classifi perform best on darker 
male face (0.7% error rate) 

• the maximum differ in error rate be- 
tween the best and bad classifi group be 
34.4% 

4.2. commerci gender classifi 
selection: microsoft, ibm, face++ 

We focu on gender classifi sell in api bun- 
dle make avail by microsoft, ibm, and 

face++ (microsoft; ibm; face++). microsoft’ 
cognit servic face api and ibm’ wat- 
son visual recognit api be chosen sinc 
both compani have make larg invest in 
artifici intelligence, captur signific market 
share in the machin learn servic domain, 
and provid public demonstr of their fa- 
cial analysi technology. At the time of evalua- 
tion, googl do not provid a publicli avail 
gender classifier. previou studi have show 
that face recognit system develop in west- 
ern nation and those develop in asian nation 
tend to perform good on their respect popu- 
lation (phillip et al., 2011). face++, a com- 
puter vision compani headquart in china 
with facial analysi technolog previous inte- 
grate with some lenovo computers, be thu 
chosen to see if thi observ hold for gender 
classification. like microsoft and ibm, face++ 
also provid a publicli avail demonstr 
of their gender classif capabl at the 
time of evaluation(april and may 2017). 

all of the compani offer gender classifica- 
tion a a compon of a set of proprietari facial 
analysi api servic (microsoft; ibm; face++). 
the descript of classif methodolog 
lack detail and there be no mention of what 
train data be used. At the time of evaluation, 
microsoft’ face detect servic be describ a 
use advanc statist algorithm that “may 
not alway be 100% precise” (microsoft api ref- 
erence). ibm watson visual recognit and 
face++ servic be say to use deep learning- 
base algorithm (ibm api reference; face++ 
term of service). none of the commerci gen- 
der classifi chosen for thi analysi report 
perform metric on exist gender estima- 
tion benchmark in their provid documenta- 
tion. the face++ term of use explicitli dis- 
claim ani warranti of accuracy. onli ibm 
provid confid score (between 0 and 1) for 
face-bas gender classif labels. but it do 
not report how ani metric like true posit rate 
(tpr) or fals posit rate (fpr) be bal- 
anced. 

4.3. evalu methodolog 

In follow the gender classif evalu 
preced establish by the nation institut 
for standard and technolog (nist), we ass 

8 



gender shade 

classifi metric all F M darker lighter DF DM LF LM 

msft 

ppv(%) 93.7 89.3 97.4 87.1 99.3 79.2 94.0 98.3 100 
error rate(%) 6.3 10.7 2.6 12.9 0.7 20.8 6.0 1.7 0.0 

tpr (%) 93.7 96.5 91.7 87.1 99.3 92.1 83.7 100 98.7 
fpr (%) 6.3 8.3 3.5 12.9 0.7 16.3 7.9 1.3 0.0 

face++ 

ppv(%) 90.0 78.7 99.3 83.5 95.3 65.5 99.3 94.0 99.2 
error rate(%) 10.0 21.3 0.7 16.5 4.7 34.5 0.7 6.0 0.8 

tpr (%) 90.0 98.9 85.1 83.5 95.3 98.8 76.6 98.9 92.9 
fpr (%) 10.0 14.9 1.1 16.5 4.7 23.4 1.2 7.1 1.1 

ibm 

ppv(%) 87.9 79.7 94.4 77.6 96.8 65.3 88.0 92.9 99.7 
error rate(%) 12.1 20.3 5.6 22.4 3.2 34.7 12.0 7.1 0.3 

tpr (%) 87.9 92.1 85.2 77.6 96.8 82.3 74.8 99.6 94.8 
fpr (%) 12.1 14.8 7.9 22.4 3.2 25.2 17.7 5.20 0.4 

tabl 4: gender classif perform a measur by the posit predict valu (ppv), error 
rate (1-ppv), true posit rate (tpr), and fals posit rate (fpr) of the 3 evalu 
commerci classifi on the ppb dataset. all classifi have the high error rate for 
darker-skin femal (rang from 20.8% for microsoft to 34.7% for ibm). 

classifi metric DF DM LF LM 

msft 

ppv(%) 76.2 100 100 100 
error rate(%) 23.8 0.0 0.0 0.0 

tpr(%) 100 84.2 100 100 
fpr(%) 15.8 0.0 0.0 0.0 

face++ 

ppv(%) 64.0 99.5 100 100 
error rate(%) 36.0 0.5 0.0 0.0 

tpr(%) 99.0 77.8 100 96.9 
fpr(%) 22.2 1.03 3.08 0.0 

ibm 

ppv(%) 66.9 94.3 100 98.4 
error rate(%) 33.1 5.7 0.0 1.6 

tpr(%) 90.4 78.0 96.4 100 
fpr(%) 22.0 9.7 0.0 3.6 

tabl 5: gender classif perform a measur by the posit predict valu (ppv), error 
rate (1-ppv), true posit rate (tpr), and fals posit rate (fpr) of the 3 evalu 
commerci classifi on the south african subset of the ppb dataset. result for south 
africa follow the overal trend with the high error rate see on darker-skin females. 

the overal classif accuracy, male classifi- 
cation accuracy, and femal classif accu- 
raci a measur by the posit predict valu 
(ppv). extend beyond the nist methodol- 
ogi we also evalu the true posit rate, fals 
posit rate, and error rate (1-ppv) of the fol- 

low groups: all subjects, male subjects, femal 
subjects, lighter subjects, darker subjects, darker 
females, darker males, lighter females, and lighter 
males. see tabl 2 in supplementari materi 
for result disaggreg by gender and each fitz- 
patrick skin type. 

9 



gender shade 

4.4. audit result 

male and femal error rate 

To conduct a demograph perform analy- 
sis, the differ in male and femal error rate 
for each gender classifi be compar first in 
aggreg (tabl 4) and then for south africa 
(tabl 5). the nist evalu of autom 
gender classif algorithm report reveal 
that gender classif perform on femal 
face be 1.8% to 12.5% low than perform 
on male face for the nine evalu algorithm 
(ngan et al., 2015). the gender misclassifica- 
tion rate on the pilot parliament benchmark 
replic thi trend across all classifiers. the dif- 
ferenc between femal and male classif 
error rate rang from 8.1% to 20.6%. the rela- 
tive high true posit rate for femal indic 
that when a face be predict to be femal the es- 
timat be more like to be correct than when 
a face be predict to be male. for the microsoft 
and ibm classifiers, the fals posit rate (fpr) 
for femal be doubl or more than the fpr for 
males. the fpr for femal be more than 13 
time that of male with the face++ classifier. 

darker and lighter error rate 

To conduct a phenotyp perform analysis, 
the differ in darker and lighter skin type er- 
ror rate for each gender classifi be compar 
first in aggreg (tabl 4) and then for south 
africa (tabl 5). all classifi perform good 
on lighter subject than darker subject in ppb. 
microsoft achiev the best result with error rate 
of 12.9% on darker subject and 0.7% on lighter 
individuals. On darker subjects, ibm achiev 
the bad classif accuraci with an error 
rate of 22.4%. thi rate be nearli 7 time high 
than the ibm error rate on lighter faces. 

intersect error rate 

To conduct an intersect demograph and 
phenotyp analysis, the error rate for four inter- 
section group (darker females, darker males, 
lighter femal and lighter males) be compar 
in aggreg and then for south africa. 

across the board, darker femal account for 
the larg proport of misclassifi subjects. 
even though darker femal make up 21.3% of 
the ppb benchmark, they constitut between 

61.0% to 72.4.1% of the classif error. 
lighter male who make up 30.3% of the bench- 
mark contribut onli 0.0% to 2.4% of the total 
error from these classifi (see tabl 1 in sup- 
plementari materials). 

We present a deeper look at imag from south 
africa to see if differ in algorithm per- 
formanc be mainli due to imag qualiti from 
each parliament. In ppb, the european parlia- 
mentari imag tend to be of high resolut 
with less pose variat when compar to imag 
from african parliaments. the south african 
parliament, however, have compar imag res- 
olut and have the larg skin type spread of 
all the parliaments. lighter subject makeup 
20.8% (n=91) of the images, and darker subject 
make up the remain 79.2% (n=346) of im- 
ages. tabl 5 show that all algorithm perform 
bad on femal and darker subject when com- 
par to their counterpart male and lighter sub- 
jects. the microsoft gender classifi perform 
the best, with zero error on classifi all male 
and lighter females. 

On the south african subset of the ppb bench- 
mark, all the error for microsoft aris from mis- 
classifi imag of darker females. tabl 5 also 
show that all classifi perform bad on darker 
females. face++ be flawless on lighter male and 
lighter females. ibm perform best on lighter fe- 
male with 0.0% error rate. examin classifica- 
tion perform on the south african subset of 
ppb reveal trend that close match the algo- 
rithmic perform on the entir dataset. thus, 
we conclud that variat in perform due 
to the imag characterist of each countri do 
not fulli account for the differ in misclassifi- 
cation rate between intersect subgroups. In 
other words, the presenc of more darker individ- 
ual be a good explan for error rate than a 
deviat in how imag of parliamentarian be 
compos and produced. however, darker skin 
alon may not be fulli respons for misclassi- 
fication. instead, darker skin may be highli cor- 
relat with facial geometri or gender display 
norm that be less repres in the train 
data of the evalu classifiers. 

4.5. analysi of result 

the overal gender classif accuraci result 
show the obfusc natur of singl perfor- 

10 



gender shade 

●●●● 

● 

●●●● 
● 
●●●●● 

● 

●●●●●● 
● 

● 

● 
● 
● 

● 

● 

● 

●●●● ●● 
● 
● 
● 
●● 
●● 

● 

● 

● 

●●●●●●● 

● 

●●●●●●●●●●●●●●●● 

● 

● 

●● 

● 

●●● 
● 
● 
● 
●● 

●● 

● 
●● 
●●● 

● 

● 
● 

● 

●●● 

● 

●●●● 

● 

●●● 

● 

●●● 

● 
● 

● 

● 

● 

● 

● 

●●●● 

● 

● 

●● 

● 

●● 

● 

●● 
● 

●● 

● 

● 

● 

●● 

● 

● 

●● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

● 

●●●● 
●●●● 
●●●●● 
● 

● 

● 
● 

● 

●●●●●●●●●●● 
●●●●●●●●● 

● 

●●●●●●● 

● 

●●●●●●●●●●●●●● 
● 

●●●●●●●●●● 

● 

●●●●●●●●●●●●●● 
●● 

● 

● 

● 

●● 

0.00 

0.25 

0.50 

0.75 

1.00 

darker femal darker male lighter femal lighter male 
group 

C 
on 

fid 
en 

ce 
S 

co 
re 

s 

gender 
femal 

male 

figur 4: gender classif confid score 
from ibm (ibm). score be near 1 for 
lighter male and femal subject while 
they rang from ∼ 0.75 − 1 for darker 
females. 

manc metrics. taken at face value, gender clas- 
sific accuraci rang from 87.9% to 93.7% 
on the ppb dataset, suggest that these classi- 
fier can be use for all popul repres 
by the benchmark. A compani might justifi the 
market readi of a classifi by present per- 
formanc result in aggregate. yet a gender and 
phenotyp breakdown of the result show that 
perform differ substanti for distinct sub- 
groups. classif be 8.1% − 20.6% bad on 
femal than male subject and 11.8% − 19.2% 
bad on darker than lighter subjects. 

though help in see systemat error, gen- 
der and skin type analysi by themselv do not 
present the whole story. Is misclassif dis- 
tribut evenli amongst all females? are there 
other factor at play? likewise, be the misclassi- 
ficat of darker skin uniform across gender? 

the intersect error analysi that target 
gender classif perform on darker fe- 
male, lighter female, darker male, and lighter 
male subgroup provid more answers. darker 
femal have the high error rate for all gender 
classifi rang from 20.8% − 34.7%. for mi- 
crosoft and ibm classifi lighter male be the 
best classifi group with 0.0% and 0.3% error 
rate respectively. face++ classifi darker male 
best with an error rate of 0.7%. when examin 
the gap in lighter and darker skin classification, 
we see that even though darker femal be most 
impacted, darker male be still more misclassi- 
fie than lighter male for ibm and microsoft. 
the most improv be need on darker fe- 
male specifically. more broadly, the error gap 
between male and femal classif along with 
lighter and darker classif should be closed. 

4.6. accuraci metric 

microsoft and face++ api sole output singl 
label indic whether the face be classifi 
a femal or male. ibm’ api output an ad- 
dition number which indic the confid 
with which the classif be made. fig- 
ure 4 plot the distribut of confid valu 
for each of the subgroup we evalu (i.e. darker 
females, darker males, lighter femal and lighter 
males). number near 0 indic low confid 
wherea those close to 1 denot high confid 
in classifi gender. As show in the box plots, 
the api be most confid in classifi lighter 
male and least confid in classifi darker fe- 
males. 

while confid valu give user more in- 
formation, commerci classifi should provid 
addit metrics. all 3 evalu api onli 
provid gender classifications, they do not out- 
put probabl associ with the likelihood 
of be a particular gender. thi indic that 
compani be choos a threshold which deter- 
mine the classification: if the predict proba- 
biliti be great than thi threshold, the imag be 
determin to be that of a male (or female) sub- 
ject, and viceversa if the probabl be less than 
thi number. thi do not give user the abil- 
iti to analyz true posit (tpr) and fals posi- 
tive (fpr) rate for variou subgroup if differ 
threshold be to be chosen. the commerci 
classifi have pick threshold that result in 
specif tpr and fpr rate for each subgroup. 
and the fpr for some group can be much high 
than those for others. By have api that fail 
to provid the abil to adjust these thresholds, 
they be limit users’ abil to pick their own 
tpr/fpr trade-off. 

4.7. data qualiti and sensor 

It be well establish that pose, illumination, and 
express (pie) can impact the accuraci of au- 
tomat facial analysis. techniqu to creat ro- 
bust system that be invari to pose, illumi- 
nation, expression, occlusions, and background 
have receiv substanti attent in comput 
vision research (kakadiari et al., 2017; ganguli 
et al., 2015; ahmad radzi et al., 2014). illumi- 
nation be of particular import when do an 
evalu base on skin type. default camera 
set be often optim to expos lighter skin 

11 



gender shade 

good than darker skin (roth, 2009). underex- 
pose or overexpos imag that present signif- 
icant inform loss can make accur classi- 
ficat challenging. 

with full awar of the challeng that aris 
due to pose and illumination, we intent 
chose an optimist sampl of constrain imag 
that be take from the parliamentarian web- 
sites. each countri have it peculiarities. imag 
from rwanda and seneg have more pose and 
illumin variat than imag from other 
countri (figur 1). the swedish parliamen- 
tarian all have photo that be take with a 
shadow on the face. the south african imag 
have the most consist pose and illumination. 
the south african subset be also compos of 
a substanti number of lighter and darker sub- 
jects. given the divers of the subset, the 
high imag resolution, and the consist of 
illumin and pose, our find that classi- 
ficat accuraci vari by gender, skin type, 
and the intersect of gender with skin type do 
not appear to be confound by the qualiti of 
sensor readings. the dispar present with 
such a constrain dataset do suggest that error 
rate would be high on more challeng uncon- 
strain datasets. futur work should explor 
gender classif on an inclus benchmark 
compos of unconstrain images. 

5. conclus 

We measur the accuraci of 3 commerci gen- 
der classif algorithm on the new pilot 
parliament benchmark which be balanc by 
gender and skin type. We annot the dataset 
with the fitzpatrick skin classif system 
and test gender classif perform on 4 
subgroups: darker females, darker males, lighter 
femal and lighter males. We found that all clas- 
sifier perform best for lighter individu and 
male overall. the classifi perform bad 
for darker females. further work be need to 
see if the substanti error rate gap on the ba- 
si of gender, skin type and intersect sub- 
group reveal in thi studi of gender classifica- 
tion persist in other human-bas comput vi- 
sion tasks. futur work should explor intersec- 
tional error analysi of facial detection, identifi- 
cation and verification. intersect phenotyp 
and demograph error analysi can help inform 

method to improv dataset composition, featur 
selection, and neural network architectures. 

becaus algorithm fair be base on differ- 
ent contextu assumpt and optim for 
accuracy, thi work aim to show whi we need 
rigor report on the perform metric on 
which algorithm fair debat center. the 
work focu on increas phenotyp and demo- 
graphic represent in face dataset and algo- 
rithmic evaluation. inclus benchmark dataset 
and subgroup accuraci report will be necessari 
to increas transpar and account in 
artifici intelligence. for human-cent com- 
puter vision, we defin transpar a provid 
inform on the demograph and phenotyp 
composit of train and benchmark datasets. 
We defin account a report algorith- 
mic perform on demograph and pheno- 
typic subgroup and activ work to close 
perform gap where they arise. algorith- 
mic transpar and account reach be- 
yond technic report and should includ mech- 
anism for consent and redress which we do not 
focu on here. nonetheless, the find from thi 
work concern benchmark represent and 
intersect audit provid empir support 
for increas demograph and phenotyp trans- 
parenc and account in artifici intelli- 
gence. 

acknowledg 

We thank board-certifi surgic dermatologist 
dr. helen raynham for provid the offici 
fitzpatrick annot for the pilot parliament 
benchmark. 

refer 

face++ api. http://old.faceplusplus.com/ 
demo-detect/. accessed: 2017-10-06. 

face, googl api for android, googl de- 
velopers. https://developers.google.com/ 
android/reference/com/google/android/ 

gms/vision/face/face. accessed: 2017-10- 
06. 

watson visual recognition. http : 
//www.ibm.com/watson/services/visual- 
recognition/. accessed: 2017-10-06. 

12 

http://old.faceplusplus.com/demo-detect/ 
http://old.faceplusplus.com/demo-detect/ 
https://developers.google.com/android/reference/com/google/android/gms/vision/face/fac 
https://developers.google.com/android/reference/com/google/android/gms/vision/face/fac 
https://developers.google.com/android/reference/com/google/android/gms/vision/face/fac 
https://www.ibm.com/watson/services/visual-recognition/ 
https://www.ibm.com/watson/services/visual-recognition/ 
https://www.ibm.com/watson/services/visual-recognition/ 


gender shade 

microsoft face api. http : / / 
www.microsoft.com / cognit - servic / 
en-us/faceapi. accessed: 2017-10-06. 

affectiva emot recognit softwar and 
analysis. https://www.affectiva.com/. ac- 
cessed: 2017-10-06. 

physiognomi new clothes. http : / / 
medium.com/@blaisea/physiognomys- new- 
clothes-f2d4b59fdd6a. accessed: 2017-10- 
06. 

face++ term of use. a. accessed: 2018-12-13. 

faception, facial person analytics. https: 
//www.faception.com/, b. accessed: 2017-10- 
06. 

visual recognit api reference. accessed: 
2018-12-13. 

how to detect face in image. accessed: 2018- 
12-13. 

proport of seat held by woman in nation 
parliaments. https://data.worldbank.org/ 
indicator/sg.gen.parl.zs?year high desc= 
true. accessed: 2017-10-06. 

syafeeza ahmad radzi, khalil-hani mohamad, 
shan sung liew, and rabia bakhteri. con- 
volut neural network for face recognit 
with pose and illumin variation. interna- 
tional journal of engin and technolog 
(ijet), 6(1):44–57, 2014. 

julia angwin, jeff larson, surya mattu, and 
lauren kirchner. machin bias: there soft- 
ware use across the countri to predict futur 
criminals. and it bia against blacks. prop- 
ublica, may, 23, 2016. 

yancheng bai and bernard ghanem. multi-scal 
fulli convolut network for face detect 
in the wild. In comput vision and pattern 
recognit workshop (cvprw), 2017 ieee 
confer on, page 2078–2087. ieee, 2017. 

tolga bolukbasi, kai-wei chang, jame Y zou, 
venkatesh saligrama, and adam T kalai. man 
be to comput programm a woman be to 
homemaker? debias word embeddings. In 
D. D. lee, M. sugiyama, U. V. luxburg, 
I. guyon, and R. garnett, editors, advanc 

in neural inform process system 29, 
page 4349–4357. curran associates, inc., 
2016. url http://papers.nips.cc/paper/ 
6228- man- is- to- computer- programmer- 

as- woman- is- to- homemaker- debiasing- 

word-embeddings.pdf. 

encyclopedia britannica. skin distribut map. 
https://media1.britannica.com/eb-media/ 
59/61759- 004- 9a507f1c.gif, 2012. ac- 
cessed: 2017-12-17. 

aylin caliskan, joanna J bryson, and arvind 
narayanan. semant deriv automat 
from languag corpu contain human-lik bi- 
ases. science, 356(6334):183–186, 2017. 

daniel keat citron and frank A pasquale. 
the score society: due process for autom 
predictions. 2014. 

afshin dehghan, enriqu G ortiz, guang shu, 
and sy zain masood. dager: deep age, 
gender and emot recognit use con- 
volut neural network. arxiv preprint 
arxiv:1702.04280, 2017. 

andr esteva, brett kuprel, roberto A novoa, 
justin ko, susan M swetter, helen M blau, 
and sebastian thrun. dermatologist-level clas- 
sific of skin cancer with deep neural net- 
works. nature, 542(7639):115–118, 2017. 

C fabian benitez-quiroz, ramprakash srini- 
vasan, and aleix M martinez. emotionet: An 
accurate, real-tim algorithm for the automat 
annot of a million facial express in the 
wild. In proceed of the ieee confer 
on comput vision and pattern recognition, 
page 5562–5570, 2016. 

giovanna farinella and jean-luc dugelay. de- 
mograph classification: Do gender and eth- 
niciti affect each other? In informatics, elec- 
tronic & vision (iciev), 2012 intern 
confer on, page 383–390. ieee, 2012. 

sorel A friedler, carlo scheidegger, and 
suresh venkatasubramanian. On the (im) 
possibl of fairness. arxiv preprint 
arxiv:1609.07236, 2016. 

13 

https://www.microsoft.com/cognitive-services/en-us/faceapi 
https://www.microsoft.com/cognitive-services/en-us/faceapi 
https://www.microsoft.com/cognitive-services/en-us/faceapi 
https://www.affectiva.com/ 
https://medium.com/@blaisea/physiognomys-new-clothes-f2d4b59fdd6a 
https://medium.com/@blaisea/physiognomys-new-clothes-f2d4b59fdd6a 
https://medium.com/@blaisea/physiognomys-new-clothes-f2d4b59fdd6a 
https://www.faception.com/ 
https://www.faception.com/ 
https://data.worldbank.org/indicator/sg.gen.parl.zs?year_high_desc=tru 
https://data.worldbank.org/indicator/sg.gen.parl.zs?year_high_desc=tru 
https://data.worldbank.org/indicator/sg.gen.parl.zs?year_high_desc=tru 
http://papers.nips.cc/paper/6228-man-is-to-computer-programmer-as-woman-is-to-homemaker-debiasing-word-embeddings.pdf 
http://papers.nips.cc/paper/6228-man-is-to-computer-programmer-as-woman-is-to-homemaker-debiasing-word-embeddings.pdf 
http://papers.nips.cc/paper/6228-man-is-to-computer-programmer-as-woman-is-to-homemaker-debiasing-word-embeddings.pdf 
http://papers.nips.cc/paper/6228-man-is-to-computer-programmer-as-woman-is-to-homemaker-debiasing-word-embeddings.pdf 
https://media1.britannica.com/eb-media/59/61759-004-9a507f1c.gif 
https://media1.britannica.com/eb-media/59/61759-004-9a507f1c.gif 


gender shade 

suranjan ganguly, debotosh bhattacharjee, and 
mita nasipuri. illumination, pose and occlu- 
sion invari face recognit from rang im- 
age use erfi model. intern journal of 
system dynam applic (ijsda), 4(2): 
1–20, 2015. 

clare garvie, alvaro bedoya, and jonathan 
frankle. the perpetu line-up: unregul 
polic face recognit in america. george- 
town law, center on privaci & technology, 
2016. 

Hu han and anil K jain. age, gender and 
race estim from unconstrain face im- 
ages. dept. comput. sci. eng., michigan state 
univ., east lansing, mi, usa, msu tech. 
rep.(msu-cse-14-5), 2014. 

moritz hardt, eric price, nati srebro, et al. 
equal of opportun in supervis learning. 
In advanc in neural inform process 
systems, page 3315–3323, 2016a. 

moritz hardt, eric price, nati srebro, et al. 
equal of opportun in supervis learning. 
In advanc in neural inform process 
systems, page 3315–3323, 2016b. 

gari B huang, manu ramesh, tamara berg, 
and erik learned-miller. label face in the 
wild: A databas for studi face recogni- 
tion in unconstrain environments. technic 
report, technic report 07-49, univers of 
massachusetts, amherst, 2007. 

ioanni A kakadiaris, georg toderici, georgio 
evangelopoulos, georgio passalis, dat chu, 
Xi zhao, shishir K shah, and theohari theo- 
haris. 3d-2d face recognit with pose and 
illumin normalization. comput vision 
and imag understanding, 154:137–151, 2017. 

ira kemelmacher-shlizerman, steven M seitz, 
daniel miller, and evan brossard. the 
megafac benchmark: 1 million face for recog- 
nition at scale. In proceed of the ieee 
confer on comput vision and pattern 
recognition, page 4873–4882, 2016. 

niki kilbertus, mateo rojas-carulla, giambat- 
tista parascandolo, moritz hardt, dominik 
janzing, and bernhard schölkopf. avoid 
discrimin through causal reasoning. arxiv 
preprint arxiv:1706.02744, 2017. 

brendan F klare, mark J burge, joshua C 
klontz, richard W vorder bruegge, and 
anil K jain. face recognit performance: 
role of demograph information. ieee trans- 
action on inform forens and security, 
7(6):1789–1801, 2012. 

brendan F klare, ben klein, emma taborsky, 
austin blanton, jordan cheney, kristen allen, 
patrick grother, alan mah, and anil K jain. 
push the frontier of unconstrain face de- 
tection and recognition: iarpa janu bench- 
mark a. In proceed of the ieee confer 
on comput vision and pattern recognition, 
page 1931–1939, 2015. 

michal kosinski and yilun wang. deep neural 
network be more accur than human at 
detect sexual orient from facial images. 
2017. 

marco leo, marco del coco, pierluigi carcagni, 
cosimo distante, massimo bernava, giovanni 
pioggia, and giusepp palestra. automat 
emot recognit in robot-children interac- 
tion for asd treatment. In proceed of the 
ieee intern confer on comput 
vision workshops, page 145–153, 2015. 

gil levi and tal hassner. age and gender classifi- 
cation use convolut neural networks. In 
proceed of the ieee confer on com- 
puter vision and pattern recognit work- 
shops, page 34–42, 2015a. 

gil levi and tal hassner. age and gender classifi- 
cation use convolut neural networks. In 
proceed of the ieee confer on com- 
puter vision and pattern recognit work- 
shops, page 34–42, 2015b. 

marku mathias, rodrigo benenson, marco ped- 
ersoli, and luc van gool. face detect with- 
out bell and whistles. In european confer 
on comput vision, page 720–735. springer, 
2014. 

chiara melloni, jeffrey S berger, traci Y wang, 
funda gunes, amanda stebbins, karen S 
pieper, rowena J dolor, pamela S douglas, 
daniel B mark, and L kristin newby. repre- 
sentat of woman in random clinic tri- 
al of cardiovascular diseas prevention. circu- 

14 



gender shade 

lation: cardiovascular qualiti and outcomes, 
3(2):135–142, 2010. 

mei ngan, mei ngan, and patrick grother. face 
recognit vendor test (frvt) perform of 
autom gender classif algorithms. US 
depart of commerce, nation institut 
of standard and technology, 2015. 

cathi o’neil. weapon of math destruction: 
how big data increas inequ and threat- 
en democracy. broadway books, 2017. 

giusepp palestra, giovanna varni, moham 
chetouani, and floriana esposito. A multi- 
modal and multilevel system for robot treat- 
ment of autism in children. In proceed of 
the intern workshop on social learn- 
ing and multimod interact for design 
artifici agents, page 3. acm, 2016. 

omkar M parkhi, andrea vedaldi, andrew zis- 
serman, et al. deep face recognition. In 
bmvc, volum 1, page 6, 2015. 

P jonathon phillips, fang jiang, abhijit 
narvekar, juliann ayyad, and alic J 
o’toole. An other-rac effect for face recogni- 
tion algorithms. acm transact on appli 
percept (tap), 8(2):14, 2011. 

alic B popejoy and stephani M fullerton. ge- 
nomic be fail on diversity. nature, 538 
(7624):161, 2016. 

rajeev ranjan, swami sankaranarayanan, car- 
lo D castillo, and rama chellappa. An all-in- 
one convolut neural network for face anal- 
ysis. In automat face & gestur recogni- 
tion (fg 2017), 2017 12th ieee intern 
confer on, page 17–24. ieee, 2017. 

daniel reid, sina samangooei, cunjian chen, 
mark nixon, and arun ross. soft biometr 
for surveillance: an overview. machin learn- 
ing: theori and applications. elsevier, page 
327–352, 2013. 

lorna roth. look at shirley, the ultim 
norm: colour balance, imag technologies, and 
cognit equity. canadian journal of commu- 
nication, 34(1):111, 2009. 

rasmu rothe, radu timofte, and luc 
van gool. deep expect of real and ap- 
parent age from a singl imag without facial 
landmarks. intern journal of comput 
vision, page 1–14, 2016. 

ramprakash srinivasan, juli D golomb, and 
aleix M martinez. A neural basi of facial ac- 
tion recognit in humans. journal of neuro- 
science, 36(16):4434–4442, 2016. 

yaniv taigman, ming yang, marc’aurelio ran- 
zato, and lior wolf. deepface: close the 
gap to human-level perform in face veri- 
fication. In proceed of the ieee confer- 
enc on comput vision and pattern recogni- 
tion, page 1701–1708, 2014. 

fitzpatrick tb. the valid and practic of 
sun-react skin type i through vi. archiv 
of dermatology, 124(6):869–871, 1988. doi: 
10.1001 / archderm.1988.01670060015008. 
url +http : / / dx.doi.org / 10.1001 / 
archderm.1988.01670060015008. 

bart thomee, david A shamma, gerald fried- 
land, benjamin elizalde, karl ni, dougla 
poland, damian borth, and li-jia li. the 
new data and new challeng in multimedia re- 
search. arxiv preprint arxiv:1503.01817, 1(8), 
2015. 

yandong wen, kaipeng zhang, zhifeng li, and 
Yu qiao. A discrimin featur learn ap- 
proach for deep face recognition. In european 
confer on comput vision, page 499– 
515. springer, 2016. 

xiaolin Wu and Xi zhang. autom infer- 
enc on crimin use face images. arxiv 
preprint arxiv:1611.04135, 2016. 

stefano zafeiriou, cha zhang, and zhengyou 
zhang. A survey on face detect in the wild: 
past, present and future. comput vision and 
imag understanding, 138:1–24, 2015. 

15 

+ http://dx.doi.org/10.1001/archderm.1988.01670060015008 
+ http://dx.doi.org/10.1001/archderm.1988.01670060015008 

introduct 
relat work 
intersect benchmark 
rational for phenotyp label 
exist benchmark select rational 
creation of pilot parliament benchmark 
intersect label methodolog 
fitzpatrick skin type comparison 

commerci gender classif audit 
key find on evalu classifi 
commerci gender classifi selection: microsoft, ibm, face++ 
evalu methodolog 
audit result 
analysi of result 
accuraci metric 
data qualiti and sensor 

conclus 

