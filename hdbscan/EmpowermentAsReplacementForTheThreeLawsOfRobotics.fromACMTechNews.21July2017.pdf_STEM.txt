






































frontier | empower As replac for the three law of robot | robot and AI 


the great ubiqu of robot creat a need for gener guidelin for robot behavior. 

We focu less on how a robot can technic achiev a predefin goal and more on 

what a robot should do in the first place. particularly, we be interest in the question 

how a heurist should look like, which motiv the robot’ behavior in interact 

with human agents. We make a concrete, oper propos a to how the 

information-theoret concept of empower can be use a a gener heurist to 

quantifi concepts, such a self-preservation, protect of the human partner, and 

respond to human actions. while elsewher we studi involv single-ag 

scenario in detail, here, we present proof-of-principl scenario demonstr how 

empower interpret in light of these perspect allow one to specifi core 

concept with a similar aim a asimov’ three law of robot in an oper way. 

frontier | empower As replac for the three law of robot | robot and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/ful 

1 sur 33 21/07/2017 19:08 



importantly, thi rout do not depend on have to establish an explicit verbal 

understand of human languag and convent in the robots. also, it incorpor 

the abil to take into account a rich varieti of differ situat and type of robot 

embodiment. 

one of the trend of modern robot be to extend the role of robot beyond be a specif 

design machin with a clearli defin function that oper accord to a confin 

specif or safe separ from humans. instead, robot increasingli share live and work 

space with human and act a servants, companions, and co-workers. In the future, these robot 

will have to deal with increasingli complex and novel situations. thus, their oper will 

requir to be guid by some form of generic, high instruct level to be abl to deal with 

previous unknown and unplanned-for situat in an effect way. 

onc robot control have to cope with more than replay meticul pre-arrang action 

sequences, or the execut of a predefin set of task a a reaction to a specifi situation, the 

need aris for gener yet formal guidelin which the robot can use to gener action and 

prefer base on the current situat and the robot’ concret embodiment. 

We propos that ani such guidelin should address the follow three issues. first, “robot 

initiative”: we expect the principl to be gener enough for the robot to be abl to appli them to 

novel situations. In particular, the robot should not onli be abl to respond accord to 

predefin situat but also be abl to gener new goal and direct a need in new 

situations. second, break action equivalence: how should a robot choos between sever 

differ action when all produc essenti the same desir outcome, onli in differ ways? 

can we formul good secondari criterion that the robot should optim in addition, onc it can 

ensur that the primari job get done? finally, safeti around robots: the default approach often 

involv a “kill switch,” i.e., the drastic and crude step of shut down the robot and stop all 

it actuators. thi rudimentari respons be often undesirable, e.g., when the robot be carri out 

a vital function where an immedi shutdown would lead to harm a human or itself, or when, to 

maintain safeti and prevent damage, the robot be requir to act rather than to stop acting. In 

summary, we propos that there be a pronounc need for generic, situation-awar guidelin that 

can inform and gener robot behavior. 

scienc fiction literature, an often product vehicl to explor idea about the future, have come 

across thi problem in it countless specul about the role of robot in society. arguably, the 

best-known suggest for gener rule for robot behavior be asimov’ three law of robot 

(asimov, 1942): 

1. A robot may not injur a human be or, through inaction, allow a human be to come to 

harm. 

2. A robot must obey the order give to it by human beings, except where such order would 

frontier | empower As replac for the three law of robot | robot and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/ful 

2 sur 33 21/07/2017 19:08 



conflict with the first law. 

3. A robot must protect it own exist a long a such protect do not conflict with the 

first or second law. 

while there be ampl room to discu the technic and implic of the three law 

(mccauley, 2007; anderson, 2008; murphi and woods, 2009), we believ most peopl would 

agre with the gener sentiment of the rules; asimov himself argu that these rule be not 

particularli novel, but govern the design of ani kind of tool human produc (asimov, 1981). 

asimov state that he aim to captur basic requir of tools, namely, safety, compliance, 

and robustness, and hi three law be an attempt to explicitli express these properti in 

language. but one central problem in adapt these rule to current-day robot be the scant 

semant comprehens of rule express in natur language. 

In part, thi be base on fundament AI problems, such a determin the scope and context 

pertin to such rule by robot or ai in gener (dennett, 1984). anoth ai-philosoph 

problem rais the question on how to assign mean to the semant concept (coradeschi et 

al., 2013). sinc robot usual have a radic differ perspect to humans, and henc a 

differ perceptu reality, it remain doubt if robot and human could have a common 

language. alreadi simple, and common concepts, such a “harm,” cannot be naiv relat to the 

robot’ perspective. subsequently, it be difficult to build robot that understand what constitut 

harm and thu can avoid inflict it. 

even if we be to somehow imbu a robot with a human-level understand of human 

language, we would still face the more pragmat problem that human languag carri intrins 

ambiguity. one exampl of thi be the legal domain, where human will argu what exactli 

constitut “harm” in legal cases, demonstr that there be no unambigu understand of 

thi term that could just be appli in a technic fashion. rel simpl sentences, such a the 

amend of the US constitut have spawn decad of interpretation. also, sever of 

asimov’ stori illustr how robot find loophol in their interpret of the three law 

that defi human expectations. becaus of all previous mention problems, current-day robot 

be unabl to gener action or behavior compli with natur languag directives, such a 

“protect human life” or “do no harm.” even great demand in regard to natur languag 

process be pose by the second law which requir the robot to be abl to interpret ani order. 

thi requir a robust, unambigu understand of human languag that cannot even be 

realiz by humans. 

In thi paper, we have a similar aim a asimov have with hi three laws; however, rather than 

exactli reproduc the laws, we propos a formal, non language-bas method to captur the 

underli properti of robot a tools. instead of employ language, we suggest to use the 

information-theoret measur of empower (klyubin et al., 2008) in particular, and 

potenti causal inform flow (ay and polani, 2008) in general, a a heurist to produc 

characterist behavior phenomenolog which can be interpret a correspond to the 

three law in certain, crucial aspects. note that we do not expect to reproduc the precis 

behavior associ with the three laws, but rather to captur essenti intuit we have about 

frontier | empower As replac for the three law of robot | robot and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/ful 

3 sur 33 21/07/2017 19:08 



how the three law should operate; those which caus u to agre with them in the first place. 

importantly, we do not argu that the propos heurist give a complet and suffici account 

for ethic robot behavior. rather, at thi stage, we consid properti such a safety, 

compliance, and robust a secondari to the main robot mission. thi be veri much in line 

with the idea of robot a servant and companion put forward in the “principl of robotics” 

(boden et al., 2011). In contrast, principl such a tilden’ law of robot that focu sole on 

the robot a autonomous, self-preserv life forms—bas live machin (hasslach and 

tilden, 1995)—are expressli not in the scope of thi article. nevertheless, we like to point out 

exist work that link empower to the idea of autonom and live system 

(guckelsberg and salge, 2016). 

centrally, we propos here that the empower formal offer an oper and 

quantifi rout to technic realiz some of the idea behind the three law in a gener 

fashion. To thi end, we will first introduc the idea behind empowerment. We will then proceed 

to give both a formal definit and the differ empower perspectives. We will then discu 

how these differ perspect correspond to concepts, such a self-preservation, compliance, 

and safety. finally, we will discu extensions, challenges, and futur work need to fulli realiz 

thi approach on actual robots. 

empower be an information-theoret quantiti that captur how much an agent be in 

control of the world it can perceive. It be formal by the information-theoret channel capac 

between the agent’ actuat dure a give time interv and the effect on it sensori 

percept at a time follow thi interval. empower be introduc by klyubin et al. 

(2005) to provid agent with a generic, a priorist intrins motiv that might act a a 

step stone toward more complex behavior. An information-theoret measure, it quantifi 

how much potenti causal influenc an agent have on the world it can perceive. empower 

be motiv by the idea to unifi sever seemingli dispar drive of organ of multipl 

level of complexity, such a maintain a good intern sugar level, stay healthy, becom a 

leader in a gang, accumul money, etc. (klyubin et al., 2008). while all these drive enhanc 

surviv in one way or another, one unifi theme that tie them togeth be maintain 

and enhanc one’ abil to act and control the environment. empower attempt to 

captur thi notion in an oper formalism; in thi paper, we specif want to 

demonstr how thi principl can serv a a cognit heurist to gener behavior in the spirit 

of the three law of robotics. for this, we consid empower from different, but relat 

perspectives. 

To motiv empower and gain a good understanding, let u first take a brief look at the 

background, befor move on to the formal definition. oesterreich (1979) argu that agent 

should act so that their action lead to perceiv differ outcomes, which he call “effici 

divergence” (“effizienzdivergenz” in german). In the ideal case, differ action should lead to 

frontier | empower As replac for the three law of robot | robot and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/ful 

4 sur 33 21/07/2017 19:08 



differ perceiv outcomes. von foerster (2003) famous state “I shall act alway so a to 

increas the total number of choices,” argu that a state where mani option be open to an 

agent be preferable. furthermore, seligman (1975) argu that human who be forc to be in a 

state where one’ action appear to have random outcom or no outcom variat at all suffer 

mental health problems. thi relat to more recent empir studi by trendafilov and murray- 

smith (2013), which indic that human in a control task associ a low level of 

empower with frustrat and perform good in situat where they be highli 

empowered. more recently, idea similar to empower have also emerg in physic 

(wissner-gross and freer, 2013), propos a close relat action principle; the latter is, 

however, motiv by the hypothes thermodynam maximum entropi product principl 

instead of be base on evolutionari and psycholog arguments. 

In essence, empower formal a “motiv for effectance, person causation, 

competence, and self-determination,” which be consid to be one area of intrins motiv 

by oudey and kaplan (2007), oudey et al. (2007). intrins motiv be a term introduc 

by ryan and deci (2000) as: “[…] the do of an activ for it inher satisfact rather than 

for some separ consequence.” In the last decades, a number of method have be suggest 

to artifici gener behavior of a similar natur a have be hypothes about intrins 

motiv organisms. among these be artifici curios (schmidhuber, 1991), learn 

progress (oudey and kaplan, 2007), predict inform (ay et al., 2008), homeokinesi 

(der et al., 1999), or the autotel principl (steels, 2004). not all of them be relat to person 

causation, most be more focu on the “reduct of cognit dissonance” and on “optim 

incongruity.” but all of them be to some extent intrins to the idea of agenc itself, and they all 

share a set of properti that make them well suit to imbu agent and robot with generic, 

motiv behavior without relianc on an extern defin reward structure. they usual be 

• task-independent, 

• comput from the agent’ perspective, 

• directli applic to mani differ sensorimotor configurations, without or with littl extern 

tuning, and 

• sensit to and reflect of differ agent embodiments. 

the task-independ demarc thi approach from most classic AI techniques, such a 

reinforc learn (sutton and barto, 1998); the gener idea be not to solv ani particular 

task well, or to be abl to learn how to do a specif task well, but instead to offer an incent for 

behavior even if there be current no specif task the agent need to attend to. In the case of 

empowerment, the behavior gener turn out to coincid well with the idea of robot self- 

preservation. 

the comput from an agent’ perspect be an essenti requirement. If some form of 

frontier | empower As replac for the three law of robot | robot and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/ful 

5 sur 33 21/07/2017 19:08 



intrins motiv be to be realiz by an organ or deploy onto an autonom robot, then 

the organism/robot need to be abl to evalu thi measur from it own perspective, i.e., base 

on it own sensor input. thi reli on a notion of umwelt by von uexküll (1909), becaus ani 

intrins prefer relat will be defin with respect to the agent’ experience, i.e., it 

perceiv dynam between the agent’ sensor and actuators; the latter, in turn, aris from the 

interplay of the environ and the embodi agent. thi be close relat to the concept of a 

“counterworld” (gegenwelt (von uexküll, 1909)), the intern mirror of the umwelt, but one 

that onli captur function circles, those relat where action relat to relev feedback 

from the environment. empower fit with thi approach, a it do not requir an explicit, 

full world model that tri to captur the whole environment, but onli a short-term forward 

model that relat it current action and context (typic a sensor-bas belief about the 

current state) to the subsequ sensor state which be expect to result from these actions. 

ziemk and sharkey (2001) provid a more in-depth explan of the umwelt concept and also 

provid an overview of modern robot approaches, such a the subsumpt architectur by 

brook (1986) that realiz robot control a a hierarchi of function circles. empowerment, and 

to a larg extent also the other mention intrins motiv measures, be usual compat 

with these bottom-up approach with minim model focu on immedi action–percept 

loops. 

the next properti of intrins motiv be the abil to cope with different, quit dispar 

sensorimotor configurations. thi be highli desir for the definit of gener behavior 

guidelin for robots. thi mean not have to defin them separ for everi robot or chang 

them manual everi time the robot’ morpholog changes. the applic to differ 

sensorimotor configur combin with the requir of task-independ be the central 

requir for such a principl to be universal. more precisely: to be universal, a driver for 

intrins motiv should ideal oper in essenti the same manner and aris from the 

same principles, regardless of the particular embodi or particular situation. A measur of 

thi kind can then identifi “desirable” chang in both situat (e.g., in the context of behavior 

generation) and embodi (e.g., in the context of develop or evolution). for example, 

while most empower work focu on state evalu and action generation, some work 

also consid it use for sensor or actuat evolut (klyubin et al., 2008). 

furthermore, thi impli that a measur for intrins motiv should not just remain 

gener computable, but also be sensit to differ morphologies. the challeng be to defin 

a valu function in such a way that it stay meaning when the situat or the embodi of 

the agent changes. An illustr exampl here be studi where an agent have the abil to move 

and place block in a simul world (salg et al., 2014a). driven by empower 

maximization, the agent chang the world in such a way that the result structur end up 

reflect the particular embodi of the agent. 

To sum up thi section, if we want to use an intrins motiv measur a a surrog for what 

pfeifer and bongard (2006) call a valu function in the context of embodi robotics, then we 

propos it need to fulfil these criteria. here, we specif concentr on empowerment, sinc 

frontier | empower As replac for the three law of robot | robot and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/ful 

6 sur 33 21/07/2017 19:08 



it have be show to be a suitabl candid to produc the desir behavior; furthermore, mani 

of it relev properti have alreadi be studi in some detail now (salg et al., 2014c). 

however, we would like to emphas that the concept to be develop below be not limit to 

empower in their application, but might also be adapt to altern intrins motiv 

methodolog in order to provid oper safeti principl for robots. 

To make our subsequ studi precise, we now give a formal definit of empowerment. 

empower be formal a the maxim potenti causal flow (ay and polani, 2008) from an 

agent’ actuat to an agent’ sensor at a late point in time. thi can be formal in the term 

of inform theori a channel capac (shannon, 1948). 

To comput empowerment, we model the agent–world interact a a perception–act loop a 

in figur 1. In figur 1, we be look at a time-discret model, where an agent interact with the 

world. An agent choos an action A for the next time step base on it sensor input S in the 

current time step t. thi influenc the state of R (in the next time step), which in turn 

influenc the sensor input S of the agent at that time step. the cycl then repeat itself, with 

the agent choos anoth action in A . note that, in a more gener model, thi choic of 

action might also be influenc by some intern state of the agent which carri inform 

about the agent’ past. 

(http://www.frontiersin.org/files/articles/260425/frobt-04-00025-html/image_m 
/frobt-04-00025-g001.jpg) 
figur 1. the perception–act loop visual a a causal bayesian network (pearl, 

2000). S be the sensor, A be the actuator, and R repres the rest of the system. the index t indic the time at which 
the variabl be considered. thi model be a minim model for a simpl memoryless agent. the red arrow indic the 
direct of the potenti causal flow relev for 3-step empowerment. If empower be measured, the input to each 
of the action be freeli chosen, disconnect from the sensor input, but insid the 3-step horizon the action may 
expressli be correlated—se also discuss in klyubin et al. (2008). 

for the comput of empowerment, we consid thi perception–act loop a tell u how 

action may potenti influenc a state in the future, and by influenc we emphat mean not 

the actual outcom of the concret trajectori that the agent takes, but rather the potenti futur 

outcom at the give time horizon t + 3, i.e., the distribut of outcom that could be 

gener by actuation, start from time t. the most straightforward interpret be a a 

probabilist commun channel where the agent transmit inform about action A , 

A , A through a channel and consid how much of it be reflect in the outcom in S . the 

maxim influenc of an agent’ action on it futur sensor state (again, not it actual actions, 

t t 

t+1 

t+1 

t+1 

t 

t+1 t+2 t+3 

frontier | empower As replac for the three law of robot | robot and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/ful 

7 sur 33 21/07/2017 19:08 



but it potenti actions) can now be model formal a shannon channel capacity: what the 

agent may possibl (but need not) transmit over the channel—or, in fact, what the agent may (but 

need not) have chang in the environment, at the end of it 3-step action sequence. 

empower be then defin a the channel capac between the agent’ actuat A in a 

sequenc of time step and it own sensor S at a late point in time. for example, if we look at 

empower in regard to just the next time step, then empower can be express a 

(1) 

note that the maxim impli that it be calcul under the assumpt that the control 

which choos the action sequenc (A ) be complet free to act from time t onward (but 

permit to correl the actions) and be not bound to a particular behavior strategi p(a|s, r). 

furthermore, empower be a state-depend quantity, a it depend on the state r in which 

the consider of potenti futur be initiated. instead of an extern observ object 

state r, one could also consid empower base on a pure agent-intrins “context” state 

deriv from earli agent experi (klyubin et al., 2008) without conceptu changes. for 

simplic and clarity, we will here discu onli empower landscap depend on 

“objective” state r. We also assum for the begin of the paper that the agent have somehow 

previous acquir a suffici accur local forward model p( |a , s ). We will late discu 

the gener difficulti and implic of the model acquisit itself. 

empower be defin for both discret and continu variables. however, while it be possibl 

to directli determin the channel capac for the discret case use the blahut–arimoto 

algorithm (arimoto, 1972; blahut, 1972) to comput a channel capac achiev distribut 

p*(a|r), thi algorithm cannot be straightforwardli appli to the continu case. there exist 

adapt for empower calcul in the continuum, though. jung et al. (2011) use 

monte-carlo integr to approxim empowerment, but thi method be veri comput 

expensive. A significantli faster method approxim empower of a continu channel by 

treat it a a linear channel with add independ and ident distribut (i.i.d.) 

gaussian nois (salg et al., 2012). 

when talk about an empowerment-maxim agent, it must be emphas that the 

distribut p*(a|r) achiev the channel capac be not the one that an empowerment- 

maxim agent actual us to choos it next action. the capacity-achiev distribut be 

onli util to comput the empower valu of world states; for each such state, an 

empower valu be thu computed, which defin a pseudo-util landscap on the state 

space. for the actual action, the agent choos a greedi strategi with respect to thi pseudo- 

utility: it choos it action a to local maxim the empower of the next state it will visit. 

To illustrate, an agent might prefer a state where it would have the option to jump off a cliff. 

𝔈(r) := C( → r) ≡ I( ; r).at st+1 
∣ 

∣ 
∣ max 

p( r)at ∣∣ 
st+1 At 

∣ 

∣ 
∣ 

t t 

t+1 t t 

frontier | empower As replac for the three law of robot | robot and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/ful 

8 sur 33 21/07/2017 19:08 



however, assum that the agent would break from the fall or have to tortuous climb up again, 

the agent would not actual select the action that would caus it to fall off the cliff; it will just 

want to poss the option. importantly, thi requir the agent to have a correct forward model 

of what will happen when step off the cliff. If there be nois in the dynamics, thi will, on the 

other hand, lead empower to pull the agent slightli away from the cliff, a the agent in thi 

case cannot ensur that it would not accident fall off the cliff. thi be similar to on-polici 

reinforc learning. 

In past work, two main strategi have be used. greedi empower maxim basic 

consid all possibl action in the current state and then comput the successor state (or state 

distributions) for each of those actions. then, empower be calcul for each of those 

successor states. the successor state with the high empower be selected, and the agent 

then perform the action lead to the chosen successor state. In case each action have a 

distribut of successor states, then the action with the high averag successor state 

empower be selected. thi have the advantag that the agent onli need to comput the 

empower for the immedi successor state in the future. 

alternatively, the agent could comput the empower valu for each possibl state of the 

world, or a subset thereof. the agent could then determin the state with the maxim 

empower and then plan a sequenc of action to get to thi state (leu et al., 2013). thi 

solut is, of course, infeas in general. 

here, however, we will, in accord with the latter principle, gener present the comput 

empower valu a an empower map, becaus it give an overview over what behavior 

would be prefer in either case. the map visual both the local gradient and the optima. the 

behavior result from these map would then be either an agent that act in order to climb up 

the local gradient or to reach a global optimum. 

In thi section, we outlin how we can use the empower formal to captur the essenti 

aspect of the three laws. for this, we look at a system that contain both a human and a robot 

agent. the causal bayesian network from figur 2 show the combin perception–act loop 

of both a human and a robot. there be a jointli access world R that both the human and 

robot agent can perceiv and act upon with their respect sensor and actuat variables. In 

such a system, it be possibl to defin differ empower perspectives: here, we will look at 

robot empowerment, human empowerment, and human-to-robot transfer empowerment. 

(http://www.frontiersin.org/files/articles/260425/frobt-04-00025-html/image_m/frobt-04-00025-g002.jpg) 
figur 2. the time-unrol perception–act loop with two agent visual a a bayesian network. S be the robot 

frontier | empower As replac for the three law of robot | robot and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/ful 

9 sur 33 21/07/2017 19:08 



sensor, S the human sensor, A be the robot actuator, A be the human actuator, and R 
repres the rest of the system. the index t indic the time at which the variabl be 
considered. the arrow be causal connect of the bayesian networks, the dot and 
dash line denot the three type of causal inform flow relev to the three type 
of empower discuss in the text. the red dot arrow indic the direct of the 

potenti causal flow relev for 3-step robot empowerment, the blue dot arrow denot human empowerment, 
and the dash purpl line indic the human-to-robot transfer empowerment. 

robot empower be defin a the channel capac with respect to the robot’ actuat A 

and sensor S. thi be the classic empower perspective. the robot choos action to 

maxim robot empower lead to behavior that preserv and enhanc the robot abil to 

act and affect be surroundings. the propose, therefore, that robot empower can provid a 

heurist for self-preserv and reliability. 

human empower be similarli defin a the channel capac with respect to the human’ 

actuat A and sensor S . the differ here be that it be still the robot that choos it own 

action a to maxim the human’ empowerment. thi should creat robot behavior aim at 

preserv and enhanc the human’ abil to act. thi provid a heurist that ultim 

protect the human from environment influenc that would destroy the human or reduc it 

abil to act. It also creat behavior that aim to enhanc the human’ access and influenc on 

the world and keep the robot from hinder or harm the human directly. thi heurist 

somewhat correspond to the first law and provid a degre of safety. 

human-to-robot transfer empower be defin a the channel capac from the human’ 

actuat A to the robot’ sensor S. thi captur the potenti causal flow from the human’ 

action to the world perceiv by the robot. If the robot act to maxim thi value, it will 

maintain someth we like to call oper proximity. It will keep the robot close to the 

human in a way where close do not necessarili mean physic close, but close so that the 

human can affect the robot. furthermore, transfer empower can also be rais by the robot 

act reliable, i.e., react in a predict manner to the human’ actions. thi enhanc the 

human abil to act and would allow for the human to use certain action to direct the robot. We 

propose, therefore, that thi heurist captur certain aspect of reliabl and compliance, 

without directli reproduc the second law of robotics. 

In combin these three heurist should provid an operation motiv for robot to 

act in a way that reflect the sentiment behind the three law of robotics. the core of thi idea 

be initi suggest by salg et al. (2014b). guckelsberg et al. (2016) have late use similar 

perspect (they use transfer empower in the opposit direction) to gener companion 

behavior for a non-play charact (npc) in a dungeon crawler game. 

robot empower be the potenti causal inform flow from the robot’ actuat to the 

robot’ sensor at a late point in time. In thi perspective, the human be simpli includ in the 

h h 

h h 

h 

frontier | empower As replac for the three law of robot | robot and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/ful 

10 sur 33 21/07/2017 19:08 



extern part of the perception–act loop of the robot. from the robot’ perspective, all 

variabl pertain to the human be subsum in R. the human’ influenc on the transit 

probabl from A to S becom relev to it onli a part of the robot’ “umwelt” and a such 

they be integr into the robot’ local forward model. therefore, we expect robot 

empower behavior to be similar to what be observ in exist work on singl agent 

empower maxim (klyubin et al., 2005, 2008; salg et al., 2014c), where 

empower behavior aim to maintain the agent’ freedom of oper and, indirectly, it 

survivability. 

typic empowerment-driven behavior can be seen, e.g., in control problems, where 

empower maxim balanc a pendulum and a doubl pendulum, and also stabil a 

bicycl (jung et al., 2011). We emphas that in these exampl no extern reward need to be 

specified, and empower deriv directli from the intrins dynam of the system. In other 

words, empower identifi the balanc posit a goal without an extern specif 

of a goal, becaus these state offer the great degre of simultan control and predictability. 

notably, empower have a tendenc to drive the agent away from state where it would 

becom inoperational, correspond to a breakdown or “death” of an organism. importantly, 

thi do not requir an extern penalti for death, a breakdown or death be directli 

repres in the formal via the vanish of empowerment. typically, a neg 

empower gradient can serv a an alert to the agent that it be in danger of move toward 

destruct (or loss-of-control) state (salg et al., 2014a). guckelsberg and salg (2016) 

summar a lot of the self-preserv aspect of empower and argu that empower 

maxim can lead to autopoesi (maturana and varela, 1991). 

more concret relev for the present argument be the work by leu et al. (2013), pictur in 

figur 3, where a physic robot us the 2d-map of it environ to creat an empower 

map to modul it navigation. while the robot realiz it primari object to follow a human, 

it also tri to maintain it own empowerment, therebi avoid to get stuck or to navig into a 

tight passag which would reduc it abil to act. In the experiment, the reaction of the 

environ to the robot’ action be learnt use gaussian process models. the human-follow 

behavior itself be hard-cod and the human behavior itself be not cover by the model. 

frontier | empower As replac for the three law of robot | robot and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/ful 

11 sur 33 21/07/2017 19:08 



(http://www.frontiersin.org/files/articles/260425/frobt-04-00025-html/image_m 
/frobt-04-00025-g003.jpg) 
figur 3. empowerment-driven robot follow a describ in leu et al. (2013). the 
robot tri to follow the human while tri to maintain it empower in the obstacl 

environment. By tri to maintain empowerment, the robot keep away from obstacl and wall and, furthermore, 
avoid pass through the narrow passag separ it from the human becaus it would constrain it movement. the 
left subfigur show the experiment setup, with a scale empower map on the bottom left. the top left show the 
robot’ view, use for track the human. the right subfigur show the room layout with empower map 
overlaid; right: gradient vector field of the scale empower map, scale by euclidean distanc to the human to 
induc follow behavior. 

while the human-in-the-loop can be treated, from the robot’ perspective, a just anoth part of 

the environment, we can modifi our question and ask how the maxim of robot 

empower will affect the human or what kind of interact behavior will result from this? 

consid figur 4, depict a simplifi model of the set-up in figur 3. the figur show that, 

onc we simul the human behavior a part of the model, the robot’ empower be 

drastic reduc around the human. first, in thi particular scenario the robot’ safeti 

shutdown turn it off in proxim to the human, and it empower drop to zero. So the 

human can perform (move) action that will obliter the robot’ empowerment. other setup 

will have a differ and possibl less drastic response, but in ani case the presenc of the human 

impact the robot’ empowerment. notably, if the robot’ result sensor state can be influenc 

by the human’ actions, it be possibl for the human to disturb the outcom of the robot’ 

behavior. depend on how well the robot can predict the human’ action, the anticip 

outcome, i.e., it sensor state at the time horizon, will be more or less noisy. empower 

select avoid interact with unpredict agent (salg et al., 2013) and gener noisy, 

unpredict situations. It lower the robot’ control over it own environ and therebi it 

sensor input; thi loss of predict control express itself in a loss of empowerment. 

(http://www.frontiersin.org/files/articles/260425/frobt-04-00025-html/image_m 
/frobt-04-00025-g004.jpg) 
figur 4. robot empower (in grayscale: dark—low, bright—high) depend on the 
robot position. obstacl in blue. two differ human (yellow circle) behavior model be 
considered. If the robot would be within the safeti shutdown distanc (red circle), it be not 

abl to act. the red dot be the endpoint of the 2,000 random human action trajectori use for possibl action 
predictions, the two graph differ in the assum distribut of human movement in the next three steps. If one 
compar the empower close to the safeti shutdown distance, one can see that the assum human behavior 
influenc the estim empower while all other aspect of the simul remain unchanged. 

the effect of thi can be see in figur 4, where the robot empower landscap be chang 

frontier | empower As replac for the three law of robot | robot and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/ful 

12 sur 33 21/07/2017 19:08 



pure by a differ human behavior model. On the right, we have a more accur model of the 

predict human behavior, which also assum that the human move toward the upper left. thi 

move the shutdown zone where the robot empower vanish and at the same time also 

“sharpens” the contrast between the high- and low-empow areas. the sharper contrast be a 

result of the reduc amount of nois be inject by the human into the robot’ perception– 

action loop. 

A reliabl predict human would also allow the robot to maintain a high empower 

closer to the human if it would stay south-west of the human, basic opposit of the human 

predict movement direction. In general, obtain a good human model can increas the 

robot’ perceiv model-bas empower by reduc the human nois and by provid a 

good estim which state in close proxim to the human be less like to becom 

disempowering. 

A relat phenomenon be observ in a studi by guckelsberg et al. (2016), where three 

differ empower perspect be use to control a npc companion in a nethack-lik 

dungeon crawler game. In one simulation, the player be abl to shoot an arrow which would kill 

the npc. thi caus the empowerment-driven npc agent to alway avoid stand in the 

direct of the player. the npc’ world model assum that all action of the player be equal 

likely, and therefore, assum that there be a chanc that the player would kill the npc. thi lead 

to a tendenc to avoid the player. guckelsberg et al. show that thi could be mitig by a 

“trust” assumption, basic chang the player model a to assum the player to be benevol 

to the npc and would not perform an action that would lead to a loss of all npc empower 

(i.e., kill the npc). thi make the npc less inclin to flee from the player. appli to a real 

robot, thi trust assumpt would make sure that the robot would focu on mitig actual 

possibl threat rather than have to hedg against malevol or even just neglig human 

action (“friendli fire”). 

better model acquisit be necessari for an agent to gage whether or not to avoid humans, 

depend on their cooperation, unpredictability, or antagonism. but empower 

maxim offers, by itself, not a direct incent toward or away from human interaction. It be 

possibl to imagin that the human could perform action that would increas or preserv the 

robot or npc empowerment, such a feed or repairing/h it. thi would then like 

creat a drive toward the human, if thi be model in viabl timescales. In absenc of ani specif 

possibl benefit provid by the human, however, the agent driven by empower alon be not 

automat drawn toward interact with a human and be like to drift away over time. thi 

will be address in the other perspect below. 

In short, we propos to maxim robot empower to gener behavior by which the robot 

strive toward self-preservation. specifically, becom inoper correspond to vanish 

empowerment. In turn, have high empower mean that the robot have a high influenc on 

the world it can perceive, impli a high readi to respond to a varieti of challeng that 

might emerge. We propos thi principle, namely, maxim empowerment, a a gener 

measur a a plausibl proxi for produc behavior in the spirit of the third law, a it will caus 

frontier | empower As replac for the three law of robot | robot and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/ful 

13 sur 33 21/07/2017 19:08 



the robot to strive away from state where it expect to be destroy or inoperational, and to 

strive toward state where it achiev the maximum potenti effect. robot empower 

maxim thu act to some extent a a surrog for a drive toward self-preservation. 

We now turn to human empowerment. human empower be defin in analog to robot 

empower a the potenti causal flow from the human’ actuat to the human’ sensors. 

the robot be now part of the extern compon of the perception–act loop of the human. 

maximizing, or at least preserv human empower have similar effect to the previou case: 

keep it at a high valu impli maintain the human’ influenc on the world and avoid 

situat which would hinder or disabl the human agent. A central differ to the previou 

case be that the human empower be make depend on the robot; in other words, now the 

robot aim to maxim the empower of anoth agent rather than it own. 

figur 5 show anoth continu 2D scenario, thi time involv a laser. the laser would block 

the human’ movement, but be harmless to the robot and can be block by it. the grayscal 

color thi time indic the valu of the human empowerment, but still depend on the 

robot’ position. notably, the high empower be achiev when the robot be in the white 

area. thi be where the robot block the laser come from the right side, permit the human to 

move past the laser barrier. driven by maxim of human empowerment, the robot would, 

therefore, prefer to move in front of the laser. importantly, note that high human empower 

valu for the robot in thi area onli becom pronounc when the human be close to the laser 

barrier (a be the case in the figure, the human posit denot by the yellow circle). thi mean 

that the drive to block the laser onli emerg at all when the human be actual in a posit to 

pa it. 

(http://www.frontiersin.org/files/articles/260425/frobt-04-00025-html/image_m 
/frobt-04-00025-g005.jpg) 
figur 5. human empower (in grayscale: dark—low, bright—high) depend on 
the robot’ position. In thi simulation, a laser (indic by the red line) block the 
human’ movement, but the laser can be occlud by the robot body. thus, human 
empower be the high for robot posit toward the right wall where the robot 
block the laser and therebi allow the human a great rang of movement. 

We can also see in figur 5 that posit in the area directli around the human produc low 

human empowerment. thi be becaus the robot would partial block the human movement if it 

be in these posit close to the human. also note that the empower landscap for the 

frontier | empower As replac for the three law of robot | robot and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/ful 

14 sur 33 21/07/2017 19:08 



robot be further away from the human be flat. here, the robot be so far away that it do not 

interact in ani way with the human’ action–percept loop, and therefore, it exact posit have 

no influenc on the human’ empowerment. 

for anoth illustr exampl of the effect of consid human empowerment-driven robots, 

consid the npc (non-person character; autonomous, computer-control player in a video 

games) in the dungeon crawler game scenario from guckelsberg and salg (2016). here, the 

npc avoid stand directli next to the (human) player, a thi would block the player’ 

movement. If enemi be present that be predict to shoot and kill the player, the npc strive 

to kill these enemi to save the player. thi can be combin with a maxim of the npc’ 

own empowerment. figur 6 show a sequenc of npc action that aris from combin the 

differ heuristics. here, the heurist be a linear combin of the differ empower 

types. As a result, the npc will first save itself (a the human player have more health) and then it 

remov the two enemies. thi complex behavior emerg from a greedi maxim of the 

linear combin of the differ empower perspectives. 

(http://www.frontiersin.org/files/articles/260425/frobt-04-00025-html/image_m 
/frobt-04-00025-g006.jpg) 
figur 6. companion (c) and player (p), both purple, be threaten simultan by 

two enemi (e), both red. the imag repres the success moves: the companion escap it own death, rescu 
the player, and final defend itself. left: combin heurist for 2-step empower (see text), lighter color 
indic high empowerment. arrow indic shooting. figur take from guckelsberg and salg (2016), 
reproduc with permission. 

In thi section, we consid human empower maxim (in the variant of be 

influenc by the artifici agent rather than the human). use thi variant a driver lead to a 

number of desir behaviors. It prevent the robot from obstruct the human, for example, by 

get too close or by interfer with the human’ actions. both would be notic in the 

human empower value, becaus they would either constrain access to state around 

the human, or inject nois in the human’ perception–act loop. In addit to that, the robot 

act a to enhanc or maintain the human’ empowerment, through “proactive”-appear 

activities, repres in abov exampl by remov a barrier from the environ or by 

neutral a threat that would destroy or maim the human or even just imped their freedom of 

movement. In thi sense, human empower maxim can be plausibl interpret a a 

driver for the agent toward protect the human and support their agenda. 

A number of caveat remain: to comput the human empower value, the robot not onli 

need a suffici forward model but also need to be abl to identifi the human agent in the 

environment, their possibl actions, and how the human perceiv the world via their sensor and 

frontier | empower As replac for the three law of robot | robot and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/ful 

15 sur 33 21/07/2017 19:08 



what they be abl to do with their actuators. thi be not a trivial problem; however, it 

nevertheless have the advantag that it offers, in some ways, a “portable” and oper model 

route. while it depend on a suffici reliabl algorithm for detect human and plausible, if 

strongli abstracted, model for human percept and actuation, onc these be provided, the 

principl be applic to a wide rang of scenarios. the present propos suggest possibl rout 

toward an oper implement of a “do not caus harm to a human” and a “do not permit 

harm to be caus to a human” principle, provid one can endow the artifici agent with 

a—what could loos be termed—“proto-empathetic” perspect of the human’ situation. 

anoth critic limit to the applic of the formal be the time horizon, which be the 

central free paramet in the empower computation. while a robot driven by human 

empower maxim might stop a bullet, or a fall into a pit, it would need to extend it 

time horizon massiv to account for thing that would be undesir for the human in the 

short-term, but be advantag in the long run. To illustrate, consid the analog from human 

lawmaking, where freedom to act on the short scale be curtail in an effort to limit long-term 

damag (e.g., in environment policies). the principl a discuss in thi section is, therefore, 

best suit for interact that have to avoid obstruct or interfer by a robot in the short 

term and with immedi consequences. that be said, noth in the formal prevent one— 

in principle—to be abl to account for long-term effects. To do so in practic will requir 

extend the method to deal with longer time-scal and level of hierarchies. 

As the third and last variant, we consid transfer empowerment. transfer empower be 

defin a the potenti causal inform flow from the action of one agent to the sensor of 

another. one of the motiv for it develop be to counter the lack of the two previou 

perspect to provid an incent that keep the robot/companion from drift away from the 

human. the aim be to add an incent for the robot to remain at the human’ service. thi be 

achiev by requir that the human’ action can influenc the sensori input of the robot. 

figur 7 show the human-to-robot (htr) transfer empowerment, i.e., we consid the human 

movement a the empowerment-induc action set and the empowerment-relev sensor input 

be give by the robot positions. here, we employ the safeti shutdown mechan at the fix 

distanc a a simpl illustr proxi for other, potenti more complex influenc that the 

human may have on the robot. In our case, the shutdown mechan allow the human to 

select disabl the robot, by move toward or away from it. thi creat a direct causal 

influenc from the human to the robot. consequently, thi gener a ring of high htr transfer 

empower around the human. In general, ani form of influenc of the human on the 

percept of the robot will produc a modul of the htr transfer empower landscape. 

By maxim thi value, the robot would tri to remain in a domain where the human can affect 

it. 

frontier | empower As replac for the three law of robot | robot and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/ful 

16 sur 33 21/07/2017 19:08 



(http://www.frontiersin.org/files/articles/260425/frobt-04-00025-html/image_m 
/frobt-04-00025-g007.jpg) 
figur 7. A visual of the human-to-robot (htr) transfer empower depend 
on robot posit (dark—low, light—high). thi simul show a slightli elev 
human-to-robot transfer empower around the human agent (yellow) at the 
shutdown distanc (red circle). thi be becaus the human can move toward or away from 
the robot, therebi have the potenti to stop the robot. thi creat a potenti causal 
flow from the human’ action to the robot’ sensors, which in thi case measur the robot 
position. here, the physic proxim of the human allow it to directli influenc the 

robot’ state. 

thi effect can altern be obtain by the analog robot-to-human transfer 

empowerment; thi be demonstr in guckelsberg and salg (2016), see figur 8. here, the 

companion tri to maxim the causal influenc it action have on the human player’ input 

state, which also caus it to remain close to the player. thi particular variant of empower 

help to overcom the persist problem that the companion would not follow the player 

through narrow corridors, a they be strongli constrain it empowerment. 

(http://www.frontiersin.org/files/articles/260425/frobt-04-00025-html/image_m 
/frobt-04-00025-g008.jpg) 
figur 8. two room scenario from guckelsberg and salg (2016), reproduc with 

permission. (a) companion empowerment, n = 2. (b) companion-play transfer empowerment, n = 2. (c) coupl 
empower with movement trace, n = 2. In the last subfigur (c), the companion agent C be driven by a combin 
of it own empower and transfer empower from companion to player (valu show in grayscale, bright 
—high, dark—low). If onli companion empower be drive the agent, a in subfigur (a), then the companion do 
not enter the corridor, a it narrow will low the agent’ own empowerment. with the addit of transfer 
empowerment, however, the companion begin to maintain oper proximity, and thu follow the player also 
through the narrow corridor. thi can be see in the movement trace of both player and agent. 

so, in regard to creat player-follow behavior, both direct of transfer empower 

seem to be suitable. but, look at the causal bayesian network represent in figur 9, we 

can see that there be in principl two differ way how the human’ action can affect the 

robot’ sensor (and vice versa). one way be for the human’ action to directli chang the world R 

in a way that will be perceiv by the robot. the other way be for the human to also affect the 

world R, but then for the robot to detect thi chang via it own sensors, and react base on thi 

input, chang part of R itself. In the second case, the inform flow through the intern 

part of the perception–act loop of the robot—in the first case it do not. An exampl of the 

frontier | empower As replac for the three law of robot | robot and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/ful 

17 sur 33 21/07/2017 19:08 



second case can be see in figur 10, where the robot move in the same direct a the human, 

if there be a direct line of sight between the two agents. thi result in a high transfer 

empower in those area where the human can be see by the robot. obtain thi high 

transfer empower requir the robot to react reliabl to certain human actions. 

(http://www.frontiersin.org/files/articles/260425/frobt-04-00025-html/image_m 
/frobt-04-00025-g009.jpg) 
figur 9. the time-unrol perception–act loop of two agents, color to visual 
the differ pathway potenti causal flow can be realized. the red dash line indic 
the causal flow from the human actuat at time t to the robot’ sensor variabl S at 

time t + 3, which contribut to human-to-robot transfer empowerment. thi potenti causal flow can be realiz by 
direct human influenc on the environ R (one exemplari path show in blue). alternatively, the human can 
influenc the environ R, and the robot can then perceiv thi change, react to it by choos an appropri action 
A and therebi influenc it perceiv environ itself. one exemplari path be show in orange. the dash arrow 
be those use by both pathways. 

(http://www.frontiersin.org/files/articles/260425/frobt-04-00025-html/image_m 
/frobt-04-00025-g010.jpg) 
figur 10. A visual of the human-to-robot (htr) transfer empower 
depend on robot posit (dark—low, light—high). In thi scenario, the robot will 
mirror the human’ movement if it have a direct line of sight. thi creat a high amount of 
potenti causal flow through the robot where the latter see the human. It result in 
compar high transfer empower in those area where the robot have both a 
direct line of sight to the human (yellow) and be not shut down by close proxim to the 
human. the high transfer empower be attain at a distance, but in an area where 

the robot can see and react to the human; with this, the robot provid the human with oper proximity, i.e., the 
abil to influenc the robot’ result state. 

the distinct between the two pathway for transfer empowerment, directli through the 

environ and through the intern part of the other agent’ perception–act loop, also 

provid u with reason to prefer human-to-robot transfer empower over transfer 

empower in the other direction. In human-to-robot transfer empowerment, the intern 

pathway be through the agent; so the robot can consid adjust it behavior, i.e., the way it 

respond with action to sensor inputs, in order to increas the transfer empowerment. In the 

robot-to-human transfer empowerment, the intern pathway be through the human, which the 

robot cannot optim and the human should ideal not be burden with optimizing. so, if one 

seek to elicit a reliabl reaction of the robot to the human’ action, then human-to-robot transfer 

empower should be the quantiti to optimize. 

aht t+3 

frontier | empower As replac for the three law of robot | robot and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/ful 

18 sur 33 21/07/2017 19:08 



anoth differ between the two direct of transfer empower becom evid when 

we compar figur 4 and 7. both show the same simulation, but depict htr- and robot 

empowerment, respectively. the area with high htr transfer empower be exactli the same 

area where the robot empower around the human begin to drop. thi be becaus while the 

human here gain control over the robot’ position, the latter lose thi veri control. 

control of a specif share variabl in the environ be a limit resource, and if one 

agent have full control of it, the other agent consequ have none. thi be anoth reason whi the 

use of transfer empower be usual prefer in the human-to-robot direction, namely, a to 

not provid an incent for the robot to take control away from the human. 

the differ scenario we look at also illustr the idea of “oper proximity” that 

transfer empower captures. the influenc of one agent on anoth do not necessarili 

depend on physic proximity, but rather on both agents’ embodiment, here in the form of their 

action and sensor perceptions. while in one scenario the human could stop the robot by physic 

proximity, in the other they could direct the robot along their line of sight. In the dungeon 

example, the companion need proxim to directli affect the player by block or shoot it, 

but one could also instead imagin a situat where the npc would push a button far away or 

block a laser somewher els to affect the environ of the player. maxim transfer 

empower tri to attain thi oper rather than physic proximity. In turn, oper 

proxim act a a necessari precondit for ani interact and coordin between the 

agents. To interact, one agent have to be abl to perceiv the chang of the world induc by the 

other agent. vanish transfer empower would mean that not even thi basic level of 

interact be possible. 

furthermore, htr transfer empower maxim also creat an incent to reliabl react 

to the human actions. In detail, thi mean increas the transfer empower further by 

allow for some potenti causal flow through the intern part of the robot’ perception–act 

loop. note that for the empower calculation, it do not matter how precis robot action 

be match to human actions; all that count be that by consist respond in the same way 

the robot effect extend the human’ empower in the world. the robot react to the 

human expand the influenc of the latter on the world, becaus the human’ action be 

amplifi by the robot’ actions. An addit effect be that, if a robot reliabl react to the 

human’ actions, the human can learn thi relationship and use it own action a proto-gestur 

to control the robot. On the one hand, thi be still far remov from give explicit verbal order to 

the robot, a describ in the second law. On the other hand, such a reliabl reaction of the robot 

to human action would permit human to “learn” a command languag consist of certain 

behavior and gestur that would then caus the robot to respond in a desir way. 

summar the section, while the maxim of transfer empower do not precis 

captur the second law, it creat oper proxim between the human and the robot, and 

therebi the basi for further interaction; togeth with the enhanc of human 

empowerment, it set the foundat for the human to have the maximum amount of option 

available. furthermore, if the robot behavior itself be includ in the comput of transfer 

frontier | empower As replac for the three law of robot | robot and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/ful 

19 sur 33 21/07/2017 19:08 



empower to be optimized, then thi would provid an addit rout to amplifi the 

human’ action in the world, name by virtu of manipul the robot via action and proto- 

gestur which make use of an implicitli learnt understand of the intern control of the robot. 

the core aim of thi articl be to suggest three empower perspect and to propos that 

these allow—in principle—for a formal and operation of idea roughli 

correspond to the three law of robot (not in order): the self-preserv of a robot, the 

protect of the robot’ human partner, and the robot supporting/expand the human’ 

oper capabilities. empower endow a state space cum transit dynam with a 

gener pseudo-util function that serf a a rich prefer landscap without requir an 

explicit, extern defin reward structure; on the other hand, where desired, it can be 

combin with explicit task-depend rewards. empower can be use a both a gener and 

intrins valu function. It serf not onli a a warn indic that one be approach the 

boundari of the viabil domain (i.e., be close to area of immin breakdown/destruction) 

but also imbu the interior of the viabil domain with addit prefer structur in 

advanc of ani task-specif utility. this, togeth with the properti outlin in section 2.1 

about intrins motivations, suggest empower a a use drive principl for an embodi 

robot. 

for the practic applic of the present formal to real and more complex robot–human 

interact scenarios, still a number of issues, such a comput and model acquisit need 

to be addressed. the follow discuss outlin suggest on how some of these challeng 

can be overcom and the problem still to be solv to deploy the present heurist on real- 

world scenarios. 

extend the idea present here from simpl abstract model into the domain of practic 

robot immedi rais the question of computability. In the classic empower 

formalism, comput time scale dramat with an increas in sensor and actuat state 

and with an extens of the tempor horizon. In discret domains, previou work have 

demonstr a number of way a to how to speed up the computation: one be the 

impoverish empower approach by anthoni et al. (2011). here, one onli consid the 

most “meaningful” action sequenc to gener the empowerment, prune away the others, and 

then build up longer action sequenc by extend onli those meaning action sequences. 

A simpl altern option be to just sampl a subset of all action sequenc and comput 

empower base on thi sampl to get a heurist estim for the actual valu (salg et al., 

2014a). thi approach onli work effect in a system with discret state and determinist 

dynam that do not spread out too much. 

frontier | empower As replac for the three law of robot | robot and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/ful 

20 sur 33 21/07/2017 19:08 



earlier, we mention a fast approxim method for continu variabl (salg et al., 2012). 

thi assum that the local transit can be suffici well approxim by a gaussian 

channel. anoth recent and fast approxim for gaussian channel us varianc propag 

methods, implement use neural network (karl et al., 2015). anoth promis approach 

util neural network be present by moham and jimenez rezend (2015) and provid 

not onli consider speed-up but also have the advantag of work without an explicit 

forward model. 

with the establish of empower a a viabl and use intrins motiv driver for 

artifici agent in a batteri of proof-of-principl scenario over the last years, it have becom 

evid that it be well warrant to invest effort into improv and speed up empower 

comput for realist size scenarios. the previou list of method show that a promis 

rang of approach to speed up empower comput alreadi exist and that such 

approxim may well be viable. We have, therefore, ground to believ that futur work will 

find even good way to scale empower comput up, thu render it more suitabl to 

deploy on practic relev robot systems. 

tradit method for empower calcul crucial requir the agent to have an 

intervent forward model (salg et al., 2012). So far, we have sidestep thi question of 

model acquisition, mostli becaus the acquisit of the local intervent model to comput 

empower can be treat a a separ problem which can be solv in differ way by 

exist method (dearden and demiris, 2005; nguyen-tuong and peters, 2011). 

first, one would learn the local causal dynam of agent–world interaction; from thi one can 

then comput empower which, a a second step, provid an intrins reward or pseudo- 

util function which be associ with the differ world state distinguish to the agent. As 

example, previou work in the continu domain demonstr how gaussian process learner 

(rasmussen and williams, 2006) can learn the local dynam of a system on the fli while 

empower base on these increment improved, experience-bas model can then be 

use to control invert pendulum model (jung et al., 2011) or even a physic robot (leu et al., 

2013). 

whether the forward model be prespecifi or learnt dure the run, empower will gener 

drive the agent toward state with more options. however, if train dure the run of the agent, 

the model will in gener also includ uncertainti on the outcom of actions. such uncertainti 

“devalues” ani option avail in thi state and will lead to a reduct of empowerment. thi 

reduct be irrespect of whether the uncertainti be due to “objective” nois in the environ 

and unpredict (e.g., due to anoth agent) or due to intern model error stem from 

insuffici training. from the point of view of empower both effect be equivalent. 

the first class of uncertainti (environment uncertainty) will tend to drive the agent away from 

noisi or unpredict area to compar more predict one if the avail option be 

frontier | empower As replac for the three law of robot | robot and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/ful 

21 sur 33 21/07/2017 19:08 



otherwis equivalent, or reduc the valu of richer option set when they can be onli 

unpredict invoked. the second class of uncertainti (model uncertainty) will—in the initi 

phase of the training—caus empower to devalu state where the model cannot resolv the 

avail options. thi have consequ for a pure empowerment-driven explor of rich, 

but non-obvi interact patterns; a promin candid for such a scenario would be 

learn the behavior of other agents, a long a they be compar reliable. 

the intertwin of learn and empowerment-driven behavior can thu be expect to produc 

a number of meta-effect on top of the alreadi discuss dynamics. thi could rang from 

exhibit a veri specif type of exploratori behavior; moreover, such agent might initi be 

avers to encount complex novel dynam and other agents. On the other hand, by 

modul the learn process and experi of an agent a well a it sensori resolut or 

“scope of attention” depend on the situation, one could guid the agent toward develop the 

desir sensitivities. 

such a process would, in a way, be reminisc of the social of anim and human to 

ensur that they develop an appropri sens for the social dynam of the world they live in. 

this, togeth with the earli discuss in thi paper, invit the hypothesi that, to be confid 

of the safeti of an autonom robot the follow be essential: not onli do thi machin need to 

be “other-aware,” but if that “other-awareness” be to be learnt while enjoy to a larg extent the 

level of autonomi that an intrins motiv model provides, it will be essenti for the machin 

to undergo a suitabl organ social process. 

As a technic note, we remark that the type of model requir for empower comput 

onli need to relat the action and current sensor state to the expect subsequ sensor state 

and do not requir the complet world mechanics. In fact, empower can be base on the 

general, but pure intrins predict state represent (psr) formal (singh et al., 

2004; anthoni et al., 2013). thi make it suitabl for applic to recent robot approach 

(may and engel, 2013) interest in the idea of sensorimotor conting (o’regan and noë, 

2001); thi work consid the understand of the world to be built up by immedi interact 

with it and learn which action chang and which do not chang the agent’ perception. thi 

offer a rout to deploy empower alreadi on veri simpl robot with the aim of gradual 

build an “understanding” of the world from the bottom up. 

one central properti of empower be that the formal remain practic unchang for 

differ incarn of robot or agent and have veri few parameters; the time horizon be the 

onli one for discret empowerment. however, there be one, less obvious, “parameter” which have 

onli be briefli discuss in the previou literatur (salg et al., 2014c) and onli hint at in the 

last section: the question of sensor and actuat select in the model. 

By consid onli certain sensor variables, one can reduc the state space and speed up 

comput immensely. however, one also influenc the outcom of the comput by 

frontier | empower As replac for the three law of robot | robot and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/ful 

22 sur 33 21/07/2017 19:08 



basic assign which distinct between state of the world should be consid relevant. 

An agent with posit sensor will onli care about mobility, while an agent with visual sensor 

might also care about be in a state with differ reachabl views. In the simplest models, we 

often just assum that the agent perceiv the whole world. In biolog examples, we can lean on 

the idea of evolutionari adapt (i.e., jefferi (2005)), argu that sensor that would regist 

state irrelev to the agent would disappear, leav onli relev sensors. meanwhile, on a 

robot, we usual have a gener select of sensors, and we might not consid all of them to 

be relevant. however, for parsimoni design, or in imit of a hypothes principl of 

parsimoni in biolog (laughlin et al., 1998), it might be opportun to limit oneself to select 

essenti those sensor associ with capabl worth preserving. similarly, when 

consid the human empowerment, model the appropri human sensor will make a big 

differ to which oper capac of the human, and which form of influenc on the 

world, will be protect by the robot. 

thi becom even more of an issu when consid transfer empower which be basic 

an exampl of use partial sensor select to focu on relev properties. If both the human 

and the robot could fulli sens the environment, then the human empower and the human- 

to-robot transfer empower would be identical, a both the human and the robot sensor 

would captur exactli the same information. In the continu 2D exampl present in thi 

paper, we consid the human’ sensor to onli captur the human’ position, and the robot 

sensor to onli captur the robot’ position, so their percept would be distinct. In the npc AI 

exampl by guckelsberg and salg (2016), the player and companion have sensor that perceiv 

the world around it within a certain distance, and alway rel to their own position. that is, 

they detect the content of the field directli to the east of the player, rather than specifi the field of 

interest by a coordin valu such a 3.1. 

If we extend the human’ sensor to the extent that the human could sens at least everyth 

that the robot can sense, then the sensor relev for transfer empower would be a subset of 

human empowerment. We could then just comput human empower and captur both 

potenti causal flow at the same time. but by split the sensor variables, we basic 

comput partial sensor empowerment, onc for the sensor pertain to the human state and 

onc with a select of sensor pertain to the robot state. In a real world scenario the 

embodi perspect of both the human and the robot usual lead to differ percept of the 

world. both have limit sensor and a a result there be a natur distinct between their 

respect sensor inputs. when use simul environment, on the other hand, it be often easi 

to give all agent access to the whole world state. In thi case it becom necessari to limit the 

sensor of the differ agent to introduc thi split, befor one be abl to differenti between 

the two differ heuristics. thi separ of human and human-to-robot empower allow 

for the priorit of human empower over transfer empowerment. In general, we would 

expect one bit of human empower to be more valuabl than one bit of human-to-robot 

empower and, therefore, aim to retain thi distinction. 

frontier | empower As replac for the three law of robot | robot and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/ful 

23 sur 33 21/07/2017 19:08 



whenev differ variant of some evalu function exist which cover differ aspect of a 

phenomenon and these aspect be combined, one be left with the question how to weight them 

against each other. In the present case, thi would mean balanc the three type of 

empowerment. the analog with the three law might suggest a clear hierarchy, where one 

would first maxim human empower and then onli consid the other heuristics. 

however, give that one can alway expect some minim non-trivi gradient to exist in the first, 

such a lexicograph order would basic lead to onli maxim human empower 

abov all else, complet overrid the other measures. 

On the other hand, go back to figur 6, we saw that the companion, when face with a threat 

to itself and the player, choos to first save itself from death, while permit minor damag to 

the player, and onli then proceed to remov the threat to the player. while thi clearli violat 

the strict hierarchi of the three laws, such a cours of action might well be in the ration 

interest of the player, sinc it might be worthwhil to trade the minor loss of a life point for still 

have a companion (all this, of course, presum that the agent’ forward model be correct that 

the enemi shoot the human onc will not serious damag the latter; but such dilemmata be 

also present in mission-crit human decision-mak under uncertainty). 

thi conceptu tension be also present in the origin three laws. consid a 

gedankenexperi where a robot be face with two options: (a) inflict minor harm, such a a 

scratch, on a singl human or (b) by avoid that, permit the destruct of all (perfectli 

peaceful) robot on earth. In a strict interpretation, the law would dictat to chose option (b), 

but we might be inclin to consid that there must be some amount of harm so neglig that 

(a) would seem the good option than caus a regress to a robot “stone age.” 

but how could we captur thi insight with our three previous develop heuristics? We can, of 

course, consid a straightforward weight sum of the three heuristics, defin some trade-off 

between the three valu in the usual manner. but thi approach inevit rais the question 

whether there would be some distinct non-arbitrari trade-off. 

the previou analog be instructive. the problem be that option (b), the destruct of all robots, 

would creat a lot of more signific problem further down the line than the singl scratch of 

option A. It would result in the loss of all robot abl to carri out the human commands, and 

there would be few robot to protect and save human in the futur (they would have to be 

rebuilt, absorb signific product work, before—if at all—reach origin levels). 

both of these problem be reflect in human empower on longer timescales. In fact, we 

would suggest that all three heuristics, and actual also the origin three laws, reflect the idea 

that one core reason whi human build and program robot be actual to increas their veri own 

empowerment, their veri own option for the future. We alreadi argu that transfer 

empowerment, the second heuristic, extend human empower further into the world, 

becaus the robot amplifi the human’ action and their impact on the world. similarly, robot 

frontier | empower As replac for the three law of robot | robot and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/ful 

24 sur 33 21/07/2017 19:08 



that preserv themselves, a by follow the third heuristic, make sure that they preserv or 

extend the human’ empower further. 

the first heurist be alreadi directli about human empower maxim itself. so, in 

essence, the two other heuristics, robot empower and transfer empowerment, can be see a 

a form of meta-heurist for ultim human empower maximization. We conjectur that 

both the behavior of the second and the third heurist might emerg onc one maxim the 

human empower with a suffici long tempor horizon. for example, the robot could 

realize, with a good enough model of the future, that it need to keep itself function in order to 

prevent harm to the human in the future. so, basically, we hypothes that the second and third 

law might manifest themselv a a short term proxi for a suitabl longer term optim of 

human empowerment. If so, it may be that thi would help defin a natur trade-off: in our 

example, the robot might calcul that, by prevent destruct of all robot on earth, at cost of 

inflict a small scratch on a human, it would prevent mani more and bad injuri of human 

in the futur by the thu rescu robots. 

one final remark: in thi paper we have not consid true multi-ag empowerment. the 

reason for thi be subtle: empower so far be usual comput a an open-loop channel 

capacity. the futur (potential) action sequenc consid for empower be basic 

execut without react to the chang sensor state insid the time horizon. In other words, 

empower be comput a the channel capac between fixed-length “open-loop” action 

sequenc and the futur sensor observation. In choos these action sequences, intermedi 

sensor observ be not take into account. thu the agent do not react to particular 

develop in the environ while probe the potenti futur actions. 

thi make it imposs to formal account for instantan react to anoth agent’ 

action dure the comput of the potenti futures, sinc thi model select action onli at 

the begin and then onli evalu how the will affect the world at the end of the action run. 

however, we show earli that transfer empower can be massiv enhanc by react 

to the human’ actions. thi indic strongli that it would be import to model empower 

with “reactive” action sequences, i.e., empower where action sequenc be express in 

closed-loop form and which instantan react to other agent (or even chang in the 

environment) while still insid the time horizon of the probe futures. 

these variou aspect of the implement of empower indic a number of strategi to 

render it a use tool to operation the three law in a transpar way. furthermore, they 

also may offer a pathway demonstr how also other class of intrins motiv measur 

might be adapt to achiev the fusion of the desir autonomi of robot with the requir 

of the three laws. 

frontier | empower As replac for the three law of robot | robot and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/ful 

25 sur 33 21/07/2017 19:08 



CS and DP develop the origin idea. CS write and ran the simul and draft the paper. 

DP advis dure the develop of the simul and co-wrot the paper. 

the author declar that the research be conduct in the absenc of ani commerci or 

financi relationship that could be constru a a potenti conflict of interest. 

the author would like to acknowledg support by the EC h2020-641321 socsmc fet proactiv 

project, the h2020-645141 wimust ict-23-2014 robot project, and the european union 

horizon 2020 research and innov program under the mari sklodowska-curi grant 

(705643). the author also thank corneliu glackin and christian guckelsberg for help 

discussions. 

anderson, S. L. (2008). asimov’ “three law of robotics” and machin metaethics. Ai soc. 22, 477–493. doi: 
10.1007/s00146-007-0094-5 

crossref full text (https://doi.org/10.1007/s00146-007-0094-5) | googl scholar (http://scholar.google.com 
/scholar_lookup?title=asimov’s+“three+laws+of+robotics”+and+machine+metaethics&author=s.+l.+anderson&jour- 
nal=ai+soc.&publication_year=2008&volume=22&pages=477–493&doi=10.1007/s00146-007-0094-5) 

anthony, t., polani, d., and nehaniv, C. (2013). gener self-motiv and strategi identification: case studi base on 
sokoban and pac-man. ieee trans. comput. intell. AI game pp, 1. doi:10.1109/tciaig.2013.2295372 

crossref full text (https://doi.org/10.1109/tciaig.2013.2295372) | googl scholar (http://scholar.google.com 
/scholar_lookup?title=general+self-motivation+and+strategy+identification:+case+studies+based+on+sokoban+and+pac- 
man&author=t.+anthony&author=d.+polani&author=c.+nehaniv&journal=ieee+trans.+comput.+intell.+ai+games& 
publication_year=2013&pages=1&doi=10.1109/tciaig.2013.2295372) 

anthony, t., polani, d., and nehaniv, C. L. (2011). “impoverish empowerment: ‘meaningful’ action sequenc gener 
through bandwidth limitation,” in advanc in artifici life. darwin meet von neumann – 10th european conference, 
ecal 2009, budapest, hungary, septemb 13–16, 2009, revis select papers, part ii, volum 5778 of lectur note in 
comput science, ed G. kampis, I. karsai, and E. szathmári (budapest, hungary: springer), 294–301. 

googl scholar (http://scholar.google.com/scholar_lookup?title=“impoverished+empowerment:+‘meaningful’+action+se- 
quence+generation+through+bandwidth+limitation,”&author=t.+anthony&author=d.+polani&author=c.+l.+nehaniv& 
conference=advances+in+artificial+life.+darwin+meets+von+neumann+–+10th+european+confer- 
ence,+ecal+2009,+budapest,+hungary,+september+13–16,+2009,+revised+selected+papers,+part+ii,+vol- 
ume+5778+of+lecture+notes+in+computer+science&publication_year=2011&pages=294–301) 

arimoto, S. (1972). An algorithm for comput the capac of arbitrari discret memoryless channels. ieee trans. info. 
theori 18, 14–20. doi:10.1109/tit.1972.1054753 

crossref full text (https://doi.org/10.1109/tit.1972.1054753) | googl scholar (http://scholar.google.com 
/scholar_lookup?title=an+algorithm+for+computing+the+capacity+of+arbitrary+discrete+memoryless+channels&au- 
thor=s.+arimoto&journal=ieee+trans.+info.+theory&publication_year=1972&volume=18&pages=14–20&doi=10.1109 

frontier | empower As replac for the three law of robot | robot and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/ful 

26 sur 33 21/07/2017 19:08 



/tit.1972.1054753) 

asimov, I. (1942). runaround. astound. sci. fiction 29, 94–103. 

googl scholar (http://scholar.google.com/scholar_lookup?title=runaround&author=i.+asimov&journal=as- 
tound.+sci.+fiction&publication_year=1942&volume=29&pages=94–103) 

asimov, I. (1981). the three laws. comput 18, 18. 

googl scholar (http://scholar.google.com/scholar_lookup?title=the+three+laws&author=i.+asimov&journal=compute& 
publication_year=1981&volume=18&pages=18) 

ay, n., bertschinger, n., der, r., güttler, f., and olbrich, E. (2008). predict inform and explor behavior of 
autonom robots. eur. phys. J. B condens. matter complex syst. 63, 329–339. doi:10.1140/epjb/e2008-00175-0 

crossref full text (https://doi.org/10.1140/epjb/e2008-00175-0) | googl scholar (http://scholar.google.com 
/scholar_lookup?title=predictive+information+and+explorative+behavior+of+autonomous+robots&author=n.+ay&au- 
thor=n.+bertschinger&author=r.+der&author=f.+güttler&author=e.+olbrich&journal=eur.+phys.+j.+b+condens.+mat- 
ter+complex+syst.&publication_year=2008&volume=63&pages=329–339&doi=10.1140/epjb/e2008-00175-0) 

ay, n., and polani, D. (2008). inform flow in causal networks. adv. complex syst. 11, 17–41. 
doi:10.1142/s0219525908001465 

crossref full text (https://doi.org/10.1142/s0219525908001465) | googl scholar (http://scholar.google.com 
/scholar_lookup?title=information+flows+in+causal+networks&author=n.+ay&author=d.+polani&journal=adv.+com- 
plex+syst.&publication_year=2008&volume=11&pages=17–41&doi=10.1142/s0219525908001465) 

blahut, R. (1972). comput of channel capac and rate-distort functions. ieee trans. info. theori 18, 460–473. 
doi:10.1109/tit.1972.1054855 

crossref full text (https://doi.org/10.1109/tit.1972.1054855) | googl scholar (http://scholar.google.com 
/scholar_lookup?title=computation+of+channel+capacity+and+rate-distortion+functions&author=r.+blahut&jour- 
nal=ieee+trans.+info.+theory&publication_year=1972&volume=18&pages=460–473&doi=10.1109/tit.1972.1054855) 

boden, m., bryson, j., caldwell, d., dautenhahn, k., edwards, l., kember, s., et al. (2011). “principl of robotics,” in the 
unit kingdom engin and physic scienc research council (epsrc) (web publication). avail at: 
https://www.epsrc.ac.uk/research/ourportfolio/themes/engineering/activities/principlesofrobotics/ (https://www.ep- 
src.ac.uk/research/ourportfolio/themes/engineering/activities/principlesofrobotics/) 

googl scholar (http://scholar.google.com/scholar_lookup?title=“principles+of+robotics,”&author=m.+boden&au- 
thor=j.+bryson&author=d.+caldwell&author=k.+dautenhahn&author=l.+edwards&author=s.+kember&publica- 
tion_year=2011) 

brooks, R. (1986). A robust layer control system for a mobil robot. ieee J. robot. auto. 2, 14–23. 
doi:10.1109/jra.1986.1087032 

crossref full text (https://doi.org/10.1109/jra.1986.1087032) | googl scholar (http://scholar.google.com 
/scholar_lookup?title=a+robust+layered+control+system+for+a+mobile+robot&author=r.+brooks&journal=ieee+j.+ro- 
bot.+auto.&publication_year=1986&volume=2&pages=14–23&doi=10.1109/jra.1986.1087032) 

coradeschi, s., loutfi, a., and wrede, B. (2013). A short review of symbol ground in robot and intellig systems. 
künstlich intell. 27, 129–136. doi:10.1007/s13218-013-0247-2 

crossref full text (https://doi.org/10.1007/s13218-013-0247-2) | googl scholar (http://scholar.google.com 
/scholar_lookup?title=a+short+review+of+symbol+grounding+in+robotic+and+intelligent+systems&author=s.+corade- 
schi&author=a.+loutfi&author=b.+wrede&journal=künstliche+intell.&publication_year=2013&volume=27& 
pages=129–136&doi=10.1007/s13218-013-0247-2) 

dearden, a., and demiris, Y. (2005). “learn forward model for robots,” in proceed of the 19th intern joint 
confer on artifici intellig (edinburgh: morgan kaufmann publish inc.), 1440–1445. 

googl scholar (http://scholar.google.com/scholar_lookup?title=“learning+forward+models+for+robots,”&au- 
thor=a.+dearden&author=y.+demiris&conference=proceedings+of+the+19th+international+joint+conference+on+artifi- 
cial+intelligence&publication_year=2005&pages=1440–1445) 

dennett, D. C. (1984). “cognit wheels: the frame problem of ai,” in minds, machin and evolution, ed. C. hookway 
(cambridge, ma: cambridg univers press), 129–150. 

googl scholar (http://scholar.google.com/scholar_lookup?title=“cognitive+wheels:+the+frame+problem+of+ai,”&au- 

frontier | empower As replac for the three law of robot | robot and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/ful 

27 sur 33 21/07/2017 19:08 



thor=d.+c.+dennett&publication_year=1984&pages=129–150) 

der, r., steinmetz, u., and pasemann, F. (1999). homeokinesis: A new principl to back up evolut with learning. 
leipzig: max-planck-inst. für mathematik in den naturwiss. 

googl scholar (http://scholar.google.com/scholar_lookup?title=homeokinesis:+a+new+principle+to+back+up+evolu- 
tion+with+learning&author=r.+der&author=u.+steinmetz&author=f.+pasemann&publication_year=1999) 

guckelsberger, c., and salge, C. (2016). “doe empower maximis allow for enact artifici agents?” in 
proceed of the 15th intern confer on the synthesi and simul of live system (alife’16), cancun. 

googl scholar (http://scholar.google.com/scholar_lookup?title=“does+empowerment+maximisation+allow+for+enac- 
tive+artificial+agents?”&author=c.+guckelsberger&author=c.+salge&conference=proceedings+of+the+15th+interna- 
tional+conference+on+the+synthesis+and+simulation+of+living+systems+(alife’16)&publication_year=2016) 

guckelsberger, c., salge, c., and colton, S. (2016). “intrins motiv gener companion npc via coupl 
empower maximisation,” in ieee confer on comput intellig and game (cig) (santorini: ieee). 

googl scholar (http://scholar.google.com/scholar_lookup?title=“intrinsically+motivated+general+compan- 
ion+npcs+via+coupled+empowerment+maximisation,”&author=c.+guckelsberger&author=c.+salge&author=s.+colton& 
conference=ieee+conference+on+computational+intelligence+and+games+(cig)&publication_year=2016) 

hasslacher, b., and tilden, M. W. (1995). live machines. rob. auton. syst. 15, 143–169. 
doi:10.1016/0921-8890(95)00019-c 

crossref full text (https://doi.org/10.1016/0921-8890(95)00019-c) | googl scholar (http://scholar.google.com 
/scholar_lookup?title=living+machines&author=b.+hasslacher&author=m.+w.+tilden&journal=rob.+auton.+syst.&pub- 
lication_year=1995&volume=15&pages=143–169&doi=10.1016/0921-8890(95)00019-c) 

jeffery, W. R. (2005). adapt evolut of eye degener in the mexican blind cavefish. J. hered. 96, 185–196. 
doi:10.1093/jhered/esi028 

pubm abstract (http://www.ncbi.nlm.nih.gov/sites/entrez?db=pubmed&cmd=showdetailview& 
termtosearch=15653557) | crossref full text (https://doi.org/10.1093/jhered/esi028) | googl scholar 
(http://scholar.google.com/scholar_lookup?title=adaptive+evolution+of+eye+degeneration+in+the+mexican+blind+cave- 
fish&author=w.+r.+jeffery&journal=j.+hered.&publication_year=2005&volume=96&pages=185–196&doi=10.1093 
/jhered/esi028&pmid=15653557) 

jung, t., polani, d., and stone, P. (2011). empower for continu agent environ systems. adapt. behav. 19, 16. 
doi:10.1177/1059712310392389 

crossref full text (https://doi.org/10.1177/1059712310392389) | googl scholar (http://scholar.google.com 
/scholar_lookup?title=empowerment+for+continuous+agent+environment+systems&author=t.+jung&author=d.+polani& 
author=p.+stone&journal=adapt.+behav.&publication_year=2011&volume=19&pages=16&doi=10.1177 
/1059712310392389) 

karl, m., bayer, j., and van der smagt, P. (2015). effici empowerment. arxiv preprint arxiv:1509.08455. avail at: 
https://arxiv.org/abs/1509.08455 (https://arxiv.org/abs/1509.08455) 

googl scholar (http://scholar.google.com/scholar_lookup?title=efficient+empowerment.+arxiv+pre- 
print+arxiv:1509.08455&author=m.+karl&author=j.+bayer&author=p.+van+der+smagt&publication_year=2015) 

klyubin, a., polani, d., and nehaniv, C. (2005). “empowerment: a univers agent-centr measur of control,” in the 2005 
ieee congress on evolutionari computation, vol. 1 (edinburgh: ieee), 128–135. 

googl scholar (http://scholar.google.com/scholar_lookup?title=“empowerment:+a+universal+agent-centric+mea- 
sure+of+control,”&author=a.+klyubin&author=d.+polani&author=c.+nehaniv&publication_year=2005&volume=1) 

klyubin, a., polani, d., and nehaniv, C. (2008). keep your option open: an information-bas drive principl for 
sensorimotor systems. plo one 3:e4018. doi:10.1371/journal.pone.0004018 

pubm abstract (http://www.ncbi.nlm.nih.gov/sites/entrez?db=pubmed&cmd=showdetailview& 
termtosearch=19107219) | crossref full text (https://doi.org/10.1371/journal.pone.0004018) | googl scholar 
(http://scholar.google.com/scholar_lookup?title=keep+your+options+open:+an+information-based+driving+princi- 
ple+for+sensorimotor+systems&author=a.+klyubin&author=d.+polani&author=c.+nehaniv&journal=plos+one&publi- 
cation_year=2008&volume=3&pages=e4018&doi=10.1371/journal.pone.0004018&pmid=19107219) 

laughlin, S. b., de ruyter van steveninck, R. r., and anderson, J. C. (1998). the metabol cost of neural information. nat. 
neurosci. 1, 36–41. doi:10.1038/236 

frontier | empower As replac for the three law of robot | robot and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/ful 

28 sur 33 21/07/2017 19:08 



pubm abstract (http://www.ncbi.nlm.nih.gov/sites/entrez?db=pubmed&cmd=showdetailview& 
termtosearch=10195106) | crossref full text (https://doi.org/10.1038/236) | googl scholar (http://scholar.google.com 
/scholar_lookup?title=the+metabolic+cost+of+neural+information&author=s.+b.+laughlin&au- 
thor=r.+r.+de+ruyter+van+steveninck&author=j.+c.+anderson&journal=nat.+neurosci.&publication_year=1998&vol- 
ume=1&pages=36–41&doi=10.1038/236&pmid=10195106) 

leu, a., ristic-durrant, d., slavnic, s., glackin, c., salge, c., polani, d., et al. (2013). “corbi cognit control architectur 
for robot follower,” in ieee/sic intern symposium on system integr (sii) (taipei: ieee), 394–399. 

googl scholar (http://scholar.google.com/scholar_lookup?title=“corbys+cognitive+control+architecture+for+robotic+fol- 
lower,”&author=a.+leu&author=d.+ristic-durrant&author=s.+slavnic&author=c.+glackin&author=c.+salge&au- 
thor=d.+polani&conference=ieee/sice+international+symposium+on+system+integration+(sii)&publica- 
tion_year=2013&pages=394–399) 

maturana, H. r., and varela, F. J. (1991). autopoiesi and cognition: the realiz of the living, vol. 42. springer. 

googl scholar (http://scholar.google.com/scholar_lookup?title=autopoiesis+and+cognition:+the+realiza- 
tion+of+the+living&author=h.+r.+maturana&author=f.+j.+varela&publication_year=1991&volume=42) 

maye, a., and engel, A. K. (2013). extend sensorimotor conting theory: prediction, planning, and action generation. 
adapt. behav. 21, 423–436. doi:10.1177/1059712313497975 

crossref full text (https://doi.org/10.1177/1059712313497975) | googl scholar (http://scholar.google.com 
/scholar_lookup?title=extending+sensorimotor+contingency+theory:+prediction,+planning,+and+action+generation&au- 
thor=a.+maye&author=a.+k.+engel&journal=adapt.+behav.&publication_year=2013&volume=21&pages=423–436& 
doi=10.1177/1059712313497975) 

mccauley, L. (2007). Ai armageddon and the three law of robotics. ethic inf. technol. 9, 153–164. 
doi:10.1007/s10676-007-9138-2 

crossref full text (https://doi.org/10.1007/s10676-007-9138-2) | googl scholar (http://scholar.google.com 
/scholar_lookup?title=ai+armageddon+and+the+three+laws+of+robotics&author=l.+mccauley&jour- 
nal=ethics+inf.+technol.&publication_year=2007&volume=9&pages=153–164&doi=10.1007/s10676-007-9138-2) 

mohamed, s., and jimenez rezende, D. (2015). “variat inform maximis for intrins motiv 
reinforc learning,” in advanc in neural inform process system 28, ed C. cortes, N. lawrence, D. lee, M. 
sugiyama, R. garnett, and R. garnett (montreal: curran & associ inc.), 2116–2124. 

googl scholar (http://scholar.google.com/scholar_lookup?title=“variational+information+maximisation+for+intrinsi- 
cally+motivated+reinforcement+learning,”&author=s.+mohamed&author=d.+jimenez+rezende&publication_year=2015& 
pages=2116–2124) 

murphy, R. r., and woods, D. D. (2009). beyond asimov: the three law of respons robotics. ieee intell. syst 24, 14–20. 
doi:10.1109/mis.2009.69 

crossref full text (https://doi.org/10.1109/mis.2009.69) | googl scholar (http://scholar.google.com/scholar_lookup?ti- 
tle=beyond+asimov:+the+three+laws+of+responsible+robotics&author=r.+r.+murphy&author=d.+d.+woods&jour- 
nal=ieee+intell.+syst&publication_year=2009&volume=24&pages=14–20&doi=10.1109/mis.2009.69) 

nguyen-tuong, d., and peters, J. (2011). model learn for robot control: a survey. cogn. process. 12, 319–340. 
doi:10.1007/s10339-011-0404-1 

pubm abstract (http://www.ncbi.nlm.nih.gov/sites/entrez?db=pubmed&cmd=showdetailview& 
termtosearch=21487784) | crossref full text (https://doi.org/10.1007/s10339-011-0404-1) | googl scholar 
(http://scholar.google.com/scholar_lookup?title=model+learning+for+robot+control:+a+survey&author=d.+nguyen- 
tuong&author=j.+peters&journal=cogn.+process.&publication_year=2011&volume=12&pages=319–340&doi=10.1007 
/s10339-011-0404-1&pmid=21487784) 

oesterreich, R. (1979). entwicklung ein konzept der objectiven kontrol und kontrollkompetenz. ein 
handlungstheoretisch ansatz. ph.d. thesis, technisch universität, berlin. 

googl scholar (http://scholar.google.com/scholar_lookup?title=entwicklung+eines+konzepts+der+objectiven+kon- 
trolle+und+kontrollkompetenz.+ein+handlungstheoretischer+ansatz&author=r.+oesterreich&publication_year=1979) 

o’regan, J. k., and noë, A. (2001). A sensorimotor account of vision and visual consciousness. behav. brain sci. 24, 
939–973. doi:10.1017/s0140525x01000115 

pubm abstract (http://www.ncbi.nlm.nih.gov/sites/entrez?db=pubmed&cmd=showdetailview& 

frontier | empower As replac for the three law of robot | robot and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/ful 

29 sur 33 21/07/2017 19:08 



termtosearch=12239892) | crossref full text (https://doi.org/10.1017/s0140525x01000115) | googl scholar 
(http://scholar.google.com/scholar_lookup?title=a+sensorimotor+account+of+vision+and+visual+consciousness&au- 
thor=j.+k.+o’regan&author=a.+noë&journal=behav.+brain+sci.&publication_year=2001&volume=24&pages=939–973& 
doi=10.1017/s0140525x01000115&pmid=12239892) 

oudeyer, p.-y., and kaplan, F. (2007). what be intrins motivation? A typolog of comput approaches. front. 
neurorobot. 1:6. doi:10.3389/neuro.12.006.2007 

pubm abstract (http://www.ncbi.nlm.nih.gov/sites/entrez?db=pubmed&cmd=showdetailview& 
termtosearch=18958277) | crossref full text (https://doi.org/10.3389/neuro.12.006.2007) | googl scholar 
(http://scholar.google.com/scholar_lookup?title=what+is+intrinsic+motivation?+a+typology+of+computational+ap- 
proaches&author=p.+y.+oudeyer&author=f.+kaplan&journal=front.+neurorobot.&publication_year=2007&volume=1& 
pages=6&doi=10.3389/neuro.12.006.2007&pmid=18958277) 

oudeyer, p.-y., kaplan, f., and hafner, V. (2007). intrins motiv system for autonom mental development. ieee 
trans. evol. comput. 11, 265–286. doi:10.1109/tevc.2006.890271 

crossref full text (https://doi.org/10.1109/tevc.2006.890271) | googl scholar (http://scholar.google.com 
/scholar_lookup?title=intrinsic+motivation+systems+for+autonomous+mental+development&author=p.+y.+oudeyer&au- 
thor=f.+kaplan&author=v.+hafner&journal=ieee+trans.+evol.+comput.&publication_year=2007&volume=11& 
pages=265–286&doi=10.1109/tevc.2006.890271) 

pearl, J. (2000). causality: models, reason and inference. cambridge, uk: cambridg univers press. 

googl scholar (http://scholar.google.com/scholar_lookup?title=causality:+models,+reasoning+and+inference&au- 
thor=j.+pearl&publication_year=2000) 

pfeifer, r., and bongard, J. (2006). how the bodi shape the way We think: A new view of intelligence. cambridge, ma: 
mit press. 

googl scholar (http://scholar.google.com/scholar_lookup?ti- 
tle=how+the+body+shapes+the+way+we+think:+a+new+view+of+intelligence&author=r.+pfeifer&author=j.+bon- 
gard&publication_year=2006) 

rasmussen, c., and williams, C. (2006). gaussian process for machin learning. cambridge, ma: mit press, 1. 

googl scholar (http://scholar.google.com/scholar_lookup?title=gaussian+processes+for+machine+learning&au- 
thor=c.+rasmussen&author=c.+williams&publication_year=2006) 

ryan, R. m., and deci, E. L. (2000). intrins and extrins motivations: classic definit and new directions. contemp. 
educ. psychol. 25, 54–67. doi:10.1006/ceps.1999.1020 

pubm abstract (http://www.ncbi.nlm.nih.gov/sites/entrez?db=pubmed&cmd=showdetailview& 
termtosearch=10620381) | crossref full text (https://doi.org/10.1006/ceps.1999.1020) | googl scholar 
(http://scholar.google.com/scholar_lookup?title=intrinsic+and+extrinsic+motivations:+classic+definitions+and+new+di- 
rections&author=r.+m.+ryan&author=e.+l.+deci&journal=contemp.+educ.+psychol.&publication_year=2000&vol- 
ume=25&pages=54–67&doi=10.1006/ceps.1999.1020&pmid=10620381) 

salge, c., glackin, c., and polani, D. (2012). approxim of empower in the continu domain. adv. complex syst. 
16, 1250079. doi:10.1142/s0219525912500798 

crossref full text (https://doi.org/10.1142/s0219525912500798) | googl scholar (http://scholar.google.com 
/scholar_lookup?title=approximation+of+empowerment+in+the+continuous+domain&author=c.+salge&au- 
thor=c.+glackin&author=d.+polani&journal=adv.+complex+syst.&publication_year=2012&volume=16&pages=1250079& 
doi=10.1142/s0219525912500798) 

salge, c., glackin, c., and polani, D. (2013). “empower and state-depend noise-an intrins motiv for avoid 
unpredict agents,” in advanc in artifici life, ecal, vol. 12, 118–125. avail at: https://mitpress.mit.edu/sites/de- 
fault/files/titles/content/ecal13/ch018.html (https://mitpress.mit.edu/sites/default/files/titles/content/ecal13/ch018.html) 

googl scholar (http://scholar.google.com/scholar_lookup?title=“empowerment+and+state-dependent+noise-an+intrin- 
sic+motivation+for+avoiding+unpredictable+agents,”&author=c.+salge&author=c.+glackin&author=d.+polani&publica- 
tion_year=2013&volume=12&pages=118–125) 

salge, c., glackin, c., and polani, D. (2014a). chang the environ base on empower a intrins motivation. 
entropi 16, 2789. doi:10.3390/e16052789 

crossref full text (https://doi.org/10.3390/e16052789) | googl scholar (http://scholar.google.com/scholar_lookup?ti- 

frontier | empower As replac for the three law of robot | robot and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/ful 

30 sur 33 21/07/2017 19:08 



tle=changing+the+environment+based+on+empowerment+as+intrinsic+motivation&author=c.+salge&au- 
thor=c.+glackin&author=d.+polani&journal=entropy&publication_year=2014a&volume=16&pages=2789&doi=10.3390 
/e16052789) 

salge, c., glackin, c., and polani, D. (2014b). “empowerment: a rout toward the three law of robotics,” in seventh 
intern workshop on guid self-organization. freiburg. avail at: http://ml.informatik.uni-freiburg.de/ev 
/gso14/index (http://ml.informatik.uni-freiburg.de/events/gso14/index) 

googl scholar (http://scholar.google.com/scholar_lookup?title=“empowerment:+a+route+to- 
wards+the+three+laws+of+robotics,”&author=c.+salge&author=c.+glackin&author=d.+polani&conference=seventh+in- 
ternational+workshop+on+guided+self-organization&publication_year=2014b) 

salge, c., glackin, c., and polani, D. (2014c). “empower – an introduction,” in guid self-organization: incept 
(springer). avail at: https://link.springer.com/chapter/10.1007/978-3-642-53734-9_4?no-access=tru 
(https://link.springer.com/chapter/10.1007/978-3-642-53734-9_4?no-access=true) 

googl scholar (http://scholar.google.com/scholar_lookup?title=“empowerment+–+an+introduction,”&author=c.+salge& 
author=c.+glackin&author=d.+polani&publication_year=2014c) 

schmidhuber, J. (1991). “curiou model-build control systems,” in ieee intern joint confer on neural 
network (singapore: ieee), 1458–1463. 

googl scholar (http://scholar.google.com/scholar_lookup?title=“curious+model-building+control+systems,”&au- 
thor=j.+schmidhuber&conference=ieee+international+joint+conference+on+neural+networks&publication_year=1991& 
pages=1458–1463) 

seligman, M. E. (1975). helplessness: On depression, development, and death. new york, ny: WH freeman/tim 
books/henri holt & co. 

googl scholar (http://scholar.google.com/scholar_lookup?title=helplessness:+on+depression,+develop- 
ment,+and+death&author=m.+e.+seligman&publication_year=1975) 

shannon, C. E. (1948). A mathemat theori of communication. bell syst. tech. J. 27, 623–656. 
doi:10.1002/j.1538-7305.1948.tb00917.x 

crossref full text (https://doi.org/10.1002/j.1538-7305.1948.tb00917.x) | googl scholar (http://scholar.google.com 
/scholar_lookup?title=a+mathematical+theory+of+communication&author=c.+e.+shannon&jour- 
nal=bell+syst.+tech.+j.&publication_year=1948&volume=27&pages=623–656&doi=10.1002/j.1538-7305.1948.tb00917.x) 

singh, s., james, M. r., and rudary, M. R. (2004). “predict state representations: a new theori for model dynam 
systems,” in proceed of the twentieth confer on uncertainti in artifici intellig (uai), banff, 512–519. 

googl scholar (http://scholar.google.com/scholar_lookup?title=“predictive+state+representations:+a+new+the- 
ory+for+modeling+dynamical+systems,”&author=s.+singh&author=m.+r.+james&author=m.+r.+rudary&confer- 
ence=proceedings+of+the+twentieth+conference+on+uncertainty+in+artificial+intelligence+(uai)&publica- 
tion_year=2004&pages=512–519) 

steels, L. (2004). “the autotel principle,” in embodi artifici intelligence: intern seminar, dagstuhl castle, 
germany, juli 7–11, 2003. revis papers, ed F. iida, R. pfeifer, L. steels, and Y. kuniyoshi (berlin, heidelberg: springer), 
231–242. 

googl scholar (http://scholar.google.com/scholar_lookup?title=“the+autotelic+principle,”&author=l.+steels&publica- 
tion_year=2004&pages=231–242) 

sutton, R. s., and barto, A. G. (1998). reinforc learning. cambridge, ma: mit press. 

googl scholar (http://scholar.google.com/scholar_lookup?title=reinforcement+learning&author=r.+s.+sutton&au- 
thor=a.+g.+barto&publication_year=1998) 

trendafilov, d., and murray-smith, R. (2013). “information-theoret character of uncertainti in manual control,” in 
2013 ieee intern confer on systems, man, and cybernet (smc), manchester, 4913–4918. 

googl scholar (http://scholar.google.com/scholar_lookup?title=“information-theoretic+characterization+of+uncer- 
tainty+in+manual+control,”&author=d.+trendafilov&author=r.+murray-smith&conference=2013+ieee+interna- 
tional+conference+on+systems,+man,+and+cybernetics+(smc)&publication_year=2013&pages=4913–4918) 

von foerster, H. (2003). disorder/order: discoveri or invention? understand understand book subtitl essay on 
cybernet and cognition. new york: springer, 273–282. 

frontier | empower As replac for the three law of robot | robot and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/ful 

31 sur 33 21/07/2017 19:08 



googl scholar (http://scholar.google.com/scholar_lookup?title=disorder/order:+discovery+or+invention?+understand- 
ing+understanding+book+subtitle+essays+on+cybernetics+and+cognition&author=h.+von+foerster&publica- 
tion_year=2003) 

von uexküll, J. (1909). umwelt und innenwelt der tiere. berlin: springer. 

googl scholar (http://scholar.google.com/scholar_lookup?title=umwelt+und+innenwelt+der+tiere&au- 
thor=j.+von+uexküll&publication_year=1909) 

wissner-gross, a., and freer, C. (2013). causal entrop forces. phys. rev. lett. 110, 168702. 
doi:10.1103/physrevlett.110.168702 

pubm abstract (http://www.ncbi.nlm.nih.gov/sites/entrez?db=pubmed&cmd=showdetailview& 
termtosearch=23679649) | crossref full text (https://doi.org/10.1103/physrevlett.110.168702) | googl scholar 
(http://scholar.google.com/scholar_lookup?title=causal+entropic+forces&author=a.+wissner-gross&author=c.+freer& 
journal=phys.+rev.+lett.&publication_year=2013&volume=110&pages=168702&doi=10.1103/physrevlett.110.168702& 
pmid=23679649) 

ziemke, t., and sharkey, N. E. (2001). A stroll through the world of robot and animals: appli jakob von uexküll’ theori 
of mean to adapt robot and artifici life. semiotica 134, 701–746. doi:10.1515/semi.2001.050 

crossref full text (https://doi.org/10.1515/semi.2001.050) | googl scholar (http://scholar.google.com/scholar_lookup?ti- 
tle=a+stroll+through+the+worlds+of+robots+and+animals:+applying+jakob+von+uexküll’s+theory+of+mean- 
ing+to+adaptive+robots+and+artificial+life&author=t.+ziemke&author=n.+e.+sharkey&journal=semiotica&publica- 
tion_year=2001&volume=134&pages=701–746&doi=10.1515/semi.2001.050) 

frontier | empower As replac for the three law of robot | robot and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/ful 

32 sur 33 21/07/2017 19:08 



frontier | empower As replac for the three law of robot | robot and AI http://journal.frontiersin.org/article/10.3389/frobt.2017.00025/ful 

33 sur 33 21/07/2017 19:08 


