









































improv imag select for focu stack IN digit photographi 

david choi, aliya pazylbekova, wuhan zhou, and peter van beek 

cheriton school of comput science, univers of waterloo, canada 

abstract 

focu stacking, or all-in-focu imaging, be a techniqu for 
achiev larg depth of field in an imag by fuse imag 
acquir at differ focu distances. minim the set 
of imag to fuse, while ensur that the result fuse im- 
age be all-in-focus, be import in order to avoid long imag 
acquisit and post-process times. recently, an end-to- 
end system for focu stack have be propos that auto- 
matic select imag to acquire. the system be adapt to 
the scene be imag and show excel perform on 
a mobil device, where the len have a short focal length and 
fix aperture, and few imag need to be selected. however, 
with longer focal lengths, variabl apertures, and more se- 
lect imag (a exist with other cameras, notabl dslrs), 
classif and algorithm inaccuraci becom apparent. 
In thi paper, we propos improv to previou work that 
remov these limitations, and show on eight real scene that 
overal our techniqu lead to improv accuraci while re- 
duce the number of requir images. 

index terms— focu stacking, increas depth of field, 
comput photographi 

1. introduct 

focu stack combin sever imag captur at differ- 
ent focu distanc into a singl imag to produc a larg 
depth of field. It be use when the camera be unabl to ac- 
quir an all-in-focu imag or when the qualiti of an all-in- 
focu imag would be degrad becaus the narrow apertur 
result in a shutter speed too slow to freez motion. the mo- 
tivat for obtain an all-in-focu imag rang from the 
aesthet to the practical: architectural, interior, and macro 
photography, a well a pattern recognit and object detec- 
tion [2, 3]. 

An essenti part of focu stack be select the set of 
imag to be fused. the set must be small, in order to de- 
creas captur and fusion times, but must result in an all-in- 
focu image. time between imag captur can be on the 
order of seconds, so even gradual motion can impact quality. 
however, in contrast to a wide literatur on combin a set 
of imag into a singl imag (see, e.g., [4–6]), imag selec- 
tion have not receiv much attention. the simpl approach of 
move the len a uniform step-siz and acquir an imag at 

each step lead to set which contain imag with noth in 
focu or redund images. hasinoff et al. [7–9] consid 
the problem of quickli select the set of imag to cover a 
give depth of field. however, their analysi neglect camera 
overhead, imag post-processing, and rang without objects. 

vaquero et al. [1] present an end-to-end system that 
adapt select a minim set of high-resolut imag to 
acquir by process a stream of low-resolut one (which 
can be acquir quickly). It have the camera display a final all- 
in-focu image, allow the photograph to verifi the final 
result in the field (see fig. 1). their system show excel 
perform on a mobil device, where the len have a short 
focal length and a fix aperture. 

unfortunately, a we show, their techniqu which work 
well for mobil devic do not necessarili gener well to 
dslrs, which featur len with longer focal length and 
variabl apertures, and so requir mani more imag for fo- 
cu stacking. We propos improv to the work of va- 
quero et al. [1] which afford increas perform on non- 
mobil devices. our improv make use of shape from 
focu techniqu (see, e.g., [2, 10, 11]), supervis machin 
learn techniqu (see, e.g., [12,13]), and standard depth of 
field equat to improv on previou inefficiencies. empir- 
ically, on eight real scene and variou apertur settings, our 
techniqu lead to an overal improv accuraci while signif- 
icantli reduc the cardin of the select set of images. 

2. our propos 

We first summar vaquero et al.’ [1] system (see fig. 1), 
then describ our propos improvements. 

vaquero et al.’ [1] approach proce a follows: 
step 1. captur a stack of low-resolut imag p = 
0, . . . , n − 1 by sweep the len slowli enough that the 
depth of field for adjac imag overlap. 
step 2. overlay a grid on each imag and calcul a focu 
measur φi,j(p) for each cell (i, j) in the grid for each imag 
(see fig. 2). A focu measur map an imag to a valu that 
repres it degre of focu (see, e.g., [14–16]). let f(x, y) 
be the lumin at pixel (x, y) in an image. here, the focu 
measur for a cell of size w × h pixel be give by: 

φi,j(p) = 

h−1∑ 
x=0 

w−2∑ 
y=1 

| −f(x, y−1)+2f(x, y)−f(x, y+1) | . 



fig. 1. pipelin for vaquero et al.’ [1] end-to-end system for imag set select and fusion for an all-in-focu image. 

then, classifi each cell (i, j) in the grid a foreground iff the 
standard deviat of it focu measur across all imag be 
abov a give threshold t1 (see alg. 1, line 4). ignor back- 
ground cell in step 3. 

0 

0.1 

0.2 

0.3 

imag 

fo 
cu 

s 
m 

ea 
su 

re 

0.0 

1.0 

2.0 

3.0 

4.0·10 
−2 

imag 

fo 
cu 

s 
m 

ea 
su 

re 

fig. 2. focu measur construct for two cell from the 
exampl scene show in fig. 1; (left) cell with a well-defin 
peak; (right) cell where reliabl of the peak be less clear. 

step 3. A key insight of vaquero et al. [1] be that the prob- 
lem of select the final set of imag to fuse into a singl 
all-in-focu imag can be map to a set cover problem. 
let A be an m × n (0-1)-matrix. A row i of A be cover 
by a column j if the correspond matrix entri aij be equal 
to one. the set cover problem be to find a subset of the 
column C ⊆ {1, . . . , n} that minim the cardin of C 
such that everi row be covered; i.e., for everi i ∈ {1, . . . ,m} 
there exist a j ∈ C such that aij = 1. they setup a set cov- 
ere instanc where the row be the foreground cells, the 
column repres the images, and an entri be 1 if and onli 
if the cell be in-focu in that imag (base on whether φi,j(p) 
be within some threshold t2 of the maximum valu of that 
cell; see line 5–12 in alg. 1). In general, solv set cov- 
ere be np-hard [17], however, due to the consecut one 
properti present in focu stacking, select can be comput 
linearli in the number of imag [18]. 
step 4 & 5. acquir high-resolut imag at the specifi 
len posit of the set cover instanc and fuse them into 
a singl all-in-focu image. 

the issu aris in step 2 & 3 of their pipeline, where 
due to hand-craft heurist use t1 and t2, some cell be 
incorrectli classifi into foreground, background, in-focus, 
and out-of focus, and slightli incorrect peak be found. We 
now describ improv to address these problems. 

algorithm 1: vaquero et al. [1] hand-craft heuristic. 
input : focu measur φi,j(p), for each cell (i, j) and 

p = 0, . . . , n− 1; threshold t1 and t2 
output: set cover instanc a an m× n (0,1)-matrix 

A = [ak,p] 
1 k ← 0; 
2 foreach cell (i, j) do 
3 σ = std{φi,j(p) | p = 0, . . . , n− 1}; 
4 if σ > t1 then 
5 ak,p ← 0, p = 0, . . . , n− 1; 
6 M = argmax 

p=0,...,n−1 
{φi,j(p)}; 

7 ak,m ← 1; 
8 p←m − 1; 
9 while φi,j(m)− φi,j(p) < t2 and ak,p+1 = 1 

do ak,p ← 1; p← p− 1; ; 
10 p←m + 1; 
11 while φi,j(m)− φi,j(p) < t2 and ak,p−1 = 1 

do ak,p ← 1; p← p+ 1; ; 
12 k ← k + 1; 

2.1. construct an explicit depth map 

rather than classifi a cell a foreground or background (step 
2, line 4 in alg. 1) we construct an explicit depth map us- 
ing shape from focu techniqu [2, 10, 11] and use super- 
vise machin learn to construct a classifi that predict 
whether a depth estim be reliabl or unreliable. An exam- 
ple of an unreli depth estim be a plain white wall that 
lack contrast or texture. note that vaquero et al. [1] implic- 
itli construct a depth map and classifi estim (into what 
they call foreground and background) by use the standard 
deviat of focu measur for a cell. 

To construct a depth map, we use the standard method 
where the len posit of the focu measur peak in a cell 
across all imag be the estim of the depth of the scene 
at that cell. the map be improv by smooth the fo- 
cu measur for a cell to reduc depth estim noise, and 
find the peak of the smooth focu measures. smooth 



consist of sum the measur of the cell under consid- 
erat and eight adjac cell (or few at boundaries). 

We construct the classifi for depth estim relia- 
biliti by train a decis tree [19] base on 60 featur of 
each cell, one of which be the standard deviat use by 
vaquero et al. [1], to creat a more robust classification. 

2.2. classifi in-focu and out-of-focu 

onc the depth estim for a cell have be comput and 
classifi a reliable, the next step be to determin which len 
posit around the peak be in accept focus. vaquero 
et al. [1] use a simpl heurist where consecut len po- 
sition whose focu measur be within some toler t2 
of the peak be deem to be in accept focu (step 3, 
line 9 & 11 in alg. 1). however, while intuitive, thi heuris- 
tic reli on two assumpt that do not hold in general. 

first, the heurist assum that a focu measur close to 
the peak in absolut term be also in accept focus. how- 
ever, focu curv often have distinguish peak but small 
absolut heights. In these cases, reason toler valu 
inaccur deem most or all of the len posit a in-focus. 
second, the heurist assum that the apertur at which low- 
resolut imag be acquir from the live preview stream be 
the same a the apertur at which high-resolut imag will 
be acquired. however, to improv the accuraci of focu 
and to maintain a fast shutter speed (approxim twice the 
video frame rate), in live preview mode the camera open the 
apertur a wide a possibl give the bright of the scene. 
typically, thi can be a differ a a wide apertur of f/1.4 
versu a narrow apertur of f/8.0, and ani depth of field 
estim from the wide apertur would not be accur for the 
narrow aperture. 

rather than estim depth of field from the focu mea- 
sure we propos to instead use standard depth of field equa- 
tion to predict in-focu and out-of-focus, 

h = 
f2 

ac 
+f, dnear = 

d(h− f) 
h+ d− 2f 

, dfar = 
d(h− f) 
h− d 

, 

where a be the aperture, c be the circl of confusion, d be the 
distanc to the subject, f be the focal length of the lens, h be the 
hyperfoc distance, and all calcul be in millimeters. 
the circl of confus be the diamet of the larg blur spot 
indistinguish from a focu point sourc of light [20], 
and have establish valu for most contexts. 

after comput a distanc interv [dnear , dfar ], repre- 
sent a depth of field in millimeters, that would lead to in- 
focu objects, one must comput an accept len interval, 
repres start and end len positions. thi be accu- 
rate do by determin which len posit correspond 
to the distanc mark on a lens, and interpol between 
these len posit to determin the remain ones. interpo- 
lation us the differ in reciproc of the distanc time 
the proport of the distanc between len positions. 

2.3. robust select of imag via set cover 

To improv imag select (step 3) robustness, we use the 
explicitli construct depth map to augment the set cover- 
ing instanc a follows. let L be the set of peak classifi 
a reliabl in the depth map. for each consecut sequenc 
of len posit pi, pi+1, . . . , pi+k in L, such that pi−1 and 
pi+k+1 do not occur in L, the len posit pi−1 and pi+k+1 
be add to L. the augment set L be then use to construct 
the set cover instance, where each element of L be a row in 
the set cover matrix. thi augment smooth the dis- 
crete natur of divid an imag into a grid, which address 
problem like dramat depth chang between adjac cell 
of continu object (such a a book angl sharpli away). 
smooth make imag select more accur while occa- 
sional modestli increas the number of imag selected. 

3. experiment evalu 

In thi section, we perform a compar evalu of our 
improv with the baselin vaquero et al. [1] approach1. 

3.1. experiment methodolog 

imag sets. We acquir eight benchmark imag set use a 
camera remot control applic we implemented. A canon 
eo 550d/rebel t2i camera be tether to a comput via 
a usb cabl and control by software, which make use of 
the canon sdk (version 2.11). the canon sdk do not 
expos function for sweep the len (step 1, fig. 1) so 
we simul the effect by step the len through the pos- 
sibl len posit and acquir a 1056×704 low resolut 
imag from the live preview stream at each step. for evalua- 
tion, 5184× 3456 high resolut imag be also acquir 
at each len position. 

decis tree training. We construct label train 
data by consensu for the depth estim reliabl deci- 
sion tree classifi by overlay a grid on the low resolu- 
tion imag and visual inspect each cell to determin 
the peak focu posit (or no valid peak if the cell lack 
contrast or have multipl peaks, a would occur with a blank 
wall or multipl occlud objects). the decis tree itself 
consid about 60 featur base on properti of the fo- 
cu measur curv and depth maps. one feature—kurtosis, 
a statist measur base on the fourth moment of the fo- 
cu measures—wa the most predict featur by far, clearli 
domin standard deviat use by vaquero et al.’ [1] ap- 
proach. To learn the decis tree, we use weka’ j48 [21]. 
We experi with paramet that lead to complex trees, 
but reason set lead to tree with a singl node: kurto- 
sis. for the experi report here we favor simplic 
at the expens of some accuracy. 

1the implement and data be avail at: https://cs. 
uwaterloo.ca/˜vanbeek. 



tabl 1. number of imag select (m) and accuraci (acc.) of our method and vaquero et al.’ [1] method compar to the 
minimum possibl number of imag need (gold), for variou benchmarks, grid sizes, and apertures. the coin and flower 
benchmark be acquir with a 200mm lens; the remain benchmark be acquir with a 50mm lens. 

wide our vaquero narrow our vaquero 
grid size benchmark aper. gold m acc. m acc. aper. gold m acc. m acc. 

backyard f/1.4 31 30 97.5 21 80.9 f/8.0 5 5 99.2 11 100.0 
bar f/1.4 12 13 98.5 8 80.0 f/8.0 2 3 100.0 4 88.3 
book f/1.4 72 81 96.0 34 55.7 f/8.0 11 11 99.0 16 89.8 
build f/2.0 14 14 100.0 16 100.0 f/8.0 2 2 100.0 7 100.0 

16× 24 can f/1.4 19 34 97.1 5 16.9 f/8.0 5 5 99.5 4 67.7 
coin f/2.8 16 18 100.0 16 93.6 f/8.0 16 18 100.0 9 59.2 
flower f/2.8 30 33 71.7 22 38.6 f/8.0 14 16 89.8 10 48.6 
trail f/4.0 5 5 100.0 10 100.0 f/8.0 3 3 99.1 4 100.0 
averag 24.9 28.5 95.1 16.5 70.7 7.4 7.9 98.0 8.1 81.7 
backyard f/1.4 33 35 100.0 37 99.7 f/8.0 5 5 100.0 31 100.0 
bar f/1.4 12 18 100.0 44 100.0 f/8.0 2 3 100.0 20 100.0 
book f/1.4 87 95 100.0 76 90.8 f/8.0 11 12 100.0 41 100.0 
build f/2.0 15 15 100.0 16 100.0 f/8.0 3 3 100.0 16 100.0 

32× 48 can f/1.4 18 34 100.0 84 100.0 f/8.0 4 5 100.0 9 100.0 
coin f/2.8 16 18 100.0 26 100.0 f/8.0 16 18 100.0 18 100.0 
flower f/2.8 35 41 91.2 163 79.3 f/8.0 15 19 96.1 96 93.4 
trail f/4.0 5 6 100.0 21 100.0 f/8.0 3 3 99.6 21 100.0 
averag 27.6 32.8 98.9 58.4 96.2 7.4 8.5 99.5 31.5 99.2 

paramet selection: t1 and t2. vaquero et al.’ approach 
requir set for the threshold t1 and t2 (line 4, 9 & 11 
in alg. 1). for a fair comparison, we choos the optim val- 
ues. threshold t1 be set to the valu that best fit all the abov 
train data. threshold t2 be set by iter run our 
evalu search for the optim accuraci or, within accu- 
racy, the low number of images. 

perform evaluation. We compar the approach us- 
ing two perform measures: (i) number of imag select 
and (ii) accuraci a measur by the percentag of cell in a 
grid that be in focus. To compar against the minim num- 
ber of imag need and to determin the accuraci of the two 
approaches, we construct a gold standard depth map for a 
scene use the set of high resolut imag for the scene. 
We use an adapt of 8-fold cross-valid to obtain re- 
liabl estim of the perform of our approach (see [22], 
pp. 161-205), where for each of the eight benchmark in turn, 
we train on the other seven and test on that benchmark. 

fig. 3. all-in-focu imag obtain by fuse select high 
resolut imag use f/8.0 apertur and 32 × 48 grid. 

3.2. experiment result 

tabl 1 summar the result of empir evaluation. On 
these benchmarks, our method be more accur than vaquero 
et al.’ [1] for the coarser grid, and have compar accuraci 
with mani few imag on the finer grid. for the most im- 
portant case, a 32 × 48 grid and narrow aperture, both meth- 
od have excel accuracy. however, our approach be close 
to the minimum possibl number of imag and a signific 
reduct over the number of imag select by vaquero et 
al.’ [1] method with an averag of 4.5 time few images, 
which would significantli reduc imag acquisit time (the 
time between imag captur often exce two seconds). se- 
lection algorithm run time remain negligible. We also 
compar the post-process imag fusion times. In photo- 
shop cs5 our improv reduc post-process time 
by up to ten times. for example, for a 32× 48 grid and a nar- 
row aperture, the time (mm:ss) for fuse the imag select 
use our improv rang from 0:30 to 3:00 compar 
to 1:30 to 31:00 for the imag select by vaquero et al.’ [1] 
approach. 

4. conclus 

We propos enhanc to a propos by vaquero et al. [1] 
that improv their imag select on camera with variabl 
apertur and len with longer focal lengths. our approach 
maintain equival or good accuracy, while significantli re- 
duce the cardin of the select set of images. 



5. refer 

[1] D. vaquero, N. gelfand, M. tico, K. pulli, and M. turk, 
“gener autofocus,” in proceed of the ieee 
workshop on applic of comput vision, 2011. 

[2] P. grossman, “depth from focus,” pattern recognit 
letters, vol. 5, pp. 63–69, 1987. 

[3] J. gulbin and R. gulbins, photograph multishot 
techniques: high dynam range, super-resolution, 
extend depth of field, stitching, rocki nook, 2009. 

[4] T. mertens, J. kautz, and F. V. reeth, “exposur fu- 
sion,” in proc. of pacif graphics, 2007. 

[5] W. B. seal and S. dutta, “everywhere-in-focu im- 
age fusion use control cameras,” in proceed 
of spie 2905, sensor fusion and distribut robot 
agents, 1996, pp. 227–234. 

[6] C. zhang, J. W. bastian, C. shen, A. van den hengel, 
and T. shen, “extend depth-of-field via focu stack- 
ing and graph cuts,” in proceed of the ieee in- 
ternat confer on imag processing, 2013, pp. 
1272–1276. 

[7] S. W. hasinoff and K. N. kutulakos, “light-effici 
photography,” ieee trans. pattern analysi and ma- 
chine intelligence, vol. 33, pp. 2203–2214, 2011. 

[8] S. W. hasinoff, K. N. kutulakos, F. durand, and W. T. 
freeman, “time-constrain photography,” in proceed- 
ing of the ieee intern confer on comput 
vision, 2009, pp. 333–340. 

[9] K. N. kutulako and S. W. hasinoff, “focal stack pho- 
tography: high-perform photographi with a con- 
vention camera,” in proceed of the eleventh iapr 
confer on machin vision applications, 2009, pp. 
332–337. 

[10] S. K. nayar and Y. nakagawa, “shape from focus,” 
ieee trans. pattern anal. mach. intell., vol. 16, pp. 
824–831, 1994. 

[11] s.-o. shim and t.-s. choi, “A novel iter shape from 
focu algorithm base on combinatori optimization,” 
pattern recognition, vol. 43, no. 10, pp. 3338–3347, 
2010. 

[12] I. H. witten, E. frank, and M. A. hall, data mining, 
morgan kaufmann, 3rd edition, 2011. 

[13] T. hastie, R. tibshirani, and J. friedman, the element 
of statist learning: data mining, infer and pre- 
diction, springer, 2nd edition, 2009. 

[14] F. C. A. groen, I. T. young, and G. ligthart, “A com- 
parison of differ focu function for use in autofocu 
algorithms,” cytometry, vol. 6, pp. 81–91, 1985. 

[15] M. subbarao and j.-k. tyan, “select the optim 
focu measur for autofocus and depth-from-focus,” 
ieee trans. pattern anal. mach. intell., vol. 20, pp. 
864–870, 1998. 

[16] H. mir, P. xu, and P. van beek, “an extens empir 
evalu of focu measur for digit photography,” 
in proc. spie 9023, digit photographi X, 2014. 

[17] M. R. garey and D. S. johnson, comput and in- 
tractability: A guid to the theori of np-completeness, 
W. H. freeman, 1979. 

[18] G. L. nemhaus and L. A. wolsey, integ and combi- 
natori optimization, wiley, 1988. 

[19] J. R. quinlan, c4.5: program for machin learning, 
morgan kaufmann, 1993. 

[20] C. S. johnson, jr., scienc for the curiou photogra- 
pher, A K peters, ltd., 2010. 

[21] M. hall, E. frank, G. holmes, B. pfahringer, P. reute- 
mann, and I. H. witten, “the weka data mine soft- 
ware: An update,” sigkdd explorations, vol. 11, 2009. 

[22] N. japkowicz and M. shah, evalu learn algo- 
rithms: A classif perspective, cambridg uni- 
versiti press, 2011. 


